[{"id": "1907.00020", "submitter": "Mikhail Yurochkin", "authors": "Mikhail Yurochkin, Amanda Bower and Yuekai Sun", "title": "Training individually fair ML models with Sensitive Subspace Robustness", "comments": "ICLR 2020 (spotlight)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider training machine learning models that are fair in the sense that\ntheir performance is invariant under certain sensitive perturbations to the\ninputs. For example, the performance of a resume screening system should be\ninvariant under changes to the gender and/or ethnicity of the applicant. We\nformalize this notion of algorithmic fairness as a variant of individual\nfairness and develop a distributionally robust optimization approach to enforce\nit during training. We also demonstrate the effectiveness of the approach on\ntwo ML tasks that are susceptible to gender and racial biases.\n", "versions": [{"version": "v1", "created": "Fri, 28 Jun 2019 18:11:25 GMT"}, {"version": "v2", "created": "Fri, 13 Mar 2020 05:25:24 GMT"}], "update_date": "2020-03-16", "authors_parsed": [["Yurochkin", "Mikhail", ""], ["Bower", "Amanda", ""], ["Sun", "Yuekai", ""]]}, {"id": "1907.00025", "submitter": "Carlo Vittorio Cannistraci", "authors": "Alessandro Muscoloni and Carlo Vittorio Cannistraci", "title": "Angular separability of data clusters or network communities in\n  geometrical space and its relevance to hyperbolic embedding", "comments": "arXiv admin note: text overlap with arXiv:1802.01183", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI physics.soc-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Analysis of 'big data' characterized by high-dimensionality such as word\nvectors and complex networks requires often their representation in a\ngeometrical space by embedding. Recent developments in machine learning and\nnetwork geometry have pointed out the hyperbolic space as a useful framework\nfor the representation of this data derived by real complex physical systems.\nIn the hyperbolic space, the radial coordinate of the nodes characterizes their\nhierarchy, whereas the angular distance between them represents their\nsimilarity. Several studies have highlighted the relationship between the\nangular coordinates of the nodes embedded in the hyperbolic space and the\ncommunity metadata available. However, such analyses have been often limited to\na visual or qualitative assessment. Here, we introduce the angular separation\nindex (ASI), to quantitatively evaluate the separation of node network\ncommunities or data clusters over the angular coordinates of a geometrical\nspace. ASI is particularly useful in the hyperbolic space - where it is\nextensively tested along this study - but can be used in general for any\nassessment of angular separation regardless of the adopted geometry. ASI is\nproposed together with an exact test statistic based on a uniformly random null\nmodel to assess the statistical significance of the separation. We show that\nASI allows to discover two significant phenomena in network geometry. The first\nis that the increase of temperature in 2D hyperbolic network generative models,\nnot only reduces the network clustering but also induces a 'dimensionality\njump' of the network to dimensions higher than two. The second is that ASI can\nbe successfully applied to detect the intrinsic dimensionality of network\nstructures that grow in a hidden geometrical space.\n", "versions": [{"version": "v1", "created": "Fri, 28 Jun 2019 18:23:30 GMT"}], "update_date": "2019-07-03", "authors_parsed": [["Muscoloni", "Alessandro", ""], ["Cannistraci", "Carlo Vittorio", ""]]}, {"id": "1907.00030", "submitter": "Rares-Darius Buhai", "authors": "Rares-Darius Buhai, Yoni Halpern, Yoon Kim, Andrej Risteski, David\n  Sontag", "title": "Empirical Study of the Benefits of Overparameterization in Learning\n  Latent Variable Models", "comments": "22 pages, to appear at ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the most surprising and exciting discoveries in supervised learning\nwas the benefit of overparameterization (i.e. training a very large model) to\nimproving the optimization landscape of a problem, with minimal effect on\nstatistical performance (i.e. generalization). In contrast, unsupervised\nsettings have been under-explored, despite the fact that it was observed that\noverparameterization can be helpful as early as Dasgupta & Schulman (2007). We\nperform an empirical study of different aspects of overparameterization in\nunsupervised learning of latent variable models via synthetic and\nsemi-synthetic experiments. We discuss benefits to different metrics of success\n(recovering the parameters of the ground-truth model, held-out log-likelihood),\nsensitivity to variations of the training algorithm, and behavior as the amount\nof overparameterization increases. We find that across a variety of models\n(noisy-OR networks, sparse coding, probabilistic context-free grammars) and\ntraining algorithms (variational inference, alternating minimization,\nexpectation-maximization), overparameterization can significantly increase the\nnumber of ground truth latent variables recovered.\n", "versions": [{"version": "v1", "created": "Fri, 28 Jun 2019 18:31:52 GMT"}, {"version": "v2", "created": "Mon, 15 Jun 2020 13:41:15 GMT"}, {"version": "v3", "created": "Thu, 16 Jul 2020 06:43:28 GMT"}], "update_date": "2020-07-17", "authors_parsed": [["Buhai", "Rares-Darius", ""], ["Halpern", "Yoni", ""], ["Kim", "Yoon", ""], ["Risteski", "Andrej", ""], ["Sontag", "David", ""]]}, {"id": "1907.00031", "submitter": "Vaden Masrani", "authors": "Vaden Masrani, Tuan Anh Le and Frank Wood", "title": "The Thermodynamic Variational Objective", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the thermodynamic variational objective (TVO) for learning in\nboth continuous and discrete deep generative models. The TVO arises from a key\nconnection between variational inference and thermodynamic integration that\nresults in a tighter lower bound to the log marginal likelihood than the\nstandard variational variational evidence lower bound (ELBO) while remaining as\nbroadly applicable. We provide a computationally efficient gradient estimator\nfor the TVO that applies to continuous, discrete, and non-reparameterizable\ndistributions and show that the objective functions used in variational\ninference, variational autoencoders, wake sleep, and inference compilation are\nall special cases of the TVO. We use the TVO to learn both discrete and\ncontinuous deep generative models and empirically demonstrate state of the art\nmodel and inference network learning.\n", "versions": [{"version": "v1", "created": "Fri, 28 Jun 2019 18:33:05 GMT"}, {"version": "v2", "created": "Tue, 29 Oct 2019 18:45:23 GMT"}, {"version": "v3", "created": "Thu, 31 Oct 2019 16:43:05 GMT"}, {"version": "v4", "created": "Tue, 26 Nov 2019 21:13:25 GMT"}, {"version": "v5", "created": "Wed, 7 Apr 2021 19:25:48 GMT"}], "update_date": "2021-04-09", "authors_parsed": [["Masrani", "Vaden", ""], ["Le", "Tuan Anh", ""], ["Wood", "Frank", ""]]}, {"id": "1907.00032", "submitter": "Jos\\'e Camacho", "authors": "Jos\\'e Camacho, Evrim Acar, Morten A. Rasmussen, Rasmus Bro", "title": "Cross-product Penalized Component Analysis (XCAN)", "comments": null, "journal-ref": "Chemometrics and Intelligent Laboratory Systems, 2020, 203:\n  104038-", "doi": "10.1016/j.chemolab.2020.104038.", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Matrix factorization methods are extensively employed to understand complex\ndata. In this paper, we introduce the cross-product penalized component\nanalysis (XCAN), a sparse matrix factorization based on the optimization of a\nloss function that allows a trade-off between variance maximization and\nstructural preservation. The approach is based on previous developments,\nnotably (i) the Sparse Principal Component Analysis (SPCA) framework based on\nthe LASSO, (ii) extensions of SPCA to constrain both modes of the\nfactorization, like co-clustering or the Penalized Matrix Decomposition (PMD),\nand (iii) the Group-wise Principal Component Analysis (GPCA) method. The result\nis a flexible modeling approach that can be used for data exploration in a\nlarge variety of problems. We demonstrate its use with applications from\ndifferent disciplines.\n", "versions": [{"version": "v1", "created": "Fri, 28 Jun 2019 18:33:43 GMT"}], "update_date": "2020-11-19", "authors_parsed": [["Camacho", "Jos\u00e9", ""], ["Acar", "Evrim", ""], ["Rasmussen", "Morten A.", ""], ["Bro", "Rasmus", ""]]}, {"id": "1907.00038", "submitter": "Afshin Rostamizadeh", "authors": "Jean-Fran\\c{c}ois Kagy, Tolga Kayadelen, Ji Ma, Afshin Rostamizadeh,\n  Jana Strnadova", "title": "The Practical Challenges of Active Learning: Lessons Learned from Live\n  Experimentation", "comments": "Presented at 2019 ICML Workshop on Human in the Loop Learning (HILL\n  2019), Long Beach, USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We tested in a live setting the use of active learning for selecting text\nsentences for human annotations used in training a Thai segmentation machine\nlearning model. In our study, two concurrent annotated samples were\nconstructed, one through random sampling of sentences from a text corpus, and\nthe other through model-based scoring and ranking of sentences from the same\ncorpus. In the course of the experiment, we observed the effect of significant\nchanges to the learning environment which are likely to occur in real-world\nlearning tasks. We describe how our active learning strategy interacted with\nthese events and discuss other practical challenges encountered in using active\nlearning in the live setting.\n", "versions": [{"version": "v1", "created": "Fri, 28 Jun 2019 18:56:20 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Kagy", "Jean-Fran\u00e7ois", ""], ["Kayadelen", "Tolga", ""], ["Ma", "Ji", ""], ["Rostamizadeh", "Afshin", ""], ["Strnadova", "Jana", ""]]}, {"id": "1907.00058", "submitter": "Carlo Biffi", "authors": "Carlo Biffi, Juan J. Cerrolaza, Giacomo Tarroni, Wenjia Bai, Antonio\n  de Marvao, Ozan Oktay, Christian Ledig, Loic Le Folgoc, Konstantinos\n  Kamnitsas, Georgia Doumou, Jinming Duan, Sanjay K. Prasad, Stuart A. Cook,\n  Declan P. O'Regan, and Daniel Rueckert", "title": "Explainable Anatomical Shape Analysis through Deep Hierarchical\n  Generative Models", "comments": "Accepted for publication in IEEE Transactions on Medical Imaging\n  (TMI)", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantification of anatomical shape changes currently relies on scalar global\nindexes which are largely insensitive to regional or asymmetric modifications.\nAccurate assessment of pathology-driven anatomical remodeling is a crucial step\nfor the diagnosis and treatment of many conditions. Deep learning approaches\nhave recently achieved wide success in the analysis of medical images, but they\nlack interpretability in the feature extraction and decision processes. In this\nwork, we propose a new interpretable deep learning model for shape analysis. In\nparticular, we exploit deep generative networks to model a population of\nanatomical segmentations through a hierarchy of conditional latent variables.\nAt the highest level of this hierarchy, a two-dimensional latent space is\nsimultaneously optimised to discriminate distinct clinical conditions, enabling\nthe direct visualisation of the classification space. Moreover, the anatomical\nvariability encoded by this discriminative latent space can be visualised in\nthe segmentation space thanks to the generative properties of the model, making\nthe classification task transparent. This approach yielded high accuracy in the\ncategorisation of healthy and remodelled left ventricles when tested on unseen\nsegmentations from our own multi-centre dataset as well as in an external\nvalidation set, and on hippocampi from healthy controls and patients with\nAlzheimer's disease when tested on ADNI data. More importantly, it enabled the\nvisualisation in three-dimensions of both global and regional anatomical\nfeatures which better discriminate between the conditions under exam. The\nproposed approach scales effectively to large populations, facilitating\nhigh-throughput analysis of normal anatomy and pathology in large-scale studies\nof volumetric imaging.\n", "versions": [{"version": "v1", "created": "Fri, 28 Jun 2019 19:58:08 GMT"}, {"version": "v2", "created": "Sat, 4 Jan 2020 13:54:23 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Biffi", "Carlo", ""], ["Cerrolaza", "Juan J.", ""], ["Tarroni", "Giacomo", ""], ["Bai", "Wenjia", ""], ["de Marvao", "Antonio", ""], ["Oktay", "Ozan", ""], ["Ledig", "Christian", ""], ["Folgoc", "Loic Le", ""], ["Kamnitsas", "Konstantinos", ""], ["Doumou", "Georgia", ""], ["Duan", "Jinming", ""], ["Prasad", "Sanjay K.", ""], ["Cook", "Stuart A.", ""], ["O'Regan", "Declan P.", ""], ["Rueckert", "Daniel", ""]]}, {"id": "1907.00063", "submitter": "Tammo Rukat", "authors": "Tammo Rukat, Christopher Yau", "title": "Bayesian Nonparametric Boolean Factor Models", "comments": "Presented at the 2018 NeurIPS Workshop on Bayesian Nonparametrics", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We build upon probabilistic models for Boolean Matrix and Boolean Tensor\nfactorisation that have recently been shown to solve these problems with\nunprecedented accuracy and to enable posterior inference to scale to Billions\nof observation. Here, we lift the restriction of a pre-specified number of\nlatent dimensions by introducing an Indian Buffet Process prior over factor\nmatrices. Not only does the full factor-conditional take a computationally\nconvenient form due to the logical dependencies in the model, but also the\nposterior over the number of non-zero latent dimensions is remarkably simple.\nIt amounts to counting the number false and true negative predictions, whereas\npositive predictions can be ignored. This constitutes a very transparent\nexample of sampling-based posterior inference with an IBP prior and,\nimportantly, lets us maintain extremely efficient inference. We discuss\napplications to simulated data, as well as to a real world data matrix with 6\nMillion entries.\n", "versions": [{"version": "v1", "created": "Fri, 28 Jun 2019 20:28:18 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Rukat", "Tammo", ""], ["Yau", "Christopher", ""]]}, {"id": "1907.00089", "submitter": "Ramin Mohammadi", "authors": "Ramin Mohammadi, Sarthak Jain, Stephen Agboola, Ramya Palacholla,\n  Sagar Kamarthi, Byron C. Wallace", "title": "Learning to Identify Patients at Risk of Uncontrolled Hypertension Using\n  Electronic Health Records Data", "comments": "Accepted at The AMIA informatics summit 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hypertension is a major risk factor for stroke, cardiovascular disease, and\nend-stage renal disease, and its prevalence is expected to rise dramatically.\nEffective hypertension management is thus critical. A particular priority is\ndecreasing the incidence of uncontrolled hypertension. Early identification of\npatients at risk for uncontrolled hypertension would allow targeted use of\npersonalized, proactive treatments. We develop machine learning models\n(logistic regression and recurrent neural networks) to stratify patients with\nrespect to the risk of exhibiting uncontrolled hypertension within the coming\nthree-month period. We trained and tested models using EHR data from 14,407 and\n3,009 patients, respectively. The best model achieved an AUROC of 0.719,\noutperforming the simple, competitive baseline of relying prediction based on\nthe last BP measure alone (0.634). Perhaps surprisingly, recurrent neural\nnetworks did not outperform a simple logistic regression for this task,\nsuggesting that linear models should be included as strong baselines for\npredictive tasks using EHR\n", "versions": [{"version": "v1", "created": "Fri, 28 Jun 2019 21:33:40 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Mohammadi", "Ramin", ""], ["Jain", "Sarthak", ""], ["Agboola", "Stephen", ""], ["Palacholla", "Ramya", ""], ["Kamarthi", "Sagar", ""], ["Wallace", "Byron C.", ""]]}, {"id": "1907.00098", "submitter": "Min Wu", "authors": "Min Wu and Marta Kwiatkowska", "title": "Robustness Guarantees for Deep Neural Networks on Videos", "comments": "To appear in 2020 IEEE/CVF Conference on Computer Vision and Pattern\n  Recognition (CVPR)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The widespread adoption of deep learning models places demands on their\nrobustness. In this paper, we consider the robustness of deep neural networks\non videos, which comprise both the spatial features of individual frames\nextracted by a convolutional neural network and the temporal dynamics between\nadjacent frames captured by a recurrent neural network. To measure robustness,\nwe study the maximum safe radius problem, which computes the minimum distance\nfrom the optical flow sequence obtained from a given input to that of an\nadversarial example in the neighbourhood of the input. We demonstrate that,\nunder the assumption of Lipschitz continuity, the problem can be approximated\nusing finite optimisation via discretising the optical flow space, and the\napproximation has provable guarantees. We then show that the finite\noptimisation problem can be solved by utilising a two-player turn-based game in\na cooperative setting, where the first player selects the optical flows and the\nsecond player determines the dimensions to be manipulated in the chosen flow.\nWe employ an anytime approach to solve the game, in the sense of approximating\nthe value of the game by monotonically improving its upper and lower bounds. We\nexploit a gradient-based search algorithm to compute the upper bounds, and the\nadmissible A* algorithm to update the lower bounds. Finally, we evaluate our\nframework on the UCF101 video dataset.\n", "versions": [{"version": "v1", "created": "Fri, 28 Jun 2019 22:27:17 GMT"}, {"version": "v2", "created": "Fri, 6 Dec 2019 16:53:11 GMT"}, {"version": "v3", "created": "Fri, 3 Apr 2020 18:07:06 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Wu", "Min", ""], ["Kwiatkowska", "Marta", ""]]}, {"id": "1907.00103", "submitter": "Matthew Streeter", "authors": "Matthew Streeter", "title": "Learning Effective Loss Functions Efficiently", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of learning a loss function which, when minimized\nover a training dataset, yields a model that approximately minimizes a\nvalidation error metric. Though learning an optimal loss function is NP-hard,\nwe present an anytime algorithm that is asymptotically optimal in the worst\ncase, and is provably efficient in an idealized \"easy\" case. Experimentally, we\nshow that this algorithm can be used to tune loss function hyperparameters\norders of magnitude faster than state-of-the-art alternatives. We also show\nthat our algorithm can be used to learn novel and effective loss functions\non-the-fly during training.\n", "versions": [{"version": "v1", "created": "Fri, 28 Jun 2019 22:35:17 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Streeter", "Matthew", ""]]}, {"id": "1907.00107", "submitter": "Ahmadreza Momeni", "authors": "Yonatan Gur and Ahmadreza Momeni", "title": "Adaptive Sequential Experiments with Unknown Information Arrival\n  Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sequential experiments are often characterized by an exploration-exploitation\ntradeoff that is captured by the multi-armed bandit (MAB) framework. This\nframework has been studied and applied, typically when at each time period\nfeedback is received only on the action that was selected at that period.\nHowever, in many practical settings additional data may become available\nbetween decision epochs. We introduce a generalized MAB formulation, which\nconsiders a broad class of distributions that are informative about mean\nrewards, and allows observations from these distributions to arrive according\nto an arbitrary and a priori unknown arrival process. When it is known how to\nmap auxiliary data to reward estimates, by obtaining matching lower and upper\nbounds we characterize a spectrum of minimax complexities for this class of\nproblems as a function of the information arrival process, which captures how\nsalient characteristics of this process impact achievable performance. In terms\nof achieving optimal performance, we establish that upper confidence bound and\nposterior sampling policies possess natural robustness with respect to the\ninformation arrival process without any adjustments, which uncovers a novel\nproperty of these popular policies and further lends credence to their appeal.\nWhen the mappings connecting auxiliary data and rewards are a priori unknown,\nwe characterize necessary and sufficient conditions under which auxiliary\ninformation allows performance improvement. We devise a new policy that is\nbased on two different upper confidence bounds (one that accounts for auxiliary\nobservation and one that does not) and establish the near-optimality of this\npolicy. We use data from a large media site to analyze the value that may be\ncaptured in practice by leveraging auxiliary data for designing content\nrecommendations.\n", "versions": [{"version": "v1", "created": "Fri, 28 Jun 2019 22:40:47 GMT"}, {"version": "v2", "created": "Mon, 6 Apr 2020 00:57:48 GMT"}, {"version": "v3", "created": "Thu, 9 Apr 2020 21:29:46 GMT"}, {"version": "v4", "created": "Wed, 11 Nov 2020 07:18:43 GMT"}, {"version": "v5", "created": "Fri, 13 Nov 2020 22:39:03 GMT"}, {"version": "v6", "created": "Fri, 18 Dec 2020 19:13:30 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Gur", "Yonatan", ""], ["Momeni", "Ahmadreza", ""]]}, {"id": "1907.00109", "submitter": "Alessandro Ferrero Mr.", "authors": "Alessandro Ferrero, Shireen Elhabian, Ross Whitaker", "title": "SetGAN: Improving the stability and diversity of generative models\n  through a permutation invariant architecture", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative adversarial networks (GANs) have proven effective in modeling\ndistributions of high-dimensional data. However, their training instability is\na well-known hindrance to convergence, which results in practical challenges in\ntheir applications to novel data. Furthermore, even when convergence is\nreached, GANs can be affected by mode collapse, a phenomenon for which the\ngenerator learns to model only a small part of the target distribution,\ndisregarding the vast majority of the data manifold or distribution. This paper\naddresses these challenges by introducing SetGAN, an adversarial architecture\nthat processes sets of generated and real samples, and discriminates between\nthe origins of these sets (i.e., training versus generated data) in a flexible,\npermutation invariant manner. We also propose a new metric to quantitatively\nevaluate GANs that does not require previous knowledge of the application,\napart from the data itself. Using the new metric, in conjunction with the\nstate-of-the-art evaluation methods, we show that the proposed architecture,\nwhen compared with GAN variants stemming from similar strategies, produces more\naccurate models of the input data in a way that is also less sensitive to\nhyperparameter settings.\n", "versions": [{"version": "v1", "created": "Fri, 28 Jun 2019 22:43:02 GMT"}, {"version": "v2", "created": "Mon, 10 Feb 2020 21:36:56 GMT"}], "update_date": "2020-02-12", "authors_parsed": [["Ferrero", "Alessandro", ""], ["Elhabian", "Shireen", ""], ["Whitaker", "Ross", ""]]}, {"id": "1907.00112", "submitter": "Vikramjit Mitra", "authors": "Vikramjit Mitra, Sue Booker, Erik Marchi, David Scott Farrar, Ute\n  Dorothea Peitz, Bridget Cheng, Ermine Teves, Anuj Mehta, Devang Naik", "title": "Leveraging Acoustic Cues and Paralinguistic Embeddings to Detect\n  Expression from Voice", "comments": "5 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SD eess.AS", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Millions of people reach out to digital assistants such as Siri every day,\nasking for information, making phone calls, seeking assistance, and much more.\nThe expectation is that such assistants should understand the intent of the\nusers query. Detecting the intent of a query from a short, isolated utterance\nis a difficult task. Intent cannot always be obtained from speech-recognized\ntranscriptions. A transcription driven approach can interpret what has been\nsaid but fails to acknowledge how it has been said, and as a consequence, may\nignore the expression present in the voice. Our work investigates whether a\nsystem can reliably detect vocal expression in queries using acoustic and\nparalinguistic embedding. Results show that the proposed method offers a\nrelative equal error rate (EER) decrease of 60% compared to a bag-of-word based\nsystem, corroborating that expression is significantly represented by vocal\nattributes, rather than being purely lexical. Addition of emotion embedding\nhelped to reduce the EER by 30% relative to the acoustic embedding,\ndemonstrating the relevance of emotion in expressive voice.\n", "versions": [{"version": "v1", "created": "Fri, 28 Jun 2019 22:57:36 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Mitra", "Vikramjit", ""], ["Booker", "Sue", ""], ["Marchi", "Erik", ""], ["Farrar", "David Scott", ""], ["Peitz", "Ute Dorothea", ""], ["Cheng", "Bridget", ""], ["Teves", "Ermine", ""], ["Mehta", "Anuj", ""], ["Naik", "Devang", ""]]}, {"id": "1907.00118", "submitter": "Colin Targonski", "authors": "Colin Targonski, Benjamin T. Shealy, Melissa C. Smith, F. Alex Feltus", "title": "Cellular State Transformations using Generative Adversarial Networks", "comments": "11 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a novel method to unite deep learning with biology by which\ngenerative adversarial networks (GANs) generate transcriptome perturbations and\nreveal condition-defining gene expression patterns. We find that a generator\nconditioned to perturb any input gene expression profile simulates a realistic\ntransition between source and target RNA expression states. The perturbed\nsamples follow a similar distribution to original samples from the dataset,\nalso suggesting these are biologically meaningful perturbations. Finally, we\nshow that it is possible to identify the genes most positively and negatively\nperturbed by the generator and that the enriched biological function of the\nperturbed genes are realistic. We call the framework the Transcriptome State\nPerturbation Generator (TSPG), which is open source software available at\nhttps://github.com/ctargon/TSPG.\n", "versions": [{"version": "v1", "created": "Fri, 28 Jun 2019 23:59:57 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Targonski", "Colin", ""], ["Shealy", "Benjamin T.", ""], ["Smith", "Melissa C.", ""], ["Feltus", "F. Alex", ""]]}, {"id": "1907.00126", "submitter": "Babak Rahmani", "authors": "Babak Rahmani, Damien Loterie, Eirini Kakkava, Navid Borhani, U\\u{g}ur\n  Te\\u{g}in, Demetri Psaltis, Christophe Moser", "title": "Competing Neural Networks for Robust Control of Nonlinear Systems", "comments": "14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.optics cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The output of physical systems is often accessible by measurements such as\nthe 3D position of a robotic arm actuated by many actuators or the speckle\npatterns formed by shining the spot of a laser pointer on a wall. The selection\nof the input of such a system (actuators and the shape of the laser spot\nrespectively) to obtain a desired output is difficult because it is an\nill-posed problem i.e. there are multiple inputs yielding the same output. In\nthis paper, we propose an approach that provides a robust solution to this\ndilemma for any physical system. We show that it is possible to find the\nappropriate input of a system that results in a desired output, despite the\ninput-output relation being nonlinear and\\or with incomplete measurements of\nthe systems variables. We showcase our approach using an extremely ill-posed\nproblem in imaging. We demonstrate the projection of arbitrary shapes through a\nmultimode fiber (MMF) when a sample of intensity-only measurements are taken at\nthe output. We show image projection fidelity as high as ~90 %, which is on par\nwith the gold standard methods which characterize the system fully by phase and\namplitude measurements. The generality as well as simplicity of the proposed\napproach provides a new way of target-oriented control in real-world\napplications.\n", "versions": [{"version": "v1", "created": "Sat, 29 Jun 2019 01:28:31 GMT"}, {"version": "v2", "created": "Mon, 3 Feb 2020 17:06:57 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Rahmani", "Babak", ""], ["Loterie", "Damien", ""], ["Kakkava", "Eirini", ""], ["Borhani", "Navid", ""], ["Te\u011fin", "U\u011fur", ""], ["Psaltis", "Demetri", ""], ["Moser", "Christophe", ""]]}, {"id": "1907.00138", "submitter": "Chihiro Noguchi", "authors": "Chihiro Noguchi and Yoshiyuki Kabashima", "title": "Approximate matrix completion based on cavity method", "comments": "20 pages, 11 figures", "journal-ref": null, "doi": "10.1088/1751-8121/ab40de", "report-no": null, "categories": "math.NA cond-mat.stat-mech cs.LG cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to solve large matrix completion problems with practical\ncomputational cost, an approximate approach based on matrix factorization has\nbeen widely used. Alternating least squares (ALS) and stochastic gradient\ndescent (SGD) are two major algorithms to this end. In this study, we propose a\nnew algorithm, namely cavity-based matrix factorization (CBMF) and approximate\ncavity-based matrix factorization (ACBMF), which are developed based on the\ncavity method from statistical mechanics. ALS yields solutions with less\niterations when compared to those of SGD. This is because its update rules are\ndescribed in a closed form although it entails higher computational cost. CBMF\ncan also write its update rules in a closed form, and its computational cost is\nlower than that of ALS. ACBMF is proposed to compensate a disadvantage of CBMF\nin terms of relatively high memory cost. We experimentally illustrate that the\nproposed methods outperform the two existing algorithms in terms of convergence\nspeed per iteration, and it can work under the condition where observed entries\nare relatively fewer. Additionally, in contrast to SGD, (A)CBMF does not\nrequire scheduling of the learning rate.\n", "versions": [{"version": "v1", "created": "Sat, 29 Jun 2019 03:16:16 GMT"}], "update_date": "2020-01-08", "authors_parsed": [["Noguchi", "Chihiro", ""], ["Kabashima", "Yoshiyuki", ""]]}, {"id": "1907.00139", "submitter": "Anthony Degleris", "authors": "Anthony Degleris and Ben Antin and Surya Ganguli and Alex H Williams", "title": "Fast Convolutive Nonnegative Matrix Factorization Through Coordinate and\n  Block Coordinate Updates", "comments": "10 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Identifying recurring patterns in high-dimensional time series data is an\nimportant problem in many scientific domains. A popular model to achieve this\nis convolutive nonnegative matrix factorization (CNMF), which extends classic\nnonnegative matrix factorization (NMF) to extract short-lived temporal motifs\nfrom a long time series. Prior work has typically fit this model by\nmultiplicative parameter updates---an approach widely considered to be\nsuboptimal for NMF, especially in large-scale data applications. Here, we\ndescribe how to extend two popular and computationally scalable NMF\nalgorithms---Hierarchical Alternating Least Squares (HALS) and Alternatining\nNonnegative Least Squares (ANLS)---for the CNMF model. Both methods demonstrate\nperformance advantages over multiplicative updates on large-scale synthetic and\nreal world data.\n", "versions": [{"version": "v1", "created": "Sat, 29 Jun 2019 03:53:09 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Degleris", "Anthony", ""], ["Antin", "Ben", ""], ["Ganguli", "Surya", ""], ["Williams", "Alex H", ""]]}, {"id": "1907.00141", "submitter": "Alireza Heidari", "authors": "Alireza Heidari, Ihab F. Ilyas, Theodoros Rekatsinas", "title": "Approximate Inference in Structured Instances with Noisy Categorical\n  Observations", "comments": "UAI 2019, 33 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of recovering the latent ground truth labeling of a\nstructured instance with categorical random variables in the presence of noisy\nobservations. We present a new approximate algorithm for graphs with\ncategorical variables that achieves low Hamming error in the presence of noisy\nvertex and edge observations. Our main result shows a logarithmic dependency of\nthe Hamming error to the number of categories of the random variables. Our\napproach draws connections to correlation clustering with a fixed number of\nclusters. Our results generalize the works of Globerson et al. (2015) and\nFoster et al. (2018), who study the hardness of structured prediction under\nbinary labels, to the case of categorical labels.\n", "versions": [{"version": "v1", "created": "Sat, 29 Jun 2019 04:15:33 GMT"}, {"version": "v2", "created": "Sat, 6 Jul 2019 02:30:56 GMT"}], "update_date": "2019-07-09", "authors_parsed": [["Heidari", "Alireza", ""], ["Ilyas", "Ihab F.", ""], ["Rekatsinas", "Theodoros", ""]]}, {"id": "1907.00157", "submitter": "Sandeep Singh Adhikari Mr", "authors": "Sandeep Singh Adhikari, Sukhneer Singh, Anoop Rajagopal, Aruna Rajan", "title": "Progressive Fashion Attribute Extraction", "comments": "6 pages, 6 figures, AI for fashion : KDD 2019 Workshop, August 2019,\n  Anchorage, Alaska - USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.CV cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Extracting fashion attributes from images of people wearing clothing/fashion\naccessories is a very hard multi-class classification problem. Most often, even\ncatalogues of fashion do not have all the fine-grained attributes tagged due to\nprohibitive cost of annotation. Using images of fashion articles, running\nmulti-class attribute extraction with a single model for all kinds of\nattributes (neck design detailing, sleeves detailing, etc) requires classifiers\nthat are robust to missing and ambiguously labelled data. In this work, we\npropose a progressive training approach for such multi-class classification,\nwhere weights learnt from an attribute are fine tuned for another attribute of\nthe same fashion article (say, dresses). We branch networks for each attributes\nfrom a base network progressively during training. While it may have many\nlabels, an image doesn't need to have all possible labels for fashion articles\npresent in it. We also compare our approach to multi-label classification, and\ndemonstrate improvements over overall classification accuracies using our\napproach.\n", "versions": [{"version": "v1", "created": "Sat, 29 Jun 2019 06:51:34 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Adhikari", "Sandeep Singh", ""], ["Singh", "Sukhneer", ""], ["Rajagopal", "Anoop", ""], ["Rajan", "Aruna", ""]]}, {"id": "1907.00164", "submitter": "Martin Strobel", "authors": "Reza Shokri, Martin Strobel, Yair Zick", "title": "On the Privacy Risks of Model Explanations", "comments": "19 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Privacy and transparency are two key foundations of trustworthy machine\nlearning. Model explanations offer insights into a model's decisions on input\ndata, whereas privacy is primarily concerned with protecting information about\nthe training data. We analyze connections between model explanations and the\nleakage of sensitive information about the model's training set. We investigate\nthe privacy risks of feature-based model explanations using membership\ninference attacks: quantifying how much model predictions plus their\nexplanations leak information about the presence of a datapoint in the training\nset of a model. We extensively evaluate membership inference attacks based on\nfeature-based model explanations, over a variety of datasets. We show that\nbackpropagation-based explanations can leak a significant amount of information\nabout individual training datapoints. This is because they reveal statistical\ninformation about the decision boundaries of the model about an input, which\ncan reveal its membership. We also empirically investigate the trade-off\nbetween privacy and explanation quality, by studying the perturbation-based\nmodel explanations.\n", "versions": [{"version": "v1", "created": "Sat, 29 Jun 2019 07:59:34 GMT"}, {"version": "v2", "created": "Mon, 2 Dec 2019 08:10:38 GMT"}, {"version": "v3", "created": "Tue, 3 Dec 2019 11:01:43 GMT"}, {"version": "v4", "created": "Wed, 4 Dec 2019 06:51:27 GMT"}, {"version": "v5", "created": "Tue, 14 Jul 2020 09:08:57 GMT"}, {"version": "v6", "created": "Fri, 5 Feb 2021 05:04:17 GMT"}], "update_date": "2021-02-08", "authors_parsed": [["Shokri", "Reza", ""], ["Strobel", "Martin", ""], ["Zick", "Yair", ""]]}, {"id": "1907.00182", "submitter": "Timoth\\'ee Lesort", "authors": "Timoth\\'ee Lesort, Vincenzo Lomonaco, Andrei Stoian, Davide Maltoni,\n  David Filliat, Natalia D\\'iaz-Rodr\\'iguez", "title": "Continual Learning for Robotics: Definition, Framework, Learning\n  Strategies, Opportunities and Challenges", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Continual learning (CL) is a particular machine learning paradigm where the\ndata distribution and learning objective changes through time, or where all the\ntraining data and objective criteria are never available at once. The evolution\nof the learning process is modeled by a sequence of learning experiences where\nthe goal is to be able to learn new skills all along the sequence without\nforgetting what has been previously learned. Continual learning also aims at\nthe same time at optimizing the memory, the computation power and the speed\nduring the learning process.\n  An important challenge for machine learning is not necessarily finding\nsolutions that work in the real world but rather finding stable algorithms that\ncan learn in real world. Hence, the ideal approach would be tackling the real\nworld in a embodied platform: an autonomous agent. Continual learning would\nthen be effective in an autonomous agent or robot, which would learn\nautonomously through time about the external world, and incrementally develop a\nset of complex skills and knowledge.\n  Robotic agents have to learn to adapt and interact with their environment\nusing a continuous stream of observations. Some recent approaches aim at\ntackling continual learning for robotics, but most recent papers on continual\nlearning only experiment approaches in simulation or with static datasets.\nUnfortunately, the evaluation of those algorithms does not provide insights on\nwhether their solutions may help continual learning in the context of robotics.\nThis paper aims at reviewing the existing state of the art of continual\nlearning, summarizing existing benchmarks and metrics, and proposing a\nframework for presenting and evaluating both robotics and non robotics\napproaches in a way that makes transfer between both fields easier.\n", "versions": [{"version": "v1", "created": "Sat, 29 Jun 2019 11:38:05 GMT"}, {"version": "v2", "created": "Thu, 21 Nov 2019 17:09:45 GMT"}, {"version": "v3", "created": "Fri, 22 Nov 2019 13:37:23 GMT"}], "update_date": "2019-11-25", "authors_parsed": [["Lesort", "Timoth\u00e9e", ""], ["Lomonaco", "Vincenzo", ""], ["Stoian", "Andrei", ""], ["Maltoni", "Davide", ""], ["Filliat", "David", ""], ["D\u00edaz-Rodr\u00edguez", "Natalia", ""]]}, {"id": "1907.00205", "submitter": "Ido Kaminer", "authors": "Gal Raayoni, Shahar Gottlieb, George Pisha, Yoav Harris, Yahel Manor,\n  Uri Mendlovic, Doron Haviv, Yaron Hadad, and Ido Kaminer", "title": "The Ramanujan Machine: Automatically Generated Conjectures on\n  Fundamental Constants", "comments": "5 figures, 6 tables, 28 pages including the supplementary information", "journal-ref": "Nature 590, 67-73 (2021)", "doi": "10.1038/s41586-021-03229-4", "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fundamental mathematical constants like $e$ and $\\pi$ are ubiquitous in\ndiverse fields of science, from abstract mathematics to physics, biology and\nchemistry. For centuries, new formulas relating fundamental constants have been\nscarce and usually discovered sporadically. Here we propose a novel and\nsystematic approach that leverages algorithms for deriving mathematical\nformulas for fundamental constants and help reveal their underlying structure.\nOur algorithms find dozens of well-known as well as previously unknown\ncontinued fraction representations of $\\pi$, $e$, Catalan's constant, and\nvalues of the Riemann zeta function. Two example conjectures found by our\nalgorithm and so far unproven are: \\begin{equation*} \\frac{24}{\\pi^2} = 2 +\n7\\cdot 0\\cdot 1+ \\frac{8\\cdot1^4}{2 + 7\\cdot 1\\cdot 2 + \\frac{8\\cdot2^4}{2 +\n7\\cdot 2\\cdot 3 + \\frac{8\\cdot3^4}{2 + 7\\cdot 3\\cdot 4 +\n\\frac{8\\cdot4^4}{..}}}} \\quad\\quad,\\quad\\quad \\frac{8}{7 \\zeta(3)} = 1\\cdot 1 -\n\\frac{1^6}{3\\cdot 7 - \\frac{2^6}{5\\cdot 19 - \\frac{3^6}{7\\cdot 37 -\n\\frac{4^6}{..}}}} \\end{equation*} We present two algorithms that proved useful\nin finding conjectures: a Meet-In-The-Middle (MITM) algorithm and a Gradient\nDescent (GD) tailored to the recurrent structure of continued fractions. Both\nalgorithms are based on matching numerical values and thus they conjecture\nformulas without providing proofs and without requiring prior knowledge on any\nunderlying mathematical structure. This approach is especially attractive for\nconstants for which no mathematical structure is known, as it reverses the\nconventional approach of sequential logic in formal proofs. Instead, our work\nsupports a different approach for research: algorithms utilizing numerical data\nto unveil mathematical structures, thus trying to play the role of intuition of\ngreat mathematicians of the past, providing leads to new mathematical research.\n", "versions": [{"version": "v1", "created": "Sat, 29 Jun 2019 13:39:10 GMT"}, {"version": "v2", "created": "Sat, 20 Jul 2019 18:08:05 GMT"}, {"version": "v3", "created": "Sat, 3 Aug 2019 07:20:42 GMT"}, {"version": "v4", "created": "Thu, 30 Apr 2020 11:22:42 GMT"}], "update_date": "2021-04-29", "authors_parsed": [["Raayoni", "Gal", ""], ["Gottlieb", "Shahar", ""], ["Pisha", "George", ""], ["Harris", "Yoav", ""], ["Manor", "Yahel", ""], ["Mendlovic", "Uri", ""], ["Haviv", "Doron", ""], ["Hadad", "Yaron", ""], ["Kaminer", "Ido", ""]]}, {"id": "1907.00208", "submitter": "Ziyin Liu", "authors": "Liu Ziyin, Zhikang Wang, Paul Pu Liang, Ruslan Salakhutdinov,\n  Louis-Philippe Morency, Masahito Ueda", "title": "Deep Gamblers: Learning to Abstain with Portfolio Theory", "comments": "Camera-Ready version for NeurIPS2019. Link to our code updated", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We deal with the \\textit{selective classification} problem\n(supervised-learning problem with a rejection option), where we want to achieve\nthe best performance at a certain level of coverage of the data. We transform\nthe original $m$-class classification problem to $(m+1)$-class where the\n$(m+1)$-th class represents the model abstaining from making a prediction due\nto disconfidence. Inspired by portfolio theory, we propose a loss function for\nthe selective classification problem based on the doubling rate of gambling.\nMinimizing this loss function corresponds naturally to maximizing the return of\na \\textit{horse race}, where a player aims to balance between betting on an\noutcome (making a prediction) when confident and reserving one's winnings\n(abstaining) when not confident. This loss function allows us to train neural\nnetworks and characterize the disconfidence of prediction in an end-to-end\nfashion. In comparison with previous methods, our method requires almost no\nmodification to the model inference algorithm or model architecture.\nExperiments show that our method can identify uncertainty in data points, and\nachieves strong results on SVHN and CIFAR10 at various coverages of the data.\n", "versions": [{"version": "v1", "created": "Sat, 29 Jun 2019 14:04:36 GMT"}, {"version": "v2", "created": "Tue, 1 Oct 2019 08:57:03 GMT"}], "update_date": "2019-10-02", "authors_parsed": [["Ziyin", "Liu", ""], ["Wang", "Zhikang", ""], ["Liang", "Paul Pu", ""], ["Salakhutdinov", "Ruslan", ""], ["Morency", "Louis-Philippe", ""], ["Ueda", "Masahito", ""]]}, {"id": "1907.00211", "submitter": "Zheng Wang", "authors": "Feiping Nie, Hua Wang, Zheng Wang, Heng Huang", "title": "Robust Linear Discriminant Analysis Using Ratio Minimization of\n  L1,2-Norms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As one of the most popular linear subspace learning methods, the Linear\nDiscriminant Analysis (LDA) method has been widely studied in machine learning\ncommunity and applied to many scientific applications. Traditional LDA\nminimizes the ratio of squared L2-norms, which is sensitive to outliers. In\nrecent research, many L1-norm based robust Principle Component Analysis methods\nwere proposed to improve the robustness to outliers. However, due to the\ndifficulty of L1-norm ratio optimization, so far there is no existing work to\nutilize sparsity-inducing norms for LDA objective. In this paper, we propose a\nnovel robust linear discriminant analysis method based on the L1,2-norm ratio\nminimization. Minimizing the L1,2-norm ratio is a much more challenging problem\nthan the traditional methods, and there is no existing optimization algorithm\nto solve such non-smooth terms ratio problem. We derive a new efficient\nalgorithm to solve this challenging problem, and provide a theoretical analysis\non the convergence of our algorithm. The proposed algorithm is easy to\nimplement, and converges fast in practice. Extensive experiments on both\nsynthetic data and nine real benchmark data sets show the effectiveness of the\nproposed robust LDA method.\n", "versions": [{"version": "v1", "created": "Sat, 29 Jun 2019 14:39:27 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Nie", "Feiping", ""], ["Wang", "Hua", ""], ["Wang", "Zheng", ""], ["Huang", "Heng", ""]]}, {"id": "1907.00221", "submitter": "Rohit Bhattacharya", "authors": "Rohit Bhattacharya, Daniel Malinsky, Ilya Shpitser", "title": "Causal Inference Under Interference And Network Uncertainty", "comments": "16 pages, published in proceedings of 35th Conference on Uncertainty\n  in Artificial Intelligence (UAI 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classical causal and statistical inference methods typically assume the\nobserved data consists of independent realizations. However, in many\napplications this assumption is inappropriate due to a network of dependences\nbetween units in the data. Methods for estimating causal effects have been\ndeveloped in the setting where the structure of dependence between units is\nknown exactly, but in practice there is often substantial uncertainty about the\nprecise network structure. This is true, for example, in trial data drawn from\nvulnerable communities where social ties are difficult to query directly. In\nthis paper we combine techniques from the structure learning and interference\nliteratures in causal inference, proposing a general method for estimating\ncausal effects under data dependence when the structure of this dependence is\nnot known a priori. We demonstrate the utility of our method on synthetic\ndatasets which exhibit network dependence.\n", "versions": [{"version": "v1", "created": "Sat, 29 Jun 2019 15:25:53 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Bhattacharya", "Rohit", ""], ["Malinsky", "Daniel", ""], ["Shpitser", "Ilya", ""]]}, {"id": "1907.00235", "submitter": "Xiyou Zhou", "authors": "Shiyang Li, Xiaoyong Jin, Yao Xuan, Xiyou Zhou, Wenhu Chen, Yu-Xiang\n  Wang and Xifeng Yan", "title": "Enhancing the Locality and Breaking the Memory Bottleneck of Transformer\n  on Time Series Forecasting", "comments": "To appear in the proceeding of NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Time series forecasting is an important problem across many domains,\nincluding predictions of solar plant energy output, electricity consumption,\nand traffic jam situation. In this paper, we propose to tackle such forecasting\nproblem with Transformer [1]. Although impressed by its performance in our\npreliminary study, we found its two major weaknesses: (1) locality-agnostics:\nthe point-wise dot-product self-attention in canonical Transformer architecture\nis insensitive to local context, which can make the model prone to anomalies in\ntime series; (2) memory bottleneck: space complexity of canonical Transformer\ngrows quadratically with sequence length $L$, making directly modeling long\ntime series infeasible. In order to solve these two issues, we first propose\nconvolutional self-attention by producing queries and keys with causal\nconvolution so that local context can be better incorporated into attention\nmechanism. Then, we propose LogSparse Transformer with only $O(L(\\log L)^{2})$\nmemory cost, improving forecasting accuracy for time series with fine\ngranularity and strong long-term dependencies under constrained memory budget.\nOur experiments on both synthetic data and real-world datasets show that it\ncompares favorably to the state-of-the-art.\n", "versions": [{"version": "v1", "created": "Sat, 29 Jun 2019 16:36:04 GMT"}, {"version": "v2", "created": "Tue, 29 Oct 2019 07:51:31 GMT"}, {"version": "v3", "created": "Fri, 3 Jan 2020 05:10:50 GMT"}], "update_date": "2020-01-06", "authors_parsed": [["Li", "Shiyang", ""], ["Jin", "Xiaoyong", ""], ["Xuan", "Yao", ""], ["Zhou", "Xiyou", ""], ["Chen", "Wenhu", ""], ["Wang", "Yu-Xiang", ""], ["Yan", "Xifeng", ""]]}, {"id": "1907.00236", "submitter": "Nikita Ivkin", "authors": "Nikita Ivkin, Edo Liberty, Kevin Lang, Zohar Karnin and Vladimir\n  Braverman", "title": "Streaming Quantiles Algorithms with Small Space and Update Time", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DB cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Approximating quantiles and distributions over streaming data has been\nstudied for roughly two decades now. Recently, Karnin, Lang, and Liberty\nproposed the first asymptotically optimal algorithm for doing so. This\nmanuscript complements their theoretical result by providing a practical\nvariants of their algorithm with improved constants. For a given sketch size,\nour techniques provably reduce the upper bound on the sketch error by a factor\nof two. These improvements are verified experimentally. Our modified quantile\nsketch improves the latency as well by reducing the worst case update time from\n$O(1/\\varepsilon)$ down to $O(\\log (1/\\varepsilon))$. We also suggest two\nalgorithms for weighted item streams which offer improved asymptotic update\ntimes compared to na\\\"ive extensions. Finally, we provide a specialized data\nstructure for these sketches which reduces both their memory footprints and\nupdate times.\n", "versions": [{"version": "v1", "created": "Sat, 29 Jun 2019 16:37:33 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Ivkin", "Nikita", ""], ["Liberty", "Edo", ""], ["Lang", "Kevin", ""], ["Karnin", "Zohar", ""], ["Braverman", "Vladimir", ""]]}, {"id": "1907.00241", "submitter": "Rohit Bhattacharya", "authors": "Rohit Bhattacharya, Razieh Nabi, Ilya Shpitser, James M. Robins", "title": "Identification In Missing Data Models Represented By Directed Acyclic\n  Graphs", "comments": "16 pages, published in proceedings of 35th Conference on Uncertainty\n  in Artificial Intelligence (UAI 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Missing data is a pervasive problem in data analyses, resulting in datasets\nthat contain censored realizations of a target distribution. Many approaches to\ninference on the target distribution using censored observed data, rely on\nmissing data models represented as a factorization with respect to a directed\nacyclic graph. In this paper we consider the identifiability of the target\ndistribution within this class of models, and show that the most general\nidentification strategies proposed so far retain a significant gap in that they\nfail to identify a wide class of identifiable distributions. To address this\ngap, we propose a new algorithm that significantly generalizes the types of\nmanipulations used in the ID algorithm, developed in the context of causal\ninference, in order to obtain identification.\n", "versions": [{"version": "v1", "created": "Sat, 29 Jun 2019 17:17:52 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Bhattacharya", "Rohit", ""], ["Nabi", "Razieh", ""], ["Shpitser", "Ilya", ""], ["Robins", "James M.", ""]]}, {"id": "1907.00262", "submitter": "Jonathan Frankle", "authors": "Jonathan Frankle and David Bau", "title": "Dissecting Pruned Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pruning is a standard technique for removing unnecessary structure from a\nneural network to reduce its storage footprint, computational demands, or\nenergy consumption. Pruning can reduce the parameter-counts of many\nstate-of-the-art neural networks by an order of magnitude without compromising\naccuracy, meaning these networks contain a vast amount of unnecessary\nstructure. In this paper, we study the relationship between pruning and\ninterpretability. Namely, we consider the effect of removing unnecessary\nstructure on the number of hidden units that learn disentangled representations\nof human-recognizable concepts as identified by network dissection. We aim to\nevaluate how the interpretability of pruned neural networks changes as they are\ncompressed. We find that pruning has no detrimental effect on this measure of\ninterpretability until so few parameters remain that accuracy beings to drop.\nResnet-50 models trained on ImageNet maintain the same number of interpretable\nconcepts and units until more than 90% of parameters have been pruned.\n", "versions": [{"version": "v1", "created": "Sat, 29 Jun 2019 19:27:57 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Frankle", "Jonathan", ""], ["Bau", "David", ""]]}, {"id": "1907.00267", "submitter": "Dawei Yang", "authors": "Dawei Yang, Jia Deng", "title": "Learning to Generate Synthetic 3D Training Data through Hybrid Gradient", "comments": "Accepted to CVPR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Synthetic images rendered by graphics engines are a promising source for\ntraining deep networks. However, it is challenging to ensure that they can help\ntrain a network to perform well on real images, because a graphics-based\ngeneration pipeline requires numerous design decisions such as the selection of\n3D shapes and the placement of the camera. In this work, we propose a new\nmethod that optimizes the generation of 3D training data based on what we call\n\"hybrid gradient\". We parametrize the design decisions as a real vector, and\ncombine the approximate gradient and the analytical gradient to obtain the\nhybrid gradient of the network performance with respect to this vector. We\nevaluate our approach on the task of estimating surface normal, depth or\nintrinsic decomposition from a single image. Experiments on standard benchmarks\nshow that our approach can outperform the prior state of the art on optimizing\nthe generation of 3D training data, particularly in terms of computational\nefficiency.\n", "versions": [{"version": "v1", "created": "Sat, 29 Jun 2019 19:34:19 GMT"}, {"version": "v2", "created": "Sat, 25 Apr 2020 18:42:03 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Yang", "Dawei", ""], ["Deng", "Jia", ""]]}, {"id": "1907.00269", "submitter": "Madhavun Candadai", "authors": "Zach Dwiel, Madhavun Candadai, Mariano Phielipp", "title": "On Training Flexible Robots using Deep Reinforcement Learning", "comments": "Accepted at the Intelligent Robots and Systems (IRoS) conference,\n  2019. Camera-ready version coming soon", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The use of robotics in controlled environments has flourished over the last\nseveral decades and training robots to perform tasks using control strategies\ndeveloped from dynamical models of their hardware have proven very effective.\nHowever, in many real-world settings, the uncertainties of the environment, the\nsafety requirements and generalized capabilities that are expected of robots\nmake rigid industrial robots unsuitable. This created great research interest\ninto developing control strategies for flexible robot hardware for which\nbuilding dynamical models are challenging. In this paper, inspired by the\nsuccess of deep reinforcement learning (DRL) in other areas, we systematically\nstudy the efficacy of policy search methods using DRL in training flexible\nrobots. Our results indicate that DRL is successfully able to learn efficient\nand robust policies for complex tasks at various degrees of flexibility. We\nalso note that DRL using Deep Deterministic Policy Gradients can be sensitive\nto the choice of sensors and adding more informative sensors does not\nnecessarily make the task easier to learn.\n", "versions": [{"version": "v1", "created": "Sat, 29 Jun 2019 19:50:23 GMT"}, {"version": "v2", "created": "Sat, 13 Jul 2019 15:47:36 GMT"}], "update_date": "2019-07-16", "authors_parsed": [["Dwiel", "Zach", ""], ["Candadai", "Madhavun", ""], ["Phielipp", "Mariano", ""]]}, {"id": "1907.00270", "submitter": "Guillaume Derval", "authors": "Guillaume Derval, Fr\\'ed\\'eric Docquier and Pierre Schaus", "title": "An aggregate learning approach for interpretable semi-supervised\n  population prediction and disaggregation using ancillary data", "comments": "Accepted at ECML-PKDD 2019 Data on Zenodo:\n  https://zenodo.org/record/3260713", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Census data provide detailed information about population characteristics at\na coarse resolution. Nevertheless, fine-grained, high-resolution mappings of\npopulation counts are increasingly needed to characterize population dynamics\nand to assess the consequences of climate shocks, natural disasters,\ninvestments in infrastructure, development policies, etc. Dissagregating these\ncensus is a complex machine learning, and multiple solutions have been proposed\nin past research. We propose in this paper to view the problem in the context\nof the aggregate learning paradigm, where the output value for all training\npoints is not known, but where it is only known for aggregates of the points\n(i.e. in this context, for regions of pixels where a census is available). We\ndemonstrate with a very simple and interpretable model that this method is on\npar, and even outperforms on some metrics, the state-of-the-art, despite its\nsimplicity.\n", "versions": [{"version": "v1", "created": "Sat, 29 Jun 2019 19:53:11 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Derval", "Guillaume", ""], ["Docquier", "Fr\u00e9d\u00e9ric", ""], ["Schaus", "Pierre", ""]]}, {"id": "1907.00274", "submitter": "Pedro Morgado", "authors": "Pedro Morgado and Nuno Vasconcelos", "title": "NetTailor: Tuning the Architecture, Not Just the Weights", "comments": null, "journal-ref": "CVF/IEEE Conference on Computer Vision and Pattern Recognition\n  (CVPR), 2019", "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Real-world applications of object recognition often require the solution of\nmultiple tasks in a single platform. Under the standard paradigm of network\nfine-tuning, an entirely new CNN is learned per task, and the final network\nsize is independent of task complexity. This is wasteful, since simple tasks\nrequire smaller networks than more complex tasks, and limits the number of\ntasks that can be solved simultaneously. To address these problems, we propose\na transfer learning procedure, denoted NetTailor, in which layers of a\npre-trained CNN are used as universal blocks that can be combined with small\ntask-specific layers to generate new networks. Besides minimizing\nclassification error, the new network is trained to mimic the internal\nactivations of a strong unconstrained CNN, and minimize its complexity by the\ncombination of 1) a soft-attention mechanism over blocks and 2) complexity\nregularization constraints. In this way, NetTailor can adapt the network\narchitecture, not just its weights, to the target task. Experiments show that\nnetworks adapted to simple tasks, such as character or traffic sign\nrecognition, become significantly smaller than those adapted to hard tasks,\nsuch as fine-grained recognition. More importantly, due to the modular nature\nof the procedure, this reduction in network complexity is achieved without\ncompromise of either parameter sharing across tasks, or classification\naccuracy.\n", "versions": [{"version": "v1", "created": "Sat, 29 Jun 2019 20:32:58 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Morgado", "Pedro", ""], ["Vasconcelos", "Nuno", ""]]}, {"id": "1907.00275", "submitter": "Oleksandr Zadorozhnyi", "authors": "Leonidas Lefakis, Oleksandr Zadorozhnyi, Gilles Blanchard", "title": "Efficient Regularized Piecewise-Linear Regression Trees", "comments": "32 pages,6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a detailed analysis of the class of regression decision tree\nalgorithms which employ a regulized piecewise-linear node-splitting criterion\nand have regularized linear models at the leaves. From a theoretic standpoint,\nbased on Rademacher complexity framework, we present new high-probability upper\nbounds for the generalization error for the proposed classes of regularized\nregression decision tree algorithms, including LASSO-type, and $\\ell_{2}$\nregularization for linear models at the leaves. Theoretical result are further\nextended by considering a general type of variable selection procedure.\nFurthermore, in our work we demonstrate that the class of piecewise-linear\nregression trees is not only numerically stable but can be made tractable via\nan algorithmic implementation, presented herein, as well as with the help of\nmodern GPU technology. Empirically, we present results on multiple datasets\nwhich highlight the strengths and potential pitfalls, of the proposed tree\nalgorithms compared to baselines which grow trees based on piecewise constant\nmodels.\n", "versions": [{"version": "v1", "created": "Sat, 29 Jun 2019 20:34:06 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Lefakis", "Leonidas", ""], ["Zadorozhnyi", "Oleksandr", ""], ["Blanchard", "Gilles", ""]]}, {"id": "1907.00281", "submitter": "Po-Yu Kao", "authors": "Po-Yu Kao, Jefferson W. Chen, B.S. Manjunath", "title": "Improving 3D U-Net for Brain Tumor Segmentation by Utilizing Lesion\n  Prior", "comments": "5 pages, 4 figures, 1 table, LNCS format", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose a novel, simple and effective method to integrate lesion prior and\na 3D U-Net for improving brain tumor segmentation. First, we utilize the\nground-truth brain tumor lesions from a group of patients to generate the\nheatmaps of different types of lesions. These heatmaps are used to create the\nvolume-of-interest (VOI) map which contains prior information about brain tumor\nlesions. The VOI map is then integrated with the multimodal MR images and input\nto a 3D U-Net for segmentation. The proposed method is evaluated on a public\nbenchmark dataset, and the experimental results show that the proposed feature\nfusion method achieves an improvement over the baseline methods. In addition,\nour proposed method also achieves a competitive performance compared to\nstate-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Sat, 29 Jun 2019 21:29:21 GMT"}, {"version": "v2", "created": "Thu, 12 Sep 2019 23:24:01 GMT"}, {"version": "v3", "created": "Thu, 20 Feb 2020 02:28:06 GMT"}], "update_date": "2020-02-21", "authors_parsed": [["Kao", "Po-Yu", ""], ["Chen", "Jefferson W.", ""], ["Manjunath", "B. S.", ""]]}, {"id": "1907.00289", "submitter": "Jelena Diakonikolas", "authors": "Jelena Diakonikolas and Lorenzo Orecchia", "title": "Conjugate Gradients and Accelerated Methods Unified: The Approximate\n  Duality Gap View", "comments": "8 pages. v1 -> v2: corrected a reference to the paper with Nemirovski\n  acceleration with line search. v2 -> v3: updated affiliations, corrected a\n  few typos on p.7 and added an acknowledgement", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.DS cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This note provides a novel, simple analysis of the method of conjugate\ngradients for the minimization of convex quadratic functions. In contrast with\nstandard arguments, our proof is entirely self-contained and does not rely on\nthe existence of Chebyshev polynomials. Another advantage of our development is\nthat it clarifies the relation between the method of conjugate gradients and\ngeneral accelerated methods for smooth minimization by unifying their analyses\nwithin the framework of the Approximate Duality Gap Technique that was\nintroduced by the authors.\n", "versions": [{"version": "v1", "created": "Sat, 29 Jun 2019 22:40:35 GMT"}, {"version": "v2", "created": "Tue, 16 Jul 2019 22:39:23 GMT"}, {"version": "v3", "created": "Sun, 9 Feb 2020 18:06:44 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Diakonikolas", "Jelena", ""], ["Orecchia", "Lorenzo", ""]]}, {"id": "1907.00300", "submitter": "Heyi Li", "authors": "Heyi Li, Dongdong Chen, William H. Nailon, Mike E. Davies and David I.\n  Laurenson", "title": "Signed Laplacian Deep Learning with Adversarial Augmentation for\n  Improved Mammography Diagnosis", "comments": "To appear in MICCAI October 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computer-aided breast cancer diagnosis in mammography is limited by\ninadequate data and the similarity between benign and cancerous masses. To\naddress this, we propose a signed graph regularized deep neural network with\nadversarial augmentation, named \\textsc{DiagNet}. Firstly, we use adversarial\nlearning to generate positive and negative mass-contained mammograms for each\nmass class. After that, a signed similarity graph is built upon the expanded\ndata to further highlight the discrimination. Finally, a deep convolutional\nneural network is trained by jointly optimizing the signed graph regularization\nand classification loss. Experiments show that the \\textsc{DiagNet} framework\noutperforms the state-of-the-art in breast mass diagnosis in mammography.\n", "versions": [{"version": "v1", "created": "Sun, 30 Jun 2019 00:34:27 GMT"}, {"version": "v2", "created": "Sat, 14 Sep 2019 16:10:48 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Li", "Heyi", ""], ["Chen", "Dongdong", ""], ["Nailon", "William H.", ""], ["Davies", "Mike E.", ""], ["Laurenson", "David I.", ""]]}, {"id": "1907.00312", "submitter": "Omid Sadeghi", "authors": "Omid Sadeghi, Reza Eghbali and Maryam Fazel", "title": "Competitive Algorithms for Online Budget-Constrained Continuous\n  DR-Submodular Problems", "comments": "Submitted to NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study a certain class of online optimization problems,\nwhere the goal is to maximize a function that is not necessarily concave and\nsatisfies the Diminishing Returns (DR) property under budget constraints. We\nanalyze a primal-dual algorithm, called the Generalized Sequential algorithm,\nand we obtain the first bound on the competitive ratio of online monotone\nDR-submodular function maximization subject to linear packing constraints which\nmatches the known tight bound in the special case of linear objective function.\n", "versions": [{"version": "v1", "created": "Sun, 30 Jun 2019 03:33:52 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Sadeghi", "Omid", ""], ["Eghbali", "Reza", ""], ["Fazel", "Maryam", ""]]}, {"id": "1907.00316", "submitter": "Omid Sadeghi", "authors": "Omid Sadeghi and Maryam Fazel", "title": "Online Continuous DR-Submodular Maximization with Long-Term Budget\n  Constraints", "comments": "Submitted to NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study a class of online optimization problems with\nlong-term budget constraints where the objective functions are not necessarily\nconcave (nor convex) but they instead satisfy the Diminishing Returns (DR)\nproperty. Specifically, a sequence of monotone DR-submodular objective\nfunctions $\\{f_t(x)\\}_{t=1}^T$ and monotone linear budget functions $\\{\\langle\np_t,x \\rangle \\}_{t=1}^T$ arrive over time and assuming a total targeted budget\n$B_T$, the goal is to choose points $x_t$ at each time $t\\in\\{1,\\dots,T\\}$,\nwithout knowing $f_t$ and $p_t$ on that step, to achieve sub-linear regret\nbound while the total budget violation $\\sum_{t=1}^T \\langle p_t,x_t \\rangle\n-B_T$ is sub-linear as well. Prior work has shown that achieving sub-linear\nregret is impossible if the budget functions are chosen adversarially.\nTherefore, we modify the notion of regret by comparing the agent against a\n$(1-\\frac{1}{e})$-approximation to the best fixed decision in hindsight which\nsatisfies the budget constraint proportionally over any window of length $W$.\nWe propose the Online Saddle Point Hybrid Gradient (OSPHG) algorithm to solve\nthis class of online problems. For $W=T$, we recover the aforementioned\nimpossibility result. However, when $W=o(T)$, we show that it is possible to\nobtain sub-linear bounds for both the $(1-\\frac{1}{e})$-regret and the total\nbudget violation.\n", "versions": [{"version": "v1", "created": "Sun, 30 Jun 2019 04:01:32 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Sadeghi", "Omid", ""], ["Fazel", "Maryam", ""]]}, {"id": "1907.00321", "submitter": "Lonce Wyse", "authors": "Lonce Wyse", "title": "Mechanisms of Artistic Creativity in Deep Learning Neural Networks", "comments": "8 pages, International Conference on Computational Creativity,\n  Charlotte, NC, USA. June, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The generative capabilities of deep learning neural networks (DNNs) have been\nattracting increasing attention for both the remarkable artifacts they produce,\nbut also because of the vast conceptual difference between how they are\nprogrammed and what they do. DNNs are 'black boxes' where high-level behavior\nis not explicitly programmed, but emerges from the complex interactions of\nthousands or millions of simple computational elements. Their behavior is often\ndescribed in anthropomorphic terms that can be misleading, seem magical, or\nstoke fears of an imminent singularity in which machines become 'more' than\nhuman. In this paper, we examine 5 distinct behavioral characteristics\nassociated with creativity, and provide an example of a mechanisms from\ngenerative deep learning architectures that give rise to each these\ncharacteristics. All 5 emerge from machinery built for purposes other than the\ncreative characteristics they exhibit, mostly classification. These mechanisms\nof creative generative capabilities thus demonstrate a deep kinship to\ncomputational perceptual processes. By understanding how these different\nbehaviors arise, we hope to on one hand take the magic out of anthropomorphic\ndescriptions, but on the other, to build a deeper appreciation of machinic\nforms of creativity on their own terms that will allow us to nurture their\nfurther development.\n", "versions": [{"version": "v1", "created": "Sun, 30 Jun 2019 05:29:38 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Wyse", "Lonce", ""]]}, {"id": "1907.00325", "submitter": "Richard Guo", "authors": "Ronak Mehta, Richard Guo, Jesus Arroyo, Mike Powell, Hayden Helm,\n  Cencheng Shen, Joshua T. Vogelstein", "title": "Estimating Information-Theoretic Quantities with Uncertainty Forests", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Information-theoretic quantities, such as conditional entropy and mutual\ninformation, are critical data summaries for quantifying uncertainty. Existing\nestimators for these quantities either have strong theoretical guarantees or\neffective performance in high-dimensional data, but not both. We propose a\ndecision forest method, Uncertainty Forests (UF), which combines quantile\nregression forests, honest sampling, and a finite sample correction. We prove\nUF provides consistent estimates for these information-theoretic quantities,\nincluding in multivariate settings. Empirically, UF reduces finite sample bias\nand variance in a range of both low- and high-dimensional simulated settings\nfor estimating posterior probabilities, conditional entropies, and mutual\ninformation. In a real-world connectome application, UF quantifies the\nuncertainty about neuron type given various cellular features in the Drosophila\nlarva mushroom body, a key challenge for modern neuroscience.\n", "versions": [{"version": "v1", "created": "Sun, 30 Jun 2019 05:59:50 GMT"}, {"version": "v2", "created": "Wed, 3 Jul 2019 16:49:44 GMT"}, {"version": "v3", "created": "Thu, 28 Nov 2019 07:12:15 GMT"}, {"version": "v4", "created": "Wed, 27 May 2020 21:21:09 GMT"}, {"version": "v5", "created": "Tue, 25 Aug 2020 04:39:25 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Mehta", "Ronak", ""], ["Guo", "Richard", ""], ["Arroyo", "Jesus", ""], ["Powell", "Mike", ""], ["Helm", "Hayden", ""], ["Shen", "Cencheng", ""], ["Vogelstein", "Joshua T.", ""]]}, {"id": "1907.00329", "submitter": "Niranjan Balachandar", "authors": "Niranjan Balachandar, Christine Liu, Winston Wang", "title": "Prediction of Small Molecule Kinase Inhibitors for Chemotherapy Using\n  Deep Learning", "comments": "15 pages, 8 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.BM cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The current state of cancer therapeutics has been moving away from\none-size-fits-all cytotoxic chemotherapy, and towards a more individualized and\nspecific approach involving the targeting of each tumor's genetic\nvulnerabilities. Different tumors, even of the same type, may be more reliant\non certain cellular pathways more than others. With modern advancements in our\nunderstanding of cancer genome sequencing, these pathways can be discovered.\nInvestigating each of the millions of possible small molecule inhibitors for\neach kinase in vitro, however, would be extremely expensive and time consuming.\nThis project focuses on predicting the inhibition activity of small molecules\ntargeting 8 different kinases using multiple deep learning models. We trained\nfingerprint-based MLPs and simplified molecular-input line-entry specification\n(SMILES)-based recurrent neural networks (RNNs) and molecular graph\nconvolutional networks (GCNs) to accurately predict inhibitory activity\ntargeting these 8 kinases.\n", "versions": [{"version": "v1", "created": "Sun, 30 Jun 2019 06:36:46 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Balachandar", "Niranjan", ""], ["Liu", "Christine", ""], ["Wang", "Winston", ""]]}, {"id": "1907.00366", "submitter": "Song-Kyoo Amang Kim Ph.D.", "authors": "Ebrahim Al Alkeem, Song-Kyoo Kim, Chan Yeob Yeun, M. Jamal Zemerly,\n  Kin Poon, Paul D. Yoo", "title": "An Enhanced Electrocardiogram Biometric Authentication System Using\n  Machine Learning", "comments": "This paper has been published in the IEEE Access", "journal-ref": "IEEE Access 7 (2019), pp. 123069-123075", "doi": "10.1109/ACCESS.2019.2937357", "report-no": null, "categories": "cs.CR cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional authentication systems use alphanumeric or graphical passwords,\nor token-based techniques that require \"something you know and something you\nhave\". The disadvantages of these systems include the risks of forgetfulness,\nloss, and theft. To address these shortcomings, biometric authentication is\nrapidly replacing traditional authentication methods and is becoming a part of\neveryday life. The electrocardiogram (ECG) is one of the most recent traits\nconsidered for biometric purposes. In this work we describe an ECG-based\nauthentication system suitable for security checks and hospital environments.\nThe proposed system will help investigators studying ECG-based biometric\nauthentication techniques to define dataset boundaries and to acquire\nhigh-quality training data. We evaluated the performance of the proposed system\nand found that it could achieve up to the 92 percent identification accuracy.\nIn addition, by applying the Amang ECG (amgecg) toolbox within MATLAB, we\ninvestigated the two parameters that directly affect the accuracy of\nauthentication: the ECG slicing time (sliding window) and the sampling time\nperiod, and found their optimal values.\n", "versions": [{"version": "v1", "created": "Sun, 30 Jun 2019 11:10:35 GMT"}, {"version": "v2", "created": "Tue, 24 Sep 2019 10:47:03 GMT"}], "update_date": "2019-09-25", "authors_parsed": [["Alkeem", "Ebrahim Al", ""], ["Kim", "Song-Kyoo", ""], ["Yeun", "Chan Yeob", ""], ["Zemerly", "M. Jamal", ""], ["Poon", "Kin", ""], ["Yoo", "Paul D.", ""]]}, {"id": "1907.00378", "submitter": "Ye Zhu PhD", "authors": "Xiaoyu Qin, Kai Ming Ting, Ye Zhu, Vincent CS Lee", "title": "Nearest-Neighbour-Induced Isolation Similarity and its Impact on\n  Density-Based Clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A recent proposal of data dependent similarity called Isolation\nKernel/Similarity has enabled SVM to produce better classification accuracy. We\nidentify shortcomings of using a tree method to implement Isolation Similarity;\nand propose a nearest neighbour method instead. We formally prove the\ncharacteristic of Isolation Similarity with the use of the proposed method. The\nimpact of Isolation Similarity on density-based clustering is studied here. We\nshow for the first time that the clustering performance of the classic\ndensity-based clustering algorithm DBSCAN can be significantly uplifted to\nsurpass that of the recent density-peak clustering algorithm DP. This is\nachieved by simply replacing the distance measure with the proposed\nnearest-neighbour-induced Isolation Similarity in DBSCAN, leaving the rest of\nthe procedure unchanged. A new type of clusters called mass-connected clusters\nis formally defined. We show that DBSCAN, which detects density-connected\nclusters, becomes one which detects mass-connected clusters, when the distance\nmeasure is replaced with the proposed similarity. We also provide the condition\nunder which mass-connected clusters can be detected, while density-connected\nclusters cannot.\n", "versions": [{"version": "v1", "created": "Sun, 30 Jun 2019 13:06:26 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Qin", "Xiaoyu", ""], ["Ting", "Kai Ming", ""], ["Zhu", "Ye", ""], ["Lee", "Vincent CS", ""]]}, {"id": "1907.00382", "submitter": "Saket Singh", "authors": "Saket Singh, Debdoot Sheet and Mithun Dasgupta", "title": "Adversarially Trained Deep Neural Semantic Hashing Scheme for Subjective\n  Search in Fashion Inventory", "comments": "The paper comprises of 8 Pages that contain 9 figures and 3 tables to\n  support the work. The paper got accepted in the ACM's 25th KDD conference's\n  workshop titled AI for fashion", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The simple approach of retrieving a closest match of a query image from one\nin the gallery, compares an image pair using sum of absolute difference in\npixel or feature space. The process is computationally expensive, ill-posed to\nillumination, background composition, pose variation, as well as inefficient to\nbe deployed on gallery sets with more than 1000 elements. Hashing is a faster\nalternative which involves representing images in reduced dimensional simple\nfeature spaces. Encoding images into binary hash codes enables similarity\ncomparison in an image-pair using the Hamming distance measure. The challenge,\nhowever, lies in encoding the images using a semantic hashing scheme that lets\nsubjective neighbors lie within the tolerable Hamming radius. This work\npresents a solution employing adversarial learning of a deep neural semantic\nhashing network for fashion inventory retrieval. It consists of a feature\nextracting convolutional neural network (CNN) learned to (i) minimize error in\nclassifying type of clothing, (ii) minimize hamming distance between semantic\nneighbors and maximize distance between semantically dissimilar images, (iii)\nmaximally scramble a discriminator's ability to identify the corresponding hash\ncode-image pair when processing a semantically similar query-gallery image\npair. Experimental validation for fashion inventory search yields a mean\naverage precision (mAP) of 90.65% in finding the closest match as compared to\n53.26% obtained by the prior art of deep Cauchy hashing for hamming space\nretrieval.\n", "versions": [{"version": "v1", "created": "Sun, 30 Jun 2019 13:59:01 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Singh", "Saket", ""], ["Sheet", "Debdoot", ""], ["Dasgupta", "Mithun", ""]]}, {"id": "1907.00397", "submitter": "Samuel Yen-Chi Chen", "authors": "Samuel Yen-Chi Chen, Chao-Han Huck Yang, Jun Qi, Pin-Yu Chen, Xiaoli\n  Ma, Hsi-Sheng Goan", "title": "Variational Quantum Circuits for Deep Reinforcement Learning", "comments": "Accepted for publication by IEEE Access", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI quant-ph stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The state-of-the-art machine learning approaches are based on classical von\nNeumann computing architectures and have been widely used in many industrial\nand academic domains. With the recent development of quantum computing,\nresearchers and tech-giants have attempted new quantum circuits for machine\nlearning tasks. However, the existing quantum computing platforms are hard to\nsimulate classical deep learning models or problems because of the\nintractability of deep quantum circuits. Thus, it is necessary to design\nfeasible quantum algorithms for quantum machine learning for noisy intermediate\nscale quantum (NISQ) devices. This work explores variational quantum circuits\nfor deep reinforcement learning. Specifically, we reshape classical deep\nreinforcement learning algorithms like experience replay and target network\ninto a representation of variational quantum circuits. Moreover, we use a\nquantum information encoding scheme to reduce the number of model parameters\ncompared to classical neural networks. To the best of our knowledge, this work\nis the first proof-of-principle demonstration of variational quantum circuits\nto approximate the deep $Q$-value function for decision-making and\npolicy-selection reinforcement learning with experience replay and target\nnetwork. Besides, our variational quantum circuits can be deployed in many\nnear-term NISQ machines.\n", "versions": [{"version": "v1", "created": "Sun, 30 Jun 2019 15:35:07 GMT"}, {"version": "v2", "created": "Sat, 17 Aug 2019 03:56:39 GMT"}, {"version": "v3", "created": "Mon, 20 Jul 2020 13:47:07 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Chen", "Samuel Yen-Chi", ""], ["Yang", "Chao-Han Huck", ""], ["Qi", "Jun", ""], ["Chen", "Pin-Yu", ""], ["Ma", "Xiaoli", ""], ["Goan", "Hsi-Sheng", ""]]}, {"id": "1907.00400", "submitter": "Andrea Polonioli PhD", "authors": "Luca Bigon, Giovanni Cassani, Ciro Greco, Lucas Lacasa, Mattia Pavoni,\n  Andrea Polonioli and Jacopo Tagliabue", "title": "Prediction is very hard, especially about conversion. Predicting user\n  purchases from clickstream data in fashion e-commerce", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowing if a user is a buyer vs window shopper solely based on clickstream\ndata is of crucial importance for ecommerce platforms seeking to implement\nreal-time accurate NBA (next best action) policies. However, due to the low\nfrequency of conversion events and the noisiness of browsing data, classifying\nuser sessions is very challenging. In this paper, we address the clickstream\nclassification problem in the fashion industry and present three major\ncontributions to the burgeoning field of AI in fashion: first, we collected,\nnormalized and prepared a novel dataset of live shopping sessions from a major\nEuropean e-commerce fashion website; second, we use the dataset to test in a\ncontrolled environment strong baselines and SOTA models from the literature;\nfinally, we propose a new discriminative neural model that outperforms neural\narchitectures recently proposed at Rakuten labs.\n", "versions": [{"version": "v1", "created": "Sun, 30 Jun 2019 15:42:53 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Bigon", "Luca", ""], ["Cassani", "Giovanni", ""], ["Greco", "Ciro", ""], ["Lacasa", "Lucas", ""], ["Pavoni", "Mattia", ""], ["Polonioli", "Andrea", ""], ["Tagliabue", "Jacopo", ""]]}, {"id": "1907.00420", "submitter": "Artit Wangperawong", "authors": "Pasawee Wirojwatanakul and Artit Wangperawong", "title": "Multi-Label Product Categorization Using Multi-Modal Fusion Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this study, we investigated multi-modal approaches using images,\ndescriptions, and titles to categorize e-commerce products on Amazon.\nSpecifically, we examined late fusion models, where the modalities are fused at\nthe decision level. Products were each assigned multiple labels, and the\nhierarchy in the labels were flattened and filtered. For our individual\nbaseline models, we modified a CNN architecture to classify the description and\ntitle, and then modified Keras' ResNet-50 to classify the images, achieving\n$F_1$ scores of 77.0%, 82.7%, and 61.0%, respectively. In comparison, our\ntri-modal late fusion model can classify products more effectively than single\nmodal models can, improving the $F_1$ score to 88.2%. Each modality\ncomplemented the shortcomings of the other modalities, demonstrating that\nincreasing the number of modalities can be an effective method for improving\nthe performance of multi-label classification problems.\n", "versions": [{"version": "v1", "created": "Sun, 30 Jun 2019 17:10:21 GMT"}, {"version": "v2", "created": "Tue, 17 Sep 2019 02:54:31 GMT"}], "update_date": "2019-09-18", "authors_parsed": [["Wirojwatanakul", "Pasawee", ""], ["Wangperawong", "Artit", ""]]}, {"id": "1907.00429", "submitter": "He Fang", "authors": "He Fang, Xianbin Wang, and Stefano Tomasin", "title": "Machine Learning for Intelligent Authentication in 5G-and-Beyond\n  Wireless Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The fifth generation (5G) and beyond wireless networks are critical to\nsupport diverse vertical applications by connecting heterogeneous devices and\nmachines, which directly increase vulnerability for various spoofing attacks.\nConventional cryptographic and physical layer authentication techniques are\nfacing some challenges in complex dynamic wireless environments, including\nsignificant security overhead, low reliability, as well as difficulty in\npre-designing authentication model, providing continuous protections, and\nlearning time-varying attributes. In this article, we envision new\nauthentication approaches based on machine learning techniques by\nopportunistically leveraging physical layer attributes, and introduce\nintelligence to authentication for more efficient security provisioning.\nMachine learning paradigms for intelligent authentication design are presented,\nnamely for parametric/non-parametric and supervised/unsupervised/reinforcement\nlearning algorithms. In a nutshell, the machine learning-based intelligent\nauthentication approaches utilize specific features in the multi-dimensional\ndomain for achieving cost-effective, more reliable, model-free, continuous and\nsituation-aware device validation under unknown network conditions and\nunpredictable dynamics.\n", "versions": [{"version": "v1", "created": "Sun, 30 Jun 2019 18:36:26 GMT"}, {"version": "v2", "created": "Sun, 28 Jul 2019 00:25:21 GMT"}], "update_date": "2019-07-30", "authors_parsed": [["Fang", "He", ""], ["Wang", "Xianbin", ""], ["Tomasin", "Stefano", ""]]}, {"id": "1907.00437", "submitter": "Rodney LaLonde Iii", "authors": "Rodney LaLonde, Irene Tanner, Katerina Nikiforaki, Georgios Z.\n  Papadakis, Pujan Kandel, Candice W. Bolan, Michael B. Wallace, Ulas Bagci", "title": "INN: Inflated Neural Networks for IPMN Diagnosis", "comments": "Accepted for publication at MICCAI 2019 (22nd International\n  Conference on Medical Image Computing and Computer Assisted Intervention).\n  Code is publicly available at\n  https://github.com/lalonderodney/INN-Inflated-Neural-Nets", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Intraductal papillary mucinous neoplasm (IPMN) is a precursor to pancreatic\nductal adenocarcinoma. While over half of patients are diagnosed with\npancreatic cancer at a distant stage, patients who are diagnosed early enjoy a\nmuch higher 5-year survival rate of $34\\%$ compared to $3\\%$ in the former;\nhence, early diagnosis is key. Unique challenges in the medical imaging domain\nsuch as extremely limited annotated data sets and typically large 3D volumetric\ndata have made it difficult for deep learning to secure a strong foothold. In\nthis work, we construct two novel \"inflated\" deep network architectures,\n$\\textit{InceptINN}$ and $\\textit{DenseINN}$, for the task of diagnosing IPMN\nfrom multisequence (T1 and T2) MRI. These networks inflate their 2D layers to\n3D and bootstrap weights from their 2D counterparts (Inceptionv3 and\nDenseNet121 respectively) trained on ImageNet to the new 3D kernels. We also\nextend the inflation process by further expanding the pre-trained kernels to\nhandle any number of input modalities and different fusion strategies. This is\none of the first studies to train an end-to-end deep network on multisequence\nMRI for IPMN diagnosis, and shows that our proposed novel inflated network\narchitectures are able to handle the extremely limited training data (139 MRI\nscans), while providing an absolute improvement of $8.76\\%$ in accuracy for\ndiagnosing IPMN over the current state-of-the-art. Code is publicly available\nat https://github.com/lalonderodney/INN-Inflated-Neural-Nets.\n", "versions": [{"version": "v1", "created": "Sun, 30 Jun 2019 19:24:41 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["LaLonde", "Rodney", ""], ["Tanner", "Irene", ""], ["Nikiforaki", "Katerina", ""], ["Papadakis", "Georgios Z.", ""], ["Kandel", "Pujan", ""], ["Bolan", "Candice W.", ""], ["Wallace", "Michael B.", ""], ["Bagci", "Ulas", ""]]}, {"id": "1907.00438", "submitter": "Yipeng Hu", "authors": "Yipeng Hu, Eli Gibson, Dean C. Barratt, Mark Emberton, J. Alison\n  Noble, Tom Vercauteren", "title": "Conditional Segmentation in Lieu of Image Registration", "comments": "Accepted to MICCAI 2019", "journal-ref": null, "doi": "10.1007/978-3-030-32245-8_45", "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classical pairwise image registration methods search for a spatial\ntransformation that optimises a numerical measure that indicates how well a\npair of moving and fixed images are aligned. Current learning-based\nregistration methods have adopted the same paradigm and typically predict, for\nany new input image pair, dense correspondences in the form of a dense\ndisplacement field or parameters of a spatial transformation model. However, in\nmany applications of registration, the spatial transformation itself is only\nrequired to propagate points or regions of interest (ROIs). In such cases,\ndetailed pixel- or voxel-level correspondence within or outside of these ROIs\noften have little clinical value. In this paper, we propose an alternative\nparadigm in which the location of corresponding image-specific ROIs, defined in\none image, within another image is learnt. This results in replacing image\nregistration by a conditional segmentation algorithm, which can build on\ntypical image segmentation networks and their widely-adopted training\nstrategies. Using the registration of 3D MRI and ultrasound images of the\nprostate as an example to demonstrate this new approach, we report a median\ntarget registration error (TRE) of 2.1 mm between the ground-truth ROIs defined\non intraoperative ultrasound images and those propagated from the preoperative\nMR images. Significantly lower (>34%) TREs were obtained using the proposed\nconditional segmentation compared with those obtained from a\npreviously-proposed spatial-transformation-predicting registration network\ntrained with the same multiple ROI labels for individual image pairs. We\nconclude this work by using a quantitative bias-variance analysis to provide\none explanation of the observed improvement in registration accuracy.\n", "versions": [{"version": "v1", "created": "Sun, 30 Jun 2019 19:33:08 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Hu", "Yipeng", ""], ["Gibson", "Eli", ""], ["Barratt", "Dean C.", ""], ["Emberton", "Mark", ""], ["Noble", "J. Alison", ""], ["Vercauteren", "Tom", ""]]}, {"id": "1907.00441", "submitter": "Marcio Fonseca", "authors": "Marcio Fonseca", "title": "Unsupervised predictive coding models may explain visual brain\n  representation", "comments": "4 pages, 1 figure, Algonauts Challenge", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep predictive coding networks are neuroscience-inspired unsupervised\nlearning models that learn to predict future sensory states. We build upon the\nPredNet implementation by Lotter, Kreiman, and Cox (2016) to investigate if\npredictive coding representations are useful to predict brain activity in the\nvisual cortex. We use representational similarity analysis (RSA) to compare\nPredNet representations to functional magnetic resonance imaging (fMRI) and\nmagnetoencephalography (MEG) data from the Algonauts Project. In contrast to\nprevious findings in the literature (Khaligh-Razavi &Kriegeskorte, 2014), we\nreport empirical data suggesting that unsupervised models trained to predict\nframes of videos may outperform supervised image classification baselines. Our\nbest submission achieves an average noise normalized score of 16.67% and 27.67%\non the fMRI and MEG tracks of the Algonauts Challenge.\n", "versions": [{"version": "v1", "created": "Sun, 30 Jun 2019 19:53:32 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Fonseca", "Marcio", ""]]}, {"id": "1907.00443", "submitter": "Dhananjay Ram", "authors": "Dhananjay Ram, Lesly Miculicich, Herv\\'e Bourlard", "title": "Multilingual Bottleneck Features for Query by Example Spoken Term\n  Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.HC cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  State of the art solutions to query by example spoken term detection\n(QbE-STD) usually rely on bottleneck feature representation of the query and\naudio document to perform dynamic time warping (DTW) based template matching.\nHere, we present a study on QbE-STD performance using several monolingual as\nwell as multilingual bottleneck features extracted from feed forward networks.\nThen, we propose to employ residual networks (ResNet) to estimate the\nbottleneck features and show significant improvements over the corresponding\nfeed forward network based features. The neural networks are trained on\nGlobalPhone corpus and QbE-STD experiments are performed on a very challenging\nQUESST 2014 database.\n", "versions": [{"version": "v1", "created": "Sun, 30 Jun 2019 20:14:19 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Ram", "Dhananjay", ""], ["Miculicich", "Lesly", ""], ["Bourlard", "Herv\u00e9", ""]]}, {"id": "1907.00452", "submitter": "David Lindner", "authors": "Jason Mancuso, Tomasz Kisielewski, David Lindner, Alok Singh", "title": "Detecting Spiky Corruption in Markov Decision Processes", "comments": "paper accepted to the AI Safety Workshop at IJCAI-19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current reinforcement learning methods fail if the reward function is\nimperfect, i.e. if the agent observes reward different from what it actually\nreceives. We study this problem within the formalism of Corrupt Reward Markov\nDecision Processes (CRMDPs). We show that if the reward corruption in a CRMDP\nis sufficiently \"spiky\", the environment is solvable. We fully characterize the\nregret bound of a Spiky CRMDP, and introduce an algorithm that is able to\ndetect its corrupt states. We show that this algorithm can be used to learn the\noptimal policy with any common reinforcement learning algorithm. Finally, we\ninvestigate our algorithm in a pair of simple gridworld environments, finding\nthat our algorithm can detect the corrupt states and learn the optimal policy\ndespite the corruption.\n", "versions": [{"version": "v1", "created": "Sun, 30 Jun 2019 20:30:05 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Mancuso", "Jason", ""], ["Kisielewski", "Tomasz", ""], ["Lindner", "David", ""], ["Singh", "Alok", ""]]}, {"id": "1907.00455", "submitter": "Marie-Jean Meurs", "authors": "Diego Maupom\\'e and Marie-Jean Meurs", "title": "Multiplicative Models for Recurrent Language Modeling", "comments": "10 pages, pre-print from Proceedings of CICLing 2019: 20th\n  International Conference on Computational Linguistics and Intelligent Text\n  Processing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, there has been interest in multiplicative recurrent neural networks\nfor language modeling. Indeed, simple Recurrent Neural Networks (RNNs)\nencounter difficulties recovering from past mistakes when generating sequences\ndue to high correlation between hidden states. These challenges can be\nmitigated by integrating second-order terms in the hidden-state update. One\nsuch model, multiplicative Long Short-Term Memory (mLSTM) is particularly\ninteresting in its original formulation because of the sharing of its\nsecond-order term, referred to as the intermediate state. We explore these\narchitectural improvements by introducing new models and testing them on\ncharacter-level language modeling tasks. This allows us to establish the\nrelevance of shared parametrization in recurrent language modeling.\n", "versions": [{"version": "v1", "created": "Sun, 30 Jun 2019 20:51:43 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Maupom\u00e9", "Diego", ""], ["Meurs", "Marie-Jean", ""]]}, {"id": "1907.00456", "submitter": "Natasha Jaques", "authors": "Natasha Jaques, Asma Ghandeharioun, Judy Hanwen Shen, Craig Ferguson,\n  Agata Lapedriza, Noah Jones, Shixiang Gu, Rosalind Picard", "title": "Way Off-Policy Batch Deep Reinforcement Learning of Implicit Human\n  Preferences in Dialog", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most deep reinforcement learning (RL) systems are not able to learn\neffectively from off-policy data, especially if they cannot explore online in\nthe environment. These are critical shortcomings for applying RL to real-world\nproblems where collecting data is expensive, and models must be tested offline\nbefore being deployed to interact with the environment -- e.g. systems that\nlearn from human interaction. Thus, we develop a novel class of off-policy\nbatch RL algorithms, which are able to effectively learn offline, without\nexploring, from a fixed batch of human interaction data. We leverage models\npre-trained on data as a strong prior, and use KL-control to penalize\ndivergence from this prior during RL training. We also use dropout-based\nuncertainty estimates to lower bound the target Q-values as a more efficient\nalternative to Double Q-Learning. The algorithms are tested on the problem of\nopen-domain dialog generation -- a challenging reinforcement learning problem\nwith a 20,000-dimensional action space. Using our Way Off-Policy algorithm, we\ncan extract multiple different reward functions post-hoc from collected human\ninteraction data, and learn effectively from all of these. We test the\nreal-world generalization of these systems by deploying them live to converse\nwith humans in an open-domain setting, and demonstrate that our algorithm\nachieves significant improvements over prior methods in off-policy batch RL.\n", "versions": [{"version": "v1", "created": "Sun, 30 Jun 2019 20:53:19 GMT"}, {"version": "v2", "created": "Mon, 8 Jul 2019 17:21:46 GMT"}], "update_date": "2019-07-09", "authors_parsed": [["Jaques", "Natasha", ""], ["Ghandeharioun", "Asma", ""], ["Shen", "Judy Hanwen", ""], ["Ferguson", "Craig", ""], ["Lapedriza", "Agata", ""], ["Jones", "Noah", ""], ["Gu", "Shixiang", ""], ["Picard", "Rosalind", ""]]}, {"id": "1907.00457", "submitter": "Julian Salazar", "authors": "Shaoshi Ling, Julian Salazar, Katrin Kirchhoff", "title": "Contextual Phonetic Pretraining for End-to-end Utterance-level Language\n  and Speaker Recognition", "comments": "submitted to INTERSPEECH 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pretrained contextual word representations in NLP have greatly improved\nperformance on various downstream tasks. For speech, we propose contextual\nframe representations that capture phonetic information at the acoustic frame\nlevel and can be used for utterance-level language, speaker, and speech\nrecognition. These representations come from the frame-wise intermediate\nrepresentations of an end-to-end, self-attentive ASR model (SAN-CTC) on spoken\nutterances. We first train the model on the Fisher English corpus with\ncontext-independent phoneme labels, then use its representations at inference\ntime as features for task-specific models on the NIST LRE07 closed-set language\nrecognition task and a Fisher speaker recognition task, giving significant\nimprovements over the state-of-the-art on both (e.g., language EER of 4.68% on\n3sec utterances, 23% relative reduction in speaker EER). Results remain\ncompetitive when using a novel dilated convolutional model for language\nrecognition, or when ASR pretraining is done with character labels only.\n", "versions": [{"version": "v1", "created": "Sun, 30 Jun 2019 20:54:21 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Ling", "Shaoshi", ""], ["Salazar", "Julian", ""], ["Kirchhoff", "Katrin", ""]]}, {"id": "1907.00462", "submitter": "Marie-Jean Meurs", "authors": "Diego Maupom\\'e, Marc Queudot, Marie-Jean Meurs", "title": "Inter and Intra Document Attention for Depression Risk Assessment", "comments": "9 pages, in Proceedings of The 32nd Canadian Conference on Artificial\n  Intelligence (Canadian AI 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We take interest in the early assessment of risk for depression in social\nmedia users. We focus on the eRisk 2018 dataset, which represents users as a\nsequence of their written online contributions. We implement four RNN-based\nsystems to classify the users. We explore several aggregations methods to\ncombine predictions on individual posts. Our best model reads through all\nwritings of a user in parallel but uses an attention mechanism to prioritize\nthe most important ones at each timestep.\n", "versions": [{"version": "v1", "created": "Sun, 30 Jun 2019 21:09:48 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Maupom\u00e9", "Diego", ""], ["Queudot", "Marc", ""], ["Meurs", "Marie-Jean", ""]]}, {"id": "1907.00464", "submitter": "Joseph Fisher", "authors": "Joseph Fisher, Andreas Vlachos", "title": "Merge and Label: A novel neural network architecture for nested NER", "comments": "Accepted at ACL 2019. Code available at\n  https://github.com/fishjh2/merge_label", "journal-ref": "ACL 2019 P19-1585", "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Named entity recognition (NER) is one of the best studied tasks in natural\nlanguage processing. However, most approaches are not capable of handling\nnested structures which are common in many applications. In this paper we\nintroduce a novel neural network architecture that first merges tokens and/or\nentities into entities forming nested structures, and then labels each of them\nindependently. Unlike previous work, our merge and label approach predicts\nreal-valued instead of discrete segmentation structures, which allow it to\ncombine word and nested entity embeddings while maintaining differentiability.\n%which smoothly groups entities into single vectors across multiple levels. We\nevaluate our approach using the ACE 2005 Corpus, where it achieves\nstate-of-the-art F1 of 74.6, further improved with contextual embeddings (BERT)\nto 82.4, an overall improvement of close to 8 F1 points over previous\napproaches trained on the same data. Additionally we compare it against\nBiLSTM-CRFs, the dominant approach for flat NER structures, demonstrating that\nits ability to predict nested structures does not impact performance in simpler\ncases.\n", "versions": [{"version": "v1", "created": "Sun, 30 Jun 2019 21:12:14 GMT"}], "update_date": "2019-08-12", "authors_parsed": [["Fisher", "Joseph", ""], ["Vlachos", "Andreas", ""]]}, {"id": "1907.00481", "submitter": "Filippo Maria Bianchi", "authors": "Filippo Maria Bianchi, Daniele Grattarola, Cesare Alippi", "title": "Spectral Clustering with Graph Neural Networks for Graph Pooling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spectral clustering (SC) is a popular clustering technique to find strongly\nconnected communities on a graph. SC can be used in Graph Neural Networks\n(GNNs) to implement pooling operations that aggregate nodes belonging to the\nsame cluster. However, the eigendecomposition of the Laplacian is expensive\nand, since clustering results are graph-specific, pooling methods based on SC\nmust perform a new optimization for each new sample. In this paper, we propose\na graph clustering approach that addresses these limitations of SC. We\nformulate a continuous relaxation of the normalized minCUT problem and train a\nGNN to compute cluster assignments that minimize this objective. Our GNN-based\nimplementation is differentiable, does not require to compute the spectral\ndecomposition, and learns a clustering function that can be quickly evaluated\non out-of-sample graphs. From the proposed clustering method, we design a graph\npooling operator that overcomes some important limitations of state-of-the-art\ngraph pooling techniques and achieves the best performance in several\nsupervised and unsupervised tasks.\n", "versions": [{"version": "v1", "created": "Sun, 30 Jun 2019 22:08:16 GMT"}, {"version": "v2", "created": "Thu, 11 Jul 2019 14:26:02 GMT"}, {"version": "v3", "created": "Wed, 3 Jun 2020 16:07:45 GMT"}, {"version": "v4", "created": "Fri, 17 Jul 2020 09:46:10 GMT"}, {"version": "v5", "created": "Mon, 14 Dec 2020 13:39:00 GMT"}, {"version": "v6", "created": "Tue, 29 Dec 2020 08:32:54 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Bianchi", "Filippo Maria", ""], ["Grattarola", "Daniele", ""], ["Alippi", "Cesare", ""]]}, {"id": "1907.00485", "submitter": "Massimo Fornasier", "authors": "Massimo Fornasier, Timo Klock, Michael Rauchensteiner", "title": "Robust and Resource Efficient Identification of Two Hidden Layer Neural\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the structure identification and the uniform approximation of two\nfully nonlinear layer neural networks of the type $f(x)=1^T h(B^T g(A^T x))$ on\n$\\mathbb R^d$ from a small number of query samples. We approach the problem by\nsampling actively finite difference approximations to Hessians of the network.\nGathering several approximate Hessians allows reliably to approximate the\nmatrix subspace $\\mathcal W$ spanned by symmetric tensors $a_1 \\otimes a_1\n,\\dots,a_{m_0}\\otimes a_{m_0}$ formed by weights of the first layer together\nwith the entangled symmetric tensors $v_1 \\otimes v_1 ,\\dots,v_{m_1}\\otimes\nv_{m_1}$, formed by suitable combinations of the weights of the first and\nsecond layer as $v_\\ell=A G_0 b_\\ell/\\|A G_0 b_\\ell\\|_2$, $\\ell \\in [m_1]$, for\na diagonal matrix $G_0$ depending on the activation functions of the first\nlayer. The identification of the 1-rank symmetric tensors within $\\mathcal W$\nis then performed by the solution of a robust nonlinear program. We provide\nguarantees of stable recovery under a posteriori verifiable conditions. We\nfurther address the correct attribution of approximate weights to the first or\nsecond layer. By using a suitably adapted gradient descent iteration, it is\npossible then to estimate, up to intrinsic symmetries, the shifts of the\nactivations functions of the first layer and compute exactly the matrix $G_0$.\nOur method of identification of the weights of the network is fully\nconstructive, with quantifiable sample complexity, and therefore contributes to\ndwindle the black-box nature of the network training phase. We corroborate our\ntheoretical results by extensive numerical experiments.\n", "versions": [{"version": "v1", "created": "Sun, 30 Jun 2019 22:27:13 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Fornasier", "Massimo", ""], ["Klock", "Timo", ""], ["Rauchensteiner", "Michael", ""]]}, {"id": "1907.00489", "submitter": "Maximilian Du", "authors": "Maximilian Du", "title": "Improving LSTM Neural Networks for Better Short-Term Wind Power\n  Predictions", "comments": "5 pages, 4 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper improves wind power prediction via weather forecast-contextualized\nLong Short-Term Memory Neural Network (LSTM) models. Initially, only wind power\ndata was fed to a generic LSTM, but this model performed poorly, with erratic\nand naive behavior observed on even low-variance data sections. To address this\nissue, weather forecast data was added to better contextualize the power data,\nand LSTM modifications were made to address specific model shortcomings. These\nmodels were tested through both a Normalized Mean Absolute Error and the Naive\nRatio (NR), which is a score introduced by this paper to quantify the unwanted\npresence of naive character in trained models. Results showed an increased\naccuracy with the addition of weather forecast data on the modified models, as\nwell as a decrease in naive character. Key contributions include making\nimproved LSTM variants, usage of weather forecast data, and the introduction of\na new model performance index.\n", "versions": [{"version": "v1", "created": "Sun, 30 Jun 2019 22:43:18 GMT"}, {"version": "v2", "created": "Sat, 3 Aug 2019 21:08:32 GMT"}], "update_date": "2019-08-06", "authors_parsed": [["Du", "Maximilian", ""]]}, {"id": "1907.00494", "submitter": "Liang Ding", "authors": "Liang Ding and Dacheng Tao", "title": "The University of Sydney's Machine Translation System for WMT19", "comments": "To appear in WMT2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes the University of Sydney's submission of the WMT 2019\nshared news translation task. We participated in the\nFinnish$\\rightarrow$English direction and got the best BLEU(33.0) score among\nall the participants. Our system is based on the self-attentional Transformer\nnetworks, into which we integrated the most recent effective strategies from\nacademic research (e.g., BPE, back translation, multi-features data selection,\ndata augmentation, greedy model ensemble, reranking, ConMBR system combination,\nand post-processing). Furthermore, we propose a novel augmentation method\n$Cycle Translation$ and a data mixture strategy $Big$/$Small$ parallel\nconstruction to entirely exploit the synthetic corpus. Extensive experiments\nshow that adding the above techniques can make continuous improvements of the\nBLEU scores, and the best result outperforms the baseline (Transformer ensemble\nmodel trained with the original parallel corpus) by approximately 5.3 BLEU\nscore, achieving the state-of-the-art performance.\n", "versions": [{"version": "v1", "created": "Sun, 30 Jun 2019 22:55:27 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Ding", "Liang", ""], ["Tao", "Dacheng", ""]]}, {"id": "1907.00496", "submitter": "Zachary Ross", "authors": "Zachary E. Ross, Daniel T. Trugman, Kamyar Azizzadenesheli, Anima\n  Anandkumar", "title": "Directivity Modes of Earthquake Populations with Unsupervised Learning", "comments": "14 pages, 14 figures", "journal-ref": null, "doi": "10.1029/2019JB018299", "report-no": null, "categories": "physics.geo-ph cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel approach for resolving modes of rupture directivity in\nlarge populations of earthquakes. A seismic spectral decomposition technique is\nused to first produce relative measurements of radiated energy for earthquakes\nin a spatially-compact cluster. The azimuthal distribution of energy for each\nearthquake is then assumed to result from one of several distinct modes of\nrupture propagation. Rather than fitting a kinematic rupture model to determine\nthe most likely mode of rupture propagation, we instead treat the modes as\nlatent variables and learn them with a Gaussian mixture model. The mixture\nmodel simultaneously determines the number of events that best identify with\neach mode. The technique is demonstrated on four datasets in California with\nseveral thousand earthquakes. We show that the datasets naturally decompose\ninto distinct rupture propagation modes that correspond to different rupture\ndirections, and the fault plane is unambiguously identified for all cases. We\nfind that these small earthquakes exhibit unilateral ruptures 53-74% of the\ntime on average. The results provide important observational constraints on the\nphysics of earthquakes and faults.\n", "versions": [{"version": "v1", "created": "Sun, 30 Jun 2019 23:24:24 GMT"}], "update_date": "2020-04-22", "authors_parsed": [["Ross", "Zachary E.", ""], ["Trugman", "Daniel T.", ""], ["Azizzadenesheli", "Kamyar", ""], ["Anandkumar", "Anima", ""]]}, {"id": "1907.00497", "submitter": "Hakan G\\\"okcesu", "authors": "Hakan Gokcesu, S. Serdar Kozat", "title": "Efficient Online Convex Optimization with Adaptively Minimax Optimal\n  Dynamic Regret", "comments": "10 pages, 1 figure, preprint, [v0] 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce an online convex optimization algorithm using projected\nsub-gradient descent with ideal adaptive learning rates, where each computation\nis efficiently done in a sequential manner. For the first time in the\nliterature, this algorithm provides an adaptively minimax optimal dynamic\nregret guarantee for a sequence of convex functions without any restrictions --\nsuch as strong convexity, smoothness or even Lipschitz continuity -- against a\ncomparator decision sequence with bounded total successive changes. We show\noptimality by generating the worst-case dynamic regret adaptive lower bound,\nwhich constitutes of actual sub-gradient norms and matches with our guarantees.\nWe discuss the advantages of our algorithm as opposed to adaptive projection\nwith sub-gradient self outer products and also derive the extension for\nindependent learning in each decision coordinate separately. Additionally, we\ndemonstrate how to best preserve our guarantees when the bound on total\nsuccessive changes in the dynamic comparator sequence grows as time goes, in a\ntruly online manner.\n", "versions": [{"version": "v1", "created": "Sun, 30 Jun 2019 23:37:56 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Gokcesu", "Hakan", ""], ["Kozat", "S. Serdar", ""]]}, {"id": "1907.00501", "submitter": "Moustafa Alzantot", "authors": "Moustafa Alzantot, Ziqi Wang, Mani B. Srivastava", "title": "Deep Residual Neural Networks for Audio Spoofing Detection", "comments": "\u00ef\u00bb\u00bfThis article has been removed by arXiv administrators because the\n  submitter did not have the rights to agree to the license at the time of\n  submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The state-of-art models for speech synthesis and voice conversion are capable\nof generating synthetic speech that is perceptually indistinguishable from\nbonafide human speech. These methods represent a threat to the automatic\nspeaker verification (ASV) systems. Additionally, replay attacks where the\nattacker uses a speaker to replay a previously recorded genuine human speech\nare also possible. We present our solution for the ASVSpoof2019 competition,\nwhich aims to develop countermeasure systems that distinguish between spoofing\nattacks and genuine speeches. Our model is inspired by the success of residual\nconvolutional networks in many classification tasks. We build three variants of\na residual convolutional neural network that accept different feature\nrepresentations (MFCC, Log-magnitude STFT, and CQCC) of input. We compare the\nperformance achieved by our model variants and the competition baseline models.\nIn the logical access scenario, the fusion of our models has zero t-DCF cost\nand zero equal error rate (EER), as evaluated on the development set. On the\nevaluation set, our model fusion improves the t-DCF and EER by 25% compared to\nthe baseline algorithms. Against physical access replay attacks, our model\nfusion improves the baseline algorithms t-DCF and EER scores by 71% and 75% on\nthe evaluation set, respectively.\n", "versions": [{"version": "v1", "created": "Sun, 30 Jun 2019 23:58:28 GMT"}], "update_date": "2019-07-11", "authors_parsed": [["Alzantot", "Moustafa", ""], ["Wang", "Ziqi", ""], ["Srivastava", "Mani B.", ""]]}, {"id": "1907.00503", "submitter": "Lei Xu", "authors": "Lei Xu, Maria Skoularidou, Alfredo Cuesta-Infante, Kalyan\n  Veeramachaneni", "title": "Modeling Tabular data using Conditional GAN", "comments": "Accepted to NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modeling the probability distribution of rows in tabular data and generating\nrealistic synthetic data is a non-trivial task. Tabular data usually contains a\nmix of discrete and continuous columns. Continuous columns may have multiple\nmodes whereas discrete columns are sometimes imbalanced making the modeling\ndifficult. Existing statistical and deep neural network models fail to properly\nmodel this type of data. We design TGAN, which uses a conditional generative\nadversarial network to address these challenges. To aid in a fair and thorough\ncomparison, we design a benchmark with 7 simulated and 8 real datasets and\nseveral Bayesian network baselines. TGAN outperforms Bayesian methods on most\nof the real datasets whereas other deep learning methods could not.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jul 2019 00:11:32 GMT"}, {"version": "v2", "created": "Mon, 28 Oct 2019 02:13:06 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Xu", "Lei", ""], ["Skoularidou", "Maria", ""], ["Cuesta-Infante", "Alfredo", ""], ["Veeramachaneni", "Kalyan", ""]]}, {"id": "1907.00516", "submitter": "Weixia Zhang", "authors": "Weixia Zhang, Kede Ma, Guangtao Zhai, and Xiaokang Yang", "title": "Learning to Blindly Assess Image Quality in the Laboratory and Wild", "comments": "Accepted by ICIP2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computational models for blind image quality assessment (BIQA) are typically\ntrained in well-controlled laboratory environments with limited\ngeneralizability to realistically distorted images. Similarly, BIQA models\noptimized for images captured in the wild cannot adequately handle\nsynthetically distorted images. To face the cross-distortion-scenario\nchallenge, we develop a BIQA model and an approach of training it on multiple\nIQA databases (of different distortion scenarios) simultaneously. A key step in\nour approach is to create and combine image pairs within individual databases\nas the training set, which effectively bypasses the issue of perceptual scale\nrealignment. We compute a continuous quality annotation for each pair from the\ncorresponding human opinions, indicating the probability of one image having\nbetter perceptual quality. We train a deep neural network for BIQA over the\ntraining set of massive image pairs by minimizing the fidelity loss.\nExperiments on six IQA databases demonstrate that the optimized model by the\nproposed training strategy is effective in blindly assessing image quality in\nthe laboratory and wild, outperforming previous BIQA methods by a large margin.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jul 2019 02:31:07 GMT"}, {"version": "v2", "created": "Wed, 23 Oct 2019 02:25:30 GMT"}, {"version": "v3", "created": "Wed, 20 May 2020 05:51:24 GMT"}], "update_date": "2020-05-21", "authors_parsed": [["Zhang", "Weixia", ""], ["Ma", "Kede", ""], ["Zhai", "Guangtao", ""], ["Yang", "Xiaokang", ""]]}, {"id": "1907.00526", "submitter": "Longxiang Shi", "authors": "Longxiang Shi, Shijian Li, Longbing Cao, Long Yang, Gang Zheng, Gang\n  Pan", "title": "FiDi-RL: Incorporating Deep Reinforcement Learning with\n  Finite-Difference Policy Search for Efficient Learning of Continuous Control", "comments": "I found some theoretical errors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years significant progress has been made in dealing with\nchallenging problems using reinforcement learning.Despite its great success,\nreinforcement learning still faces challenge in continuous control tasks.\nConventional methods always compute the derivatives of the optimal goal with a\ncostly computation resources, and are inefficient, unstable and lack of\nrobust-ness when dealing with such tasks. Alternatively, derivative-based\nmethods treat the optimization process as a blackbox and show robustness and\nstability in learning continuous control tasks, but not data efficient in\nlearning. The combination of both methods so as to get the best of the both has\nraised attention. However, most of the existing combination works adopt complex\nneural networks (NNs) as the policy for control. The double-edged sword of deep\nNNs can yield better performance, but also makes it difficult for parameter\ntuning and computation. To this end, in this paper we presents a novel method\ncalled FiDi-RL, which incorporates deep RL with Finite-Difference (FiDi) policy\nsearch.FiDi-RL combines Deep Deterministic Policy Gradients (DDPG)with Augment\nRandom Search (ARS) and aims at improving the data efficiency of ARS. The\nempirical results show that FiDi-RL can improves the performance and stability\nof ARS, and provide competitive results against some existing deep\nreinforcement learning methods\n", "versions": [{"version": "v1", "created": "Mon, 1 Jul 2019 03:21:19 GMT"}, {"version": "v2", "created": "Wed, 10 Jul 2019 03:29:40 GMT"}, {"version": "v3", "created": "Sat, 1 Feb 2020 03:22:47 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Shi", "Longxiang", ""], ["Li", "Shijian", ""], ["Cao", "Longbing", ""], ["Yang", "Long", ""], ["Zheng", "Gang", ""], ["Pan", "Gang", ""]]}, {"id": "1907.00533", "submitter": "Travis Dick", "authors": "Maria-Florina Balcan, Travis Dick, Manuel Lang", "title": "Learning to Link", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clustering is an important part of many modern data analysis pipelines,\nincluding network analysis and data retrieval. There are many different\nclustering algorithms developed by various communities, and it is often not\nclear which algorithm will give the best performance on a specific clustering\ntask. Similarly, we often have multiple ways to measure distances between data\npoints, and the best clustering performance might require a non-trivial\ncombination of those metrics. In this work, we study data-driven algorithm\nselection and metric learning for clustering problems, where the goal is to\nsimultaneously learn the best algorithm and metric for a specific application.\nThe family of clustering algorithms we consider is parameterized linkage based\nprocedures that includes single and complete linkage. The family of distance\nfunctions we learn over are convex combinations of base distance functions. We\ndesign efficient learning algorithms which receive samples from an\napplication-specific distribution over clustering instances and simultaneously\nlearn both a near-optimal distance and clustering algorithm from these classes.\nWe also carry out a comprehensive empirical evaluation of our techniques\nshowing that they can lead to significantly improved clustering performance.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jul 2019 04:08:40 GMT"}, {"version": "v2", "created": "Tue, 16 Jul 2019 18:36:24 GMT"}, {"version": "v3", "created": "Wed, 2 Oct 2019 20:32:34 GMT"}], "update_date": "2019-10-04", "authors_parsed": [["Balcan", "Maria-Florina", ""], ["Dick", "Travis", ""], ["Lang", "Manuel", ""]]}, {"id": "1907.00542", "submitter": "Hee-Soo Heo", "authors": "Hee-Soo Heo, Jee-weon Jung, Hye-jin Shim, IL-Ho Yang, Ha-Jin Yu", "title": "Cosine similarity-based adversarial process", "comments": "10 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.AS eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An adversarial process between two deep neural networks is a promising\napproach to train a robust model. In this paper, we propose an adversarial\nprocess using cosine similarity, whereas conventional adversarial processes are\nbased on inverted categorical cross entropy (CCE). When used for training an\nidentification model, the adversarial process induces the competition of two\ndiscriminative models; one for a primary task such as speaker identification or\nimage recognition, the other one for a subsidiary task such as channel\nidentification or domain identification. In particular, the adversarial process\ndegrades the performance of the subsidiary model by eliminating the subsidiary\ninformation in the input which, in assumption, may degrade the performance of\nthe primary model. The conventional adversarial processes maximize the CCE of\nthe subsidiary model to degrade the performance. We have studied a framework\nfor training robust discriminative models by eliminating channel or domain\ninformation (subsidiary information) by applying such an adversarial process.\nHowever, we found through experiments that using the process of maximizing the\nCCE does not guarantee the performance degradation of the subsidiary model. In\nthe proposed adversarial process using cosine similarity, on the contrary, the\nperformance of the subsidiary model can be degraded more efficiently by\nsearching feature space orthogonal to the subsidiary model. The experiments on\nspeaker identification and image recognition show that we found features that\nmake the outputs of the subsidiary models independent of the input, and the\nperformances of the primary models are improved.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jul 2019 04:44:35 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Heo", "Hee-Soo", ""], ["Jung", "Jee-weon", ""], ["Shim", "Hye-jin", ""], ["Yang", "IL-Ho", ""], ["Yu", "Ha-Jin", ""]]}, {"id": "1907.00544", "submitter": "Chaoqi Chen", "authors": "Chaoqi Chen, Weiping Xie, Tingyang Xu, Yu Rong, Wenbing Huang, Xinghao\n  Ding, Yue Huang, Junzhou Huang", "title": "Unsupervised Adversarial Graph Alignment with Graph Embedding", "comments": "10 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph alignment, also known as network alignment, is a fundamental task in\nsocial network analysis. Many recent works have relied on partially labeled\ncross-graph node correspondences, i.e., anchor links. However, due to the\nprivacy and security issue, the manual labeling of anchor links for diverse\nscenarios may be prohibitive. Aligning two graphs without any anchor links is a\ncrucial and challenging task. In this paper, we propose an Unsupervised\nAdversarial Graph Alignment (UAGA) framework to learn a cross-graph alignment\nbetween two embedding spaces of different graphs in a fully unsupervised\nfashion (\\emph{i.e.,} no existing anchor links and no users' personal profile\nor attribute information is available). The proposed framework learns the\nembedding spaces of each graph, and then attempts to align the two spaces via\nadversarial training, followed by a refinement procedure. We further extend our\nUAGA method to incremental UAGA (iUAGA) that iteratively reveals the unobserved\nuser links based on the pseudo anchor links. This can be used to further\nimprove both the embedding quality and the alignment accuracy. Moreover, the\nproposed methods will benefit some real-world applications, \\emph{e.g.,} link\nprediction in social networks. Comprehensive experiments on real-world data\ndemonstrate the effectiveness of our proposed approaches UAGA and iUAGA for\nunsupervised graph alignment.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jul 2019 04:48:48 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Chen", "Chaoqi", ""], ["Xie", "Weiping", ""], ["Xu", "Tingyang", ""], ["Rong", "Yu", ""], ["Huang", "Wenbing", ""], ["Ding", "Xinghao", ""], ["Huang", "Yue", ""], ["Huang", "Junzhou", ""]]}, {"id": "1907.00558", "submitter": "Maria Glenski", "authors": "Maria Glenski, Tim Weninger, and Svitlana Volkova", "title": "Improved Forecasting of Cryptocurrency Price using Social Signals", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST cs.LG cs.SI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Social media signals have been successfully used to develop large-scale\npredictive and anticipatory analytics. For example, forecasting stock market\nprices and influenza outbreaks. Recently, social data has been explored to\nforecast price fluctuations of cryptocurrencies, which are a novel disruptive\ntechnology with significant political and economic implications. In this paper\nwe leverage and contrast the predictive power of social signals, specifically\nuser behavior and communication patterns, from multiple social platforms GitHub\nand Reddit to forecast prices for three cyptocurrencies with high developer and\ncommunity interest - Bitcoin, Ethereum, and Monero. We evaluate the performance\nof neural network models that rely on long short-term memory units (LSTMs)\ntrained on historical price data and social data against price only LSTMs and\nbaseline autoregressive integrated moving average (ARIMA) models, commonly used\nto predict stock prices. Our results not only demonstrate that social signals\nreduce error when forecasting daily coin price, but also show that the language\nused in comments within the official communities on Reddit (r/Bitcoin,\nr/Ethereum, and r/Monero) are the best predictors overall. We observe that\nmodels are more accurate in forecasting price one day ahead for Bitcoin (4%\nroot mean squared percent error) compared to Ethereum (7%) and Monero (8%).\n", "versions": [{"version": "v1", "created": "Mon, 1 Jul 2019 05:51:05 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Glenski", "Maria", ""], ["Weninger", "Tim", ""], ["Volkova", "Svitlana", ""]]}, {"id": "1907.00559", "submitter": "Evgeny Burnaev", "authors": "Maria Taktasheva and Albert Matveev and Alexey Artemov and Evgeny\n  Burnaev", "title": "Learning to Approximate Directional Fields Defined over 2D Planes", "comments": "7 pages, 5 figures", "journal-ref": "Proc. of AIST, 2019", "doi": null, "report-no": null, "categories": "cs.CV cs.GR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reconstruction of directional fields is a need in many geometry processing\ntasks, such as image tracing, extraction of 3D geometric features, and finding\nprincipal surface directions. A common approach to the construction of\ndirectional fields from data relies on complex optimization procedures, which\nare usually poorly formalizable, require a considerable computational effort,\nand do not transfer across applications. In this work, we propose a deep\nlearning-based approach and study the expressive power and generalization\nability.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jul 2019 05:58:46 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Taktasheva", "Maria", ""], ["Matveev", "Albert", ""], ["Artemov", "Alexey", ""], ["Burnaev", "Evgeny", ""]]}, {"id": "1907.00560", "submitter": "Ido Nachum", "authors": "Ido Nachum and Amir Yehudayoff", "title": "On Symmetry and Initialization for Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work provides an additional step in the theoretical understanding of\nneural networks. We consider neural networks with one hidden layer and show\nthat when learning symmetric functions, one can choose initial conditions so\nthat standard SGD training efficiently produces generalization guarantees. We\nempirically verify this and show that this does not hold when the initial\nconditions are chosen at random. The proof of convergence investigates the\ninteraction between the two layers of the network. Our results highlight the\nimportance of using symmetry in the design of neural networks.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jul 2019 06:03:05 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Nachum", "Ido", ""], ["Yehudayoff", "Amir", ""]]}, {"id": "1907.00568", "submitter": "Tong-Jie Zhang Dr.", "authors": "Shi-Yu Li, Yun-Long Li, Tong-Jie Zhang", "title": "Model Comparison of Dark Energy models Using Deep Network", "comments": "11 pages, 5 figures. Matches the published version in RAA", "journal-ref": "Research in Astronomy and Astrophysics, Volume 19, Issue 9,\n  article id. 137 (2019)", "doi": null, "report-no": null, "categories": "astro-ph.CO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work uses a combination of a variational auto-encoder and generative\nadversarial network to compare different dark energy models in light of\nobservations, e.g., the distance modulus from type Ia supernovae. The network\nfinds an analytical variational approximation to the true posterior of the\nlatent parameters in the models, yielding consistent model comparison results\nwith those derived by the standard Bayesian method, which suffers from a\ncomputationally expensive integral over the parameters in the product of the\nlikelihood and the prior. The parallel computational nature of the network\ntogether with the stochastic gradient descent optimization technique leads to\nan efficient way to compare the physical models given a set of observations.\nThe converged network also provides interpolation for a dataset, which is\nuseful for data reconstruction.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jul 2019 06:40:30 GMT"}, {"version": "v2", "created": "Tue, 2 Jul 2019 02:38:40 GMT"}, {"version": "v3", "created": "Mon, 14 Oct 2019 12:22:44 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Li", "Shi-Yu", ""], ["Li", "Yun-Long", ""], ["Zhang", "Tong-Jie", ""]]}, {"id": "1907.00570", "submitter": "Joris Baan", "authors": "Joris Baan, Maartje ter Hoeve, Marlies van der Wees, Anne Schuth,\n  Maarten de Rijke", "title": "Do Transformer Attention Heads Provide Transparency in Abstractive\n  Summarization?", "comments": "To appear at FACTS-IR 2019, SIGIR", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning algorithms become more powerful, often at the cost of increased\ncomplexity. In response, the demand for algorithms to be transparent is\ngrowing. In NLP tasks, attention distributions learned by attention-based deep\nlearning models are used to gain insights in the models' behavior. To which\nextent is this perspective valid for all NLP tasks? We investigate whether\ndistributions calculated by different attention heads in a transformer\narchitecture can be used to improve transparency in the task of abstractive\nsummarization. To this end, we present both a qualitative and quantitative\nanalysis to investigate the behavior of the attention heads. We show that some\nattention heads indeed specialize towards syntactically and semantically\ndistinct input. We propose an approach to evaluate to which extent the\nTransformer model relies on specifically learned attention distributions. We\nalso discuss what this implies for using attention distributions as a means of\ntransparency.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jul 2019 06:46:43 GMT"}, {"version": "v2", "created": "Mon, 8 Jul 2019 14:57:07 GMT"}], "update_date": "2019-07-09", "authors_parsed": [["Baan", "Joris", ""], ["ter Hoeve", "Maartje", ""], ["van der Wees", "Marlies", ""], ["Schuth", "Anne", ""], ["de Rijke", "Maarten", ""]]}, {"id": "1907.00586", "submitter": "Heishiro Kanagawa", "authors": "Heishiro Kanagawa and Wittawat Jitkrittum and Lester Mackey and Kenji\n  Fukumizu and Arthur Gretton", "title": "A Kernel Stein Test for Comparing Latent Variable Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a kernel-based nonparametric test of relative goodness of fit,\nwhere the goal is to compare two models, both of which may have unobserved\nlatent variables, such that the marginal distribution of the observed variables\nis intractable. The proposed test generalises the recently proposed kernel\nStein discrepancy (KSD) tests (Liu et al., 2016, Chwialkowski et al., 2016,\nYang et al., 2018) to the case of latent variable models, a much more general\nclass than the fully observed models treated previously. As our main\ntheoretical contribution, we prove that the new test, with a properly\ncalibrated threshold, has a well-controlled type-I error. In the case of models\nwith low-dimensional latent structure and high-dimensional observations, our\ntest significantly outperforms the relative Maximum Mean Discrepancy test,\nwhich is based on samples from the models and does not exploit the latent\nstructure.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jul 2019 07:46:16 GMT"}, {"version": "v2", "created": "Sun, 1 Nov 2020 09:52:22 GMT"}, {"version": "v3", "created": "Wed, 5 May 2021 11:56:30 GMT"}], "update_date": "2021-05-06", "authors_parsed": [["Kanagawa", "Heishiro", ""], ["Jitkrittum", "Wittawat", ""], ["Mackey", "Lester", ""], ["Fukumizu", "Kenji", ""], ["Gretton", "Arthur", ""]]}, {"id": "1907.00593", "submitter": "Wen-Pu Cai", "authors": "Wen-Pu Cai and Wu-Jun Li", "title": "Weight Normalization based Quantization for Deep Neural Network\n  Compression", "comments": "10 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the development of deep neural networks, the size of network models\nbecomes larger and larger. Model compression has become an urgent need for\ndeploying these network models to mobile or embedded devices. Model\nquantization is a representative model compression technique. Although a lot of\nquantization methods have been proposed, many of them suffer from a high\nquantization error caused by a long-tail distribution of network weights. In\nthis paper, we propose a novel quantization method, called weight normalization\nbased quantization (WNQ), for model compression. WNQ adopts weight\nnormalization to avoid the long-tail distribution of network weights and\nsubsequently reduces the quantization error. Experiments on CIFAR-100 and\nImageNet show that WNQ can outperform other baselines to achieve\nstate-of-the-art performance.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jul 2019 07:59:39 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Cai", "Wen-Pu", ""], ["Li", "Wu-Jun", ""]]}, {"id": "1907.00612", "submitter": "Tao He", "authors": "Tao He, Yuan-Fang Li, Lianli Gao, Dongxiang Zhang, Jingkuan Song", "title": "One Network for Multi-Domains: Domain Adaptive Hashing with Intersectant\n  Generative Adversarial Network", "comments": "Accepted by IJCAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the recent explosive increase of digital data, image recognition and\nretrieval become a critical practical application. Hashing is an effective\nsolution to this problem, due to its low storage requirement and high query\nspeed. However, most of past works focus on hashing in a single (source)\ndomain. Thus, the learned hash function may not adapt well in a new (target)\ndomain that has a large distributional difference with the source domain. In\nthis paper, we explore an end-to-end domain adaptive learning framework that\nsimultaneously and precisely generates discriminative hash codes and classifies\ntarget domain images. Our method encodes two domains images into a semantic\ncommon space, followed by two independent generative adversarial networks\narming at crosswise reconstructing two domains' images, reducing domain\ndisparity and improving alignment in the shared space. We evaluate our\nframework on {four} public benchmark datasets, all of which show that our\nmethod is superior to the other state-of-the-art methods on the tasks of object\nrecognition and image retrieval.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jul 2019 08:48:39 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["He", "Tao", ""], ["Li", "Yuan-Fang", ""], ["Gao", "Lianli", ""], ["Zhang", "Dongxiang", ""], ["Song", "Jingkuan", ""]]}, {"id": "1907.00624", "submitter": "Georgios Leontidis", "authors": "Bashar Alhnaity, Simon Pearson, Georgios Leontidis and Stefanos\n  Kollias", "title": "Using Deep Learning to Predict Plant Growth and Yield in Greenhouse\n  Environments", "comments": "8 pages, 2 figures, 1 table. arXiv admin note: text overlap with\n  arXiv:1807.11809, arXiv:1707.00666 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Effective plant growth and yield prediction is an essential task for\ngreenhouse growers and for agriculture in general. Developing models which can\neffectively model growth and yield can help growers improve the environmental\ncontrol for better production, match supply and market demand and lower costs.\nRecent developments in Machine Learning (ML) and, in particular, Deep Learning\n(DL) can provide powerful new analytical tools. The proposed study utilises ML\nand DL techniques to predict yield and plant growth variation across two\ndifferent scenarios, tomato yield forecasting and Ficus benjamina stem growth,\nin controlled greenhouse environments. We deploy a new deep recurrent neural\nnetwork (RNN), using the Long Short-Term Memory (LSTM) neuron model, in the\nprediction formulations. Both the former yield, growth and stem diameter\nvalues, as well as the microclimate conditions, are used by the RNN\narchitecture to model the targeted growth parameters. A comparative study is\npresented, using ML methods, such as support vector regression and random\nforest regression, utilising the mean square error criterion, in order to\nevaluate the performance achieved by the different methods. Very promising\nresults, based on data that have been obtained from two greenhouses, in Belgium\nand the UK, in the framework of the EU Interreg SMARTGREEN project (2017-2021),\nare presented.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jul 2019 09:36:06 GMT"}], "update_date": "2019-07-03", "authors_parsed": [["Alhnaity", "Bashar", ""], ["Pearson", "Simon", ""], ["Leontidis", "Georgios", ""], ["Kollias", "Stefanos", ""]]}, {"id": "1907.00650", "submitter": "Qi She", "authors": "Qi She, Anqi Wu", "title": "Neural Dynamics Discovery via Gaussian Process Recurrent Neural Networks", "comments": "11 pages, 3 figures, 7 Tables, accepted to The Conference on\n  Uncertainty in Artificial Intelligence (UAI), 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Latent dynamics discovery is challenging in extracting complex dynamics from\nhigh-dimensional noisy neural data. Many dimensionality reduction methods have\nbeen widely adopted to extract low-dimensional, smooth and time-evolving latent\ntrajectories. However, simple state transition structures, linear embedding\nassumptions, or inflexible inference networks impede the accurate recovery of\ndynamic portraits. In this paper, we propose a novel latent dynamic model that\nis capable of capturing nonlinear, non-Markovian, long short-term\ntime-dependent dynamics via recurrent neural networks and tackling complex\nnonlinear embedding via non-parametric Gaussian process. Due to the complexity\nand intractability of the model and its inference, we also provide a powerful\ninference network with bi-directional long short-term memory networks that\nencode both past and future information into posterior distributions. In the\nexperiment, we show that our model outperforms other state-of-the-art methods\nin reconstructing insightful latent dynamics from both simulated and\nexperimental neural datasets with either Gaussian or Poisson observations,\nespecially in the low-sample scenario. Our codes and additional materials are\navailable at https://github.com/sheqi/GP-RNN_UAI2019.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jul 2019 10:51:38 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["She", "Qi", ""], ["Wu", "Anqi", ""]]}, {"id": "1907.00652", "submitter": "Ashley Gritzman", "authors": "Ashley Daniel Gritzman", "title": "Avoiding Implementation Pitfalls of \"Matrix Capsules with EM Routing\" by\n  Hinton et al", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent progress on capsule networks by Hinton et al. has generated\nconsiderable excitement in the machine learning community. The idea behind a\ncapsule is inspired by a cortical minicolumn in the brain, whereby a vertically\norganised group of around 100 neurons receive common inputs, have common\noutputs, are interconnected, and may well constitute a fundamental computation\nunit of the cerebral cortex. However, Hinton's paper on \"Matrix Capsule with EM\nRouting'\" was unfortunately not accompanied by a release of source code, which\nleft interested researchers attempting to implement the architecture and\nreproduce the benchmarks on their own. This has certainly slowed the progress\nof research building on this work. While writing our own implementation, we\nnoticed several common mistakes in other open source implementations that we\ncame across. In this paper we share some of these learnings, specifically\nfocusing on three implementation pitfalls and how to avoid them: (1) parent\ncapsules with only one child; (2) normalising the amount of data assigned to\nparent capsules; (3) parent capsules at different positions compete for child\ncapsules. While our implementation is a considerable improvement over currently\navailable implementations, it still falls slightly short of the performance\nreported by Hinton et al. (2018). The source code for this implementation is\navailable on GitHub at the following URL:\nhttps://github.com/IBM/matrix-capsules-with-em-routing.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jul 2019 10:51:58 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Gritzman", "Ashley Daniel", ""]]}, {"id": "1907.00662", "submitter": "Roope Tervo", "authors": "Roope Tervo, Joonas Karjalainen, Alexander Jung", "title": "Short-term prediction of Electricity Outages Caused by Convective Storms", "comments": "arXiv admin note: text overlap with arXiv:1805.07897", "journal-ref": null, "doi": "10.1109/TGRS.2019.2921809", "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Prediction of power outages caused by convective storms which are highly\nlocalised in space and time is of crucial importance to power grid operators.\nWe propose a new machine learning approach to predict the damage caused by\nstorms. This approach hinges identifying and tracking of storm cells using\nweather radar images on the application of machine learning techniques. Overall\nprediction process consists of identifying storm cells from CAPPI weather radar\nimages by contouring them with a solid 35 dBZ threshold, predicting a track of\nstorm cells and classifying them based on their damage potential to power grid\noperators. Tracked storm cells are then classified by combining data obtained\nfrom weather radar, ground weather observations and lightning detectors. We\ncompare random forest classifiers and deep neural networks as alternative\nmethods to classify storm cells. The main challenge is that the training data\nare heavily imbalanced as extreme weather events are rare.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jul 2019 11:18:01 GMT"}], "update_date": "2019-07-03", "authors_parsed": [["Tervo", "Roope", ""], ["Karjalainen", "Joonas", ""], ["Jung", "Alexander", ""]]}, {"id": "1907.00664", "submitter": "Wenling Shang", "authors": "Wenling Shang, Alex Trott, Stephan Zheng, Caiming Xiong, Richard\n  Socher", "title": "Learning World Graphs to Accelerate Hierarchical Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many real-world scenarios, an autonomous agent often encounters various\ntasks within a single complex environment. We propose to build a graph\nabstraction over the environment structure to accelerate the learning of these\ntasks. Here, nodes are important points of interest (pivotal states) and edges\nrepresent feasible traversals between them. Our approach has two stages. First,\nwe jointly train a latent pivotal state model and a curiosity-driven\ngoal-conditioned policy in a task-agnostic manner. Second, provided with the\ninformation from the world graph, a high-level Manager quickly finds solution\nto new tasks and expresses subgoals in reference to pivotal states to a\nlow-level Worker. The Worker can then also leverage the graph to easily\ntraverse to the pivotal states of interest, even across long distance, and\nexplore non-locally. We perform a thorough ablation study to evaluate our\napproach on a suite of challenging maze tasks, demonstrating significant\nadvantages from the proposed framework over baselines that lack world graph\nknowledge in terms of performance and efficiency.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jul 2019 11:22:52 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Shang", "Wenling", ""], ["Trott", "Alex", ""], ["Zheng", "Stephan", ""], ["Xiong", "Caiming", ""], ["Socher", "Richard", ""]]}, {"id": "1907.00678", "submitter": "Alexandre Quemy", "authors": "Alexandre Quemy", "title": "Two-stage Optimization for Machine Learning Workflow", "comments": "Submitted to Information Systems, DOLAP special issue", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machines learning techniques plays a preponderant role in dealing with\nmassive amount of data and are employed in almost every possible domain.\nBuilding a high quality machine learning model to be deployed in production is\na challenging task, from both, the subject matter experts and the machine\nlearning practitioners.\n  For a broader adoption and scalability of machine learning systems, the\nconstruction and configuration of machine learning workflow need to gain in\nautomation. In the last few years, several techniques have been developed in\nthis direction, known as autoML.\n  In this paper, we present a two-stage optimization process to build data\npipelines and configure machine learning algorithms. First, we study the impact\nof data pipelines compared to algorithm configuration in order to show the\nimportance of data preprocessing over hyperparameter tuning. The second part\npresents policies to efficiently allocate search time between data pipeline\nconstruction and algorithm configuration. Those policies are agnostic from the\nmetaoptimizer. Last, we present a metric to determine if a data pipeline is\nspecific or independent from the algorithm, enabling fine-grain pipeline\npruning and meta-learning for the coldstart problem.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jul 2019 12:06:18 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Quemy", "Alexandre", ""]]}, {"id": "1907.00680", "submitter": "Sibylle Hess", "authors": "Sibylle Hess, Wouter Duivesteijn, Philipp Honysz, Katharina Morik", "title": "The SpectACl of Nonconvex Clustering: A Spectral Approach to\n  Density-Based Clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When it comes to clustering nonconvex shapes, two paradigms are used to find\nthe most suitable clustering: minimum cut and maximum density. The most popular\nalgorithms incorporating these paradigms are Spectral Clustering and DBSCAN.\nBoth paradigms have their pros and cons. While minimum cut clusterings are\nsensitive to noise, density-based clusterings have trouble handling clusters\nwith varying densities. In this paper, we propose \\textsc{SpectACl}: a method\ncombining the advantages of both approaches, while solving the two mentioned\ndrawbacks. Our method is easy to implement, such as spectral clustering, and\ntheoretically founded to optimize a proposed density criterion of clusterings.\nThrough experiments on synthetic and real-world data, we demonstrate that our\napproach provides robust and reliable clusterings.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jul 2019 12:08:58 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Hess", "Sibylle", ""], ["Duivesteijn", "Wouter", ""], ["Honysz", "Philipp", ""], ["Morik", "Katharina", ""]]}, {"id": "1907.00686", "submitter": "Nicolas Meyer", "authors": "Meyer Nicolas (LPSM (UMR\\_8001)), Olivier Wintenberger (LPSM\n  (UMR\\_8001))", "title": "Sparse regular variation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Regular variation provides a convenient theoretical framework to study large\nevents. In the multivariate setting, the dependence structure of the positive\nextremes is characterized by a measure - the spectral measure - defined on the\npositive orthant of the unit sphere. This measure gathers information on the\nlocalization of extreme events and has often a sparse support since severe\nevents do not simultaneously occur in all directions. However, it is defined\nthrough weak convergence which does not provide a natural way to capture this\nsparsity structure.In this paper, we introduce the notion of sparse regular\nvariation which allows to better learn the dependence structure of extreme\nevents. This concept is based on the Euclidean projection onto the simplex for\nwhich efficient algorithms are known. We prove that under mild assumptions\nsparse regular variation and regular variation are two equivalent notions and\nwe establish several results for sparsely regularly varying random vectors.\nFinally, we illustrate on numerical examples how this new concept allows one to\ndetect extremal directions.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jul 2019 12:11:57 GMT"}, {"version": "v2", "created": "Fri, 10 Jan 2020 09:55:28 GMT"}, {"version": "v3", "created": "Thu, 18 Jun 2020 18:43:38 GMT"}, {"version": "v4", "created": "Fri, 27 Nov 2020 15:52:29 GMT"}, {"version": "v5", "created": "Tue, 23 Feb 2021 08:33:40 GMT"}], "update_date": "2021-02-24", "authors_parsed": [["Nicolas", "Meyer", "", "LPSM"], ["Wintenberger", "Olivier", "", "LPSM"]]}, {"id": "1907.00693", "submitter": "Seiichi Uchida", "authors": "Toshiki Nakamura, Anna Zhu, and Seiichi Uchida", "title": "Scene Text Magnifier", "comments": "to appear at the International Conference on Document Analysis and\n  Recognition (ICDAR) 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Scene text magnifier aims to magnify text in natural scene images without\nrecognition. It could help the special groups, who have myopia or dyslexia to\nbetter understand the scene. In this paper, we design the scene text magnifier\nthrough interacted four CNN-based networks: character erasing, character\nextraction, character magnify, and image synthesis. The architecture of the\nnetworks are extended based on the hourglass encoder-decoders. It inputs the\noriginal scene text image and outputs the text magnified image while keeps the\nbackground unchange. Intermediately, we can get the side-output results of text\nerasing and text extraction. The four sub-networks are first trained\nindependently and fine-tuned in end-to-end mode. The training samples for each\nstage are processed through a flow with original image and text annotation in\nICDAR2013 and Flickr dataset as input, and corresponding text erased image,\nmagnified text annotation, and text magnified scene image as output. To\nevaluate the performance of text magnifier, the Structural Similarity is used\nto measure the regional changes in each character region. The experimental\nresults demonstrate our method can magnify scene text effectively without\neffecting the background.\n", "versions": [{"version": "v1", "created": "Mon, 17 Jun 2019 03:14:08 GMT"}, {"version": "v2", "created": "Fri, 5 Jul 2019 09:16:02 GMT"}], "update_date": "2019-07-08", "authors_parsed": [["Nakamura", "Toshiki", ""], ["Zhu", "Anna", ""], ["Uchida", "Seiichi", ""]]}, {"id": "1907.00697", "submitter": "Sibylle Hess", "authors": "Sibylle Hess, Nico Piatkowski, Katharina Morik", "title": "The Trustworthy Pal: Controlling the False Discovery Rate in Boolean\n  Matrix Factorization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Boolean matrix factorization (BMF) is a popular and powerful technique for\ninferring knowledge from data. The mining result is the Boolean product of two\nmatrices, approximating the input dataset. The Boolean product is a disjunction\nof rank-1 binary matrices, each describing a feature-relation, called pattern,\nfor a group of samples. Yet, there are no guarantees that any of the returned\npatterns do not actually arise from noise, i.e., are false discoveries. In this\npaper, we propose and discuss the usage of the false discovery rate in the\nunsupervised BMF setting. We prove two bounds on the probability that a found\npattern is constituted of random Bernoulli-distributed noise. Each bound\nexploits a specific property of the factorization which minimizes the\napproximation error---yielding new insights on the minimizers of Boolean matrix\nfactorization. This leads to improved BMF algorithms by replacing heuristic\nrank selection techniques with a theoretically well-based approach. Our\nempirical demonstration shows that both bounds deliver excellent results in\nvarious practical settings.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jul 2019 12:23:49 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Hess", "Sibylle", ""], ["Piatkowski", "Nico", ""], ["Morik", "Katharina", ""]]}, {"id": "1907.00700", "submitter": "Yingyang Chen", "authors": "Chunkai Zhang and Yingyang Chen and Ao Yin and Zhen Qin and Xing Zhang\n  and Keli Zhang and Zoe L. Jiang", "title": "An Improvement of PAA on Trend-Based Approximation for Time Series", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Piecewise Aggregate Approximation (PAA) is a competitive basic dimension\nreduction method for high-dimensional time series mining. When deployed,\nhowever, the limitations are obvious that some important information will be\nmissed, especially the trend. In this paper, we propose two new approaches for\ntime series that utilize approximate trend feature information. Our first\nmethod is based on relative mean value of each segment to record the trend,\nwhich divide each segment into two parts and use the numerical average\nrespectively to represent the trend. We proved that this method satisfies lower\nbound which guarantee no false dismissals. Our second method uses a binary\nstring to record the trend which is also relative to mean in each segment. Our\nmethods are applied on similarity measurement in classification and anomaly\ndetection, the experimental results show the improvement of accuracy and\neffectiveness by extracting the trend feature suitably.\n", "versions": [{"version": "v1", "created": "Fri, 28 Jun 2019 06:45:07 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Zhang", "Chunkai", ""], ["Chen", "Yingyang", ""], ["Yin", "Ao", ""], ["Qin", "Zhen", ""], ["Zhang", "Xing", ""], ["Zhang", "Keli", ""], ["Jiang", "Zoe L.", ""]]}, {"id": "1907.00701", "submitter": "Yingyang Chen", "authors": "Chunkai Zhang and Yingyang Chen and Ao Yin", "title": "Anomaly Subsequence Detection with Dynamic Local Density for Time Series", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Anomaly subsequence detection is to detect inconsistent data, which always\ncontains important information, among time series. Due to the high\ndimensionality of the time series, traditional anomaly detection often requires\na large time overhead; furthermore, even if the dimensionality reduction\ntechniques can improve the efficiency, they will lose some information and\nsuffer from time drift and parameter tuning. In this paper, we propose a new\nanomaly subsequence detection with Dynamic Local Density Estimation (DLDE) to\nimprove the detection effect without losing the trend information by\ndynamically dividing the time series using Time Split Tree. In order to avoid\nthe impact of the hash function and the randomness of dynamic time segments,\nensemble learning is used. Experimental results on different types of data sets\nverify that the proposed model outperforms the state-of-art methods, and the\naccuracy has big improvement.\n", "versions": [{"version": "v1", "created": "Fri, 28 Jun 2019 07:06:32 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Zhang", "Chunkai", ""], ["Chen", "Yingyang", ""], ["Yin", "Ao", ""]]}, {"id": "1907.00708", "submitter": "Dominic Danks", "authors": "Fran\\c{c}ois-Xavier Aubet, Dominic Danks, Yuchen Zhu", "title": "EQuANt (Enhanced Question Answer Network)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine Reading Comprehension (MRC) is an important topic in the domain of\nautomated question answering and in natural language processing more generally.\nSince the release of the SQuAD 1.1 and SQuAD 2 datasets, progress in the field\nhas been particularly significant, with current state-of-the-art models now\nexhibiting near-human performance at both answering well-posed questions and\ndetecting questions which are unanswerable given a corresponding context. In\nthis work, we present Enhanced Question Answer Network (EQuANt), an MRC model\nwhich extends the successful QANet architecture of Yu et al. to cope with\nunanswerable questions. By training and evaluating EQuANt on SQuAD 2, we show\nthat it is indeed possible to extend QANet to the unanswerable domain. We\nachieve results which are close to 2 times better than our chosen baseline\nobtained by evaluating a lightweight version of the original QANet architecture\non SQuAD 2. In addition, we report that the performance of EQuANt on SQuAD 1.1\nafter being trained on SQuAD2 exceeds that of our lightweight QANet\narchitecture trained and evaluated on SQuAD 1.1, demonstrating the utility of\nmulti-task learning in the MRC context.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jun 2019 08:13:45 GMT"}, {"version": "v2", "created": "Wed, 3 Jul 2019 21:03:37 GMT"}], "update_date": "2019-07-05", "authors_parsed": [["Aubet", "Fran\u00e7ois-Xavier", ""], ["Danks", "Dominic", ""], ["Zhu", "Yuchen", ""]]}, {"id": "1907.00710", "submitter": "Lizi Liao Ms", "authors": "Lizi Liao, Ryuichi Takanobu, Yunshan Ma, Xun Yang, Minlie Huang and\n  Tat-Seng Chua", "title": "Deep Conversational Recommender in Travel", "comments": "12 pages, 7 figures, submitted to TKDE. arXiv admin note: text\n  overlap with arXiv:1809.07070 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When traveling to a foreign country, we are often in dire need of an\nintelligent conversational agent to provide instant and informative responses\nto our various queries. However, to build such a travel agent is non-trivial.\nFirst of all, travel naturally involves several sub-tasks such as hotel\nreservation, restaurant recommendation and taxi booking etc, which invokes the\nneed for global topic control. Secondly, the agent should consider various\nconstraints like price or distance given by the user to recommend an\nappropriate venue. In this paper, we present a Deep Conversational Recommender\n(DCR) and apply to travel. It augments the sequence-to-sequence (seq2seq)\nmodels with a neural latent topic component to better guide response generation\nand make the training easier. To consider the various constraints for venue\nrecommendation, we leverage a graph convolutional network (GCN) based approach\nto capture the relationships between different venues and the match between\nvenue and dialog context. For response generation, we combine the topic-based\ncomponent with the idea of pointer networks, which allows us to effectively\nincorporate recommendation results. We perform extensive evaluation on a\nmulti-turn task-oriented dialog dataset in travel domain and the results show\nthat our method achieves superior performance as compared to a wide range of\nbaselines.\n", "versions": [{"version": "v1", "created": "Tue, 25 Jun 2019 04:39:26 GMT"}], "update_date": "2019-07-03", "authors_parsed": [["Liao", "Lizi", ""], ["Takanobu", "Ryuichi", ""], ["Ma", "Yunshan", ""], ["Yang", "Xun", ""], ["Huang", "Minlie", ""], ["Chua", "Tat-Seng", ""]]}, {"id": "1907.00734", "submitter": "Matias Valdenegro-Toro", "authors": "Matias Valdenegro-Toro", "title": "Learning Objectness from Sonar Images for Class-Independent Object\n  Detection", "comments": "European Conference on Mobile Robots 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.RO eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Detecting novel objects without class information is not trivial, as it is\ndifficult to generalize from a small training set. This is an interesting\nproblem for underwater robotics, as modeling marine objects is inherently more\ndifficult in sonar images, and training data might not be available apriori.\nDetection proposals algorithms can be used for this purpose but usually\nrequires a large amount of output bounding boxes. In this paper we propose the\nuse of a fully convolutional neural network that regresses an objectness value\ndirectly from a Forward-Looking sonar image. By ranking objectness, we can\nproduce high recall (96 %) with only 100 proposals per image. In comparison,\nEdgeBoxes requires 5000 proposals to achieve a slightly better recall of 97 %,\nwhile Selective Search requires 2000 proposals to achieve 95 % recall. We also\nshow that our method outperforms a template matching baseline by a considerable\nmargin, and is able to generalize to completely new objects. We expect that\nthis kind of technique can be used in the field to find lost objects under the\nsea.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jul 2019 12:46:08 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Valdenegro-Toro", "Matias", ""]]}, {"id": "1907.00749", "submitter": "Vidyasagar Sadhu", "authors": "Vidyasagar Sadhu, Teruhisa Misu, Dario Pompili", "title": "Deep Multi-Task Learning for Anomalous Driving Detection Using CAN Bus\n  Scalar Sensor Data", "comments": "IROS 2019, 8 pages", "journal-ref": "2019 IEEE/RSJ International Conference on Intelligent Robots and\n  Systems (IROS), pp. 1-8", "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Corner cases are the main bottlenecks when applying Artificial Intelligence\n(AI) systems to safety-critical applications. An AI system should be\nintelligent enough to detect such situations so that system developers can\nprepare for subsequent planning. In this paper, we propose semi-supervised\nanomaly detection considering the imbalance of normal situations. In\nparticular, driving data consists of multiple positive/normal situations (e.g.,\nright turn, going straight), some of which (e.g., U-turn) could be as rare as\nanomalous situations. Existing machine learning based anomaly detection\napproaches do not fare sufficiently well when applied to such imbalanced data.\nIn this paper, we present a novel multi-task learning based approach that\nleverages domain-knowledge (maneuver labels) for anomaly detection in driving\ndata. We evaluate the proposed approach both quantitatively and qualitatively\non 150 hours of real-world driving data and show improved performance over\nbaseline approaches.\n", "versions": [{"version": "v1", "created": "Fri, 28 Jun 2019 04:36:47 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Sadhu", "Vidyasagar", ""], ["Misu", "Teruhisa", ""], ["Pompili", "Dario", ""]]}, {"id": "1907.00758", "submitter": "Aciel Eshky", "authors": "Aciel Eshky, Manuel Sam Ribeiro, Korin Richmond, Steve Renals", "title": "Synchronising audio and ultrasound by learning cross-modal embeddings", "comments": "5 pages, 1 figure, 4 tables; Interspeech 2019 with the following\n  edits: 1) Loss and accuracy upon convergence were accidentally reported from\n  an older model. Now updated with model described throughout the paper. All\n  other results remain unchanged. 2) Max true offset in the training data\n  corrected from 179ms to 1789ms. 3) Detectability \"boundary/range\" renamed to\n  detectability \"thresholds\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CV cs.LG cs.SD eess.AS eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Audiovisual synchronisation is the task of determining the time offset\nbetween speech audio and a video recording of the articulators. In child speech\ntherapy, audio and ultrasound videos of the tongue are captured using\ninstruments which rely on hardware to synchronise the two modalities at\nrecording time. Hardware synchronisation can fail in practice, and no mechanism\nexists to synchronise the signals post hoc. To address this problem, we employ\na two-stream neural network which exploits the correlation between the two\nmodalities to find the offset. We train our model on recordings from 69\nspeakers, and show that it correctly synchronises 82.9% of test utterances from\nunseen therapy sessions and unseen speakers, thus considerably reducing the\nnumber of utterances to be manually synchronised. An analysis of model\nperformance on the test utterances shows that directed phone articulations are\nmore difficult to automatically synchronise compared to utterances containing\nnatural variation in speech such as words, sentences, or conversations.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jul 2019 13:22:48 GMT"}, {"version": "v2", "created": "Wed, 27 Nov 2019 11:24:26 GMT"}], "update_date": "2019-11-28", "authors_parsed": [["Eshky", "Aciel", ""], ["Ribeiro", "Manuel Sam", ""], ["Richmond", "Korin", ""], ["Renals", "Steve", ""]]}, {"id": "1907.00762", "submitter": "Blake Woodworth", "authors": "Blake Woodworth and Nathan Srebro", "title": "Open Problem: The Oracle Complexity of Convex Optimization with Limited\n  Memory", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We note that known methods achieving the optimal oracle complexity for first\norder convex optimization require quadratic memory, and ask whether this is\nnecessary, and more broadly seek to characterize the minimax number of first\norder queries required to optimize a convex Lipschitz function subject to a\nmemory constraint.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jul 2019 13:37:34 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Woodworth", "Blake", ""], ["Srebro", "Nathan", ""]]}, {"id": "1907.00770", "submitter": "Artur Speiser", "authors": "Artur Speiser, Lucas-Raphael M\\\"uller, Ulf Matti, Christopher J.\n  Obara, Wesley R. Legant, Jonas Ries, Jakob H. Macke, Srinivas C. Turaga", "title": "Teaching deep neural networks to localize single molecules for\n  super-resolution microscopy", "comments": "Significant improvements of the algorithm, including a novel loss\n  function. Evaluations on multiple real data sets", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Single-molecule localization fluorescence microscopy constructs\nsuper-resolution images by sequential imaging and computational localization of\nsparsely activated fluorophores. Accurate and efficient fluorophore\nlocalization algorithms are key to the success of this computational microscopy\nmethod. We present a novel localization algorithm based on deep learning which\nsignificantly improves upon the state of the art. Our contributions are a novel\nnetwork architecture for simultaneous detection and localization, and new loss\nfunction which phrases detection and localization as a Bayesian inference\nproblem, and thus allows the network to provide uncertainty-estimates. In\ncontrast to standard methods which independently process imaging frames, our\nnetwork architecture uses temporal context from multiple sequentially imaged\nframes to detect and localize molecules. We demonstrate the power of our method\nacross a variety of datasets, imaging modalities, signal to noise ratios, and\nfluorophore densities. While existing localization algorithms can achieve\noptimal localization accuracy at low fluorophore densities, they are confounded\nby high densities. Our method is the first deep-learning based approach which\nachieves state-of-the-art on the SMLM2016 challenge. It achieves the best\nscores on 12 out of 12 data-sets when comparing both detection accuracy and\nprecision, and excels at high densities. Finally, we investigate how\nunsupervised learning can be used to make the network robust against mismatch\nbetween simulated and real data. The lessons learned here are more generally\nrelevant for the training of deep networks to solve challenging Bayesian\ninverse problems on spatially extended domains in biology and physics.\n", "versions": [{"version": "v1", "created": "Thu, 27 Jun 2019 22:27:17 GMT"}, {"version": "v2", "created": "Mon, 20 Jul 2020 14:28:35 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Speiser", "Artur", ""], ["M\u00fcller", "Lucas-Raphael", ""], ["Matti", "Ulf", ""], ["Obara", "Christopher J.", ""], ["Legant", "Wesley R.", ""], ["Ries", "Jonas", ""], ["Macke", "Jakob H.", ""], ["Turaga", "Srinivas C.", ""]]}, {"id": "1907.00772", "submitter": "Ahmed Mustafa", "authors": "Ahmed Mustafa, Arijit Biswas, Christian Bergler, Julia Schottenhamml\n  and Andreas Maier", "title": "Analysis by Adversarial Synthesis -- A Novel Approach for Speech\n  Vocoding", "comments": "Accepted to Interspeech 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classical parametric speech coding techniques provide a compact\nrepresentation for speech signals. This affords a very low transmission rate\nbut with a reduced perceptual quality of the reconstructed signals. Recently,\nautoregressive deep generative models such as WaveNet and SampleRNN have been\nused as speech vocoders to scale up the perceptual quality of the reconstructed\nsignals without increasing the coding rate. However, such models suffer from a\nvery slow signal generation mechanism due to their sample-by-sample modelling\napproach. In this work, we introduce a new methodology for neural speech\nvocoding based on generative adversarial networks (GANs). A fake speech signal\nis generated from a very compressed representation of the glottal excitation\nusing conditional GANs as a deep generative model. This fake speech is then\nrefined using the LPC parameters of the original speech signal to obtain a\nnatural reconstruction. The reconstructed speech waveforms based on this\napproach show a higher perceptual quality than the classical vocoder\ncounterparts according to subjective and objective evaluation scores for a\ndataset of 30 male and female speakers. Moreover, the usage of GANs enables to\ngenerate signals in one-shot compared to autoregressive generative models. This\nmakes GANs promising for exploration to implement high-quality neural vocoders.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jul 2019 13:46:54 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Mustafa", "Ahmed", ""], ["Biswas", "Arijit", ""], ["Bergler", "Christian", ""], ["Schottenhamml", "Julia", ""], ["Maier", "Andreas", ""]]}, {"id": "1907.00782", "submitter": "Jun Zhao", "authors": "Ning Wang, Xiaokui Xiao, Yin Yang, Jun Zhao, Siu Cheung Hui, Hyejin\n  Shin, Junbum Shin, Ge Yu", "title": "Collecting and Analyzing Multidimensional Data with Local Differential\n  Privacy", "comments": "12-Page Full Paper in Proceedings of the 2019 IEEE International\n  Conference on Data Engineering (ICDE). arXiv admin note: text overlap with\n  arXiv:1606.05053", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY cs.DB cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Local differential privacy (LDP) is a recently proposed privacy standard for\ncollecting and analyzing data, which has been used, e.g., in the Chrome\nbrowser, iOS and macOS. In LDP, each user perturbs her information locally, and\nonly sends the randomized version to an aggregator who performs analyses, which\nprotects both the users and the aggregator against private information leaks.\nAlthough LDP has attracted much research attention in recent years, the\nmajority of existing work focuses on applying LDP to complex data and/or\nanalysis tasks. In this paper, we point out that the fundamental problem of\ncollecting multidimensional data under LDP has not been addressed sufficiently,\nand there remains much room for improvement even for basic tasks such as\ncomputing the mean value over a single numeric attribute under LDP. Motivated\nby this, we first propose novel LDP mechanisms for collecting a numeric\nattribute, whose accuracy is at least no worse (and usually better) than\nexisting solutions in terms of worst-case noise variance. Then, we extend these\nmechanisms to multidimensional data that can contain both numeric and\ncategorical attributes, where our mechanisms always outperform existing\nsolutions regarding worst-case noise variance. As a case study, we apply our\nsolutions to build an LDP-compliant stochastic gradient descent algorithm\n(SGD), which powers many important machine learning tasks. Experiments using\nreal datasets confirm the effectiveness of our methods, and their advantages\nover existing solutions.\n", "versions": [{"version": "v1", "created": "Fri, 28 Jun 2019 13:33:43 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Wang", "Ning", ""], ["Xiao", "Xiaokui", ""], ["Yang", "Yin", ""], ["Zhao", "Jun", ""], ["Hui", "Siu Cheung", ""], ["Shin", "Hyejin", ""], ["Shin", "Junbum", ""], ["Yu", "Ge", ""]]}, {"id": "1907.00783", "submitter": "Cem Tekin", "authors": "Eralp Turgay, Cem Bulucu, Cem Tekin", "title": "Exploiting Relevance for Online Decision-Making in High-Dimensions", "comments": "Accepted for publication in IEEE Transactions on Signal Processing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many sequential decision-making tasks require choosing at each decision step\nthe right action out of the vast set of possibilities by extracting actionable\nintelligence from high-dimensional data streams. Most of the times, the\nhigh-dimensionality of actions and data makes learning of the optimal actions\nby traditional learning methods impracticable. In this work, we investigate how\nto discover and leverage sparsity in actions and data to enable fast learning.\nAs our learning model, we consider a structured contextual multi-armed bandit\n(CMAB) with high-dimensional arm (action) and context (data) sets, where the\nrewards depend only on a few relevant dimensions of the joint context-arm set,\npossibly in a non-linear way. We depart from the prior work by assuming a\nhigh-dimensional, continuum set of arms, and allow relevant context dimensions\nto vary for each arm. We propose a new online learning algorithm called {\\em\nCMAB with Relevance Learning} (CMAB-RL) and prove that its time-averaged regret\nasymptotically goes to zero when the expected reward varies smoothly in\ncontexts and arms. CMAB-RL enjoys a substantially improved regret bound\ncompared to classical CMAB algorithms whose regrets depend on dimensions $d_x$\nand $d_a$ of the context and arm sets. Importantly, we show that when the\nlearner has prior knowledge on sparsity, given in terms of upper bounds\n$\\overline{d}_x$ and $\\overline{d}_a$ on the number of relevant dimensions,\nthen CMAB-RL achieves $\\tilde{O}(T^{1-1/(2+2\\overline{d}_x +\\overline{d}_a)})$\nregret. Finally, we illustrate how CMAB algorithms can be used for optimal\npersonalized blood glucose control in type 1 diabetes mellitus patients, and\nshow that CMAB-RL outperforms other contextual MAB algorithms in this task.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jul 2019 13:52:11 GMT"}, {"version": "v2", "created": "Mon, 28 Dec 2020 13:26:00 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Turgay", "Eralp", ""], ["Bulucu", "Cem", ""], ["Tekin", "Cem", ""]]}, {"id": "1907.00787", "submitter": "Larissa Triess", "authors": "Larissa T. Triess, David Peter, Christoph B. Rist, Markus Enzweiler,\n  J. Marius Z\\\"ollner", "title": "CNN-based synthesis of realistic high-resolution LiDAR data", "comments": "2019 IEEE Intelligent Vehicles Symposium (IV)", "journal-ref": null, "doi": "10.1109/IVS.2019.8813771", "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a novel CNN-based approach for synthesizing\nhigh-resolution LiDAR point cloud data. Our approach generates semantically and\nperceptually realistic results with guidance from specialized loss-functions.\nFirst, we utilize a modified per-point loss that addresses missing LiDAR point\nmeasurements. Second, we align the quality of our generated output with\nreal-world sensor data by applying a perceptual loss. In large-scale\nexperiments on real-world datasets, we evaluate both the geometric accuracy and\nsemantic segmentation performance using our generated data vs. ground truth. In\na mean opinion score testing we further assess the perceptual quality of our\ngenerated point clouds. Our results demonstrate a significant quantitative and\nqualitative improvement in both geometry and semantics over traditional non\nCNN-based up-sampling methods.\n", "versions": [{"version": "v1", "created": "Fri, 28 Jun 2019 12:36:18 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Triess", "Larissa T.", ""], ["Peter", "David", ""], ["Rist", "Christoph B.", ""], ["Enzweiler", "Markus", ""], ["Z\u00f6llner", "J. Marius", ""]]}, {"id": "1907.00811", "submitter": "Xiaoyang Wang", "authors": "Xiaoyang Wang, Ioannis Mavromatis, Andrea Tassi, Raul\n  Santos-Rodriguez, Robert J. Piechocki", "title": "Location Anomalies Detection for Connected and Autonomous Vehicles", "comments": "Accepted to IEEE CAVS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NI eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Future Connected and Automated Vehicles (CAV), and more generally ITS, will\nform a highly interconnected system. Such a paradigm is referred to as the\nInternet of Vehicles (herein Internet of CAVs) and is a prerequisite to\norchestrate traffic flows in cities. For optimal decision making and\nsupervision, traffic centres will have access to suitably anonymized CAV\nmobility information. Safe and secure operations will then be contingent on\nearly detection of anomalies. In this paper, a novel unsupervised learning\nmodel based on deep autoencoder is proposed to detect the self-reported\nlocation anomaly in CAVs, using vehicle locations and the Received Signal\nStrength Indicator (RSSI) as features. Quantitative experiments on simulation\ndatasets show that the proposed approach is effective and robust in detecting\nself-reported location anomalies.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jul 2019 14:16:54 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Wang", "Xiaoyang", ""], ["Mavromatis", "Ioannis", ""], ["Tassi", "Andrea", ""], ["Santos-Rodriguez", "Raul", ""], ["Piechocki", "Robert J.", ""]]}, {"id": "1907.00813", "submitter": "Matthew Joseph", "authors": "Matthew Joseph, Jieming Mao, Aaron Roth", "title": "Exponential Separations in Local Differential Privacy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove a general connection between the communication complexity of\ntwo-player games and the sample complexity of their multi-player locally\nprivate analogues. We use this connection to prove sample complexity lower\nbounds for locally differentially private protocols as straightforward\ncorollaries of results from communication complexity. In particular, we 1) use\na communication lower bound for the hidden layers problem to prove an\nexponential sample complexity separation between sequentially and fully\ninteractive locally private protocols, and 2) use a communication lower bound\nfor the pointer chasing problem to prove an exponential sample complexity\nseparation between $k$ round and $k+1$ round sequentially interactive locally\nprivate protocols, for every $k$.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jul 2019 14:18:39 GMT"}, {"version": "v2", "created": "Fri, 27 Sep 2019 15:28:35 GMT"}, {"version": "v3", "created": "Tue, 29 Oct 2019 14:10:49 GMT"}], "update_date": "2019-10-30", "authors_parsed": [["Joseph", "Matthew", ""], ["Mao", "Jieming", ""], ["Roth", "Aaron", ""]]}, {"id": "1907.00820", "submitter": "Kexin Wang", "authors": "Kexin Wang, Yu Zhou, Shaonan Wang, Jiajun Zhang and Chengqing Zong", "title": "Understanding Memory Modules on Learning Simple Algorithms", "comments": "Accepted at the XAI Workshop in IJCAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work has shown that memory modules are crucial for the generalization\nability of neural networks on learning simple algorithms. However, we still\nhave little understanding of the working mechanism of memory modules. To\nalleviate this problem, we apply a two-step analysis pipeline consisting of\nfirst inferring hypothesis about what strategy the model has learned according\nto visualization and then verify it by a novel proposed qualitative analysis\nmethod based on dimension reduction. Using this method, we have analyzed two\npopular memory-augmented neural networks, neural Turing machine and\nstack-augmented neural network on two simple algorithm tasks including\nreversing a random sequence and evaluation of arithmetic expressions. Results\nhave shown that on the former task both models can learn to generalize and on\nthe latter task only the stack-augmented model can do so. We show that\ndifferent strategies are learned by the models, in which specific categories of\ninput are monitored and different policies are made based on that to change the\nmemory.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jul 2019 14:27:03 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Wang", "Kexin", ""], ["Zhou", "Yu", ""], ["Wang", "Shaonan", ""], ["Zhang", "Jiajun", ""], ["Zong", "Chengqing", ""]]}, {"id": "1907.00821", "submitter": "Nikola Simidjievski", "authors": "Nikola Simidjievski, Ljup\\v{c}o Todorovski, Ju\\v{s} Kocijan, Sa\\v{s}o\n  D\\v{z}eroski", "title": "Equation Discovery for Nonlinear System Identification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SY math.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Equation discovery methods enable modelers to combine domain-specific\nknowledge and system identification to construct models most suitable for a\nselected modeling task. The method described and evaluated in this paper can be\nused as a nonlinear system identification method for gray-box modeling. It\nconsists of two interlaced parts of modeling that are computer-aided. The first\nperforms computer-aided identification of a model structure composed of\nelements selected from user-specified domain-specific modeling knowledge, while\nthe second part performs parameter estimation. In this paper, recent\ndevelopments of the equation discovery method called process-based modeling,\nsuited for nonlinear system identification, are elaborated and illustrated on\ntwo continuous-time case studies. The first case study illustrates the use of\nthe process-based modeling on synthetic data while the second case-study\nevaluates on measured data for a standard system-identification benchmark. The\nexperimental results clearly demonstrate the ability of process-based modeling\nto reconstruct both model structure and parameters from measured data.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jul 2019 14:28:40 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Simidjievski", "Nikola", ""], ["Todorovski", "Ljup\u010do", ""], ["Kocijan", "Ju\u0161", ""], ["D\u017eeroski", "Sa\u0161o", ""]]}, {"id": "1907.00824", "submitter": "Hugo Scurto", "authors": "Hugo Scurto, Bavo Van Kerrebroeck, Baptiste Caramiaux, Fr\\'ed\\'eric\n  Bevilacqua", "title": "Designing Deep Reinforcement Learning for Human Parameter Exploration", "comments": "Author's version of the work. The definitive Version of Record was\n  published in ACM Transactions on Computer-Human Interaction (TOCHI)", "journal-ref": "ACM Trans. Comput.-Hum. Interact. 28, 1, Article 1 (January 2021),\n  35 pages (2021)", "doi": "10.1145/3414472", "report-no": null, "categories": "cs.HC cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Software tools for generating digital sound often present users with\nhigh-dimensional, parametric interfaces, that may not facilitate exploration of\ndiverse sound designs. In this paper, we propose to investigate artificial\nagents using deep reinforcement learning to explore parameter spaces in\npartnership with users for sound design. We describe a series of user-centred\nstudies to probe the creative benefits of these agents and adapting their\ndesign to exploration. Preliminary studies observing users' exploration\nstrategies with parametric interfaces and testing different agent exploration\nbehaviours led to the design of a fully-functioning prototype, called\nCo-Explorer, that we evaluated in a workshop with professional sound designers.\nWe found that the Co-Explorer enables a novel creative workflow centred on\nhuman-machine partnership, which has been positively received by practitioners.\nWe also highlight varied user exploration behaviors throughout partnering with\nour system. Finally, we frame design guidelines for enabling such\nco-exploration workflow in creative digital applications.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jul 2019 14:32:47 GMT"}, {"version": "v2", "created": "Thu, 28 Jan 2021 11:50:04 GMT"}], "update_date": "2021-01-29", "authors_parsed": [["Scurto", "Hugo", ""], ["Van Kerrebroeck", "Bavo", ""], ["Caramiaux", "Baptiste", ""], ["Bevilacqua", "Fr\u00e9d\u00e9ric", ""]]}, {"id": "1907.00825", "submitter": "H{\\aa}vard Kvamme", "authors": "H{\\aa}vard Kvamme, {\\O}rnulf Borgan, Ida Scheel", "title": "Time-to-Event Prediction with Neural Networks and Cox Regression", "comments": null, "journal-ref": "Journal of Machine Learning Research, 20(129):1-30, 2019", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  New methods for time-to-event prediction are proposed by extending the Cox\nproportional hazards model with neural networks. Building on methodology from\nnested case-control studies, we propose a loss function that scales well to\nlarge data sets, and enables fitting of both proportional and non-proportional\nextensions of the Cox model. Through simulation studies, the proposed loss\nfunction is verified to be a good approximation for the Cox partial\nlog-likelihood. The proposed methodology is compared to existing methodologies\non real-world data sets, and is found to be highly competitive, typically\nyielding the best performance in terms of Brier score and binomial\nlog-likelihood. A python package for the proposed methods is available at\nhttps://github.com/havakv/pycox.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jul 2019 14:34:03 GMT"}, {"version": "v2", "created": "Fri, 13 Sep 2019 10:32:24 GMT"}], "update_date": "2019-09-16", "authors_parsed": [["Kvamme", "H\u00e5vard", ""], ["Borgan", "\u00d8rnulf", ""], ["Scheel", "Ida", ""]]}, {"id": "1907.00831", "submitter": "Young-chul Yoon", "authors": "Young-Chul Yoon, Du Yong Kim, Young-min Song, Kwangjin Yoon and Moongu\n  Jeon", "title": "Online Multiple Pedestrians Tracking using Deep Temporal Appearance\n  Matching Association", "comments": "Accepted in Information Sciences, Elsevier. 3rd Prize on 4th BMTT\n  MOTChallenge Workshop held in CVPR2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In online multi-target tracking, modeling of appearance and geometric\nsimilarities between pedestrians visual scenes is of great importance. The\nhigher dimension of inherent information in the appearance model compared to\nthe geometric model is problematic in many ways. However, due to the recent\nsuccess of deep-learning-based methods, handling of high-dimensional appearance\ninformation becomes feasible. Among many deep neural networks, Siamese network\nwith triplet loss has been widely adopted as an effective appearance feature\nextractor. Since the Siamese network can extract the features of each input\nindependently, one can update and maintain target-specific features. However,\nit is not suitable for multi-target settings that require comparison with other\ninputs. To address this issue, we propose a novel track appearance model based\non the joint-inference network. The proposed method enables a comparison of two\ninputs to be used for adaptive appearance modeling and contributes to the\ndisambiguation of target-observation matching and to the consolidation of\nidentity consistency. Diverse experimental results support the effectiveness of\nour method. Our work was recognized as the 3rd-best tracker in BMTT\nMOTChallenge 2019, held at CVPR2019. The code is available at\nhttps://github.com/yyc9268/Deep-TAMA.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jul 2019 14:44:41 GMT"}, {"version": "v2", "created": "Sat, 23 Nov 2019 19:12:15 GMT"}, {"version": "v3", "created": "Wed, 4 Mar 2020 17:29:37 GMT"}, {"version": "v4", "created": "Fri, 9 Oct 2020 14:32:42 GMT"}], "update_date": "2020-10-12", "authors_parsed": [["Yoon", "Young-Chul", ""], ["Kim", "Du Yong", ""], ["Song", "Young-min", ""], ["Yoon", "Kwangjin", ""], ["Jeon", "Moongu", ""]]}, {"id": "1907.00832", "submitter": "Xing Gao", "authors": "Xing Gao, Hongkai Xiong, Pascal Frossard", "title": "iPool -- Information-based Pooling in Hierarchical Graph Neural Networks", "comments": "Typos corrected and one reference added", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the advent of data science, the analysis of network or graph data has\nbecome a very timely research problem. A variety of recent works have been\nproposed to generalize neural networks to graphs, either from a spectral graph\ntheory or a spatial perspective. The majority of these works however focus on\nadapting the convolution operator to graph representation. At the same time,\nthe pooling operator also plays an important role in distilling multiscale and\nhierarchical representations but it has been mostly overlooked so far. In this\npaper, we propose a parameter-free pooling operator, called iPool, that permits\nto retain the most informative features in arbitrary graphs. With the argument\nthat informative nodes dominantly characterize graph signals, we propose a\ncriterion to evaluate the amount of information of each node given its\nneighbors, and theoretically demonstrate its relationship to neighborhood\nconditional entropy. This new criterion determines how nodes are selected and\ncoarsened graphs are constructed in the pooling layer. The resulting\nhierarchical structure yields an effective isomorphism-invariant representation\nof networked data in arbitrary topologies. The proposed strategy is evaluated\nin terms of graph classification on a collection of public graph datasets,\nincluding bioinformatics and social networks, and achieves state-of-the-art\nperformance on most of the datasets.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jul 2019 14:48:49 GMT"}, {"version": "v2", "created": "Wed, 11 Dec 2019 06:55:29 GMT"}], "update_date": "2019-12-12", "authors_parsed": [["Gao", "Xing", ""], ["Xiong", "Hongkai", ""], ["Frossard", "Pascal", ""]]}, {"id": "1907.00865", "submitter": "Sebastian Farquhar", "authors": "Sebastian Farquhar, Michael Osborne, Yarin Gal", "title": "Radial Bayesian Neural Networks: Beyond Discrete Support In Large-Scale\n  Bayesian Deep Learning", "comments": null, "journal-ref": "AI Stats, PMLR 108:1352-1362, 2020", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose Radial Bayesian Neural Networks (BNNs): a variational approximate\nposterior for BNNs which scales well to large models while maintaining a\ndistribution over weight-space with full support. Other scalable Bayesian deep\nlearning methods, like MC dropout or deep ensembles, have discrete support-they\nassign zero probability to almost all of the weight-space. Unlike these\ndiscrete support methods, Radial BNNs' full support makes them suitable for use\nas a prior for sequential inference. In addition, they solve the conceptual\nchallenges with the a priori implausibility of weight distributions with\ndiscrete support. The Radial BNN is motivated by avoiding a sampling problem in\n'mean-field' variational inference (MFVI) caused by the so-called 'soap-bubble'\npathology of multivariate Gaussians. We show that, unlike MFVI, Radial BNNs are\nrobust to hyperparameters and can be efficiently applied to a challenging\nreal-world medical application without needing ad-hoc tweaks and intensive\ntuning. In fact, in this setting Radial BNNs out-perform discrete-support\nmethods like MC dropout. Lastly, by using Radial BNNs as a theoretically\nprincipled, robust alternative to MFVI we make significant strides in a\nBayesian continual learning evaluation.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jul 2019 15:25:50 GMT"}, {"version": "v2", "created": "Tue, 15 Oct 2019 09:22:38 GMT"}, {"version": "v3", "created": "Tue, 7 Apr 2020 10:38:39 GMT"}, {"version": "v4", "created": "Mon, 31 May 2021 11:12:44 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Farquhar", "Sebastian", ""], ["Osborne", "Michael", ""], ["Gal", "Yarin", ""]]}, {"id": "1907.00868", "submitter": "Lucas Beyer", "authors": "Lucas Beyer, Damien Vincent, Olivier Teboul, Sylvain Gelly, Matthieu\n  Geist, Olivier Pietquin", "title": "MULEX: Disentangling Exploitation from Exploration in Deep RL", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  An agent learning through interactions should balance its action selection\nprocess between probing the environment to discover new rewards and using the\ninformation acquired in the past to adopt useful behaviour. This trade-off is\nusually obtained by perturbing either the agent's actions (e.g., e-greedy or\nGibbs sampling) or the agent's parameters (e.g., NoisyNet), or by modifying the\nreward it receives (e.g., exploration bonus, intrinsic motivation, or\nhand-shaped rewards). Here, we adopt a disruptive but simple and generic\nperspective, where we explicitly disentangle exploration and exploitation.\nDifferent losses are optimized in parallel, one of them coming from the true\nobjective (maximizing cumulative rewards from the environment) and others being\nrelated to exploration. Every loss is used in turn to learn a policy that\ngenerates transitions, all shared in a single replay buffer. Off-policy methods\nare then applied to these transitions to optimize each loss. We showcase our\napproach on a hard-exploration environment, show its sample-efficiency and\nrobustness, and discuss further implications.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jul 2019 15:28:02 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Beyer", "Lucas", ""], ["Vincent", "Damien", ""], ["Teboul", "Olivier", ""], ["Gelly", "Sylvain", ""], ["Geist", "Matthieu", ""], ["Pietquin", "Olivier", ""]]}, {"id": "1907.00873", "submitter": "Bowen Shi", "authors": "Bowen Shi, Ming Sun, Chieh-Chi Kao, Viktor Rozgic, Spyros Matsoukas,\n  Chao Wang", "title": "Compression of Acoustic Event Detection Models With Quantized\n  Distillation", "comments": "Interspeech 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Acoustic Event Detection (AED), aiming at detecting categories of events\nbased on audio signals, has found application in many intelligent systems.\nRecently deep neural network significantly advances this field and reduces\ndetection errors to a large scale. However how to efficiently execute deep\nmodels in AED has received much less attention. Meanwhile state-of-the-art AED\nmodels are based on large deep models, which are computational demanding and\nchallenging to deploy on devices with constrained computational resources. In\nthis paper, we present a simple yet effective compression approach which\njointly leverages knowledge distillation and quantization to compress larger\nnetwork (teacher model) into compact network (student model). Experimental\nresults show proposed technique not only lowers error rate of original compact\nnetwork by 15% through distillation but also further reduces its model size to\na large extent (2% of teacher, 12% of full-precision student) through\nquantization.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jul 2019 15:37:52 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Shi", "Bowen", ""], ["Sun", "Ming", ""], ["Kao", "Chieh-Chi", ""], ["Rozgic", "Viktor", ""], ["Matsoukas", "Spyros", ""], ["Wang", "Chao", ""]]}, {"id": "1907.00874", "submitter": "Linara Adilova", "authors": "Linara Adilova, Livin Natious, Siming Chen, Olivier Thonnard, and\n  Michael Kamp", "title": "System Misuse Detection via Informed Behavior Clustering and Modeling", "comments": "9 pages including appendix, DSN Workshop on Data-Centric\n  Dependability and Security (http://dcds.lasige.di.fc.ul.pt/)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the main tasks of cybersecurity is recognizing malicious interactions\nwith an arbitrary system. Currently, the logging information from each\ninteraction can be collected in almost unrestricted amounts, but identification\nof attacks requires a lot of effort and time of security experts. We propose an\napproach for identifying fraud activity through modeling normal behavior in\ninteractions with a system via machine learning methods, in particular LSTM\nneural networks. In order to enrich the modeling with system specific\nknowledge, we propose to use an interactive visual interface that allows\nsecurity experts to identify semantically meaningful clusters of interactions.\nThese clusters incorporate domain knowledge and lead to more precise behavior\nmodeling via informed machine learning. We evaluate the proposed approach on a\ndataset containing logs of interactions with an administrative interface of\nlogin and security server. Our empirical results indicate that the informed\nmodeling is capable of capturing normal behavior, which can then be used to\ndetect abnormal behavior.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jul 2019 15:38:39 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Adilova", "Linara", ""], ["Natious", "Livin", ""], ["Chen", "Siming", ""], ["Thonnard", "Olivier", ""], ["Kamp", "Michael", ""]]}, {"id": "1907.00878", "submitter": "Jan Niclas Reimann", "authors": "Jan Niclas Reimann, Andreas Schwung", "title": "Neural Logic Rule Layers", "comments": null, "journal-ref": null, "doi": "10.13140/RG.2.2.10091.59687", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Despite their great success in recent years, deep neural networks (DNN) are\nmainly black boxes where the results obtained by running through the network\nare difficult to understand and interpret. Compared to e.g. decision trees or\nbayesian classifiers, DNN suffer from bad interpretability where we understand\nby interpretability, that a human can easily derive the relations modeled by\nthe network. A reasonable way to provide interpretability for humans are\nlogical rules. In this paper we propose neural logic rule layers (NLRL) which\nare able to represent arbitrary logic rules in terms of their conjunctive and\ndisjunctive normal forms. Using various NLRL within one layer and\ncorrespondingly stacking various layers, we are able to represent arbitrary\ncomplex rules by the resulting neural network architecture. The NLRL are\nend-to-end trainable allowing to learn logic rules directly from available data\nsets. Experiments show that NLRL-enhanced neural networks can learn to model\narbitrary complex logic and perform arithmetic operation over the input values.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jul 2019 15:49:06 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Reimann", "Jan Niclas", ""], ["Schwung", "Andreas", ""]]}, {"id": "1907.00884", "submitter": "Nicholas Denis", "authors": "Nick Denis", "title": "On mechanisms for transfer using landmark value functions in multi-task\n  lifelong reinforcement learning", "comments": "12 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transfer learning across different reinforcement learning (RL) tasks is\nbecoming an increasingly valuable area of research. We consider a goal-based\nmulti-task RL framework and mechanisms by which previously solved tasks can\nreduce sample complexity and regret when the agent is faced with a new task.\nSpecifically, we introduce two metrics on the state space that encode notions\nof traversibility of the state space for an agent. Using these metrics a\ntopological covering is constructed by way of a set of landmark states in a\nfully self-supervised manner. We show that these landmark coverings confer\ntheoretical advantages for transfer learning within the goal-based multi-task\nRL setting. Specifically, we demonstrate three mechanisms by which landmark\ncoverings can be used for successful transfer learning. First, we extend the\nLandmark Options Via Reflection (LOVR) framework to this new topological\ncovering; second, we use the landmark-centric value functions themselves as\nfeatures and define a greedy zombie policy that achieves near oracle\nperformance on a sequence of zero-shot transfer tasks; finally, motivated by\nthe second transfer mechanism, we introduce a learned reward function that\nprovides a more dense reward signal for goal-based RL. Our novel topological\nlandmark covering confers beneficial theoretical results, bounding the Q values\nat each state-action pair. In doing so, we introduce a mechanism that performs\naction-pruning at infeasible actions which cannot possibly be part of an\noptimal policy for the current goal.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jul 2019 15:56:24 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Denis", "Nick", ""]]}, {"id": "1907.00895", "submitter": "Roland S. Zimmermann", "authors": "Roland S. Zimmermann", "title": "Comment on \"Adv-BNN: Improved Adversarial Defense through Robust\n  Bayesian Neural Network\"", "comments": "3 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A recent paper by Liu et al. combines the topics of adversarial training and\nBayesian Neural Networks (BNN) and suggests that adversarially trained BNNs are\nmore robust against adversarial attacks than their non-Bayesian counterparts.\nHere, I analyze the proposed defense and suggest that one needs to adjust the\nadversarial attack to incorporate the stochastic nature of a Bayesian network\nto perform an accurate evaluation of its robustness. Using this new type of\nattack I show that there appears to be no strong evidence for higher robustness\nof the adversarially trained BNNs.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jul 2019 16:11:28 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Zimmermann", "Roland S.", ""]]}, {"id": "1907.00909", "submitter": "Pieter Gijsbers", "authors": "Pieter Gijsbers, Erin LeDell, Janek Thomas, S\\'ebastien Poirier, Bernd\n  Bischl, Joaquin Vanschoren", "title": "An Open Source AutoML Benchmark", "comments": "Accepted paper at the AutoML Workshop at ICML 2019. Code:\n  https://github.com/openml/automlbenchmark/ Accompanying website:\n  https://openml.github.io/automlbenchmark/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, an active field of research has developed around automated\nmachine learning (AutoML). Unfortunately, comparing different AutoML systems is\nhard and often done incorrectly. We introduce an open, ongoing, and extensible\nbenchmark framework which follows best practices and avoids common mistakes.\nThe framework is open-source, uses public datasets and has a website with\nup-to-date results. We use the framework to conduct a thorough comparison of 4\nAutoML systems across 39 datasets and analyze the results.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jul 2019 16:28:11 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Gijsbers", "Pieter", ""], ["LeDell", "Erin", ""], ["Thomas", "Janek", ""], ["Poirier", "S\u00e9bastien", ""], ["Bischl", "Bernd", ""], ["Vanschoren", "Joaquin", ""]]}, {"id": "1907.00921", "submitter": "Kalesha Bullard", "authors": "Kalesha Bullard, Yannick Schroecker, Sonia Chernova", "title": "Active Learning within Constrained Environments through Imitation of an\n  Expert Questioner", "comments": "In Conference Proceedings for IJCAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Active learning agents typically employ a query selection algorithm which\nsolely considers the agent's learning objectives. However, this may be\ninsufficient in more realistic human domains. This work uses imitation learning\nto enable an agent in a constrained environment to concurrently reason about\nboth its internal learning goals and environmental constraints externally\nimposed, all within its objective function. Experiments are conducted on a\nconcept learning task to test generalization of the proposed algorithm to\ndifferent environmental conditions and analyze how time and resource\nconstraints impact efficacy of solving the learning problem. Our findings show\nthe environmentally-aware learning agent is able to statistically outperform\nall other active learners explored under most of the constrained conditions. A\nkey implication is adaptation for active learning agents to more realistic\nhuman environments, where constraints are often externally imposed on the\nlearner.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jul 2019 16:53:47 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Bullard", "Kalesha", ""], ["Schroecker", "Yannick", ""], ["Chernova", "Sonia", ""]]}, {"id": "1907.00924", "submitter": "Giorgia Franchini", "authors": "Giorgia Franchini, Mathilde Galinier, Micaela Verucchi", "title": "Mise en abyme with artificial intelligence: how to predict the accuracy\n  of NN, applied to hyper-parameter tuning", "comments": "The research leading to these results has received funding from the\n  European Union's Horizon 2020 Programme under the CLASS Project\n  (https://class-project.eu/), grant agreement n 780622", "journal-ref": "INNS Big Data and Deep Learning conference, 286-295, Springer,\n  2018", "doi": "10.1007/978-3-030-16841-4_30", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the context of deep learning, the costliest phase from a computational\npoint of view is the full training of the learning algorithm. However, this\nprocess is to be used a significant number of times during the design of a new\nartificial neural network, leading therefore to extremely expensive operations.\nHere, we propose a low-cost strategy to predict the accuracy of the algorithm,\nbased only on its initial behaviour. To do so, we train the network of interest\nup to convergence several times, modifying its characteristics at each\ntraining. The initial and final accuracies observed during this beforehand\nprocess are stored in a database. We then make use of both curve fitting and\nSupport Vector Machines techniques, the latter being trained on the created\ndatabase, to predict the accuracy of the network, given its accuracy on the\nprimary iterations of its learning. This approach can be of particular interest\nwhen the space of the characteristics of the network is notably large or when\nits full training is highly time-consuming. The results we obtained are\npromising and encouraged us to apply this strategy to a topical issue:\nhyper-parameter optimisation (HO). In particular, we focused on the HO of a\nconvolutional neural network for the classification of the databases MNIST and\nCIFAR-10. By using our method of prediction, and an algorithm implemented by us\nfor a probabilistic exploration of the hyper-parameter space, we were able to\nfind the hyper-parameter settings corresponding to the optimal accuracies\nalready known in literature, at a quite low-cost.\n", "versions": [{"version": "v1", "created": "Fri, 28 Jun 2019 14:38:39 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Franchini", "Giorgia", ""], ["Galinier", "Mathilde", ""], ["Verucchi", "Micaela", ""]]}, {"id": "1907.00927", "submitter": "Adarsh Prasad", "authors": "Adarsh Prasad, Sivaraman Balakrishnan, Pradeep Ravikumar", "title": "A Unified Approach to Robust Mean Estimation", "comments": "51 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we develop connections between two seemingly disparate, but\ncentral, models in robust statistics: Huber's epsilon-contamination model and\nthe heavy-tailed noise model. We provide conditions under which this connection\nprovides near-statistically-optimal estimators. Building on this connection, we\nprovide a simple variant of recent computationally-efficient algorithms for\nmean estimation in Huber's model, which given our connection entails that the\nsame efficient sample-pruning based estimators is simultaneously robust to\nheavy-tailed noise and Huber contamination. Furthermore, we complement our\nefficient algorithms with statistically-optimal albeit computationally\nintractable estimators, which are simultaneously optimally robust in both\nmodels. We study the empirical performance of our proposed estimators on\nsynthetic datasets, and find that our methods convincingly outperform a variety\nof practical baselines.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jul 2019 17:03:11 GMT"}], "update_date": "2019-07-03", "authors_parsed": [["Prasad", "Adarsh", ""], ["Balakrishnan", "Sivaraman", ""], ["Ravikumar", "Pradeep", ""]]}, {"id": "1907.00932", "submitter": "Guido Muscioni", "authors": "Guido Muscioni, Riccardo Pressiani, Matteo Foglio, Margaret C.\n  Crofoot, Marco D. Santambrogio and Tanya Berger-Wolf", "title": "A Framework For Identifying Group Behavior Of Wild Animals", "comments": "KDD19 Workshop on Data Mining and AI for Conservation, Earth Day (5\n  August 2019), Anchorage, AL", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Activity recognition and, more generally, behavior inference tasks are\ngaining a lot of interest. Much of it is work in the context of human behavior.\nNew available tracking technologies for wild animals are generating datasets\nthat indirectly may provide information about animal behavior. In this work, we\npropose a method for classifying these data into behavioral annotation,\nparticularly collective behavior of a social group. Our method is based on\nsequence analysis with a direct encoding of the interactions of a group of wild\nanimals. We evaluate our approach on a real world dataset, showing significant\naccuracy improvements over baseline methods.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jul 2019 17:12:32 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Muscioni", "Guido", ""], ["Pressiani", "Riccardo", ""], ["Foglio", "Matteo", ""], ["Crofoot", "Margaret C.", ""], ["Santambrogio", "Marco D.", ""], ["Berger-Wolf", "Tanya", ""]]}, {"id": "1907.00941", "submitter": "Yi Liu", "authors": "Yi Liu, Hao Yuan, Zhengyang Wang, Shuiwang Ji", "title": "Global Pixel Transformers for Virtual Staining of Microscopy Images", "comments": "10 pages, 6 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Visualizing the details of different cellular structures is of great\nimportance to elucidate cellular functions. However, it is challenging to\nobtain high quality images of different structures directly due to complex\ncellular environments. Fluorescence staining is a popular technique to label\ndifferent structures but has several drawbacks. In particular, label staining\nis time consuming and may affect cell morphology, and simultaneous labels are\ninherently limited. This raises the need of building computational models to\nlearn relationships between unlabeled microscopy images and labeled\nfluorescence images, and to infer fluorescence labels of other microscopy\nimages excluding the physical staining process. We propose to develop a novel\ndeep model for virtual staining of unlabeled microscopy images. We first\npropose a novel network layer, known as the global pixel transformer layer,\nthat fuses global information from inputs effectively. The proposed global\npixel transformer layer can generate outputs with arbitrary dimensions, and can\nbe employed for all the regular, down-sampling, and up-sampling operators. We\nthen incorporate our proposed global pixel transformer layers and dense blocks\nto build an U-Net like network. We believe such a design can promote feature\nreusing between layers. In addition, we propose a multi-scale input strategy to\nencourage networks to capture features at different scales. We conduct\nevaluations across various fluorescence image prediction tasks to demonstrate\nthe effectiveness of our approach. Both quantitative and qualitative results\nshow that our method outperforms the state-of-the-art approach significantly.\nIt is also shown that our proposed global pixel transformer layer is useful to\nimprove the fluorescence image prediction results.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jul 2019 17:28:08 GMT"}, {"version": "v2", "created": "Tue, 2 Jul 2019 02:42:32 GMT"}, {"version": "v3", "created": "Mon, 30 Sep 2019 16:13:19 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Liu", "Yi", ""], ["Yuan", "Hao", ""], ["Wang", "Zhengyang", ""], ["Ji", "Shuiwang", ""]]}, {"id": "1907.00953", "submitter": "Alex Lee", "authors": "Alex X. Lee, Anusha Nagabandi, Pieter Abbeel, Sergey Levine", "title": "Stochastic Latent Actor-Critic: Deep Reinforcement Learning with a\n  Latent Variable Model", "comments": "Project website: https://alexlee-gk.github.io/slac/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning (RL) algorithms can use high-capacity deep\nnetworks to learn directly from image observations. However, these\nhigh-dimensional observation spaces present a number of challenges in practice,\nsince the policy must now solve two problems: representation learning and task\nlearning. In this work, we tackle these two problems separately, by explicitly\nlearning latent representations that can accelerate reinforcement learning from\nimages. We propose the stochastic latent actor-critic (SLAC) algorithm: a\nsample-efficient and high-performing RL algorithm for learning policies for\ncomplex continuous control tasks directly from high-dimensional image inputs.\nSLAC provides a novel and principled approach for unifying stochastic\nsequential models and RL into a single method, by learning a compact latent\nrepresentation and then performing RL in the model's learned latent space. Our\nexperimental evaluation demonstrates that our method outperforms both\nmodel-free and model-based alternatives in terms of final performance and\nsample efficiency, on a range of difficult image-based control tasks. Our code\nand videos of our results are available at our website.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jul 2019 17:45:09 GMT"}, {"version": "v2", "created": "Mon, 3 Feb 2020 15:07:43 GMT"}, {"version": "v3", "created": "Tue, 11 Aug 2020 16:02:04 GMT"}, {"version": "v4", "created": "Mon, 26 Oct 2020 12:21:51 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Lee", "Alex X.", ""], ["Nagabandi", "Anusha", ""], ["Abbeel", "Pieter", ""], ["Levine", "Sergey", ""]]}, {"id": "1907.00959", "submitter": "Dimitrios Stamoulis", "authors": "Dimitrios Stamoulis, Ruizhou Ding, Di Wang, Dimitrios Lymberopoulos,\n  Bodhi Priyantha, Jie Liu, Diana Marculescu", "title": "Single-Path Mobile AutoML: Efficient ConvNet Design and NAS\n  Hyperparameter Optimization", "comments": "Detailed extension (journal) of the Single-Path NAS ECMLPKDD'19 paper\n  (arXiv:1904.02877)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Can we reduce the search cost of Neural Architecture Search (NAS) from days\ndown to only few hours? NAS methods automate the design of Convolutional\nNetworks (ConvNets) under hardware constraints and they have emerged as key\ncomponents of AutoML frameworks. However, the NAS problem remains challenging\ndue to the combinatorially large design space and the significant search time\n(at least 200 GPU-hours). In this work, we alleviate the NAS search cost down\nto less than 3 hours, while achieving state-of-the-art image classification\nresults under mobile latency constraints. We propose a novel differentiable NAS\nformulation, namely Single-Path NAS, that uses one single-path\nover-parameterized ConvNet to encode all architectural decisions based on\nshared convolutional kernel parameters, hence drastically decreasing the search\noverhead. Single-Path NAS achieves state-of-the-art top-1 ImageNet accuracy\n(75.62%), hence outperforming existing mobile NAS methods in similar latency\nsettings (~80ms). In particular, we enhance the accuracy-runtime trade-off in\ndifferentiable NAS by treating the Squeeze-and-Excitation path as a fully\nsearchable operation with our novel single-path encoding. Our method has an\noverall cost of only 8 epochs (24 TPU-hours), which is up to 5,000x faster\ncompared to prior work. Moreover, we study how different NAS formulation\nchoices affect the performance of the designed ConvNets. Furthermore, we\nexploit the efficiency of our method to answer an interesting question: instead\nof empirically tuning the hyperparameters of the NAS solver (as in prior work),\ncan we automatically find the hyperparameter values that yield the desired\naccuracy-runtime trade-off? We open-source our entire codebase at:\nhttps://github.com/dstamoulis/single-path-nas.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jul 2019 17:52:55 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Stamoulis", "Dimitrios", ""], ["Ding", "Ruizhou", ""], ["Wang", "Di", ""], ["Lymberopoulos", "Dimitrios", ""], ["Priyantha", "Bodhi", ""], ["Liu", "Jie", ""], ["Marculescu", "Diana", ""]]}, {"id": "1907.00971", "submitter": "Philippe Esling", "authors": "Philippe Esling, Naotake Masuda, Adrien Bardet, Romeo Despres, Axel\n  Chemla--Romeu-Santos", "title": "Universal audio synthesizer control with normalizing flows", "comments": "DaFX 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.HC cs.MM cs.SD eess.AS stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The ubiquity of sound synthesizers has reshaped music production and even\nentirely defined new music genres. However, the increasing complexity and\nnumber of parameters in modern synthesizers make them harder to master. Hence,\nthe development of methods allowing to easily create and explore with\nsynthesizers is a crucial need. Here, we introduce a novel formulation of audio\nsynthesizer control. We formalize it as finding an organized latent audio space\nthat represents the capabilities of a synthesizer, while constructing an\ninvertible mapping to the space of its parameters. By using this formulation,\nwe show that we can address simultaneously automatic parameter inference,\nmacro-control learning and audio-based preset exploration within a single\nmodel. To solve this new formulation, we rely on Variational Auto-Encoders\n(VAE) and Normalizing Flows (NF) to organize and map the respective auditory\nand parameter spaces. We introduce the disentangling flows, which allow to\nperform the invertible mapping between separate latent spaces, while steering\nthe organization of some latent dimensions to match target variation factors by\nsplitting the objective as partial density evaluation. We evaluate our proposal\nagainst a large set of baseline models and show its superiority in both\nparameter inference and audio reconstruction. We also show that the model\ndisentangles the major factors of audio variations as latent dimensions, that\ncan be directly used as macro-parameters. We also show that our model is able\nto learn semantic controls of a synthesizer by smoothly mapping to its\nparameters. Finally, we discuss the use of our model in creative applications\nand its real-time implementation in Ableton Live\n", "versions": [{"version": "v1", "created": "Mon, 1 Jul 2019 14:49:07 GMT"}], "update_date": "2019-07-03", "authors_parsed": [["Esling", "Philippe", ""], ["Masuda", "Naotake", ""], ["Bardet", "Adrien", ""], ["Despres", "Romeo", ""], ["Chemla--Romeu-Santos", "Axel", ""]]}, {"id": "1907.00973", "submitter": "Ivan Ezhov", "authors": "Ivan Ezhov, Jana Lipkova, Suprosanna Shit, Florian Kofler, Nore\n  Collomb, Benjamin Lemasson, Emmanuel Barbier, Bjoern Menze", "title": "Neural parameters estimation for brain tumor growth modeling", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-030-32245-8_87", "report-no": null, "categories": "q-bio.QM cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding the dynamics of brain tumor progression is essential for\noptimal treatment planning. Cast in a mathematical formulation, it is typically\nviewed as evaluation of a system of partial differential equations, wherein the\nphysiological processes that govern the growth of the tumor are considered. To\npersonalize the model, i.e. find a relevant set of parameters, with respect to\nthe tumor dynamics of a particular patient, the model is informed from\nempirical data, e.g., medical images obtained from diagnostic modalities, such\nas magnetic-resonance imaging. Existing model-observation coupling schemes\nrequire a large number of forward integrations of the biophysical model and\nrely on simplifying assumption on the functional form, linking the output of\nthe model with the image information. In this work, we propose a learning-based\ntechnique for the estimation of tumor growth model parameters from medical\nscans. The technique allows for explicit evaluation of the posterior\ndistribution of the parameters by sequentially training a mixture-density\nnetwork, relaxing the constraint on the functional form and reducing the number\nof samples necessary to propagate through the forward model for the estimation.\nWe test the method on synthetic and real scans of rats injected with brain\ntumors to calibrate the model and to predict tumor progression.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jul 2019 17:57:14 GMT"}, {"version": "v2", "created": "Thu, 9 Jan 2020 19:04:45 GMT"}], "update_date": "2020-01-13", "authors_parsed": [["Ezhov", "Ivan", ""], ["Lipkova", "Jana", ""], ["Shit", "Suprosanna", ""], ["Kofler", "Florian", ""], ["Collomb", "Nore", ""], ["Lemasson", "Benjamin", ""], ["Barbier", "Emmanuel", ""], ["Menze", "Bjoern", ""]]}, {"id": "1907.01003", "submitter": "Wieland Brendel", "authors": "Wieland Brendel, Jonas Rauber, Matthias K\\\"ummerer, Ivan\n  Ustyuzhaninov, Matthias Bethge", "title": "Accurate, reliable and fast robustness evaluation", "comments": "Accepted at the 2019 Conference on Neural Information Processing\n  Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CR cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Throughout the past five years, the susceptibility of neural networks to\nminimal adversarial perturbations has moved from a peculiar phenomenon to a\ncore issue in Deep Learning. Despite much attention, however, progress towards\nmore robust models is significantly impaired by the difficulty of evaluating\nthe robustness of neural network models. Today's methods are either fast but\nbrittle (gradient-based attacks), or they are fairly reliable but slow (score-\nand decision-based attacks). We here develop a new set of gradient-based\nadversarial attacks which (a) are more reliable in the face of gradient-masking\nthan other gradient-based attacks, (b) perform better and are more query\nefficient than current state-of-the-art gradient-based attacks, (c) can be\nflexibly adapted to a wide range of adversarial criteria and (d) require\nvirtually no hyperparameter tuning. These findings are carefully validated\nacross a diverse set of six different models and hold for L0, L1, L2 and Linf\nin both targeted as well as untargeted scenarios. Implementations will soon be\navailable in all major toolboxes (Foolbox, CleverHans and ART). We hope that\nthis class of attacks will make robustness evaluations easier and more\nreliable, thus contributing to more signal in the search for more robust\nmachine learning models.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jul 2019 18:18:10 GMT"}, {"version": "v2", "created": "Thu, 12 Dec 2019 18:32:51 GMT"}], "update_date": "2019-12-13", "authors_parsed": [["Brendel", "Wieland", ""], ["Rauber", "Jonas", ""], ["K\u00fcmmerer", "Matthias", ""], ["Ustyuzhaninov", "Ivan", ""], ["Bethge", "Matthias", ""]]}, {"id": "1907.01011", "submitter": "Zhun Liu", "authors": "Paul Pu Liang, Zhun Liu, Yao-Hung Hubert Tsai, Qibin Zhao, Ruslan\n  Salakhutdinov, Louis-Philippe Morency", "title": "Learning Representations from Imperfect Time Series Data via Tensor Rank\n  Regularization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There has been an increased interest in multimodal language processing\nincluding multimodal dialog, question answering, sentiment analysis, and speech\nrecognition. However, naturally occurring multimodal data is often imperfect as\na result of imperfect modalities, missing entries or noise corruption. To\naddress these concerns, we present a regularization method based on tensor rank\nminimization. Our method is based on the observation that high-dimensional\nmultimodal time series data often exhibit correlations across time and\nmodalities which leads to low-rank tensor representations. However, the\npresence of noise or incomplete values breaks these correlations and results in\ntensor representations of higher rank. We design a model to learn such tensor\nrepresentations and effectively regularize their rank. Experiments on\nmultimodal language data show that our model achieves good results across\nvarious levels of imperfection.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jul 2019 18:40:52 GMT"}], "update_date": "2019-07-03", "authors_parsed": [["Liang", "Paul Pu", ""], ["Liu", "Zhun", ""], ["Tsai", "Yao-Hung Hubert", ""], ["Zhao", "Qibin", ""], ["Salakhutdinov", "Ruslan", ""], ["Morency", "Louis-Philippe", ""]]}, {"id": "1907.01022", "submitter": "Yunlong Wang", "authors": "Kezi Yu, Yunlong Wang, Yong Cai, Cao Xiao, Emily Zhao, Lucas Glass,\n  Jimeng Sun", "title": "Rare Disease Detection by Sequence Modeling with Generative Adversarial\n  Networks", "comments": "International Conference on Machine Learning (ICML) 2019 time series\n  workshop accepted paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rare diseases affecting 350 million individuals are commonly associated with\ndelay in diagnosis or misdiagnosis. To improve those patients' outcome, rare\ndisease detection is an important task for identifying patients with rare\nconditions based on longitudinal medical claims. In this paper, we present a\ndeep learning method for detecting patients with exocrine pancreatic\ninsufficiency (EPI) (a rare disease). The contribution includes 1) a large\nlongitudinal study using 7 years medical claims from 1.8 million patients\nincluding 29,149 EPI patients, 2) a new deep learning model using generative\nadversarial networks (GANs) to boost rare disease class, and also leveraging\nrecurrent neural networks to model patient sequence data, 3) an accurate\nprediction with 0.56 PR-AUC which outperformed benchmark models in terms of\nprecision and recall.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jul 2019 19:18:31 GMT"}], "update_date": "2019-07-03", "authors_parsed": [["Yu", "Kezi", ""], ["Wang", "Yunlong", ""], ["Cai", "Yong", ""], ["Xiao", "Cao", ""], ["Zhao", "Emily", ""], ["Glass", "Lucas", ""], ["Sun", "Jimeng", ""]]}, {"id": "1907.01023", "submitter": "Nader Asadi", "authors": "Nader Asadi, AmirMohammad Sarfi, Mehrdad Hosseinzadeh, Sahba Tahsini,\n  Mahdi Eftekhari", "title": "Diminishing the Effect of Adversarial Perturbations via Refining Feature\n  Representation", "comments": "Accepted at NeuralIPS 2019 workshop on Safety and Robustness in\n  Decision Making", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks are highly vulnerable to adversarial examples, which\nimposes severe security issues for these state-of-the-art models. Many defense\nmethods have been proposed to mitigate this problem. However, a lot of them\ndepend on modification or additional training of the target model. In this\nwork, we analytically investigate each layer's representation of non-perturbed\nand perturbed images and show the effect of perturbations on each of these\nrepresentations. Accordingly, a method based on whitening coloring transform is\nproposed in order to diminish the misrepresentation of any desirable layer\ncaused by adversaries. Our method can be applied to any layer of any arbitrary\nmodel without the need of any modification or additional training. Due to the\nfact that the full whitening of the layer's representation is not easily\ndifferentiable, our proposed method is superbly robust against white-box\nattacks. Furthermore, we demonstrate the strength of our method against some\nstate-of-the-art black-box attacks.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jul 2019 19:21:22 GMT"}, {"version": "v2", "created": "Tue, 1 Oct 2019 17:43:49 GMT"}], "update_date": "2019-10-02", "authors_parsed": [["Asadi", "Nader", ""], ["Sarfi", "AmirMohammad", ""], ["Hosseinzadeh", "Mehrdad", ""], ["Tahsini", "Sahba", ""], ["Eftekhari", "Mahdi", ""]]}, {"id": "1907.01030", "submitter": "Wei Zhou", "authors": "Eugen Beck, Wei Zhou, Ralf Schl\\\"uter, Hermann Ney", "title": "LSTM Language Models for LVCSR in First-Pass Decoding and\n  Lattice-Rescoring", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  LSTM based language models are an important part of modern LVCSR systems as\nthey significantly improve performance over traditional backoff language\nmodels. Incorporating them efficiently into decoding has been notoriously\ndifficult. In this paper we present an approach based on a combination of\none-pass decoding and lattice rescoring. We perform decoding with the LSTM-LM\nin the first pass but recombine hypothesis that share the last two words,\nafterwards we rescore the resulting lattice. We run our systems on GPGPU\nequipped machines and are able to produce competitive results on the Hub5'00\nand Librispeech evaluation corpora with a runtime better than real-time. In\naddition we shortly investigate the possibility to carry out the full sum over\nall state-sequences belonging to a given word-hypothesis during decoding\nwithout recombination.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jul 2019 19:29:04 GMT"}], "update_date": "2019-07-03", "authors_parsed": [["Beck", "Eugen", ""], ["Zhou", "Wei", ""], ["Schl\u00fcter", "Ralf", ""], ["Ney", "Hermann", ""]]}, {"id": "1907.01040", "submitter": "Niki Kilbertus", "authors": "Niki Kilbertus, Philip J. Ball, Matt J. Kusner, Adrian Weller, Ricardo\n  Silva", "title": "The Sensitivity of Counterfactual Fairness to Unmeasured Confounding", "comments": "published at UAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Causal approaches to fairness have seen substantial recent interest, both\nfrom the machine learning community and from wider parties interested in\nethical prediction algorithms. In no small part, this has been due to the fact\nthat causal models allow one to simultaneously leverage data and expert\nknowledge to remove discriminatory effects from predictions. However, one of\nthe primary assumptions in causal modeling is that you know the causal graph.\nThis introduces a new opportunity for bias, caused by misspecifying the causal\nmodel. One common way for misspecification to occur is via unmeasured\nconfounding: the true causal effect between variables is partially described by\nunobserved quantities. In this work we design tools to assess the sensitivity\nof fairness measures to this confounding for the popular class of non-linear\nadditive noise models (ANMs). Specifically, we give a procedure for computing\nthe maximum difference between two counterfactually fair predictors, where one\nhas become biased due to confounding. For the case of bivariate confounding our\ntechnique can be swiftly computed via a sequence of closed-form updates. For\nmultivariate confounding we give an algorithm that can be efficiently solved\nvia automatic differentiation. We demonstrate our new sensitivity analysis\ntools in real-world fairness scenarios to assess the bias arising from\nconfounding.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jul 2019 19:47:40 GMT"}], "update_date": "2019-08-17", "authors_parsed": [["Kilbertus", "Niki", ""], ["Ball", "Philip J.", ""], ["Kusner", "Matt J.", ""], ["Weller", "Adrian", ""], ["Silva", "Ricardo", ""]]}, {"id": "1907.01041", "submitter": "Lakshay Sharma", "authors": "Lakshay Sharma, Laura Graesser, Nikita Nangia, Utku Evci", "title": "Natural Language Understanding with the Quora Question Pairs Dataset", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper explores the task Natural Language Understanding (NLU) by looking\nat duplicate question detection in the Quora dataset. We conducted extensive\nexploration of the dataset and used various machine learning models, including\nlinear and tree-based models. Our final finding was that a simple Continuous\nBag of Words neural network model had the best performance, outdoing more\ncomplicated recurrent and attention based models. We also conducted error\nanalysis and found some subjectivity in the labeling of the dataset.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jul 2019 19:48:34 GMT"}], "update_date": "2019-07-03", "authors_parsed": [["Sharma", "Lakshay", ""], ["Graesser", "Laura", ""], ["Nangia", "Nikita", ""], ["Evci", "Utku", ""]]}, {"id": "1907.01051", "submitter": "Saurabh Jha", "authors": "Saurabh Jha, Subho S. Banerjee, Timothy Tsai, Siva K. S. Hari, Michael\n  B. Sullivan, Zbigniew T. Kalbarczyk, Stephen W. Keckler, Ravishankar K. Iyer", "title": "ML-based Fault Injection for Autonomous Vehicles: A Case for Bayesian\n  Fault Injection", "comments": "Accepted at 2019 49th Annual IEEE/IFIP International Conference on\n  Dependable Systems and Networks", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The safety and resilience of fully autonomous vehicles (AVs) are of\nsignificant concern, as exemplified by several headline-making accidents. While\nAV development today involves verification, validation, and testing, end-to-end\nassessment of AV systems under accidental faults in realistic driving scenarios\nhas been largely unexplored. This paper presents DriveFI, a machine\nlearning-based fault injection engine, which can mine situations and faults\nthat maximally impact AV safety, as demonstrated on two industry-grade AV\ntechnology stacks (from NVIDIA and Baidu). For example, DriveFI found 561\nsafety-critical faults in less than 4 hours. In comparison, random injection\nexperiments executed over several weeks could not find any safety-critical\nfaults\n", "versions": [{"version": "v1", "created": "Mon, 1 Jul 2019 20:16:26 GMT"}], "update_date": "2019-07-03", "authors_parsed": [["Jha", "Saurabh", ""], ["Banerjee", "Subho S.", ""], ["Tsai", "Timothy", ""], ["Hari", "Siva K. S.", ""], ["Sullivan", "Michael B.", ""], ["Kalbarczyk", "Zbigniew T.", ""], ["Keckler", "Stephen W.", ""], ["Iyer", "Ravishankar K.", ""]]}, {"id": "1907.01055", "submitter": "Zixu Wang", "authors": "Zixu Wang, Julia Ive, Sumithra Velupillai, Lucia Specia", "title": "Is artificial data useful for biomedical Natural Language Processing\n  algorithms?", "comments": "BioNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A major obstacle to the development of Natural Language Processing (NLP)\nmethods in the biomedical domain is data accessibility. This problem can be\naddressed by generating medical data artificially. Most previous studies have\nfocused on the generation of short clinical text, and evaluation of the data\nutility has been limited. We propose a generic methodology to guide the\ngeneration of clinical text with key phrases. We use the artificial data as\nadditional training data in two key biomedical NLP tasks: text classification\nand temporal relation extraction. We show that artificially generated training\ndata used in conjunction with real training data can lead to performance boosts\nfor data-greedy neural network algorithms. We also demonstrate the usefulness\nof the generated data for NLP setups where it fully replaces real training\ndata.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jul 2019 20:17:59 GMT"}, {"version": "v2", "created": "Wed, 7 Aug 2019 19:08:19 GMT"}], "update_date": "2019-08-09", "authors_parsed": [["Wang", "Zixu", ""], ["Ive", "Julia", ""], ["Velupillai", "Sumithra", ""], ["Specia", "Lucia", ""]]}, {"id": "1907.01068", "submitter": "Robert Bamler", "authors": "Robert Bamler, Farnood Salehi, and Stephan Mandt", "title": "Augmenting and Tuning Knowledge Graph Embeddings", "comments": "Published version, Conference on Uncertainty in Artificial\n  Intelligence (UAI 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge graph embeddings rank among the most successful methods for link\nprediction in knowledge graphs, i.e., the task of completing an incomplete\ncollection of relational facts. A downside of these models is their strong\nsensitivity to model hyperparameters, in particular regularizers, which have to\nbe extensively tuned to reach good performance [Kadlec et al., 2017]. We\npropose an efficient method for large scale hyperparameter tuning by\ninterpreting these models in a probabilistic framework. After a model\naugmentation that introduces per-entity hyperparameters, we use a variational\nexpectation-maximization approach to tune thousands of such hyperparameters\nwith minimal additional cost. Our approach is agnostic to details of the model\nand results in a new state of the art in link prediction on standard benchmark\ndata.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jul 2019 20:40:37 GMT"}], "update_date": "2019-07-03", "authors_parsed": [["Bamler", "Robert", ""], ["Salehi", "Farnood", ""], ["Mandt", "Stephan", ""]]}, {"id": "1907.01070", "submitter": "Pedro Braga", "authors": "Pedro H. M. Braga and Hansenclever F. Bassani", "title": "A Semi-Supervised Self-Organizing Map for Clustering and Classification", "comments": null, "journal-ref": "2018 International Joint Conference on Neural Networks (IJCNN)", "doi": "10.1109/IJCNN.2018.8489675", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  There has been an increasing interest in semi-supervised learning in the\nrecent years because of the great number of datasets with a large number of\nunlabeled data but only a few labeled samples. Semi-supervised learning\nalgorithms can work with both types of data, combining them to obtain better\nperformance for both clustering and classification. Also, these datasets\ncommonly have a high number of dimensions. This article presents a new\nsemi-supervised method based on self-organizing maps (SOMs) for clustering and\nclassification, called Semi-Supervised Self-Organizing Map (SS-SOM). The method\ncan dynamically switch between supervised and unsupervised learning during the\ntraining according to the availability of the class labels for each pattern.\nOur results show that the SS-SOM outperforms other semi-supervised methods in\nconditions in which there is a low amount of labeled samples, also achieving\ngood results when all samples are labeled.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jul 2019 20:45:01 GMT"}], "update_date": "2020-03-26", "authors_parsed": [["Braga", "Pedro H. M.", ""], ["Bassani", "Hansenclever F.", ""]]}, {"id": "1907.01085", "submitter": "Srinath Sridhar", "authors": "Srinath Sridhar, Davis Rempe, Julien Valentin, Sofien Bouaziz,\n  Leonidas J. Guibas", "title": "Multiview Aggregation for Learning Category-Specific Shape\n  Reconstruction", "comments": "In Proceedings of Advances in Neural Information Processing Systems\n  (NeurIPS) 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the problem of learning category-specific 3D shape\nreconstruction from a variable number of RGB views of previously unobserved\nobject instances. Most approaches for multiview shape reconstruction operate on\nsparse shape representations, or assume a fixed number of views. We present a\nmethod that can estimate dense 3D shape, and aggregate shape across multiple\nand varying number of input views. Given a single input view of an object\ninstance, we propose a representation that encodes the dense shape of the\nvisible object surface as well as the surface behind line of sight occluded by\nthe visible surface. When multiple input views are available, the shape\nrepresentation is designed to be aggregated into a single 3D shape using an\ninexpensive union operation. We train a 2D CNN to learn to predict this\nrepresentation from a variable number of views (1 or more). We further\naggregate multiview information by using permutation equivariant layers that\npromote order-agnostic view information exchange at the feature level.\nExperiments show that our approach is able to produce dense 3D reconstructions\nof objects that improve in quality as more views are added.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jul 2019 22:01:37 GMT"}, {"version": "v2", "created": "Sun, 8 Dec 2019 22:01:21 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["Sridhar", "Srinath", ""], ["Rempe", "Davis", ""], ["Valentin", "Julien", ""], ["Bouaziz", "Sofien", ""], ["Guibas", "Leonidas J.", ""]]}, {"id": "1907.01086", "submitter": "Pedro Braga", "authors": "Pedro H. M. Braga and Hansenclever F. Bassani", "title": "A Semi-Supervised Self-Organizing Map with Adaptive Local Thresholds", "comments": null, "journal-ref": "2019 International Joint Conference on Neural Networks (IJCNN)", "doi": "10.1109/IJCNN.2019.8851839", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In the recent years, there is a growing interest in semi-supervised learning,\nsince, in many learning tasks, there is a plentiful supply of unlabeled data,\nbut insufficient labeled ones. Hence, Semi-Supervised learning models can\nbenefit from both types of data to improve the obtained performance. Also, it\nis important to develop methods that are easy to parameterize in a way that is\nrobust to the different characteristics of the data at hand. This article\npresents a new method based on Self-Organizing Map (SOM) for clustering and\nclassification, called Adaptive Local Thresholds Semi-Supervised\nSelf-Organizing Map (ALTSS-SOM). It can dynamically switch between two forms of\nlearning at training time, according to the availability of labels, as in\nprevious models, and can automatically adjust itself to the local variance\nobserved in each data cluster. The results show that the ALTSS-SOM surpass the\nperformance of other semi-supervised methods in terms of classification, and\nother pure clustering methods when there are no labels available, being also\nless sensitive than previous methods to the parameters values.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jul 2019 22:02:47 GMT"}, {"version": "v2", "created": "Thu, 26 Mar 2020 01:26:54 GMT"}], "update_date": "2020-03-27", "authors_parsed": [["Braga", "Pedro H. M.", ""], ["Bassani", "Hansenclever F.", ""]]}, {"id": "1907.01098", "submitter": "Piyush Papreja", "authors": "Piyush Papreja and Hemanth Venkateswara and Sethuraman Panchanathan", "title": "Representation, Exploration and Recommendation of Music Playlists", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-030-43887-6_50", "report-no": null, "categories": "cs.IR cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Playlists have become a significant part of our listening experience because\nof the digital cloud-based services such as Spotify, Pandora, Apple Music.\nOwing to the meteoric rise in the usage of playlists, recommending playlists is\ncrucial to music services today. Although there has been a lot of work done in\nplaylist prediction, the area of playlist representation hasn't received that\nlevel of attention. Over the last few years, sequence-to-sequence models,\nespecially in the field of natural language processing, have shown the\neffectiveness of learned embeddings in capturing the semantic characteristics\nof sequences. We can apply similar concepts to music to learn fixed length\nrepresentations for playlists and use those representations for downstream\ntasks such as playlist discovery, browsing, and recommendation. In this work,\nwe formulate the problem of learning a fixed-length playlist representation in\nan unsupervised manner, using Sequence-to-sequence (Seq2seq) models,\ninterpreting playlists as sentences and songs as words. We compare our model\nwith two other encoding architectures for baseline comparison. We evaluate our\nwork using the suite of tasks commonly used for assessing sentence embeddings,\nalong with a few additional tasks pertaining to music, and a recommendation\ntask to study the traits captured by the playlist embeddings and their\neffectiveness for the purpose of music recommendation.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jul 2019 23:20:45 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Papreja", "Piyush", ""], ["Venkateswara", "Hemanth", ""], ["Panchanathan", "Sethuraman", ""]]}, {"id": "1907.01099", "submitter": "Tong Wu", "authors": "Fan Zhang, Tong Wu, Yunlong Wang, Yong Cai, Cao Xiao, Emily Zhao,\n  Lucas Glass, Jimeng Sun", "title": "Predicting Treatment Initiation from Clinical Time Series Data via\n  Graph-Augmented Time-Sensitive Model", "comments": "5 pages, 3 figures, accepted by ICML 2019 Time Series Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many computational models were proposed to extract temporal patterns from\nclinical time series for each patient and among patient group for predictive\nhealthcare. However, the common relations among patients (e.g., share the same\ndoctor) were rarely considered. In this paper, we represent patients and\nclinicians relations by bipartite graphs addressing for example from whom a\npatient get a diagnosis. We then solve for the top eigenvectors of the graph\nLaplacian, and include the eigenvectors as latent representations of the\nsimilarity between patient-clinician pairs into a time-sensitive prediction\nmodel. We conducted experiments using real-world data to predict the initiation\nof first-line treatment for Chronic Lymphocytic Leukemia (CLL) patients.\nResults show that relational similarity can improve prediction over multiple\nbaselines, for example a 5% incremental over long-short term memory baseline in\nterms of area under precision-recall curve.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jul 2019 23:22:45 GMT"}], "update_date": "2019-07-03", "authors_parsed": [["Zhang", "Fan", ""], ["Wu", "Tong", ""], ["Wang", "Yunlong", ""], ["Cai", "Yong", ""], ["Xiao", "Cao", ""], ["Zhao", "Emily", ""], ["Glass", "Lucas", ""], ["Sun", "Jimeng", ""]]}, {"id": "1907.01103", "submitter": "Masahito Ohue", "authors": "Masahito Ohue, Ryota Ii, Keisuke Yanagisawa, Yutaka Akiyama", "title": "Molecular activity prediction using graph convolutional deep neural\n  network considering distance on a molecular graph", "comments": "7 pages", "journal-ref": "In Proceedings of the 2019 International Conference on Parallel\n  and Distributed Processing Techniques & Applications (PDPTA'19), 122-128,\n  2019", "doi": null, "report-no": null, "categories": "q-bio.BM cs.LG q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning is often used in virtual screening to find compounds that\nare pharmacologically active on a target protein. The weave module is a type of\ngraph convolutional deep neural network that uses not only features focusing on\natoms alone (atom features) but also features focusing on atom pairs (pair\nfeatures); thus, it can consider information of nonadjacent atoms. However, the\ncorrelation between the distance on the graph and the three-dimensional\ncoordinate distance is uncertain. In this paper, we propose three improvements\nfor modifying the weave module. First, the distances between ring atoms on the\ngraph were modified to bring the distances on the graph closer to the\ncoordinate distance. Second, different weight matrices were used depending on\nthe distance on the graph in the convolution layers of the pair features.\nFinally, a weighted sum, by distance, was used when converting pair features to\natom features. The experimental results show that the performance of the\nproposed method is slightly better than that of the weave module, and the\nimprovement in the distance representation might be useful for compound\nactivity prediction.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jul 2019 00:23:42 GMT"}, {"version": "v2", "created": "Thu, 4 Jul 2019 14:29:01 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Ohue", "Masahito", ""], ["Ii", "Ryota", ""], ["Yanagisawa", "Keisuke", ""], ["Akiyama", "Yutaka", ""]]}, {"id": "1907.01104", "submitter": "Jonathan Wells", "authors": "Kai Ming Ting and Jonathan R. Wells and Takashi Washio", "title": "Isolation Kernel: The X Factor in Efficient and Effective Large Scale\n  Online Kernel Learning", "comments": "Textural updates. Restructured section 8.4 including additional\n  experimental results", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large scale online kernel learning aims to build an efficient and scalable\nkernel-based predictive model incrementally from a sequence of potentially\ninfinite data points. A current key approach focuses on ways to produce an\napproximate finite-dimensional feature map, assuming that the kernel used has a\nfeature map with intractable dimensionality---an assumption traditionally held\nin kernel-based methods. While this approach can deal with large scale datasets\nefficiently, this outcome is achieved by compromising predictive accuracy\nbecause of the approximation. We offer an alternative approach which overrides\nthe assumption and puts the kernel used at the heart of the approach. It\nfocuses on creating an exact, sparse and finite-dimensional feature map of a\nkernel called Isolation Kernel. Using this new approach, to achieve the above\naim of large scale online kernel learning becomes extremely simple---simply use\nIsolation Kernel instead of a kernel having a feature map with intractable\ndimensionality. We show that, using Isolation Kernel, large scale online kernel\nlearning can be achieved efficiently without sacrificing accuracy.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jul 2019 00:23:43 GMT"}, {"version": "v2", "created": "Tue, 24 Sep 2019 05:34:59 GMT"}], "update_date": "2019-09-25", "authors_parsed": [["Ting", "Kai Ming", ""], ["Wells", "Jonathan R.", ""], ["Washio", "Takashi", ""]]}, {"id": "1907.01113", "submitter": "Xiongjun Zhang", "authors": "Guangjing Song, Michael K. Ng, and Xiongjun Zhang", "title": "Robust Tensor Completion Using Transformed Tensor SVD", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study robust tensor completion by using transformed tensor\nsingular value decomposition (SVD), which employs unitary transform matrices\ninstead of discrete Fourier transform matrix that is used in the traditional\ntensor SVD. The main motivation is that a lower tubal rank tensor can be\nobtained by using other unitary transform matrices than that by using discrete\nFourier transform matrix. This would be more effective for robust tensor\ncompletion. Experimental results for hyperspectral, video and face datasets\nhave shown that the recovery performance for the robust tensor completion\nproblem by using transformed tensor SVD is better in PSNR than that by using\nFourier transform and other robust tensor completion methods.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jul 2019 00:50:31 GMT"}], "update_date": "2019-07-03", "authors_parsed": [["Song", "Guangjing", ""], ["Ng", "Michael K.", ""], ["Zhang", "Xiongjun", ""]]}, {"id": "1907.01121", "submitter": "Zhanxuan Hu", "authors": "Feiping Nie, Zhanxuan Hu, Xiaoqian Wang, Rong Wang, Xuelong Li, Heng\n  Huang", "title": "An Iteratively Re-weighted Method for Problems with Sparsity-Inducing\n  Norms", "comments": "11 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work aims at solving the problems with intractable sparsity-inducing\nnorms that are often encountered in various machine learning tasks, such as\nmulti-task learning, subspace clustering, feature selection, robust principal\ncomponent analysis, and so on. Specifically, an Iteratively Re-Weighted method\n(IRW) with solid convergence guarantee is provided. We investigate its\nconvergence speed via numerous experiments on real data. Furthermore, in order\nto validate the practicality of IRW, we use it to solve a concrete robust\nfeature selection model with complicated objective function. The experimental\nresults show that the model coupled with proposed optimization method\noutperforms alternative methods significantly.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jul 2019 01:36:52 GMT"}], "update_date": "2019-07-03", "authors_parsed": [["Nie", "Feiping", ""], ["Hu", "Zhanxuan", ""], ["Wang", "Xiaoqian", ""], ["Wang", "Rong", ""], ["Li", "Xuelong", ""], ["Huang", "Heng", ""]]}, {"id": "1907.01127", "submitter": "Jonathan Lee", "authors": "Jonathan N. Lee, Aldo Pacchiano, Michael I. Jordan", "title": "Convergence Rates of Smooth Message Passing with Rounding in\n  Entropy-Regularized MAP Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Maximum a posteriori (MAP) inference is a fundamental computational paradigm\nfor statistical inference. In the setting of graphical models, MAP inference\nentails solving a combinatorial optimization problem to find the most likely\nconfiguration of the discrete-valued model. Linear programming (LP) relaxations\nin the Sherali-Adams hierarchy are widely used to attempt to solve this\nproblem, and smooth message passing algorithms have been proposed to solve\nregularized versions of these LPs with great success. This paper leverages\nrecent work in entropy-regularized LPs to analyze convergence rates of a class\nof edge-based smooth message passing algorithms to $\\epsilon$-optimality in the\nrelaxation. With an appropriately chosen regularization constant, we present a\ntheoretical guarantee on the number of iterations sufficient to recover the\ntrue integral MAP solution when the LP is tight and the solution is unique.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jul 2019 02:21:44 GMT"}, {"version": "v2", "created": "Sun, 1 Mar 2020 02:59:30 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Lee", "Jonathan N.", ""], ["Pacchiano", "Aldo", ""], ["Jordan", "Michael I.", ""]]}, {"id": "1907.01132", "submitter": "Moming Duan", "authors": "Moming Duan, Duo Liu, Xianzhang Chen, Yujuan Tan, Jinting Ren, Lei\n  Qiao, Liang Liang", "title": "Astraea: Self-balancing Federated Learning for Improving Classification\n  Accuracy of Mobile Deep Learning Applications", "comments": "Published as a conference paper at IEEE 37th International Conference\n  on Computer Design (ICCD) 2019", "journal-ref": null, "doi": "10.1109/ICCD46524.2019.00038", "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning (FL) is a distributed deep learning method which enables\nmultiple participants, such as mobile phones and IoT devices, to contribute a\nneural network model while their private training data remains in local\ndevices. This distributed approach is promising in the edge computing system\nwhere have a large corpus of decentralized data and require high privacy.\nHowever, unlike the common training dataset, the data distribution of the edge\ncomputing system is imbalanced which will introduce biases in the model\ntraining and cause a decrease in accuracy of federated learning applications.\nIn this paper, we demonstrate that the imbalanced distributed training data\nwill cause accuracy degradation in FL. To counter this problem, we build a\nself-balancing federated learning framework call Astraea, which alleviates the\nimbalances by 1) Global data distribution based data augmentation, and 2)\nMediator based multi-client rescheduling. The proposed framework relieves\nglobal imbalance by runtime data augmentation, and for averaging the local\nimbalance, it creates the mediator to reschedule the training of clients based\non Kullback-Leibler divergence (KLD) of their data distribution. Compared with\nFedAvg, the state-of-the-art FL algorithm, Astraea shows +5.59% and +5.89%\nimprovement of top-1 accuracy on the imbalanced EMNIST and imbalanced CINIC-10\ndatasets, respectively. Meanwhile, the communication traffic of Astraea can be\n82% lower than that of FedAvg.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jul 2019 02:44:36 GMT"}, {"version": "v2", "created": "Fri, 8 May 2020 07:01:56 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Duan", "Moming", ""], ["Liu", "Duo", ""], ["Chen", "Xianzhang", ""], ["Tan", "Yujuan", ""], ["Ren", "Jinting", ""], ["Qiao", "Lei", ""], ["Liang", "Liang", ""]]}, {"id": "1907.01149", "submitter": "Ruiyuan Wu", "authors": "Ruiyuan Wu, Wing-Kin Ma, Xiao Fu, and Qiang Li", "title": "Hyperspectral Super-Resolution via Global-Local Low-Rank Matrix\n  Estimation", "comments": "30 pages, 12 figures, 5 tables. Codes available at\n  https://github.com/REIYANG/GLORIA. To appear in IEEE Transactions on\n  Geoscience and Remote Sensing", "journal-ref": null, "doi": "10.1109/TGRS.2020.2979908", "report-no": null, "categories": "eess.IV cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hyperspectral super-resolution (HSR) is a problem that aims to estimate an\nimage of high spectral and spatial resolutions from a pair of co-registered\nmultispectral (MS) and hyperspectral (HS) images, which have coarser spectral\nand spatial resolutions, respectively. In this paper we pursue a low-rank\nmatrix estimation approach for HSR. We assume that the spectral-spatial\nmatrices associated with the whole image and the local areas of the image have\nlow-rank structures. The local low-rank assumption, in particular, has the aim\nof providing a more flexible model for accounting for local variation effects\ndue to endmember variability. We formulate the HSR problem as a global-local\nrank-regularized least-squares problem. By leveraging on the recent advances in\nnon-convex large-scale optimization, namely, the smooth Schatten-p\napproximation and the accelerated majorization-minimization method, we develop\nan efficient algorithm for the global-local low-rank problem. Numerical\nexperiments on synthetic, semi-real and real data show that the proposed\nalgorithm outperforms a number of benchmark algorithms in terms of recovery\nperformance.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jul 2019 03:46:02 GMT"}, {"version": "v2", "created": "Sun, 8 Mar 2020 21:06:50 GMT"}], "update_date": "2020-10-28", "authors_parsed": [["Wu", "Ruiyuan", ""], ["Ma", "Wing-Kin", ""], ["Fu", "Xiao", ""], ["Li", "Qiang", ""]]}, {"id": "1907.01160", "submitter": "Jonathan Le Roux", "authors": "Gordon Wichern, Joe Antognini, Michael Flynn, Licheng Richard Zhu,\n  Emmett McQuinn, Dwight Crow, Ethan Manilow, Jonathan Le Roux", "title": "WHAM!: Extending Speech Separation to Noisy Environments", "comments": "Accepted for publication at Interspeech 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.CL cs.LG eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent progress in separating the speech signals from multiple overlapping\nspeakers using a single audio channel has brought us closer to solving the\ncocktail party problem. However, most studies in this area use a constrained\nproblem setup, comparing performance when speakers overlap almost completely,\nat artificially low sampling rates, and with no external background noise. In\nthis paper, we strive to move the field towards more realistic and challenging\nscenarios. To that end, we created the WSJ0 Hipster Ambient Mixtures (WHAM!)\ndataset, consisting of two speaker mixtures from the wsj0-2mix dataset combined\nwith real ambient noise samples. The samples were collected in coffee shops,\nrestaurants, and bars in the San Francisco Bay Area, and are made publicly\navailable. We benchmark various speech separation architectures and objective\nfunctions to evaluate their robustness to noise. While separation performance\ndecreases as a result of noise, we still observe substantial gains relative to\nthe noisy signals for most approaches.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jul 2019 04:27:55 GMT"}], "update_date": "2019-07-03", "authors_parsed": [["Wichern", "Gordon", ""], ["Antognini", "Joe", ""], ["Flynn", "Michael", ""], ["Zhu", "Licheng Richard", ""], ["McQuinn", "Emmett", ""], ["Crow", "Dwight", ""], ["Manilow", "Ethan", ""], ["Roux", "Jonathan Le", ""]]}, {"id": "1907.01162", "submitter": "Zhibin Li", "authors": "Zhibin Li, Jian Zhang, Qiang Wu, Yongshun Gong, Jinfeng Yi, Christina\n  Kirsch", "title": "Sample Adaptive Multiple Kernel Learning for Failure Prediction of\n  Railway Points", "comments": "Accepted by KDD2019 Applied Data Science track", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Railway points are among the key components of railway infrastructure. As a\npart of signal equipment, points control the routes of trains at railway\njunctions, having a significant impact on the reliability, capacity, and\npunctuality of rail transport. Traditionally, maintenance of points is based on\na fixed time interval or raised after the equipment failures. Instead, it would\nbe of great value if we could forecast points' failures and take action\nbeforehand, minimising any negative effect. To date, most of the existing\nprediction methods are either lab-based or relying on specially installed\nsensors which makes them infeasible for large-scale implementation. Besides,\nthey often use data from only one source. We, therefore, explore a new way that\nintegrates multi-source data which are ready to hand to fulfil this task. We\nconducted our case study based on Sydney Trains rail network which is an\nextensive network of passenger and freight railways. Unfortunately, the\nreal-world data are usually incomplete due to various reasons, e.g., faults in\nthe database, operational errors or transmission faults. Besides, railway\npoints differ in their locations, types and some other properties, which means\nit is hard to use a unified model to predict their failures. Aiming at this\nchallenging task, we firstly constructed a dataset from multiple sources and\nselected key features with the help of domain experts. In this paper, we\nformulate our prediction task as a multiple kernel learning problem with\nmissing kernels. We present a robust multiple kernel learning algorithm for\npredicting points failures. Our model takes into account the missing pattern of\ndata as well as the inherent variance on different sets of railway points.\nExtensive experiments demonstrate the superiority of our algorithm compared\nwith other state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jul 2019 04:36:38 GMT"}], "update_date": "2019-07-03", "authors_parsed": [["Li", "Zhibin", ""], ["Zhang", "Jian", ""], ["Wu", "Qiang", ""], ["Gong", "Yongshun", ""], ["Yi", "Jinfeng", ""], ["Kirsch", "Christina", ""]]}, {"id": "1907.01164", "submitter": "Ashis Pati", "authors": "Ashis Pati, Alexander Lerch, Ga\\\"etan Hadjeres", "title": "Learning to Traverse Latent Spaces for Musical Score Inpainting", "comments": "20th International Society for Music Information Retrieval Conference\n  (ISMIR), 2019, Delft, The Netherlands; 6 pages, 8 figures", "journal-ref": "20th International Society for Music Information Retrieval\n  Conference (ISMIR), 2019, Delft, The Netherlands", "doi": null, "report-no": null, "categories": "cs.LG cs.SD eess.AS stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Music Inpainting is the task of filling in missing or lost information in a\npiece of music. We investigate this task from an interactive music creation\nperspective. To this end, a novel deep learning-based approach for musical\nscore inpainting is proposed. The designed model takes both past and future\nmusical context into account and is capable of suggesting ways to connect them\nin a musically meaningful manner. To achieve this, we leverage the\nrepresentational power of the latent space of a Variational Auto-Encoder and\ntrain a Recurrent Neural Network which learns to traverse this latent space\nconditioned on the past and future musical contexts. Consequently, the designed\nmodel is capable of generating several measures of music to connect two musical\nexcerpts. The capabilities and performance of the model are showcased by\ncomparison with competitive baselines using several objective and subjective\nevaluation methods. The results show that the model generates meaningful\ninpaintings and can be used in interactive music creation applications.\nOverall, the method demonstrates the merit of learning complex trajectories in\nthe latent spaces of deep generative models.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jul 2019 04:39:05 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Pati", "Ashis", ""], ["Lerch", "Alexander", ""], ["Hadjeres", "Ga\u00ebtan", ""]]}, {"id": "1907.01180", "submitter": "Aaron M. Roth", "authors": "Aaron M. Roth, Nicholay Topin, Pooyan Jamshidi, Manuela Veloso", "title": "Conservative Q-Improvement: Reinforcement Learning for an Interpretable\n  Decision-Tree Policy", "comments": "6 pages + 1 page of references", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is a growing desire in the field of reinforcement learning (and machine\nlearning in general) to move from black-box models toward more \"interpretable\nAI.\" We improve interpretability of reinforcement learning by increasing the\nutility of decision tree policies learned via reinforcement learning. These\npolicies consist of a decision tree over the state space, which requires fewer\nparameters to express than traditional policy representations. Existing methods\nfor creating decision tree policies via reinforcement learning focus on\naccurately representing an action-value function during training, but this\nleads to much larger trees than would otherwise be required. To address this\nshortcoming, we propose a novel algorithm which only increases tree size when\nthe estimated discounted future reward of the overall policy would increase by\na sufficient amount. Through evaluation in a simulated environment, we show\nthat its performance is comparable or superior to traditional tree-based\napproaches and that it yields a more succinct policy. Additionally, we discuss\ntuning parameters to control the tradeoff between optimizing for smaller tree\nsize or for overall reward.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jul 2019 05:51:04 GMT"}], "update_date": "2019-07-03", "authors_parsed": [["Roth", "Aaron M.", ""], ["Topin", "Nicholay", ""], ["Jamshidi", "Pooyan", ""], ["Veloso", "Manuela", ""]]}, {"id": "1907.01184", "submitter": "Linh Nguyen PhD", "authors": "Linh Nguyen, Jaime Valls Miro, Lei Shi and Teresa Vidal-Calleja", "title": "Gaussian Mixture Marginal Distributions for Modelling Remaining Pipe\n  Wall Thickness of Critical Water Mains in Non-Destructive Evaluation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SY stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rapidly estimating the remaining wall thickness (RWT) is paramount for the\nnon-destructive condition assessment evaluation of large critical metallic\npipelines. A robotic vehicle with embedded magnetism-based sensors has been\ndeveloped to traverse the inside of a pipeline and conduct inspections at the\nlocation of a break. However its sensing speed is constrained by the magnetic\nprinciple of operation, thus slowing down the overall operation in seeking\ndense RWT mapping. To ameliorate this drawback, this work proposes the partial\nscanning of the pipe and then employing Gaussian Processes (GPs) to infer RWT\nat the unseen pipe sections. Since GP prediction assumes to have normally\ndistributed input data - which does correspond with real RWT measurements -\nGaussian mixture (GM) models are proven in this work as fitting marginal\ndistributions to effectively capture the probability of any RWT value in the\ninspected data. The effectiveness of the proposed approach is extensively\nvalidated from real-world data collected in collaboration with a water utility\nfrom a cast iron water main pipeline in Sydney, Australia.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jul 2019 06:07:12 GMT"}], "update_date": "2019-07-03", "authors_parsed": [["Nguyen", "Linh", ""], ["Miro", "Jaime Valls", ""], ["Shi", "Lei", ""], ["Vidal-Calleja", "Teresa", ""]]}, {"id": "1907.01197", "submitter": "Claudio Lucchese", "authors": "Stefano Calzavara, Claudio Lucchese, Gabriele Tolomei, Seyum Assefa\n  Abebe and Salvatore Orlando", "title": "Treant: Training Evasion-Aware Decision Trees", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite its success and popularity, machine learning is now recognized as\nvulnerable to evasion attacks, i.e., carefully crafted perturbations of test\ninputs designed to force prediction errors. In this paper we focus on evasion\nattacks against decision tree ensembles, which are among the most successful\npredictive models for dealing with non-perceptual problems. Even though they\nare powerful and interpretable, decision tree ensembles have received only\nlimited attention by the security and machine learning communities so far,\nleading to a sub-optimal state of the art for adversarial learning techniques.\nWe thus propose Treant, a novel decision tree learning algorithm that, on the\nbasis of a formal threat model, minimizes an evasion-aware loss function at\neach step of the tree construction. Treant is based on two key technical\ningredients: robust splitting and attack invariance, which jointly guarantee\nthe soundness of the learning process. Experimental results on three publicly\navailable datasets show that Treant is able to generate decision tree ensembles\nthat are at the same time accurate and nearly insensitive to evasion attacks,\noutperforming state-of-the-art adversarial learning techniques.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jul 2019 06:59:15 GMT"}, {"version": "v2", "created": "Wed, 3 Jul 2019 13:39:30 GMT"}], "update_date": "2019-07-04", "authors_parsed": [["Calzavara", "Stefano", ""], ["Lucchese", "Claudio", ""], ["Tolomei", "Gabriele", ""], ["Abebe", "Seyum Assefa", ""], ["Orlando", "Salvatore", ""]]}, {"id": "1907.01216", "submitter": "Moshe Kravchik", "authors": "Moshe Kravchik, Asaf Shabtai", "title": "Efficient Cyber Attacks Detection in Industrial Control Systems Using\n  Lightweight Neural Networks and PCA", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Industrial control systems (ICSs) are widely used and vital to industry and\nsociety. Their failure can have severe impact on both economics and human life.\nHence, these systems have become an attractive target for attacks, both\nphysical and cyber. A number of attack detection methods have been proposed,\nhowever they are characterized by a low detection rate, a substantial false\npositive rate, or are system specific. In this paper, we study an attack\ndetection method based on simple and lightweight neural networks, namely, 1D\nconvolutions and autoencoders. We apply these networks to both the time and\nfrequency domains of the collected data and discuss pros and cons of each\napproach. We evaluate the suggested method on three popular public datasets and\nachieve detection rates matching or exceeding previously published detection\nresults, while featuring small footprint, short training and detection times,\nand generality. We also demonstrate the effectiveness of PCA, which, given\nproper data preprocessing and feature selection, can provide high attack\ndetection scores in many settings. Finally, we study the proposed method's\nrobustness against adversarial attacks, that exploit inherent blind spots of\nneural networks to evade detection while achieving their intended physical\neffect. Our results show that the proposed method is robust to such evasion\nattacks: in order to evade detection, the attacker is forced to sacrifice the\ndesired physical impact on the system. This finding suggests that neural\nnetworks trained under the constraints of the laws of physics can be trusted\nmore than networks trained under more flexible conditions.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jul 2019 07:58:42 GMT"}, {"version": "v2", "created": "Tue, 1 Oct 2019 16:55:00 GMT"}], "update_date": "2019-10-02", "authors_parsed": [["Kravchik", "Moshe", ""], ["Shabtai", "Asaf", ""]]}, {"id": "1907.01221", "submitter": "Kun Zhao", "authors": "Kun Zhao, Takayuki Osogami and Tetsuro Morimura", "title": "Visual analytics for team-based invasion sports with significant events\n  and Markov reward process", "comments": "8 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In team-based invasion sports such as soccer and basketball, analytics is\nimportant for teams to understand their performance and for audiences to\nunderstand matches better. The present work focuses on performing visual\nanalytics to evaluate the value of any kind of event occurring in a sports\nmatch with a continuous parameter space. Here, the continuous parameter space\ninvolves the time, location, score, and other parameters. Because the\nspatiotemporal data used in such analytics is a low-level representation and\nhas a very large size, however, traditional analytics may need to discretize\nthe continuous parameter space (e.g., subdivide the playing area) or use a\nlocal feature to limit the analysis to specific events (e.g., only shots).\nThese approaches make evaluation impossible for any kind of event with a\ncontinuous parameter space. To solve this problem, we consider a whole match as\na Markov chain of significant events, so that event values can be estimated\nwith a continuous parameter space by solving the Markov chain with a machine\nlearning model. The significant events are first extracted by considering the\ntime-varying distribution of players to represent the whole match. Then, the\nextracted events are redefined as different states with the continuous\nparameter space and built as a Markov chain so that a Markov reward process can\nbe applied. Finally, the Markov reward process is solved by a customized\nfitted-value iteration algorithm so that the event values with the continuous\nparameter space can be predicted by a regression model. As a result, the event\nvalues can be visually inspected over the whole playing field under arbitrary\ngiven conditions. Experimental results with real soccer data show the\neffectiveness of the proposed system.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jul 2019 08:11:16 GMT"}], "update_date": "2019-07-03", "authors_parsed": [["Zhao", "Kun", ""], ["Osogami", "Takayuki", ""], ["Morimura", "Tetsuro", ""]]}, {"id": "1907.01253", "submitter": "Erdi Calli", "authors": "Erdi \\c{C}all{\\i}, Keelin Murphy, Ecem Sogancioglu, Bram van Ginneken", "title": "FRODO: Free rejection of out-of-distribution samples: application to\n  chest x-ray analysis", "comments": "MIDL 2019 [arXiv:1907.08612]", "journal-ref": null, "doi": null, "report-no": "MIDL/2019/ExtendedAbstract/H1e7kWD794", "categories": "cs.LG eess.IV stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this work, we propose a method to reject out-of-distribution samples which\ncan be adapted to any network architecture and requires no additional training\ndata. Publicly available chest x-ray data (38,353 images) is used to train a\nstandard ResNet-50 model to detect emphysema. Feature activations of\nintermediate layers are used as descriptors defining the training data\ndistribution. A novel metric, FRODO, is measured by using the Mahalanobis\ndistance of a new test sample to the training data distribution. The method is\ntested using a held-out test dataset of 21,176 chest x-rays (in-distribution)\nand a set of 14,821 out-of-distribution x-ray images of incorrect orientation\nor anatomy. In classifying test samples as in or out-of distribution, our\nmethod achieves an AUC score of 0.99.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jul 2019 09:28:58 GMT"}], "update_date": "2019-09-13", "authors_parsed": [["\u00c7all\u0131", "Erdi", ""], ["Murphy", "Keelin", ""], ["Sogancioglu", "Ecem", ""], ["van Ginneken", "Bram", ""]]}, {"id": "1907.01256", "submitter": "Yo Joong Choe", "authors": "Yo Joong Choe, Jiyeon Ham, Kyubyong Park and Yeoil Yoon", "title": "A Neural Grammatical Error Correction System Built On Better\n  Pre-training and Sequential Transfer Learning", "comments": "Accepted to ACL 2019 Workshop on Innovative Use of NLP for Building\n  Educational Applications (BEA)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Grammatical error correction can be viewed as a low-resource\nsequence-to-sequence task, because publicly available parallel corpora are\nlimited. To tackle this challenge, we first generate erroneous versions of\nlarge unannotated corpora using a realistic noising function. The resulting\nparallel corpora are subsequently used to pre-train Transformer models. Then,\nby sequentially applying transfer learning, we adapt these models to the domain\nand style of the test set. Combined with a context-aware neural spellchecker,\nour system achieves competitive results in both restricted and low resource\ntracks in ACL 2019 BEA Shared Task. We release all of our code and materials\nfor reproducibility.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jul 2019 09:33:36 GMT"}], "update_date": "2019-07-03", "authors_parsed": [["Choe", "Yo Joong", ""], ["Ham", "Jiyeon", ""], ["Park", "Kyubyong", ""], ["Yoon", "Yeoil", ""]]}, {"id": "1907.01262", "submitter": "Huidong Xie", "authors": "Huidong Xie, Hongming Shan, Wenxiang Cong, Xiaohua Zhang, Shaohua Liu,\n  Ruola Ning, Ge Wang", "title": "Dual Network Architecture for Few-view CT -- Trained on ImageNet Data\n  and Transferred for Medical Imaging", "comments": "11 pages, 5 figures, 2019 SPIE Optical Engineering + Applications", "journal-ref": null, "doi": "10.1117/12.2531198", "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  X-ray computed tomography (CT) reconstructs cross-sectional images from\nprojection data. However, ionizing X-ray radiation associated with CT scanning\nmight induce cancer and genetic damage. Therefore, the reduction of radiation\ndose has attracted major attention. Few-view CT image reconstruction is an\nimportant topic to reduce the radiation dose. Recently, data-driven algorithms\nhave shown great potential to solve the few-view CT problem. In this paper, we\ndevelop a dual network architecture (DNA) for reconstructing images directly\nfrom sinograms. In the proposed DNA method, a point-based fully-connected layer\nlearns the backprojection process requesting significantly less memory than the\nprior arts do. Proposed method uses O(C*N*N_c) parameters where N and N_c\ndenote the dimension of reconstructed images and number of projections\nrespectively. C is an adjustable parameter that can be set as low as 1. Our\nexperimental results demonstrate that DNA produces a competitive performance\nover the other state-of-the-art methods. Interestingly, natural images can be\nused to pre-train DNA to avoid overfitting when the amount of real patient\nimages is limited.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jul 2019 09:46:27 GMT"}, {"version": "v2", "created": "Wed, 3 Jul 2019 15:23:10 GMT"}, {"version": "v3", "created": "Fri, 12 Jul 2019 19:05:59 GMT"}, {"version": "v4", "created": "Wed, 17 Jul 2019 17:20:07 GMT"}, {"version": "v5", "created": "Sun, 25 Aug 2019 05:01:59 GMT"}, {"version": "v6", "created": "Thu, 12 Sep 2019 12:49:18 GMT"}], "update_date": "2019-09-13", "authors_parsed": [["Xie", "Huidong", ""], ["Shan", "Hongming", ""], ["Cong", "Wenxiang", ""], ["Zhang", "Xiaohua", ""], ["Liu", "Shaohua", ""], ["Ning", "Ruola", ""], ["Wang", "Ge", ""]]}, {"id": "1907.01277", "submitter": "Gabriel Meseguer-Brocal", "authors": "Gabriel Meseguer-Brocal, and Geoffroy Peeters", "title": "Conditioned-U-Net: Introducing a Control Mechanism in the U-Net for\n  Multiple Source Separations", "comments": null, "journal-ref": "Proceedings of the 20th International Society for Music\n  Information Retrieval Conference, ISMIR, Delft, Netherlands, 2019", "doi": "10.5281/zenodo.3527766", "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Data-driven models for audio source separation such as U-Net or Wave-U-Net\nare usually models dedicated to and specifically trained for a single task,\ne.g. a particular instrument isolation. Training them for various tasks at once\ncommonly results in worse performances than training them for a single\nspecialized task. In this work, we introduce the Conditioned-U-Net (C-U-Net)\nwhich adds a control mechanism to the standard U-Net. The control mechanism\nallows us to train a unique and generic U-Net to perform the separation of\nvarious instruments. The C-U-Net decides the instrument to isolate according to\na one-hot-encoding input vector. The input vector is embedded to obtain the\nparameters that control Feature-wise Linear Modulation (FiLM) layers. FiLM\nlayers modify the U-Net feature maps in order to separate the desired\ninstrument via affine transformations. The C-U-Net performs different\ninstrument separations, all with a single model achieving the same performances\nas the dedicated ones at a lower cost.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jul 2019 10:10:53 GMT"}, {"version": "v2", "created": "Tue, 9 Jul 2019 10:35:33 GMT"}, {"version": "v3", "created": "Thu, 21 Nov 2019 18:12:29 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Meseguer-Brocal", "Gabriel", ""], ["Peeters", "Geoffroy", ""]]}, {"id": "1907.01284", "submitter": "Rajesh Shreedhar Bhat", "authors": "Pranay Dugar, Anirban Chatterjee, Rajesh Shreedhar Bhat, Saswata Sahoo", "title": "Semi-Bagging Based Deep Neural Architecture to Extract Text from High\n  Entropy Images", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Extracting texts of various size and shape from images containing multiple\nobjects is an important problem in many contexts, especially, in connection to\ne-commerce, augmented reality assistance system in natural scene, etc. The\nexisting works (based on only CNN) often perform sub-optimally when the image\ncontains regions of high entropy having multiple objects. This paper presents\nan end-to-end text detection strategy combining a segmentation algorithm and an\nensemble of multiple text detectors of different types to detect text in every\nindividual image segments independently. The proposed strategy involves a\nsuper-pixel based image segmenter which splits an image into multiple regions.\nA convolutional deep neural architecture is developed which works on each of\nthe segments and detects texts of multiple shapes, sizes, and structures. It\noutperforms the competing methods in terms of coverage in detecting texts in\nimages especially the ones where the text of various types and sizes are\ncompacted in a small region along with various other objects. Furthermore, the\nproposed text detection method along with a text recognizer outperforms the\nexisting state-of-the-art approaches in extracting text from high entropy\nimages. We validate the results on a dataset consisting of product images on an\ne-commerce website.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jul 2019 10:26:14 GMT"}], "update_date": "2019-07-03", "authors_parsed": [["Dugar", "Pranay", ""], ["Chatterjee", "Anirban", ""], ["Bhat", "Rajesh Shreedhar", ""], ["Sahoo", "Saswata", ""]]}, {"id": "1907.01285", "submitter": "Steffen Wolf", "authors": "Nasim Rahaman, Steffen Wolf, Anirudh Goyal, Roman Remme, Yoshua Bengio", "title": "Learning the Arrow of Time", "comments": "A shorter version of this work was presented at the Theoretical\n  Phyiscs for Deep Learning Workshop, ICML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We humans seem to have an innate understanding of the asymmetric progression\nof time, which we use to efficiently and safely perceive and manipulate our\nenvironment. Drawing inspiration from that, we address the problem of learning\nan arrow of time in a Markov (Decision) Process. We illustrate how a learned\narrow of time can capture meaningful information about the environment, which\nin turn can be used to measure reachability, detect side-effects and to obtain\nan intrinsic reward signal. We show empirical results on a selection of\ndiscrete and continuous environments, and demonstrate for a class of stochastic\nprocesses that the learned arrow of time agrees reasonably well with a known\nnotion of an arrow of time given by the celebrated Jordan-Kinderlehrer-Otto\nresult.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jul 2019 10:32:09 GMT"}], "update_date": "2019-07-03", "authors_parsed": [["Rahaman", "Nasim", ""], ["Wolf", "Steffen", ""], ["Goyal", "Anirudh", ""], ["Remme", "Roman", ""], ["Bengio", "Yoshua", ""]]}, {"id": "1907.01287", "submitter": "Ping-Chun Hsieh", "authors": "Xi Liu, Ping-Chun Hsieh, Anirban Bhattacharya, P. R. Kumar", "title": "Exploration Through Reward Biasing: Reward-Biased Maximum Likelihood\n  Estimation for Stochastic Multi-Armed Bandits", "comments": "ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inspired by the Reward-Biased Maximum Likelihood Estimate method of adaptive\ncontrol, we propose RBMLE -- a novel family of learning algorithms for\nstochastic multi-armed bandits (SMABs). For a broad range of SMABs including\nboth the parametric Exponential Family as well as the non-parametric\nsub-Gaussian/Exponential family, we show that RBMLE yields an index policy. To\nchoose the bias-growth rate $\\alpha(t)$ in RBMLE, we reveal the nontrivial\ninterplay between $\\alpha(t)$ and the regret bound that generally applies in\nboth the Exponential Family as well as the sub-Gaussian/Exponential family\nbandits. To quantify the finite-time performance, we prove that RBMLE attains\norder-optimality by adaptively estimating the unknown constants in the\nexpression of $\\alpha(t)$ for Gaussian and sub-Gaussian bandits. Extensive\nexperiments demonstrate that the proposed RBMLE achieves empirical regret\nperformance competitive with the state-of-the-art methods, while being more\ncomputationally efficient and scalable in comparison to the best-performing\nones among them.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jul 2019 10:34:53 GMT"}, {"version": "v2", "created": "Tue, 23 Jul 2019 23:45:00 GMT"}, {"version": "v3", "created": "Fri, 23 Oct 2020 15:22:26 GMT"}], "update_date": "2020-10-26", "authors_parsed": [["Liu", "Xi", ""], ["Hsieh", "Ping-Chun", ""], ["Bhattacharya", "Anirban", ""], ["Kumar", "P. R.", ""]]}, {"id": "1907.01288", "submitter": "Ahmed ELGazzar", "authors": "Ahmed El Gazzar, Leonardo Cerliani, Guido van Wingen, Rajat Mani\n  Thomas", "title": "Simple 1-D Convolutional Networks for Resting-State fMRI Based\n  Classification in Autism", "comments": "accepted for publication in IJCNN 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning methods are increasingly being used with neuroimaging data like\nstructural and function magnetic resonance imaging (MRI) to predict the\ndiagnosis of neuropsychiatric and neurological disorders. For psychiatric\ndisorders in particular, it is believed that one of the most promising modality\nis the resting-state functional MRI (rsfMRI), which captures the intrinsic\nconnectivity between regions in the brain. Because rsfMRI data points are\ninherently high-dimensional (~1M), it is impossible to process the entire input\nin its raw form. In this paper, we propose a very simple transformation of the\nrsfMRI images that captures all of the temporal dynamics of the signal but\nsub-samples its spatial extent. As a result, we use a very simple 1-D\nconvolutional network which is fast to train, requires minimal preprocessing\nand performs at par with the state-of-the-art on the classification of Autism\nspectrum disorders.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jul 2019 10:35:25 GMT"}], "update_date": "2019-07-03", "authors_parsed": [["Gazzar", "Ahmed El", ""], ["Cerliani", "Leonardo", ""], ["van Wingen", "Guido", ""], ["Thomas", "Rajat Mani", ""]]}, {"id": "1907.01298", "submitter": "Matthieu Geist", "authors": "Erinc Merdivan, Sten Hanke and Matthieu Geist", "title": "Modified Actor-Critics", "comments": "Long version of AAMAS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Recent successful deep reinforcement learning algorithms, such as Trust\nRegion Policy Optimization (TRPO) or Proximal Policy Optimization (PPO), are\nfundamentally variations of conservative policy iteration (CPI). These\nalgorithms iterate policy evaluation followed by a softened policy improvement\nstep. As so, they are naturally on-policy. In this paper, we propose to combine\n(any kind of) soft greediness with Modified Policy Iteration (MPI). The\nproposed abstract framework applies repeatedly: (i) a partial policy evaluation\nstep that allows off-policy learning and (ii) any softened greedy step. Our\ncontribution can be seen as a new generic tool for the deep reinforcement\nlearning toolbox. As a proof of concept, we instantiate this framework with the\nPPO greediness. Comparison to the original PPO shows that our algorithm is much\nmore sample efficient. We also show that it is competitive with the\nstate-of-art off-policy algorithm Soft Actor Critic (SAC).\n", "versions": [{"version": "v1", "created": "Tue, 2 Jul 2019 11:22:56 GMT"}, {"version": "v2", "created": "Fri, 24 Jan 2020 10:08:28 GMT"}], "update_date": "2020-01-27", "authors_parsed": [["Merdivan", "Erinc", ""], ["Hanke", "Sten", ""], ["Geist", "Matthieu", ""]]}, {"id": "1907.01319", "submitter": "Jong Chul Ye", "authors": "Boah Kim, Jieun Kim, June-Goo Lee, Dong Hwan Kim, Seong Ho Park, Jong\n  Chul Ye", "title": "Unsupervised Deformable Image Registration Using Cycle-Consistent CNN", "comments": "accepted for MICCAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Medical image registration is one of the key processing steps for biomedical\nimage analysis such as cancer diagnosis. Recently, deep learning based\nsupervised and unsupervised image registration methods have been extensively\nstudied due to its excellent performance in spite of ultra-fast computational\ntime compared to the classical approaches. In this paper, we present a novel\nunsupervised medical image registration method that trains deep neural network\nfor deformable registration of 3D volumes using a cycle-consistency. Thanks to\nthe cycle consistency, the proposed deep neural networks can take diverse pair\nof image data with severe deformation for accurate registration. Experimental\nresults using multiphase liver CT images demonstrate that our method provides\nvery precise 3D image registration within a few seconds, resulting in more\naccurate cancer size estimation.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jul 2019 12:29:02 GMT"}], "update_date": "2019-07-03", "authors_parsed": [["Kim", "Boah", ""], ["Kim", "Jieun", ""], ["Lee", "June-Goo", ""], ["Kim", "Dong Hwan", ""], ["Park", "Seong Ho", ""], ["Ye", "Jong Chul", ""]]}, {"id": "1907.01328", "submitter": "Erik Bryhn Myklebust", "authors": "Erik Bryhn Myklebust and Ernesto Jimenez-Ruiz and Jiaoyan Chen and\n  Raoul Wolf and Knut Erik Tollefsen", "title": "Knowledge Graph Embedding for Ecotoxicological Effect Prediction", "comments": null, "journal-ref": "In: Ghidini C. et al. (eds) The Semantic Web - ISWC 2019. ISWC\n  2019. Lecture Notes in Computer Science, vol 11779. Springer, Cham", "doi": "10.1007/978-3-030-30796-7_30", "report-no": null, "categories": "cs.AI cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Exploring the effects a chemical compound has on a species takes a\nconsiderable experimental effort. Appropriate methods for estimating and\nsuggesting new effects can dramatically reduce the work needed to be done by a\nlaboratory. In this paper we explore the suitability of using a knowledge graph\nembedding approach for ecotoxicological effect prediction. A knowledge graph\nhas been constructed from publicly available data sets, including a species\ntaxonomy and chemical classification and similarity. The publicly available\neffect data is integrated to the knowledge graph using ontology alignment\ntechniques. Our experimental results show that the knowledge graph based\napproach improves the selected baselines.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jul 2019 12:43:17 GMT"}, {"version": "v2", "created": "Thu, 29 Aug 2019 12:11:23 GMT"}, {"version": "v3", "created": "Mon, 11 Nov 2019 14:20:08 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Myklebust", "Erik Bryhn", ""], ["Jimenez-Ruiz", "Ernesto", ""], ["Chen", "Jiaoyan", ""], ["Wolf", "Raoul", ""], ["Tollefsen", "Knut Erik", ""]]}, {"id": "1907.01329", "submitter": "Erik Daxberger", "authors": "Erik Daxberger, Anastasia Makarova, Matteo Turchetta, Andreas Krause", "title": "Mixed-Variable Bayesian Optimization", "comments": "IJCAI 2020 camera-ready; 17 pages, extended version with\n  supplementary material", "journal-ref": "Proceedings of the Twenty-Ninth International Joint Conference on\n  Artificial Intelligence (IJCAI-20), 2020, pages 2633-2639", "doi": "10.24963/ijcai.2020/365", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The optimization of expensive to evaluate, black-box, mixed-variable\nfunctions, i.e. functions that have continuous and discrete inputs, is a\ndifficult and yet pervasive problem in science and engineering. In Bayesian\noptimization (BO), special cases of this problem that consider fully continuous\nor fully discrete domains have been widely studied. However, few methods exist\nfor mixed-variable domains and none of them can handle discrete constraints\nthat arise in many real-world applications. In this paper, we introduce MiVaBo,\na novel BO algorithm for the efficient optimization of mixed-variable functions\ncombining a linear surrogate model based on expressive feature representations\nwith Thompson sampling. We propose an effective method to optimize its\nacquisition function, a challenging problem for mixed-variable domains, making\nMiVaBo the first BO method that can handle complex constraints over the\ndiscrete variables. Moreover, we provide the first convergence analysis of a\nmixed-variable BO algorithm. Finally, we show that MiVaBo is significantly more\nsample efficient than state-of-the-art mixed-variable BO algorithms on several\nhyperparameter tuning tasks, including the tuning of deep generative models.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jul 2019 12:46:43 GMT"}, {"version": "v2", "created": "Fri, 18 Oct 2019 09:57:58 GMT"}, {"version": "v3", "created": "Mon, 16 Dec 2019 11:36:04 GMT"}, {"version": "v4", "created": "Tue, 4 Aug 2020 08:35:25 GMT"}], "update_date": "2020-08-05", "authors_parsed": [["Daxberger", "Erik", ""], ["Makarova", "Anastasia", ""], ["Turchetta", "Matteo", ""], ["Krause", "Andreas", ""]]}, {"id": "1907.01332", "submitter": "Coert Van Gemeren", "authors": "Axel Uran, Coert van Gemeren, Rosanne van Diepen, Ricardo Chavarriaga,\n  Jos\\'e del R. Mill\\'an", "title": "Applying Transfer Learning To Deep Learned Models For EEG Analysis", "comments": "14 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The introduction of deep learning and transfer learning techniques in fields\nsuch as computer vision allowed a leap forward in the accuracy of image\nclassification tasks. Currently there is only limited use of such techniques in\nneuroscience. The challenge of using deep learning methods to successfully\ntrain models in neuroscience, lies in the complexity of the information that is\nprocessed, the availability of data and the cost of producing sufficient high\nquality annotations. Inspired by its application in computer vision, we\nintroduce transfer learning on electrophysiological data to enable training a\nmodel with limited amounts of data. Our method was tested on the dataset of the\nBCI competition IV 2a and compared to the top results that were obtained using\ntraditional machine learning techniques. Using our DL model we outperform the\ntop result of the competition by 33%. We also explore transferability of\nknowledge between trained models over different experiments, called\ninter-experimental transfer learning. This reduces the amount of required data\neven further and is especially useful when few subjects are available. This\nmethod is able to outperform the standard deep learning methods used in the BCI\ncompetition IV 2b approaches by 18%. In this project we propose a method that\ncan produce reliable electroencephalography (EEG) signal classification, based\non modest amounts of training data through the use of transfer learning.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jul 2019 12:51:26 GMT"}], "update_date": "2019-07-03", "authors_parsed": [["Uran", "Axel", ""], ["van Gemeren", "Coert", ""], ["van Diepen", "Rosanne", ""], ["Chavarriaga", "Ricardo", ""], ["Mill\u00e1n", "Jos\u00e9 del R.", ""]]}, {"id": "1907.01339", "submitter": "David Vilares", "authors": "Michalina Strzyz, David Vilares, Carlos G\\'omez-Rodr\\'iguez", "title": "Sequence Labeling Parsing by Learning Across Representations", "comments": "Proc. of the 57th Annual Meeting of the Association for Computational\n  Linguistics (ACL 2019). Revised version after fixing evaluation bug", "journal-ref": null, "doi": "10.18653/v1/P19-1531", "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We use parsing as sequence labeling as a common framework to learn across\nconstituency and dependency syntactic abstractions. To do so, we cast the\nproblem as multitask learning (MTL). First, we show that adding a parsing\nparadigm as an auxiliary loss consistently improves the performance on the\nother paradigm. Secondly, we explore an MTL sequence labeling model that parses\nboth representations, at almost no cost in terms of performance and speed. The\nresults across the board show that on average MTL models with auxiliary losses\nfor constituency parsing outperform single-task ones by 1.14 F1 points, and for\ndependency parsing by 0.62 UAS points.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jul 2019 13:13:13 GMT"}, {"version": "v2", "created": "Sat, 31 Aug 2019 14:57:14 GMT"}, {"version": "v3", "created": "Tue, 7 Jan 2020 08:02:44 GMT"}], "update_date": "2020-01-08", "authors_parsed": [["Strzyz", "Michalina", ""], ["Vilares", "David", ""], ["G\u00f3mez-Rodr\u00edguez", "Carlos", ""]]}, {"id": "1907.01343", "submitter": "Christoph Raab", "authors": "Christoph Raab and Frank-Michael Schleif", "title": "Low-Rank Subspace Override for Unsupervised Domain Adaptation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Current supervised learning models cannot generalize well across domain\nboundaries, which is a known problem in many applications, such as robotics or\nvisual classification. Domain adaptation methods are used to improve these\ngeneralization properties. However, these techniques suffer either from being\nrestricted to a particular task, such as visual adaptation, require a lot of\ncomputational time and data, which is not always guaranteed, have complex\nparameterization, or expensive optimization procedures. In this work, we\npresent an approach that requires only a well-chosen snapshot of data to find a\nsingle domain invariant subspace. The subspace is calculated in closed form and\noverrides domain structures, which makes it fast and stable in\nparameterization. By employing low-rank techniques, we emphasize on descriptive\ncharacteristics of data. The presented idea is evaluated on various domain\nadaptation tasks such as text and image classification against state of the art\ndomain adaptation approaches and achieves remarkable performance across all\ntasks.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jul 2019 13:19:29 GMT"}, {"version": "v2", "created": "Mon, 13 Jan 2020 10:02:00 GMT"}, {"version": "v3", "created": "Wed, 8 Jul 2020 12:48:25 GMT"}], "update_date": "2020-07-09", "authors_parsed": [["Raab", "Christoph", ""], ["Schleif", "Frank-Michael", ""]]}, {"id": "1907.01356", "submitter": "Shuangjia Zheng", "authors": "Shuangjia Zheng, Jiahua Rao, Zhongyue Zhang, Jun Xu, Yuedong Yang", "title": "Predicting Retrosynthetic Reaction using Self-Corrected Transformer\n  Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.chem-ph cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Synthesis planning is the process of recursively decomposing target molecules\ninto available precursors. Computer-aided retrosynthesis can potentially assist\nchemists in designing synthetic routes, but at present it is cumbersome and\nprovides results of dissatisfactory quality. In this study, we develop a\ntemplate-free self-corrected retrosynthesis predictor (SCROP) to perform a\nretrosynthesis prediction task trained by using the Transformer neural network\narchitecture. In the method, the retrosynthesis planning is converted as a\nmachine translation problem between molecular linear notations of reactants and\nthe products. Coupled with a neural network-based syntax corrector, our method\nachieves an accuracy of 59.0% on a standard benchmark dataset, which increases\n>21% over other deep learning methods, and >6% over template-based methods.\nMore importantly, our method shows an accuracy 1.7 times higher than other\nstate-of-the-art methods for compounds not appearing in the training set.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jul 2019 13:35:37 GMT"}, {"version": "v2", "created": "Wed, 3 Jul 2019 03:48:46 GMT"}], "update_date": "2019-07-04", "authors_parsed": [["Zheng", "Shuangjia", ""], ["Rao", "Jiahua", ""], ["Zhang", "Zhongyue", ""], ["Xu", "Jun", ""], ["Yang", "Yuedong", ""]]}, {"id": "1907.01361", "submitter": "Matias Tassano", "authors": "Matias Tassano, Julie Delon, Thomas Veit", "title": "FastDVDnet: Towards Real-Time Deep Video Denoising Without Flow\n  Estimation", "comments": "Code for this algorithm and results can be found in\n  https://github.com/m-tassano/fastdvdnet. arXiv admin note: text overlap with\n  arXiv:1906.11890", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.GR cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a state-of-the-art video denoising algorithm based\non a convolutional neural network architecture. Until recently, video denoising\nwith neural networks had been a largely under explored domain, and existing\nmethods could not compete with the performance of the best patch-based methods.\nThe approach we introduce in this paper, called FastDVDnet, shows similar or\nbetter performance than other state-of-the-art competitors with significantly\nlower computing times. In contrast to other existing neural network denoisers,\nour algorithm exhibits several desirable properties such as fast runtimes, and\nthe ability to handle a wide range of noise levels with a single network model.\nThe characteristics of its architecture make it possible to avoid using a\ncostly motion compensation stage while achieving excellent performance. The\ncombination between its denoising performance and lower computational load\nmakes this algorithm attractive for practical denoising applications. We\ncompare our method with different state-of-art algorithms, both visually and\nwith respect to objective quality metrics.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jul 2019 14:10:34 GMT"}, {"version": "v2", "created": "Wed, 29 Apr 2020 18:29:49 GMT"}], "update_date": "2020-05-01", "authors_parsed": [["Tassano", "Matias", ""], ["Delon", "Julie", ""], ["Veit", "Thomas", ""]]}, {"id": "1907.01367", "submitter": "Rajiv Ratn Shah", "authors": "Yaman Kumar, Rohit Jain, Khwaja Mohd. Salik, Rajiv Ratn Shah, Yifang\n  yin, Roger Zimmermann", "title": "Lipper: Synthesizing Thy Speech using Multi-View Lipreading", "comments": "Accepted at AAAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Lipreading has a lot of potential applications such as in the domain of\nsurveillance and video conferencing. Despite this, most of the work in building\nlipreading systems has been limited to classifying silent videos into classes\nrepresenting text phrases. However, there are multiple problems associated with\nmaking lipreading a text-based classification task like its dependence on a\nparticular language and vocabulary mapping. Thus, in this paper we propose a\nmulti-view lipreading to audio system, namely Lipper, which models it as a\nregression task. The model takes silent videos as input and produces speech as\nthe output. With multi-view silent videos, we observe an improvement over\nsingle-view speech reconstruction results. We show this by presenting an\nexhaustive set of experiments for speaker-dependent, out-of-vocabulary and\nspeaker-independent settings. Further, we compare the delay values of Lipper\nwith other speechreading systems in order to show the real-time nature of audio\nproduced. We also perform a user study for the audios produced in order to\nunderstand the level of comprehensibility of audios produced using Lipper.\n", "versions": [{"version": "v1", "created": "Fri, 28 Jun 2019 10:26:23 GMT"}], "update_date": "2019-07-03", "authors_parsed": [["Kumar", "Yaman", ""], ["Jain", "Rohit", ""], ["Salik", "Khwaja Mohd.", ""], ["Shah", "Rajiv Ratn", ""], ["yin", "Yifang", ""], ["Zimmermann", "Roger", ""]]}, {"id": "1907.01369", "submitter": "Gabriel Murray", "authors": "Uliyana Kubasova and Gabriel Murray and McKenzie Braley", "title": "Analyzing Verbal and Nonverbal Features for Predicting Group Performance", "comments": "Accepted to INTERSPEECH 2019 (Graz, Austria)", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work analyzes the efficacy of verbal and nonverbal features of group\nconversation for the task of automatic prediction of group task performance. We\ndescribe a new publicly available survival task dataset that was collected and\nannotated to facilitate this prediction task. In these experiments, the new\ndataset is merged with an existing survival task dataset, allowing us to\ncompare feature sets on a much larger amount of data than has been used in\nrecent related work. This work is also distinct from related research on social\nsignal processing (SSP) in that we compare verbal and nonverbal features,\nwhereas SSP is almost exclusively concerned with nonverbal aspects of social\ninteraction. A key finding is that nonverbal features from the speech signal\nare extremely effective for this task, even on their own. However, the most\neffective individual features are verbal features, and we highlight the most\nimportant ones.\n", "versions": [{"version": "v1", "created": "Wed, 26 Jun 2019 17:07:03 GMT"}, {"version": "v2", "created": "Wed, 3 Jul 2019 20:53:42 GMT"}], "update_date": "2019-07-05", "authors_parsed": [["Kubasova", "Uliyana", ""], ["Murray", "Gabriel", ""], ["Braley", "McKenzie", ""]]}, {"id": "1907.01372", "submitter": "Cal Peyser`", "authors": "Cal Peyser, Hao Zhang, Tara N. Sainath, Zelin Wu", "title": "Improving Performance of End-to-End ASR on Numeric Sequences", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recognizing written domain numeric utterances (e.g. I need $1.25.) can be\nchallenging for ASR systems, particularly when numeric sequences are not seen\nduring training. This out-of-vocabulary (OOV) issue is addressed in\nconventional ASR systems by training part of the model on spoken domain\nutterances (e.g. I need one dollar and twenty five cents.), for which numeric\nsequences are composed of in-vocabulary numbers, and then using an FST\nverbalizer to denormalize the result. Unfortunately, conventional ASR models\nare not suitable for the low memory setting of on-device speech recognition.\nE2E models such as RNN-T are attractive for on-device ASR, as they fold the AM,\nPM and LM of a conventional model into one neural network. However, in the\non-device setting the large memory footprint of an FST denormer makes spoken\ndomain training more difficult. In this paper, we investigate techniques to\nimprove E2E model performance on numeric data. We find that using a\ntext-to-speech system to generate additional numeric training data, as well as\nusing a small-footprint neural network to perform spoken-to-written domain\ndenorming, yields improvement in several numeric classes. In the case of the\nlongest numeric sequences, we see reduction of WER by up to a factor of 8.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jul 2019 14:21:09 GMT"}], "update_date": "2019-07-03", "authors_parsed": [["Peyser", "Cal", ""], ["Zhang", "Hao", ""], ["Sainath", "Tara N.", ""], ["Wu", "Zelin", ""]]}, {"id": "1907.01377", "submitter": "Tak Ming Wong", "authors": "Tak Ming Wong, Matthias Kahl, Peter Haring Bol\\'ivar, Andreas Kolb,\n  Michael M\\\"oller", "title": "Training Auto-encoder-based Optimizers for Terahertz Image\n  Reconstruction", "comments": "This is a pre-print of a conference paper published in German\n  Conference on Pattern Recognition (GCPR) 2019", "journal-ref": "Pattern Recognition. DAGM GCPR 2019. Lecture Notes in Computer\n  Science, vol 11824. Springer, Cham", "doi": "10.1007/978-3-030-33676-9_7", "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Terahertz (THz) sensing is a promising imaging technology for a wide variety\nof different applications. Extracting the interpretable and physically\nmeaningful parameters for such applications, however, requires solving an\ninverse problem in which a model function determined by these parameters needs\nto be fitted to the measured data. Since the underlying optimization problem is\nnonconvex and very costly to solve, we propose learning the prediction of\nsuitable parameters from the measured data directly. More precisely, we develop\na model-based autoencoder in which the encoder network predicts suitable\nparameters and the decoder is fixed to a physically meaningful model function,\nsuch that we can train the encoding network in an unsupervised way. We\nillustrate numerically that the resulting network is more than 140 times faster\nthan classical optimization techniques while making predictions with only\nslightly higher objective values. Using such predictions as starting points of\nlocal optimization techniques allows us to converge to better local minima\nabout twice as fast as optimization without the network-based initialization.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jul 2019 14:01:35 GMT"}, {"version": "v2", "created": "Tue, 29 Oct 2019 11:56:05 GMT"}], "update_date": "2019-10-30", "authors_parsed": [["Wong", "Tak Ming", ""], ["Kahl", "Matthias", ""], ["Bol\u00edvar", "Peter Haring", ""], ["Kolb", "Andreas", ""], ["M\u00f6ller", "Michael", ""]]}, {"id": "1907.01385", "submitter": "Yue Xu", "authors": "Yue Xu, Zengde Deng, Mengdi Wang, Wenjun Xu, Anthony Man-Cho So,\n  Shuguang Cui", "title": "Voting-Based Multi-Agent Reinforcement Learning for Intelligent IoT", "comments": "Published at IEEE Internet of Things Journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent success of single-agent reinforcement learning (RL) in Internet of\nthings (IoT) systems motivates the study of multi-agent reinforcement learning\n(MARL), which is more challenging but more useful in large-scale IoT. In this\npaper, we consider a voting-based MARL problem, in which the agents vote to\nmake group decisions and the goal is to maximize the globally averaged returns.\nTo this end, we formulate the MARL problem based on the linear programming form\nof the policy optimization problem and propose a distributed primal-dual\nalgorithm to obtain the optimal solution. We also propose a voting mechanism\nthrough which the distributed learning achieves the same sublinear convergence\nrate as centralized learning. In other words, the distributed decision making\ndoes not slow down the process of achieving global consensus on optimality.\nLastly, we verify the convergence of our proposed algorithm with numerical\nsimulations and conduct case studies in practical multi-agent IoT systems.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jul 2019 14:12:51 GMT"}, {"version": "v2", "created": "Mon, 2 Mar 2020 09:52:36 GMT"}, {"version": "v3", "created": "Sat, 29 Aug 2020 09:37:42 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Xu", "Yue", ""], ["Deng", "Zengde", ""], ["Wang", "Mengdi", ""], ["Xu", "Wenjun", ""], ["So", "Anthony Man-Cho", ""], ["Cui", "Shuguang", ""]]}, {"id": "1907.01399", "submitter": "Santiago L\\'opez-Tapia", "authors": "Santiago L\\'opez-Tapia and Alice Lucas and Rafael Molina and Aggelos\n  K. Katsaggelos", "title": "A Single Video Super-Resolution GAN for Multiple Downsampling Operators\n  based on Pseudo-Inverse Image Formation Models", "comments": null, "journal-ref": null, "doi": "10.1016/j.dsp.2020.102801", "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The popularity of high and ultra-high definition displays has led to the need\nfor methods to improve the quality of videos already obtained at much lower\nresolutions. Current Video Super-Resolution methods are not robust to mismatch\nbetween training and testing degradation models since they are trained against\na single degradation model (usually bicubic downsampling). This causes their\nperformance to deteriorate in real-life applications. At the same time, the use\nof only the Mean Squared Error during learning causes the resulting images to\nbe too smooth. In this work we propose a new Convolutional Neural Network for\nvideo super resolution which is robust to multiple degradation models. During\ntraining, which is performed on a large dataset of scenes with slow and fast\nmotions, it uses the pseudo-inverse image formation model as part of the\nnetwork architecture in conjunction with perceptual losses, in addition to a\nsmoothness constraint that eliminates the artifacts originating from these\nperceptual losses. The experimental validation shows that our approach\noutperforms current state-of-the-art methods and is robust to multiple\ndegradations.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jul 2019 14:28:27 GMT"}], "update_date": "2020-10-26", "authors_parsed": [["L\u00f3pez-Tapia", "Santiago", ""], ["Lucas", "Alice", ""], ["Molina", "Rafael", ""], ["Katsaggelos", "Aggelos K.", ""]]}, {"id": "1907.01405", "submitter": "Xingyu Li", "authors": "Xingyu Li, Mainak Mitra, Bogdan I. Epureanu", "title": "Analysis of the Synergy between Modularity and Autonomy in an Artificial\n  Intelligence Based Fleet Competition", "comments": "4 pages, 4 figures, 2019 NDIA Ground Vehicle Systems Engineering and\n  Technology Symposium", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A novel approach is provided for evaluating the benefits and burdens from\nvehicle modularity in fleets/units through the analysis of a game theoretical\nmodel of the competition between autonomous vehicle fleets in an\nattacker-defender game. We present an approach to obtain the heuristic\noperational strategies through fitting a decision tree on high-fidelity\nsimulation results of an intelligent agent-based model. A multi-stage game\ntheoretical model is also created for decision making considering military\nresources and impacts of past decisions. Nash equilibria of the operational\nstrategy are revealed, and their characteristics are explored. The benefits of\nfleet modularity are also analyzed by comparing the results of the decision\nmaking process under diverse operational situations.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jul 2019 14:34:30 GMT"}], "update_date": "2019-07-03", "authors_parsed": [["Li", "Xingyu", ""], ["Mitra", "Mainak", ""], ["Epureanu", "Bogdan I.", ""]]}, {"id": "1907.01406", "submitter": "Jwala Dhamala", "authors": "Jwala Dhamala, Sandesh Ghimire, John L. Sapp, B. Milan Horacek, Linwei\n  Wang", "title": "Bayesian Optimization on Large Graphs via a Graph Convolutional\n  Generative Model: Application in Cardiac Model Personalization", "comments": "9 pages, 5 figures, MICCAI", "journal-ref": null, "doi": "10.1007/978-3-030-32245-8_51", "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Personalization of cardiac models involves the optimization of organ tissue\nproperties that vary spatially over the non-Euclidean geometry model of the\nheart. To represent the high-dimensional (HD) unknown of tissue properties,\nmost existing works rely on a low-dimensional (LD) partitioning of the\ngeometrical model. While this exploits the geometry of the heart, it is of\nlimited expressiveness to allow partitioning that is small enough for effective\noptimization. Recently, a variational auto-encoder (VAE) was utilized as a more\nexpressive generative model to embed the HD optimization into the LD latent\nspace. Its Euclidean nature, however, neglects the rich geometrical information\nin the heart. In this paper, we present a novel graph convolutional VAE to\nallow generative modeling of non-Euclidean data, and utilize it to embed\nBayesian optimization of large graphs into a small latent space. This approach\nbridges the gap of previous works by introducing an expressive generative model\nthat is able to incorporate the knowledge of spatial proximity and hierarchical\ncompositionality of the underlying geometry. It further allows transferring of\nthe learned features across different geometries, which was not possible with a\nregular VAE. We demonstrate these benefits of the presented method in synthetic\nand real data experiments of estimating tissue excitability in a cardiac\nelectrophysiological model.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jul 2019 17:47:21 GMT"}, {"version": "v2", "created": "Mon, 18 May 2020 16:01:35 GMT"}], "update_date": "2020-06-04", "authors_parsed": [["Dhamala", "Jwala", ""], ["Ghimire", "Sandesh", ""], ["Sapp", "John L.", ""], ["Horacek", "B. Milan", ""], ["Wang", "Linwei", ""]]}, {"id": "1907.01409", "submitter": "Wilfried Michel", "authors": "Wilfried Michel, Ralf Schl\\\"uter, Hermann Ney", "title": "Comparison of Lattice-Free and Lattice-Based Sequence Discriminative\n  Training Criteria for LVCSR", "comments": "Submitted to Interspeech 2019", "journal-ref": "Interspeech 2019, 20th Annual Conference of the International\n  Speech Communication Association, Graz, Austria, 15-19 September 2019, pp.\n  1601--1605", "doi": "10.21437/Interspeech.2019-2254", "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sequence discriminative training criteria have long been a standard tool in\nautomatic speech recognition for improving the performance of acoustic models\nover their maximum likelihood / cross entropy trained counterparts. While\npreviously a lattice approximation of the search space has been necessary to\nreduce computational complexity, recently proposed methods use other\napproximations to dispense of the need for the computationally expensive step\nof separate lattice creation.\n  In this work we present a memory efficient implementation of the\nforward-backward computation that allows us to use uni-gram word-level language\nmodels in the denominator calculation while still doing a full summation on\nGPU. This allows for a direct comparison of lattice-based and lattice-free\nsequence discriminative training criteria such as MMI and sMBR, both using the\nsame language model during training.\n  We compared performance, speed of convergence, and stability on large\nvocabulary continuous speech recognition tasks like Switchboard and Quaero. We\nfound that silence modeling seriously impacts the performance in the\nlattice-free case and needs special treatment. In our experiments lattice-free\nMMI comes on par with its lattice-based counterpart. Lattice-based sMBR still\noutperforms all lattice-free training criteria.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jul 2019 15:16:04 GMT"}], "update_date": "2020-05-21", "authors_parsed": [["Michel", "Wilfried", ""], ["Schl\u00fcter", "Ralf", ""], ["Ney", "Hermann", ""]]}, {"id": "1907.01413", "submitter": "Sam Ribeiro", "authors": "Manuel Sam Ribeiro, Aciel Eshky, Korin Richmond and Steve Renals", "title": "Speaker-independent classification of phonetic segments from raw\n  ultrasound in child speech", "comments": "5 pages, 4 figures, published in ICASSP2019 (IEEE International\n  Conference on Acoustics, Speech and Signal Processing, 2019)", "journal-ref": null, "doi": "10.1109/ICASSP.2019.8683564", "report-no": null, "categories": "eess.AS cs.CL cs.CV cs.LG cs.SD eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ultrasound tongue imaging (UTI) provides a convenient way to visualize the\nvocal tract during speech production. UTI is increasingly being used for speech\ntherapy, making it important to develop automatic methods to assist various\ntime-consuming manual tasks currently performed by speech therapists. A key\nchallenge is to generalize the automatic processing of ultrasound tongue images\nto previously unseen speakers. In this work, we investigate the classification\nof phonetic segments (tongue shapes) from raw ultrasound recordings under\nseveral training scenarios: speaker-dependent, multi-speaker,\nspeaker-independent, and speaker-adapted. We observe that models underperform\nwhen applied to data from speakers not seen at training time. However, when\nprovided with minimal additional speaker information, such as the mean\nultrasound frame, the models generalize better to unseen speakers.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jul 2019 12:04:13 GMT"}], "update_date": "2019-07-03", "authors_parsed": [["Ribeiro", "Manuel Sam", ""], ["Eshky", "Aciel", ""], ["Richmond", "Korin", ""], ["Renals", "Steve", ""]]}, {"id": "1907.01421", "submitter": "Mark Scanlon", "authors": "Xiaoyu Du and Mark Scanlon", "title": "Methodology for the Automated Metadata-Based Classification of\n  Incriminating Digital Forensic Artefacts", "comments": null, "journal-ref": "14th International Conference on Availability, Reliability and\n  Security (ARES 2019), Canterbury, UK, August 2019", "doi": "10.1145/3339252.3340517", "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ever increasing volume of data in digital forensic investigation is one\nof the most discussed challenges in the field. Usually, most of the file\nartefacts on seized devices are not pertinent to the investigation. Manually\nretrieving suspicious files relevant to the investigation is akin to finding a\nneedle in a haystack. In this paper, a methodology for the automatic\nprioritisation of suspicious file artefacts (i.e., file artefacts that are\npertinent to the investigation) is proposed to reduce the manual analysis\neffort required. This methodology is designed to work in a human-in-the-loop\nfashion. In other words, it predicts/recommends that an artefact is likely to\nbe suspicious rather than giving the final analysis result. A supervised\nmachine learning approach is employed, which leverages the recorded results of\npreviously processed cases. The process of features extraction, dataset\ngeneration, training and evaluation are presented in this paper. In addition, a\ntoolkit for data extraction from disk images is outlined, which enables this\nmethod to be integrated with the conventional investigation process and work in\nan automated fashion.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jul 2019 14:58:24 GMT"}], "update_date": "2019-07-03", "authors_parsed": [["Du", "Xiaoyu", ""], ["Scanlon", "Mark", ""]]}, {"id": "1907.01427", "submitter": "Mark Scanlon", "authors": "Felix Anda, David Lillis, Aikaterini Kanta, Brett A. Becker, Elias\n  Bou-Harb, Nhien-An Le-Khac, Mark Scanlon", "title": "Improving Borderline Adulthood Facial Age Estimation through Ensemble\n  Learning", "comments": null, "journal-ref": "14th International Conference on Availability, Reliability and\n  Security (ARES 2019), Canterbury, UK, August 2019", "doi": "10.1145/3339252.3341491", "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Achieving high performance for facial age estimation with subjects in the\nborderline between adulthood and non-adulthood has always been a challenge.\nSeveral studies have used different approaches from the age of a baby to an\nelder adult and different datasets have been employed to measure the mean\nabsolute error (MAE) ranging between 1.47 to 8 years. The weakness of the\nalgorithms specifically in the borderline has been a motivation for this paper.\nIn our approach, we have developed an ensemble technique that improves the\naccuracy of underage estimation in conjunction with our deep learning model\n(DS13K) that has been fine-tuned on the Deep Expectation (DEX) model. We have\nachieved an accuracy of 68% for the age group 16 to 17 years old, which is 4\ntimes better than the DEX accuracy for such age range. We also present an\nevaluation of existing cloud-based and offline facial age prediction services,\nsuch as Amazon Rekognition, Microsoft Azure Cognitive Services, How-Old.net and\nDEX.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jul 2019 15:05:24 GMT"}], "update_date": "2019-07-03", "authors_parsed": [["Anda", "Felix", ""], ["Lillis", "David", ""], ["Kanta", "Aikaterini", ""], ["Becker", "Brett A.", ""], ["Bou-Harb", "Elias", ""], ["Le-Khac", "Nhien-An", ""], ["Scanlon", "Mark", ""]]}, {"id": "1907.01430", "submitter": "David V\\'azquez", "authors": "Issam H. Laradji, David Vazquez, Mark Schmidt", "title": "Where are the Masks: Instance Segmentation with Image-level Supervision", "comments": "Accepted at BMVC2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A major obstacle in instance segmentation is that existing methods often need\nmany per-pixel labels in order to be effective. These labels require large\nhuman effort and for certain applications, such labels are not readily\navailable. To address this limitation, we propose a novel framework that can\neffectively train with image-level labels, which are significantly cheaper to\nacquire. For instance, one can do an internet search for the term \"car\" and\nobtain many images where a car is present with minimal effort. Our framework\nconsists of two stages: (1) train a classifier to generate pseudo masks for the\nobjects of interest; (2) train a fully supervised Mask R-CNN on these pseudo\nmasks. Our two main contribution are proposing a pipeline that is simple to\nimplement and is amenable to different segmentation methods; and achieves new\nstate-of-the-art results for this problem setup. Our results are based on\nevaluating our method on PASCAL VOC 2012, a standard dataset for weakly\nsupervised methods, where we demonstrate major performance gains compared to\nexisting methods with respect to mean average precision.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jul 2019 15:12:20 GMT"}], "update_date": "2019-07-03", "authors_parsed": [["Laradji", "Issam H.", ""], ["Vazquez", "David", ""], ["Schmidt", "Mark", ""]]}, {"id": "1907.01433", "submitter": "Alaa Maalouf", "authors": "Alaa Maalouf, Adiel Statman, Dan Feldman", "title": "Tight Sensitivity Bounds For Smaller Coresets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An $\\varepsilon$-coreset for Least-Mean-Squares (LMS) of a matrix\n$A\\in{\\mathbb{R}}^{n\\times d}$ is a small weighted subset of its rows that\napproximates the sum of squared distances from its rows to every affine\n$k$-dimensional subspace of ${\\mathbb{R}}^d$, up to a factor of\n$1\\pm\\varepsilon$.\n  Such coresets are useful for hyper-parameter tuning and solving many\nleast-mean-squares problems such as low-rank approximation ($k$-SVD), $k$-PCA,\nLassso/Ridge/Linear regression and many more. Coresets are also useful for\nhandling streaming, dynamic and distributed big data in parallel. With high\nprobability, non-uniform sampling based on upper bounds on what is known as\nimportance or sensitivity of each row in $A$ yields a coreset. The size of the\n(sampled) coreset is then near-linear in the total sum of these sensitivity\nbounds.\n  We provide algorithms that compute provably \\emph{tight} bounds for the\nsensitivity of each input row.\n  It is based on two ingredients: (i) iterative algorithm that computes the\nexact sensitivity of each point up to arbitrary small precision for\n(non-affine) $k$-subspaces, and (ii) a general reduction of independent\ninterest from computing sensitivity for the family of affine $k$-subspaces in\n${\\mathbb{R}}^d$ to (non-affine) $(k+1)$- subspaces in ${\\mathbb{R}}^{d+1}$.\n  Experimental results on real-world datasets, including the English Wikipedia\ndocuments-term matrix, show that our bounds provide significantly smaller and\ndata-dependent coresets also in practice. Full open source is also provided.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jul 2019 15:19:37 GMT"}], "update_date": "2019-07-03", "authors_parsed": [["Maalouf", "Alaa", ""], ["Statman", "Adiel", ""], ["Feldman", "Dan", ""]]}, {"id": "1907.01439", "submitter": "Preethi Lahoti", "authors": "Preethi Lahoti, Krishna P. Gummadi, and Gerhard Weikum", "title": "Operationalizing Individual Fairness with Pairwise Fair Representations", "comments": "To be published in the proceedings of the VLDB Endowment, Vol. 13,\n  Issue. 4", "journal-ref": null, "doi": "10.14778/3372716.3372723", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We revisit the notion of individual fairness proposed by Dwork et al. A\ncentral challenge in operationalizing their approach is the difficulty in\neliciting a human specification of a similarity metric. In this paper, we\npropose an operationalization of individual fairness that does not rely on a\nhuman specification of a distance metric. Instead, we propose novel approaches\nto elicit and leverage side-information on equally deserving individuals to\ncounter subordination between social groups. We model this knowledge as a\nfairness graph, and learn a unified Pairwise Fair Representation (PFR) of the\ndata that captures both data-driven similarity between individuals and the\npairwise side-information in fairness graph. We elicit fairness judgments from\na variety of sources, including human judgments for two real-world datasets on\nrecidivism prediction (COMPAS) and violent neighborhood prediction (Crime &\nCommunities). Our experiments show that the PFR model for operationalizing\nindividual fairness is practically viable.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jul 2019 15:23:01 GMT"}, {"version": "v2", "created": "Mon, 2 Dec 2019 03:59:45 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Lahoti", "Preethi", ""], ["Gummadi", "Krishna P.", ""], ["Weikum", "Gerhard", ""]]}, {"id": "1907.01463", "submitter": "Matthew McDermott", "authors": "Matthew B.A. McDermott (1), Shirly Wang (2), Nikki Marinsek (3),\n  Rajesh Ranganath (4), Marzyeh Ghassemi (2 and 5), Luca Foschini (3) ((1)\n  Massachusetts Institute of Technology, (2) University of Toronto, (3)\n  Evidation Health, Inc., (4) New York University, (5) Vector Institute)", "title": "Reproducibility in Machine Learning for Health", "comments": "Presented at the ICLR 2019 Reproducibility in Machine Learning\n  Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning algorithms designed to characterize, monitor, and intervene\non human health (ML4H) are expected to perform safely and reliably when\noperating at scale, potentially outside strict human supervision. This\nrequirement warrants a stricter attention to issues of reproducibility than\nother fields of machine learning.\n  In this work, we conduct a systematic evaluation of over 100 recently\npublished ML4H research papers along several dimensions related to\nreproducibility. We find that the field of ML4H compares poorly to more\nestablished machine learning fields, particularly concerning data and code\naccessibility. Finally, drawing from success in other fields of science, we\npropose recommendations to data providers, academic publishers, and the ML4H\nresearch community in order to promote reproducible research moving forward.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jul 2019 15:46:46 GMT"}], "update_date": "2019-07-03", "authors_parsed": [["McDermott", "Matthew B. A.", "", "2 and 5"], ["Wang", "Shirly", "", "2 and 5"], ["Marinsek", "Nikki", "", "2 and 5"], ["Ranganath", "Rajesh", "", "2 and 5"], ["Ghassemi", "Marzyeh", "", "2 and 5"], ["Foschini", "Luca", ""]]}, {"id": "1907.01470", "submitter": "Sainbayar Sukhbaatar", "authors": "Sainbayar Sukhbaatar, Edouard Grave, Guillaume Lample, Herve Jegou,\n  Armand Joulin", "title": "Augmenting Self-attention with Persistent Memory", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transformer networks have lead to important progress in language modeling and\nmachine translation. These models include two consecutive modules, a\nfeed-forward layer and a self-attention layer. The latter allows the network to\ncapture long term dependencies and are often regarded as the key ingredient in\nthe success of Transformers. Building upon this intuition, we propose a new\nmodel that solely consists of attention layers. More precisely, we augment the\nself-attention layers with persistent memory vectors that play a similar role\nas the feed-forward layer. Thanks to these vectors, we can remove the\nfeed-forward layer without degrading the performance of a transformer. Our\nevaluation shows the benefits brought by our model on standard character and\nword level language modeling benchmarks.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jul 2019 15:56:20 GMT"}], "update_date": "2019-07-03", "authors_parsed": [["Sukhbaatar", "Sainbayar", ""], ["Grave", "Edouard", ""], ["Lample", "Guillaume", ""], ["Jegou", "Herve", ""], ["Joulin", "Armand", ""]]}, {"id": "1907.01475", "submitter": "Zachary Kenton", "authors": "Zachary Kenton, Angelos Filos, Owain Evans, Yarin Gal", "title": "Generalizing from a few environments in safety-critical reinforcement\n  learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Before deploying autonomous agents in the real world, we need to be confident\nthey will perform safely in novel situations. Ideally, we would expose agents\nto a very wide range of situations during training, allowing them to learn\nabout every possible danger, but this is often impractical. This paper\ninvestigates safety and generalization from a limited number of training\nenvironments in deep reinforcement learning (RL). We find RL algorithms can\nfail dangerously on unseen test environments even when performing perfectly on\ntraining environments. Firstly, in a gridworld setting, we show that\ncatastrophes can be significantly reduced with simple modifications, including\nensemble model averaging and the use of a blocking classifier. In the more\nchallenging CoinRun environment we find similar methods do not significantly\nreduce catastrophes. However, we do find that the uncertainty information from\nthe ensemble is useful for predicting whether a catastrophe will occur within a\nfew steps and hence whether human intervention should be requested.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jul 2019 16:12:34 GMT"}], "update_date": "2019-07-03", "authors_parsed": [["Kenton", "Zachary", ""], ["Filos", "Angelos", ""], ["Evans", "Owain", ""], ["Gal", "Yarin", ""]]}, {"id": "1907.01478", "submitter": "Canwen Xu", "authors": "Canwen Xu, Zhenzhong Chen, Chenliang Li", "title": "Obj-GloVe: Scene-Based Contextual Object Embedding", "comments": "14 pages; not the final version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, with the prevalence of large-scale image dataset, the co-occurrence\ninformation among classes becomes rich, calling for a new way to exploit it to\nfacilitate inference. In this paper, we propose Obj-GloVe, a generic\nscene-based contextual embedding for common visual objects, where we adopt the\nword embedding method GloVe to exploit the co-occurrence between entities. We\ntrain the embedding on pre-processed Open Images V4 dataset and provide\nextensive visualization and analysis by dimensionality reduction and projecting\nthe vectors along a specific semantic axis, and showcasing the nearest\nneighbors of the most common objects. Furthermore, we reveal the potential\napplications of Obj-GloVe on object detection and text-to-image synthesis, then\nverify its effectiveness on these two applications respectively.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jul 2019 16:29:02 GMT"}], "update_date": "2019-07-03", "authors_parsed": [["Xu", "Canwen", ""], ["Chen", "Zhenzhong", ""], ["Li", "Chenliang", ""]]}, {"id": "1907.01490", "submitter": "Jan N. Fuhg", "authors": "Jan N. Fuhg and Amelie Fau", "title": "An innovative adaptive kriging approach for efficient binary\n  classification of mechanical problems", "comments": "62 pages, 26 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Kriging is an efficient machine-learning tool, which allows to obtain an\napproximate response of an investigated phenomenon on the whole parametric\nspace. Adaptive schemes provide a the ability to guide the experiment yielding\nnew sample point positions to enrich the metamodel. Herein a novel adaptive\nscheme called Monte Carlo-intersite Voronoi (MiVor) is proposed to efficiently\nidentify binary decision regions on the basis of a regression surrogate model.\nThe performance of the innovative approach is tested for analytical functions\nas well as some mechanical problems and is furthermore compared to two\nregression-based adaptive schemes. For smooth problems, all three methods have\ncomparable performances. For highly fluctuating response surface as encountered\ne.g. for dynamics or damage problems, the innovative MiVor algorithm performs\nvery well and provides accurate binary classification with only a few\nobservation points.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jul 2019 16:51:40 GMT"}], "update_date": "2019-07-03", "authors_parsed": [["Fuhg", "Jan N.", ""], ["Fau", "Amelie", ""]]}, {"id": "1907.01497", "submitter": "Alan Richardson", "authors": "Alan Richardson, Caelen Feller", "title": "Seismic data denoising and deblending using deep learning", "comments": "17 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG physics.comp-ph physics.geo-ph", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  An important step of seismic data processing is removing noise, including\ninterference due to simultaneous and blended sources, from the recorded data.\nTraditional methods are time-consuming to apply as they often require manual\nchoosing of parameters to obtain good results. We use deep learning, with a\nU-net model incorporating a ResNet architecture pretrained on ImageNet and\nfurther trained on synthetic seismic data, to perform this task. The method is\napplied to common offset gathers, with adjacent offset gathers of the gather\nbeing denoised provided as additional input channels. Here we show that this\napproach leads to a method that removes noise from several datasets recorded in\ndifferent parts of the world with moderate success. We find that providing\nthree adjacent offset gathers on either side of the gather being denoised is\nmost effective. As this method does not require parameters to be chosen, it is\nmore automated than traditional methods.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jul 2019 17:02:53 GMT"}], "update_date": "2019-07-03", "authors_parsed": [["Richardson", "Alan", ""], ["Feller", "Caelen", ""]]}, {"id": "1907.01507", "submitter": "Lek-Heng Lim", "authors": "Lek-Heng Lim, Mateusz Michalek, Yang Qi", "title": "Best k-layer neural network approximations", "comments": "19 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that the empirical risk minimization (ERM) problem for neural\nnetworks has no solution in general. Given a training set $s_1, \\dots, s_n \\in\n\\mathbb{R}^p$ with corresponding responses $t_1,\\dots,t_n \\in \\mathbb{R}^q$,\nfitting a $k$-layer neural network $\\nu_\\theta : \\mathbb{R}^p \\to \\mathbb{R}^q$\ninvolves estimation of the weights $\\theta \\in \\mathbb{R}^m$ via an ERM: \\[\n\\inf_{\\theta \\in \\mathbb{R}^m} \\; \\sum_{i=1}^n \\lVert t_i - \\nu_\\theta(s_i)\n\\rVert_2^2. \\] We show that even for $k = 2$, this infimum is not attainable in\ngeneral for common activations like ReLU, hyperbolic tangent, and sigmoid\nfunctions. A high-level explanation is like that for the nonexistence of best\nrank-$r$ approximations of higher-order tensors --- the set of parameters is\nnot a closed set --- but the geometry involved for best $k$-layer neural\nnetworks approximations is more subtle. In addition, we show that for smooth\nactivations $\\sigma(x)= 1/\\bigl(1 + \\exp(-x)\\bigr)$ and $\\sigma(x)=\\tanh(x)$,\nsuch failure to attain an infimum can happen on a positive-measured subset of\nresponses. For the ReLU activation $\\sigma(x)=\\max(0,x)$, we completely\nclassifying cases where the ERM for a best two-layer neural network\napproximation attains its infimum. As an aside, we obtain a precise description\nof the geometry of the space of two-layer neural networks with $d$ neurons in\nthe hidden layer: it is the join locus of a line and the $d$-secant locus of a\ncone.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jul 2019 17:16:54 GMT"}, {"version": "v2", "created": "Wed, 11 Dec 2019 20:23:21 GMT"}], "update_date": "2019-12-13", "authors_parsed": [["Lim", "Lek-Heng", ""], ["Michalek", "Mateusz", ""], ["Qi", "Yang", ""]]}, {"id": "1907.01512", "submitter": "Ori Shental", "authors": "Ori Shental and Jakob Hoydis", "title": "\"Machine LLRning\": Learning to Softly Demodulate", "comments": "Published version, Globecom 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Soft demodulation, or demapping, of received symbols back into their conveyed\nsoft bits, or bit log-likelihood ratios (LLRs), is at the very heart of any\nmodern receiver. In this paper, a trainable universal neural network-based\ndemodulator architecture, dubbed \"LLRnet\", is introduced. LLRnet facilitates an\nimproved performance with significantly reduced overall computational\ncomplexity. For instance for the commonly used quadrature amplitude modulation\n(QAM), LLRnet demonstrates LLR estimates approaching the optimal log maximum\na-posteriori inference with an order of magnitude less operations than that of\nthe straightforward exact implementation. Link-level simulation examples for\nthe application of LLRnet to 5G-NR and DVB-S.2 are provided. LLRnet is a (yet\nanother) powerful example for the usefulness of applying machine learning to\nphysical layer design.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jul 2019 17:23:01 GMT"}, {"version": "v2", "created": "Fri, 5 Jul 2019 16:29:28 GMT"}, {"version": "v3", "created": "Fri, 20 Mar 2020 01:30:17 GMT"}], "update_date": "2020-03-23", "authors_parsed": [["Shental", "Ori", ""], ["Hoydis", "Jakob", ""]]}, {"id": "1907.01513", "submitter": "Ricard Delgado-Gonzalo", "authors": "J\\'er\\^ome Van Zaen, Olivier Ch\\'etelat, Mathieu Lemay, Enric M.\n  Calvo, Ricard Delgado-Gonzalo", "title": "Classification of Cardiac Arrhythmias from Single Lead ECG with a\n  Convolutional Recurrent Neural Network", "comments": "Nominated to best paper award", "journal-ref": null, "doi": "10.5220/0007347900330041", "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While most heart arrhythmias are not immediately harmful, they can lead to\nsevere complications. In particular, atrial fibrillation, the most common\narrhythmia, is characterized by fast and irregular heart beats and increases\nthe risk of suffering a stroke. To detect such abnormal heart conditions, we\npropose a system composed of two main parts: a smart vest with two cooperative\nsensors to collect ECG data and a neural network architecture to classify heart\nrhythms. The smart vest uses two dry bi-electrodes to record a single lead ECG\nsignal. The biopotential signal is then streamed via a gateway to the cloud\nwhere a neural network detects and classifies the heart arrhythmias. We\nselected an architecture that combines convolutional and recurrent layers. The\nconvolutional layers extract relevant features from sliding windows of ECG and\nthe recurrent layer aggregates them for a final softmax layer that performs the\nclassification. Our neural network achieves an accuracy of 87.50% on the\ndataset of the challenge of Computing in Cardiology 2017.\n", "versions": [{"version": "v1", "created": "Tue, 25 Jun 2019 05:41:44 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["Van Zaen", "J\u00e9r\u00f4me", ""], ["Ch\u00e9telat", "Olivier", ""], ["Lemay", "Mathieu", ""], ["Calvo", "Enric M.", ""], ["Delgado-Gonzalo", "Ricard", ""]]}, {"id": "1907.01515", "submitter": "Yasith Jayawardana", "authors": "Yasith Jayawardana, Mark Jaime, Sashi Thapaliya, Sampath Jayarathna", "title": "Electroencephalogram (EEG) for Delineating Objective Measure of Autism\n  Spectrum Disorder (ASD) (Extended Version)", "comments": null, "journal-ref": null, "doi": "10.4018/978-1-5225-7467-5.ch002", "report-no": null, "categories": "eess.SP cs.IR cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autism Spectrum Disorder (ASD) is a developmental disorder that often impairs\na child's normal development of the brain. According to CDC, it is estimated\nthat 1 in 6 children in the US suffer from development disorders, and 1 in 68\nchildren in the US suffer from ASD. This condition has a negative impact on a\nperson's ability to hear, socialize and communicate. Overall, ASD has a broad\nrange of symptoms and severity; hence the term spectrum is used. One of the\nmain contributors to ASD is known to be genetics. Up to date, no suitable cure\nfor ASD has been found. Early diagnosis is crucial for the long-term treatment\nof ASD, but this is challenging due to the lack of a proper objective measures.\nSubjective measures often take more time, resources, and have false positives\nor false negatives. There is a need for efficient objective measures that can\nhelp in diagnosing this disease early as possible with less effort.\n  EEG measures the electric signals of the brain via electrodes placed on\nvarious places on the scalp. These signals can be used to study complex\nneuropsychiatric issues. Studies have shown that EEG has the potential to be\nused as a biomarker for various neurological conditions including ASD. This\nchapter will outline the usage of EEG measurement for the classification of ASD\nusing machine learning algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 26 Jun 2019 01:13:21 GMT"}], "update_date": "2019-07-03", "authors_parsed": [["Jayawardana", "Yasith", ""], ["Jaime", "Mark", ""], ["Thapaliya", "Sashi", ""], ["Jayarathna", "Sampath", ""]]}, {"id": "1907.01516", "submitter": "Zhou Zhou", "authors": "Zhou Zhou, Lingjia Liu, Hao-Hsuan Chang", "title": "Learning for Detection: MIMO-OFDM Symbol Detection through Downlink\n  Pilots", "comments": null, "journal-ref": null, "doi": "10.1109/TWC.2020.2976004", "report-no": null, "categories": "eess.SP cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reservoir computing (RC) is a special recurrent neural network which consists\nof a fixed high dimensional feature mapping and trained readout weights. In\nthis paper, we introduce a new RC structure for multiple-input, multiple-output\northogonal frequency-division multiplexing (MIMO-OFDM) symbol detection, namely\nwindowed echo state network (WESN). The theoretical analysis shows that adding\nbuffers in input layers can bring an enhanced short-term memory (STM) to the\nunderlying neural network. Furthermore, a unified training framework is\ndeveloped for the WESN MIMO-OFDM symbol detector using both comb and scattered\npilot patterns that are compatible with the structure adopted in 3GPP\nLTE/LTE-Advanced systems. Complexity analysis suggests the advantages of WESN\nbased symbol detector over state-of-the-art symbol detectors such as the linear\nminimum mean square error (LMMSE) detection and the sphere decoder, when the\nsystem is employed with a large number of OFDM sub-carriers. Numerical\nevaluations illustrate the advantage of the introduced WESN-based symbol\ndetector and demonstrate that the improvement of STM can significantly improve\nsymbol detection performance as well as effectively mitigate model mismatch\neffects compared to existing methods.\n", "versions": [{"version": "v1", "created": "Tue, 25 Jun 2019 19:35:58 GMT"}, {"version": "v2", "created": "Sun, 20 Oct 2019 23:58:53 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Zhou", "Zhou", ""], ["Liu", "Lingjia", ""], ["Chang", "Hao-Hsuan", ""]]}, {"id": "1907.01523", "submitter": "Changyang She", "authors": "Rui Dong and Changyang She and Wibowo Hardjawana and Yonghui Li and\n  Branka Vucetic", "title": "Deep Learning for Hybrid 5G Services in Mobile Edge Computing Systems:\n  Learn from a Digital Twin", "comments": "To appear in IEEE Trans. on Wireless Commun. (accepted with minor\n  revision)", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we consider a mobile edge computing system with both\nultra-reliable and low-latency communications services and delay tolerant\nservices. We aim to minimize the normalized energy consumption, defined as the\nenergy consumption per bit, by optimizing user association, resource\nallocation, and offloading probabilities subject to the quality-of-service\nrequirements. The user association is managed by the mobility management entity\n(MME), while resource allocation and offloading probabilities are determined by\neach access point (AP). We propose a deep learning (DL) architecture, where a\ndigital twin of the real network environment is used to train the DL algorithm\noff-line at a central server. From the pre-trained deep neural network (DNN),\nthe MME can obtain user association scheme in a real-time manner. Considering\nthat real networks are not static, the digital twin monitors the variation of\nreal networks and updates the DNN accordingly. For a given user association\nscheme, we propose an optimization algorithm to find the optimal resource\nallocation and offloading probabilities at each AP. Simulation results show\nthat our method can achieve lower normalized energy consumption with less\ncomputation complexity compared with an existing method and approach to the\nperformance of the global optimal solution.\n", "versions": [{"version": "v1", "created": "Sun, 30 Jun 2019 04:16:14 GMT"}], "update_date": "2019-07-03", "authors_parsed": [["Dong", "Rui", ""], ["She", "Changyang", ""], ["Hardjawana", "Wibowo", ""], ["Li", "Yonghui", ""], ["Vucetic", "Branka", ""]]}, {"id": "1907.01543", "submitter": "Kiran Koshy Thekumparampil", "authors": "Kiran Koshy Thekumparampil, Prateek Jain, Praneeth Netrapalli, Sewoong\n  Oh", "title": "Efficient Algorithms for Smooth Minimax Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies first order methods for solving smooth minimax\noptimization problems $\\min_x \\max_y g(x,y)$ where $g(\\cdot,\\cdot)$ is smooth\nand $g(x,\\cdot)$ is concave for each $x$. In terms of $g(\\cdot,y)$, we consider\ntwo settings -- strongly convex and nonconvex -- and improve upon the best\nknown rates in both. For strongly-convex $g(\\cdot, y),\\ \\forall y$, we propose\na new algorithm combining Mirror-Prox and Nesterov's AGD, and show that it can\nfind global optimum in $\\tilde{O}(1/k^2)$ iterations, improving over current\nstate-of-the-art rate of $O(1/k)$. We use this result along with an inexact\nproximal point method to provide $\\tilde{O}(1/k^{1/3})$ rate for finding\nstationary points in the nonconvex setting where $g(\\cdot, y)$ can be\nnonconvex. This improves over current best-known rate of $O(1/k^{1/5})$.\nFinally, we instantiate our result for finite nonconvex minimax problems, i.e.,\n$\\min_x \\max_{1\\leq i\\leq m} f_i(x)$, with nonconvex $f_i(\\cdot)$, to obtain\nconvergence rate of $O(m(\\log m)^{3/2}/k^{1/3})$ total gradient evaluations for\nfinding a stationary point.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jul 2019 17:50:34 GMT"}], "update_date": "2019-07-03", "authors_parsed": [["Thekumparampil", "Kiran Koshy", ""], ["Jain", "Prateek", ""], ["Netrapalli", "Praneeth", ""], ["Oh", "Sewoong", ""]]}, {"id": "1907.01549", "submitter": "Siddhartha Devapujula", "authors": "Siddhartha Devapujula, Sagar Arora, Sumit Borar", "title": "Learning to Rank Broad and Narrow Queries in E-Commerce", "comments": "7+1 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Search is a prominent channel for discovering products on an e-commerce\nplatform. Ranking products retrieved from search becomes crucial to address\ncustomer's need and optimize for business metrics. While learning to Rank\n(LETOR) models have been extensively studied and have demonstrated efficacy in\nthe context of web search; it is a relatively new research area to be explored\nin the e-commerce. In this paper, we present a framework for building LETOR\nmodel for an e-commerce platform. We analyze user queries and propose a\nmechanism to segment queries between broad and narrow based on user's intent.\nWe discuss different types of features - query, product and query-product and\ndiscuss challenges in using them. We show that sparsity in product features can\nbe tackled through a denoising auto-encoder while skip-gram based word\nembeddings help solve the query-product sparsity issues. We also present\nvarious target metrics that can be employed for evaluating search results and\ncompare their robustness. Further, we build and compare performances of both\npointwise and pairwise LETOR models on fashion category data set. We also build\nand compare distinct models for broad and narrow queries, analyze feature\nimportance across these and show that these specialized models perform better\nthan a combined model in the fashion world.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jul 2019 18:30:38 GMT"}, {"version": "v2", "created": "Mon, 15 Jul 2019 09:17:51 GMT"}], "update_date": "2019-07-16", "authors_parsed": [["Devapujula", "Siddhartha", ""], ["Arora", "Sagar", ""], ["Borar", "Sumit", ""]]}, {"id": "1907.01551", "submitter": "Wilkins Aquino", "authors": "Zilong Zou, Sayan Mukherjee, Harbir Antil, and Wilkins Aquino", "title": "Adaptive particle-based approximations of the Gibbs posterior for\n  inverse problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we adopt a general framework based on the Gibbs posterior to\nupdate belief distributions for inverse problems governed by partial\ndifferential equations (PDEs). The Gibbs posterior formulation is a\ngeneralization of standard Bayesian inference that only relies on a loss\nfunction connecting the unknown parameters to the data. It is particularly\nuseful when the true data generating mechanism (or noise distribution) is\nunknown or difficult to specify. The Gibbs posterior coincides with Bayesian\nupdating when a true likelihood function is known and the loss function\ncorresponds to the negative log-likelihood, yet provides subjective inference\nin more general settings.\n  We employ a sequential Monte Carlo (SMC) approach to approximate the Gibbs\nposterior using particles. To manage the computational cost of propagating\nincreasing numbers of particles through the loss function, we employ a recently\ndeveloped local reduced basis method to build an efficient surrogate loss\nfunction that is used in the Gibbs update formula in place of the true loss. We\nderive error bounds for our approximation and propose an adaptive approach to\nconstruct the surrogate model in an efficient manner. We demonstrate the\nefficiency of our approach through several numerical examples.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jul 2019 01:29:12 GMT"}], "update_date": "2019-07-04", "authors_parsed": [["Zou", "Zilong", ""], ["Mukherjee", "Sayan", ""], ["Antil", "Harbir", ""], ["Aquino", "Wilkins", ""]]}, {"id": "1907.01552", "submitter": "Shunya Okuno", "authors": "Shunya Okuno, Kazuyuki Aihara, Yoshito Hirata", "title": "Forecasting high-dimensional dynamics exploiting suboptimal embeddings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Delay embedding---a method for reconstructing dynamical systems by delay\ncoordinates---is widely used to forecast nonlinear time series as a model-free\napproach. When multivariate time series are observed, several existing\nframeworks can be applied to yield a single forecast combining multiple\nforecasts derived from various embeddings. However, the performance of these\nframeworks is not always satisfactory because they randomly select embeddings\nor use brute force and do not consider the diversity of the embeddings to\ncombine. Herein, we develop a forecasting framework that overcomes these\nexisting problems. The framework exploits various \"suboptimal embeddings\"\nobtained by minimizing the in-sample error via combinatorial optimization. The\nframework achieves the best results among existing frameworks for sample toy\ndatasets and a real-world flood dataset. We show that the framework is\napplicable to a wide range of data lengths and dimensions. Therefore, the\nframework can be applied to various fields such as neuroscience, ecology,\nfinance, fluid dynamics, weather, and disaster prevention.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jul 2019 02:14:22 GMT"}], "update_date": "2019-07-04", "authors_parsed": [["Okuno", "Shunya", ""], ["Aihara", "Kazuyuki", ""], ["Hirata", "Yoshito", ""]]}, {"id": "1907.01586", "submitter": "Rafael Dowsley", "authors": "Anisha Agarwal, Rafael Dowsley, Nicholas D. McKinney, Dongrui Wu,\n  Chin-Teng Lin, Martine De Cock, Anderson C. A. Nascimento", "title": "Protecting Privacy of Users in Brain-Computer Interface Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning (ML) is revolutionizing research and industry. Many ML\napplications rely on the use of large amounts of personal data for training and\ninference. Among the most intimate exploited data sources is\nelectroencephalogram (EEG) data, a kind of data that is so rich with\ninformation that application developers can easily gain knowledge beyond the\nprofessed scope from unprotected EEG signals, including passwords, ATM PINs,\nand other intimate data. The challenge we address is how to engage in\nmeaningful ML with EEG data while protecting the privacy of users.\n  Hence, we propose cryptographic protocols based on Secure Multiparty\nComputation (SMC) to perform linear regression over EEG signals from many users\nin a fully privacy-preserving (PP) fashion, i.e.~such that each individual's\nEEG signals are not revealed to anyone else. To illustrate the potential of our\nsecure framework, we show how it allows estimating the drowsiness of drivers\nfrom their EEG signals as would be possible in the unencrypted case, and at a\nvery reasonable computational cost. Our solution is the first application of\ncommodity-based SMC to EEG data, as well as the largest documented experiment\nof secret sharing based SMC in general, namely with 15 players involved in all\nthe computations.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jul 2019 19:03:53 GMT"}], "update_date": "2019-07-04", "authors_parsed": [["Agarwal", "Anisha", ""], ["Dowsley", "Rafael", ""], ["McKinney", "Nicholas D.", ""], ["Wu", "Dongrui", ""], ["Lin", "Chin-Teng", ""], ["De Cock", "Martine", ""], ["Nascimento", "Anderson C. A.", ""]]}, {"id": "1907.01607", "submitter": "Hsia Liang", "authors": "Xia Liang and Junmin Wu and Yan Yin", "title": "MIDI-Sandwich: Multi-model Multi-task Hierarchical Conditional VAE-GAN\n  networks for Symbolic Single-track Music Generation", "comments": "cast KSEM2019 on May 3, 2019 (weak rejected)", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.MM cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most existing neural network models for music generation explore how to\ngenerate music bars, then directly splice the music bars into a song. However,\nthese methods do not explore the relationship between the bars, and the\nconnected song as a whole has no musical form structure and sense of musical\ndirection. To address this issue, we propose a Multi-model Multi-task\nHierarchical Conditional VAE-GAN (Variational Autoencoder-Generative\nadversarial networks) networks, named MIDI-Sandwich, which combines musical\nknowledge, such as musical form, tonic, and melodic motion. The MIDI-Sandwich\nhas two submodels: Hierarchical Conditional Variational Autoencoder (HCVAE) and\nHierarchical Conditional Generative Adversarial Network (HCGAN). The HCVAE uses\nhierarchical structure. The underlying layer of HCVAE uses Local Conditional\nVariational Autoencoder (L-CVAE) to generate a music bar which is pre-specified\nby the First and Last Notes (FLN). The upper layer of HCVAE uses Global\nVariational Autoencoder(G-VAE) to analyze the latent vector sequence generated\nby the L-CVAE encoder, to explore the musical relationship between the bars,\nand to produce the song pieced together by multiple music bars generated by the\nL-CVAE decoder, which makes the song both have musical structure and sense of\ndirection. At the same time, the HCVAE shares a part of itself with the HCGAN\nto further improve the performance of the generated music. The MIDI-Sandwich is\nvalidated on the Nottingham dataset and is able to generate a single-track\nmelody sequence (17x8 beats), which is superior to the length of most of the\ngenerated models (8 to 32 beats). Meanwhile, by referring to the experimental\nmethods of many classical kinds of literature, the quality evaluation of the\ngenerated music is performed. The above experiments prove the validity of the\nmodel.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jul 2019 19:55:33 GMT"}, {"version": "v2", "created": "Thu, 4 Jul 2019 06:59:33 GMT"}], "update_date": "2019-07-05", "authors_parsed": [["Liang", "Xia", ""], ["Wu", "Junmin", ""], ["Yin", "Yan", ""]]}, {"id": "1907.01615", "submitter": "Anna Belova", "authors": "Anna Belova, Wen He, Ziyi Zhong", "title": "E-Sports Talent Scouting Based on Multimodal Twitch Stream Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose and investigate feasibility of a novel task that consists in\nfinding e-sports talent using multimodal Twitch chat and video stream data. In\nthat, we focus on predicting the ranks of Counter-Strike: Global Offensive\n(CS:GO) gamers who broadcast their games on Twitch. During January 2019-April\n2019, we have built two Twitch stream collections: One for 425 publicly ranked\nCS:GO gamers and one for 9,928 unranked CS:GO gamers. We extract neural\nfeatures from video, audio and text chat data and estimate modality-specific\nprobabilities for a gamer to be top-ranked during the data collection\ntime-frame. A hierarchical Bayesian model is then used to pool the evidence\nacross modalities and generate estimates of intrinsic skill for each gamer. Our\nmodeling is validated through correlating the intrinsic skill predictions with\nMay 2019 ranks of the publicly profiled gamers.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jul 2019 20:06:21 GMT"}], "update_date": "2019-07-04", "authors_parsed": [["Belova", "Anna", ""], ["He", "Wen", ""], ["Zhong", "Ziyi", ""]]}, {"id": "1907.01619", "submitter": "Cl\\'ement Canonne", "authors": "Cl\\'ement L. Canonne and Anindya De and Rocco A. Servedio", "title": "Learning from satisfying assignments under continuous distributions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  What kinds of functions are learnable from their satisfying assignments?\nMotivated by this simple question, we extend the framework of De, Diakonikolas,\nand Servedio [DDS15], which studied the learnability of probability\ndistributions over $\\{0,1\\}^n$ defined by the set of satisfying assignments to\n\"low-complexity\" Boolean functions, to Boolean-valued functions defined over\ncontinuous domains. In our learning scenario there is a known \"background\ndistribution\" $\\mathcal{D}$ over $\\mathbb{R}^n$ (such as a known normal\ndistribution or a known log-concave distribution) and the learner is given\ni.i.d. samples drawn from a target distribution $\\mathcal{D}_f$, where\n$\\mathcal{D}_f$ is $\\mathcal{D}$ restricted to the satisfying assignments of an\nunknown low-complexity Boolean-valued function $f$. The problem is to learn an\napproximation $\\mathcal{D}'$ of the target distribution $\\mathcal{D}_f$ which\nhas small error as measured in total variation distance.\n  We give a range of efficient algorithms and hardness results for this\nproblem, focusing on the case when $f$ is a low-degree polynomial threshold\nfunction (PTF). When the background distribution $\\mathcal{D}$ is log-concave,\nwe show that this learning problem is efficiently solvable for degree-1 PTFs\n(i.e.,~linear threshold functions) but not for degree-2 PTFs. In contrast, when\n$\\mathcal{D}$ is a normal distribution, we show that this learning problem is\nefficiently solvable for degree-2 PTFs but not for degree-4 PTFs. Our hardness\nresults rely on standard assumptions about secure signature schemes.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jul 2019 20:17:59 GMT"}], "update_date": "2019-07-04", "authors_parsed": [["Canonne", "Cl\u00e9ment L.", ""], ["De", "Anindya", ""], ["Servedio", "Rocco A.", ""]]}, {"id": "1907.01632", "submitter": "Daniel Schwalbe-Koda", "authors": "Daniel Schwalbe-Koda, Rafael G\\'omez-Bombarelli", "title": "Generative Models for Automatic Chemical Design", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-030-40245-7_21", "report-no": null, "categories": "cs.LG physics.chem-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Materials discovery is decisive for tackling urgent challenges related to\nenergy, the environment, health care and many others. In chemistry,\nconventional methodologies for innovation usually rely on expensive and\nincremental strategies to optimize properties from molecular structures. On the\nother hand, inverse approaches map properties to structures, thus expediting\nthe design of novel useful compounds. In this chapter, we examine the way in\nwhich current deep generative models are addressing the inverse chemical\ndiscovery paradigm. We begin by revisiting early inverse design algorithms.\nThen, we introduce generative models for molecular systems and categorize them\naccording to their architecture and molecular representation. Using this\nclassification, we review the evolution and performance of important molecular\ngeneration schemes reported in the literature. Finally, we conclude\nhighlighting the prospects and challenges of generative models as cutting edge\ntools in materials discovery.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jul 2019 20:57:23 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Schwalbe-Koda", "Daniel", ""], ["G\u00f3mez-Bombarelli", "Rafael", ""]]}, {"id": "1907.01636", "submitter": "Clint Pazhayidam George", "authors": "Clint P. George, Wei Xia, George Michailidis", "title": "Analyses of Multi-collection Corpora via Compound Topic Modeling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  As electronically stored data grow in daily life, obtaining novel and\nrelevant information becomes challenging in text mining. Thus people have\nsought statistical methods based on term frequency, matrix algebra, or topic\nmodeling for text mining. Popular topic models have centered on one single text\ncollection, which is deficient for comparative text analyses. We consider a\nsetting where one can partition the corpus into subcollections. Each\nsubcollection shares a common set of topics, but there exists relative\nvariation in topic proportions among collections. Including any prior knowledge\nabout the corpus (e.g. organization structure), we propose the compound latent\nDirichlet allocation (cLDA) model, improving on previous work, encouraging\ngeneralizability, and depending less on user-input parameters. To identify the\nparameters of interest in cLDA, we study Markov chain Monte Carlo (MCMC) and\nvariational inference approaches extensively, and suggest an efficient MCMC\nmethod. We evaluate cLDA qualitatively and quantitatively using both synthetic\nand real-world corpora. The usability study on some real-world corpora\nillustrates the superiority of cLDA to explore the underlying topics\nautomatically but also model their connections and variations across multiple\ncollections.\n", "versions": [{"version": "v1", "created": "Mon, 17 Jun 2019 06:59:25 GMT"}], "update_date": "2019-07-04", "authors_parsed": [["George", "Clint P.", ""], ["Xia", "Wei", ""], ["Michailidis", "George", ""]]}, {"id": "1907.01637", "submitter": "Syrine Krichene", "authors": "Syrine Krichene and Mike Gartrell and Clement Calauzenes", "title": "Embedding models for recommendation under contextual constraints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Embedding models, which learn latent representations of users and items based\non user-item interaction patterns, are a key component of recommendation\nsystems. In many applications, contextual constraints need to be applied to\nrefine recommendations, e.g. when a user specifies a price range or product\ncategory filter. The conventional approach, for both context-aware and standard\nmodels, is to retrieve items and apply the constraints as independent\noperations. The order in which these two steps are executed can induce\nsignificant problems. For example, applying constraints a posteriori can result\nin incomplete recommendations or low-quality results for the tail of the\ndistribution (i.e., less popular items). As a result, the additional\ninformation that the constraint brings about user intent may not be accurately\ncaptured.\n  In this paper we propose integrating the information provided by the\ncontextual constraint into the similarity computation, by merging constraint\napplication and retrieval into one operation in the embedding space. This\ntechnique allows us to generate high-quality recommendations for the specified\nconstraint. Our approach learns constraints representations jointly with the\nuser and item embeddings. We incorporate our methods into a matrix\nfactorization model, and perform an experimental evaluation on one internal and\ntwo real-world datasets. Our results show significant improvements in\npredictive performance compared to context-aware and standard models.\n", "versions": [{"version": "v1", "created": "Fri, 21 Jun 2019 07:59:38 GMT"}], "update_date": "2019-07-04", "authors_parsed": [["Krichene", "Syrine", ""], ["Gartrell", "Mike", ""], ["Calauzenes", "Clement", ""]]}, {"id": "1907.01639", "submitter": "Yu Zhu", "authors": "Yu Zhu, Yu Gong, Qingwen Liu, Yingcai Ma, Wenwu Ou, Junxiong Zhu,\n  Beidou Wang, Ziyu Guan, and Deng Cai", "title": "Query-based Interactive Recommendation by Meta-Path and Adapted\n  Attention-GRU", "comments": "9 pages, 6 figures, submitted to CIKM 2019 Applied Research Track", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, interactive recommender systems are becoming increasingly popular.\nThe insight is that, with the interaction between users and the system, (1)\nusers can actively intervene the recommendation results rather than passively\nreceive them, and (2) the system learns more about users so as to provide\nbetter recommendation.\n  We focus on the single-round interaction, i.e. the system asks the user a\nquestion (Step 1), and exploits his feedback to generate better recommendation\n(Step 2). A novel query-based interactive recommender system is proposed in\nthis paper, where \\textbf{personalized questions are accurately generated from\nmillions of automatically constructed questions} in Step 1, and \\textbf{the\nrecommendation is ensured to be closely-related to users' feedback} in Step 2.\nWe achieve this by transforming Step 1 into a query recommendation task and\nStep 2 into a retrieval task. The former task is our key challenge. We firstly\npropose a model based on Meta-Path to efficiently retrieve hundreds of query\ncandidates from the large query pool. Then an adapted Attention-GRU model is\ndeveloped to effectively rank these candidates for recommendation. Offline and\nonline experiments on Taobao, a large-scale e-commerce platform in China,\nverify the effectiveness of our interactive system. The system has already gone\ninto production in the homepage of Taobao App since Nov. 11, 2018 (see\nhttps://v.qq.com/x/page/s0833tkp1uo.html on how it works online). Our code and\ndataset are public in https://github.com/zyody/QueryQR.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jun 2019 05:59:29 GMT"}], "update_date": "2019-07-04", "authors_parsed": [["Zhu", "Yu", ""], ["Gong", "Yu", ""], ["Liu", "Qingwen", ""], ["Ma", "Yingcai", ""], ["Ou", "Wenwu", ""], ["Zhu", "Junxiong", ""], ["Wang", "Beidou", ""], ["Guan", "Ziyu", ""], ["Cai", "Deng", ""]]}, {"id": "1907.01640", "submitter": "Khalil Damak", "authors": "Khalil Damak, Olfa Nasraoui", "title": "SeER: An Explainable Deep Learning MIDI-based Hybrid Song Recommender\n  System", "comments": "8 pages, 6 figures; added offline validation of explainability method", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  State of the art music recommender systems mainly rely on either matrix\nfactorization-based collaborative filtering approaches or deep learning\narchitectures. Deep learning models usually use metadata for content-based\nfiltering or predict the next user interaction by learning from temporal\nsequences of user actions. Despite advances in deep learning for song\nrecommendation, none has taken advantage of the sequential nature of songs by\nlearning sequence models that are based on content. Aside from the importance\nof prediction accuracy, other significant aspects are important, such as\nexplainability and solving the cold start problem. In this work, we propose a\nhybrid deep learning model, called \"SeER\", that uses collaborative filtering\n(CF) and deep learning sequence models on the MIDI content of songs for\nrecommendation in order to provide more accurate personalized recommendations;\nsolve the item cold start problem; and generate a relevant explanation for a\nsong recommendation. Our evaluation experiments show promising results compared\nto state of the art baseline and hybrid song recommender systems in terms of\nranking evaluation. Moreover, based on proposed tests for offline validation,\nwe show that our personalized explanations capture properties that are in\naccordance with the user's preferences.\n", "versions": [{"version": "v1", "created": "Tue, 25 Jun 2019 18:23:37 GMT"}, {"version": "v2", "created": "Thu, 19 Dec 2019 07:01:35 GMT"}], "update_date": "2019-12-20", "authors_parsed": [["Damak", "Khalil", ""], ["Nasraoui", "Olfa", ""]]}, {"id": "1907.01641", "submitter": "Hirotada Honda", "authors": "Hirotada Honda", "title": "Sensitivity of quantum PageRank", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we discuss the sensitivity of quantum PageRank. By using the\nfinite dimensional perturbation theory, we estimate the change of the quantum\nPageRank under a small analytical perturbation on the Google matrix. In\naddition, we will show the way to estimate the lower bound of the convergence\nradius as well as the error bound of the finite sum in the expansion of the\nperturbed PageRank.\n", "versions": [{"version": "v1", "created": "Thu, 27 Jun 2019 05:02:04 GMT"}], "update_date": "2019-07-04", "authors_parsed": [["Honda", "Hirotada", ""]]}, {"id": "1907.01643", "submitter": "Hemant Pugaliya", "authors": "Hemant Pugaliya, Karan Saxena, Shefali Garg, Sheetal Shalini, Prashant\n  Gupta, Eric Nyberg, Teruko Mitamura", "title": "Pentagon at MEDIQA 2019: Multi-task Learning for Filtering and\n  Re-ranking Answers using Language Inference and Question Entailment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Parallel deep learning architectures like fine-tuned BERT and MT-DNN, have\nquickly become the state of the art, bypassing previous deep and shallow\nlearning methods by a large margin. More recently, pre-trained models from\nlarge related datasets have been able to perform well on many downstream tasks\nby just fine-tuning on domain-specific datasets . However, using powerful\nmodels on non-trivial tasks, such as ranking and large document classification,\nstill remains a challenge due to input size limitations of parallel\narchitecture and extremely small datasets (insufficient for fine-tuning). In\nthis work, we introduce an end-to-end system, trained in a multi-task setting,\nto filter and re-rank answers in the medical domain. We use task-specific\npre-trained models as deep feature extractors. Our model achieves the highest\nSpearman's Rho and Mean Reciprocal Rank of 0.338 and 0.9622 respectively, on\nthe ACL-BioNLP workshop MediQA Question Answering shared-task.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jul 2019 17:48:40 GMT"}], "update_date": "2019-07-04", "authors_parsed": [["Pugaliya", "Hemant", ""], ["Saxena", "Karan", ""], ["Garg", "Shefali", ""], ["Shalini", "Sheetal", ""], ["Gupta", "Prashant", ""], ["Nyberg", "Eric", ""], ["Mitamura", "Teruko", ""]]}, {"id": "1907.01644", "submitter": "Dimitrios Rafailidis Dr", "authors": "Dimitrios Rafailidis and Gerhard Weiss", "title": "A Neural Attention Model for Adaptive Learning of Social Friends'\n  Preferences", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Social-based recommendation systems exploit the selections of friends to\ncombat the data sparsity on user preferences, and improve the recommendation\naccuracy of the collaborative filtering strategy. The main challenge is to\ncapture and weigh friends' preferences, as in practice they do necessarily\nmatch. In this paper, we propose a Neural Attention mechanism for Social\ncollaborative filtering, namely NAS. We design a neural architecture, to\ncarefully compute the non-linearity in friends' preferences by taking into\naccount the social latent effects of friends on user behavior. In addition, we\nintroduce a social behavioral attention mechanism to adaptively weigh the\ninfluence of friends on user preferences and consequently generate accurate\nrecommendations. Our experiments on publicly available datasets demonstrate the\neffectiveness of the proposed NAS model over other state-of-the-art methods.\nFurthermore, we study the effect of the proposed social behavioral attention\nmechanism and show that it is a key factor to our model's performance.\n", "versions": [{"version": "v1", "created": "Sat, 29 Jun 2019 15:59:28 GMT"}], "update_date": "2019-07-04", "authors_parsed": [["Rafailidis", "Dimitrios", ""], ["Weiss", "Gerhard", ""]]}, {"id": "1907.01645", "submitter": "Dimitrios Rafailidis Dr", "authors": "Dimitrios Rafailidis and Gerhard Weiss", "title": "Adaptive Deep Learning of Cross-Domain Loss in Collaborative Filtering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays, users open multiple accounts on social media platforms and\ne-commerce sites, expressing their personal preferences on different domains.\nHowever, users' behaviors change across domains, depending on the content that\nusers interact with, such as movies, music, clothing and retail products. In\nthis paper, we propose an adaptive deep learning strategy for cross-domain\nrecommendation, referred to as ADC. We design a neural architecture and\nformulate a cross-domain loss function, to compute the non-linearity in user\npreferences across domains and transfer the knowledge of users' multiple\nbehaviors, accordingly. In addition, we introduce an efficient algorithm for\ncross-domain loss balancing which directly tunes gradient magnitudes and adapts\nthe learning rates based on the domains' complexities/scales when training the\nmodel via backpropagation. In doing so, ADC controls and adjusts the\ncontribution of each domain when optimizing the model parameters. Our\nexperiments on six publicly available cross-domain recommendation tasks\ndemonstrate the effectiveness of the proposed ADC model over other\nstate-of-the-art methods. Furthermore, we study the effect of the proposed\nadaptive deep learning strategy and show that ADC can well balance the impact\nof the domains with different complexities.\n", "versions": [{"version": "v1", "created": "Sat, 29 Jun 2019 16:03:44 GMT"}], "update_date": "2019-07-04", "authors_parsed": [["Rafailidis", "Dimitrios", ""], ["Weiss", "Gerhard", ""]]}, {"id": "1907.01647", "submitter": "Yong Liu Stephen", "authors": "Yong Liu, Yingtai Xiao, Qiong Wu, Chunyan Miao, Juyong Zhang", "title": "Bandit Learning for Diversified Interactive Recommendation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interactive recommender systems that enable the interactions between users\nand the recommender system have attracted increasing research attentions.\nPrevious methods mainly focus on optimizing recommendation accuracy. However,\nthey usually ignore the diversity of the recommendation results, thus usually\nresults in unsatisfying user experiences. In this paper, we propose a novel\ndiversified recommendation model, named Diversified Contextual Combinatorial\nBandit (DC$^2$B), for interactive recommendation with users' implicit feedback.\nSpecifically, DC$^2$B employs determinantal point process in the recommendation\nprocedure to promote diversity of the recommendation results. To learn the\nmodel parameters, a Thompson sampling-type algorithm based on variational\nBayesian inference is proposed. In addition, theoretical regret analysis is\nalso provided to guarantee the performance of DC$^2$B. Extensive experiments on\nreal datasets are performed to demonstrate the effectiveness of the proposed\nmethod.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jul 2019 03:52:55 GMT"}], "update_date": "2019-07-04", "authors_parsed": [["Liu", "Yong", ""], ["Xiao", "Yingtai", ""], ["Wu", "Qiong", ""], ["Miao", "Chunyan", ""], ["Zhang", "Juyong", ""]]}, {"id": "1907.01650", "submitter": "Andr\\'as Horv\\'ath", "authors": "K\\'alm\\'an Szentannai, Jalal Al-Afandi, Andr\\'as Horv\\'ath", "title": "MimosaNet: An Unrobust Neural Network Preventing Model Stealing", "comments": "Presented at CVPR workshop: Adversarial Machine Learning in\n  Real-World Computer Vision Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Neural Networks are robust to minor perturbations of the learned network\nparameters and their minor modifications do not change the overall network\nresponse significantly. This allows space for model stealing, where a\nmalevolent attacker can steal an already trained network, modify the weights\nand claim the new network his own intellectual property. In certain cases this\ncan prevent the free distribution and application of networks in the embedded\ndomain. In this paper, we propose a method for creating an equivalent version\nof an already trained fully connected deep neural network that can prevent\nnetwork stealing: namely, it produces the same responses and classification\naccuracy, but it is extremely sensitive to weight changes.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jul 2019 21:13:02 GMT"}], "update_date": "2019-07-04", "authors_parsed": [["Szentannai", "K\u00e1lm\u00e1n", ""], ["Al-Afandi", "Jalal", ""], ["Horv\u00e1th", "Andr\u00e1s", ""]]}, {"id": "1907.01651", "submitter": "Yu-Chia Chen", "authors": "Yu-Chia Chen and Marina Meil\\u{a}", "title": "Selecting the independent coordinates of manifolds with large aspect\n  ratios", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many manifold embedding algorithms fail apparently when the data manifold has\na large aspect ratio (such as a long, thin strip). Here, we formulate success\nand failure in terms of finding a smooth embedding, showing also that the\nproblem is pervasive and more complex than previously recognized.\nMathematically, success is possible under very broad conditions, provided that\nembedding is done by carefully selected eigenfunctions of the Laplace-Beltrami\noperator $\\Delta$. Hence, we propose a bicriterial Independent Eigencoordinate\nSelection (IES) algorithm that selects smooth embeddings with few eigenvectors.\nThe algorithm is grounded in theory, has low computational overhead, and is\nsuccessful on synthetic and large real data.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jul 2019 21:14:07 GMT"}, {"version": "v2", "created": "Thu, 29 Aug 2019 09:07:23 GMT"}], "update_date": "2019-08-30", "authors_parsed": [["Chen", "Yu-Chia", ""], ["Meil\u0103", "Marina", ""]]}, {"id": "1907.01654", "submitter": "Mojdeh Saadati", "authors": "Mojdeh Saadati, Jin Tian", "title": "Adjustment Criteria for Recovering Causal Effects from Missing Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Confounding bias, missing data, and selection bias are three common obstacles\nto valid causal inference in the data sciences. Covariate adjustment is the\nmost pervasive technique for recovering casual effects from confounding bias.\nIn this paper, we introduce a covariate adjustment formulation for controlling\nconfounding bias in the presence of missing-not-at-random data and develop a\nnecessary and sufficient condition for recovering causal effects using the\nadjustment. We also introduce an adjustment formulation for controlling both\nconfounding and selection biases in the presence of missing data and develop a\nnecessary and sufficient condition for valid adjustment. Furthermore, we\npresent an algorithm that lists all valid adjustment sets and an algorithm that\nfinds a valid adjustment set containing the minimum number of variables, which\nare useful for researchers interested in selecting adjustment sets with desired\nproperties.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jul 2019 21:26:28 GMT"}, {"version": "v2", "created": "Tue, 13 Aug 2019 01:29:12 GMT"}, {"version": "v3", "created": "Sun, 15 Sep 2019 06:02:49 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Saadati", "Mojdeh", ""], ["Tian", "Jin", ""]]}, {"id": "1907.01657", "submitter": "Archit Sharma", "authors": "Archit Sharma, Shixiang Gu, Sergey Levine, Vikash Kumar, Karol Hausman", "title": "Dynamics-Aware Unsupervised Discovery of Skills", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conventionally, model-based reinforcement learning (MBRL) aims to learn a\nglobal model for the dynamics of the environment. A good model can potentially\nenable planning algorithms to generate a large variety of behaviors and solve\ndiverse tasks. However, learning an accurate model for complex dynamical\nsystems is difficult, and even then, the model might not generalize well\noutside the distribution of states on which it was trained. In this work, we\ncombine model-based learning with model-free learning of primitives that make\nmodel-based planning easy. To that end, we aim to answer the question: how can\nwe discover skills whose outcomes are easy to predict? We propose an\nunsupervised learning algorithm, Dynamics-Aware Discovery of Skills (DADS),\nwhich simultaneously discovers predictable behaviors and learns their dynamics.\nOur method can leverage continuous skill spaces, theoretically, allowing us to\nlearn infinitely many behaviors even for high-dimensional state-spaces. We\ndemonstrate that zero-shot planning in the learned latent space significantly\noutperforms standard MBRL and model-free goal-conditioned RL, can handle\nsparse-reward tasks, and substantially improves over prior hierarchical RL\nmethods for unsupervised skill discovery.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jul 2019 21:32:19 GMT"}, {"version": "v2", "created": "Fri, 14 Feb 2020 23:20:43 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Sharma", "Archit", ""], ["Gu", "Shixiang", ""], ["Levine", "Sergey", ""], ["Kumar", "Vikash", ""], ["Hausman", "Karol", ""]]}, {"id": "1907.01660", "submitter": "Frederic Pascal", "authors": "Violeta Roizman and Matthieu Jonckheere and Fr\\'ed\\'eric Pascal", "title": "A flexible EM-like clustering algorithm for noisy data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Though very popular, it is well known that the EM for GMM algorithm suffers\nfrom non-Gaussian distribution shapes, outliers and high-dimensionality. In\nthis paper, we design a new robust clustering algorithm that can efficiently\ndeal with noise and outliers in diverse data sets. As an EM-like algorithm, it\nis based on both estimations of clusters centers and covariances. In addition,\nusing a semi-parametric paradigm, the method estimates an unknown scale\nparameter per data-point. This allows the algorithm to accommodate for heavier\ntails distributions and outliers without significantly loosing efficiency in\nvarious classical scenarios. We first derive and analyze the proposed algorithm\nin the context of elliptical distributions, showing in particular important\ninsensitivity properties to the underlying data distributions. We then study\nthe convergence and accuracy of the algorithm by considering first synthetic\ndata. Then, we show that the proposed algorithm outperforms other classical\nunsupervised methods of the literature such as k-means, the EM for Gaussian\nmixture models and its recent modifications or spectral clustering when applied\nto real data sets as MNIST, NORB, and 20newsgroups.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jul 2019 21:36:30 GMT"}, {"version": "v2", "created": "Thu, 5 Dec 2019 14:21:55 GMT"}, {"version": "v3", "created": "Wed, 30 Sep 2020 07:51:28 GMT"}, {"version": "v4", "created": "Mon, 5 Oct 2020 11:28:26 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Roizman", "Violeta", ""], ["Jonckheere", "Matthieu", ""], ["Pascal", "Fr\u00e9d\u00e9ric", ""]]}, {"id": "1907.01661", "submitter": "Xiaoxiao Li", "authors": "Xiaoxiao Li, Nicha C. Dvornek, Yuan Zhou, Juntang Zhuang, Pamela\n  Ventola and James S. Duncan", "title": "Graph Neural Network for Interpreting Task-fMRI Biomarkers", "comments": null, "journal-ref": "Medical Image Computing and Computer-Assisted Intervention 2019", "doi": null, "report-no": null, "categories": "cs.LG cs.CV eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Finding the biomarkers associated with ASD is helpful for understanding the\nunderlying roots of the disorder and can lead to earlier diagnosis and more\ntargeted treatment. A promising approach to identify biomarkers is using Graph\nNeural Networks (GNNs), which can be used to analyze graph structured data,\ni.e. brain networks constructed by fMRI. One way to interpret important\nfeatures is through looking at how the classification probability changes if\nthe features are occluded or replaced. The major limitation of this approach is\nthat replacing values may change the distribution of the data and lead to\nserious errors. Therefore, we develop a 2-stage pipeline to eliminate the need\nto replace features for reliable biomarker interpretation. Specifically, we\npropose an inductive GNN to embed the graphs containing different properties of\ntask-fMRI for identifying ASD and then discover the brain regions/sub-graphs\nused as evidence for the GNN classifier. We first show GNN can achieve high\naccuracy in identifying ASD. Next, we calculate the feature importance scores\nusing GNN and compare the interpretation ability with Random Forest. Finally,\nwe run with different atlases and parameters, proving the robustness of the\nproposed method. The detected biomarkers reveal their association with social\nbehaviors. We also show the potential of discovering new informative\nbiomarkers. Our pipeline can be generalized to other graph feature importance\ninterpretation problems.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jul 2019 21:43:43 GMT"}, {"version": "v2", "created": "Fri, 12 Jul 2019 02:40:08 GMT"}], "update_date": "2019-07-15", "authors_parsed": [["Li", "Xiaoxiao", ""], ["Dvornek", "Nicha C.", ""], ["Zhou", "Yuan", ""], ["Zhuang", "Juntang", ""], ["Ventola", "Pamela", ""], ["Duncan", "James S.", ""]]}, {"id": "1907.01662", "submitter": "Hatem Hajri", "authors": "Thomas Gerald, Hadi Zaatiti, Hatem Hajri, Nicolas Baskiotis, Olivier\n  Schwander", "title": "From Node Embedding To Community Embedding : A Hyperbolic Approach", "comments": "This version replaces the previous one. The package generating the\n  experimental results will be made public in the near future", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Detecting communities on graphs has received significant interest in recent\nliterature. Current state-of-the-art community embedding approach called\n\\textit{ComE} tackles this problem by coupling graph embedding with community\ndetection. Considering the success of hyperbolic representations of\ngraph-structured data in last years, an ongoing challenge is to set up a\nhyperbolic approach for the community detection problem. The present paper\nmeets this challenge by introducing a Riemannian equivalent of \\textit{ComE}.\nOur proposed approach combines hyperbolic embeddings with Riemannian K-means or\nRiemannian mixture models to perform community detection. We illustrate the\nusefulness of this framework through several experiments on real-world social\nnetworks and comparisons with \\textit{ComE} and recent hyperbolic-based\nclassification approaches.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jul 2019 21:45:22 GMT"}, {"version": "v2", "created": "Sun, 1 Mar 2020 12:23:50 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Gerald", "Thomas", ""], ["Zaatiti", "Hadi", ""], ["Hajri", "Hatem", ""], ["Baskiotis", "Nicolas", ""], ["Schwander", "Olivier", ""]]}, {"id": "1907.01671", "submitter": "Vivek Singh", "authors": "Vivek K. Singh and Ishaan Singh", "title": "Quantifying Algorithmic Biases over Time", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Algorithms now permeate multiple aspects of human lives and multiple recent\nresults have reported that these algorithms may have biases pertaining to\ngender, race, and other demographic characteristics. The metrics used to\nquantify such biases have still focused on a static notion of algorithms.\nHowever, algorithms evolve over time. For instance, Tay (a conversational bot\nlaunched by Microsoft) was arguably not biased at its launch but quickly became\nbiased, sexist, and racist over time. We suggest a set of intuitive metrics to\nstudy the variations in biases over time and present the results for a case\nstudy for genders represented in images resulting from a Twitter image search\nfor #Nurse and #Doctor over a period of 21 days. Results indicate that biases\nvary significantly over time and the direction of bias could appear to be\ndifferent on different days. Hence, one-shot measurements may not suffice for\nunderstanding algorithmic bias, thus motivating further work on studying biases\nin algorithms over time.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jul 2019 22:44:12 GMT"}], "update_date": "2019-07-04", "authors_parsed": [["Singh", "Vivek K.", ""], ["Singh", "Ishaan", ""]]}, {"id": "1907.01674", "submitter": "Manisha Panta", "authors": "Manisha Panta, Avdesh Mishra, Md Tamjidul Hoque, Joel Atallah", "title": "Machine Learning based Prediction of Hierarchical Classification of\n  Transposable Elements", "comments": "9 pages, 7 figures, 5 tables, BIOKDD 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-bio.GN stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Transposable Elements (TEs) or jumping genes are the DNA sequences that have\nan intrinsic capability to move within a host genome from one genomic location\nto another. Studies show that the presence of a TE within or adjacent to a\nfunctional gene may alter its expression. TEs can also cause an increase in the\nrate of mutation and can even mediate duplications and large insertions and\ndeletions in the genome, promoting gross genetic rearrangements. Thus, the\nproper classification of the identified jumping genes is essential to\nunderstand their genetic and evolutionary effects in the genome. While\ncomputational methods have been developed that perform either binary\nclassification or multi-label classification of TEs, few studies have focused\non their hierarchical classification. The state-of-the-art machine learning\nclassification method utilizes a Multi-Layer Perceptron (MLP), a class of\nneural network, for hierarchical classification of TEs. However, the existing\nmethods have limited accuracy in classifying TEs. A more effective classifier,\nwhich can explain the role of TEs in germline and somatic evolution, is needed.\nIn this study, we examine the performance of a variety of machine learning (ML)\nmethods. And eventually, propose a robust approach for the hierarchical\nclassification of TEs, with higher accuracy, using Support Vector Machines\n(SVM).\n", "versions": [{"version": "v1", "created": "Tue, 2 Jul 2019 23:09:57 GMT"}, {"version": "v2", "created": "Tue, 9 Jul 2019 00:21:38 GMT"}, {"version": "v3", "created": "Mon, 26 Aug 2019 17:31:50 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["Panta", "Manisha", ""], ["Mishra", "Avdesh", ""], ["Hoque", "Md Tamjidul", ""], ["Atallah", "Joel", ""]]}, {"id": "1907.01677", "submitter": "Anirudh Raju", "authors": "Anirudh Raju, Denis Filimonov, Gautam Tiwari, Guitang Lan, Ariya\n  Rastrow", "title": "Scalable Multi Corpora Neural Language Models for ASR", "comments": "Interspeech 2019 (accepted: oral)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural language models (NLM) have been shown to outperform conventional\nn-gram language models by a substantial margin in Automatic Speech Recognition\n(ASR) and other tasks. There are, however, a number of challenges that need to\nbe addressed for an NLM to be used in a practical large-scale ASR system. In\nthis paper, we present solutions to some of the challenges, including training\nNLM from heterogenous corpora, limiting latency impact and handling\npersonalized bias in the second-pass rescorer. Overall, we show that we can\nachieve a 6.2% relative WER reduction using neural LM in a second-pass n-best\nrescoring framework with a minimal increase in latency.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jul 2019 23:28:52 GMT"}], "update_date": "2019-07-04", "authors_parsed": [["Raju", "Anirudh", ""], ["Filimonov", "Denis", ""], ["Tiwari", "Gautam", ""], ["Lan", "Guitang", ""], ["Rastrow", "Ariya", ""]]}, {"id": "1907.01678", "submitter": "Antonio Orvieto", "authors": "Antonio Orvieto, Jonas Kohler and Aurelien Lucchi", "title": "The Role of Memory in Stochastic Optimization", "comments": "Accepted paper at the 35th Conference on Uncertainty in Artificial\n  Intelligence (UAI), Tel Aviv, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The choice of how to retain information about past gradients dramatically\naffects the convergence properties of state-of-the-art stochastic optimization\nmethods, such as Heavy-ball, Nesterov's momentum, RMSprop and Adam. Building on\nthis observation, we use stochastic differential equations (SDEs) to explicitly\nstudy the role of memory in gradient-based algorithms. We first derive a\ngeneral continuous-time model that can incorporate arbitrary types of memory,\nfor both deterministic and stochastic settings. We provide convergence\nguarantees for this SDE for weakly-quasi-convex and quadratically growing\nfunctions. We then demonstrate how to discretize this SDE to get a flexible\ndiscrete-time algorithm that can implement a board spectrum of memories ranging\nfrom short- to long-term. Not only does this algorithm increase the degrees of\nfreedom in algorithmic choice for practitioners but it also comes with better\nstability properties than classical momentum in the convex stochastic setting.\nIn particular, no iterate averaging is needed for convergence. Interestingly,\nour analysis also provides a novel interpretation of Nesterov's momentum as\nstable gradient amplification and highlights a possible reason for its unstable\nbehavior in the (convex) stochastic setting. Furthermore, we discuss the use of\nlong term memory for second-moment estimation in adaptive methods, such as Adam\nand RMSprop. Finally, we provide an extensive experimental study of the effect\nof different types of memory in both convex and nonconvex settings.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jul 2019 23:30:18 GMT"}, {"version": "v2", "created": "Wed, 11 Mar 2020 23:19:05 GMT"}], "update_date": "2020-03-13", "authors_parsed": [["Orvieto", "Antonio", ""], ["Kohler", "Jonas", ""], ["Lucchi", "Aurelien", ""]]}, {"id": "1907.01683", "submitter": "Priya Kansal Dr.", "authors": "Sabari Nathan, Priya Kansal", "title": "SkeletonNet: Shape Pixel to Skeleton Pixel", "comments": "Published in CVPRw 2019", "journal-ref": "IEEE/CVPRw 2019", "doi": null, "report-no": null, "categories": "cs.CV cs.CG cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Learning for Geometric Shape Understating has organized a challenge for\nextracting different kinds of skeletons from the images of different objects.\nThis competition is organized in association with CVPR 2019. There are three\ndifferent tracks of this competition. The present manuscript describes the\nmethod used to train the model for the dataset provided in the first track. The\nfirst track aims to extract skeleton pixels from the shape pixels of 89\ndifferent objects. For the purpose of extracting the skeleton, a U-net model\nwhich is comprised of an encoder-decoder structure has been used. In our\nproposed architecture, unlike the plain decoder in the traditional Unet, we\nhave designed the decoder in the format of HED architecture, wherein we have\nintroduced 4 side layers and fused them to one dilation convolutional layer to\nconnect the broken links of the skeleton. Our proposed architecture achieved\nthe F1 score of 0.77 on test data.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jul 2019 23:44:05 GMT"}], "update_date": "2019-07-04", "authors_parsed": [["Nathan", "Sabari", ""], ["Kansal", "Priya", ""]]}, {"id": "1907.01693", "submitter": "Dongrui Wu", "authors": "Chenfeng Guo, Dongrui Wu", "title": "Canonical Correlation Analysis (CCA) Based Multi-View Learning: An\n  Overview", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-view learning (MVL) is a strategy for fusing data from different\nsources or subsets. Canonical correlation analysis (CCA) is very important in\nMVL, whose main idea is to map data from different views onto a common space\nwith maximum correlation. Traditional CCA can only be used to calculate the\nlinear correlation of two views. Besides, it is unsupervised and the label\ninformation is wasted. Many nonlinear, supervised, or generalized extensions\nhave been proposed to overcome these limitations. However, to our knowledge,\nthere is no overview for these approaches. This paper provides an overview of\nmany representative CCA-based MVL approaches.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jul 2019 00:53:32 GMT"}, {"version": "v2", "created": "Sun, 2 May 2021 00:08:54 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Guo", "Chenfeng", ""], ["Wu", "Dongrui", ""]]}, {"id": "1907.01698", "submitter": "S\\'ebastien Le Digabel", "authors": "Dounia Lakhmiri and S\\'ebastien Le Digabel and Christophe Tribes", "title": "HyperNOMAD: Hyperparameter optimization of deep neural networks using\n  mesh adaptive direct search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The performance of deep neural networks is highly sensitive to the choice of\nthe hyperparameters that define the structure of the network and the learning\nprocess. When facing a new application, tuning a deep neural network is a\ntedious and time consuming process that is often described as a \"dark art\".\nThis explains the necessity of automating the calibration of these\nhyperparameters. Derivative-free optimization is a field that develops methods\ndesigned to optimize time consuming functions without relying on derivatives.\nThis work introduces the HyperNOMAD package, an extension of the NOMAD software\nthat applies the MADS algorithm [7] to simultaneously tune the hyperparameters\nresponsible for both the architecture and the learning process of a deep neural\nnetwork (DNN), and that allows for an important flexibility in the exploration\nof the search space by taking advantage of categorical variables. This new\napproach is tested on the MNIST and CIFAR-10 data sets and achieves results\ncomparable to the current state of the art.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jul 2019 01:36:29 GMT"}], "update_date": "2019-07-04", "authors_parsed": [["Lakhmiri", "Dounia", ""], ["Digabel", "S\u00e9bastien Le", ""], ["Tribes", "Christophe", ""]]}, {"id": "1907.01702", "submitter": "Yingyang Chen", "authors": "Chunkai Zhang, Shaocong Li, Hongye Zhang, and Yingyang Chen", "title": "VELC: A New Variational AutoEncoder Based Model for Time Series Anomaly\n  Detection", "comments": "13 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Anomaly detection is a classical but worthwhile problem, and many deep\nlearning-based anomaly detection algorithms have been proposed, which can\nusually achieve better detection results than traditional methods. In view of\nreconstruct ability of the model and the calculation of anomaly score, this\npaper proposes a time series anomaly detection method based on Variational\nAutoEncoder model(VAE) with re-Encoder and Latent Constraint network(VELC). In\norder to modify reconstruct ability of the model to prevent it from\nreconstructing abnormal samples well, we add a constraint network in the latent\nspace of the VAE to force it generate new latent variables that are similar\nwith that of training samples. To be able to calculate anomaly score in two\nfeature spaces, we train a re-encoder to transform the generated data to a new\nlatent space. For better handling the time series, we use the LSTM as the\nencoder and decoder part of the VAE framework. Experimental results of several\nbenchmarks show that our method outperforms state-of-the-art anomaly detection\nmethods.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jul 2019 02:00:52 GMT"}, {"version": "v2", "created": "Wed, 15 Apr 2020 08:07:35 GMT"}], "update_date": "2020-04-16", "authors_parsed": [["Zhang", "Chunkai", ""], ["Li", "Shaocong", ""], ["Zhang", "Hongye", ""], ["Chen", "Yingyang", ""]]}, {"id": "1907.01703", "submitter": "Sidharth Gupta", "authors": "Sidharth Gupta, R\\'emi Gribonval, Laurent Daudet and Ivan Dokmani\\'c", "title": "Don't take it lightly: Phasing optical random projections with unknown\n  operators", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.ET eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we tackle the problem of recovering the phase of complex linear\nmeasurements when only magnitude information is available and we control the\ninput. We are motivated by the recent development of dedicated optics-based\nhardware for rapid random projections which leverages the propagation of light\nin random media. A signal of interest $\\mathbf{\\xi} \\in \\mathbb{R}^N$ is mixed\nby a random scattering medium to compute the projection $\\mathbf{y} =\n\\mathbf{A} \\mathbf{\\xi}$, with $\\mathbf{A} \\in \\mathbb{C}^{M \\times N}$ being a\nrealization of a standard complex Gaussian iid random matrix. Such optics-based\nmatrix multiplications can be much faster and energy-efficient than their CPU\nor GPU counterparts, yet two difficulties must be resolved: only the intensity\n${|\\mathbf{y}|}^2$ can be recorded by the camera, and the transmission matrix\n$\\mathbf{A}$ is unknown. We show that even without knowing $\\mathbf{A}$, we can\nrecover the unknown phase of $\\mathbf{y}$ for some equivalent transmission\nmatrix with the same distribution as $\\mathbf{A}$. Our method is based on two\nobservations: first, conjugating or changing the phase of any row of\n$\\mathbf{A}$ does not change its distribution; and second, since we control the\ninput we can interfere $\\mathbf{\\xi}$ with arbitrary reference signals. We show\nhow to leverage these observations to cast the measurement phase retrieval\nproblem as a Euclidean distance geometry problem. We demonstrate appealing\nproperties of the proposed algorithm in both numerical simulations and real\nhardware experiments. Not only does our algorithm accurately recover the\nmissing phase, but it mitigates the effects of quantization and the sensitivity\nthreshold, thus improving the measured magnitudes.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jul 2019 02:01:41 GMT"}, {"version": "v2", "created": "Wed, 30 Oct 2019 01:58:53 GMT"}, {"version": "v3", "created": "Thu, 13 Feb 2020 21:55:55 GMT"}], "update_date": "2020-02-17", "authors_parsed": [["Gupta", "Sidharth", ""], ["Gribonval", "R\u00e9mi", ""], ["Daudet", "Laurent", ""], ["Dokmani\u0107", "Ivan", ""]]}, {"id": "1907.01705", "submitter": "Keegan Hines E", "authors": "C. Bayan Bruss, Anish Khazane, Jonathan Rider, Richard Serpe, Saurabh\n  Nagrecha, Keegan E. Hines", "title": "Graph Embeddings at Scale", "comments": "Workshop on Mining and Learning with Graphs 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph embedding is a popular algorithmic approach for creating vector\nrepresentations for individual vertices in networks. Training these algorithms\nat scale is important for creating embeddings that can be used for\nclassification, ranking, recommendation and other common applications in\nindustry. While industrial systems exist for training graph embeddings on large\ndatasets, many of these distributed architectures are forced to partition\ncopious amounts of data and model logic across many worker nodes. In this\npaper, we propose a distributed infrastructure that completely avoids graph\npartitioning, dynamically creates size constrained computational graphs across\nworker nodes, and uses highly efficient indexing operations for updating\nembeddings that allow the system to function at scale. We show that our system\ncan scale an existing embeddings algorithm - skip-gram - to train on the\nopen-source Friendster network (68 million vertices) and on an internal\nheterogeneous graph (50 million vertices). We measure the performance of our\nsystem on two key quantitative metrics: link-prediction accuracy and rate of\nconvergence. We conclude this work by analyzing how a greater number of worker\nnodes actually improves our system's performance on the aforementioned metrics\nand discuss our next steps for rigorously evaluating the embedding vectors\nproduced by our system.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jul 2019 02:02:39 GMT"}], "update_date": "2019-07-04", "authors_parsed": [["Bruss", "C. Bayan", ""], ["Khazane", "Anish", ""], ["Rider", "Jonathan", ""], ["Serpe", "Richard", ""], ["Nagrecha", "Saurabh", ""], ["Hines", "Keegan E.", ""]]}, {"id": "1907.01709", "submitter": "Kyoung-Woon On", "authors": "Kyoung-Woon On, Eun-Sol Kim, Yu-Jung Heo, Byoung-Tak Zhang", "title": "Compositional Structure Learning for Sequential Video Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conventional sequential learning methods such as Recurrent Neural Networks\n(RNNs) focus on interactions between consecutive inputs, i.e. first-order\nMarkovian dependency. However, most of sequential data, as seen with videos,\nhave complex temporal dependencies that imply variable-length semantic flows\nand their compositions, and those are hard to be captured by conventional\nmethods. Here, we propose Temporal Dependency Networks (TDNs) for learning\nvideo data by discovering these complex structures of the videos. The TDNs\nrepresent video as a graph whose nodes and edges correspond to frames of the\nvideo and their dependencies respectively. Via a parameterized kernel with\ngraph-cut and graph convolutions, the TDNs find compositional temporal\ndependencies of the data in multilevel graph forms. We evaluate the proposed\nmethod on the large-scale video dataset Youtube-8M. The experimental results\nshow that our model efficiently learns the complex semantic structure of video\ndata.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jul 2019 02:28:48 GMT"}], "update_date": "2019-07-04", "authors_parsed": [["On", "Kyoung-Woon", ""], ["Kim", "Eun-Sol", ""], ["Heo", "Yu-Jung", ""], ["Zhang", "Byoung-Tak", ""]]}, {"id": "1907.01710", "submitter": "Zhe Zhu", "authors": "Yinhao Ren, Zhe Zhu, Yingzhou Li, and Joseph Lo", "title": "Mask Embedding in conditional GAN for Guided Synthesis of High\n  Resolution Images", "comments": "11 pages,6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advancements in conditional Generative Adversarial Networks (cGANs)\nhave shown promises in label guided image synthesis. Semantic masks, such as\nsketches and label maps, are another intuitive and effective form of guidance\nin image synthesis. Directly incorporating the semantic masks as constraints\ndramatically reduces the variability and quality of the synthesized results. We\nobserve this is caused by the incompatibility of features from different inputs\n(such as mask image and latent vector) of the generator. To use semantic masks\nas guidance whilst providing realistic synthesized results with fine details,\nwe propose to use mask embedding mechanism to allow for a more efficient\ninitial feature projection in the generator. We validate the effectiveness of\nour approach by training a mask guided face generator using CELEBA-HQ dataset.\nWe can generate realistic and high resolution facial images up to the\nresolution of 512*512 with a mask guidance. Our code is publicly available.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jul 2019 02:30:36 GMT"}], "update_date": "2019-07-04", "authors_parsed": [["Ren", "Yinhao", ""], ["Zhu", "Zhe", ""], ["Li", "Yingzhou", ""], ["Lo", "Joseph", ""]]}, {"id": "1907.01723", "submitter": "Yihuang Kang", "authors": "Yihuang Kang, I-Ling Cheng, Wenjui Mao, Bowen Kuo, Pei-Ju Lee", "title": "Towards Interpretable Deep Extreme Multi-label Learning", "comments": "6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many Machine Learning algorithms, such as deep neural networks, have long\nbeen criticized for being \"black-boxes\"-a kind of models unable to provide how\nit arrive at a decision without further efforts to interpret. This problem has\nraised concerns on model applications' trust, safety, nondiscrimination, and\nother ethical issues. In this paper, we discuss the machine learning\ninterpretability of a real-world application, eXtreme Multi-label Learning\n(XML), which involves learning models from annotated data with many pre-defined\nlabels. We propose a two-step XML approach that combines deep non-negative\nautoencoder with other multi-label classifiers to tackle different data\napplications with a large number of labels. Our experimental result shows that\nthe proposed approach is able to cope with many-label problems as well as to\nprovide interpretable label hierarchies and dependencies that helps us\nunderstand how the model recognizes the existences of objects in an image.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jul 2019 03:51:31 GMT"}], "update_date": "2019-07-04", "authors_parsed": [["Kang", "Yihuang", ""], ["Cheng", "I-Ling", ""], ["Mao", "Wenjui", ""], ["Kuo", "Bowen", ""], ["Lee", "Pei-Ju", ""]]}, {"id": "1907.01728", "submitter": "Yahya Sattar", "authors": "Yahya Sattar and Samet Oymak", "title": "Quickly Finding the Best Linear Model in High Dimensions", "comments": null, "journal-ref": "IEEE Transactions on Signal Processing, 2020", "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of finding the best linear model that can minimize\nleast-squares loss given a data-set. While this problem is trivial in the low\ndimensional regime, it becomes more interesting in high dimensions where the\npopulation minimizer is assumed to lie on a manifold such as sparse vectors. We\npropose projected gradient descent (PGD) algorithm to estimate the population\nminimizer in the finite sample regime. We establish linear convergence rate and\ndata dependent estimation error bounds for PGD. Our contributions include: 1)\nThe results are established for heavier tailed sub-exponential distributions\nbesides sub-gaussian. 2) We directly analyze the empirical risk minimization\nand do not require a realizable model that connects input data and labels. 3)\nOur PGD algorithm is augmented to learn the bias terms which boosts the\nperformance. The numerical experiments validate our theoretical results.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jul 2019 04:16:49 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Sattar", "Yahya", ""], ["Oymak", "Samet", ""]]}, {"id": "1907.01729", "submitter": "Thomas Viehmann", "authors": "Thomas Viehmann", "title": "Implementation of batched Sinkhorn iterations for entropy-regularized\n  Wasserstein loss", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this report, we review the calculation of entropy-regularised Wasserstein\nloss introduced by Cuturi and document a practical implementation in PyTorch.\nCode is available at\nhttps://github.com/t-vi/pytorch-tvmisc/blob/master/wasserstein-distance/Pytorch_Wasserstein.ipynb\n", "versions": [{"version": "v1", "created": "Mon, 1 Jul 2019 15:25:49 GMT"}, {"version": "v2", "created": "Fri, 5 Jul 2019 14:08:44 GMT"}], "update_date": "2019-07-08", "authors_parsed": [["Viehmann", "Thomas", ""]]}, {"id": "1907.01734", "submitter": "Zeyuan Wang", "authors": "Zeyuan Wang, Josiah Poon, and Simon Poon", "title": "AMI-Net+: A Novel Multi-Instance Neural Network for Medical Diagnosis\n  from Incomplete and Imbalanced Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In medical real-world study (RWS), how to fully utilize the fragmentary and\nscarce information in model training to generate the solid diagnosis results is\na challenging task. In this work, we introduce a novel multi-instance neural\nnetwork, AMI-Net+, to train and predict from the incomplete and extremely\nimbalanced data. It is more effective than the state-of-art method, AMI-Net.\nFirst, we also implement embedding, multi-head attention and gated\nattention-based multi-instance pooling to capture the relations of symptoms\nthemselves and with the given disease. Besides, we propose var-ious\nimprovements to AMI-Net, that the cross-entropy loss is replaced by focal loss\nand we propose a novel self-adaptive multi-instance pooling method on\ninstance-level to obtain the bag representation. We validate the performance of\nAMI-Net+ on two real-world datasets, from two different medical domains.\nResults show that our approach outperforms other base-line models by a\nconsiderable margin.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jul 2019 04:37:31 GMT"}], "update_date": "2019-07-04", "authors_parsed": [["Wang", "Zeyuan", ""], ["Poon", "Josiah", ""], ["Poon", "Simon", ""]]}, {"id": "1907.01739", "submitter": "Charu Sharma", "authors": "Charu Sharma, Deepak Nathani, Manohar Kaul", "title": "Solving Partial Assignment Problems using Random Clique Complexes", "comments": "Accepted as a long talk at ICML 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an alternate formulation of the partial assignment problem as\nmatching random clique complexes, that are higher-order analogues of random\ngraphs, designed to provide a set of invariants that better detect higher-order\nstructure. The proposed method creates random clique adjacency matrices for\neach k-skeleton of the random clique complexes and matches them, taking into\naccount each point as the affine combination of its geometric neighbourhood. We\njustify our solution theoretically, by analyzing the runtime and storage\ncomplexity of our algorithm along with the asymptotic behaviour of the\nquadratic assignment problem (QAP) that is associated with the underlying\nrandom clique adjacency matrices. Experiments on both synthetic and real-world\ndatasets, containing severe occlusions and distortions, provide insight into\nthe accuracy, efficiency, and robustness of our approach. We outperform diverse\nmatching algorithms by a significant margin.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jul 2019 04:56:34 GMT"}, {"version": "v2", "created": "Wed, 8 Jul 2020 12:28:06 GMT"}, {"version": "v3", "created": "Wed, 29 Jul 2020 15:12:50 GMT"}], "update_date": "2020-07-30", "authors_parsed": [["Sharma", "Charu", ""], ["Nathani", "Deepak", ""], ["Kaul", "Manohar", ""]]}, {"id": "1907.01742", "submitter": "Chandan Karadagur Ananda Reddy", "authors": "Chandan K A Reddy, Ross Cutler, Johannes Gehrke", "title": "Supervised Classifiers for Audio Impairments with Noisy Labels", "comments": "To appear in INTERSPEECH 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Voice-over-Internet-Protocol (VoIP) calls are prone to various speech\nimpairments due to environmental and network conditions resulting in bad user\nexperience. A reliable audio impairment classifier helps to identify the cause\nfor bad audio quality. The user feedback after the call can act as the ground\ntruth labels for training a supervised classifier on a large audio dataset.\nHowever, the labels are noisy as most of the users lack the expertise to\nprecisely articulate the impairment in the perceived speech. In this paper, we\nanalyze the effects of massive noise in labels in training dense networks and\nConvolutional Neural Networks (CNN) using engineered features, spectrograms and\nraw audio samples as inputs. We demonstrate that CNN can generalize better on\nthe training data with a large number of noisy labels and gives remarkably\nhigher test performance. The classifiers were trained both on randomly\ngenerated label noise and the label noise introduced by human errors. We also\nshow that training with noisy labels requires a significant increase in the\ntraining dataset size, which is in proportion to the amount of noise in the\nlabels.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jul 2019 05:21:06 GMT"}], "update_date": "2019-07-04", "authors_parsed": [["Reddy", "Chandan K A", ""], ["Cutler", "Ross", ""], ["Gehrke", "Johannes", ""]]}, {"id": "1907.01743", "submitter": "Haoran Dou", "authors": "Yi Wang, Haoran Dou, Xiaowei Hu, Lei Zhu, Xin Yang, Ming Xu, Jing Qin,\n  Pheng-Ann Heng, Tianfu Wang, and Dong Ni", "title": "Deep Attentive Features for Prostate Segmentation in 3D Transrectal\n  Ultrasound", "comments": "11 pages, 10 figures, 2 tables. Accepted by IEEE transactions on\n  Medical Imaging", "journal-ref": null, "doi": "10.1109/TMI.2019.2913184", "report-no": null, "categories": "eess.IV cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic prostate segmentation in transrectal ultrasound (TRUS) images is of\nessential importance for image-guided prostate interventions and treatment\nplanning. However, developing such automatic solutions remains very challenging\ndue to the missing/ambiguous boundary and inhomogeneous intensity distribution\nof the prostate in TRUS, as well as the large variability in prostate shapes.\nThis paper develops a novel 3D deep neural network equipped with attention\nmodules for better prostate segmentation in TRUS by fully exploiting the\ncomplementary information encoded in different layers of the convolutional\nneural network (CNN). Our attention module utilizes the attention mechanism to\nselectively leverage the multilevel features integrated from different layers\nto refine the features at each individual layer, suppressing the non-prostate\nnoise at shallow layers of the CNN and increasing more prostate details into\nfeatures at deep layers. Experimental results on challenging 3D TRUS volumes\nshow that our method attains satisfactory segmentation performance. The\nproposed attention mechanism is a general strategy to aggregate multi-level\ndeep features and has the potential to be used for other medical image\nsegmentation tasks. The code is publicly available at\nhttps://github.com/wulalago/DAF3D.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jul 2019 05:21:52 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Wang", "Yi", ""], ["Dou", "Haoran", ""], ["Hu", "Xiaowei", ""], ["Zhu", "Lei", ""], ["Yang", "Xin", ""], ["Xu", "Ming", ""], ["Qin", "Jing", ""], ["Heng", "Pheng-Ann", ""], ["Wang", "Tianfu", ""], ["Ni", "Dong", ""]]}, {"id": "1907.01752", "submitter": "Leshem Choshen", "authors": "Leshem Choshen, Lior Fox, Zohar Aizenbud, Omri Abend", "title": "On the Weaknesses of Reinforcement Learning for Neural Machine\n  Translation", "comments": "Accepted to ICLR 2020 (matching content, different style)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning (RL) is frequently used to increase performance in\ntext generation tasks, including machine translation (MT), notably through the\nuse of Minimum Risk Training (MRT) and Generative Adversarial Networks (GAN).\nHowever, little is known about what and how these methods learn in the context\nof MT. We prove that one of the most common RL methods for MT does not optimize\nthe expected reward, as well as show that other methods take an infeasibly long\ntime to converge. In fact, our results suggest that RL practices in MT are\nlikely to improve performance only where the pre-trained parameters are already\nclose to yielding the correct translation. Our findings further suggest that\nobserved gains may be due to effects unrelated to the training signal, but\nrather from changes in the shape of the distribution curve.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jul 2019 06:15:14 GMT"}, {"version": "v2", "created": "Sat, 9 Nov 2019 13:57:23 GMT"}, {"version": "v3", "created": "Mon, 23 Dec 2019 10:31:04 GMT"}, {"version": "v4", "created": "Wed, 15 Jan 2020 07:19:09 GMT"}], "update_date": "2020-01-16", "authors_parsed": [["Choshen", "Leshem", ""], ["Fox", "Lior", ""], ["Aizenbud", "Zohar", ""], ["Abend", "Omri", ""]]}, {"id": "1907.01755", "submitter": "Ba Dung Le Dr", "authors": "Ba Dung Le, Guanhua Wang, Mehwish Nasim and Ali Babar", "title": "Gathering Cyber Threat Intelligence from Twitter Using Novelty\n  Classification", "comments": "ACCEPTED by the 2019 International Conference on Cyberworlds (CW2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Preventing organizations from Cyber exploits needs timely intelligence about\nCyber vulnerabilities and attacks, referred as threats. Cyber threat\nintelligence can be extracted from various sources including social media\nplatforms where users publish the threat information in real time. Gathering\nCyber threat intelligence from social media sites is a time consuming task for\nsecurity analysts that can delay timely response to emerging Cyber threats. We\npropose a framework for automatically gathering Cyber threat intelligence from\nTwitter by using a novelty detection model. Our model learns the features of\nCyber threat intelligence from the threat descriptions published in public\nrepositories such as Common Vulnerabilities and Exposures (CVE) and classifies\na new unseen tweet as either normal or anomalous to Cyber threat intelligence.\nWe evaluate our framework using a purpose-built data set of tweets from 50\ninfluential Cyber security related accounts over twelve months (in 2018). Our\nclassifier achieves the F1-score of 0.643 for classifying Cyber threat tweets\nand outperforms several baselines including binary classification models. Our\nanalysis of the classification results suggests that Cyber threat relevant\ntweets on Twitter do not often include the CVE identifier of the related\nthreats. Hence, it would be valuable to collect these tweets and associate them\nwith the related CVE identifier for cyber security applications.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jul 2019 06:31:52 GMT"}, {"version": "v2", "created": "Thu, 5 Sep 2019 00:45:40 GMT"}], "update_date": "2019-09-06", "authors_parsed": [["Le", "Ba Dung", ""], ["Wang", "Guanhua", ""], ["Nasim", "Mehwish", ""], ["Babar", "Ali", ""]]}, {"id": "1907.01771", "submitter": "Ulysse Marteau-Ferey", "authors": "Ulysse Marteau-Ferey (SIERRA, DI-ENS, PSL), Francis Bach (SIERRA,\n  DI-ENS, PSL), Alessandro Rudi (SIERRA, DI-ENS, PSL)", "title": "Globally Convergent Newton Methods for Ill-conditioned Generalized\n  Self-concordant Losses", "comments": null, "journal-ref": "NeurIPS 2019 - Conference on Neural Information Processing\n  Systems, Dec 2019, Vancouver, Canada", "doi": null, "report-no": null, "categories": "math.OC cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study large-scale convex optimization algorithms based on\nthe Newton method applied to regularized generalized self-concordant losses,\nwhich include logistic regression and softmax regression. We first prove that\nour new simple scheme based on a sequence of problems with decreasing\nregularization parameters is provably globally convergent, that this\nconvergence is linear with a constant factor which scales only logarithmically\nwith the condition number. In the parametric setting, we obtain an algorithm\nwith the same scaling than regular first-order methods but with an improved\nbehavior, in particular in ill-conditioned problems. Second, in the non\nparametric machine learning setting, we provide an explicit algorithm combining\nthe previous scheme with Nystr{\\\"o}m projection techniques, and prove that it\nachieves optimal generalization bounds with a time complexity of order O(ndf\n$\\lambda$), a memory complexity of order O(df 2 $\\lambda$) and no dependence on\nthe condition number, generalizing the results known for least-squares\nregression. Here n is the number of observations and df $\\lambda$ is the\nassociated degrees of freedom. In particular, this is the first large-scale\nalgorithm to solve logistic and softmax regressions in the non-parametric\nsetting with large condition numbers and theoretical guarantees.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jul 2019 07:15:44 GMT"}, {"version": "v2", "created": "Thu, 21 Nov 2019 15:09:01 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Marteau-Ferey", "Ulysse", "", "SIERRA, DI-ENS, PSL"], ["Bach", "Francis", "", "SIERRA,\n  DI-ENS, PSL"], ["Rudi", "Alessandro", "", "SIERRA, DI-ENS, PSL"]]}, {"id": "1907.01773", "submitter": "Kaijie Tu", "authors": "Dawen Xu, Ying Wang, Kaijie Tu, Cheng Liu, Bingsheng He, and Lei Zhang", "title": "Accelerating Generative Neural Networks on Unmodified Deep Learning\n  Processors -- A Software Approach", "comments": "13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.DS cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative neural network is a new category of neural networks and it has\nbeen widely utilized in applications such as content generation, unsupervised\nlearning, segmentation and pose estimation. It typically involves massive\ncomputing-intensive deconvolution operations that cannot be fitted to\nconventional neural network processors directly. However, prior works mainly\ninvestigated specialized hardware architectures through intensive hardware\nmodifications to the existing deep learning processors to accelerate\ndeconvolution together with the convolution. In contrast, this work proposes a\nnovel deconvolution implementation with a software approach and enables fast\nand efficient deconvolution execution on the legacy deep learning processors.\nOur proposed method reorganizes the computation of deconvolution and allows the\ndeep learning processors to treat it as the standard convolution by splitting\nthe original deconvolution filters into multiple small filters. Compared to\nprior acceleration schemes, the implemented acceleration scheme achieves 2.41x\n- 4.34x performance speedup and reduces the energy consumption by 27.7% - 54.5%\non a set of realistic benchmarks. In addition, we also applied the\ndeconvolution computing approach to the off-the-shelf commodity deep learning\nprocessors. The performance of deconvolution also exhibits significant\nperformance speedup over prior deconvolution implementations.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jul 2019 07:18:57 GMT"}, {"version": "v2", "created": "Tue, 10 Dec 2019 08:19:41 GMT"}, {"version": "v3", "created": "Wed, 29 Apr 2020 02:50:01 GMT"}], "update_date": "2020-04-30", "authors_parsed": [["Xu", "Dawen", ""], ["Wang", "Ying", ""], ["Tu", "Kaijie", ""], ["Liu", "Cheng", ""], ["He", "Bingsheng", ""], ["Zhang", "Lei", ""]]}, {"id": "1907.01791", "submitter": "Shiva P", "authors": "Shiva Pentyala, Mengwen Liu, Markus Dreyer", "title": "Multi-Task Networks With Universe, Group, and Task Feature Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present methods for multi-task learning that take advantage of natural\ngroupings of related tasks. Task groups may be defined along known properties\nof the tasks, such as task domain or language. Such task groups represent\nsupervised information at the inter-task level and can be encoded into the\nmodel. We investigate two variants of neural network architectures that\naccomplish this, learning different feature spaces at the levels of individual\ntasks, task groups, as well as the universe of all tasks: (1) parallel\narchitectures encode each input simultaneously into feature spaces at different\nlevels; (2) serial architectures encode each input successively into feature\nspaces at different levels in the task hierarchy. We demonstrate the methods on\nnatural language understanding (NLU) tasks, where a grouping of tasks into\ndifferent task domains leads to improved performance on ATIS, Snips, and a\nlarge inhouse dataset.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jul 2019 08:39:14 GMT"}], "update_date": "2019-07-04", "authors_parsed": [["Pentyala", "Shiva", ""], ["Liu", "Mengwen", ""], ["Dreyer", "Markus", ""]]}, {"id": "1907.01803", "submitter": "Khaled Koutini", "authors": "Khaled Koutini, Hamid Eghbal-zadeh, Matthias Dorfer and Gerhard Widmer", "title": "The Receptive Field as a Regularizer in Deep Convolutional Neural\n  Networks for Acoustic Scene Classification", "comments": "IEEE EUSIPCO 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional Neural Networks (CNNs) have had great success in many machine\nvision as well as machine audition tasks. Many image recognition network\narchitectures have consequently been adapted for audio processing tasks.\nHowever, despite some successes, the performance of many of these did not\ntranslate from the image to the audio domain. For example, very deep\narchitectures such as ResNet and DenseNet, which significantly outperform VGG\nin image recognition, do not perform better in audio processing tasks such as\nAcoustic Scene Classification (ASC). In this paper, we investigate the reasons\nwhy such powerful architectures perform worse in ASC compared to simpler models\n(e.g., VGG). To this end, we analyse the receptive field (RF) of these CNNs and\ndemonstrate the importance of the RF to the generalization capability of the\nmodels. Using our receptive field analysis, we adapt both ResNet and DenseNet,\nachieving state-of-the-art performance and eventually outperforming the\nVGG-based models. We introduce systematic ways of adapting the RF in CNNs, and\npresent results on three data sets that show how changing the RF over the time\nand frequency dimensions affects a model's performance. Our experimental\nresults show that very small or very large RFs can cause performance\ndegradation, but deep models can be made to generalize well by carefully\nchoosing an appropriate RF size within a certain range.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jul 2019 09:06:42 GMT"}], "update_date": "2019-07-04", "authors_parsed": [["Koutini", "Khaled", ""], ["Eghbal-zadeh", "Hamid", ""], ["Dorfer", "Matthias", ""], ["Widmer", "Gerhard", ""]]}, {"id": "1907.01813", "submitter": "Olga Slizovskaia", "authors": "Olga Slizovskaia, Emilia G\\'omez, Gloria Haro", "title": "A Case Study of Deep-Learned Activations via Hand-Crafted Audio Features", "comments": "The 2018 Joint Workshop on Machine Learning for Music, The Federated\n  Artificial Intelligence Meeting (FAIM), Joint workshop program of ICML,\n  IJCAI/ECAI, and AAMAS, Stockholm, Sweden, Saturday, July 14th, 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The explainability of Convolutional Neural Networks (CNNs) is a particularly\nchallenging task in all areas of application, and it is notably\nunder-researched in music and audio domain. In this paper, we approach\nexplainability by exploiting the knowledge we have on hand-crafted audio\nfeatures. Our study focuses on a well-defined MIR task, the recognition of\nmusical instruments from user-generated music recordings. We compute the\nsimilarity between a set of traditional audio features and representations\nlearned by CNNs. We also propose a technique for measuring the similarity\nbetween activation maps and audio features which typically presented in the\nform of a matrix, such as chromagrams or spectrograms. We observe that some\nneurons' activations correspond to well-known classical audio features. In\nparticular, for shallow layers, we found similarities between activations and\nharmonic and percussive components of the spectrum. For deeper layers, we\ncompare chromagrams with high-level activation maps as well as loudness and\nonset rate with deep-learned embeddings.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jul 2019 09:32:42 GMT"}], "update_date": "2019-07-04", "authors_parsed": [["Slizovskaia", "Olga", ""], ["G\u00f3mez", "Emilia", ""], ["Haro", "Gloria", ""]]}, {"id": "1907.01824", "submitter": "Guillaume Doras", "authors": "Guillaume Doras, Geoffroy Peeters", "title": "Cover Detection using Dominant Melody Embeddings", "comments": null, "journal-ref": "20th International Society for Music Information Retrieval\n  Conference, Delft, The Netherlands, 2019", "doi": null, "report-no": null, "categories": "cs.SD cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Automatic cover detection -- the task of finding in an audio database all the\ncovers of one or several query tracks -- has long been seen as a challenging\ntheoretical problem in the MIR community and as an acute practical problem for\nauthors and composers societies. Original algorithms proposed for this task\nhave proven their accuracy on small datasets, but are unable to scale up to\nmodern real-life audio corpora. On the other hand, faster approaches designed\nto process thousands of pairwise comparisons resulted in lower accuracy, making\nthem unsuitable for practical use.\n  In this work, we propose a neural network architecture that is trained to\nrepresent each track as a single embedding vector. The computation burden is\ntherefore left to the embedding extraction -- that can be conducted offline and\nstored, while the pairwise comparison task reduces to a simple Euclidean\ndistance computation. We further propose to extract each track's embedding out\nof its dominant melody representation, obtained by another neural network\ntrained for this task. We then show that this architecture improves\nstate-of-the-art accuracy both on small and large datasets, and is able to\nscale to query databases of thousands of tracks in a few seconds.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jul 2019 09:56:58 GMT"}], "update_date": "2019-07-05", "authors_parsed": [["Doras", "Guillaume", ""], ["Peeters", "Geoffroy", ""]]}, {"id": "1907.01845", "submitter": "Xiangxiang Chu", "authors": "Xiangxiang Chu and Bo Zhang and Ruijun Xu", "title": "FairNAS: Rethinking Evaluation Fairness of Weight Sharing Neural\n  Architecture Search", "comments": "Accepted to ICCV21", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the most critical problems in weight-sharing neural architecture\nsearch is the evaluation of candidate models within a predefined search space.\nIn practice, a one-shot supernet is trained to serve as an evaluator. A\nfaithful ranking certainly leads to more accurate searching results. However,\ncurrent methods are prone to making misjudgments. In this paper, we prove that\ntheir biased evaluation is due to inherent unfairness in the supernet training.\nIn view of this, we propose two levels of constraints: expectation fairness and\nstrict fairness. Particularly, strict fairness ensures equal optimization\nopportunities for all choice blocks throughout the training, which neither\noverestimates nor underestimates their capacity. We demonstrate that this is\ncrucial for improving the confidence of models' ranking. Incorporating the\none-shot supernet trained under the proposed fairness constraints with a\nmulti-objective evolutionary search algorithm, we obtain various\nstate-of-the-art models, e.g., FairNAS-A attains 77.5% top-1 validation\naccuracy on ImageNet. The models and their evaluation codes are made publicly\navailable online http://github.com/fairnas/FairNAS .\n", "versions": [{"version": "v1", "created": "Wed, 3 Jul 2019 10:50:38 GMT"}, {"version": "v2", "created": "Wed, 14 Aug 2019 06:16:45 GMT"}, {"version": "v3", "created": "Wed, 20 Nov 2019 06:41:45 GMT"}, {"version": "v4", "created": "Tue, 10 Mar 2020 11:53:02 GMT"}, {"version": "v5", "created": "Wed, 28 Jul 2021 10:19:08 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Chu", "Xiangxiang", ""], ["Zhang", "Bo", ""], ["Xu", "Ruijun", ""]]}, {"id": "1907.01849", "submitter": "Stefan Vlaski", "authors": "Stefan Vlaski and Ali H. Sayed", "title": "Distributed Learning in Non-Convex Environments -- Part II: Polynomial\n  Escape from Saddle-Points", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.LG eess.SP math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The diffusion strategy for distributed learning from streaming data employs\nlocal stochastic gradient updates along with exchange of iterates over\nneighborhoods. In Part I [2] of this work we established that agents cluster\naround a network centroid and proceeded to study the dynamics of this point. We\nestablished expected descent in non-convex environments in the large-gradient\nregime and introduced a short-term model to examine the dynamics over\nfinite-time horizons. Using this model, we establish in this work that the\ndiffusion strategy is able to escape from strict saddle-points in O(1/$\\mu$)\niterations; it is also able to return approximately second-order stationary\npoints in a polynomial number of iterations. Relative to prior works on the\npolynomial escape from saddle-points, most of which focus on centralized\nperturbed or stochastic gradient descent, our approach requires less\nrestrictive conditions on the gradient noise process.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jul 2019 11:06:43 GMT"}], "update_date": "2019-07-04", "authors_parsed": [["Vlaski", "Stefan", ""], ["Sayed", "Ali H.", ""]]}, {"id": "1907.01851", "submitter": "Aqeel Labash", "authors": "Aqeel Labash, Jaan Aru, Tambet Matiisen, Ardi Tampuu, Raul Vicente", "title": "Perspective Taking in Deep Reinforcement Learning Agents", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.MA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Perspective taking is the ability to take the point of view of another agent.\nThis skill is not unique to humans as it is also displayed by other animals\nlike chimpanzees. It is an essential ability for social interactions, including\nefficient cooperation, competition, and communication. Here we present our\nprogress toward building artificial agents with such abilities. We implemented\na perspective taking task inspired by experiments done with chimpanzees. We\nshow that agents controlled by artificial neural networks can learn via\nreinforcement learning to pass simple tests that require perspective taking\ncapabilities. We studied whether this ability is more readily learned by agents\nwith information encoded in allocentric or egocentric form for both their\nvisual perception and motor actions. We believe that, in the long run, building\nbetter artificial agents with perspective taking ability can help us develop\nartificial intelligence that is more human-like and easier to communicate with.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jul 2019 11:08:28 GMT"}, {"version": "v2", "created": "Thu, 16 Apr 2020 00:57:24 GMT"}], "update_date": "2020-04-17", "authors_parsed": [["Labash", "Aqeel", ""], ["Aru", "Jaan", ""], ["Matiisen", "Tambet", ""], ["Tampuu", "Ardi", ""], ["Vicente", "Raul", ""]]}, {"id": "1907.01860", "submitter": "Patricio Cerda", "authors": "Patricio Cerda (PARIETAL), Ga\\\"el Varoquaux (NEUROSPIN)", "title": "Encoding high-cardinality string categorical variables", "comments": null, "journal-ref": "IEEE Transactions on Knowledge and Data Engineering, Institute of\n  Electrical and Electronics Engineers, pp.1-1", "doi": "10.1109/TKDE.2020.2992529", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Statistical models usually require vector representations of categorical\nvariables, using for instance one-hot encoding. This strategy breaks down when\nthe number of categories grows, as it creates high-dimensional feature vectors.\nAdditionally, for string entries, one-hot encoding does not capture information\nin their representation.Here, we seek low-dimensional encoding of\nhigh-cardinality string categorical variables. Ideally, these should be:\nscalable to many categories; interpretable to end users; and facilitate\nstatistical analysis. We introduce two encoding approaches for string\ncategories: a Gamma-Poisson matrix factorization on substring counts, and the\nmin-hash encoder, for fast approximation of string similarities. We show that\nmin-hash turns set inclusions into inequality relations that are easier to\nlearn. Both approaches are scalable and streamable. Experiments on real and\nsimulated data show that these methods improve supervised learning with\nhigh-cardinality categorical variables. We recommend the following: if\nscalability is central, the min-hash encoder is the best option as it does not\nrequire any data fit; if interpretability is important, the Gamma-Poisson\nfactorization is the best alternative, as it can be interpreted as one-hot\nencoding on inferred categories with informative feature names. Both models\nenable autoML on the original string entries as they remove the need for\nfeature engineering or data cleaning.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jul 2019 11:36:07 GMT"}, {"version": "v2", "created": "Thu, 11 Jul 2019 12:32:56 GMT"}, {"version": "v3", "created": "Wed, 17 Jul 2019 10:17:59 GMT"}, {"version": "v4", "created": "Thu, 5 Sep 2019 08:54:06 GMT"}, {"version": "v5", "created": "Mon, 18 May 2020 15:18:45 GMT"}], "update_date": "2020-07-16", "authors_parsed": [["Cerda", "Patricio", "", "PARIETAL"], ["Varoquaux", "Ga\u00ebl", "", "NEUROSPIN"]]}, {"id": "1907.01867", "submitter": "C\\'esar Lincoln Cavalcante Mattos", "authors": "Daniel Augusto R. M. A. de Souza, Diego Mesquita, C\\'esar Lincoln C.\n  Mattos, Jo\\~ao Paulo P. Gomes", "title": "Learning GPLVM with arbitrary kernels using the unscented transformation", "comments": "10 pages, currently under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gaussian Process Latent Variable Model (GPLVM) is a flexible framework to\nhandle uncertain inputs in Gaussian Processes (GPs) and incorporate GPs as\ncomponents of larger graphical models. Nonetheless, the standard GPLVM\nvariational inference approach is tractable only for a narrow family of kernel\nfunctions. The most popular implementations of GPLVM circumvent this limitation\nusing quadrature methods, which may become a computational bottleneck even for\nrelatively low dimensions. For instance, the widely employed Gauss-Hermite\nquadrature has exponential complexity on the number of dimensions. In this\nwork, we propose using the unscented transformation instead. Overall, this\nmethod presents comparable, if not better, performance than offthe-shelf\nsolutions to GPLVM and its computational complexity scales only linearly on\ndimension. In contrast to Monte Carlo methods, our approach is deterministic\nand works well with quasi-Newton methods, such as the\nBroyden-Fletcher-Goldfarb-Shanno (BFGS) algorithm. We illustrate the\napplicability of our method with experiments on dimensionality reduction and\nmultistep-ahead prediction with uncertainty propagation.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jul 2019 11:59:04 GMT"}, {"version": "v2", "created": "Tue, 10 Nov 2020 19:35:03 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["de Souza", "Daniel Augusto R. M. A.", ""], ["Mesquita", "Diego", ""], ["Mattos", "C\u00e9sar Lincoln C.", ""], ["Gomes", "Jo\u00e3o Paulo P.", ""]]}, {"id": "1907.01869", "submitter": "Panagiotis Linardos", "authors": "Panagiotis Linardos, Eva Mohedano, Juan Jose Nieto, Noel E. O'Connor,\n  Xavier Giro-i-Nieto, Kevin McGuinness", "title": "Simple vs complex temporal recurrences for video saliency prediction", "comments": "Accepted at BMVC 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates modifying an existing neural network architecture for\nstatic saliency prediction using two types of recurrences that integrate\ninformation from the temporal domain. The first modification is the addition of\na ConvLSTM within the architecture, while the second is a conceptually simple\nexponential moving average of an internal convolutional state. We use weights\npre-trained on the SALICON dataset and fine-tune our model on DHF1K. Our\nresults show that both modifications achieve state-of-the-art results and\nproduce similar saliency maps. Source code is available at\nhttps://git.io/fjPiB.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jul 2019 12:02:05 GMT"}, {"version": "v2", "created": "Tue, 9 Jul 2019 14:03:42 GMT"}, {"version": "v3", "created": "Thu, 11 Jul 2019 16:03:44 GMT"}, {"version": "v4", "created": "Tue, 16 Jul 2019 13:13:46 GMT"}], "update_date": "2019-07-17", "authors_parsed": [["Linardos", "Panagiotis", ""], ["Mohedano", "Eva", ""], ["Nieto", "Juan Jose", ""], ["O'Connor", "Noel E.", ""], ["Giro-i-Nieto", "Xavier", ""], ["McGuinness", "Kevin", ""]]}, {"id": "1907.01882", "submitter": "Fangcheng Fu", "authors": "Fangcheng Fu, Jiawei Jiang, Yingxia Shao, Bin Cui", "title": "An Experimental Evaluation of Large Scale GBDT Systems", "comments": "Technical Report for paper to appear in VLDB 2019", "journal-ref": null, "doi": "10.14778/3342263.3342273", "report-no": null, "categories": "cs.LG cs.DB stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gradient boosting decision tree (GBDT) is a widely-used machine learning\nalgorithm in both data analytic competitions and real-world industrial\napplications. Further, driven by the rapid increase in data volume, efforts\nhave been made to train GBDT in a distributed setting to support large-scale\nworkloads. However, we find it surprising that the existing systems manage the\ntraining dataset in different ways, but none of them have studied the impact of\ndata management. To that end, this paper aims to study the pros and cons of\ndifferent data management methods regarding the performance of distributed\nGBDT. We first introduce a quadrant categorization of data management policies\nbased on data partitioning and data storage. Then we conduct an in-depth\nsystematic analysis and summarize the advantageous scenarios of the quadrants.\nBased on the analysis, we further propose a novel distributed GBDT system named\nVero, which adopts the unexplored composition of vertical partitioning and\nrow-store and suits for many large-scale cases. To validate our analysis\nempirically, we implement different quadrants in the same code base and compare\nthem under extensive workloads, and finally compare Vero with other\nstate-of-the-art systems over a wide range of datasets. Our theoretical and\nexperimental results provide a guideline on choosing a proper data management\npolicy for a given workload.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jul 2019 12:26:38 GMT"}, {"version": "v2", "created": "Mon, 5 Aug 2019 15:51:47 GMT"}], "update_date": "2019-08-06", "authors_parsed": [["Fu", "Fangcheng", ""], ["Jiang", "Jiawei", ""], ["Shao", "Yingxia", ""], ["Cui", "Bin", ""]]}, {"id": "1907.01894", "submitter": "Francis Bunnin", "authors": "F.O.Bunnin and J.Q.Smith", "title": "A Bayesian Hierarchical Model for Criminal Investigations", "comments": "57 pages, 20 figures, 8 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Potential violent criminals will often need to go through a sequence of\npreparatory steps before they can execute their plans. During this escalation\nprocess police have the opportunity to evaluate the threat posed by such people\nthrough what they know, observe and learn from intelligence reports about their\nactivities. In this paper we customise a three-level Bayesian hierarchical\nmodel to describe this process. This is able to propagate both routine and\nunexpected evidence in real time. We discuss how to set up such a model so that\nit calibrates to domain expert judgments. The model illustrations include a\nhypothetical example based on a potential vehicle based terrorist attack.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jul 2019 12:40:42 GMT"}, {"version": "v2", "created": "Tue, 5 Nov 2019 14:39:31 GMT"}], "update_date": "2019-11-06", "authors_parsed": [["Bunnin", "F. O.", ""], ["Smith", "J. Q.", ""]]}, {"id": "1907.01898", "submitter": "Amit Moscovich", "authors": "Amit Moscovich and Amit Halevi and Joakim And\\'en and Amit Singer", "title": "Cryo-EM reconstruction of continuous heterogeneity by Laplacian spectral\n  volumes", "comments": "33 pages, 10 figures", "journal-ref": "Inverse Problems, 36:2 (2020)", "doi": "10.1088/1361-6420/ab4f55", "report-no": null, "categories": "eess.IV cs.LG stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Single-particle electron cryomicroscopy is an essential tool for\nhigh-resolution 3D reconstruction of proteins and other biological\nmacromolecules. An important challenge in cryo-EM is the reconstruction of\nnon-rigid molecules with parts that move and deform. Traditional reconstruction\nmethods fail in these cases, resulting in smeared reconstructions of the moving\nparts. This poses a major obstacle for structural biologists, who need\nhigh-resolution reconstructions of entire macromolecules, moving parts\nincluded. To address this challenge, we present a new method for the\nreconstruction of macromolecules exhibiting continuous heterogeneity. The\nproposed method uses projection images from multiple viewing directions to\nconstruct a graph Laplacian through which the manifold of three-dimensional\nconformations is analyzed. The 3D molecular structures are then expanded in a\nbasis of Laplacian eigenvectors, using a novel generalized tomographic\nreconstruction algorithm to compute the expansion coefficients. These\ncoefficients, which we name spectral volumes, provide a high-resolution\nvisualization of the molecular dynamics. We provide a theoretical analysis and\nevaluate the method empirically on several simulated data sets.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jul 2019 22:58:05 GMT"}, {"version": "v2", "created": "Thu, 26 Sep 2019 21:00:48 GMT"}], "update_date": "2021-05-31", "authors_parsed": [["Moscovich", "Amit", ""], ["Halevi", "Amit", ""], ["And\u00e9n", "Joakim", ""], ["Singer", "Amit", ""]]}, {"id": "1907.01901", "submitter": "Ross Kleiman PhD", "authors": "Ross S. Kleiman, Paul S. Bennett, Peggy L. Peissig, Richard L. Berg,\n  Zhaobin Kuang, Scott J. Hebbring, Michael D. Caldwell, David Page", "title": "High-Throughput Machine Learning from Electronic Health Records", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The widespread digitization of patient data via electronic health records\n(EHRs) has created an unprecedented opportunity to use machine learning\nalgorithms to better predict disease risk at the patient level. Although\npredictive models have previously been constructed for a few important\ndiseases, such as breast cancer and myocardial infarction, we currently know\nvery little about how accurately the risk for most diseases or events can be\npredicted, and how far in advance. Machine learning algorithms use training\ndata rather than preprogrammed rules to make predictions and are well suited\nfor the complex task of disease prediction. Although there are thousands of\nconditions and illnesses patients can encounter, no prior research\nsimultaneously predicts risks for thousands of diagnosis codes and thereby\nestablishes a comprehensive patient risk profile. Here we show that such\npandiagnostic prediction is possible with a high level of performance across\ndiagnosis codes. For the tasks of predicting diagnosis risks both 1 and 6\nmonths in advance, we achieve average areas under the receiver operating\ncharacteristic curve (AUCs) of 0.803 and 0.758, respectively, across thousands\nof prediction tasks. Finally, our research contributes a new clinical\nprediction dataset in which researchers can explore how well a diagnosis can be\npredicted and what health factors are most useful for prediction. For the first\ntime, we can get a much more complete picture of how well risks for thousands\nof different diagnosis codes can be predicted.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jul 2019 12:46:33 GMT"}], "update_date": "2019-07-04", "authors_parsed": [["Kleiman", "Ross S.", ""], ["Bennett", "Paul S.", ""], ["Peissig", "Peggy L.", ""], ["Berg", "Richard L.", ""], ["Kuang", "Zhaobin", ""], ["Hebbring", "Scott J.", ""], ["Caldwell", "Michael D.", ""], ["Page", "David", ""]]}, {"id": "1907.01913", "submitter": "Rahman Attar", "authors": "Rahman Attar, Marco Pereanez, Christopher Bowles, Stefan K. Piechnik,\n  Stefan Neubauer, Steffen E. Petersen, Alejandro F. Frangi", "title": "3D Cardiac Shape Prediction with Deep Neural Networks: Simultaneous Use\n  of Images and Patient Metadata", "comments": "Accepted for publication in MICCAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large prospective epidemiological studies acquire cardiovascular magnetic\nresonance (CMR) images for pre-symptomatic populations and follow these over\ntime. To support this approach, fully automatic large-scale 3D analysis is\nessential. In this work, we propose a novel deep neural network using both CMR\nimages and patient metadata to directly predict cardiac shape parameters. The\nproposed method uses the promising ability of statistical shape models to\nsimplify shape complexity and variability together with the advantages of\nconvolutional neural networks for the extraction of solid visual features. To\nthe best of our knowledge, this is the first work that uses such an approach\nfor 3D cardiac shape prediction. We validated our proposed CMR analytics method\nagainst a reference cohort containing 500 3D shapes of the cardiac ventricles.\nOur results show broadly significant agreement with the reference shapes in\nterms of the estimated volume of the cardiac ventricles, myocardial mass, 3D\nDice, and mean and Hausdorff distance.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jul 2019 12:29:20 GMT"}], "update_date": "2019-07-04", "authors_parsed": [["Attar", "Rahman", ""], ["Pereanez", "Marco", ""], ["Bowles", "Christopher", ""], ["Piechnik", "Stefan K.", ""], ["Neubauer", "Stefan", ""], ["Petersen", "Steffen E.", ""], ["Frangi", "Alejandro F.", ""]]}, {"id": "1907.01914", "submitter": "Dmytro Tkanov", "authors": "Ievgen Karaulov, Dmytro Tkanov", "title": "Attention model for articulatory features detection", "comments": "Interspeech 2019, 5 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Articulatory distinctive features, as well as phonetic transcription, play\nimportant role in speech-related tasks: computer-assisted pronunciation\ntraining, text-to-speech conversion (TTS), studying speech production\nmechanisms, speech recognition for low-resourced languages. End-to-end\napproaches to speech-related tasks got a lot of traction in recent years. We\napply Listen, Attend and Spell~(LAS)~\\cite{Chan-LAS2016} architecture to phones\nrecognition on a small small training set, like TIMIT~\\cite{TIMIT-1992}. Also,\nwe introduce a novel decoding technique that allows to train manners and places\nof articulation detectors end-to-end using attention models. We also explore\njoint phones recognition and articulatory features detection in multitask\nlearning setting.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jul 2019 10:30:27 GMT"}], "update_date": "2019-07-04", "authors_parsed": [["Karaulov", "Ievgen", ""], ["Tkanov", "Dmytro", ""]]}, {"id": "1907.01919", "submitter": "Ping-En Lu", "authors": "Jen-Hung Wang, Ping-En Lu, Cheng-Shang Chang, and Duan-Shin Lee", "title": "A Reinforcement Learning Approach for the Multichannel Rendezvous\n  Problem", "comments": "5 pages, 9 figures. arXiv admin note: text overlap with\n  arXiv:1906.10424", "journal-ref": "2019 IEEE Globecom Workshops (GC Wkshps), Waikoloa, HI, USA, 2019,\n  pp. 1-5", "doi": "10.1109/GCWkshps45667.2019.9024429", "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider the multichannel rendezvous problem in cognitive\nradio networks (CRNs) where the probability that two users hopping on the same\nchannel have a successful rendezvous is a function of channel states. The\nchannel states are modelled by two-state Markov chains that have a good state\nand a bad state. These channel states are not observable by the users. For such\na multichannel rendezvous problem, we are interested in finding the optimal\npolicy to minimize the expected time-to-rendezvous (ETTR) among the class of\n{\\em dynamic blind rendezvous policies}, i.e., at the $t^{th}$ time slot each\nuser selects channel $i$ independently with probability $p_i(t)$, $i=1,2,\n\\ldots, N$. By formulating such a multichannel rendezvous problem as an\nadversarial bandit problem, we propose using a reinforcement learning approach\nto learn the channel selection probabilities $p_i(t)$, $i=1,2, \\ldots, N$. Our\nexperimental results show that the reinforcement learning approach is very\neffective and yields comparable ETTRs when comparing to various approximation\npolicies in the literature.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jul 2019 08:37:06 GMT"}, {"version": "v2", "created": "Fri, 5 Jul 2019 08:46:20 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Wang", "Jen-Hung", ""], ["Lu", "Ping-En", ""], ["Chang", "Cheng-Shang", ""], ["Lee", "Duan-Shin", ""]]}, {"id": "1907.01929", "submitter": "German I. Parisi", "authors": "German I. Parisi, Christopher Kanan", "title": "Rethinking Continual Learning for Autonomous Agents and Robots", "comments": "arXiv admin note: substantial text overlap with arXiv:1802.07569", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Continual learning refers to the ability of a biological or artificial system\nto seamlessly learn from continuous streams of information while preventing\ncatastrophic forgetting, i.e., a condition in which new incoming information\nstrongly interferes with previously learned representations. Since it is\nunrealistic to provide artificial agents with all the necessary prior knowledge\nto effectively operate in real-world conditions, they must exhibit a rich set\nof learning capabilities enabling them to interact in complex environments with\nthe aim to process and make sense of continuous streams of (often uncertain)\ninformation. While the vast majority of continual learning models are designed\nto alleviate catastrophic forgetting on simplified classification tasks, here\nwe focus on continual learning for autonomous agents and robots required to\noperate in much more challenging experimental settings. In particular, we\ndiscuss well-established biological learning factors such as developmental and\ncurriculum learning, transfer learning, and intrinsic motivation and their\ncomputational counterparts for modeling the progressive acquisition of\nincreasingly complex knowledge and skills in a continual fashion.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jul 2019 16:51:45 GMT"}], "update_date": "2019-07-04", "authors_parsed": [["Parisi", "German I.", ""], ["Kanan", "Christopher", ""]]}, {"id": "1907.01949", "submitter": "Shi Hu", "authors": "Shi Hu and Daniel Worrall and Stefan Knegt and Bas Veeling and Henkjan\n  Huisman and Max Welling", "title": "Supervised Uncertainty Quantification for Segmentation with Multiple\n  Annotations", "comments": "Accepted as a conference paper to MICCAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The accurate estimation of predictive uncertainty carries importance in\nmedical scenarios such as lung node segmentation. Unfortunately, most existing\nworks on predictive uncertainty do not return calibrated uncertainty estimates,\nwhich could be used in practice. In this work we exploit multi-grader\nannotation variability as a source of 'groundtruth' aleatoric uncertainty,\nwhich can be treated as a target in a supervised learning problem. We combine\nthis groundtruth uncertainty with a Probabilistic U-Net and test on the\nLIDC-IDRI lung nodule CT dataset and MICCAI2012 prostate MRI dataset. We find\nthat we are able to improve predictive uncertainty estimates. We also find that\nwe can improve sample accuracy and sample diversity.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jul 2019 13:53:54 GMT"}], "update_date": "2019-07-04", "authors_parsed": [["Hu", "Shi", ""], ["Worrall", "Daniel", ""], ["Knegt", "Stefan", ""], ["Veeling", "Bas", ""], ["Huisman", "Henkjan", ""], ["Welling", "Max", ""]]}, {"id": "1907.01953", "submitter": "Armin Thomas", "authors": "Armin W. Thomas, Klaus-Robert M\\\"uller and Wojciech Samek", "title": "Deep Transfer Learning For Whole-Brain fMRI Analyses", "comments": "8 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The application of deep learning (DL) models to the decoding of cognitive\nstates from whole-brain functional Magnetic Resonance Imaging (fMRI) data is\noften hindered by the small sample size and high dimensionality of these\ndatasets. Especially, in clinical settings, where patient data are scarce. In\nthis work, we demonstrate that transfer learning represents a solution to this\nproblem. Particularly, we show that a DL model, which has been previously\ntrained on a large openly available fMRI dataset of the Human Connectome\nProject, outperforms a model variant with the same architecture, but which is\ntrained from scratch, when both are applied to the data of a new, unrelated\nfMRI task. Even further, the pre-trained DL model variant is already able to\ncorrectly decode 67.51% of the cognitive states from a test dataset with 100\nindividuals, when fine-tuned on a dataset of the size of only three subjects.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jul 2019 10:03:54 GMT"}], "update_date": "2019-07-04", "authors_parsed": [["Thomas", "Armin W.", ""], ["M\u00fcller", "Klaus-Robert", ""], ["Samek", "Wojciech", ""]]}, {"id": "1907.01959", "submitter": "Saeid Soheily Khah", "authors": "Saeid Soheily Khah, Yiming Wu", "title": "An Enhanced Ad Event-Prediction Method Based on Feature Engineering", "comments": "8th International Conference on Soft Computing, Artificial\n  Intelligence and Applications (SAI 2019), June 29-30, 2019, Copenhagen,\n  Denmark", "journal-ref": "AIRCC Publishing Corporation, 8th International Conference on Soft\n  Computing, Artificial Intelligence and Applications (SAI 2019), Volume\n  Editors: Natarajan Meghanathan and David wyld(Eds), ISBN: 978-1-925953-03-9", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In digital advertising, Click-Through Rate (CTR) and Conversion Rate (CVR)\nare very important metrics for evaluating ad performance. As a result, ad event\nprediction systems are vital and widely used for sponsored search and display\nadvertising as well as Real-Time Bidding (RTB). In this work, we introduce an\nenhanced method for ad event prediction (i.e. clicks, conversions) by proposing\na new efficient feature engineering approach. A large real-world event-based\ndataset of a running marketing campaign is used to evaluate the efficiency of\nthe proposed prediction algorithm. The results illustrate the benefits of the\nproposed ad event prediction approach, which significantly outperforms the\nalternative ones.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jul 2019 14:16:10 GMT"}], "update_date": "2019-07-04", "authors_parsed": [["Khah", "Saeid Soheily", ""], ["Wu", "Yiming", ""]]}, {"id": "1907.01974", "submitter": "Jonathan Johannemann", "authors": "Jonathan Johannemann, Robert Tibshirani", "title": "Spectral Overlap and a Comparison of Parameter-Free, Dimensionality\n  Reduction Quality Metrics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Nonlinear dimensionality reduction methods are a popular tool for data\nscientists and researchers to visualize complex, high dimensional data.\nHowever, while these methods continue to improve and grow in number, it is\noften difficult to evaluate the quality of a visualization due to a variety of\nfactors such as lack of information about the intrinsic dimension of the data\nand additional tuning required for many evaluation metrics. In this paper, we\nseek to provide a systematic comparison of dimensionality reduction quality\nmetrics using datasets where we know the ground truth manifold. We utilize each\nmetric for hyperparameter optimization in popular dimensionality reduction\nmethods used for visualization and provide quantitative metrics to objectively\ncompare visualizations to their original manifold. In our results, we find a\nfew methods that appear to consistently do well and propose the best performer\nas a benchmark for evaluating dimensionality reduction based visualizations.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jul 2019 14:53:21 GMT"}, {"version": "v2", "created": "Tue, 3 Sep 2019 06:37:50 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Johannemann", "Jonathan", ""], ["Tibshirani", "Robert", ""]]}, {"id": "1907.01989", "submitter": "Juhyun Lee", "authors": "Juhyun Lee, Nikolay Chirkov, Ekaterina Ignasheva, Yury Pisarchyk,\n  Mogan Shieh, Fabio Riccardi, Raman Sarokin, Andrei Kulik, and Matthias\n  Grundmann", "title": "On-Device Neural Net Inference with Mobile GPUs", "comments": "Computer Vision and Pattern Recognition Workshop: Efficient Deep\n  Learning for Computer Vision 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  On-device inference of machine learning models for mobile phones is desirable\ndue to its lower latency and increased privacy. Running such a\ncompute-intensive task solely on the mobile CPU, however, can be difficult due\nto limited computing power, thermal constraints, and energy consumption. App\ndevelopers and researchers have begun exploiting hardware accelerators to\novercome these challenges. Recently, device manufacturers are adding neural\nprocessing units into high-end phones for on-device inference, but these\naccount for only a small fraction of hand-held devices. In this paper, we\npresent how we leverage the mobile GPU, a ubiquitous hardware accelerator on\nvirtually every phone, to run inference of deep neural networks in real-time\nfor both Android and iOS devices. By describing our architecture, we also\ndiscuss how to design networks that are mobile GPU-friendly. Our\nstate-of-the-art mobile GPU inference engine is integrated into the open-source\nproject TensorFlow Lite and publicly available at https://tensorflow.org/lite.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jul 2019 15:23:20 GMT"}], "update_date": "2019-10-16", "authors_parsed": [["Lee", "Juhyun", ""], ["Chirkov", "Nikolay", ""], ["Ignasheva", "Ekaterina", ""], ["Pisarchyk", "Yury", ""], ["Shieh", "Mogan", ""], ["Riccardi", "Fabio", ""], ["Sarokin", "Raman", ""], ["Kulik", "Andrei", ""], ["Grundmann", "Matthias", ""]]}, {"id": "1907.01991", "submitter": "Alan Mishchenko", "authors": "Satrajit Chatterjee, Alan Mishchenko", "title": "Circuit-Based Intrinsic Methods to Detect Overfitting", "comments": "37th International Conference on Machine Learning held as a virtual\n  conference on July 12-18, 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The focus of this paper is on intrinsic methods to detect overfitting. By\nintrinsic methods, we mean methods that rely only on the model and the training\ndata, as opposed to traditional methods (we call them extrinsic methods) that\nrely on performance on a test set or on bounds from model complexity. We\npropose a family of intrinsic methods, called Counterfactual Simulation (CFS),\nwhich analyze the flow of training examples through the model by identifying\nand perturbing rare patterns. By applying CFS to logic circuits we get a method\nthat has no hyper-parameters and works uniformly across different types of\nmodels such as neural networks, random forests and lookup tables.\nExperimentally, CFS can separate models with different levels of overfit using\nonly their logic circuit representations without any access to the high level\nstructure. By comparing lookup tables, neural networks, and random forests\nusing CFS, we get insight into why neural networks generalize. In particular,\nwe find that stochastic gradient descent in neural nets does not lead to \"brute\nforce\" memorization, but finds common patterns (whether we train with actual or\nrandomized labels), and neural networks are not unlike forests in this regard.\nFinally, we identify a limitation with our proposal that makes it unsuitable in\nan adversarial setting, but points the way to future work on robust intrinsic\nmethods.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jul 2019 15:32:35 GMT"}, {"version": "v2", "created": "Wed, 5 Aug 2020 23:35:09 GMT"}], "update_date": "2020-08-07", "authors_parsed": [["Chatterjee", "Satrajit", ""], ["Mishchenko", "Alan", ""]]}, {"id": "1907.01992", "submitter": "Andreas Maier", "authors": "Andreas K. Maier, Christopher Syben, Bernhard Stimpel, Tobias W\\\"urfl,\n  Mathis Hoffmann, Frank Schebesch, Weilin Fu, Leonid Mill, Lasse Kling, and\n  Silke Christiansen", "title": "Learning with Known Operators reduces Maximum Training Error Bounds", "comments": "Paper conditionally accepted in Nature Machine Intelligence", "journal-ref": "Nature Machine Intelligence 1, 373-380, 2019", "doi": "10.1038/s42256-019-0077-5", "report-no": null, "categories": "cs.LG cs.CV physics.med-ph stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We describe an approach for incorporating prior knowledge into machine\nlearning algorithms. We aim at applications in physics and signal processing in\nwhich we know that certain operations must be embedded into the algorithm. Any\noperation that allows computation of a gradient or sub-gradient towards its\ninputs is suited for our framework. We derive a maximal error bound for deep\nnets that demonstrates that inclusion of prior knowledge results in its\nreduction. Furthermore, we also show experimentally that known operators reduce\nthe number of free parameters. We apply this approach to various tasks ranging\nfrom CT image reconstruction over vessel segmentation to the derivation of\npreviously unknown imaging algorithms. As such the concept is widely applicable\nfor many researchers in physics, imaging, and signal processing. We assume that\nour analysis will support further investigation of known operators in other\nfields of physics, imaging, and signal processing.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jul 2019 15:35:16 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Maier", "Andreas K.", ""], ["Syben", "Christopher", ""], ["Stimpel", "Bernhard", ""], ["W\u00fcrfl", "Tobias", ""], ["Hoffmann", "Mathis", ""], ["Schebesch", "Frank", ""], ["Fu", "Weilin", ""], ["Mill", "Leonid", ""], ["Kling", "Lasse", ""], ["Christiansen", "Silke", ""]]}, {"id": "1907.01995", "submitter": "Mingxi Zhu", "authors": "Mingxi Zhu, Kresimir Mihic, Yinyu Ye", "title": "On a Randomized Multi-Block ADMM for Solving Selected Machine Learning\n  Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Alternating Direction Method of Multipliers (ADMM) has now days gained\ntremendous attentions for solving large-scale machine learning and signal\nprocessing problems due to the relative simplicity. However, the two-block\nstructure of the classical ADMM still limits the size of the real problems\nbeing solved. When one forces a more-than-two-block structure by\nvariable-splitting, the convergence speed slows down greatly as observed in\npractice. Recently, a randomly assembled cyclic multi-block ADMM (RAC-MBADMM)\nwas developed by the authors for solving general convex and nonconvex quadratic\noptimization problems where the number of blocks can go greater than two so\nthat each sub-problem has a smaller size and can be solved much more\nefficiently. In this paper, we apply this method to solving few selected\nmachine learning problems related to convex quadratic optimization, such as\nLinear Regression, LASSO, Elastic-Net, and SVM. We prove that the algorithm\nwould converge in expectation linearly under the standard statistical data\nassumptions. We use our general-purpose solver to conduct multiple numerical\ntests, solving both synthetic and large-scale bench-mark problems. Our results\nshow that RAC-MBADMM could significantly outperform, in both solution time and\nquality, other optimization algorithms/codes for solving these machine learning\nproblems, and match up the performance of the best tailored methods such as\nGlmnet or LIBSVM. In certain problem regions RAC-MBADMM even achieves a\nsuperior performance than that of the tailored methods.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jul 2019 15:38:01 GMT"}, {"version": "v2", "created": "Fri, 20 Mar 2020 07:52:02 GMT"}], "update_date": "2020-03-23", "authors_parsed": [["Zhu", "Mingxi", ""], ["Mihic", "Kresimir", ""], ["Ye", "Yinyu", ""]]}, {"id": "1907.02015", "submitter": "Jonas Fassbender", "authors": "Jonas Fassbender", "title": "libconform v0.1.0: a Python library for conformal prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper introduces libconform v0.1.0, a Python library for the conformal\nprediction framework, licensed under the MIT-license. libconform is not yet\nstable. This paper describes the main algorithms implemented and documents the\nAPI of libconform. Also some details about the implementation and changes in\nfuture versions are described.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jul 2019 16:24:10 GMT"}], "update_date": "2019-07-04", "authors_parsed": [["Fassbender", "Jonas", ""]]}, {"id": "1907.02044", "submitter": "Francesco Croce", "authors": "Francesco Croce, Matthias Hein", "title": "Minimally distorted Adversarial Examples with a Fast Adaptive Boundary\n  Attack", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The evaluation of robustness against adversarial manipulation of neural\nnetworks-based classifiers is mainly tested with empirical attacks as methods\nfor the exact computation, even when available, do not scale to large networks.\nWe propose in this paper a new white-box adversarial attack wrt the $l_p$-norms\nfor $p \\in \\{1,2,\\infty\\}$ aiming at finding the minimal perturbation necessary\nto change the class of a given input. It has an intuitive geometric meaning,\nyields quickly high quality results, minimizes the size of the perturbation (so\nthat it returns the robust accuracy at every threshold with a single run). It\nperforms better or similar to state-of-the-art attacks which are partially\nspecialized to one $l_p$-norm, and is robust to the phenomenon of gradient\nmasking.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jul 2019 17:22:05 GMT"}, {"version": "v2", "created": "Mon, 20 Jul 2020 15:18:47 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Croce", "Francesco", ""], ["Hein", "Matthias", ""]]}, {"id": "1907.02046", "submitter": "Lin Li", "authors": "Donghang Pan, Jingling Yuan, Lin Li, Deming Sheng", "title": "Deep neural network-based classification model for Sentiment Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The growing prosperity of social networks has brought great challenges to the\nsentimental tendency mining of users. As more and more researchers pay\nattention to the sentimental tendency of online users, rich research results\nhave been obtained based on the sentiment classification of explicit texts.\nHowever, research on the implicit sentiment of users is still in its infancy.\nAiming at the difficulty of implicit sentiment classification, a research on\nimplicit sentiment classification model based on deep neural network is carried\nout. Classification models based on DNN, LSTM, Bi-LSTM and CNN were established\nto judge the tendency of the user's implicit sentiment text. Based on the\nBi-LSTM model, the classification model of word-level attention mechanism is\nstudied. The experimental results on the public dataset show that the\nestablished LSTM series classification model and CNN classification model can\nachieve good sentiment classification effect, and the classification effect is\nsignificantly better than the DNN model. The Bi-LSTM based attention mechanism\nclassification model obtained the optimal R value in the positive category\nidentification.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jul 2019 17:24:14 GMT"}], "update_date": "2019-07-04", "authors_parsed": [["Pan", "Donghang", ""], ["Yuan", "Jingling", ""], ["Li", "Lin", ""], ["Sheng", "Deming", ""]]}, {"id": "1907.02050", "submitter": "Daniel Saunders", "authors": "Sam Wenke, Dan Saunders, Mike Qiu, Jim Fleming", "title": "Reasoning and Generalization in RL: A Tool Use Perspective", "comments": "13 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning to use tools to solve a variety of tasks is an innate ability of\nhumans and has been observed of animals in the wild. However, the underlying\nmechanisms that are required to learn to use tools are abstract and widely\ncontested in the literature. In this paper, we study tool use in the context of\nreinforcement learning and propose a framework for analyzing generalization\ninspired by a classic study of tool using behavior, the trap-tube task.\nRecently, it has become common in reinforcement learning to measure\ngeneralization performance on a single test set of environments. We instead\npropose transfers that produce multiple test sets that are used to measure\nspecified types of generalization, inspired by abilities demonstrated by animal\nand human tool users. The source code to reproduce our experiments is publicly\navailable at https://github.com/fomorians/gym_tool_use.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jul 2019 17:35:58 GMT"}], "update_date": "2019-07-04", "authors_parsed": [["Wenke", "Sam", ""], ["Saunders", "Dan", ""], ["Qiu", "Mike", ""], ["Fleming", "Jim", ""]]}, {"id": "1907.02051", "submitter": "Arman Hasanzadeh Moghimi", "authors": "Arman Hasanzadeh, Nagaraj T. Janakiraman, Vamsi K. Amalladinne,\n  Krishna R. Narayanan", "title": "Spatially-Coupled Neural Network Architectures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we leverage advances in sparse coding techniques to reduce the\nnumber of trainable parameters in a fully connected neural network. While most\nof the works in literature impose $\\ell_1$ regularization, DropOut or\nDropConnect techniques to induce sparsity, our scheme considers feature\nimportance as a criterion to allocate the trainable parameters (resources)\nefficiently in the network. Even though sparsity is ensured, $\\ell_1$\nregularization requires training on all the resources in a deep neural network.\nThe DropOut/DropConnect techniques reduce the number of trainable parameters in\nthe training stage by dropping a random collection of neurons/edges in the\nhidden layers. However, both these techniques do not pay heed to the underlying\nstructure in the data when dropping the neurons/edges. Moreover, these\nframeworks require a storage space equivalent to the number of parameters in a\nfully connected neural network. We address the above issues with a more\nstructured architecture inspired from spatially-coupled sparse constructions.\nThe proposed architecture is shown to have a performance akin to a conventional\nfully connected neural network with dropouts, and yet achieving a $94\\%$\nreduction in the training parameters. Extensive simulations are presented and\nthe performance of the proposed scheme is compared against traditional neural\nnetwork architectures.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jul 2019 17:37:35 GMT"}], "update_date": "2019-07-04", "authors_parsed": [["Hasanzadeh", "Arman", ""], ["Janakiraman", "Nagaraj T.", ""], ["Amalladinne", "Vamsi K.", ""], ["Narayanan", "Krishna R.", ""]]}, {"id": "1907.02052", "submitter": "Jieh-Sheng Lee", "authors": "Jieh-Sheng Lee and Jieh Hsiang", "title": "Patent Claim Generation by Fine-Tuning OpenAI GPT-2", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we focus on fine-tuning an OpenAI GPT-2 pre-trained model for\ngenerating patent claims. GPT-2 has demonstrated impressive efficacy of\npre-trained language models on various tasks, particularly coherent text\ngeneration. Patent claim language itself has rarely been explored in the past\nand poses a unique challenge. We are motivated to generate coherent patent\nclaims automatically so that augmented inventing might be viable someday. In\nour implementation, we identified a unique language structure in patent claims\nand leveraged its implicit human annotations. We investigated the fine-tuning\nprocess by probing the first 100 steps and observing the generated text at each\nstep. Based on both conditional and unconditional random sampling, we analyze\nthe overall quality of generated patent claims. Our contributions include: (1)\nbeing the first to generate patent claims by machines and being the first to\napply GPT-2 to patent claim generation, (2) providing various experiment\nresults for qualitative analysis and future research, (3) proposing a new\nsampling approach for text generation, and (4) building an e-mail bot for\nfuture researchers to explore the fine-tuned GPT-2 model further.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jul 2019 00:02:59 GMT"}], "update_date": "2019-07-04", "authors_parsed": [["Lee", "Jieh-Sheng", ""], ["Hsiang", "Jieh", ""]]}, {"id": "1907.02056", "submitter": "Yair Carmon", "authors": "Yair Carmon, Yujia Jin, Aaron Sidford and Kevin Tian", "title": "Variance Reduction for Matrix Games", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a randomized primal-dual algorithm that solves the problem\n$\\min_{x} \\max_{y} y^\\top A x$ to additive error $\\epsilon$ in time\n$\\mathrm{nnz}(A) + \\sqrt{\\mathrm{nnz}(A)n}/\\epsilon$, for matrix $A$ with\nlarger dimension $n$ and $\\mathrm{nnz}(A)$ nonzero entries. This improves the\nbest known exact gradient methods by a factor of $\\sqrt{\\mathrm{nnz}(A)/n}$ and\nis faster than fully stochastic gradient methods in the accurate and/or sparse\nregime $\\epsilon \\le \\sqrt{n/\\mathrm{nnz}(A)}$. Our results hold for $x,y$ in\nthe simplex (matrix games, linear programming) and for $x$ in an $\\ell_2$ ball\nand $y$ in the simplex (perceptron / SVM, minimum enclosing ball). Our\nalgorithm combines Nemirovski's \"conceptual prox-method\" and a novel\nreduced-variance gradient estimator based on \"sampling from the difference\"\nbetween the current iterate and a reference point.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jul 2019 17:51:35 GMT"}, {"version": "v2", "created": "Sun, 1 Dec 2019 03:43:42 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Carmon", "Yair", ""], ["Jin", "Yujia", ""], ["Sidford", "Aaron", ""], ["Tian", "Kevin", ""]]}, {"id": "1907.02057", "submitter": "Tingwu Wang", "authors": "Tingwu Wang, Xuchan Bao, Ignasi Clavera, Jerrick Hoang, Yeming Wen,\n  Eric Langlois, Shunshi Zhang, Guodong Zhang, Pieter Abbeel, Jimmy Ba", "title": "Benchmarking Model-Based Reinforcement Learning", "comments": "8 main pages, 8 figures; 14 appendix pages, 25 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Model-based reinforcement learning (MBRL) is widely seen as having the\npotential to be significantly more sample efficient than model-free RL.\nHowever, research in model-based RL has not been very standardized. It is\nfairly common for authors to experiment with self-designed environments, and\nthere are several separate lines of research, which are sometimes\nclosed-sourced or not reproducible. Accordingly, it is an open question how\nthese various existing MBRL algorithms perform relative to each other. To\nfacilitate research in MBRL, in this paper we gather a wide collection of MBRL\nalgorithms and propose over 18 benchmarking environments specially designed for\nMBRL. We benchmark these algorithms with unified problem settings, including\nnoisy environments. Beyond cataloguing performance, we explore and unify the\nunderlying algorithmic differences across MBRL algorithms. We characterize\nthree key research challenges for future MBRL research: the dynamics\nbottleneck, the planning horizon dilemma, and the early-termination dilemma.\nFinally, to maximally facilitate future research on MBRL, we open-source our\nbenchmark in http://www.cs.toronto.edu/~tingwuwang/mbrl.html.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jul 2019 17:53:02 GMT"}], "update_date": "2019-07-04", "authors_parsed": [["Wang", "Tingwu", ""], ["Bao", "Xuchan", ""], ["Clavera", "Ignasi", ""], ["Hoang", "Jerrick", ""], ["Wen", "Yeming", ""], ["Langlois", "Eric", ""], ["Zhang", "Shunshi", ""], ["Zhang", "Guodong", ""], ["Abbeel", "Pieter", ""], ["Ba", "Jimmy", ""]]}, {"id": "1907.02065", "submitter": "Lakshay Sharma", "authors": "Elaina Tan, Lakshay Sharma", "title": "Neural Image Captioning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, the biggest advances in major Computer Vision tasks, such as\nobject recognition, handwritten-digit identification, facial recognition, and\nmany others., have all come through the use of Convolutional Neural Networks\n(CNNs). Similarly, in the domain of Natural Language Processing, Recurrent\nNeural Networks (RNNs), and Long Short Term Memory networks (LSTMs) in\nparticular, have been crucial to some of the biggest breakthroughs in\nperformance for tasks such as machine translation, part-of-speech tagging,\nsentiment analysis, and many others. These individual advances have greatly\nbenefited tasks even at the intersection of NLP and Computer Vision, and\ninspired by this success, we studied some existing neural image captioning\nmodels that have proven to work well. In this work, we study some existing\ncaptioning models that provide near state-of-the-art performances, and try to\nenhance one such model. We also present a simple image captioning model that\nmakes use of a CNN, an LSTM, and the beam search1 algorithm, and study its\nperformance based on various qualitative and quantitative metrics.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jul 2019 22:49:25 GMT"}], "update_date": "2019-07-05", "authors_parsed": [["Tan", "Elaina", ""], ["Sharma", "Lakshay", ""]]}, {"id": "1907.02098", "submitter": "Philipp Windischhofer", "authors": "Philipp Windischhofer, Miha Zgubic, Daniela Bortoletto", "title": "Preserving physically important variables in optimal event selections: A\n  case study in Higgs physics", "comments": null, "journal-ref": null, "doi": "10.1007/JHEP07(2020)001", "report-no": null, "categories": "hep-ph cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Analyses of collider data, often assisted by modern Machine Learning methods,\ncondense a number of observables into a few powerful discriminants for the\nseparation of the targeted signal process from the contributing backgrounds.\nThese discriminants are highly correlated with important physical observables;\nusing them in the event selection thus leads to the distortion of physically\nrelevant distributions. We present a novel method based on a differentiable\nestimate of mutual information, a measure of non-linear dependency between\nvariables, to construct a discriminant that is statistically independent of a\nnumber of selected observables, and so manages to preserve their distributions\nin the event selection. Our strategy is evaluated in a realistic setting, the\nanalysis of the Standard Model Higgs boson decaying into a pair of bottom\nquarks. Using the distribution of the invariant mass of the di-b-jet system to\nextract the Higgs boson signal strength, our method achieves state-of-the-art\nperformance compared to other decorrelation techniques, while significantly\nimproving the sensitivity of a similar, cut-based, analysis published by ATLAS.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jul 2019 18:49:10 GMT"}, {"version": "v2", "created": "Sun, 7 Jun 2020 18:23:06 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Windischhofer", "Philipp", ""], ["Zgubic", "Miha", ""], ["Bortoletto", "Daniela", ""]]}, {"id": "1907.02100", "submitter": "Nikodem Tomczak", "authors": "Emir Hrnjic and Nikodem Tomczak", "title": "Machine learning and behavioral economics for personalized choice\n  architecture", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.GN cs.LG q-fin.EC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Behavioral economics changed the way we think about market participants and\nrevolutionized policy-making by introducing the concept of choice architecture.\nHowever, even though effective on the level of a population, interventions from\nbehavioral economics, nudges, are often characterized by weak generalisation as\nthey struggle on the level of individuals. Recent developments in data science,\nartificial intelligence (AI) and machine learning (ML) have shown ability to\nalleviate some of the problems of weak generalisation by providing tools and\nmethods that result in models with stronger predictive power. This paper aims\nto describe how ML and AI can work with behavioral economics to support and\naugment decision-making and inform policy decisions by designing personalized\ninterventions, assuming that enough personalized traits and psychological\nvariables can be sampled.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jul 2019 18:53:59 GMT"}], "update_date": "2019-07-05", "authors_parsed": [["Hrnjic", "Emir", ""], ["Tomczak", "Nikodem", ""]]}, {"id": "1907.02109", "submitter": "Ryan Cory-Wright", "authors": "Dimitris Bertsimas, Ryan Cory-Wright, Jean Pauphilet", "title": "A unified approach to mixed-integer optimization problems with logical\n  constraints", "comments": "Revised version (including title change). The old title was \"A\n  unified approach to mixed-integer optimization: Nonlinear formulations and\n  scalable algorithms\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a unified framework to address a family of classical mixed-integer\noptimization problems with logically constrained decision variables, including\nnetwork design, facility location, unit commitment, sparse portfolio selection,\nbinary quadratic optimization, sparse principal analysis and sparse learning\nproblems. These problems exhibit logical relationships between continuous and\ndiscrete variables, which are usually reformulated linearly using a big-M\nformulation. In this work, we challenge this longstanding modeling practice and\nexpress the logical constraints in a non-linear way. By imposing a\nregularization condition, we reformulate these problems as convex binary\noptimization problems, which are solvable using an outer-approximation\nprocedure. In numerical experiments, we establish that a general-purpose\nnumerical strategy, which combines cutting-plane, first-order and local search\nmethods, solves these problems faster and at a larger scale than\nstate-of-the-art mixed-integer linear or second-order cone methods. Our\napproach successfully solves network design problems with 100s of nodes and\nprovides solutions up to 40\\% better than the state-of-the-art; sparse\nportfolio selection problems with up to 3,200 securities compared with 400\nsecurities for previous attempts; and sparse regression problems with up to\n100,000 covariates.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jul 2019 19:02:28 GMT"}, {"version": "v2", "created": "Thu, 2 Jul 2020 03:42:06 GMT"}, {"version": "v3", "created": "Mon, 25 Jan 2021 15:23:12 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Bertsimas", "Dimitris", ""], ["Cory-Wright", "Ryan", ""], ["Pauphilet", "Jean", ""]]}, {"id": "1907.02110", "submitter": "Jimit Doshi", "authors": "Jimit Doshi, Guray Erus, Mohamad Habes, Christos Davatzikos", "title": "DeepMRSeg: A convolutional deep neural network for anatomy and\n  abnormality segmentation on MR images", "comments": "18 pages, 8 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Segmentation has been a major task in neuroimaging. A large number of\nautomated methods have been developed for segmenting healthy and diseased brain\ntissues. In recent years, deep learning techniques have attracted a lot of\nattention as a result of their high accuracy in different segmentation\nproblems. We present a new deep learning based segmentation method, DeepMRSeg,\nthat can be applied in a generic way to a variety of segmentation tasks. The\nproposed architecture combines recent advances in the field of biomedical image\nsegmentation and computer vision. We use a modified UNet architecture that\ntakes advantage of multiple convolution filter sizes to achieve multi-scale\nfeature extraction adaptive to the desired segmentation task. Importantly, our\nmethod operates on minimally processed raw MRI scan. We validated our method on\na wide range of segmentation tasks, including white matter lesion segmentation,\nsegmentation of deep brain structures and hippocampus segmentation. We provide\ncode and pre-trained models to allow researchers apply our method on their own\ndatasets.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jul 2019 19:10:37 GMT"}], "update_date": "2019-07-05", "authors_parsed": [["Doshi", "Jimit", ""], ["Erus", "Guray", ""], ["Habes", "Mohamad", ""], ["Davatzikos", "Christos", ""]]}, {"id": "1907.02114", "submitter": "Falcon Dai", "authors": "Falcon Z. Dai, Matthew R. Walter", "title": "Maximum Expected Hitting Cost of a Markov Decision Process and\n  Informativeness of Rewards", "comments": "Minor post-review revision. Main paper with appendix. To appear at\n  NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new complexity measure for Markov decision processes (MDPs), the\nmaximum expected hitting cost (MEHC). This measure tightens the closely related\nnotion of diameter [JOA10] by accounting for the reward structure. We show that\nthis parameter replaces diameter in the upper bound on the optimal value span\nof an extended MDP, thus refining the associated upper bounds on the regret of\nseveral UCRL2-like algorithms. Furthermore, we show that potential-based reward\nshaping [NHR99] can induce equivalent reward functions with varying\ninformativeness, as measured by MEHC. We further establish that shaping can\nreduce or increase MEHC by at most a factor of two in a large class of MDPs\nwith finite MEHC and unsaturated optimal average rewards.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jul 2019 19:41:04 GMT"}, {"version": "v2", "created": "Mon, 4 Nov 2019 19:47:40 GMT"}], "update_date": "2019-11-06", "authors_parsed": [["Dai", "Falcon Z.", ""], ["Walter", "Matthew R.", ""]]}, {"id": "1907.02121", "submitter": "Isaac Shiri", "authors": "Isaac Shiri, Hassan Maleki, Ghasem Hajianfar, Hamid Abdollahi, Saeed\n  Ashrafinia, Mathieu Hatt, Mehrdad Oveisi, Arman Rahmim", "title": "Next Generation Radiogenomics Sequencing for Prediction of EGFR and KRAS\n  Mutation Status in NSCLC Patients Using Multimodal Imaging and Machine\n  Learning Approaches", "comments": "42 pages,3 Figures,4 Tables, 13 Supplemental Figures, 11 Supplemental\n  Tables", "journal-ref": null, "doi": "10.1007/s11307-020-01487-8", "report-no": null, "categories": "physics.med-ph cs.LG physics.bio-ph q-bio.GN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Aim: In the present work, we aimed to evaluate a comprehensive radiomics\nframework that enabled prediction of EGFR and KRAS mutation status in NSCLC\ncancer patients based on PET and CT multi-modalities radiomic features and\nmachine learning (ML) algorithms. Methods: Our study involved 211 NSCLC cancer\npatient with PET and CTD images. More than twenty thousand radiomic features\nfrom different image-feature sets were extracted Feature value was normalized\nto obtain Z-scores, followed by student t-test students for comparison, high\ncorrelated features were eliminated and the False discovery rate (FDR)\ncorrection were performed Six feature selection methods and twelve classifiers\nwere used to predict gene status in patient and model evaluation was reported\non independent validation sets (68 patients). Results: The best predictive\npower of conventional PET parameters was achieved by SUVpeak (AUC: 0.69,\nP-value = 0.0002) and MTV (AUC: 0.55, P-value = 0.0011) for EGFR and KRAS,\nrespectively. Univariate analysis of radiomics features improved prediction\npower up to AUC: 75 (q-value: 0.003, Short Run Emphasis feature of GLRLM from\nLOG preprocessed image of PET with sigma value 1.5) and AUC: 0.71 (q-value\n0.00005, The Large Dependence Low Gray Level Emphasis from GLDM in LOG\npreprocessed image of CTD sigma value 5) for EGFR and KRAS, respectively.\nFurthermore, the machine learning algorithm improved the perdition power up to\nAUC: 0.82 for EGFR (LOG preprocessed of PET image set with sigma 3 with VT\nfeature selector and SGD classifier) and AUC: 0.83 for KRAS (CT image set with\nsigma 3.5 with SM feature selector and SGD classifier). Conclusion: We\ndemonstrated that radiomic features extracted from different image-feature sets\ncould be used for EGFR and KRAS mutation status prediction in NSCLC patients,\nand showed that they have more predictive power than conventional imaging\nparameters.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jul 2019 20:17:20 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Shiri", "Isaac", ""], ["Maleki", "Hassan", ""], ["Hajianfar", "Ghasem", ""], ["Abdollahi", "Hamid", ""], ["Ashrafinia", "Saeed", ""], ["Hatt", "Mathieu", ""], ["Oveisi", "Mehrdad", ""], ["Rahmim", "Arman", ""]]}, {"id": "1907.02124", "submitter": "Xiaolong Ma", "authors": "Xiaolong Ma, Sheng Lin, Shaokai Ye, Zhezhi He, Linfeng Zhang, Geng\n  Yuan, Sia Huat Tan, Zhengang Li, Deliang Fan, Xuehai Qian, Xue Lin, Kaisheng\n  Ma, Yanzhi Wang", "title": "Non-Structured DNN Weight Pruning -- Is It Beneficial in Any Platform?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large deep neural network (DNN) models pose the key challenge to energy\nefficiency due to the significantly higher energy consumption of off-chip DRAM\naccesses than arithmetic or SRAM operations. It motivates the intensive\nresearch on model compression with two main approaches. Weight pruning\nleverages the redundancy in the number of weights and can be performed in a\nnon-structured, which has higher flexibility and pruning rate but incurs index\naccesses due to irregular weights, or structured manner, which preserves the\nfull matrix structure with lower pruning rate. Weight quantization leverages\nthe redundancy in the number of bits in weights. Compared to pruning,\nquantization is much more hardware-friendly, and has become a \"must-do\" step\nfor FPGA and ASIC implementations. This paper provides a definitive answer to\nthe question for the first time. First, we build ADMM-NN-S by extending and\nenhancing ADMM-NN, a recently proposed joint weight pruning and quantization\nframework. Second, we develop a methodology for fair and fundamental comparison\nof non-structured and structured pruning in terms of both storage and\ncomputation efficiency. Our results show that ADMM-NN-S consistently\noutperforms the prior art: (i) it achieves 348x, 36x, and 8x overall weight\npruning on LeNet-5, AlexNet, and ResNet-50, respectively, with (almost) zero\naccuracy loss; (ii) we demonstrate the first fully binarized (for all layers)\nDNNs can be lossless in accuracy in many cases. These results provide a strong\nbaseline and credibility of our study. Based on the proposed comparison\nframework, with the same accuracy and quantization, the results show that\nnon-structrued pruning is not competitive in terms of both storage and\ncomputation efficiency. Thus, we conclude that non-structured pruning is\nconsidered harmful. We urge the community not to continue the DNN inference\nacceleration for non-structured sparsity.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jul 2019 20:27:51 GMT"}, {"version": "v2", "created": "Tue, 7 Jan 2020 19:43:16 GMT"}], "update_date": "2020-01-09", "authors_parsed": [["Ma", "Xiaolong", ""], ["Lin", "Sheng", ""], ["Ye", "Shaokai", ""], ["He", "Zhezhi", ""], ["Zhang", "Linfeng", ""], ["Yuan", "Geng", ""], ["Tan", "Sia Huat", ""], ["Li", "Zhengang", ""], ["Fan", "Deliang", ""], ["Qian", "Xuehai", ""], ["Lin", "Xue", ""], ["Ma", "Kaisheng", ""], ["Wang", "Yanzhi", ""]]}, {"id": "1907.02129", "submitter": "Marat Dukhan", "authors": "Marat Dukhan", "title": "The Indirect Convolution Algorithm", "comments": "Presented on Efficient Deep Learning for Computer Vision workshop at\n  CVPR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning frameworks commonly implement convolution operators with\nGEMM-based algorithms. In these algorithms, convolution is implemented on top\nof matrix-matrix multiplication (GEMM) functions, provided by highly optimized\nBLAS libraries. Convolutions with 1x1 kernels can be directly represented as a\nGEMM call, but convolutions with larger kernels require a special memory layout\ntransformation - im2col or im2row - to fit into GEMM interface.\n  The Indirect Convolution algorithm provides the efficiency of the GEMM\nprimitive without the overhead of im2col transformation. In contrast to\nGEMM-based algorithms, the Indirect Convolution does not reshuffle the data to\nfit into the GEMM primitive but introduces an indirection buffer - a buffer of\npointers to the start of each row of image pixels. This broadens the\napplication of our modified GEMM function to convolutions with arbitrary kernel\nsize, padding, stride, and dilation.\n  The Indirect Convolution algorithm reduces memory overhead proportionally to\nthe number of input channels and outperforms the GEMM-based algorithm by up to\n62% on convolution parameters which involve im2col transformations in\nGEMM-based algorithms. This, however, comes at cost of minor performance\nreduction on 1x1 stride-1 convolutions.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jul 2019 20:51:18 GMT"}], "update_date": "2019-07-05", "authors_parsed": [["Dukhan", "Marat", ""]]}, {"id": "1907.02136", "submitter": "Ke Wang", "authors": "Ke Wang and Zhendong Su", "title": "Learning Blended, Precise Semantic Program Embeddings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning neural program embeddings is key to utilizing deep neural networks\nin program languages research --- precise and efficient program representations\nenable the application of deep models to a wide range of program analysis\ntasks. Existing approaches predominately learn to embed programs from their\nsource code, and, as a result, they do not capture deep, precise program\nsemantics. On the other hand, models learned from runtime information\ncritically depend on the quality of program executions, thus leading to trained\nmodels with highly variant quality. This paper tackles these inherent\nweaknesses of prior approaches by introducing a new deep neural network,\n\\liger, which learns program representations from a mixture of symbolic and\nconcrete execution traces. We have evaluated \\liger on \\coset, a recently\nproposed benchmark suite for evaluating neural program embeddings. Results show\n\\liger (1) is significantly more accurate than the state-of-the-art\nsyntax-based models Gated Graph Neural Network and code2vec in classifying\nprogram semantics, and (2) requires on average 10x fewer executions covering\n74\\% fewer paths than the state-of-the-art dynamic model \\dypro. Furthermore,\nwe extend \\liger to predict the name for a method from its body's vector\nrepresentation. Learning on the same set of functions (more than 170K in\ntotal), \\liger significantly outperforms code2seq, the previous\nstate-of-the-art for method name prediction.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jul 2019 21:15:04 GMT"}, {"version": "v2", "created": "Thu, 11 Jul 2019 12:27:55 GMT"}], "update_date": "2019-07-12", "authors_parsed": [["Wang", "Ke", ""], ["Su", "Zhendong", ""]]}, {"id": "1907.02140", "submitter": "Tadahiro Taniguchi", "authors": "Akira Kinose and Tadahiro Taniguchi", "title": "Integration of Imitation Learning using GAIL and Reinforcement Learning\n  using Task-achievement Rewards via Probabilistic Graphical Model", "comments": "Submitted to Advanced Robotics", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Integration of reinforcement learning and imitation learning is an important\nproblem that has been studied for a long time in the field of intelligent\nrobotics. Reinforcement learning optimizes policies to maximize the cumulative\nreward, whereas imitation learning attempts to extract general knowledge about\nthe trajectories demonstrated by experts, i.e., demonstrators. Because each of\nthem has their own drawbacks, methods combining them and compensating for each\nset of drawbacks have been explored thus far. However, many of the methods are\nheuristic and do not have a solid theoretical basis. In this paper, we present\na new theory for integrating reinforcement and imitation learning by extending\nthe probabilistic generative model framework for reinforcement learning, {\\it\nplan by inference}. We develop a new probabilistic graphical model for\nreinforcement learning with multiple types of rewards and a probabilistic\ngraphical model for Markov decision processes with multiple optimality\nemissions (pMDP-MO). Furthermore, we demonstrate that the integrated learning\nmethod of reinforcement learning and imitation learning can be formulated as a\nprobabilistic inference of policies on pMDP-MO by considering the output of the\ndiscriminator in generative adversarial imitation learning as an additional\noptimal emission observation. We adapt the generative adversarial imitation\nlearning and task-achievement reward to our proposed framework, achieving\nsignificantly better performance than agents trained with reinforcement\nlearning or imitation learning alone. Experiments demonstrate that our\nframework successfully integrates imitation and reinforcement learning even\nwhen the number of demonstrators is only a few.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jul 2019 21:38:48 GMT"}, {"version": "v2", "created": "Wed, 16 Oct 2019 08:24:58 GMT"}], "update_date": "2019-10-17", "authors_parsed": [["Kinose", "Akira", ""], ["Taniguchi", "Tadahiro", ""]]}, {"id": "1907.02149", "submitter": "Florian Piewak", "authors": "Florian Piewak, Peter Pinggera, and Marius Z\\\"ollner", "title": "Analyzing the Cross-Sensor Portability of Neural Network Architectures\n  for LiDAR-based Semantic Labeling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  State-of-the-art approaches for the semantic labeling of LiDAR point clouds\nheavily rely on the use of deep Convolutional Neural Networks (CNNs). However,\ntransferring network architectures across different LiDAR sensor types\nrepresents a significant challenge, especially due to sensor specific design\nchoices with regard to network architecture as well as data representation. In\nthis paper we propose a new CNN architecture for the point-wise semantic\nlabeling of LiDAR data which achieves state-of-the-art results while increasing\nportability across sensor types. This represents a significant advantage given\nthe fast-paced development of LiDAR hardware technology. We perform a thorough\nquantitative cross-sensor analysis of semantic labeling performance in\ncomparison to a state-of-the-art reference method. Our evaluation shows that\nthe proposed architecture is indeed highly portable, yielding an improvement of\n10 percentage points in the Intersection-over-Union (IoU) score when compared\nto the reference approach. Further, the results indicate that the proposed\nnetwork architecture can provide an efficient way for the automated generation\nof large-scale training data for novel LiDAR sensor types without the need for\nextensive manual annotation or multi-modal label transfer.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jul 2019 22:19:37 GMT"}], "update_date": "2019-07-05", "authors_parsed": [["Piewak", "Florian", ""], ["Pinggera", "Peter", ""], ["Z\u00f6llner", "Marius", ""]]}, {"id": "1907.02151", "submitter": "Ankush Chakrabarty", "authors": "Ankush Chakrabarty, Devesh K. Jha, Gregery T. Buzzard, Yebin Wang,\n  Kyriakos Vamvoudakis", "title": "Safe Approximate Dynamic Programming Via Kernelized Lipschitz Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.LG cs.SY math.DS math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a method for obtaining safe initial policies for reinforcement\nlearning via approximate dynamic programming (ADP) techniques for uncertain\nsystems evolving with discrete-time dynamics. We employ kernelized Lipschitz\nestimation and semidefinite programming for computing admissible initial\ncontrol policies with provably high probability. Such admissible controllers\nenable safe initialization and constraint enforcement while providing\nexponential stability of the equilibrium of the closed-loop system.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jul 2019 22:31:10 GMT"}], "update_date": "2019-07-05", "authors_parsed": [["Chakrabarty", "Ankush", ""], ["Jha", "Devesh K.", ""], ["Buzzard", "Gregery T.", ""], ["Wang", "Yebin", ""], ["Vamvoudakis", "Kyriakos", ""]]}, {"id": "1907.02159", "submitter": "Jacob Imola", "authors": "Kamalika Chaudhuri, Jacob Imola, Ashwin Machanavajjhala", "title": "Capacity Bounded Differential Privacy", "comments": "10 pages, 2 figures, Neurips 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Differential privacy, a notion of algorithmic stability, is a gold standard\nfor measuring the additional risk an algorithm's output poses to the privacy of\na single record in the dataset. Differential privacy is defined as the distance\nbetween the output distribution of an algorithm on neighboring datasets that\ndiffer in one entry. In this work, we present a novel relaxation of\ndifferential privacy, capacity bounded differential privacy, where the\nadversary that distinguishes output distributions is assumed to be\ncapacity-bounded -- i.e. bounded not in computational power, but in terms of\nthe function class from which their attack algorithm is drawn. We model\nadversaries in terms of restricted f-divergences between probability\ndistributions, and study properties of the definition and algorithms that\nsatisfy them.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jul 2019 23:07:34 GMT"}], "update_date": "2019-07-05", "authors_parsed": [["Chaudhuri", "Kamalika", ""], ["Imola", "Jacob", ""], ["Machanavajjhala", "Ashwin", ""]]}, {"id": "1907.02163", "submitter": "Robert Bamler", "authors": "Robert Bamler and Stephan Mandt", "title": "A Quantum Field Theory of Representation Learning", "comments": "Presented at the ICML 2019 Workshop on Theoretical Physics for Deep\n  Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cond-mat.stat-mech cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Continuous symmetries and their breaking play a prominent role in\ncontemporary physics. Effective low-energy field theories around symmetry\nbreaking states explain diverse phenomena such as superconductivity, magnetism,\nand the mass of nucleons. We show that such field theories can also be a useful\ntool in machine learning, in particular for loss functions with continuous\nsymmetries that are spontaneously broken by random initializations. In this\npaper, we illuminate our earlier published work (Bamler & Mandt, 2018) on this\ntopic more from the perspective of theoretical physics. We show that the\nanalogies between superconductivity and symmetry breaking in temporal\nrepresentation learning are rather deep, allowing us to formulate a gauge\ntheory of `charged' embedding vectors in time series models. We show that\nmaking the loss function gauge invariant speeds up convergence in such models.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jul 2019 00:01:34 GMT"}], "update_date": "2019-07-05", "authors_parsed": [["Bamler", "Robert", ""], ["Mandt", "Stephan", ""]]}, {"id": "1907.02177", "submitter": "Masaaki Imaizumi", "authors": "Ryumei Nakada, Masaaki Imaizumi", "title": "Adaptive Approximation and Generalization of Deep Neural Network with\n  Intrinsic Dimensionality", "comments": "38 pages", "journal-ref": "Journal of Machine Learning Research, 21(174), 2020", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this study, we prove that an intrinsic low dimensionality of covariates is\nthe main factor that determines the performance of deep neural networks (DNNs).\nDNNs generally provide outstanding empirical performance. Hence, numerous\nstudies have actively investigated the theoretical properties of DNNs to\nunderstand their underlying mechanisms. In particular, the behavior of DNNs in\nterms of high-dimensional data is one of the most critical questions. However,\nthis issue has not been sufficiently investigated from the aspect of\ncovariates, although high-dimensional data have practically low intrinsic\ndimensionality. In this study, we derive bounds for an approximation error and\na generalization error regarding DNNs with intrinsically low dimensional\ncovariates. We apply the notion of the Minkowski dimension and develop a novel\nproof technique. Consequently, we show that convergence rates of the errors by\nDNNs do not depend on the nominal high dimensionality of data, but on its lower\nintrinsic dimension. We further prove that the rate is optimal in the minimax\nsense. We identify an advantage of DNNs by showing that DNNs can handle a\nbroader class of intrinsic low dimensional data than other adaptive estimators.\nFinally, we conduct a numerical simulation to validate the theoretical results.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jul 2019 01:10:58 GMT"}, {"version": "v2", "created": "Sat, 2 Nov 2019 02:58:45 GMT"}, {"version": "v3", "created": "Thu, 17 Sep 2020 16:09:04 GMT"}], "update_date": "2020-09-18", "authors_parsed": [["Nakada", "Ryumei", ""], ["Imaizumi", "Masaaki", ""]]}, {"id": "1907.02178", "submitter": "Harikesh Nair", "authors": "Tong Geng, Xiliang Lin, Harikesh S. Nair", "title": "Online Evaluation of Audiences for Targeted Advertising via Bandit\n  Experiments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Firms implementing digital advertising campaigns face a complex problem in\ndetermining the right match between their advertising creatives and target\naudiences. Typical solutions to the problem have leveraged non-experimental\nmethods, or used \"split-testing\" strategies that have not explicitly addressed\nthe complexities induced by targeted audiences that can potentially overlap\nwith one another. This paper presents an adaptive algorithm that addresses the\nproblem via online experimentation. The algorithm is set up as a contextual\nbandit and addresses the overlap issue by partitioning the target audiences\ninto disjoint, non-overlapping sub-populations. It learns an optimal creative\ndisplay policy in the disjoint space, while assessing in parallel which\ncreative has the best match in the space of possibly overlapping target\naudiences. Experiments show that the proposed method is more efficient compared\nto naive \"split-testing\" or non-adaptive \"A/B/n\" testing based methods. We also\ndescribe a testing product we built that uses the algorithm. The product is\ncurrently deployed on the advertising platform of JD.com, an eCommerce company\nand a publisher of digital ads in China.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jul 2019 01:14:46 GMT"}, {"version": "v2", "created": "Thu, 18 Jul 2019 20:43:21 GMT"}, {"version": "v3", "created": "Wed, 4 Sep 2019 23:52:25 GMT"}], "update_date": "2019-09-06", "authors_parsed": [["Geng", "Tong", ""], ["Lin", "Xiliang", ""], ["Nair", "Harikesh S.", ""]]}, {"id": "1907.02188", "submitter": "Brosnan Yuen", "authors": "Brosnan Yuen", "title": "Classifying Multi-Gas Spectrums using Monte Carlo KNN and\n  Multi-Resolution CNN", "comments": "It was submitted without proper permission granted", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  A Monte Carlo k-nearest neighbours (KNN) and a multi-resolution convolutional\nneural network (CNN) were developed to detect the presences of multiple gasses\nin near infrared (IR) spectrums. High Resolution Transmission database was used\nto synthesize the near IR spectrums. Monte Carlo KNN determined the optimal\nkernel sizes and the optimal number of channels. The multi-resolution CNN,\ncomposed of multiple different kernels, was created using the optimal kernel\nsizes and the optimal number of channels. The multi-resolution CNN outperforms\nthe multilayer perceptron and the partial least squares.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jul 2019 01:59:28 GMT"}, {"version": "v2", "created": "Wed, 10 Jul 2019 01:19:25 GMT"}, {"version": "v3", "created": "Sun, 13 Oct 2019 04:52:37 GMT"}, {"version": "v4", "created": "Mon, 23 Mar 2020 22:26:05 GMT"}], "update_date": "2020-03-25", "authors_parsed": [["Yuen", "Brosnan", ""]]}, {"id": "1907.02189", "submitter": "Xiang Li", "authors": "Xiang Li, Kaixuan Huang, Wenhao Yang, Shusen Wang, Zhihua Zhang", "title": "On the Convergence of FedAvg on Non-IID Data", "comments": "2020 International Conference on Learning Representations", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning enables a large amount of edge computing devices to\njointly learn a model without data sharing. As a leading algorithm in this\nsetting, Federated Averaging (\\texttt{FedAvg}) runs Stochastic Gradient Descent\n(SGD) in parallel on a small subset of the total devices and averages the\nsequences only once in a while. Despite its simplicity, it lacks theoretical\nguarantees under realistic settings. In this paper, we analyze the convergence\nof \\texttt{FedAvg} on non-iid data and establish a convergence rate of\n$\\mathcal{O}(\\frac{1}{T})$ for strongly convex and smooth problems, where $T$\nis the number of SGDs. Importantly, our bound demonstrates a trade-off between\ncommunication-efficiency and convergence rate. As user devices may be\ndisconnected from the server, we relax the assumption of full device\nparticipation to partial device participation and study different averaging\nschemes; low device participation rate can be achieved without severely slowing\ndown the learning. Our results indicate that heterogeneity of data slows down\nthe convergence, which matches empirical observations. Furthermore, we provide\na necessary condition for \\texttt{FedAvg} on non-iid data: the learning rate\n$\\eta$ must decay, even if full-gradient is used; otherwise, the solution will\nbe $\\Omega (\\eta)$ away from the optimal.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jul 2019 02:04:56 GMT"}, {"version": "v2", "created": "Tue, 8 Oct 2019 15:07:31 GMT"}, {"version": "v3", "created": "Thu, 6 Feb 2020 10:17:45 GMT"}, {"version": "v4", "created": "Thu, 25 Jun 2020 06:45:52 GMT"}], "update_date": "2020-06-26", "authors_parsed": [["Li", "Xiang", ""], ["Huang", "Kaixuan", ""], ["Yang", "Wenhao", ""], ["Wang", "Shusen", ""], ["Zhang", "Zhihua", ""]]}, {"id": "1907.02203", "submitter": "Lin Li", "authors": "Weibin Lin, Lin Li", "title": "An Item Recommendation Approach by Fusing Images based on Neural\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There are rich formats of information in the network, such as rating, text,\nimage, and so on, which represent different aspects of user preferences. In the\nfield of recommendation, how to use those data effectively has become a\ndifficult subject. With the rapid development of neural network, researching on\nmulti-modal method for recommendation has become one of the major directions.\nIn the existing recommender systems, numerical rating, item description and\nreview are main information to be considered by researchers. However, the\ncharacteristics of the item may affect the user's preferences, which are rarely\nused for recommendation models. In this work, we propose a novel model to\nincorporate visual factors into predictors of people's preferences, namely\nMF-VMLP, based on the recent developments of neural collaborative filtering\n(NCF). Firstly, we get visual presentation via a pre-trained convolutional\nneural network (CNN) model. To obtain the nonlinearities interaction of latent\nvectors and visual vectors, we propose to leverage a multi-layer perceptron\n(MLP) to learn. Moreover, the combination of MF and MLP has achieved\ncollaborative filtering recommendation between users and items. Our experiments\nconduct Amazon's public dataset for experimental validation and\nroot-mean-square error (RMSE) as evaluation metrics. To some extent,\nexperimental result on a real-world data set demonstrates that our model can\nboost the recommendation performance.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jul 2019 03:44:54 GMT"}], "update_date": "2019-07-05", "authors_parsed": [["Lin", "Weibin", ""], ["Li", "Lin", ""]]}, {"id": "1907.02204", "submitter": "Shuo Zhang", "authors": "Shuo Zhang, Lei Xie", "title": "Improving Attention Mechanism in Graph Neural Networks via Cardinality\n  Preservation", "comments": "The short version of this paper has been accepted by IJCAI 2020", "journal-ref": null, "doi": "10.24963/ijcai.2020/194", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph Neural Networks (GNNs) are powerful to learn the representation of\ngraph-structured data. Most of the GNNs use the message-passing scheme, where\nthe embedding of a node is iteratively updated by aggregating the information\nof its neighbors. To achieve a better expressive capability of node influences,\nattention mechanism has grown to be popular to assign trainable weights to the\nnodes in aggregation. Though the attention-based GNNs have achieved remarkable\nresults in various tasks, a clear understanding of their discriminative\ncapacities is missing. In this work, we present a theoretical analysis of the\nrepresentational properties of the GNN that adopts the attention mechanism as\nan aggregator. Our analysis determines all cases when those attention-based\nGNNs can always fail to distinguish certain distinct structures. Those cases\nappear due to the ignorance of cardinality information in attention-based\naggregation. To improve the performance of attention-based GNNs, we propose\ncardinality preserved attention (CPA) models that can be applied to any kind of\nattention mechanisms. Our experiments on node and graph classification confirm\nour theoretical analysis and show the competitive performance of our CPA\nmodels.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jul 2019 03:48:22 GMT"}, {"version": "v2", "created": "Thu, 12 Sep 2019 12:49:07 GMT"}, {"version": "v3", "created": "Mon, 16 Dec 2019 05:00:38 GMT"}, {"version": "v4", "created": "Mon, 4 May 2020 00:18:01 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Zhang", "Shuo", ""], ["Xie", "Lei", ""]]}, {"id": "1907.02205", "submitter": "Lin Li", "authors": "Duan Wei, Li Lin", "title": "An External Knowledge Enhanced Multi-label Charge Prediction Approach\n  with Label Number Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-label charge prediction is a task to predict the corresponding\naccusations for legal cases, and recently becomes a hot topic. However, current\nstudies use rough methods to deal with the label number. These methods manually\nset parameters to select label numbers, which has an effect in final prediction\nquality. We propose an external knowledge enhanced multi-label charge\nprediction approach that has two phases. One is charge label prediction phase\nwith external knowledge from law provisions, the other one is number learning\nphase with a number learning network (NLN) designed. Our approach enhanced by\nexternal knowledge can automatically adjust the threshold to get label number\nof law cases. It combines the output probabilities of samples and their\ncorresponding label numbers to get final prediction results. In experiments,\nour approach is connected to some state of-the art deep learning models. By\ntesting on the biggest published Chinese law dataset, we find that our approach\nhas improvements on these models. We future conduct experiments on multi-label\nsamples from the dataset. In items of macro-F1, the improvement of baselines\nwith our approach is 3%-5%; In items of micro-F1, the significant improvement\nof our approach is 5%-15%. The experiment results show the effectiveness our\napproach for multi-label charge prediction.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jul 2019 03:50:21 GMT"}], "update_date": "2019-07-05", "authors_parsed": [["Wei", "Duan", ""], ["Lin", "Li", ""]]}, {"id": "1907.02206", "submitter": "Bartolomeo Stellato", "authors": "Dimitris Bertsimas and Bartolomeo Stellato", "title": "Online Mixed-Integer Optimization in Milliseconds", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a method to solve online mixed-integer optimization (MIO) problems\nat very high speed using machine learning. By exploiting the repetitive nature\nof online optimization, we are able to greatly speedup the solution time. Our\napproach encodes the optimal solution into a small amount of information\ndenoted as strategy using the Voice of Optimization framework proposed in\n[BS21]. In this way the core part of the optimization algorithm becomes a\nmulticlass classification problem which can be solved very quickly. In this\nwork, we extend that framework to real-time and high-speed applications\nfocusing on parametric mixed-integer quadratic optimization (MIQO). We propose\nan extremely fast online optimization algorithm consisting of a feedforward\nneural network (NN) evaluation and a linear system solution where the matrix\nhas already been factorized. Therefore, this online approach does not require\nany solver nor iterative algorithm. We show the speed of the proposed method\nboth in terms of total computations required and measured execution time. We\nestimate the number of floating point operations (flops) required to completely\nrecover the optimal solution as a function of the problem dimensions. Compared\nto state-of-the-art MIO routines, the online running time of our method is very\npredictable and can be lower than a single matrix factorization time. We\nbenchmark our method against the state-of-the-art solver Gurobi obtaining from\ntwo to three orders of magnitude speedups on examples from fuel cell energy\nmanagement, sparse portfolio optimization and motion planning with obstacle\navoidance.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jul 2019 03:54:37 GMT"}, {"version": "v2", "created": "Mon, 29 Jun 2020 20:36:30 GMT"}, {"version": "v3", "created": "Fri, 9 Oct 2020 16:15:08 GMT"}, {"version": "v4", "created": "Tue, 23 Mar 2021 00:40:44 GMT"}], "update_date": "2021-03-24", "authors_parsed": [["Bertsimas", "Dimitris", ""], ["Stellato", "Bartolomeo", ""]]}, {"id": "1907.02209", "submitter": "Osman Duman", "authors": "Handan Cam, Osman Duman", "title": "Earthquake Prediction With Artificial Neural Network Method: The\n  Application Of West Anatolian Fault In Turkey", "comments": null, "journal-ref": "GUEJISS, Gumushane University Electronic Journal of The Institute\n  of Social Sciences Volume: 7, Number: 17, Year: 2016", "doi": "10.17823/gusb.352", "report-no": null, "categories": "cs.OH cs.LG eess.SP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A method that exactly knows the earthquakes beforehand and can generalize\nthem cannot still been developed. However, earthquakes are tried to be\npredicted through numerous methods. One of these methods, artificial neural\nnetworks give appropriate outputs to different patterns by learning the\nrelationship between the determined inputs and outputs. In this study, a\nfeedforward back propagation artificial neural network that is connected to\nGutenberg-Richter relationship and that bases on b value used in earthquake\npredictions was developed. The artificial neural network was trained employing\nearthquake data belonging to four different regions which have intensive\nseismic activity in the west of Turkey. After the training process, the\nearthquake data belonging to later dates of the same regions were used for\ntesting and the performance of the network was put forward. When the prediction\nresults of the developed network are examined, the prediction results that the\nnetwork predicts that an earthquake is not going to occur are quite high in all\nregions. Furthermore, the earthquake prediction results that the network\npredicts that an earthquake is going to occur are different to some extent for\nthe studied regions.\n", "versions": [{"version": "v1", "created": "Sun, 26 May 2019 13:54:13 GMT"}], "update_date": "2019-07-05", "authors_parsed": [["Cam", "Handan", ""], ["Duman", "Osman", ""]]}, {"id": "1907.02211", "submitter": "Haroldo Gambini Santos D.Sc.", "authors": "Matheus Guedes Vilas Boas, Haroldo Gambini Santos, Luiz Henrique de\n  Campos Merschmann, and Greet Vanden Berghe", "title": "Optimal Decision Trees for the Algorithm Selection Problem: Integer\n  Programming Based Approaches", "comments": "International Transactions in Operational Research. 2019", "journal-ref": null, "doi": "10.1111/itor.12724", "report-no": null, "categories": "cs.LG cs.DM cs.DS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Even though it is well known that for most relevant computational problems\ndifferent algorithms may perform better on different classes of problem\ninstances, most researchers still focus on determining a single best\nalgorithmic configuration based on aggregate results such as the average. In\nthis paper, we propose Integer Programming based approaches to build decision\ntrees for the Algorithm Selection Problem. These techniques allow automate\nthree crucial decisions: (i) discerning the most important problem features to\ndetermine problem classes; (ii) grouping the problems into classes and (iii)\nselect the best algorithm configuration for each class. To evaluate this new\napproach, extensive computational experiments were executed using the linear\nprogramming algorithms implemented in the COIN-OR Branch & Cut solver across a\ncomprehensive set of instances, including all MIPLIB benchmark instances. The\nresults exceeded our expectations. While selecting the single best parameter\nsetting across all instances decreased the total running time by 22%, our\napproach decreased the total running time by 40% on average across 10-fold\ncross validation experiments. These results indicate that our method\ngeneralizes quite well and does not overfit.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jul 2019 15:39:46 GMT"}, {"version": "v2", "created": "Mon, 16 Sep 2019 17:43:15 GMT"}, {"version": "v3", "created": "Tue, 24 Sep 2019 15:53:26 GMT"}], "update_date": "2020-08-10", "authors_parsed": [["Boas", "Matheus Guedes Vilas", ""], ["Santos", "Haroldo Gambini", ""], ["Merschmann", "Luiz Henrique de Campos", ""], ["Berghe", "Greet Vanden", ""]]}, {"id": "1907.02220", "submitter": "Soheil Kolouri", "authors": "Soheil Kolouri, Xuwang Yin, Gustavo K. Rohde", "title": "Neural Networks, Hypersurfaces, and Radon Transforms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Connections between integration along hypersufaces, Radon transforms, and\nneural networks are exploited to highlight an integral geometric mathematical\ninterpretation of neural networks. By analyzing the properties of neural\nnetworks as operators on probability distributions for observed data, we show\nthat the distribution of outputs for any node in a neural network can be\ninterpreted as a nonlinear projection along hypersurfaces defined by level\nsurfaces over the input data space. We utilize these descriptions to provide\nnew interpretation for phenomena such as nonlinearity, pooling, activation\nfunctions, and adversarial examples in neural network-based learning problems.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jul 2019 05:01:14 GMT"}], "update_date": "2019-07-05", "authors_parsed": [["Kolouri", "Soheil", ""], ["Yin", "Xuwang", ""], ["Rohde", "Gustavo K.", ""]]}, {"id": "1907.02226", "submitter": "Byung Cheol Song", "authors": "Seunghyun Lee and Byung Cheol Song", "title": "Graph-based Knowledge Distillation by Multi-head Attention Network", "comments": "Accepted to BMVC 2019 as an oral presentation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge distillation (KD) is a technique to derive optimal performance from\na small student network (SN) by distilling knowledge of a large teacher network\n(TN) and transferring the distilled knowledge to the small SN. Since a role of\nconvolutional neural network (CNN) in KD is to embed a dataset so as to perform\na given task well, it is very important to acquire knowledge that considers\nintra-data relations. Conventional KD methods have concentrated on distilling\nknowledge in data units. To our knowledge, any KD methods for distilling\ninformation in dataset units have not yet been proposed. Therefore, this paper\nproposes a novel method that enables distillation of dataset-based knowledge\nfrom the TN using an attention network. The knowledge of the embedding\nprocedure of the TN is distilled to graph by multi-head attention (MHA), and\nmulti-task learning is performed to give relational inductive bias to the SN.\nThe MHA can provide clear information about the source dataset, which can\ngreatly improves the performance of the SN. Experimental results show that the\nproposed method is 7.05% higher than the SN alone for CIFAR100, which is 2.46%\nhigher than the state-of-the-art.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jul 2019 05:29:08 GMT"}, {"version": "v2", "created": "Tue, 9 Jul 2019 02:46:35 GMT"}], "update_date": "2019-07-10", "authors_parsed": [["Lee", "Seunghyun", ""], ["Song", "Byung Cheol", ""]]}, {"id": "1907.02230", "submitter": "Zhichao Zhang", "authors": "Zhichao Zhang, Shugong Xu, Tianhao Qiao, Shunqing Zhang, Shan Cao", "title": "Attention based Convolutional Recurrent Neural Network for Environmental\n  Sound Classification", "comments": "Accepted to Chinese Conference on Pattern Recognition and Computer\n  Vision (PRCV) 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Environmental sound classification (ESC) is a challenging problem due to the\ncomplexity of sounds. The ESC performance is heavily dependent on the\neffectiveness of representative features extracted from the environmental\nsounds. However, ESC often suffers from the semantically irrelevant frames and\nsilent frames. In order to deal with this, we employ a frame-level attention\nmodel to focus on the semantically relevant frames and salient frames.\nSpecifically, we first propose an convolutional recurrent neural network to\nlearn spectro-temporal features and temporal correlations. Then, we extend our\nconvolutional RNN model with a frame-level attention mechanism to learn\ndiscriminative feature representations for ESC. Experiments were conducted on\nESC-50 and ESC-10 datasets. Experimental results demonstrated the effectiveness\nof the proposed method and achieved the state-of-the-art performance in terms\nof classification accuracy.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jul 2019 05:41:18 GMT"}], "update_date": "2019-07-05", "authors_parsed": [["Zhang", "Zhichao", ""], ["Xu", "Shugong", ""], ["Qiao", "Tianhao", ""], ["Zhang", "Shunqing", ""], ["Cao", "Shan", ""]]}, {"id": "1907.02237", "submitter": "Xu Zou", "authors": "Xu Zou, Qiuye Jia, Jianwei Zhang, Chang Zhou, Hongxia Yang, Jie Tang", "title": "Dimensional Reweighting Graph Convolutional Networks", "comments": "We decide to drastically modify the article so we don't wish to let\n  this outdated version continue to confuse readers", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph Convolution Networks (GCNs) are becoming more and more popular for\nlearning node representations on graphs. Though there exist various\ndevelopments on sampling and aggregation to accelerate the training process and\nimprove the performances, limited works focus on dealing with the dimensional\ninformation imbalance of node representations. To bridge the gap, we propose a\nmethod named Dimensional reweighting Graph Convolution Network (DrGCN). We\ntheoretically prove that our DrGCN can guarantee to improve the stability of\nGCNs via mean field theory. Our dimensional reweighting method is very flexible\nand can be easily combined with most sampling and aggregation techniques for\nGCNs. Experimental results demonstrate its superior performances on several\nchallenging transductive and inductive node classification benchmark datasets.\nOur DrGCN also outperforms existing models on an industrial-sized Alibaba\nrecommendation dataset.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jul 2019 06:01:32 GMT"}, {"version": "v2", "created": "Wed, 6 Nov 2019 03:05:12 GMT"}, {"version": "v3", "created": "Thu, 29 Oct 2020 09:00:53 GMT"}], "update_date": "2020-10-30", "authors_parsed": [["Zou", "Xu", ""], ["Jia", "Qiuye", ""], ["Zhang", "Jianwei", ""], ["Zhou", "Chang", ""], ["Yang", "Hongxia", ""], ["Tang", "Jie", ""]]}, {"id": "1907.02242", "submitter": "Austin Okray", "authors": "Austin Okray, Hui Hu, Chao Lan", "title": "Fair Kernel Regression via Fair Feature Embedding in Kernel Space", "comments": "ICTAI 2019, fair machine learning, kernel regression, fair feature\n  embedding, feature selection for kernel methods, mean discrepancy", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, there have been significant efforts on mitigating unethical\ndemographic biases in machine learning methods. However, very little is done\nfor kernel methods. In this paper, we propose a new fair kernel regression\nmethod via fair feature embedding (FKR-F$^2$E) in kernel space. Motivated by\nprior works on feature selection in kernel space and feature processing for\nfair machine learning, we propose to learn fair feature embedding functions\nthat minimize demographic discrepancy of feature distributions in kernel space.\nCompared to the state-of-the-art fair kernel regression method and several\nbaseline methods, we show FKR-F$^2$E achieves significantly lower prediction\ndisparity across three real-world data sets.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jul 2019 06:22:38 GMT"}, {"version": "v2", "created": "Fri, 20 Sep 2019 23:13:58 GMT"}], "update_date": "2019-09-24", "authors_parsed": [["Okray", "Austin", ""], ["Hu", "Hui", ""], ["Lan", "Chao", ""]]}, {"id": "1907.02253", "submitter": "Byung-Hak Kim", "authors": "Byung-Hak Kim and Varun Ganapathi", "title": "Lumi\\`ereNet: Lecture Video Synthesis from Audio", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present Lumi\\`ereNet, a simple, modular, and completely deep-learning\nbased architecture that synthesizes, high quality, full-pose headshot lecture\nvideos from instructor's new audio narration of any length. Unlike prior works,\nLumi\\`ereNet is entirely composed of trainable neural network modules to learn\nmapping functions from the audio to video through (intermediate) estimated\npose-based compact and abstract latent codes. Our video demos are available at\n[22] and [23].\n", "versions": [{"version": "v1", "created": "Thu, 4 Jul 2019 07:21:24 GMT"}], "update_date": "2019-07-05", "authors_parsed": [["Kim", "Byung-Hak", ""], ["Ganapathi", "Varun", ""]]}, {"id": "1907.02258", "submitter": "Thomas Lagkas", "authors": "Anastasios Lytos, Thomas Lagkas, Panagiotis Sarigiannidis, Kalina\n  Bontcheva", "title": "The evolution of argumentation mining: From models to social media and\n  emerging tools", "comments": "Journal of Information Processing & Management, Elsevier - Accepted\n  Version", "journal-ref": "Information Processing & Management, Volume 56, Issue 6, 2019", "doi": "10.1016/j.ipm.2019.102055", "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Argumentation mining is a rising subject in the computational linguistics\ndomain focusing on extracting structured arguments from natural text, often\nfrom unstructured or noisy text. The initial approaches on modeling arguments\nwas aiming to identify a flawless argument on specific fields (Law, Scientific\nPapers) serving specific needs (completeness, effectiveness). With the emerge\nof Web 2.0 and the explosion in the use of social media both the diffusion of\nthe data and the argument structure have changed. In this survey article, we\nbridge the gap between theoretical approaches of argumentation mining and\npragmatic schemes that satisfy the needs of social media generated data,\nrecognizing the need for adapting more flexible and expandable schemes, capable\nto adjust to the argumentation conditions that exist in social media. We\nreview, compare, and classify existing approaches, techniques and tools,\nidentifying the positive outcome of combining tasks and features, and\neventually propose a conceptual architecture framework. The proposed\ntheoretical framework is an argumentation mining scheme able to identify the\ndistinct sub-tasks and capture the needs of social media text, revealing the\nneed for adopting more flexible and extensible frameworks.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jul 2019 07:39:23 GMT"}], "update_date": "2019-07-05", "authors_parsed": [["Lytos", "Anastasios", ""], ["Lagkas", "Thomas", ""], ["Sarigiannidis", "Panagiotis", ""], ["Bontcheva", "Kalina", ""]]}, {"id": "1907.02260", "submitter": "Marco Virgolin", "authors": "Marco Virgolin, Tanja Alderliesten, Peter A.N. Bosman", "title": "On Explaining Machine Learning Models by Evolving Crucial and Compact\n  Features", "comments": "We included more experiments: - A high-dimensional dataset is\n  considered - The machine learning algorithm XGBoost is considered We also\n  repeated the experiments using the Naive Bayes classifier, because we\n  discovered that the implementation we relied on had issues (see\n  https://github.com/mlpack/mlpack/issues/2017)", "journal-ref": null, "doi": "10.1016/j.swevo.2019.100640", "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Feature construction can substantially improve the accuracy of Machine\nLearning (ML) algorithms. Genetic Programming (GP) has been proven to be\neffective at this task by evolving non-linear combinations of input features.\nGP additionally has the potential to improve ML explainability since explicit\nexpressions are evolved. Yet, in most GP works the complexity of evolved\nfeatures is not explicitly bound or minimized though this is arguably key for\nexplainability. In this article, we assess to what extent GP still performs\nfavorably at feature construction when constructing features that are (1) Of\nsmall-enough number, to enable visualization of the behavior of the ML model;\n(2) Of small-enough size, to enable interpretability of the features\nthemselves; (3) Of sufficient informative power, to retain or even improve the\nperformance of the ML algorithm. We consider a simple feature construction\nscheme using three different GP algorithms, as well as random search, to evolve\nfeatures for five ML algorithms, including support vector machines and random\nforest. Our results on 21 datasets pertaining to classification and regression\nproblems show that constructing only two compact features can be sufficient to\nrival the use of the entire original feature set. We further find that a modern\nGP algorithm, GP-GOMEA, performs best overall. These results, combined with\nexamples that we provide of readable constructed features and of 2D\nvisualizations of ML behavior, lead us to positively conclude that GP-based\nfeature construction still works well when explicitly searching for compact\nfeatures, making it extremely helpful to explain ML models.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jul 2019 07:52:23 GMT"}, {"version": "v2", "created": "Sun, 17 Nov 2019 14:55:31 GMT"}, {"version": "v3", "created": "Fri, 10 Jan 2020 11:21:17 GMT"}], "update_date": "2020-01-13", "authors_parsed": [["Virgolin", "Marco", ""], ["Alderliesten", "Tanja", ""], ["Bosman", "Peter A. N.", ""]]}, {"id": "1907.02265", "submitter": "Ond\\v{r}ej C\\'ifka", "authors": "Ond\\v{r}ej C\\'ifka, Umut \\c{S}im\\c{s}ekli, Ga\\\"el Richard", "title": "Supervised Symbolic Music Style Translation Using Synthetic Data", "comments": "ISMIR 2019 camera-ready", "journal-ref": "Proceedings of the 20th International Society for Music\n  Information Retrieval Conference (2019) 588-595", "doi": "10.5281/zenodo.3527878", "report-no": null, "categories": "cs.SD cs.LG eess.AS stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Research on style transfer and domain translation has clearly demonstrated\nthe ability of deep learning-based algorithms to manipulate images in terms of\nartistic style. More recently, several attempts have been made to extend such\napproaches to music (both symbolic and audio) in order to enable transforming\nmusical style in a similar manner. In this study, we focus on symbolic music\nwith the goal of altering the 'style' of a piece while keeping its original\n'content'. As opposed to the current methods, which are inherently restricted\nto be unsupervised due to the lack of 'aligned' data (i.e. the same musical\npiece played in multiple styles), we develop the first fully supervised\nalgorithm for this task. At the core of our approach lies a synthetic data\ngeneration scheme which allows us to produce virtually unlimited amounts of\naligned data, and hence avoid the above issue. In view of this data generation\nscheme, we propose an encoder-decoder model for translating symbolic music\naccompaniments between a number of different styles. Our experiments show that\nour models, although trained entirely on synthetic data, are capable of\nproducing musically meaningful accompaniments even for real (non-synthetic)\nMIDI recordings.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jul 2019 08:16:20 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["C\u00edfka", "Ond\u0159ej", ""], ["\u015eim\u015fekli", "Umut", ""], ["Richard", "Ga\u00ebl", ""]]}, {"id": "1907.02271", "submitter": "Mohammad Rostami", "authors": "Alex Gabourie, Mohammad Rostami, Philip Pope, Soheil Kolouri, Kyungnam\n  Kim", "title": "Learning a Domain-Invariant Embedding for Unsupervised Domain Adaptation\n  Using Class-Conditioned Distribution Alignment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the problem of unsupervised domain adaptation (UDA) by learning a\ncross-domain agnostic embedding space, where the distance between the\nprobability distributions of the two source and target visual domains is\nminimized. We use the output space of a shared cross-domain deep encoder to\nmodel the embedding space anduse the Sliced-Wasserstein Distance (SWD) to\nmeasure and minimize the distance between the embedded distributions of two\nsource and target domains to enforce the embedding to be\ndomain-agnostic.Additionally, we use the source domain labeled data to train a\ndeep classifier from the embedding space to the label space to enforce the\nembedding space to be discriminative.As a result of this training scheme, we\nprovide an effective solution to train the deep classification network on the\nsource domain such that it will generalize well on the target domain, where\nonly unlabeled training data is accessible. To mitigate the challenge of class\nmatching, we also align corresponding classes in the embedding space by using\nhigh confidence pseudo-labels for the target domain, i.e. assigning the class\nfor which the source classifier has a high prediction probability. We provide\nexperimental results on UDA benchmark tasks to demonstrate that our method is\neffective and leads to state-of-the-art performance.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jul 2019 08:29:11 GMT"}, {"version": "v2", "created": "Tue, 24 Sep 2019 16:09:11 GMT"}], "update_date": "2019-09-25", "authors_parsed": [["Gabourie", "Alex", ""], ["Rostami", "Mohammad", ""], ["Pope", "Philip", ""], ["Kolouri", "Soheil", ""], ["Kim", "Kyungnam", ""]]}, {"id": "1907.02288", "submitter": "Konstantinos Makantasis", "authors": "Konstantinos Makantasis, Antonios Liapis, Georgios N. Yannakakis", "title": "From Pixels to Affect: A Study on Games and Player Experience", "comments": "Proceedings of the Intl. Conference on Affective Computing and\n  Intelligent Interaction. IEEE. 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Is it possible to predict the affect of a user just by observing her\nbehavioral interaction through a video? How can we, for instance, predict a\nuser's arousal in games by merely looking at the screen during play? In this\npaper we address these questions by employing three dissimilar deep\nconvolutional neural network architectures in our attempt to learn the\nunderlying mapping between video streams of gameplay and the player's arousal.\nWe test the algorithms in an annotated dataset of 50 gameplay videos of a\nsurvival shooter game and evaluate the deep learned models' capacity to\nclassify high vs low arousal levels. Our key findings with the demanding\nleave-one-video-out validation method reveal accuracies of over 78% on average\nand 98% at best. While this study focuses on games and player experience as a\ntest domain, the findings and methodology are directly relevant to any\naffective computing area, introducing a general and user-agnostic approach for\nmodeling affect.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jul 2019 09:15:03 GMT"}, {"version": "v2", "created": "Tue, 15 Oct 2019 08:49:24 GMT"}], "update_date": "2019-10-16", "authors_parsed": [["Makantasis", "Konstantinos", ""], ["Liapis", "Antonios", ""], ["Yannakakis", "Georgios N.", ""]]}, {"id": "1907.02323", "submitter": "Jan R\\\"uth", "authors": "Constantin Sander and Jan R\\\"uth and Oliver Hohlfeld and Klaus Wehrle", "title": "DeePCCI: Deep Learning-based Passive Congestion Control Identification", "comments": null, "journal-ref": "NetAI '19: ACM SIGCOMM 2019 Workshop on Network Meets AI & ML,\n  August 23, 2019, Beijing, China", "doi": "10.1145/3341216.3342211", "report-no": null, "categories": "cs.NI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transport protocols use congestion control to avoid overloading a network.\nNowadays, different congestion control variants exist that influence\nperformance. Studying their use is thus relevant, but it is hard to identify\nwhich variant is used. While passive identification approaches exist, these\nrequire detailed domain knowledge and often also rely on outdated assumptions\nabout how congestion control operates and what data is accessible. We present\nDeePCCI, a passive, deep learning-based congestion control identification\napproach which does not need any domain knowledge other than training traffic\nof a congestion control variant. By only using packet arrival data, it is also\ndirectly applicable to encrypted (transport header) traffic. DeePCCI is\ntherefore more easily extendable and can also be used with QUIC.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jul 2019 10:50:51 GMT"}], "update_date": "2019-07-05", "authors_parsed": [["Sander", "Constantin", ""], ["R\u00fcth", "Jan", ""], ["Hohlfeld", "Oliver", ""], ["Wehrle", "Klaus", ""]]}, {"id": "1907.02329", "submitter": "Parinaz Kasebzadeh", "authors": "Parinaz Kasebzadeh, Gustaf Hendeby, Fredrik Gustafsson", "title": "Asynchronous Averaging of Gait Cycles for Classification of Gait and\n  Device Modes", "comments": "Submitted to IEEE Sensors Journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  An approach for computing unique gait signature using measurements collected\nfrom body-worn inertial measurement units (IMUs) is proposed. The gait\nsignature represents one full cycle of the human gait, and is suitable for\noff-line or on-line classification of the gait mode. The signature can also be\nused to jointly classify the gait mode and the device mode. The device mode\nidentifies how the IMU-equipped device is being carried by the user. The method\nis based on precise segmentation and resampling of the measured IMU signal, as\nan initial step, further tuned by minimizing the variability of the obtained\nsignature within each gait cycle. Finally, a Fourier series expansion of the\ngait signature is introduced which provides a low-dimensional feature vector\nwell suited for classification purposes. The proposed method is evaluated on a\nlarge dataset involving several subjects, each one containing two different\ngait modes and four different device modes. The gait signatures enable a high\nclassification rate for each step cycle.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jul 2019 11:13:11 GMT"}, {"version": "v2", "created": "Fri, 5 Jul 2019 06:43:53 GMT"}], "update_date": "2019-07-08", "authors_parsed": [["Kasebzadeh", "Parinaz", ""], ["Hendeby", "Gustaf", ""], ["Gustafsson", "Fredrik", ""]]}, {"id": "1907.02343", "submitter": "Sibylle Hess", "authors": "Sibylle Hess, Wouter Duivesteijn", "title": "k is the Magic Number -- Inferring the Number of Clusters Through\n  Nonparametric Concentration Inequalities", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most convex and nonconvex clustering algorithms come with one crucial\nparameter: the $k$ in $k$-means. To this day, there is not one generally\naccepted way to accurately determine this parameter. Popular methods are simple\nyet theoretically unfounded, such as searching for an elbow in the curve of a\ngiven cost measure. In contrast, statistically founded methods often make\nstrict assumptions over the data distribution or come with their own\noptimization scheme for the clustering objective. This limits either the set of\napplicable datasets or clustering algorithms. In this paper, we strive to\ndetermine the number of clusters by answering a simple question: given two\nclusters, is it likely that they jointly stem from a single distribution? To\nthis end, we propose a bound on the probability that two clusters originate\nfrom the distribution of the unified cluster, specified only by the sample mean\nand variance. Our method is applicable as a simple wrapper to the result of any\nclustering method minimizing the objective of $k$-means, which includes\nGaussian mixtures and Spectral Clustering. We focus in our experimental\nevaluation on an application for nonconvex clustering and demonstrate the\nsuitability of our theoretical results. Our \\textsc{SpecialK} clustering\nalgorithm automatically determines the appropriate value for $k$, without\nrequiring any data transformation or projection, and without assumptions on the\ndata distribution. Additionally, it is capable to decide that the data consists\nof only a single cluster, which many existing algorithms cannot.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jul 2019 11:57:01 GMT"}], "update_date": "2019-07-05", "authors_parsed": [["Hess", "Sibylle", ""], ["Duivesteijn", "Wouter", ""]]}, {"id": "1907.02345", "submitter": "Yaxin Shi", "authors": "Yaxin Shi, Yuangang Pan, Donna Xu, Ivor Tsang", "title": "Probabilistic CCA with Implicit Distributions", "comments": "23 pages, 9 Figures; Keywords: Multi-view Learning, Nonlinear\n  Dependency, Deep Generative models", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Canonical Correlation Analysis (CCA) is a classic technique for multi-view\ndata analysis. To overcome the deficiency of linear correlation in practical\nmulti-view learning tasks, various CCA variants were proposed to capture\nnonlinear dependency. However, it is non-trivial to have an in-principle\nunderstanding of these variants due to their inherent restrictive assumption on\nthe data and latent code distributions. Although some works have studied\nprobabilistic interpretation for CCA, these models still require the explicit\nform of the distributions to achieve a tractable solution for the inference. In\nthis work, we study probabilistic interpretation for CCA based on implicit\ndistributions. We present Conditional Mutual Information (CMI) as a new\ncriterion for CCA to consider both linear and nonlinear dependency for\narbitrarily distributed data. To eliminate direct estimation for CMI, in which\nexplicit form of the distributions is still required, we derive an objective\nwhich can provide an estimation for CMI with efficient inference methods. To\nfacilitate Bayesian inference of multi-view analysis, we propose Adversarial\nCCA (ACCA), which achieves consistent encoding for multi-view data with the\nconsistent constraint imposed on the marginalization of the implicit\nposteriors. Such a model would achieve superiority in the alignment of the\nmulti-view data with implicit distributions. It is interesting to note that\nmost of the existing CCA variants can be connected with our proposed CCA model\nby assigning specific form for the posterior and likelihood distributions.\nExtensive experiments on nonlinear correlation analysis and cross-view\ngeneration on benchmark and real-world datasets demonstrate the superiority of\nour model.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jul 2019 11:59:06 GMT"}], "update_date": "2019-07-05", "authors_parsed": [["Shi", "Yaxin", ""], ["Pan", "Yuangang", ""], ["Xu", "Donna", ""], ["Tsang", "Ivor", ""]]}, {"id": "1907.02392", "submitter": "Lynton Ardizzone", "authors": "Lynton Ardizzone, Carsten L\\\"uth, Jakob Kruse, Carsten Rother, Ullrich\n  K\\\"othe", "title": "Guided Image Generation with Conditional Invertible Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we address the task of natural image generation guided by a\nconditioning input. We introduce a new architecture called conditional\ninvertible neural network (cINN). The cINN combines the purely generative INN\nmodel with an unconstrained feed-forward network, which efficiently\npreprocesses the conditioning input into useful features. All parameters of the\ncINN are jointly optimized with a stable, maximum likelihood-based training\nprocedure. By construction, the cINN does not experience mode collapse and\ngenerates diverse samples, in contrast to e.g. cGANs. At the same time our\nmodel produces sharp images since no reconstruction loss is required, in\ncontrast to e.g. VAEs. We demonstrate these properties for the tasks of MNIST\ndigit generation and image colorization. Furthermore, we take advantage of our\nbi-directional cINN architecture to explore and manipulate emergent properties\nof the latent space, such as changing the image style in an intuitive way.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jul 2019 13:20:57 GMT"}, {"version": "v2", "created": "Fri, 5 Jul 2019 12:49:31 GMT"}, {"version": "v3", "created": "Wed, 10 Jul 2019 11:10:36 GMT"}], "update_date": "2019-07-11", "authors_parsed": [["Ardizzone", "Lynton", ""], ["L\u00fcth", "Carsten", ""], ["Kruse", "Jakob", ""], ["Rother", "Carsten", ""], ["K\u00f6the", "Ullrich", ""]]}, {"id": "1907.02404", "submitter": "Man Shun Ang", "authors": "Valentin Leplat, Nicolas Gillis, Man Shun Ang", "title": "Blind Audio Source Separation with Minimum-Volume Beta-Divergence NMF", "comments": "24 pages, 10 figures, 3 tables", "journal-ref": null, "doi": "10.1109/TSP.2020.2991801", "report-no": null, "categories": "eess.SP cs.LG cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Considering a mixed signal composed of various audio sources and recorded\nwith a single microphone, we consider on this paper the blind audio source\nseparation problem which consists in isolating and extracting each of the\nsources. To perform this task, nonnegative matrix factorization (NMF) based on\nthe Kullback-Leibler and Itakura-Saito $\\beta$-divergences is a standard and\nstate-of-the-art technique that uses the time-frequency representation of the\nsignal. We present a new NMF model better suited for this task. It is based on\nthe minimization of $\\beta$-divergences along with a penalty term that promotes\nthe columns of the dictionary matrix to have a small volume. Under some mild\nassumptions and in noiseless conditions, we prove that this model is provably\nable to identify the sources. In order to solve this problem, we propose\nmultiplicative updates whose derivations are based on the standard\nmajorization-minimization framework. We show on several numerical experiments\nthat our new model is able to obtain more interpretable results than standard\nNMF models. Moreover, we show that it is able to recover the sources even when\nthe number of sources present into the mixed signal is overestimated. In fact,\nour model automatically sets sources to zero in this situation, hence performs\nmodel order selection automatically.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jul 2019 13:56:25 GMT"}, {"version": "v2", "created": "Tue, 28 Apr 2020 16:00:15 GMT"}], "update_date": "2020-07-15", "authors_parsed": [["Leplat", "Valentin", ""], ["Gillis", "Nicolas", ""], ["Ang", "Man Shun", ""]]}, {"id": "1907.02426", "submitter": "Susanne Trick", "authors": "Susanne Trick, Dorothea Koert, Jan Peters, Constantin Rothkopf", "title": "Multimodal Uncertainty Reduction for Intention Recognition in\n  Human-Robot Interaction", "comments": "Submitted to IROS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.HC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Assistive robots can potentially improve the quality of life and personal\nindependence of elderly people by supporting everyday life activities. To\nguarantee a safe and intuitive interaction between human and robot, human\nintentions need to be recognized automatically. As humans communicate their\nintentions multimodally, the use of multiple modalities for intention\nrecognition may not just increase the robustness against failure of individual\nmodalities but especially reduce the uncertainty about the intention to be\npredicted. This is desirable as particularly in direct interaction between\nrobots and potentially vulnerable humans a minimal uncertainty about the\nsituation as well as knowledge about this actual uncertainty is necessary.\nThus, in contrast to existing methods, in this work a new approach for\nmultimodal intention recognition is introduced that focuses on uncertainty\nreduction through classifier fusion. For the four considered modalities speech,\ngestures, gaze directions and scene objects individual intention classifiers\nare trained, all of which output a probability distribution over all possible\nintentions. By combining these output distributions using the Bayesian method\nIndependent Opinion Pool the uncertainty about the intention to be recognized\ncan be decreased. The approach is evaluated in a collaborative human-robot\ninteraction task with a 7-DoF robot arm. The results show that fused\nclassifiers which combine multiple modalities outperform the respective\nindividual base classifiers with respect to increased accuracy, robustness, and\nreduced uncertainty.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jul 2019 14:33:49 GMT"}], "update_date": "2019-07-05", "authors_parsed": [["Trick", "Susanne", ""], ["Koert", "Dorothea", ""], ["Peters", "Jan", ""], ["Rothkopf", "Constantin", ""]]}, {"id": "1907.02427", "submitter": "Youmna Farag", "authors": "Youmna Farag and Helen Yannakoudakis", "title": "Multi-Task Learning for Coherence Modeling", "comments": "11 pages, 3 figures, Accepted at ACL 2019", "journal-ref": "THE 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL\n  LINGUISTICS (ACL 2019)", "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the task of assessing discourse coherence, an aspect of text\nquality that is essential for many NLP tasks, such as summarization and\nlanguage assessment. We propose a hierarchical neural network trained in a\nmulti-task fashion that learns to predict a document-level coherence score (at\nthe network's top layers) along with word-level grammatical roles (at the\nbottom layers), taking advantage of inductive transfer between the two tasks.\nWe assess the extent to which our framework generalizes to different domains\nand prediction tasks, and demonstrate its effectiveness not only on standard\nbinary evaluation coherence tasks, but also on real-world tasks involving the\nprediction of varying degrees of coherence, achieving a new state of the art.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jul 2019 14:40:22 GMT"}, {"version": "v2", "created": "Thu, 30 Apr 2020 17:30:15 GMT"}], "update_date": "2020-05-01", "authors_parsed": [["Farag", "Youmna", ""], ["Yannakoudakis", "Helen", ""]]}, {"id": "1907.02431", "submitter": "Guy Gaziv", "authors": "Roman Beliy, Guy Gaziv, Assaf Hoogi, Francesca Strappini, Tal Golan,\n  Michal Irani", "title": "From voxels to pixels and back: Self-supervision in natural-image\n  reconstruction from fMRI", "comments": "*First two authors contributed equally. NeurIPS 2019", "journal-ref": "https://proceedings.neurips.cc/paper/2019/file/7d2be41b1bde6ff8fe45150c37488ebb-Paper.pdf", "doi": null, "report-no": null, "categories": "eess.IV cs.LG q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reconstructing observed images from fMRI brain recordings is challenging.\nUnfortunately, acquiring sufficient \"labeled\" pairs of {Image, fMRI} (i.e.,\nimages with their corresponding fMRI responses) to span the huge space of\nnatural images is prohibitive for many reasons. We present a novel approach\nwhich, in addition to the scarce labeled data (training pairs), allows to train\nfMRI-to-image reconstruction networks also on \"unlabeled\" data (i.e., images\nwithout fMRI recording, and fMRI recording without images). The proposed model\nutilizes both an Encoder network (image-to-fMRI) and a Decoder network\n(fMRI-to-image). Concatenating these two networks back-to-back (Encoder-Decoder\n& Decoder-Encoder) allows augmenting the training with both types of unlabeled\ndata. Importantly, it allows training on the unlabeled test-fMRI data. This\nself-supervision adapts the reconstruction network to the new input test-data,\ndespite its deviation from the statistics of the scarce training data.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jul 2019 14:49:26 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["Beliy", "Roman", ""], ["Gaziv", "Guy", ""], ["Hoogi", "Assaf", ""], ["Strappini", "Francesca", ""], ["Golan", "Tal", ""], ["Irani", "Michal", ""]]}, {"id": "1907.02437", "submitter": "Liang Guo", "authors": "Liang Guo, Jianya Liu, Ruodan Lu", "title": "Subsampling Bias and The Best-Discrepancy Systematic Cross Validation", "comments": "SCIENCE China Mathematics. 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Statistical machine learning models should be evaluated and validated before\nputting to work. Conventional k-fold Monte Carlo Cross-Validation (MCCV)\nprocedure uses a pseudo-random sequence to partition instances into k subsets,\nwhich usually causes subsampling bias, inflates generalization errors and\njeopardizes the reliability and effectiveness of cross-validation. Based on\nordered systematic sampling theory in statistics and low-discrepancy sequence\ntheory in number theory, we propose a new k-fold cross-validation procedure by\nreplacing a pseudo-random sequence with a best-discrepancy sequence, which\nensures low subsampling bias and leads to more precise\nExpected-Prediction-Error estimates. Experiments with 156 benchmark datasets\nand three classifiers (logistic regression, decision tree and naive bayes) show\nthat in general, our cross-validation procedure can extrude subsampling bias in\nthe MCCV by lowering the EPE around 7.18% and the variances around 26.73%. In\ncomparison, the stratified MCCV can reduce the EPE and variances of the MCCV\naround 1.58% and 11.85% respectively. The Leave-One-Out (LOO) can lower the EPE\naround 2.50% but its variances are much higher than the any other CV procedure.\nThe computational time of our cross-validation procedure is just 8.64% of the\nMCCV, 8.67% of the stratified MCCV and 16.72% of the LOO. Experiments also show\nthat our approach is more beneficial for datasets characterized by relatively\nsmall size and large aspect ratio. This makes our approach particularly\npertinent when solving bioscience classification problems. Our proposed\nsystematic subsampling technique could be generalized to other machine learning\nalgorithms that involve random subsampling mechanism.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jul 2019 14:55:02 GMT"}], "update_date": "2019-07-05", "authors_parsed": [["Guo", "Liang", ""], ["Liu", "Jianya", ""], ["Lu", "Ruodan", ""]]}, {"id": "1907.02443", "submitter": "Tianxi Li", "authors": "Tianxi Li, Cheng Qian, Elizaveta Levina, Ji Zhu", "title": "High-dimensional Gaussian graphical model for network-linked data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graphical models are commonly used to represent conditional dependence\nrelationships between variables. There are multiple methods available for\nexploring them from high-dimensional data, but almost all of them rely on the\nassumption that the observations are independent and identically distributed.\nAt the same time, observations connected by a network are becoming increasingly\ncommon, and tend to violate these assumptions. Here we develop a Gaussian\ngraphical model for observations connected by a network with potentially\ndifferent mean vectors, varying smoothly over the network. We propose an\nefficient estimation algorithm and demonstrate its effectiveness on both\nsimulated and real data, obtaining meaningful and interpretable results on a\nstatistics coauthorship network. We also prove that our method estimates both\nthe inverse covariance matrix and the corresponding graph structure correctly\nunder the assumption of network \u00e2\u0080\u009ccohesion\u00e2\u0080\u009d, which refers to the empirically\nobserved phenomenon of network neighbors sharing similar traits.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jul 2019 15:08:24 GMT"}, {"version": "v2", "created": "Tue, 21 Apr 2020 14:40:31 GMT"}], "update_date": "2020-04-22", "authors_parsed": [["Li", "Tianxi", ""], ["Qian", "Cheng", ""], ["Levina", "Elizaveta", ""], ["Zhu", "Ji", ""]]}, {"id": "1907.02444", "submitter": "Naoise Holohan", "authors": "Naoise Holohan and Stefano Braghin and P\\'ol Mac Aonghusa and Killian\n  Levacher", "title": "Diffprivlib: The IBM Differential Privacy Library", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Since its conception in 2006, differential privacy has emerged as the\nde-facto standard in data privacy, owing to its robust mathematical guarantees,\ngeneralised applicability and rich body of literature. Over the years,\nresearchers have studied differential privacy and its applicability to an\never-widening field of topics. Mechanisms have been created to optimise the\nprocess of achieving differential privacy, for various data types and\nscenarios. Until this work however, all previous work on differential privacy\nhas been conducted on a ad-hoc basis, without a single, unifying codebase to\nimplement results.\n  In this work, we present the IBM Differential Privacy Library, a general\npurpose, open source library for investigating, experimenting and developing\ndifferential privacy applications in the Python programming language. The\nlibrary includes a host of mechanisms, the building blocks of differential\nprivacy, alongside a number of applications to machine learning and other data\nanalytics tasks. Simplicity and accessibility has been prioritised in\ndeveloping the library, making it suitable to a wide audience of users, from\nthose using the library for their first investigations in data privacy, to the\nprivacy experts looking to contribute their own models and mechanisms for\nothers to use.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jul 2019 15:08:38 GMT"}], "update_date": "2019-07-05", "authors_parsed": [["Holohan", "Naoise", ""], ["Braghin", "Stefano", ""], ["Mac Aonghusa", "P\u00f3l", ""], ["Levacher", "Killian", ""]]}, {"id": "1907.02452", "submitter": "Said Ouala", "authors": "Said Ouala, Duong Nguyen, Lucas Drumetz, Bertrand Chapron, Ananda\n  Pascual, Fabrice Collard, Lucile Gaultier and Ronan Fablet", "title": "Learning Latent Dynamics for Partially-Observed Chaotic Systems", "comments": null, "journal-ref": null, "doi": "10.1063/5.0019309", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses the data-driven identification of latent dynamical\nrepresentations of partially-observed systems, i.e., dynamical systems for\nwhich some components are never observed, with an emphasis on forecasting\napplications, including long-term asymptotic patterns. Whereas state-of-the-art\ndata-driven approaches rely on delay embeddings and linear decompositions of\nthe underlying operators, we introduce a framework based on the data-driven\nidentification of an augmented state-space model using a neural-network-based\nrepresentation. For a given training dataset, it amounts to jointly learn an\nODE (Ordinary Differential Equation) representation in the latent space and\nreconstructing latent states. Through numerical experiments, we demonstrate the\nrelevance of the proposed framework w.r.t. state-of-the-art approaches in terms\nof short-term forecasting performance and long-term behaviour. We further\ndiscuss how the proposed framework relates to Koopman operator theory and\nTakens' embedding theorem.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jul 2019 15:23:12 GMT"}], "update_date": "2020-12-02", "authors_parsed": [["Ouala", "Said", ""], ["Nguyen", "Duong", ""], ["Drumetz", "Lucas", ""], ["Chapron", "Bertrand", ""], ["Pascual", "Ananda", ""], ["Collard", "Fabrice", ""], ["Gaultier", "Lucile", ""], ["Fablet", "Ronan", ""]]}, {"id": "1907.02477", "submitter": "Vinod Subramanian", "authors": "Vinod Subramanian, Emmanouil Benetos, Ning Xu, SKoT McDonald, Mark\n  Sandler", "title": "Adversarial Attacks in Sound Event Classification", "comments": "Fixed Freesound data reference to FSDKaggle2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.SD eess.AS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Adversarial attacks refer to a set of methods that perturb the input to a\nclassification model in order to fool the classifier. In this paper we apply\ndifferent gradient based adversarial attack algorithms on five deep learning\nmodels trained for sound event classification. Four of the models use\nmel-spectrogram input and one model uses raw audio input. The models represent\nstandard architectures such as convolutional, recurrent and dense networks. The\ndataset used for training is the Freesound dataset released for task 2 of the\nDCASE 2018 challenge and the models used are from participants of the challenge\nwho open sourced their code. Our experiments show that adversarial attacks can\nbe generated with high confidence and low perturbation. In addition, we show\nthat the adversarial attacks are very effective across the different models.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jul 2019 16:15:35 GMT"}, {"version": "v2", "created": "Thu, 15 Aug 2019 16:49:16 GMT"}], "update_date": "2019-08-16", "authors_parsed": [["Subramanian", "Vinod", ""], ["Benetos", "Emmanouil", ""], ["Xu", "Ning", ""], ["McDonald", "SKoT", ""], ["Sandler", "Mark", ""]]}, {"id": "1907.02509", "submitter": "Alexey Ignatiev", "authors": "Alexey Ignatiev, Nina Narodytska, Joao Marques-Silva", "title": "On Validating, Repairing and Refining Heuristic ML Explanations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent years have witnessed a fast-growing interest in computing explanations\nfor Machine Learning (ML) models predictions. For non-interpretable ML models,\nthe most commonly used approaches for computing explanations are heuristic in\nnature. In contrast, recent work proposed rigorous approaches for computing\nexplanations, which hold for a given ML model and prediction over the entire\ninstance space. This paper extends earlier work to the case of boosted trees\nand assesses the quality of explanations obtained with state-of-the-art\nheuristic approaches. On most of the datasets considered, and for the vast\nmajority of instances, the explanations obtained with heuristic approaches are\nshown to be inadequate when the entire instance space is (implicitly)\nconsidered.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jul 2019 17:45:11 GMT"}], "update_date": "2019-07-05", "authors_parsed": [["Ignatiev", "Alexey", ""], ["Narodytska", "Nina", ""], ["Marques-Silva", "Joao", ""]]}, {"id": "1907.02511", "submitter": "Evaggelia Tsiligianni", "authors": "Evaggelia Tsiligianni and Nikos Deligiannis", "title": "Deep Coupled-Representation Learning for Sparse Linear Inverse Problems\n  with Side Information", "comments": "6 pages, 4 figures", "journal-ref": null, "doi": "10.1109/LSP.2019.2929869", "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In linear inverse problems, the goal is to recover a target signal from\nundersampled, incomplete or noisy linear measurements. Typically, the recovery\nrelies on complex numerical optimization methods; recent approaches perform an\nunfolding of a numerical algorithm into a neural network form, resulting in a\nsubstantial reduction of the computational complexity. In this paper, we\nconsider the recovery of a target signal with the aid of a correlated signal,\nthe so-called side information (SI), and propose a deep unfolding model that\nincorporates SI. The proposed model is used to learn coupled representations of\ncorrelated signals from different modalities, enabling the recovery of\nmultimodal data at a low computational cost. As such, our work introduces the\nfirst deep unfolding method with SI, which actually comes from a different\nmodality. We apply our model to reconstruct near-infrared images from\nundersampled measurements given RGB images as SI. Experimental results\ndemonstrate the superior performance of the proposed framework against\nsingle-modal deep learning methods that do not use SI, multimodal deep learning\ndesigns, and optimization algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jul 2019 17:47:32 GMT"}], "update_date": "2020-01-08", "authors_parsed": [["Tsiligianni", "Evaggelia", ""], ["Deligiannis", "Nikos", ""]]}, {"id": "1907.02513", "submitter": "Uri Stemmer", "authors": "Uri Stemmer", "title": "Locally Private k-Means Clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We design a new algorithm for the Euclidean $k$-means problem that operates\nin the local model of differential privacy. Unlike in the non-private\nliterature, differentially private algorithms for the $k$-means objective incur\nboth additive and multiplicative errors. Our algorithm significantly reduces\nthe additive error while keeping the multiplicative error the same as in\nprevious state-of-the-art results. Specifically, on a database of size $n$, our\nalgorithm guarantees $O(1)$ multiplicative error and $\\approx n^{1/2+a}$\nadditive error for an arbitrarily small constant $a>0$. All previous algorithms\nin the local model had additive error $\\approx n^{2/3+a}$. Our techniques\nextend to $k$-median clustering.\n  We show that the additive error we obtain is almost optimal in terms of its\ndependency on the database size $n$. Specifically, we give a simple lower bound\nshowing that every locally-private algorithm for the $k$-means objective must\nhave additive error at least $\\approx\\sqrt{n}$.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jul 2019 17:50:33 GMT"}, {"version": "v2", "created": "Mon, 28 Jun 2021 00:29:49 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Stemmer", "Uri", ""]]}, {"id": "1907.02517", "submitter": "Alessandro Betti", "authors": "Alessandro Betti, Marco Gori", "title": "Least Action Principles and Well-Posed Learning Problems", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine Learning algorithms are typically regarded as appropriate\noptimization schemes for minimizing risk functions that are constructed on the\ntraining set, which conveys statistical flavor to the corresponding learning\nproblem. When the focus is shifted on perception, which is inherently\ninterwound with time, recent alternative formulations of learning have been\nproposed that rely on the principle of Least Cognitive Action, which very much\nreminds us of the Least Action Principle in mechanics. In this paper, we\ndiscuss different forms of the cognitive action and show the well-posedness of\nlearning. In particular, unlike the special case of the action in mechanics,\nwhere the stationarity is typically gained on saddle points, we prove the\nexistence of the minimum of a special form of cognitive action, which yields\nforth-order differential equations of learning. We also briefly discuss the\ndissipative behavior of these equations that turns out to characterize the\nprocess of learning.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jul 2019 17:54:45 GMT"}], "update_date": "2019-07-05", "authors_parsed": [["Betti", "Alessandro", ""], ["Gori", "Marco", ""]]}, {"id": "1907.02519", "submitter": "Kamil Adamczewski", "authors": "Kamil Adamczewski, Mijung Park", "title": "Neuron ranking -- an informed way to condense convolutional neural\n  networks architecture", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional neural networks (CNNs) in recent years have made a dramatic\nimpact in science, technology and industry, yet the theoretical mechanism of\nCNN architecture design remains surprisingly vague. The CNN neurons, including\nits distinctive element, convolutional filters, are known to be learnable\nfeatures, yet their individual role in producing the output is rather unclear.\nThe thesis of this work is that not all neurons are equally important and some\nof them contain more useful information to perform a given task . Consequently,\nwe quantify the significance of each filter and rank its importance in\ndescribing input to produce the desired output. This work presents two\ndifferent methods: (1) a game theoretical approach based on Shapley value which\ncomputes the marginal contribution of each filter; and (2) a probabilistic\napproach based on what-we-call, the Importance switch using variational\ninference. Strikingly, these two vastly different methods produce similar\nexperimental results, confirming the general theory that some of the filters\nare inherently more important that the others. The learned ranks can be readily\nuseable for network compression and interpretability.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jul 2019 15:20:21 GMT"}, {"version": "v2", "created": "Sat, 13 Jul 2019 21:34:19 GMT"}], "update_date": "2019-07-16", "authors_parsed": [["Adamczewski", "Kamil", ""], ["Park", "Mijung", ""]]}, {"id": "1907.02526", "submitter": "Nursadul Mamun Mr.", "authors": "Nursadul Mamun, Soheil Khorram, John H.L. Hansen", "title": "Convolutional Neural Network-based Speech Enhancement for Cochlear\n  Implant Recipients", "comments": "Interspeech 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Attempts to develop speech enhancement algorithms with improved speech\nintelligibility for cochlear implant (CI) users have met with limited success.\nTo improve speech enhancement methods for CI users, we propose to perform\nspeech enhancement in a cochlear filter-bank feature space, a feature-set\nspecifically designed for CI users based on CI auditory stimuli. We leverage a\nconvolutional neural network (CNN) to extract both stationary and\nnon-stationary components of environmental acoustics and speech. We propose\nthree CNN architectures: (1) vanilla CNN that directly generates the enhanced\nsignal; (2) spectral-subtraction-style CNN (SS-CNN) that first predicts noise\nand then generates the enhanced signal by subtracting noise from the noisy\nsignal; (3) Wiener-style CNN (Wiener-CNN) that generates an optimal mask for\nsuppressing noise. An important problem of the proposed networks is that they\nintroduce considerable delays, which limits their real-time application for CI\nusers. To address this, this study also considers causal variations of these\nnetworks. Our experiments show that the proposed networks (both causal and\nnon-causal forms) achieve significant improvement over existing baseline\nsystems. We also found that causal Wiener-CNN outperforms other networks, and\nleads to the best overall envelope coefficient measure (ECM). The proposed\nalgorithms represent a viable option for implementation on the CCi-MOBILE\nresearch platform as a pre-processor for CI users in naturalistic environments.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jul 2019 21:25:21 GMT"}], "update_date": "2019-07-08", "authors_parsed": [["Mamun", "Nursadul", ""], ["Khorram", "Soheil", ""], ["Hansen", "John H. L.", ""]]}, {"id": "1907.02531", "submitter": "Souvik Chakraborty", "authors": "Somdatta Goswami and Cosmin Anitescu and Souvik Chakraborty and Timon\n  Rabczuk", "title": "Transfer learning enhanced physics informed neural network for\n  phase-field modeling of fracture", "comments": "21 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new physics informed neural network (PINN) algorithm for solving\nbrittle fracture problems. While most of the PINN algorithms available in the\nliterature minimize the residual of the governing partial differential\nequation, the proposed approach takes a different path by minimizing the\nvariational energy of the system. Additionally, we modify the neural network\noutput such that the boundary conditions associated with the problem are\nexactly satisfied. Compared to conventional residual based PINN, the proposed\napproach has two major advantages. First, the imposition of boundary conditions\nis relatively simpler and more robust. Second, the order of derivatives present\nin the functional form of the variational energy is of lower order than in the\nresidual form. Hence, training the network is faster. To compute the total\nvariational energy of the system, an efficient scheme that takes as input a\ngeometry described by spline based CAD model and employs Gauss quadrature rules\nfor numerical integration has been proposed. Moreover, we utilize the concept\nof transfer learning to obtain the crack path in an efficient manner. The\nproposed approach is used to solve four fracture mechanics problems. For all\nthe examples, results obtained using the proposed approach match closely with\nthe results available in the literature. For the first two examples, we compare\nthe results obtained using the proposed approach with the conventional residual\nbased neural network results. For both the problems, the proposed approach is\nfound to yield better accuracy compared to conventional residual based PINN\nalgorithms.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jul 2019 17:03:43 GMT"}], "update_date": "2019-07-08", "authors_parsed": [["Goswami", "Somdatta", ""], ["Anitescu", "Cosmin", ""], ["Chakraborty", "Souvik", ""], ["Rabczuk", "Timon", ""]]}, {"id": "1907.02544", "submitter": "Jeff Donahue", "authors": "Jeff Donahue and Karen Simonyan", "title": "Large Scale Adversarial Representation Learning", "comments": "32 pages. In proceedings of NeurIPS 2019. This is the camera-ready\n  version of the paper, with supplementary material included as appendices", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarially trained generative models (GANs) have recently achieved\ncompelling image synthesis results. But despite early successes in using GANs\nfor unsupervised representation learning, they have since been superseded by\napproaches based on self-supervision. In this work we show that progress in\nimage generation quality translates to substantially improved representation\nlearning performance. Our approach, BigBiGAN, builds upon the state-of-the-art\nBigGAN model, extending it to representation learning by adding an encoder and\nmodifying the discriminator. We extensively evaluate the representation\nlearning and generation capabilities of these BigBiGAN models, demonstrating\nthat these generation-based models achieve the state of the art in unsupervised\nrepresentation learning on ImageNet, as well as in unconditional image\ngeneration. Pretrained BigBiGAN models -- including image generators and\nencoders -- are available on TensorFlow Hub\n(https://tfhub.dev/s?publisher=deepmind&q=bigbigan).\n", "versions": [{"version": "v1", "created": "Thu, 4 Jul 2019 18:00:17 GMT"}, {"version": "v2", "created": "Tue, 5 Nov 2019 18:05:57 GMT"}], "update_date": "2019-11-06", "authors_parsed": [["Donahue", "Jeff", ""], ["Simonyan", "Karen", ""]]}, {"id": "1907.02547", "submitter": "Le Thanh Nguyen-Meidine", "authors": "Hugo Masson, Amran Bhuiyan, Le Thanh Nguyen-Meidine, Mehrsan Javan,\n  Parthipan Siva, Ismail Ben Ayed, Eric Granger", "title": "Exploiting Prunability for Person Re-Identification", "comments": "Accepted for EURASIP Journal on Image and Video Processing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent years have witnessed a substantial increase in the deep learning\n(DL)architectures proposed for visual recognition tasks like person\nre-identification,where individuals must be recognized over multiple\ndistributed cameras. Althoughthese architectures have greatly improved the\nstate-of-the-art accuracy, thecomputational complexity of the CNNs commonly\nused for feature extractionremains an issue, hindering their deployment on\nplatforms with limited resources,or in applications with real-time constraints.\nThere is an obvious advantage toaccelerating and compressing DL models without\nsignificantly decreasing theiraccuracy. However, the source (pruning) domain\ndiffers from operational (target)domains, and the domain shift between image\ndata captured with differentnon-overlapping camera viewpoints leads to lower\nrecognition accuracy. In thispaper, we investigate the prunability of these\narchitectures under different designscenarios. This paper first revisits\npruning techniques that are suitable forreducing the computational complexity\nof deep CNN networks applied to personre-identification. Then, these techniques\nare analysed according to their pruningcriteria and strategy, and according to\ndifferent scenarios for exploiting pruningmethods to fine-tuning networks to\ntarget domains. Experimental resultsobtained using DL models with ResNet\nfeature extractors, and multiplebenchmarks re-identification datasets, indicate\nthat pruning can considerablyreduce network complexity while maintaining a high\nlevel of accuracy. Inscenarios where pruning is performed with large\npre-training or fine-tuningdatasets, the number of FLOPS required by ResNet\narchitectures is reduced byhalf, while maintaining a comparable rank-1 accuracy\n(within 1% of the originalmodel). Pruning while training a larger CNNs can also\nprovide a significantlybetter performance than fine-tuning smaller ones.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jul 2019 18:02:53 GMT"}, {"version": "v2", "created": "Wed, 14 Apr 2021 17:19:59 GMT"}], "update_date": "2021-04-15", "authors_parsed": [["Masson", "Hugo", ""], ["Bhuiyan", "Amran", ""], ["Nguyen-Meidine", "Le Thanh", ""], ["Javan", "Mehrsan", ""], ["Siva", "Parthipan", ""], ["Ayed", "Ismail Ben", ""], ["Granger", "Eric", ""]]}, {"id": "1907.02549", "submitter": "Hlynur Dav\\'i{\\dh} Hlynsson", "authors": "Hlynur Dav\\'i{\\dh} Hlynsson, Alberto N. Escalante-B., Laurenz Wiskott", "title": "Measuring the Data Efficiency of Deep Learning Methods", "comments": "8 pages", "journal-ref": "In Proceedings of the 8th International Conference on Pattern\n  Recognition Applications and Methods - Volume 1: ICPRAM (2019) pages 691-698", "doi": "10.5220/0007456306910698", "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a new experimental protocol and use it to benchmark\nthe data efficiency --- performance as a function of training set size --- of\ntwo deep learning algorithms, convolutional neural networks (CNNs) and\nhierarchical information-preserving graph-based slow feature analysis (HiGSFA),\nfor tasks in classification and transfer learning scenarios. The algorithms are\ntrained on different-sized subsets of the MNIST and Omniglot data sets. HiGSFA\noutperforms standard CNN networks when the models are trained on 50 and 200\nsamples per class for MNIST classification. In other cases, the CNNs perform\nbetter. The results suggest that there are cases where greedy, locally optimal\nbottom-up learning is equally or more powerful than global gradient-based\nlearning.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jul 2019 15:22:23 GMT"}], "update_date": "2019-07-08", "authors_parsed": [["Hlynsson", "Hlynur Dav\u00ed\u00f0", ""], ["Escalante-B.", "Alberto N.", ""], ["Wiskott", "Laurenz", ""]]}, {"id": "1907.02571", "submitter": "Stefano  Trac\\`a", "authors": "Stefano Trac\\`a, Cynthia Rudin, Weiyu Yan", "title": "Reducing Exploration of Dying Arms in Mortal Bandits", "comments": "Conference: UAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mortal bandits have proven to be extremely useful for providing news article\nrecommendations, running automated online advertising campaigns, and for other\napplications where the set of available options changes over time. Previous\nwork on this problem showed how to regulate exploration of new arms when they\nhave recently appeared, but they do not adapt when the arms are about to\ndisappear. Since in most applications we can determine either exactly or\napproximately when arms will disappear, we can leverage this information to\nimprove performance: we should not be exploring arms that are about to\ndisappear. We provide adaptations of algorithms, regret bounds, and experiments\nfor this study, showing a clear benefit from regulating greed\n(exploration/exploitation) for arms that will soon disappear. We illustrate\nnumerical performance on the Yahoo! Front Page Today Module User Click Log\nDataset.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jul 2019 19:57:03 GMT"}], "update_date": "2019-07-08", "authors_parsed": [["Trac\u00e0", "Stefano", ""], ["Rudin", "Cynthia", ""], ["Yan", "Weiyu", ""]]}, {"id": "1907.02577", "submitter": "Akshay Iyer", "authors": "Akshay Iyer, Yichi Zhang, Aditya Prasad, Siyu Tao, Yixing Wang, Linda\n  Schadler, L Catherine Brinson and Wei Chen", "title": "Data-Centric Mixed-Variable Bayesian Optimization For Materials Design", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.comp-ph cond-mat.mtrl-sci cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Materials design can be cast as an optimization problem with the goal of\nachieving desired properties, by varying material composition, microstructure\nmorphology, and processing conditions. Existence of both qualitative and\nquantitative material design variables leads to disjointed regions in property\nspace, making the search for optimal design challenging. Limited availability\nof experimental data and the high cost of simulations magnify the challenge.\nThis situation calls for design methodologies that can extract useful\ninformation from existing data and guide the search for optimal designs\nefficiently. To this end, we present a data-centric, mixed-variable Bayesian\nOptimization framework that integrates data from literature, experiments, and\nsimulations for knowledge discovery and computational materials design. Our\nframework pivots around the Latent Variable Gaussian Process (LVGP), a novel\nGaussian Process technique which projects qualitative variables on a continuous\nlatent space for covariance formulation, as the surrogate model to quantify\n\"lack of data\" uncertainty. Expected improvement, an acquisition criterion that\nbalances exploration and exploitation, helps navigate a complex, nonlinear\ndesign space to locate the optimum design. The proposed framework is tested\nthrough a case study which seeks to concurrently identify the optimal\ncomposition and morphology for insulating polymer nanocomposites. We also\npresent an extension of mixed-variable Bayesian Optimization for multiple\nobjectives to identify the Pareto Frontier within tens of iterations. These\nfindings project Bayesian Optimization as a powerful tool for design of\nengineered material systems.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jul 2019 20:21:40 GMT"}], "update_date": "2019-07-08", "authors_parsed": [["Iyer", "Akshay", ""], ["Zhang", "Yichi", ""], ["Prasad", "Aditya", ""], ["Tao", "Siyu", ""], ["Wang", "Yixing", ""], ["Schadler", "Linda", ""], ["Brinson", "L Catherine", ""], ["Chen", "Wei", ""]]}, {"id": "1907.02582", "submitter": "Ana Lucic", "authors": "Ana Lucic, Hinda Haned, Maarten de Rijke", "title": "Explaining Predictions from Tree-based Boosting Ensembles", "comments": "SIGIR 2019: FACTS-IR Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding how \"black-box\" models arrive at their predictions has sparked\nsignificant interest from both within and outside the AI community. Our work\nfocuses on doing this by generating local explanations about individual\npredictions for tree-based ensembles, specifically Gradient Boosting Decision\nTrees (GBDTs). Given a correctly predicted instance in the training set, we\nwish to generate a counterfactual explanation for this instance, that is, the\nminimal perturbation of this instance such that the prediction flips to the\nopposite class. Most existing methods for counterfactual explanations are (1)\nmodel-agnostic, so they do not take into account the structure of the original\nmodel, and/or (2) involve building a surrogate model on top of the original\nmodel, which is not guaranteed to represent the original model accurately.\nThere exists a method specifically for random forests; we wish to extend this\nmethod for GBDTs. This involves accounting for (1) the sequential dependency\nbetween trees and (2) training on the negative gradients instead of the\noriginal labels.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jul 2019 20:43:12 GMT"}], "update_date": "2019-07-08", "authors_parsed": [["Lucic", "Ana", ""], ["Haned", "Hinda", ""], ["de Rijke", "Maarten", ""]]}, {"id": "1907.02584", "submitter": "Janis Klaise", "authors": "Arnaud Van Looveren and Janis Klaise", "title": "Interpretable Counterfactual Explanations Guided by Prototypes", "comments": "17 pages, 13 figures. For an open source implementation of the\n  algorithm, see https://github.com/SeldonIO/alibi", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a fast, model agnostic method for finding interpretable\ncounterfactual explanations of classifier predictions by using class\nprototypes. We show that class prototypes, obtained using either an encoder or\nthrough class specific k-d trees, significantly speed up the the search for\ncounterfactual instances and result in more interpretable explanations. We\nintroduce two novel metrics to quantitatively evaluate local interpretability\nat the instance level. We use these metrics to illustrate the effectiveness of\nour method on an image and tabular dataset, respectively MNIST and Breast\nCancer Wisconsin (Diagnostic). The method also eliminates the computational\nbottleneck that arises because of numerical gradient evaluation for\n$\\textit{black box}$ models.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jul 2019 13:12:08 GMT"}, {"version": "v2", "created": "Tue, 18 Feb 2020 11:46:29 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Van Looveren", "Arnaud", ""], ["Klaise", "Janis", ""]]}, {"id": "1907.02586", "submitter": "Guangfeng Lin", "authors": "Guangfeng Lin and Jing Wang and Kaiyang Liao and Fan Zhao and Wanjun\n  Chen", "title": "Structure fusion based on graph convolutional networks for\n  semi-supervised classification", "comments": null, "journal-ref": "Electronics,2020", "doi": "10.3390/electronics9030432", "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Suffering from the multi-view data diversity and complexity for\nsemi-supervised classification, most of existing graph convolutional networks\nfocus on the networks architecture construction or the salient graph structure\npreservation, and ignore the the complete graph structure for semi-supervised\nclassification contribution. To mine the more complete distribution structure\nfrom multi-view data with the consideration of the specificity and the\ncommonality, we propose structure fusion based on graph convolutional networks\n(SF-GCN) for improving the performance of semi-supervised classification.\nSF-GCN can not only retain the special characteristic of each view data by\nspectral embedding, but also capture the common style of multi-view data by\ndistance metric between multi-graph structures. Suppose the linear relationship\nbetween multi-graph structures, we can construct the optimization function of\nstructure fusion model by balancing the specificity loss and the commonality\nloss. By solving this function, we can simultaneously obtain the fusion\nspectral embedding from the multi-view data and the fusion structure as\nadjacent matrix to input graph convolutional networks for semi-supervised\nclassification. Experiments demonstrate that the performance of SF-GCN\noutperforms that of the state of the arts on three challenging datasets, which\nare Cora,Citeseer and Pubmed in citation networks.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jul 2019 23:43:05 GMT"}], "update_date": "2020-06-01", "authors_parsed": [["Lin", "Guangfeng", ""], ["Wang", "Jing", ""], ["Liao", "Kaiyang", ""], ["Zhao", "Fan", ""], ["Chen", "Wanjun", ""]]}, {"id": "1907.02596", "submitter": "Abderrazak Chahid Mr", "authors": "Abderrazak Chahid, Fahad Albalawi, Turky Nayef Alotaiby, Majed Hamad\n  Al-Hameed, Saleh Alshebeili, Taous-Meriem Laleg-Kirati", "title": "QuPWM: Feature Extraction Method for MEG Epileptic Spike Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Epilepsy is a neurological disorder classified as the second most serious\nneurological disease known to humanity, after stroke. Localization of the\nepileptogenic zone is an important step for epileptic patient treatment, which\nstarts with epileptic spike detection. The common practice for spike detection\nof brain signals is via visual scanning of the recordings, which is a\nsubjective and a very time-consuming task. Motivated by that, this paper\nfocuses on using machine learning for automatic detection of epileptic spikes\nin magnetoencephalography (MEG) signals. First, we used the Position Weight\nMatrix (PWM) method combined with a uniform quantizer to generate useful\nfeatures. Second, the extracted features are classified using a Support Vector\nMachine (SVM) for the purpose of epileptic spikes detection. The proposed\ntechnique shows great potential in improving the spike detection accuracy and\nreducing the feature vector size. Specifically, the proposed technique achieved\naverage accuracy up to 98\\% in using 5-folds cross-validation applied to a\nbalanced dataset of 3104 samples. These samples are extracted from 16 subjects\nwhere eight are healthy and eight are epileptic subjects using a sliding frame\nof size of 100 samples-points with a step-size of 2 sample-points\n", "versions": [{"version": "v1", "created": "Wed, 3 Jul 2019 11:11:19 GMT"}], "update_date": "2019-07-08", "authors_parsed": [["Chahid", "Abderrazak", ""], ["Albalawi", "Fahad", ""], ["Alotaiby", "Turky Nayef", ""], ["Al-Hameed", "Majed Hamad", ""], ["Alshebeili", "Saleh", ""], ["Laleg-Kirati", "Taous-Meriem", ""]]}, {"id": "1907.02610", "submitter": "Chongli Qin", "authors": "Chongli Qin, James Martens, Sven Gowal, Dilip Krishnan, Krishnamurthy\n  Dvijotham, Alhussein Fawzi, Soham De, Robert Stanforth, Pushmeet Kohli", "title": "Adversarial Robustness through Local Linearization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial training is an effective methodology for training deep neural\nnetworks that are robust against adversarial, norm-bounded perturbations.\nHowever, the computational cost of adversarial training grows prohibitively as\nthe size of the model and number of input dimensions increase. Further,\ntraining against less expensive and therefore weaker adversaries produces\nmodels that are robust against weak attacks but break down under attacks that\nare stronger. This is often attributed to the phenomenon of gradient\nobfuscation; such models have a highly non-linear loss surface in the vicinity\nof training examples, making it hard for gradient-based attacks to succeed even\nthough adversarial examples still exist. In this work, we introduce a novel\nregularizer that encourages the loss to behave linearly in the vicinity of the\ntraining data, thereby penalizing gradient obfuscation while encouraging\nrobustness. We show via extensive experiments on CIFAR-10 and ImageNet, that\nmodels trained with our regularizer avoid gradient obfuscation and can be\ntrained significantly faster than adversarial training. Using this regularizer,\nwe exceed current state of the art and achieve 47% adversarial accuracy for\nImageNet with l-infinity adversarial perturbations of radius 4/255 under an\nuntargeted, strong, white-box attack. Additionally, we match state of the art\nresults for CIFAR-10 at 8/255.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jul 2019 21:55:29 GMT"}, {"version": "v2", "created": "Thu, 10 Oct 2019 16:43:35 GMT"}], "update_date": "2019-10-11", "authors_parsed": [["Qin", "Chongli", ""], ["Martens", "James", ""], ["Gowal", "Sven", ""], ["Krishnan", "Dilip", ""], ["Dvijotham", "Krishnamurthy", ""], ["Fawzi", "Alhussein", ""], ["De", "Soham", ""], ["Stanforth", "Robert", ""], ["Kohli", "Pushmeet", ""]]}, {"id": "1907.02633", "submitter": "Romuald Elie", "authors": "Romuald Elie, Julien P\\'erolat, Mathieu Lauri\\`ere, Matthieu Geist,\n  Olivier Pietquin", "title": "On the Convergence of Model Free Learning in Mean Field Games", "comments": null, "journal-ref": "AAAI 2020 conference proceedings", "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning by experience in Multi-Agent Systems (MAS) is a difficult and\nexciting task, due to the lack of stationarity of the environment, whose\ndynamics evolves as the population learns. In order to design scalable\nalgorithms for systems with a large population of interacting agents (e.g.\nswarms), this paper focuses on Mean Field MAS, where the number of agents is\nasymptotically infinite. Recently, a very active burgeoning field studies the\neffects of diverse reinforcement learning algorithms for agents with no prior\ninformation on a stationary Mean Field Game (MFG) and learn their policy\nthrough repeated experience. We adopt a high perspective on this problem and\nanalyze in full generality the convergence of a fictitious iterative scheme\nusing any single agent learning algorithm at each step. We quantify the quality\nof the computed approximate Nash equilibrium, in terms of the accumulated\nerrors arising at each learning iteration step. Notably, we show for the first\ntime convergence of model free learning algorithms towards non-stationary MFG\nequilibria, relying only on classical assumptions on the MFG dynamics. We\nillustrate our theoretical results with a numerical experiment in a continuous\naction-space environment, where the approximate best response of the iterative\nfictitious play scheme is computed with a deep RL algorithm.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jul 2019 11:54:09 GMT"}, {"version": "v2", "created": "Fri, 20 Dec 2019 16:01:32 GMT"}, {"version": "v3", "created": "Fri, 21 Feb 2020 00:13:13 GMT"}], "update_date": "2020-02-24", "authors_parsed": [["Elie", "Romuald", ""], ["P\u00e9rolat", "Julien", ""], ["Lauri\u00e8re", "Mathieu", ""], ["Geist", "Matthieu", ""], ["Pietquin", "Olivier", ""]]}, {"id": "1907.02636", "submitter": "Zi Long", "authors": "Zi Long, Lianzhi Tan, Shengping Zhou, Chaoyang He, Xin Liu", "title": "Collecting Indicators of Compromise from Unstructured Text of\n  Cybersecurity Articles using Neural-Based Sequence Labelling", "comments": "IJCNN 2019. arXiv admin note: substantial text overlap with\n  arXiv:1810.10156", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Indicators of Compromise (IOCs) are artifacts observed on a network or in an\noperating system that can be utilized to indicate a computer intrusion and\ndetect cyber-attacks in an early stage. Thus, they exert an important role in\nthe field of cybersecurity. However, state-of-the-art IOCs detection systems\nrely heavily on hand-crafted features with expert knowledge of cybersecurity,\nand require large-scale manually annotated corpora to train an IOC classifier.\nIn this paper, we propose using an end-to-end neural-based sequence labelling\nmodel to identify IOCs automatically from cybersecurity articles without expert\nknowledge of cybersecurity. By using a multi-head self-attention module and\ncontextual features, we find that the proposed model is capable of gathering\ncontextual information from texts of cybersecurity articles and performs better\nin the task of IOC identification. Experiments show that the proposed model\noutperforms other sequence labelling models, achieving the average F1-score of\n89.0% on English cybersecurity article test set, and approximately the average\nF1-score of 81.8% on Chinese test set.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jul 2019 02:54:02 GMT"}, {"version": "v2", "created": "Fri, 27 Sep 2019 02:35:04 GMT"}], "update_date": "2019-09-30", "authors_parsed": [["Long", "Zi", ""], ["Tan", "Lianzhi", ""], ["Zhou", "Shengping", ""], ["He", "Chaoyang", ""], ["Liu", "Xin", ""]]}, {"id": "1907.02637", "submitter": "Cyran Aouameur", "authors": "Cyran Aouameur, Philippe Esling, Ga\\\"etan Hadjeres", "title": "Neural Drum Machine : An Interactive System for Real-time Synthesis of\n  Drum Sounds", "comments": "8 pages, accepted at the International Conference on Computational\n  Creativity 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this work, we introduce a system for real-time generation of drum sounds.\nThis system is composed of two parts: a generative model for drum sounds\ntogether with a Max4Live plugin providing intuitive controls on the generative\nprocess. The generative model consists of a Conditional Wasserstein autoencoder\n(CWAE), which learns to generate Mel-scaled magnitude spectrograms of short\npercussion samples, coupled with a Multi-Head Convolutional Neural Network\n(MCNN) which estimates the corresponding audio signal from the magnitude\nspectrogram. The design of this model makes it lightweight, so that it allows\none to perform real-time generation of novel drum sounds on an average CPU,\nremoving the need for the users to possess dedicated hardware in order to use\nthis system. We then present our Max4Live interface designed to interact with\nthis generative model. With this setup, the system can be easily integrated\ninto a studio-production environment and enhance the creative process. Finally,\nwe discuss the advantages of our system and how the interaction of music\nproducers with such tools could change the way drum tracks are composed.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jul 2019 17:22:27 GMT"}, {"version": "v2", "created": "Wed, 13 Nov 2019 12:51:55 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["Aouameur", "Cyran", ""], ["Esling", "Philippe", ""], ["Hadjeres", "Ga\u00ebtan", ""]]}, {"id": "1907.02644", "submitter": "Adalberto Claudio Quiros", "authors": "Adalberto Claudio Quiros, Roderick Murray-Smith, Ke Yuan", "title": "PathologyGAN: Learning deep representations of cancer tissue", "comments": "Accepted for publication at the Journal of Machine Learning for\n  Biomedical Imaging (MELBA) https://melba-journal.org", "journal-ref": "Journal of Machine Learning for Biomedical Imaging. 2021:4. pp\n  1-48. Special Issue: Medical Imaging with Deep Learning (MIDL) 2020", "doi": null, "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Histopathological images of tumors contain abundant information about how\ntumors grow and how they interact with their micro-environment. Better\nunderstanding of tissue phenotypes in these images could reveal novel\ndeterminants of pathological processes underlying cancer, and in turn improve\ndiagnosis and treatment options. Advances of Deep learning makes it ideal to\nachieve those goals, however, its application is limited by the cost of high\nquality labels from patients data. Unsupervised learning, in particular, deep\ngenerative models with representation learning properties provides an\nalternative path to further understand cancer tissue phenotypes, capturing\ntissue morphologies. In this paper, we develop a framework which allows GANs to\ncapture key tissue features and uses these characteristics to give structure to\nits latent space. To this end, we trained our model on two different datasets,\nan H&E colorectal cancer tissue from the National Center for Tumor diseases\n(NCT) and an H&E breast cancer tissue from the Netherlands Cancer Institute\n(NKI) and Vancouver General Hospital (VGH). Composed of 86 slide images and 576\nTMAs respectively. We show that our model generates high quality images, with a\nFID of 16.65 (breast cancer) and 32.05 (colorectal cancer). We further assess\nthe quality of the images with cancer tissue characteristics (e.g. count of\ncancer, lymphocytes, or stromal cells), using quantitative information to\ncalculate the FID and showing consistent performance of 9.86. Additionally, the\nlatent space of our model shows an interpretable structure and allows semantic\nvector operations that translate into tissue feature transformations.\nFurthermore, ratings from two expert pathologists found no significant\ndifference between our generated tissue images from real ones. The code,\nimages, and pretrained models are available at\nhttps://github.com/AdalbertoCq/Pathology-GAN\n", "versions": [{"version": "v1", "created": "Thu, 4 Jul 2019 15:27:22 GMT"}, {"version": "v2", "created": "Fri, 31 Jan 2020 11:30:01 GMT"}, {"version": "v3", "created": "Tue, 26 May 2020 11:45:40 GMT"}, {"version": "v4", "created": "Thu, 28 May 2020 15:16:08 GMT"}, {"version": "v5", "created": "Tue, 13 Apr 2021 16:54:45 GMT"}], "update_date": "2021-04-14", "authors_parsed": [["Quiros", "Adalberto Claudio", ""], ["Murray-Smith", "Roderick", ""], ["Yuan", "Ke", ""]]}, {"id": "1907.02647", "submitter": "F. William Townes", "authors": "F. William Townes", "title": "Generalized Principal Component Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generalized principal component analysis (GLM-PCA) facilitates dimension\nreduction of non-normally distributed data. We provide a detailed derivation of\nGLM-PCA with a focus on optimization. We also demonstrate how to incorporate\ncovariates, and suggest post-processing transformations to improve\ninterpretability of latent factors.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jul 2019 04:18:31 GMT"}], "update_date": "2019-07-08", "authors_parsed": [["Townes", "F. William", ""]]}, {"id": "1907.02649", "submitter": "Owen Marschall", "authors": "Owen Marschall, Kyunghyun Cho, Cristina Savin", "title": "A Unified Framework of Online Learning Algorithms for Training Recurrent\n  Neural Networks", "comments": "29 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a framework for compactly summarizing many recent results in\nefficient and/or biologically plausible online training of recurrent neural\nnetworks (RNN). The framework organizes algorithms according to several\ncriteria: (a) past vs. future facing, (b) tensor structure, (c) stochastic vs.\ndeterministic, and (d) closed form vs. numerical. These axes reveal latent\nconceptual connections among several recent advances in online learning.\nFurthermore, we provide novel mathematical intuitions for their degree of\nsuccess. Testing various algorithms on two synthetic tasks shows that\nperformances cluster according to our criteria. Although a similar clustering\nis also observed for gradient alignment, alignment with exact methods does not\nalone explain ultimate performance, especially for stochastic algorithms. This\nsuggests the need for better comparison metrics.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jul 2019 01:49:45 GMT"}], "update_date": "2019-07-08", "authors_parsed": [["Marschall", "Owen", ""], ["Cho", "Kyunghyun", ""], ["Savin", "Cristina", ""]]}, {"id": "1907.02662", "submitter": "Amit Rege", "authors": "Amit Rege, Claire Monteleoni", "title": "Evaluating the distribution learning capabilities of GANs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We evaluate the distribution learning capabilities of generative adversarial\nnetworks by testing them on synthetic datasets. The datasets include common\ndistributions of points in $R^n$ space and images containing polygons of\nvarious shapes and sizes. We find that by and large GANs fail to faithfully\nrecreate point datasets which contain discontinous support or sharp bends with\nnoise. Additionally, on image datasets, we find that GANs do not seem to learn\nto count the number of objects of the same kind in an image. We also highlight\nthe apparent tension between generalization and learning in GANs.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jul 2019 02:59:40 GMT"}], "update_date": "2019-07-08", "authors_parsed": [["Rege", "Amit", ""], ["Monteleoni", "Claire", ""]]}, {"id": "1907.02663", "submitter": "Weicheng Cai", "authors": "Weicheng Cai, Haiwei Wu, Danwei Cai, and Ming Li", "title": "The DKU Replay Detection System for the ASVspoof 2019 Challenge: On Data\n  Augmentation, Feature Representation, Classification, and Fusion", "comments": "Accepted for INTERSPEECH 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CR cs.LG cs.MM cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes our DKU replay detection system for the ASVspoof 2019\nchallenge. The goal is to develop spoofing countermeasure for automatic speaker\nrecognition in physical access scenario. We leverage the countermeasure system\npipeline from four aspects, including the data augmentation, feature\nrepresentation, classification, and fusion. First, we introduce an\nutterance-level deep learning framework for anti-spoofing. It receives the\nvariable-length feature sequence and outputs the utterance-level scores\ndirectly. Based on the framework, we try out various kinds of input feature\nrepresentations extracted from either the magnitude spectrum or phase spectrum.\nBesides, we also perform the data augmentation strategy by applying the speed\nperturbation on the raw waveform. Our best single system employs a residual\nneural network trained by the speed-perturbed group delay gram. It achieves EER\nof 1.04% on the development set, as well as EER of 1.08% on the evaluation set.\nFinally, using the simple average score from several single systems can further\nimprove the performance. EER of 0.24% on the development set and 0.66% on the\nevaluation set is obtained for our primary system.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jul 2019 03:00:05 GMT"}], "update_date": "2019-07-08", "authors_parsed": [["Cai", "Weicheng", ""], ["Wu", "Haiwei", ""], ["Cai", "Danwei", ""], ["Li", "Ming", ""]]}, {"id": "1907.02664", "submitter": "Deepesh Data", "authors": "Deepesh Data, Linqi Song, Suhas Diggavi", "title": "Data Encoding for Byzantine-Resilient Distributed Optimization", "comments": "38 pages, Accepted for publication in the IEEE Transactions on\n  Information Theory", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study distributed optimization in the presence of Byzantine adversaries,\nwhere both data and computation are distributed among $m$ worker machines, $t$\nof which may be corrupt. The compromised nodes may collaboratively and\narbitrarily deviate from their pre-specified programs, and a designated\n(master) node iteratively computes the model/parameter vector for generalized\nlinear models. In this work, we primarily focus on two iterative algorithms:\nProximal Gradient Descent (PGD) and Coordinate Descent (CD). Gradient descent\n(GD) is a special case of these algorithms. PGD is typically used in the\ndata-parallel setting, where data is partitioned across different samples,\nwhereas, CD is used in the model-parallelism setting, where data is partitioned\nacross the parameter space.\n  In this paper, we propose a method based on data encoding and error\ncorrection over real numbers to combat adversarial attacks. We can tolerate up\nto $t\\leq \\lfloor\\frac{m-1}{2}\\rfloor$ corrupt worker nodes, which is\ninformation-theoretically optimal. We give deterministic guarantees, and our\nmethod does not assume any probability distribution on the data. We develop a\n{\\em sparse} encoding scheme which enables computationally efficient data\nencoding and decoding. We demonstrate a trade-off between the corruption\nthreshold and the resource requirements (storage, computational, and\ncommunication complexity). As an example, for $t\\leq\\frac{m}{3}$, our scheme\nincurs only a {\\em constant} overhead on these resources, over that required by\nthe plain distributed PGD/CD algorithms which provide no adversarial\nprotection. To the best of our knowledge, ours is the first paper that makes CD\nsecure against adversarial attacks.\n  Our encoding scheme extends efficiently to the data streaming model and for\nstochastic gradient descent (SGD). We also give experimental results to show\nthe efficacy of our proposed schemes.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jul 2019 03:31:43 GMT"}, {"version": "v2", "created": "Wed, 4 Nov 2020 05:57:11 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["Data", "Deepesh", ""], ["Song", "Linqi", ""], ["Diggavi", "Suhas", ""]]}, {"id": "1907.02670", "submitter": "Jeong Choi", "authors": "Jeong Choi, Jongpil Lee, Jiyoung Park, and Juhan Nam", "title": "Zero-shot Learning for Audio-based Music Classification and Tagging", "comments": "20th International Society for Music Information Retrieval Conference\n  (ISMIR), 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.MM cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Audio-based music classification and tagging is typically based on\ncategorical supervised learning with a fixed set of labels. This intrinsically\ncannot handle unseen labels such as newly added music genres or semantic words\nthat users arbitrarily choose for music retrieval. Zero-shot learning can\naddress this problem by leveraging an additional semantic space of labels where\nside information about the labels is used to unveil the relationship between\neach other. In this work, we investigate the zero-shot learning in the music\ndomain and organize two different setups of side information. One is using\nhuman-labeled attribute information based on Free Music Archive and\nOpenMIC-2018 datasets. The other is using general word semantic information\nbased on Million Song Dataset and Last.fm tag annotations. Considering a music\ntrack is usually multi-labeled in music classification and tagging datasets, we\nalso propose a data split scheme and associated evaluation settings for the\nmulti-label zero-shot learning. Finally, we report experimental results and\ndiscuss the effectiveness and new possibilities of zero-shot learning in the\nmusic domain.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jul 2019 04:19:37 GMT"}, {"version": "v2", "created": "Thu, 19 Mar 2020 11:02:36 GMT"}], "update_date": "2020-03-20", "authors_parsed": [["Choi", "Jeong", ""], ["Lee", "Jongpil", ""], ["Park", "Jiyoung", ""], ["Nam", "Juhan", ""]]}, {"id": "1907.02677", "submitter": "Jos\\'e Camacho", "authors": "Jos\\'e Camacho, Rasmus Bro, David Kotz", "title": "Networkmetrics unraveled: MBDA in Action", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose networkmetrics, a new data-driven approach for monitoring,\ntroubleshooting and understanding communication networks using multivariate\nanalysis. Networkmetric models are powerful machine-learning tools to interpret\nand interact with data collected from a network. In this paper, we illustrate\nthe application of Multivariate Big Data Analysis (MBDA), a recently proposed\nnetworkmetric method with application to Big Data sets. We use MBDA for the\ndetection and troubleshooting of network problems in a campus-wide Wi-Fi\nnetwork. Data includes a seven-year trace (from 2012 to 2018) of the network's\nmost recent activity, with approximately 3,000 distinct access points, 40,000\nauthenticated users, and 600,000 distinct Wi-Fi stations. This is the longest\nand largest Wi-Fi trace known to date. To analyze this data, we propose\nlearning and visualization procedures that extend MBDA. These procedures result\nin a methodology that allows network analysts to identify problems and diagnose\nand troubleshoot them, optimizing the network performance. In the paper, we go\nthrough the entire workflow of the approach, illustrating its application in\ndetail and discussing processing times for parallel hardware.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jul 2019 04:51:49 GMT"}], "update_date": "2019-07-08", "authors_parsed": [["Camacho", "Jos\u00e9", ""], ["Bro", "Rasmus", ""], ["Kotz", "David", ""]]}, {"id": "1907.02690", "submitter": "Yanwu Xu", "authors": "Mingming Gong, Yanwu Xu, Chunyuan Li, Kun Zhang, Kayhan Batmanghelich", "title": "Twin Auxiliary Classifiers GAN", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conditional generative models enjoy remarkable progress over the past few\nyears. One of the popular conditional models is Auxiliary Classifier GAN\n(AC-GAN), which generates highly discriminative images by extending the loss\nfunction of GAN with an auxiliary classifier. However, the diversity of the\ngenerated samples by AC-GAN tends to decrease as the number of classes\nincreases, hence limiting its power on large-scale data. In this paper, we\nidentify the source of the low diversity issue theoretically and propose a\npractical solution to solve the problem. We show that the auxiliary classifier\nin AC-GAN imposes perfect separability, which is disadvantageous when the\nsupports of the class distributions have significant overlap. To address the\nissue, we propose Twin Auxiliary Classifiers Generative Adversarial Net\n(TAC-GAN) that further benefits from a new player that interacts with other\nplayers (the generator and the discriminator) in GAN. Theoretically, we\ndemonstrate that TAC-GAN can effectively minimize the divergence between the\ngenerated and real-data distributions. Extensive experimental results show that\nour TAC-GAN can successfully replicate the true data distributions on simulated\ndata, and significantly improves the diversity of class-conditional image\ngeneration on real datasets.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jul 2019 06:29:06 GMT"}, {"version": "v2", "created": "Wed, 10 Jul 2019 03:04:06 GMT"}, {"version": "v3", "created": "Tue, 30 Jul 2019 05:14:12 GMT"}, {"version": "v4", "created": "Mon, 4 Nov 2019 20:30:21 GMT"}], "update_date": "2019-11-06", "authors_parsed": [["Gong", "Mingming", ""], ["Xu", "Yanwu", ""], ["Li", "Chunyuan", ""], ["Zhang", "Kun", ""], ["Batmanghelich", "Kayhan", ""]]}, {"id": "1907.02698", "submitter": "Jonggwon Park", "authors": "Jonggwon Park, Kyoyun Choi, Sungwook Jeon, Dokyun Kim and Jonghun Park", "title": "A Bi-directional Transformer for Musical Chord Recognition", "comments": "20th International Society for Music Information Retrieval Conference\n  (ISMIR), Delft, The Netherlands, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Chord recognition is an important task since chords are highly abstract and\ndescriptive features of music. For effective chord recognition, it is essential\nto utilize relevant context in audio sequence. While various machine learning\nmodels such as convolutional neural networks (CNNs) and recurrent neural\nnetworks (RNNs) have been employed for the task, most of them have limitations\nin capturing long-term dependency or require training of an additional model.\nIn this work, we utilize a self-attention mechanism for chord recognition to\nfocus on certain regions of chords. Training of the proposed bi-directional\nTransformer for chord recognition (BTC) consists of a single phase while\nshowing competitive performance. Through an attention map analysis, we have\nvisualized how attention was performed. It turns out that the model was able to\ndivide segments of chords by utilizing adaptive receptive field of the\nattention mechanism. Furthermore, it was observed that the model was able to\neffectively capture long-term dependencies, making use of essential information\nregardless of distance.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jul 2019 07:00:38 GMT"}], "update_date": "2019-07-08", "authors_parsed": [["Park", "Jonggwon", ""], ["Choi", "Kyoyun", ""], ["Jeon", "Sungwook", ""], ["Kim", "Dokyun", ""], ["Park", "Jonghun", ""]]}, {"id": "1907.02711", "submitter": "Lakmal Meegahapola", "authors": "Lakmal Meegahapola, Vengateswaran Subramaniam, Lance Kaplan, Archan\n  Misra", "title": "Prior Activation Distribution (PAD): A Versatile Representation to\n  Utilize DNN Hidden Units", "comments": "Submitted to NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce the concept of Prior Activation Distribution\n(PAD) as a versatile and general technique to capture the typical activation\npatterns of hidden layer units of a Deep Neural Network used for classification\ntasks. We show that the combined neural activations of such a hidden layer have\nclass-specific distributional properties, and then define multiple statistical\nmeasures to compute how far a test sample's activations deviate from such\ndistributions. Using a variety of benchmark datasets (including MNIST, CIFAR10,\nFashion-MNIST & notMNIST), we show how such PAD-based measures can be used,\nindependent of any training technique, to (a) derive fine-grained uncertainty\nestimates for inferences; (b) provide inferencing accuracy competitive with\nalternatives that require execution of the full pipeline, and (c) reliably\nisolate out-of-distribution test samples.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jul 2019 07:55:09 GMT"}], "update_date": "2019-07-08", "authors_parsed": [["Meegahapola", "Lakmal", ""], ["Subramaniam", "Vengateswaran", ""], ["Kaplan", "Lance", ""], ["Misra", "Archan", ""]]}, {"id": "1907.02745", "submitter": "Jinhyun Ahn", "authors": "Jin-Hyun Ahn, Osvaldo Simeone, Joonhyuk Kang", "title": "Wireless Federated Distillation for Distributed Edge Learning with\n  Heterogeneous Data", "comments": "submitted for conference publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cooperative training methods for distributed machine learning typically\nassume noiseless and ideal communication channels. This work studies some of\nthe opportunities and challenges arising from the presence of wireless\ncommunication links. We specifically consider wireless implementations of\nFederated Learning (FL) and Federated Distillation (FD), as well as of a novel\nHybrid Federated Distillation (HFD) scheme. Both digital implementations based\non separate source-channel coding and over-the-air computing implementations\nbased on joint source-channel coding are proposed and evaluated over Gaussian\nmultiple-access channels.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jul 2019 09:47:40 GMT"}], "update_date": "2019-07-08", "authors_parsed": [["Ahn", "Jin-Hyun", ""], ["Simeone", "Osvaldo", ""], ["Kang", "Joonhyuk", ""]]}, {"id": "1907.02784", "submitter": "No\\'e Tits", "authors": "No\\'e Tits", "title": "A Methodology for Controlling the Emotional Expressiveness in Synthetic\n  Speech -- a Deep Learning approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this project, we aim to build a Text-to-Speech system able to produce\nspeech with a controllable emotional expressiveness. We propose a methodology\nfor solving this problem in three main steps. The first is the collection of\nemotional speech data. We discuss the various formats of existing datasets and\ntheir usability in speech generation. The second step is the development of a\nsystem to automatically annotate data with emotion/expressiveness features. We\ncompare several techniques using transfer learning to extract such a\nrepresentation through other tasks and propose a method to visualize and\ninterpret the correlation between vocal and emotional features. The third step\nis the development of a deep learning-based system taking text and\nemotion/expressiveness as input and producing speech as output. We study the\nimpact of fine tuning from a neutral TTS towards an emotional TTS in terms of\nintelligibility and perception of the emotion.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jul 2019 12:00:53 GMT"}], "update_date": "2019-07-08", "authors_parsed": [["Tits", "No\u00e9", ""]]}, {"id": "1907.02786", "submitter": "Kenjiro Kondo", "authors": "Kenjiro Kondo, Akihiko Ishikawa, Masashi Kimura", "title": "Sequence to Sequence with Attention for Influenza Prevalence Prediction\n  using Google Trends", "comments": "7 pages, ICCBB2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Early prediction of the prevalence of influenza reduces its impact. Various\nstudies have been conducted to predict the number of influenza-infected people.\nHowever, these studies are not highly accurate especially in the distant future\nsuch as over one month. To deal with this problem, we investigate the sequence\nto sequence (Seq2Seq) with attention model using Google Trends data to assess\nand predict the number of influenza-infected people over the course of multiple\nweeks. Google Trends data help to compensate the dark figures including the\nstatistics and improve the prediction accuracy. We demonstrate that the\nattention mechanism is highly effective to improve prediction accuracy and\nachieves state-of-the art results, with a Pearson correlation and\nroot-mean-square error of 0.996 and 0.67, respectively. However, the prediction\naccuracy of the peak of influenza epidemic is not sufficient, and further\ninvestigation is needed to overcome this problem.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jul 2019 08:14:05 GMT"}], "update_date": "2019-07-08", "authors_parsed": [["Kondo", "Kenjiro", ""], ["Ishikawa", "Akihiko", ""], ["Kimura", "Masashi", ""]]}, {"id": "1907.02788", "submitter": "Huaiyu Li", "authors": "Huaiyu Li, Weiming Dong, Bao-Gang Hu", "title": "Incremental Concept Learning via Online Generative Memory Recall", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability to learn more and more concepts over time from incrementally\narriving data is essential for the development of a life-long learning system.\nHowever, deep neural networks often suffer from forgetting previously learned\nconcepts when continually learning new concepts, which is known as catastrophic\nforgetting problem. The main reason for catastrophic forgetting is that the\npast concept data is not available and neural weights are changed during\nincrementally learning new concepts. In this paper, we propose a\npseudo-rehearsal based class incremental learning approach to make neural\nnetworks capable of continually learning new concepts. We use a conditional\ngenerative adversarial network to consolidate old concepts memory and recall\npseudo samples during learning new concepts and a balanced online memory recall\nstrategy is to maximally maintain old memories. And we design a comprehensible\nincremental concept learning network as well as a concept contrastive loss to\nalleviate the magnitude of neural weights change. We evaluate the proposed\napproach on MNIST, Fashion-MNIST and SVHN datasets and compare with other\nrehearsal based approaches. The extensive experiments demonstrate the\neffectiveness of our approach.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jul 2019 12:13:46 GMT"}], "update_date": "2019-07-08", "authors_parsed": [["Li", "Huaiyu", ""], ["Dong", "Weiming", ""], ["Hu", "Bao-Gang", ""]]}, {"id": "1907.02796", "submitter": "David Zimmerer", "authors": "David Zimmerer, Fabian Isensee, Jens Petersen, Simon Kohl, Klaus\n  Maier-Hein", "title": "Unsupervised Anomaly Localization using Variational Auto-Encoders", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An assumption-free automatic check of medical images for potentially overseen\nanomalies would be a valuable assistance for a radiologist. Deep learning and\nespecially Variational Auto-Encoders (VAEs) have shown great potential in the\nunsupervised learning of data distributions. In principle, this allows for such\na check and even the localization of parts in the image that are most\nsuspicious. Currently, however, the reconstruction-based localization by design\nrequires adjusting the model architecture to the specific problem looked at\nduring evaluation. This contradicts the principle of building assumption-free\nmodels. We propose complementing the localization part with a term derived from\nthe Kullback-Leibler (KL)-divergence. For validation, we perform a series of\nexperiments on FashionMNIST as well as on a medical task including >1000\nhealthy and >250 brain tumor patients. Results show that the proposed formalism\noutperforms the state of the art VAE-based localization of anomalies across\nmany hyperparameter settings and also shows a competitive max performance.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jul 2019 13:03:29 GMT"}, {"version": "v2", "created": "Thu, 11 Jul 2019 09:55:21 GMT"}], "update_date": "2019-07-12", "authors_parsed": [["Zimmerer", "David", ""], ["Isensee", "Fabian", ""], ["Petersen", "Jens", ""], ["Kohl", "Simon", ""], ["Maier-Hein", "Klaus", ""]]}, {"id": "1907.02797", "submitter": "Andrea Polonioli PhD", "authors": "Jacopo Tagliabue, Lucas Lacasa, Ciro Greco, Mattia Pavoni and Andrea\n  Polonioli", "title": "Predicting e-commerce customer conversion from minimal temporal patterns\n  on symbolized clickstream trajectories", "comments": "arXiv admin note: substantial text overlap with arXiv:1907.00400", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowing if a user is a buyer or window shopper solely based on clickstream\ndata is of crucial importance for e-commerce platforms seeking to implement\nreal-time accurate NBA (next best action) policies. However, due to the low\nfrequency of conversion events and the noisiness of browsing data, classifying\nuser sessions is very challenging. In this paper, we address the clickstream\nclassification problem in the eCommerce industry and present three major\ncontributions to the burgeoning field of AI-for-retail: first, we collected,\nnormalized and prepared a novel dataset of live shopping sessions from a major\nEuropean e-commerce website; second, we use the dataset to test in a controlled\nenvironment strong baselines and SOTA models from the literature; finally, we\npropose a new discriminative neural model that outperforms neural architectures\nrecently proposed at Rakuten labs.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jul 2019 16:37:48 GMT"}, {"version": "v2", "created": "Sat, 14 Mar 2020 14:25:49 GMT"}], "update_date": "2020-03-17", "authors_parsed": [["Tagliabue", "Jacopo", ""], ["Lacasa", "Lucas", ""], ["Greco", "Ciro", ""], ["Pavoni", "Mattia", ""], ["Polonioli", "Andrea", ""]]}, {"id": "1907.02811", "submitter": "Esra Akbas", "authors": "Esra Akbas and Mehmet Aktas", "title": "Network Embedding: on Compression and Learning", "comments": "arXiv admin note: text overlap with arXiv:1706.07845,\n  arXiv:1607.00653 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recently, network embedding that encodes structural information of graphs\ninto a vector space has become popular for network analysis. Although recent\nmethods show promising performance for various applications, the huge sizes of\ngraphs may hinder a direct application of existing network embedding method to\nthem. This paper presents NECL, a novel efficient Network Embedding method with\ntwo goals. 1) Is there an ideal Compression of a network? 2) Will the\ncompression of a network significantly boost the representation Learning of the\nnetwork? For the first problem, we propose a neighborhood similarity based\ngraph compression method that compresses the input graph to get a smaller graph\nwithout losing any/much information about the global structure of the graph and\nthe local proximity of the vertices in the graph. For the second problem, we\nuse the compressed graph for network embedding instead of the original large\ngraph to bring down the embedding cost. NECL is a general meta-strategy to\nimprove the efficiency of all of the state-of-the-art graph embedding\nalgorithms based on random walks, including DeepWalk and Node2vec, without\nlosing their effectiveness. Extensive experiments on large real-world networks\nvalidate the efficiency of NECL method that yields an average improvement of 23\n- 57% embedding time, including walking and learning time without decreasing\nclassification accuracy as evaluated on single and multi-label classification\ntasks on real-world graphs such as DBLP, BlogCatalog, Cora and Wiki.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jul 2019 13:22:02 GMT"}, {"version": "v2", "created": "Mon, 8 Jul 2019 17:18:21 GMT"}], "update_date": "2019-07-18", "authors_parsed": [["Akbas", "Esra", ""], ["Aktas", "Mehmet", ""]]}, {"id": "1907.02818", "submitter": "Jan H\\\"uckelheim", "authors": "Jan H\\\"uckelheim, Navjot Kukreja, Sri Hari Krishna Narayanan, Fabio\n  Luporini, Gerard Gorman, Paul Hovland", "title": "Automatic Differentiation for Adjoint Stencil Loops", "comments": "ICPP 2019", "journal-ref": null, "doi": "10.1145/3337821.3337906", "report-no": null, "categories": "cs.DC cs.LG cs.PF cs.SC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stencil loops are a common motif in computations including convolutional\nneural networks, structured-mesh solvers for partial differential equations,\nand image processing. Stencil loops are easy to parallelise, and their fast\nexecution is aided by compilers, libraries, and domain-specific languages.\nReverse-mode automatic differentiation, also known as algorithmic\ndifferentiation, autodiff, adjoint differentiation, or back-propagation, is\nsometimes used to obtain gradients of programs that contain stencil loops.\nUnfortunately, conventional automatic differentiation results in a memory\naccess pattern that is not stencil-like and not easily parallelisable.\n  In this paper we present a novel combination of automatic differentiation and\nloop transformations that preserves the structure and memory access pattern of\nstencil loops, while computing fully consistent derivatives. The generated\nloops can be parallelised and optimised for performance in the same way and\nusing the same tools as the original computation. We have implemented this new\ntechnique in the Python tool PerforAD, which we release with this paper along\nwith test cases derived from seismic imaging and computational fluid dynamics\napplications.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jul 2019 13:33:34 GMT"}], "update_date": "2019-07-08", "authors_parsed": [["H\u00fcckelheim", "Jan", ""], ["Kukreja", "Navjot", ""], ["Narayanan", "Sri Hari Krishna", ""], ["Luporini", "Fabio", ""], ["Gorman", "Gerard", ""], ["Hovland", "Paul", ""]]}, {"id": "1907.02821", "submitter": "Lia Morra", "authors": "Lia Morra and Fabrizio Lamberti", "title": "Benchmarking unsupervised near-duplicate image detection", "comments": "Accepted for publication in Expert Systems with Applications", "journal-ref": "Expert Systems with Applications, online first, 2019", "doi": "10.1016/j.eswa.2019.05.002", "report-no": null, "categories": "cs.CV cs.CR cs.LG cs.MM stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Unsupervised near-duplicate detection has many practical applications ranging\nfrom social media analysis and web-scale retrieval, to digital image forensics.\nIt entails running a threshold-limited query on a set of descriptors extracted\nfrom the images, with the goal of identifying all possible near-duplicates,\nwhile limiting the false positives due to visually similar images. Since the\nrate of false alarms grows with the dataset size, a very high specificity is\nthus required, up to $1 - 10^{-9}$ for realistic use cases; this important\nrequirement, however, is often overlooked in literature. In recent years,\ndescriptors based on deep convolutional neural networks have matched or\nsurpassed traditional feature extraction methods in content-based image\nretrieval tasks. To the best of our knowledge, ours is the first attempt to\nestablish the performance range of deep learning-based descriptors for\nunsupervised near-duplicate detection on a range of datasets, encompassing a\nbroad spectrum of near-duplicate definitions. We leverage both established and\nnew benchmarks, such as the Mir-Flick Near-Duplicate (MFND) dataset, in which a\nknown ground truth is provided for all possible pairs over a general, large\nscale image collection. To compare the specificity of different descriptors, we\nreduce the problem of unsupervised detection to that of binary classification\nof near-duplicate vs. not-near-duplicate images. The latter can be conveniently\ncharacterized using Receiver Operating Curve (ROC). Our findings in general\nfavor the choice of fine-tuning deep convolutional networks, as opposed to\nusing off-the-shelf features, but differences at high specificity settings\ndepend on the dataset and are often small. The best performance was observed on\nthe MFND benchmark, achieving 96\\% sensitivity at a false positive rate of\n$1.43 \\times 10^{-6}$.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jul 2019 09:08:47 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Morra", "Lia", ""], ["Lamberti", "Fabrizio", ""]]}, {"id": "1907.02822", "submitter": "Pavlos Mitsoulis-Ntompos", "authors": "Meisam Hejazinia, Pavlos Mitsoulis-Ntompos, Serena Zhang", "title": "Deep Personalized Re-targeting", "comments": "arXiv admin note: text overlap with arXiv:1906.11336", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predicting booking probability and value at the traveler level plays a\ncentral role in computational advertising for massive two-sided vacation rental\nmarketplaces. These marketplaces host millions of travelers with long shopping\ncycles, spending a lot of time in the discovery phase. The footprint of the\ntravelers in their discovery is a useful data source to help these marketplaces\nto predict shopping probability and value. However, there is no\none-size-fits-all solution for this purpose. In this paper, we propose a hybrid\nmodel that infuses deep and shallow neural network embeddings into a gradient\nboosting tree model. This approach allows the latent preferences of millions of\ntravelers to be automatically learned from sparse session logs. In addition, we\npresent the architecture that we deployed into our production system. We find\nthat there is a pragmatic sweet spot between expensive complex deep neural\nnetworks and simple shallow neural networks that can increase the prediction\nperformance of a model by seven percent, based on offline analysis.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jul 2019 11:28:23 GMT"}, {"version": "v2", "created": "Wed, 10 Jul 2019 11:09:01 GMT"}], "update_date": "2019-07-11", "authors_parsed": [["Hejazinia", "Meisam", ""], ["Mitsoulis-Ntompos", "Pavlos", ""], ["Zhang", "Serena", ""]]}, {"id": "1907.02844", "submitter": "Joshua Vogelstein", "authors": "Meghana Madhyastha, Percy Li, James Browne, Veronika Strnadova-Neeley,\n  Carey E. Priebe, Randal Burns, Joshua T. Vogelstein", "title": "Geodesic Learning via Unsupervised Decision Forests", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IR cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Geodesic distance is the shortest path between two points in a Riemannian\nmanifold. Manifold learning algorithms, such as Isomap, seek to learn a\nmanifold that preserves geodesic distances. However, such methods operate on\nthe ambient dimensionality, and are therefore fragile to noise dimensions. We\ndeveloped an unsupervised random forest method (URerF) to approximately learn\ngeodesic distances in linear and nonlinear manifolds with noise. URerF operates\non low-dimensional sparse linear combinations of features, rather than the full\nobserved dimensionality. To choose the optimal split in a computationally\nefficient fashion, we developed a fast Bayesian Information Criterion statistic\nfor Gaussian mixture models. We introduce geodesic precision-recall curves\nwhich quantify performance relative to the true latent manifold. Empirical\nresults on simulated and real data demonstrate that URerF is robust to\nhigh-dimensional noise, where as other methods, such as Isomap, UMAP, and\nFLANN, quickly deteriorate in such settings. In particular, URerF is able to\nestimate geodesic distances on a real connectome dataset better than other\napproaches.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jul 2019 14:15:07 GMT"}], "update_date": "2019-07-08", "authors_parsed": [["Madhyastha", "Meghana", ""], ["Li", "Percy", ""], ["Browne", "James", ""], ["Strnadova-Neeley", "Veronika", ""], ["Priebe", "Carey E.", ""], ["Burns", "Randal", ""], ["Vogelstein", "Joshua T.", ""]]}, {"id": "1907.02848", "submitter": "Chinnadhurai Sankar", "authors": "Chinnadhurai Sankar, Sujith Ravi", "title": "Deep Reinforcement Learning For Modeling Chit-Chat Dialog With Discrete\n  Attributes", "comments": "SIGDIAL 2019 - BEST PAPER AWARD", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Open domain dialog systems face the challenge of being repetitive and\nproducing generic responses. In this paper, we demonstrate that by conditioning\nthe response generation on interpretable discrete dialog attributes and\ncomposed attributes, it helps improve the model perplexity and results in\ndiverse and interesting non-redundant responses. We propose to formulate the\ndialog attribute prediction as a reinforcement learning (RL) problem and use\npolicy gradients methods to optimize utterance generation using long-term\nrewards. Unlike existing RL approaches which formulate the token prediction as\na policy, our method reduces the complexity of the policy optimization by\nlimiting the action space to dialog attributes, thereby making the policy\noptimization more practical and sample efficient. We demonstrate this with\nexperimental and human evaluations.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jul 2019 14:19:15 GMT"}, {"version": "v2", "created": "Sat, 14 Sep 2019 17:03:04 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Sankar", "Chinnadhurai", ""], ["Ravi", "Sujith", ""]]}, {"id": "1907.02874", "submitter": "Oliver Richter", "authors": "Timo Bram, Gino Brunner, Oliver Richter, Roger Wattenhofer", "title": "Attentive Multi-Task Deep Reinforcement Learning", "comments": "Accepted as conference paper at ECML PKDD 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sharing knowledge between tasks is vital for efficient learning in a\nmulti-task setting. However, most research so far has focused on the easier\ncase where knowledge transfer is not harmful, i.e., where knowledge from one\ntask cannot negatively impact the performance on another task. In contrast, we\npresent an approach to multi-task deep reinforcement learning based on\nattention that does not require any a-priori assumptions about the\nrelationships between tasks. Our attention network automatically groups task\nknowledge into sub-networks on a state level granularity. It thereby achieves\npositive knowledge transfer if possible, and avoids negative transfer in cases\nwhere tasks interfere. We test our algorithm against two state-of-the-art\nmulti-task/transfer learning approaches and show comparable or superior\nperformance while requiring fewer network parameters.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jul 2019 14:59:41 GMT"}], "update_date": "2019-07-08", "authors_parsed": [["Bram", "Timo", ""], ["Brunner", "Gino", ""], ["Richter", "Oliver", ""], ["Wattenhofer", "Roger", ""]]}, {"id": "1907.02877", "submitter": "Sumit Raurale", "authors": "Sumit A. Raurale, Saif Nalband, Geraldine B. Boylan, Gordon Lightbody\n  and John M. O'Toole", "title": "Suitability of an inter-burst detection method for grading\n  hypoxic-ischemic encephalopathy in newborn EEG", "comments": "4 pages, to be appearing in upcoming 2019 EMBC conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Electroencephalography (EEG) is an important clinical tool for grading injury\ncaused by lack of oxygen or blood to the brain during birth. Characteristics of\nlow-voltage waveforms, known as inter-bursts, are related to different grades\nof injury. This study assesses the suitability of an existing inter-burst\ndetection method, developed from preterm infants born <30 weeks of gestational\nage, to detect inter-bursts in term infants. Different features from the\ntemporal organisation of the inter-bursts are combined using a multi-layer\nperceptron (MLP) machine learning algorithm to classify four grades of injury\nin the EEG. We find that the best performing feature, percentage of\ninter-bursts, has an accuracy of 59.3%. Combining this with the maximum\nduration of inter-bursts in the MLP produces a testing accuracy of 77.8%, with\nsimilar performance to existing multi-feature methods. These results validate\nthe use of the preterm detection method in term EEG and show how simple\nmeasures of the inter-burst interval can be used to classify different grades\nof injury.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jul 2019 15:02:28 GMT"}], "update_date": "2019-07-08", "authors_parsed": [["Raurale", "Sumit A.", ""], ["Nalband", "Saif", ""], ["Boylan", "Geraldine B.", ""], ["Lightbody", "Gordon", ""], ["O'Toole", "John M.", ""]]}, {"id": "1907.02882", "submitter": "Micha Pfeiffer", "authors": "Micha Pfeiffer, Isabel Funke, Maria R. Robu, Sebastian Bodenstedt,\n  Leon Strenger, Sandy Engelhardt, Tobias Ro{\\ss}, Matthew J. Clarkson,\n  Kurinchi Gurusamy, Brian R. Davidson, Lena Maier-Hein, Carina Riediger, Thilo\n  Welsch, J\\\"urgen Weitz and Stefanie Speidel", "title": "Generating large labeled data sets for laparoscopic image processing\n  tasks using unpaired image-to-image translation", "comments": "Accepted at MICCAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In the medical domain, the lack of large training data sets and benchmarks is\noften a limiting factor for training deep neural networks. In contrast to\nexpensive manual labeling, computer simulations can generate large and fully\nlabeled data sets with a minimum of manual effort. However, models that are\ntrained on simulated data usually do not translate well to real scenarios. To\nbridge the domain gap between simulated and real laparoscopic images, we\nexploit recent advances in unpaired image-to-image translation. We extent an\nimage-to-image translation method to generate a diverse multitude of\nrealistically looking synthetic images based on images from a simple\nlaparoscopy simulation. By incorporating means to ensure that the image content\nis preserved during the translation process, we ensure that the labels given\nfor the simulated images remain valid for their realistically looking\ntranslations. This way, we are able to generate a large, fully labeled\nsynthetic data set of laparoscopic images with realistic appearance. We show\nthat this data set can be used to train models for the task of liver\nsegmentation of laparoscopic images. We achieve average dice scores of up to\n0.89 in some patients without manually labeling a single laparoscopic image and\nshow that using our synthetic data to pre-train models can greatly improve\ntheir performance. The synthetic data set will be made publicly available,\nfully labeled with segmentation maps, depth maps, normal maps, and positions of\ntools and camera (http://opencas.dkfz.de/image2image).\n", "versions": [{"version": "v1", "created": "Fri, 5 Jul 2019 15:10:20 GMT"}], "update_date": "2019-07-08", "authors_parsed": [["Pfeiffer", "Micha", ""], ["Funke", "Isabel", ""], ["Robu", "Maria R.", ""], ["Bodenstedt", "Sebastian", ""], ["Strenger", "Leon", ""], ["Engelhardt", "Sandy", ""], ["Ro\u00df", "Tobias", ""], ["Clarkson", "Matthew J.", ""], ["Gurusamy", "Kurinchi", ""], ["Davidson", "Brian R.", ""], ["Maier-Hein", "Lena", ""], ["Riediger", "Carina", ""], ["Welsch", "Thilo", ""], ["Weitz", "J\u00fcrgen", ""], ["Speidel", "Stefanie", ""]]}, {"id": "1907.02884", "submitter": "Giuseppe Castellucci", "authors": "Giuseppe Castellucci, Valentina Bellomaria, Andrea Favalli, Raniero\n  Romagnoli", "title": "Multi-lingual Intent Detection and Slot Filling in a Joint BERT-based\n  Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Intent Detection and Slot Filling are two pillar tasks in Spoken Natural\nLanguage Understanding. Common approaches adopt joint Deep Learning\narchitectures in attention-based recurrent frameworks. In this work, we aim at\nexploiting the success of \"recurrence-less\" models for these tasks. We\nintroduce Bert-Joint, i.e., a multi-lingual joint text classification and\nsequence labeling framework. The experimental evaluation over two well-known\nEnglish benchmarks demonstrates the strong performances that can be obtained\nwith this model, even when few annotated data is available. Moreover, we\nannotated a new dataset for the Italian language, and we observed similar\nperformances without the need for changing the model.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jul 2019 15:11:29 GMT"}], "update_date": "2019-07-08", "authors_parsed": [["Castellucci", "Giuseppe", ""], ["Bellomaria", "Valentina", ""], ["Favalli", "Andrea", ""], ["Romagnoli", "Raniero", ""]]}, {"id": "1907.02889", "submitter": "A\\'ecio Solano Rodrigues Santos", "authors": "A\\'ecio Santos, Sonia Castelo, Cristian Felix, Jorge Piazentin Ono,\n  Bowen Yu, Sungsoo Hong, Cl\\'audio T. Silva, Enrico Bertini, Juliana Freire", "title": "Visus: An Interactive System for Automatic Machine Learning Model\n  Building and Curation", "comments": "Accepted for publication in the 2019 Workshop on Human-In-the-Loop\n  Data Analytics (HILDA'19), co-located with SIGMOD 2019", "journal-ref": null, "doi": "10.1145/3328519.3329134", "report-no": null, "categories": "cs.LG cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While the demand for machine learning (ML) applications is booming, there is\na scarcity of data scientists capable of building such models. Automatic\nmachine learning (AutoML) approaches have been proposed that help with this\nproblem by synthesizing end-to-end ML data processing pipelines. However, these\nfollow a best-effort approach and a user in the loop is necessary to curate and\nrefine the derived pipelines. Since domain experts often have little or no\nexpertise in machine learning, easy-to-use interactive interfaces that guide\nthem throughout the model building process are necessary. In this paper, we\npresent Visus, a system designed to support the model building process and\ncuration of ML data processing pipelines generated by AutoML systems. We\ndescribe the framework used to ground our design choices and a usage scenario\nenabled by Visus. Finally, we discuss the feedback received in user testing\nsessions with domain experts.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jul 2019 15:21:51 GMT"}], "update_date": "2019-07-08", "authors_parsed": [["Santos", "A\u00e9cio", ""], ["Castelo", "Sonia", ""], ["Felix", "Cristian", ""], ["Ono", "Jorge Piazentin", ""], ["Yu", "Bowen", ""], ["Hong", "Sungsoo", ""], ["Silva", "Cl\u00e1udio T.", ""], ["Bertini", "Enrico", ""], ["Freire", "Juliana", ""]]}, {"id": "1907.02893", "submitter": "Martin Arjovsky", "authors": "Martin Arjovsky, L\\'eon Bottou, Ishaan Gulrajani, David Lopez-Paz", "title": "Invariant Risk Minimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce Invariant Risk Minimization (IRM), a learning paradigm to\nestimate invariant correlations across multiple training distributions. To\nachieve this goal, IRM learns a data representation such that the optimal\nclassifier, on top of that data representation, matches for all training\ndistributions. Through theory and experiments, we show how the invariances\nlearned by IRM relate to the causal structures governing the data and enable\nout-of-distribution generalization.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jul 2019 15:26:26 GMT"}, {"version": "v2", "created": "Sun, 1 Sep 2019 09:17:10 GMT"}, {"version": "v3", "created": "Fri, 27 Mar 2020 19:07:58 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Arjovsky", "Martin", ""], ["Bottou", "L\u00e9on", ""], ["Gulrajani", "Ishaan", ""], ["Lopez-Paz", "David", ""]]}, {"id": "1907.02907", "submitter": "Jianmei Luo", "authors": "Jianmei Luo, ChandraVyas Annakula, Aruna Sai Kannamareddy, Jasjeet S.\n  Sekhon, William Henry Hsu, Michael Higgins", "title": "Hybridized Threshold Clustering for Massive Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As the size $n$ of datasets become massive, many commonly-used clustering\nalgorithms (for example, $k$-means or hierarchical agglomerative clustering\n(HAC) require prohibitive computational cost and memory. In this paper, we\npropose a solution to these clustering problems by extending threshold\nclustering (TC) to problems of instance selection. TC is a recently developed\nclustering algorithm designed to partition data into many small clusters in\nlinearithmic time (on average). Our proposed clustering method is as follows.\nFirst, TC is performed and clusters are reduced into single \"prototype\" points.\nThen, TC is applied repeatedly on these prototype points until sufficient data\nreduction has been obtained. Finally, a more sophisticated clustering algorithm\nis applied to the reduced prototype points, thereby obtaining a clustering on\nall $n$ data points. This entire procedure for clustering is called iterative\nhybridized threshold clustering (IHTC). Through simulation results and by\napplying our methodology on several real datasets, we show that IHTC combined\nwith $k$-means or HAC substantially reduces the run time and memory usage of\nthe original clustering algorithms while still preserving their performance.\nAdditionally, IHTC helps prevent singular data points from being overfit by\nclustering algorithms.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jul 2019 16:10:57 GMT"}], "update_date": "2019-07-08", "authors_parsed": [["Luo", "Jianmei", ""], ["Annakula", "ChandraVyas", ""], ["Kannamareddy", "Aruna Sai", ""], ["Sekhon", "Jasjeet S.", ""], ["Hsu", "William Henry", ""], ["Higgins", "Michael", ""]]}, {"id": "1907.02908", "submitter": "Matteo Hessel", "authors": "Matteo Hessel, Hado van Hasselt, Joseph Modayil, David Silver", "title": "On Inductive Biases in Deep Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many deep reinforcement learning algorithms contain inductive biases that\nsculpt the agent's objective and its interface to the environment. These\ninductive biases can take many forms, including domain knowledge and pretuned\nhyper-parameters. In general, there is a trade-off between generality and\nperformance when algorithms use such biases. Stronger biases can lead to faster\nlearning, but weaker biases can potentially lead to more general algorithms.\nThis trade-off is important because inductive biases are not free; substantial\neffort may be required to obtain relevant domain knowledge or to tune\nhyper-parameters effectively. In this paper, we re-examine several\ndomain-specific components that bias the objective and the environmental\ninterface of common deep reinforcement learning agents. We investigated whether\nthe performance deteriorates when these components are replaced with adaptive\nsolutions from the literature. In our experiments, performance sometimes\ndecreased with the adaptive components, as one might expect when comparing to\ncomponents crafted for the domain, but sometimes the adaptive components\nperformed better. We investigated the main benefit of having fewer\ndomain-specific components, by comparing the learning performance of the two\nsystems on a different set of continuous control problems, without additional\ntuning of either system. As hypothesized, the system with adaptive components\nperformed better on many of the new tasks.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jul 2019 16:14:55 GMT"}], "update_date": "2019-07-08", "authors_parsed": [["Hessel", "Matteo", ""], ["van Hasselt", "Hado", ""], ["Modayil", "Joseph", ""], ["Silver", "David", ""]]}, {"id": "1907.02911", "submitter": "Berfin Simsek Mrs.", "authors": "Johanni Brea, Berfin Simsek, Bernd Illing and Wulfram Gerstner", "title": "Weight-space symmetry in deep networks gives rise to permutation\n  saddles, connected by equal-loss valleys across the loss landscape", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The permutation symmetry of neurons in each layer of a deep neural network\ngives rise not only to multiple equivalent global minima of the loss function,\nbut also to first-order saddle points located on the path between the global\nminima. In a network of $d-1$ hidden layers with $n_k$ neurons in layers $k =\n1, \\ldots, d$, we construct smooth paths between equivalent global minima that\nlead through a `permutation point' where the input and output weight vectors of\ntwo neurons in the same hidden layer $k$ collide and interchange. We show that\nsuch permutation points are critical points with at least $n_{k+1}$ vanishing\neigenvalues of the Hessian matrix of second derivatives indicating a local\nplateau of the loss function. We find that a permutation point for the exchange\nof neurons $i$ and $j$ transits into a flat valley (or generally, an extended\nplateau of $n_{k+1}$ flat dimensions) that enables all $n_k!$ permutations of\nneurons in a given layer $k$ at the same loss value. Moreover, we introduce\nhigh-order permutation points by exploiting the recursive structure in neural\nnetwork functions, and find that the number of $K^{\\text{th}}$-order\npermutation points is at least by a factor\n$\\sum_{k=1}^{d-1}\\frac{1}{2!^K}{n_k-K \\choose K}$ larger than the (already\nhuge) number of equivalent global minima. In two tasks, we illustrate\nnumerically that some of the permutation points correspond to first-order\nsaddles (`permutation saddles'): first, in a toy network with a single hidden\nlayer on a function approximation task and, second, in a multilayer network on\nthe MNIST task. Our geometric approach yields a lower bound on the number of\ncritical points generated by weight-space symmetries and provides a simple\nintuitive link between previous mathematical results and numerical\nobservations.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jul 2019 16:17:01 GMT"}], "update_date": "2019-07-08", "authors_parsed": [["Brea", "Johanni", ""], ["Simsek", "Berfin", ""], ["Illing", "Bernd", ""], ["Gerstner", "Wulfram", ""]]}, {"id": "1907.02929", "submitter": "S\\'ebastien Bougleux", "authors": "Nicolas Boria, David B. Blumenthal, S\\'ebastien Bougleux and Luc Brun", "title": "Improved local search for graph edit distance", "comments": null, "journal-ref": "Pattern Recognition Letters 129, pages 19-25, 2020", "doi": "10.1016/j.patrec.2019.10.028", "report-no": null, "categories": "cs.DS cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The graph edit distance (GED) measures the dissimilarity between two graphs\nas the minimal cost of a sequence of elementary operations transforming one\ngraph into another. This measure is fundamental in many areas such as\nstructural pattern recognition or classification. However, exactly computing\nGED is NP-hard. Among different classes of heuristic algorithms that were\nproposed to compute approximate solutions, local search based algorithms\nprovide the tightest upper bounds for GED. In this paper, we present K-REFINE\nand RANDPOST. K-REFINE generalizes and improves an existing local search\nalgorithm and performs particularly well on small graphs. RANDPOST is a general\nwarm start framework that stochastically generates promising initial solutions\nto be used by any local search based GED algorithm. It is particularly\nefficient on large graphs. An extensive empirical evaluation demonstrates that\nboth K-REFINE and RANDPOST perform excellently in practice.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jul 2019 16:52:40 GMT"}, {"version": "v2", "created": "Tue, 26 Nov 2019 11:55:25 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Boria", "Nicolas", ""], ["Blumenthal", "David B.", ""], ["Bougleux", "S\u00e9bastien", ""], ["Brun", "Luc", ""]]}, {"id": "1907.02936", "submitter": "Vasiliki Liakoni", "authors": "Vasiliki Liakoni, Alireza Modirshanechi, Wulfram Gerstner, Johanni\n  Brea", "title": "Learning in Volatile Environments with the Bayes Factor Surprise", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG q-bio.NC stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Surprise-based learning allows agents to rapidly adapt to non-stationary\nstochastic environments characterized by sudden changes. We show that exact\nBayesian inference in a hierarchical model gives rise to a surprise-modulated\ntrade-off between forgetting old observations and integrating them with the new\nones. The modulation depends on a probability ratio, which we call \"Bayes\nFactor Surprise\", that tests the prior belief against the current belief. We\ndemonstrate that in several existing approximate algorithms the Bayes Factor\nSurprise modulates the rate of adaptation to new observations. We derive three\nnovel surprised-based algorithms, one in the family of particle filters, one in\nthe family of variational learning, and the other in the family of message\npassing, that have constant scaling in observation sequence length and\nparticularly simple update dynamics for any distribution in the exponential\nfamily. Empirical results show that these surprise-based algorithms estimate\nparameters better than alternative approximate approaches and reach levels of\nperformance comparable to computationally more expensive algorithms. The Bayes\nFactor Surprise is related to but different from Shannon Surprise. In two\nhypothetical experiments, we make testable predictions for physiological\nindicators that dissociate the Bayes Factor Surprise from Shannon Surprise. The\ntheoretical insight of casting various approaches as surprise-based learning,\nas well as the proposed online algorithms, may be applied to the analysis of\nanimal and human behavior, and to reinforcement learning in non-stationary\nenvironments.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jul 2019 17:07:18 GMT"}, {"version": "v2", "created": "Fri, 28 Feb 2020 13:50:28 GMT"}, {"version": "v3", "created": "Wed, 23 Sep 2020 19:55:12 GMT"}], "update_date": "2020-09-25", "authors_parsed": [["Liakoni", "Vasiliki", ""], ["Modirshanechi", "Alireza", ""], ["Gerstner", "Wulfram", ""], ["Brea", "Johanni", ""]]}, {"id": "1907.02940", "submitter": "Jae Seo", "authors": "Jae Duk Seo", "title": "Visualizing Uncertainty and Saliency Maps of Deep Convolutional Neural\n  Networks for Medical Imaging Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning models are now used in many different industries, while in\ncertain domains safety is not a critical issue in the medical field it is a\nhuge concern. Not only, we want the models to generalize well but we also want\nto know the models confidence respect to its decision and which features matter\nthe most. Our team aims to develop a full pipeline in which not only displays\nthe uncertainty of the models decision but also, the saliency map to show which\nsets of pixels of the input image contribute most to the predictions.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jul 2019 17:23:04 GMT"}], "update_date": "2019-07-08", "authors_parsed": [["Seo", "Jae Duk", ""]]}, {"id": "1907.02942", "submitter": "Qianqian Yang", "authors": "Qianqian Yang, Mahdi Boloursaz Mashhadi and Deniz G\\\"und\\\"uz", "title": "Deep Convolutional Compression for Massive MIMO CSI Feedback", "comments": "Submitted to MLSP", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG eess.SP math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Coded caching provides significant gains over conventional uncoded caching by\ncreating multicasting opportunities among distinct requests.\n  Massive multiple-input multiple-output (MIMO) systems require downlink\nchannel state information (CSI) at the base station (BS) to better utilize the\navailable spatial diversity and multiplexing gains. However, in a frequency\ndivision duplex (FDD) massive MIMO system, the huge CSI feedback overhead\nbecomes restrictive and degrades the overall spectral efficiency. In this\npaper, we propose a deep learning based channel state matrix compression\nscheme, called DeepCMC, composed of convolutional layers followed by\nquantization and entropy coding blocks. In comparison with previous works, the\nmain contributions of DeepCMC are two-fold: i) DeepCMC is fully convolutional,\nand it can be used in a wide range of scenarios with various numbers of\nsub-channels and transmit antennas; ii) DeepCMC includes quantization and\nentropy coding blocks and minimizes a cost function that accounts for both the\nrate of compression and the reconstruction quality of the channel matrix at the\nBS. Simulation results demonstrate that DeepCMC significantly outperforms the\nstate of the art compression schemes in terms of the reconstruction quality of\nthe channel state matrix for the same compression rate, measured in bits per\nchannel dimension.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jul 2019 14:16:37 GMT"}], "update_date": "2019-07-08", "authors_parsed": [["Yang", "Qianqian", ""], ["Mashhadi", "Mahdi Boloursaz", ""], ["G\u00fcnd\u00fcz", "Deniz", ""]]}, {"id": "1907.02957", "submitter": "Yao Qin", "authors": "Yao Qin, Nicholas Frosst, Sara Sabour, Colin Raffel, Garrison Cottrell\n  and Geoffrey Hinton", "title": "Detecting and Diagnosing Adversarial Images with Class-Conditional\n  Capsule Reconstructions", "comments": null, "journal-ref": "ICLR 2020", "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial examples raise questions about whether neural network models are\nsensitive to the same visual features as humans. In this paper, we first detect\nadversarial examples or otherwise corrupted images based on a class-conditional\nreconstruction of the input. To specifically attack our detection mechanism, we\npropose the Reconstructive Attack which seeks both to cause a misclassification\nand a low reconstruction error. This reconstructive attack produces undetected\nadversarial examples but with much smaller success rate. Among all these\nattacks, we find that CapsNets always perform better than convolutional\nnetworks. Then, we diagnose the adversarial examples for CapsNets and find that\nthe success of the reconstructive attack is highly related to the visual\nsimilarity between the source and target class. Additionally, the resulting\nperturbations can cause the input image to appear visually more like the target\nclass and hence become non-adversarial. This suggests that CapsNets use\nfeatures that are more aligned with human perception and have the potential to\naddress the central issue raised by adversarial examples.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jul 2019 17:57:57 GMT"}, {"version": "v2", "created": "Tue, 18 Feb 2020 05:05:45 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Qin", "Yao", ""], ["Frosst", "Nicholas", ""], ["Sabour", "Sara", ""], ["Raffel", "Colin", ""], ["Cottrell", "Garrison", ""], ["Hinton", "Geoffrey", ""]]}, {"id": "1907.02959", "submitter": "Diego Valsesia", "authors": "Diego Valsesia, Enrico Magli", "title": "High-throughput Onboard Hyperspectral Image Compression with\n  Ground-based CNN Reconstruction", "comments": null, "journal-ref": null, "doi": "10.1109/TGRS.2019.2927434", "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Compression of hyperspectral images onboard of spacecrafts is a tradeoff\nbetween the limited computational resources and the ever-growing spatial and\nspectral resolution of the optical instruments. As such, it requires\nlow-complexity algorithms with good rate-distortion performance and high\nthroughput. In recent years, the Consultative Committee for Space Data Systems\n(CCSDS) has focused on lossless and near-lossless compression approaches based\non predictive coding, resulting in the recently published CCSDS 123.0-B-2\nrecommended standard. While the in-loop reconstruction of quantized prediction\nresiduals provides excellent rate-distortion performance for the near-lossless\noperating mode, it significantly constrains the achievable throughput due to\ndata dependencies. In this paper, we study the performance of a faster method\nbased on prequantization of the image followed by a lossless predictive\ncompressor. While this is well known to be suboptimal, one can exploit powerful\nsignal models to reconstruct the image at the ground segment, recovering part\nof the suboptimality. In particular, we show that convolutional neural networks\ncan be used for this task and that they can recover the whole SNR drop incurred\nat a bitrate of 2 bits per pixel.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jul 2019 17:59:25 GMT"}], "update_date": "2019-07-08", "authors_parsed": [["Valsesia", "Diego", ""], ["Magli", "Enrico", ""]]}, {"id": "1907.02987", "submitter": "Bing Li Dr.", "authors": "Zichen Fan and Ziru Li and Bing Li and Yiran Chen and Hai (Helen) Li", "title": "RED: A ReRAM-based Deconvolution Accelerator", "comments": "2019 Design, Automation & Test in Europe Conference & Exhibition\n  (DATE)", "journal-ref": null, "doi": "10.23919/DATE.2019.8715103", "report-no": null, "categories": "cs.ET cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deconvolution has been widespread in neural networks. For example, it is\nessential for performing unsupervised learning in generative adversarial\nnetworks or constructing fully convolutional networks for semantic\nsegmentation. Resistive RAM (ReRAM)-based processing-in-memory architecture has\nbeen widely explored in accelerating convolutional computation and demonstrates\ngood performance. Performing deconvolution on existing ReRAM-based accelerator\ndesigns, however, suffers from long latency and high energy consumption because\ndeconvolutional computation includes not only convolution but also extra add-on\noperations. To realize the more efficient execution for deconvolution, we\nanalyze its computation requirement and propose a ReRAM-based accelerator\ndesign, namely, RED. More specific, RED integrates two orthogonal methods, the\npixel-wise mapping scheme for reducing redundancy caused by zero-inserting\noperations and the zero-skipping data flow for increasing the computation\nparallelism and therefore improving performance. Experimental evaluations show\nthat compared to the state-of-the-art ReRAM-based accelerator, RED can speed up\noperation 3.69x~1.15x and reduce 8%~88.36% energy consumption.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jul 2019 18:08:22 GMT"}], "update_date": "2019-07-09", "authors_parsed": [["Fan", "Zichen", "", "Helen"], ["Li", "Ziru", "", "Helen"], ["Li", "Bing", "", "Helen"], ["Chen", "Yiran", "", "Helen"], ["Hai", "", "", "Helen"], ["Li", "", ""]]}, {"id": "1907.02994", "submitter": "Ruud JG van Sloun", "authors": "Ruud JG van Sloun and Regev Cohen and Yonina C Eldar", "title": "Deep learning in ultrasound imaging", "comments": "Accepted for publication in the Proceedings of the IEEE", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider deep learning strategies in ultrasound systems, from the\nfront-end to advanced applications. Our goal is to provide the reader with a\nbroad understanding of the possible impact of deep learning methodologies on\nmany aspects of ultrasound imaging. In particular, we discuss methods that lie\nat the interface of signal acquisition and machine learning, exploiting both\ndata structure (e.g. sparsity in some domain) and data dimensionality (big\ndata) already at the raw radio-frequency channel stage. As some examples, we\noutline efficient and effective deep learning solutions for adaptive\nbeamforming and adaptive spectral Doppler through artificial agents, learn\ncompressive encodings for color Doppler, and provide a framework for structured\nsignal recovery by learning fast approximations of iterative minimization\nproblems, with applications to clutter suppression and super-resolution\nultrasound. These emerging technologies may have considerable impact on\nultrasound imaging, showing promise across key components in the receive\nprocessing chain.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jul 2019 18:39:49 GMT"}, {"version": "v2", "created": "Mon, 29 Jul 2019 07:31:07 GMT"}], "update_date": "2019-07-30", "authors_parsed": [["van Sloun", "Ruud JG", ""], ["Cohen", "Regev", ""], ["Eldar", "Yonina C", ""]]}, {"id": "1907.02998", "submitter": "Srinivas Venkattaramanujam", "authors": "Srinivas Venkattaramanujam, Eric Crawford, Thang Doan and Doina Precup", "title": "Self-supervised Learning of Distance Functions for Goal-Conditioned\n  Reinforcement Learning", "comments": "Preprint; Under Review (updated)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Goal-conditioned policies are used in order to break down complex\nreinforcement learning (RL) problems by using subgoals, which can be defined\neither in state space or in a latent feature space. This can increase the\nefficiency of learning by using a curriculum, and also enables simultaneous\nlearning and generalization across goals. A crucial requirement of\ngoal-conditioned policies is to be able to determine whether the goal has been\nachieved. Having a notion of distance to a goal is thus a crucial component of\nthis approach. However, it is not straightforward to come up with an\nappropriate distance, and in some tasks, the goal space may not even be known a\npriori. In this work we learn a distance-to-goal estimate which is computed in\nterms of the number of actions that would need to be carried out in a\nself-supervised approach. Our method solves complex tasks without prior domain\nknowledge in the online setting in three different scenarios in the context of\ngoal-conditioned policies a) the goal space is the same as the state space b)\nthe goal space is given but an appropriate distance is unknown and c) the state\nspace is accessible, but only a subset of the state space represents desired\ngoals, and this subset is known a priori. We also propose a goal-generation\nmechanism as a secondary contribution.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jul 2019 19:00:14 GMT"}, {"version": "v2", "created": "Tue, 2 Jun 2020 15:42:15 GMT"}], "update_date": "2020-06-04", "authors_parsed": [["Venkattaramanujam", "Srinivas", ""], ["Crawford", "Eric", ""], ["Doan", "Thang", ""], ["Precup", "Doina", ""]]}, {"id": "1907.03010", "submitter": "Fabrice Daniel", "authors": "Fabrice Daniel", "title": "Financial Time Series Data Processing for Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article studies the financial time series data processing for machine\nlearning. It introduces the most frequent scaling methods, then compares the\nresulting stationarity and preservation of useful information for trend\nforecasting. It proposes an empirical test based on the capability to learn\nsimple data relationship with simple models. It also speaks about the data\nsplit method specific to time series, avoiding unwanted overfitting and\nproposes various labelling for classification and regression.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jul 2019 15:10:23 GMT"}], "update_date": "2019-07-09", "authors_parsed": [["Daniel", "Fabrice", ""]]}, {"id": "1907.03030", "submitter": "Xiaofeng Liu", "authors": "Xiaofeng Liu, B.V.K Vijaya Kumar, Chao Yang, Qingming Tang, Jane You", "title": "Dependency-aware Attention Control for Unconstrained Face Recognition\n  with Image Sets", "comments": "Fixed the unreadable code in CVF version. arXiv admin note: text\n  overlap with arXiv:1707.00130 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper targets the problem of image set-based face verification and\nidentification. Unlike traditional single media (an image or video) setting, we\nencounter a set of heterogeneous contents containing orderless images and\nvideos. The importance of each image is usually considered either equal or\nbased on their independent quality assessment. How to model the relationship of\norderless images within a set remains a challenge. We address this problem by\nformulating it as a Markov Decision Process (MDP) in the latent space.\nSpecifically, we first present a dependency-aware attention control (DAC)\nnetwork, which resorts to actor-critic reinforcement learning for sequential\nattention decision of each image embedding to fully exploit the rich\ncorrelation cues among the unordered images. Moreover, we introduce its\nsample-efficient variant with off-policy experience replay to speed up the\nlearning process. The pose-guided representation scheme can further boost the\nperformance at the extremes of the pose variation.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jul 2019 21:40:56 GMT"}], "update_date": "2019-08-06", "authors_parsed": [["Liu", "Xiaofeng", ""], ["Kumar", "B. V. K Vijaya", ""], ["Yang", "Chao", ""], ["Tang", "Qingming", ""], ["You", "Jane", ""]]}, {"id": "1907.03038", "submitter": "Joaquin Garcia-Alfaro", "authors": "Michel Barbeau and Joaquin Garcia-Alfaro", "title": "Faking and Discriminating the Navigation Data of a Micro Aerial Vehicle\n  Using Quantum Generative Adversarial Networks", "comments": "Accepted for publication in IEEE GLOBECOM 2019 Workshop on Quantum\n  Communications and Information Technology 2019 (fifth QCIT workshop of the\n  Emerging Technical Committee on Quantum Communications and Information\n  Technology, QCIT-ETC, cf. http://qcit.committees.comsoc.org/qcit19-workshop/)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that the Quantum Generative Adversarial Network (QGAN) paradigm can\nbe employed by an adversary to learn generating data that deceives the\nmonitoring of a Cyber-Physical System (CPS) and to perpetrate a covert attack.\nAs a test case, the ideas are elaborated considering the navigation data of a\nMicro Aerial Vehicle (MAV). A concrete QGAN design is proposed to generate fake\nMAV navigation data. Initially, the adversary is entirely ignorant about the\ndynamics of the CPS, the strength of the approach from the point of view of the\nbad guy. A design is also proposed to discriminate between genuine and fake MAV\nnavigation data. The designs combine classical optimization, qubit quantum\ncomputing and photonic quantum computing. Using the PennyLane software\nsimulation, they are evaluated over a classical computing platform. We assess\nthe learning time and accuracy of the navigation data generator and\ndiscriminator versus space complexity, i.e., the amount of quantum memory\nneeded to solve the problem.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jul 2019 22:40:16 GMT"}, {"version": "v2", "created": "Sat, 24 Aug 2019 12:08:21 GMT"}, {"version": "v3", "created": "Sun, 10 Nov 2019 19:20:25 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Barbeau", "Michel", ""], ["Garcia-Alfaro", "Joaquin", ""]]}, {"id": "1907.03039", "submitter": "Ilse Van Der Linden", "authors": "Ilse van der Linden, Hinda Haned and Evangelos Kanoulas", "title": "Global Aggregations of Local Explanations for Black Box models", "comments": "FACTS-IR: Fairness, Accountability, Confidentiality, Transparency,\n  and Safety - SIGIR 2019 Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The decision-making process of many state-of-the-art machine learning models\nis inherently inscrutable to the extent that it is impossible for a human to\ninterpret the model directly: they are black box models. This has led to a call\nfor research on explaining black box models, for which there are two main\napproaches. Global explanations that aim to explain a model's decision making\nprocess in general, and local explanations that aim to explain a single\nprediction. Since it remains challenging to establish fidelity to black box\nmodels in globally interpretable approximations, much attention is put on local\nexplanations. However, whether local explanations are able to reliably\nrepresent the black box model and provide useful insights remains an open\nquestion. We present Global Aggregations of Local Explanations (GALE) with the\nobjective to provide insights in a model's global decision making process.\nOverall, our results reveal that the choice of aggregation matters. We find\nthat the global importance introduced by Local Interpretable Model-agnostic\nExplanations (LIME) does not reliably represent the model's global behavior.\nOur proposed aggregations are better able to represent how features affect the\nmodel's predictions, and to provide global insights by identifying\ndistinguishing features.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jul 2019 22:40:36 GMT"}], "update_date": "2019-07-09", "authors_parsed": [["van der Linden", "Ilse", ""], ["Haned", "Hinda", ""], ["Kanoulas", "Evangelos", ""]]}, {"id": "1907.03043", "submitter": "Feng Yin", "authors": "Yuxin Zhao and Feng Yin and Fredrik Gunnarsson and Fredrik Hultkrantz", "title": "Gaussian Processes for Analyzing Positioned Trajectories in Sports", "comments": "31pages, 28 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Kernel-based machine learning approaches are gaining increasing interest for\nexploring and modeling large dataset in recent years. Gaussian process (GP) is\none example of such kernel-based approaches, which can provide very good\nperformance for nonlinear modeling problems. In this work, we first propose a\ngrey-box modeling approach to analyze the forces in cross country skiing races.\nTo be more precise, a disciplined set of kinetic motion model formulae is\ncombined with data-driven Gaussian process regression model, which accounts for\neverything unknown in the system. Then, a modeling approach is proposed to\nanalyze the kinetic flow of both individual and clusters of skiers. The\nproposed approaches can be generally applied to use cases where positioned\ntrajectories and kinetic measurements are available. The proposed approaches\nare evaluated using data collected from the Falun Nordic World Ski\nChampionships 2015, in particular the Men's cross country $4\\times10$ km relay.\nForces during the cross country skiing races are analyzed and compared.\nVelocity models for skiers at different competition stages are also evaluated.\nFinally, the comparisons between the grey-box and black-box approach are\ncarried out, where the grey-box approach can reduce the predictive uncertainty\nby $30\\%$ to $40\\%$.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jul 2019 23:00:44 GMT"}], "update_date": "2019-07-09", "authors_parsed": [["Zhao", "Yuxin", ""], ["Yin", "Feng", ""], ["Gunnarsson", "Fredrik", ""], ["Hultkrantz", "Fredrik", ""]]}, {"id": "1907.03046", "submitter": "Niels Justesen", "authors": "Niels Justesen, Miguel Gonzalez Duque, Daniel Cabarcas Jaramillo,\n  Jean-Baptiste Mouret, Sebastian Risi", "title": "Learning a Behavioral Repertoire from Demonstrations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Imitation Learning (IL) is a machine learning approach to learn a policy from\na dataset of demonstrations. IL can be useful to kick-start learning before\napplying reinforcement learning (RL) but it can also be useful on its own, e.g.\nto learn to imitate human players in video games. However, a major limitation\nof current IL approaches is that they learn only a single \"average\" policy\nbased on a dataset that possibly contains demonstrations of numerous different\ntypes of behaviors. In this paper, we propose a new approach called Behavioral\nRepertoire Imitation Learning (BRIL) that instead learns a repertoire of\nbehaviors from a set of demonstrations by augmenting the state-action pairs\nwith behavioral descriptions. The outcome of this approach is a single neural\nnetwork policy conditioned on a behavior description that can be precisely\nmodulated. We apply this approach to train a policy on 7,777 human replays to\nperform build-order planning in StarCraft II. Principal Component Analysis\n(PCA) is applied to construct a low-dimensional behavioral space from the\nhigh-dimensional army unit composition of each demonstration. The results\ndemonstrate that the learned policy can be effectively manipulated to express\ndistinct behaviors. Additionally, by applying the UCB1 algorithm, we are able\nto adapt the behavior of the policy - in-between games - to reach a performance\nbeyond that of the traditional IL baseline approach.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jul 2019 23:08:08 GMT"}], "update_date": "2019-07-09", "authors_parsed": [["Justesen", "Niels", ""], ["Duque", "Miguel Gonzalez", ""], ["Jaramillo", "Daniel Cabarcas", ""], ["Mouret", "Jean-Baptiste", ""], ["Risi", "Sebastian", ""]]}, {"id": "1907.03048", "submitter": "Yingtong Dou", "authors": "Yingtong Dou, Weijian Li, Zhirong Liu, Zhenhua Dong, Jiebo Luo, Philip\n  S. Yu", "title": "Uncovering Download Fraud Activities in Mobile App Markets", "comments": "Published as a conference paper in IEEE/ACM ASONAM 2019", "journal-ref": null, "doi": "10.1145/3341161.3345306", "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Download fraud is a prevalent threat in mobile App markets, where fraudsters\nmanipulate the number of downloads of Apps via various cheating approaches.\nPurchased fake downloads can mislead recommendation and search algorithms and\nfurther lead to bad user experience in App markets. In this paper, we\ninvestigate download fraud problem based on a company's App Market, which is\none of the most popular Android App markets. We release a honeypot App on the\nApp Market and purchase fake downloads from fraudster agents to track fraud\nactivities in the wild. Based on our interaction with the fraudsters, we\ncategorize download fraud activities into three types according to their\nintentions: boosting front end downloads, optimizing App search ranking, and\nenhancing user acquisition&retention rate. For the download fraud aimed at\noptimizing App search ranking, we select, evaluate, and validate several\nfeatures in identifying fake downloads based on billions of download data. To\nget a comprehensive understanding of download fraud, we further gather stances\nof App marketers, fraudster agencies, and market operators on download fraud.\nThe followed analysis and suggestions shed light on the ways to mitigate\ndownload fraud in App markets and other social platforms. To the best of our\nknowledge, this is the first work that investigates the download fraud problem\nin mobile App markets.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jul 2019 23:45:38 GMT"}, {"version": "v2", "created": "Tue, 17 Mar 2020 22:38:14 GMT"}], "update_date": "2020-03-19", "authors_parsed": [["Dou", "Yingtong", ""], ["Li", "Weijian", ""], ["Liu", "Zhirong", ""], ["Dong", "Zhenhua", ""], ["Luo", "Jiebo", ""], ["Yu", "Philip S.", ""]]}, {"id": "1907.03050", "submitter": "Soheil Khorram", "authors": "Soheil Khorram, Melvin G McInnis, Emily Mower Provost", "title": "Jointly Aligning and Predicting Continuous Emotion Annotations", "comments": "IEEE Transactions on Affective Computing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.HC eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Time-continuous dimensional descriptions of emotions (e.g., arousal, valence)\nallow researchers to characterize short-time changes and to capture long-term\ntrends in emotion expression. However, continuous emotion labels are generally\nnot synchronized with the input speech signal due to delays caused by\nreaction-time, which is inherent in human evaluations. To deal with this\nchallenge, we introduce a new convolutional neural network (multi-delay sinc\nnetwork) that is able to simultaneously align and predict labels in an\nend-to-end manner. The proposed network is a stack of convolutional layers\nfollowed by an aligner network that aligns the speech signal and emotion\nlabels. This network is implemented using a new convolutional layer that we\nintroduce, the delayed sinc layer. It is a time-shifted low-pass (sinc) filter\nthat uses a gradient-based algorithm to learn a single delay. Multiple delayed\nsinc layers can be used to compensate for a non-stationary delay that is a\nfunction of the acoustic space. We test the efficacy of this system on two\ncommon emotion datasets, RECOLA and SEWA, and show that this approach obtains\nstate-of-the-art speech-only results by learning time-varying delays while\npredicting dimensional descriptors of emotions.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jul 2019 23:49:49 GMT"}, {"version": "v2", "created": "Thu, 18 Jul 2019 22:40:43 GMT"}], "update_date": "2019-07-22", "authors_parsed": [["Khorram", "Soheil", ""], ["McInnis", "Melvin G", ""], ["Provost", "Emily Mower", ""]]}, {"id": "1907.03053", "submitter": "Ji Liu", "authors": "Yixuan Lin, Kaiqing Zhang, Zhuoran Yang, Zhaoran Wang, Tamer\n  Ba\\c{s}ar, Romeil Sandhu, Ji Liu", "title": "A Communication-Efficient Multi-Agent Actor-Critic Algorithm for\n  Distributed Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers a distributed reinforcement learning problem in which a\nnetwork of multiple agents aim to cooperatively maximize the globally averaged\nreturn through communication with only local neighbors. A randomized\ncommunication-efficient multi-agent actor-critic algorithm is proposed for\npossibly unidirectional communication relationships depicted by a directed\ngraph. It is shown that the algorithm can solve the problem for strongly\nconnected graphs by allowing each agent to transmit only two scalar-valued\nvariables at one time.\n", "versions": [{"version": "v1", "created": "Sat, 6 Jul 2019 00:20:50 GMT"}], "update_date": "2019-07-09", "authors_parsed": [["Lin", "Yixuan", ""], ["Zhang", "Kaiqing", ""], ["Yang", "Zhuoran", ""], ["Wang", "Zhaoran", ""], ["Ba\u015far", "Tamer", ""], ["Sandhu", "Romeil", ""], ["Liu", "Ji", ""]]}, {"id": "1907.03063", "submitter": "Qing Lyu", "authors": "Qing Lyu, Hongming Shan, Ge Wang", "title": "MRI Super-Resolution with Ensemble Learning and Complementary Priors", "comments": null, "journal-ref": "IEEE Transactions on Computational Imaging, vol. 6, pp. 615-624,\n  2020", "doi": "10.1109/TCI.2020.2964201", "report-no": null, "categories": "eess.IV cs.LG physics.med-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Magnetic resonance imaging (MRI) is a widely used medical imaging modality.\nHowever, due to the limitations in hardware, scan time, and throughput, it is\noften clinically challenging to obtain high-quality MR images. The\nsuper-resolution approach is potentially promising to improve MR image quality\nwithout any hardware upgrade. In this paper, we propose an ensemble learning\nand deep learning framework for MR image super-resolution. In our study, we\nfirst enlarged low resolution images using 5 commonly used super-resolution\nalgorithms and obtained differentially enlarged image datasets with\ncomplementary priors. Then, a generative adversarial network (GAN) is trained\nwith each dataset to generate super-resolution MR images. Finally, a\nconvolutional neural network is used for ensemble learning that synergizes the\noutputs of GANs into the final MR super-resolution images. According to our\nresults, the ensemble learning results outcome any one of GAN outputs. Compared\nwith some state-of-the-art deep learning-based super-resolution methods, our\napproach is advantageous in suppressing artifacts and keeping more image\ndetails.\n", "versions": [{"version": "v1", "created": "Sat, 6 Jul 2019 02:43:30 GMT"}], "update_date": "2020-02-20", "authors_parsed": [["Lyu", "Qing", ""], ["Shan", "Hongming", ""], ["Wang", "Ge", ""]]}, {"id": "1907.03064", "submitter": "Raghav Menon", "authors": "Astik Biswas, Raghav Menon, Ewald van der Westhuizen, Thomas Niesler", "title": "Improved low-resource Somali speech recognition by semi-supervised\n  acoustic and language model training", "comments": "5 pages, 6 Tables, 3 figures, 22 references (Accepted at Interspeech\n  2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present improvements in automatic speech recognition (ASR) for Somali, a\ncurrently extremely under-resourced language. This forms part of a continuing\nUnited Nations (UN) effort to employ ASR-based keyword spotting systems to\nsupport humanitarian relief programmes in rural Africa. Using just 1.57 hours\nof annotated speech data as a seed corpus, we increase the pool of training\ndata by applying semi-supervised training to 17.55 hours of untranscribed\nspeech. We make use of factorised time-delay neural networks (TDNN-F) for\nacoustic modelling, since these have recently been shown to be effective in\nresource-scarce situations. Three semi-supervised training passes were\nperformed, where the decoded output from each pass was used for acoustic model\ntraining in the subsequent pass. The automatic transcriptions from the best\nperforming pass were used for language model augmentation. To ensure the\nquality of automatic transcriptions, decoder confidence is used as a threshold.\nThe acoustic and language models obtained from the semi-supervised approach\nshow significant improvement in terms of WER and perplexity compared to the\nbaseline. Incorporating the automatically generated transcriptions yields a\n6.55\\% improvement in language model perplexity. The use of 17.55 hour of\nSomali acoustic data in semi-supervised training shows an improvement of 7.74\\%\nrelative over the baseline.\n", "versions": [{"version": "v1", "created": "Sat, 6 Jul 2019 02:53:10 GMT"}], "update_date": "2019-07-09", "authors_parsed": [["Biswas", "Astik", ""], ["Menon", "Raghav", ""], ["van der Westhuizen", "Ewald", ""], ["Niesler", "Thomas", ""]]}, {"id": "1907.03077", "submitter": "Shusen Liu", "authors": "Shusen Liu, Bhavya Kailkhura, Donald Loveland, Yong Han", "title": "Generative Counterfactual Introspection for Explainable Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we propose an introspection technique for deep neural networks\nthat relies on a generative model to instigate salient editing of the input\nimage for model interpretation. Such modification provides the fundamental\ninterventional operation that allows us to obtain answers to counterfactual\ninquiries, i.e., what meaningful change can be made to the input image in order\nto alter the prediction. We demonstrate how to reveal interesting properties of\nthe given classifiers by utilizing the proposed introspection approach on both\nthe MNIST and the CelebA dataset.\n", "versions": [{"version": "v1", "created": "Sat, 6 Jul 2019 04:30:13 GMT"}], "update_date": "2019-07-09", "authors_parsed": [["Liu", "Shusen", ""], ["Kailkhura", "Bhavya", ""], ["Loveland", "Donald", ""], ["Han", "Yong", ""]]}, {"id": "1907.03087", "submitter": "Ankit Pensia", "authors": "Ankit Pensia, Varun Jog, Po-Ling Loh", "title": "Estimating location parameters in entangled single-sample distributions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.IT cs.LG math.IT stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of estimating the common mean of independently\nsampled data, where samples are drawn in a possibly non-identical manner from\nsymmetric, unimodal distributions with a common mean. This generalizes the\nsetting of Gaussian mixture modeling, since the number of distinct mixture\ncomponents may diverge with the number of observations. We propose an estimator\nthat adapts to the level of heterogeneity in the data, achieving\nnear-optimality in both the i.i.d. setting and some heterogeneous settings,\nwhere the fraction of ``low-noise'' points is as small as $\\frac{\\log n}{n}$.\nOur estimator is a hybrid of the modal interval, shorth, and median estimators\nfrom classical statistics; however, the key technical contributions rely on\nnovel empirical process theory results that we derive for independent but\nnon-i.i.d. data. In the multivariate setting, we generalize our theory to mean\nestimation for mixtures of radially symmetric distributions, and derive minimax\nlower bounds on the expected error of any estimator that is agnostic to the\nscales of individual data points. Finally, we describe an extension of our\nestimators applicable to linear regression. In the multivariate mean estimation\nand regression settings, we present computationally feasible versions of our\nestimators that run in time polynomial in the number of data points.\n", "versions": [{"version": "v1", "created": "Sat, 6 Jul 2019 06:39:25 GMT"}], "update_date": "2019-07-09", "authors_parsed": [["Pensia", "Ankit", ""], ["Jog", "Varun", ""], ["Loh", "Po-Ling", ""]]}, {"id": "1907.03098", "submitter": "Mehmet Guzel", "authors": "Elit Cenk Alp, Mehmet Serdar Guzel", "title": "Playing Flappy Bird via Asynchronous Advantage Actor Critic Algorithm", "comments": "8 pages , 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Flappy Bird, which has a very high popularity, has been trained in many\nalgorithms. Some of these studies were trained from raw pixel values of game\nand some from specific attributes. In this study, the model was trained with\nraw game images, which had not been seen before. The trained model has learned\nas reinforcement when to make which decision. As an input to the model, the\nreward or penalty at the end of each step was returned and the training was\ncompleted. Flappy Bird game was trained with the Reinforcement Learning\nalgorithm Deep Q-Network and Asynchronous Advantage Actor Critic (A3C)\nalgorithms.\n", "versions": [{"version": "v1", "created": "Sat, 6 Jul 2019 09:07:28 GMT"}], "update_date": "2019-07-09", "authors_parsed": [["Alp", "Elit Cenk", ""], ["Guzel", "Mehmet Serdar", ""]]}, {"id": "1907.03100", "submitter": "Reinhard Heckel", "authors": "Reinhard Heckel", "title": "Regularizing linear inverse problems with convolutional neural networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep convolutional neural networks trained on large datsets have emerged as\nan intriguing alternative for compressing images and solving inverse problems\nsuch as denoising and compressive sensing. However, it has only recently been\nrealized that even without training, convolutional networks can function as\nconcise image models, and thus regularize inverse problems. In this paper, we\nprovide further evidence for this finding by studying variations of\nconvolutional neural networks that map few weight parameters to an image. The\nnetworks we consider only consist of convolutional operations, with either\nfixed or parameterized filters followed by ReLU non-linearities. We demonstrate\nthat with both fixed and parameterized convolutional filters those networks\nenable representing images with few coefficients. What is more, the\nunderparameterization enables regularization of inverse problems, in particular\nrecovering an image from few observations. We show that, similar to standard\ncompressive sensing guarantees, on the order of the number of model parameters\nmany measurements suffice for recovering an image from compressive\nmeasurements. Finally, we demonstrate that signal recovery with a un-trained\nconvolutional network outperforms standard l1 and total variation minimization\nfor magnetic resonance imaging (MRI).\n", "versions": [{"version": "v1", "created": "Sat, 6 Jul 2019 09:30:51 GMT"}], "update_date": "2019-07-09", "authors_parsed": [["Heckel", "Reinhard", ""]]}, {"id": "1907.03103", "submitter": "Vasisht Duddu", "authors": "Vasisht Duddu, D. Vijay Rao, Valentina E. Balas", "title": "Towards Enhancing Fault Tolerance in Neural Networks", "comments": "MobiQuitous 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.DC cs.GT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Learning Accelerators are prone to faults which manifest in the form of\nerrors in Neural Networks. Fault Tolerance in Neural Networks is crucial in\nreal-time safety critical applications requiring computation for long\ndurations. Neural Networks with high regularisation exhibit superior fault\ntolerance, however, at the cost of classification accuracy. In the view of\ndifference in functionality, a Neural Network is modelled as two separate\nnetworks, i.e, the Feature Extractor with unsupervised learning objective and\nthe Classifier with a supervised learning objective. Traditional approaches of\ntraining the entire network using a single supervised learning objective is\ninsufficient to achieve the objectives of the individual components optimally.\nIn this work, a novel multi-criteria objective function, combining unsupervised\ntraining of the Feature Extractor followed by supervised tuning with Classifier\nNetwork is proposed. The unsupervised training solves two games simultaneously\nin the presence of adversary neural networks with conflicting objectives to the\nFeature Extractor. The first game minimises the loss in reconstructing the\ninput image for indistinguishability given the features from the Extractor, in\nthe presence of a generative decoder. The second game solves a minimax\nconstraint optimisation for distributional smoothening of feature space to\nmatch a prior distribution, in the presence of a Discriminator network. The\nresultant strongly regularised Feature Extractor is combined with the\nClassifier Network for supervised fine-tuning. The proposed Adversarial Fault\nTolerant Neural Network Training is scalable to large networks and is\nindependent of the architecture. The evaluation on benchmarking datasets:\nFashionMNIST and CIFAR10, indicates that the resultant networks have high\naccuracy with superior tolerance to stuck at \"0\" faults compared to widely used\nregularisers.\n", "versions": [{"version": "v1", "created": "Sat, 6 Jul 2019 09:39:26 GMT"}, {"version": "v2", "created": "Tue, 9 Jul 2019 05:37:21 GMT"}, {"version": "v3", "created": "Sun, 30 May 2021 03:31:58 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Duddu", "Vasisht", ""], ["Rao", "D. Vijay", ""], ["Balas", "Valentina E.", ""]]}, {"id": "1907.03116", "submitter": "Sungeui Yoon", "authors": "JaeWon Choi, Sung-eui Yoon", "title": "Intrinsic Motivation Driven Intuitive Physics Learning using Deep\n  Reinforcement Learning with Intrinsic Reward Normalization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  At an early age, human infants are able to learn and build a model of the\nworld very quickly by constantly observing and interacting with objects around\nthem. One of the most fundamental intuitions human infants acquire is intuitive\nphysics. Human infants learn and develop these models, which later serve as\nprior knowledge for further learning. Inspired by such behaviors exhibited by\nhuman infants, we introduce a graphical physics network integrated with deep\nreinforcement learning. Specifically, we introduce an intrinsic reward\nnormalization method that allows our agent to efficiently choose actions that\ncan improve its intuitive physics model the most.\n  Using a 3D physics engine, we show that our graphical physics network is able\nto infer object's positions and velocities very effectively, and our deep\nreinforcement learning network encourages an agent to improve its model by\nmaking it continuously interact with objects only using intrinsic motivation.\nWe experiment our model in both stationary and non-stationary state problems\nand show benefits of our approach in terms of the number of different actions\nthe agent performs and the accuracy of agent's intuition model.\n  Videos are at https://www.youtube.com/watch?v=pDbByp91r3M&t=2s\n", "versions": [{"version": "v1", "created": "Sat, 6 Jul 2019 11:08:17 GMT"}], "update_date": "2019-07-09", "authors_parsed": [["Choi", "JaeWon", ""], ["Yoon", "Sung-eui", ""]]}, {"id": "1907.03122", "submitter": "Bicky Marquez", "authors": "Bicky A. Marquez, Jose Suarez-Vargas, Bhavin J. Shastri", "title": "Takens-inspired neuromorphic processor: a downsizing tool for random\n  recurrent neural networks via feature extraction", "comments": "12 pages, 8 figures", "journal-ref": "Phys. Rev. Research 1, 033030 (2019)", "doi": "10.1103/PhysRevResearch.1.033030", "report-no": null, "categories": "cs.NE cs.LG nlin.CD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a new technique which minimizes the amount of neurons in the\nhidden layer of a random recurrent neural network (rRNN) for time series\nprediction. Merging Takens-based attractor reconstruction methods with machine\nlearning, we identify a mechanism for feature extraction that can be leveraged\nto lower the network size. We obtain criteria specific to the particular\nprediction task and derive the scaling law of the prediction error. The\nconsequences of our theory are demonstrated by designing a Takens-inspired\nhybrid processor, which extends a rRNN with a priori designed delay external\nmemory. Our hybrid architecture is therefore designed including both, real and\nvirtual nodes. Via this symbiosis, we show performance of the hybrid processor\nby stabilizing an arrhythmic neural model. Thanks to our obtained design rules,\nwe can reduce the stabilizing neural network's size by a factor of 15 with\nrespect to a standard system.\n", "versions": [{"version": "v1", "created": "Sat, 6 Jul 2019 12:10:25 GMT"}], "update_date": "2019-10-23", "authors_parsed": [["Marquez", "Bicky A.", ""], ["Suarez-Vargas", "Jose", ""], ["Shastri", "Bhavin J.", ""]]}, {"id": "1907.03137", "submitter": "Zheng Fang", "authors": "Zheng Fang, Adrian S. Wong, Kangbo Hao, Alexander J. A. Ty, Henry D.\n  I. Abarbanel", "title": "Precision annealing Monte Carlo methods for statistical data\n  assimilation and machine learning", "comments": null, "journal-ref": "Phys. Rev. Research 2, 013050 (2020)", "doi": "10.1103/PhysRevResearch.2.013050", "report-no": null, "categories": "physics.data-an cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In statistical data assimilation (SDA) and supervised machine learning (ML),\nwe wish to transfer information from observations to a model of the processes\nunderlying those observations. For SDA, the model consists of a set of\ndifferential equations that describe the dynamics of a physical system. For ML,\nthe model is usually constructed using other strategies. In this paper, we\ndevelop a systematic formulation based on Monte Carlo sampling to achieve such\ninformation transfer. Following the derivation of an appropriate target\ndistribution, we present the formulation based on the standard\nMetropolis-Hasting (MH) procedure and the Hamiltonian Monte Carlo (HMC) method\nfor performing the high dimensional integrals that appear. To the extensive\nliterature on MH and HMC, we add (1) an annealing method using a hyperparameter\nthat governs the precision of the model to identify and explore the highest\nprobability regions of phase space dominating those integrals, and (2) a\nstrategy for initializing the state space search. The efficacy of the proposed\nformulation is demonstrated using a nonlinear dynamical model with chaotic\nsolutions widely used in geophysics.\n", "versions": [{"version": "v1", "created": "Sat, 6 Jul 2019 15:22:42 GMT"}, {"version": "v2", "created": "Tue, 21 Jan 2020 17:12:54 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Fang", "Zheng", ""], ["Wong", "Adrian S.", ""], ["Hao", "Kangbo", ""], ["Ty", "Alexander J. A.", ""], ["Abarbanel", "Henry D. I.", ""]]}, {"id": "1907.03140", "submitter": "Bjarne Grimstad", "authors": "Bjarne Grimstad and Henrik Andersson", "title": "ReLU Networks as Surrogate Models in Mixed-Integer Linear Programs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the embedding of piecewise-linear deep neural networks (ReLU\nnetworks) as surrogate models in mixed-integer linear programming (MILP)\nproblems. A MILP formulation of ReLU networks has recently been applied by many\nauthors to probe for various model properties subject to input bounds. The\nformulation is obtained by programming each ReLU operator with a binary\nvariable and applying the big-M method. The efficiency of the formulation\nhinges on the tightness of the bounds defined by the big-M values. When ReLU\nnetworks are embedded in a larger optimization problem, the presence of output\nbounds can be exploited in bound tightening. To this end, we devise and study\nseveral bound tightening procedures that consider both input and output bounds.\nOur numerical results show that bound tightening may reduce solution times\nconsiderably, and that small-sized ReLU networks are suitable as surrogate\nmodels in mixed-integer linear programs.\n", "versions": [{"version": "v1", "created": "Sat, 6 Jul 2019 15:36:55 GMT"}, {"version": "v2", "created": "Sun, 22 Sep 2019 21:17:33 GMT"}, {"version": "v3", "created": "Thu, 26 Sep 2019 19:58:40 GMT"}], "update_date": "2019-09-30", "authors_parsed": [["Grimstad", "Bjarne", ""], ["Andersson", "Henrik", ""]]}, {"id": "1907.03141", "submitter": "Ning Liu", "authors": "Ning Liu and Xiaolong Ma and Zhiyuan Xu and Yanzhi Wang and Jian Tang\n  and Jieping Ye", "title": "AutoCompress: An Automatic DNN Structured Pruning Framework for\n  Ultra-High Compression Rates", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Structured weight pruning is a representative model compression technique of\nDNNs to reduce the storage and computation requirements and accelerate\ninference. An automatic hyperparameter determination process is necessary due\nto the large number of flexible hyperparameters. This work proposes\nAutoCompress, an automatic structured pruning framework with the following key\nperformance improvements: (i) effectively incorporate the combination of\nstructured pruning schemes in the automatic process; (ii) adopt the\nstate-of-art ADMM-based structured weight pruning as the core algorithm, and\npropose an innovative additional purification step for further weight reduction\nwithout accuracy loss; and (iii) develop effective heuristic search method\nenhanced by experience-based guided search, replacing the prior deep\nreinforcement learning technique which has underlying incompatibility with the\ntarget pruning problem. Extensive experiments on CIFAR-10 and ImageNet datasets\ndemonstrate that AutoCompress is the key to achieve ultra-high pruning rates on\nthe number of weights and FLOPs that cannot be achieved before. As an example,\nAutoCompress outperforms the prior work on automatic model compression by up to\n33x in pruning rate (120x reduction in the actual parameter count) under the\nsame accuracy. Significant inference speedup has been observed from the\nAutoCompress framework on actual measurements on smartphone. We release all\nmodels of this work at anonymous link: http://bit.ly/2VZ63dS.\n", "versions": [{"version": "v1", "created": "Sat, 6 Jul 2019 15:40:02 GMT"}, {"version": "v2", "created": "Wed, 11 Sep 2019 12:15:38 GMT"}], "update_date": "2019-09-12", "authors_parsed": [["Liu", "Ning", ""], ["Ma", "Xiaolong", ""], ["Xu", "Zhiyuan", ""], ["Wang", "Yanzhi", ""], ["Tang", "Jian", ""], ["Ye", "Jieping", ""]]}, {"id": "1907.03143", "submitter": "Seyed Mehran Kazemi", "authors": "Rishab Goel, Seyed Mehran Kazemi, Marcus Brubaker, Pascal Poupart", "title": "Diachronic Embedding for Temporal Knowledge Graph Completion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Knowledge graphs (KGs) typically contain temporal facts indicating\nrelationships among entities at different times. Due to their incompleteness,\nseveral approaches have been proposed to infer new facts for a KG based on the\nexisting ones-a problem known as KG completion. KG embedding approaches have\nproved effective for KG completion, however, they have been developed mostly\nfor static KGs. Developing temporal KG embedding models is an increasingly\nimportant problem. In this paper, we build novel models for temporal KG\ncompletion through equipping static models with a diachronic entity embedding\nfunction which provides the characteristics of entities at any point in time.\nThis is in contrast to the existing temporal KG embedding approaches where only\nstatic entity features are provided. The proposed embedding function is\nmodel-agnostic and can be potentially combined with any static model. We prove\nthat combining it with SimplE, a recent model for static KG embedding, results\nin a fully expressive model for temporal KG completion. Our experiments\nindicate the superiority of our proposal compared to existing baselines.\n", "versions": [{"version": "v1", "created": "Sat, 6 Jul 2019 15:51:29 GMT"}], "update_date": "2019-07-09", "authors_parsed": [["Goel", "Rishab", ""], ["Kazemi", "Seyed Mehran", ""], ["Brubaker", "Marcus", ""], ["Poupart", "Pascal", ""]]}, {"id": "1907.03149", "submitter": "Nathaniel Bastian PhD", "authors": "Sean M. Devine and Nathaniel D. Bastian", "title": "Intelligent Systems Design for Malware Classification Under Adversarial\n  Conditions", "comments": "21 pages, 5 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The use of machine learning and intelligent systems has become an established\npractice in the realm of malware detection and cyber threat prevention. In an\nenvironment characterized by widespread accessibility and big data, the\nfeasibility of malware classification without the use of artificial\nintelligence-based techniques has been diminished exponentially. Also\ncharacteristic of the contemporary realm of automated, intelligent malware\ndetection is the threat of adversarial machine learning. Adversaries are\nlooking to target the underlying data and/or algorithm responsible for the\nfunctionality of malware classification to map its behavior or corrupt its\nfunctionality. The ends of such adversaries are bypassing the cyber security\nmeasures and increasing malware effectiveness. The focus of this research is\nthe design of an intelligent systems approach using machine learning that can\naccurately and robustly classify malware under adversarial conditions. Such an\noutcome ultimately relies on increased flexibility and adaptability to build a\nmodel robust enough to identify attacks on the underlying algorithm.\n", "versions": [{"version": "v1", "created": "Sat, 6 Jul 2019 16:10:02 GMT"}], "update_date": "2019-07-09", "authors_parsed": [["Devine", "Sean M.", ""], ["Bastian", "Nathaniel D.", ""]]}, {"id": "1907.03164", "submitter": "Bilal Soomro", "authors": "Bilal Soomro, Anssi Kanervisto, Trung Ngo Trong, Ville Hautam\\\"aki", "title": "Towards Debugging Deep Neural Networks by Generating Speech Utterances", "comments": "Accepted to Interspeech 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNN) are able to successfully process and classify\nspeech utterances. However, understanding the reason behind a classification by\nDNN is difficult. One such debugging method used with image classification DNNs\nis activation maximization, which generates example-images that are classified\nas one of the classes. In this work, we evaluate applicability of this method\nto speech utterance classifiers as the means to understanding what DNN \"listens\nto\". We trained a classifier using the speech command corpus and then use\nactivation maximization to pull samples from the trained model. Then we\nsynthesize audio from features using WaveNet vocoder for subjective analysis.\nWe measure the quality of generated samples by objective measurements and\ncrowd-sourced human evaluations. Results show that when combined with the prior\nof natural speech, activation maximization can be used to generate examples of\ndifferent classes. Based on these results, activation maximization can be used\nto start opening up the DNN black-box in speech tasks.\n", "versions": [{"version": "v1", "created": "Sat, 6 Jul 2019 18:19:32 GMT"}], "update_date": "2019-07-09", "authors_parsed": [["Soomro", "Bilal", ""], ["Kanervisto", "Anssi", ""], ["Trong", "Trung Ngo", ""], ["Hautam\u00e4ki", "Ville", ""]]}, {"id": "1907.03167", "submitter": "Jingcheng Du", "authors": "Jingcheng Du, Chongliang Luo, Qiang Wei, Yong Chen, Cui Tao", "title": "Exploring difference in public perceptions on HPV vaccine between gender\n  groups from Twitter using deep learning", "comments": "This manuscript has been accepted by 2019 KDD Workshop on Applied\n  Data Science for Healthcare", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this study, we proposed a convolutional neural network model for gender\nprediction using English Twitter text as input. Ensemble of proposed model\nachieved an accuracy at 0.8237 on gender prediction and compared favorably with\nthe state-of-the-art performance in a recent author profiling task. We further\nleveraged the trained models to predict the gender labels from an HPV vaccine\nrelated corpus and identified gender difference in public perceptions regarding\nHPV vaccine. The findings are largely consistent with previous survey-based\nstudies.\n", "versions": [{"version": "v1", "created": "Sat, 6 Jul 2019 18:58:54 GMT"}], "update_date": "2019-07-09", "authors_parsed": [["Du", "Jingcheng", ""], ["Luo", "Chongliang", ""], ["Wei", "Qiang", ""], ["Chen", "Yong", ""], ["Tao", "Cui", ""]]}, {"id": "1907.03178", "submitter": "Alexander M\\\"arz", "authors": "Alexander M\\\"arz", "title": "XGBoostLSS -- An extension of XGBoost to probabilistic forecasting", "comments": "Bayesian Optimization; Distributional Modeling; Expectile Regression;\n  GAMLSS; Probabilistic Forecast; Uncertainty Quantification; XGBoost", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new framework of XGBoost that predicts the entire conditional\ndistribution of a univariate response variable. In particular, XGBoostLSS\nmodels all moments of a parametric distribution (i.e., mean, location, scale\nand shape [LSS]) instead of the conditional mean only. Choosing from a wide\nrange of continuous, discrete and mixed discrete-continuous distribution,\nmodelling and predicting the entire conditional distribution greatly enhances\nthe flexibility of XGBoost, as it allows to gain additional insight into the\ndata generating process, as well as to create probabilistic forecasts from\nwhich prediction intervals and quantiles of interest can be derived. We present\nboth a simulation study and real world examples that demonstrate the virtues of\nour approach.\n", "versions": [{"version": "v1", "created": "Sat, 6 Jul 2019 20:25:16 GMT"}, {"version": "v2", "created": "Thu, 11 Jul 2019 10:32:31 GMT"}, {"version": "v3", "created": "Sun, 11 Aug 2019 09:16:42 GMT"}, {"version": "v4", "created": "Sun, 25 Aug 2019 09:30:15 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["M\u00e4rz", "Alexander", ""]]}, {"id": "1907.03179", "submitter": "Meng Qu", "authors": "Meng Qu, Jian Tang, Yoshua Bengio", "title": "Weakly-supervised Knowledge Graph Alignment with Adversarial Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies aligning knowledge graphs from different sources or\nlanguages. Most existing methods train supervised methods for the alignment,\nwhich usually require a large number of aligned knowledge triplets. However,\nsuch a large number of aligned knowledge triplets may not be available or are\nexpensive to obtain in many domains. Therefore, in this paper we propose to\nstudy aligning knowledge graphs in fully-unsupervised or weakly-supervised\nfashion, i.e., without or with only a few aligned triplets. We propose an\nunsupervised framework to align the entity and relation embddings of different\nknowledge graphs with an adversarial learning framework. Moreover, a\nregularization term which maximizes the mutual information between the\nembeddings of different knowledge graphs is used to mitigate the problem of\nmode collapse when learning the alignment functions. Such a framework can be\nfurther seamlessly integrated with existing supervised methods by utilizing a\nlimited number of aligned triples as guidance. Experimental results on multiple\ndatasets prove the effectiveness of our proposed approach in both the\nunsupervised and the weakly-supervised settings.\n", "versions": [{"version": "v1", "created": "Sat, 6 Jul 2019 20:31:13 GMT"}], "update_date": "2019-07-09", "authors_parsed": [["Qu", "Meng", ""], ["Tang", "Jian", ""], ["Bengio", "Yoshua", ""]]}, {"id": "1907.03191", "submitter": "Saeid Hosseini", "authors": "Saeid Hosseini, Saeed Najafipour, Ngai-Man Cheung, Hongzhi Yin,\n  Mohammad Reza Kangavari, and Xiaofang Zhou", "title": "TEAGS: Time-aware Text Embedding Approach to Generate Subgraphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.DB cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Contagions (e.g. virus, gossip) spread over the nodes in propagation graphs.\nWe can use the temporal and textual data of the nodes to compute the edge\nweights and then generate subgraphs with highly relevant nodes. This is\nbeneficial to many applications. Yet, challenges abound. First, the propagation\npattern between each pair of nodes may change by time. Second, not always the\nsame contagion propagates. Hence, the state-of-the-art text mining approaches\nincluding topic-modeling cannot effectively compute the edge weights. Third,\nsince the propagation is affected by time, the word-word co-occurrence patterns\nmay differ in various temporal dimensions, that can decrease the effectiveness\nof word embedding approaches. We argue that multi-aspect temporal dimensions\n(hour, day, etc) should be considered to better calculate the correlation\nweights between the nodes. In this work, we devise a novel framework that on\nthe one hand, integrates a neural network based time-aware word embedding\ncomponent to construct the word vectors through multiple temporal facets, and\non the other hand, uses a temporal generative model to compute the weights.\nSubsequently, we propose a Max-Heap Graph cutting algorithm to generate\nsubgraphs. We validate our model through comprehensive experiments on\nreal-world datasets. The results show that our model can retrieve the subgraphs\nmore effective than other rivals and the temporal dynamics should be noticed\nboth in word embedding and propagation processes.\n", "versions": [{"version": "v1", "created": "Sat, 6 Jul 2019 21:26:22 GMT"}, {"version": "v2", "created": "Wed, 21 Aug 2019 13:28:23 GMT"}, {"version": "v3", "created": "Sat, 24 Aug 2019 11:40:41 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["Hosseini", "Saeid", ""], ["Najafipour", "Saeed", ""], ["Cheung", "Ngai-Man", ""], ["Yin", "Hongzhi", ""], ["Kangavari", "Mohammad Reza", ""], ["Zhou", "Xiaofang", ""]]}, {"id": "1907.03192", "submitter": "Gilles Blanchard", "authors": "Franziska G\\\"obel and Gilles Blanchard", "title": "Volume Doubling Condition and a Local Poincar\\'e Inequality on\n  Unweighted Random Geometric Graphs", "comments": "Only updated acknowlegements wrt. version 1", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The aim of this paper is to establish two fundamental measure-metric\nproperties of particular random geometric graphs. We consider\n$\\varepsilon$-neighborhood graphs whose vertices are drawn independently and\nidentically distributed from a common distribution defined on a regular\nsubmanifold of $\\mathbb{R}^K$. We show that a volume doubling condition (VD)\nand local Poincar\\'e inequality (LPI) hold for the random geometric graph (with\nhigh probability, and uniformly over all shortest path distance balls in a\ncertain radius range) under suitable regularity conditions of the underlying\nsubmanifold and the sampling distribution.\n", "versions": [{"version": "v1", "created": "Sat, 6 Jul 2019 21:36:47 GMT"}, {"version": "v2", "created": "Mon, 23 Mar 2020 15:16:18 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["G\u00f6bel", "Franziska", ""], ["Blanchard", "Gilles", ""]]}, {"id": "1907.03197", "submitter": "Sepideh Mahabadi", "authors": "Piotr Indyk, Sepideh Mahabadi, Shayan Oveis Gharan, Alireza Rezaei", "title": "Composable Core-sets for Determinant Maximization: A Simple Near-Optimal\n  Algorithm", "comments": "This paper has appeared in the 36th International Conference on\n  Machine Learning (ICML), 2019. This is an equal contribution paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  ``Composable core-sets'' are an efficient framework for solving optimization\nproblems in massive data models. In this work, we consider efficient\nconstruction of composable core-sets for the determinant maximization problem.\nThis can also be cast as the MAP inference task for determinantal point\nprocesses, that have recently gained a lot of interest for modeling diversity\nand fairness. The problem was recently studied in [IMOR'18], where they\ndesigned composable core-sets with the optimal approximation bound of $\\tilde\nO(k)^k$. On the other hand, the more practical Greedy algorithm has been\npreviously used in similar contexts. In this work, first we provide a\ntheoretical approximation guarantee of $O(C^{k^2})$ for the Greedy algorithm in\nthe context of composable core-sets; Further, we propose to use a Local Search\nbased algorithm that while being still practical, achieves a nearly optimal\napproximation bound of $O(k)^{2k}$; Finally, we implement all three algorithms\nand show the effectiveness of our proposed algorithm on standard data sets.\n", "versions": [{"version": "v1", "created": "Sat, 6 Jul 2019 22:22:34 GMT"}], "update_date": "2019-07-09", "authors_parsed": [["Indyk", "Piotr", ""], ["Mahabadi", "Sepideh", ""], ["Gharan", "Shayan Oveis", ""], ["Rezaei", "Alireza", ""]]}, {"id": "1907.03199", "submitter": "Andreas Loukas", "authors": "Andreas Loukas", "title": "What graph neural networks cannot learn: depth vs width", "comments": "17 pages, 10 figures. International Conference on Learning\n  Representations (ICLR), 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies the expressive power of graph neural networks falling\nwithin the message-passing framework (GNNmp). Two results are presented. First,\nGNNmp are shown to be Turing universal under sufficient conditions on their\ndepth, width, node attributes, and layer expressiveness. Second, it is\ndiscovered that GNNmp can lose a significant portion of their power when their\ndepth and width is restricted. The proposed impossibility statements stem from\na new technique that enables the repurposing of seminal results from\ndistributed computing and leads to lower bounds for an array of decision,\noptimization, and estimation problems involving graphs. Strikingly, several of\nthese problems are deemed impossible unless the product of a GNNmp's depth and\nwidth exceeds a polynomial of the graph size; this dependence remains\nsignificant even for tasks that appear simple or when considering\napproximation.\n", "versions": [{"version": "v1", "created": "Sat, 6 Jul 2019 22:26:17 GMT"}, {"version": "v2", "created": "Tue, 28 Jan 2020 13:24:15 GMT"}], "update_date": "2020-01-29", "authors_parsed": [["Loukas", "Andreas", ""]]}, {"id": "1907.03207", "submitter": "Guang-He Lee", "authors": "Guang-He Lee and David Alvarez-Melis and Tommi S. Jaakkola", "title": "Towards Robust, Locally Linear Deep Networks", "comments": "Published in International Conference on Learning Representations\n  (ICLR), 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep networks realize complex mappings that are often understood by their\nlocally linear behavior at or around points of interest. For example, we use\nthe derivative of the mapping with respect to its inputs for sensitivity\nanalysis, or to explain (obtain coordinate relevance for) a prediction. One key\nchallenge is that such derivatives are themselves inherently unstable. In this\npaper, we propose a new learning problem to encourage deep networks to have\nstable derivatives over larger regions. While the problem is challenging in\ngeneral, we focus on networks with piecewise linear activation functions. Our\nalgorithm consists of an inference step that identifies a region around a point\nwhere linear approximation is provably stable, and an optimization step to\nexpand such regions. We propose a novel relaxation to scale the algorithm to\nrealistic models. We illustrate our method with residual and recurrent networks\non image and sequence datasets.\n", "versions": [{"version": "v1", "created": "Sun, 7 Jul 2019 00:18:22 GMT"}], "update_date": "2019-07-09", "authors_parsed": [["Lee", "Guang-He", ""], ["Alvarez-Melis", "David", ""], ["Jaakkola", "Tommi S.", ""]]}, {"id": "1907.03211", "submitter": "Andrew Song", "authors": "Bahareh Tolooshams, Andrew H. Song, Simona Temereanca, Demba Ba", "title": "Convolutional dictionary learning based auto-encoders for natural\n  exponential-family distributions", "comments": null, "journal-ref": "International Conference on Machine Learning (ICML) 2020", "doi": null, "report-no": null, "categories": "cs.LG stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a class of auto-encoder neural networks tailored to data from\nthe natural exponential family (e.g., count data). The architectures are\ninspired by the problem of learning the filters in a convolutional generative\nmodel with sparsity constraints, often referred to as convolutional dictionary\nlearning (CDL). Our work is the first to combine ideas from convolutional\ngenerative models and deep learning for data that are naturally modeled with a\nnon-Gaussian distribution (e.g., binomial and Poisson). This perspective\nprovides us with a scalable and flexible framework that can be re-purposed for\na wide range of tasks and assumptions on the generative model. Specifically,\nthe iterative optimization procedure for solving CDL, an unsupervised task, is\nmapped to an unfolded and constrained neural network, with iterative\nadjustments to the inputs to account for the generative distribution. We also\nshow that the framework can easily be extended for discriminative training,\nappropriate for a supervised task. We demonstrate 1) that fitting the\ngenerative model to learn, in an unsupervised fashion, the latent stimulus that\nunderlies neural spiking data leads to better goodness-of-fit compared to other\nbaselines, 2) competitive performance compared to state-of-the-art algorithms\nfor supervised Poisson image denoising, with significantly fewer parameters,\nand 3) gradient dynamics of shallow binomial auto-encoder.\n", "versions": [{"version": "v1", "created": "Sun, 7 Jul 2019 01:45:42 GMT"}, {"version": "v2", "created": "Thu, 24 Oct 2019 23:36:18 GMT"}, {"version": "v3", "created": "Tue, 11 Feb 2020 11:55:04 GMT"}, {"version": "v4", "created": "Sun, 28 Jun 2020 23:35:04 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Tolooshams", "Bahareh", ""], ["Song", "Andrew H.", ""], ["Temereanca", "Simona", ""], ["Ba", "Demba", ""]]}, {"id": "1907.03215", "submitter": "Xiang Cheng", "authors": "Xiang Cheng, Dong Yin, Peter L. Bartlett, Michael I. Jordan", "title": "Stochastic Gradient and Langevin Processes", "comments": "ICML 2020, code available at\n  https://github.com/dongyin92/noise_covariance", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove quantitative convergence rates at which discrete Langevin-like\nprocesses converge to the invariant distribution of a related stochastic\ndifferential equation. We study the setup where the additive noise can be\nnon-Gaussian and state-dependent and the potential function can be non-convex.\nWe show that the key properties of these processes depend on the potential\nfunction and the second moment of the additive noise. We apply our theoretical\nfindings to studying the convergence of Stochastic Gradient Descent (SGD) for\nnon-convex problems and corroborate them with experiments using SGD to train\ndeep neural networks on the CIFAR-10 dataset.\n", "versions": [{"version": "v1", "created": "Sun, 7 Jul 2019 03:27:17 GMT"}, {"version": "v2", "created": "Sat, 13 Jul 2019 16:22:38 GMT"}, {"version": "v3", "created": "Wed, 23 Oct 2019 22:35:20 GMT"}, {"version": "v4", "created": "Mon, 29 Jun 2020 00:33:16 GMT"}, {"version": "v5", "created": "Wed, 22 Jul 2020 20:36:53 GMT"}, {"version": "v6", "created": "Wed, 18 Nov 2020 05:41:20 GMT"}, {"version": "v7", "created": "Thu, 19 Nov 2020 02:35:38 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Cheng", "Xiang", ""], ["Yin", "Dong", ""], ["Bartlett", "Peter L.", ""], ["Jordan", "Michael I.", ""]]}, {"id": "1907.03222", "submitter": "Dipendra Jha", "authors": "Dipendra Jha, Logan Ward, Zijiang Yang, Christopher Wolverton, Ian\n  Foster, Wei-keng Liao, Alok Choudhary, Ankit Agrawal", "title": "IRNet: A General Purpose Deep Residual Regression Framework for\n  Materials Discovery", "comments": "9 pages, under publication at KDD'19", "journal-ref": null, "doi": "10.1145/3292500.3330703", "report-no": null, "categories": "physics.comp-ph cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Materials discovery is crucial for making scientific advances in many\ndomains. Collections of data from experiments and first-principle computations\nhave spurred interest in applying machine learning methods to create predictive\nmodels capable of mapping from composition and crystal structures to materials\nproperties. Generally, these are regression problems with the input being a 1D\nvector composed of numerical attributes representing the material composition\nand/or crystal structure. While neural networks consisting of fully connected\nlayers have been applied to such problems, their performance often suffers from\nthe vanishing gradient problem when network depth is increased. In this paper,\nwe study and propose design principles for building deep regression networks\ncomposed of fully connected layers with numerical vectors as input. We\nintroduce a novel deep regression network with individual residual learning,\nIRNet, that places shortcut connections after each layer so that each layer\nlearns the residual mapping between its output and input. We use the problem of\nlearning properties of inorganic materials from numerical attributes derived\nfrom material composition and/or crystal structure to compare IRNet's\nperformance against that of other machine learning techniques. Using multiple\ndatasets from the Open Quantum Materials Database (OQMD) and Materials Project\nfor training and evaluation, we show that IRNet provides significantly better\nprediction performance than the state-of-the-art machine learning approaches\ncurrently used by domain scientists. We also show that IRNet's use of\nindividual residual learning leads to better convergence during the training\nphase than when shortcut connections are between multi-layer stacks while\nmaintaining the same number of parameters.\n", "versions": [{"version": "v1", "created": "Sun, 7 Jul 2019 05:19:35 GMT"}], "update_date": "2019-07-09", "authors_parsed": [["Jha", "Dipendra", ""], ["Ward", "Logan", ""], ["Yang", "Zijiang", ""], ["Wolverton", "Christopher", ""], ["Foster", "Ian", ""], ["Liao", "Wei-keng", ""], ["Choudhary", "Alok", ""], ["Agrawal", "Ankit", ""]]}, {"id": "1907.03236", "submitter": "Kei Majima", "authors": "Naoko Koide-Majima, Kei Majima", "title": "Quantum-inspired canonical correlation analysis for exponentially large\n  dimensional data", "comments": "45 pages, 9 figures. This article will appear in Neural Networks", "journal-ref": "Neural Networks, 2020", "doi": "10.1016/j.neunet.2020.11.019", "report-no": null, "categories": "cs.LG quant-ph stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Canonical correlation analysis (CCA) is a technique to find statistical\ndependencies between a pair of multivariate data. However, its application to\nhigh dimensional data is limited due to the resulting time complexity. While\nthe conventional CCA algorithm requires polynomial time, we have developed an\nalgorithm that approximates CCA with computational time proportional to the\nlogarithm of the input dimensionality using quantum-inspired computation. The\ncomputational efficiency and approximation performance of the proposed\nquantum-inspired CCA (qiCCA) algorithm are experimentally demonstrated.\nFurthermore, the fast computation of qiCCA allows us to directly apply CCA even\nafter nonlinearly mapping raw input data into very high dimensional spaces.\nExperiments performed using a benchmark dataset demonstrated that, by mapping\nthe raw input data into the high dimensional spaces with second-order\nmonomials, the proposed qiCCA extracted more correlations than linear CCA and\nwas comparable to deep CCA and kernel CCA. These results suggest that qiCCA is\nconsiderably useful and quantum-inspired computation has the potential to\nunlock a new field in which exponentially large dimensional data can be\nanalyzed.\n", "versions": [{"version": "v1", "created": "Sun, 7 Jul 2019 07:35:55 GMT"}, {"version": "v2", "created": "Mon, 7 Dec 2020 14:19:47 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Koide-Majima", "Naoko", ""], ["Majima", "Kei", ""]]}, {"id": "1907.03247", "submitter": "Mahdi Pedram", "authors": "Mahdi Pedram, Mahsan Rofouei, Francesco Fraternali, Zhila Esna Ashari,\n  Hassan Ghasemzadeh", "title": "Resource-Efficient Computing in Wearable Systems", "comments": null, "journal-ref": "Fourth IEEE Workshop on Smart Service Systems (SmartSys 2019), 12\n  June 2019, Washington D.C., USA", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose two optimization techniques to minimize memory usage and\ncomputation while meeting system timing constraints for real-time\nclassification in wearable systems. Our method derives a hierarchical\nclassifier structure for Support Vector Machine (SVM) in order to reduce the\namount of computations, based on the probability distribution of output classes\noccurrences. Also, we propose a memory optimization technique based on SVM\nparameters, which results in storing fewer support vectors and as a result\nrequiring less memory. To demonstrate the efficiency of our proposed\ntechniques, we performed an activity recognition experiment and were able to\nsave up to 35% and 56% in memory storage when classifying 14 and 6 different\nactivities, respectively. In addition, we demonstrated that there is a\ntrade-off between accuracy of classification and memory savings, which can be\ncontrolled based on application requirements.\n", "versions": [{"version": "v1", "created": "Sun, 7 Jul 2019 08:26:30 GMT"}], "update_date": "2019-07-09", "authors_parsed": [["Pedram", "Mahdi", ""], ["Rofouei", "Mahsan", ""], ["Fraternali", "Francesco", ""], ["Ashari", "Zhila Esna", ""], ["Ghasemzadeh", "Hassan", ""]]}, {"id": "1907.03250", "submitter": "Mahdi Pedram", "authors": "Mahdi Pedram, Seyed Ali Rokni, Marjan Nourollahi, Houman Homayoun,\n  Hassan Ghasemzadeh", "title": "Resource-Efficient Wearable Computing for Real-Time Reconfigurable\n  Machine Learning: A Cascading Binary Classification", "comments": null, "journal-ref": "The 16th IEEE International Conference on Wearable and Implantable\n  Body Sensor Networks, 19-22 May, 2019", "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Advances in embedded systems have enabled integration of many lightweight\nsensory devices within our daily life. In particular, this trend has given rise\nto continuous expansion of wearable sensors in a broad range of applications\nfrom health and fitness monitoring to social networking and military\nsurveillance. Wearables leverage machine learning techniques to profile\nbehavioral routine of their end-users through activity recognition algorithms.\nCurrent research assumes that such machine learning algorithms are trained\noffline. In reality, however, wearables demand continuous reconfiguration of\ntheir computational algorithms due to their highly dynamic operation.\nDeveloping a personalized and adaptive machine learning model requires\nreal-time reconfiguration of the model. Due to stringent computation and memory\nconstraints of these embedded sensors, the training/re-training of the\ncomputational algorithms need to be memory- and computation-efficient. In this\npaper, we propose a framework, based on the notion of online learning, for\nreal-time and on-device machine learning training. We propose to transform the\nactivity recognition problem from a multi-class classification problem to a\nhierarchical model of binary decisions using cascading online binary\nclassifiers. Our results, based on Pegasos online learning, demonstrate that\nthe proposed approach achieves 97% accuracy in detecting activities of varying\nintensities using a limited memory while power usages of the system is reduced\nby more than 40%.\n", "versions": [{"version": "v1", "created": "Sun, 7 Jul 2019 08:40:22 GMT"}], "update_date": "2019-07-09", "authors_parsed": [["Pedram", "Mahdi", ""], ["Rokni", "Seyed Ali", ""], ["Nourollahi", "Marjan", ""], ["Homayoun", "Houman", ""], ["Ghasemzadeh", "Hassan", ""]]}, {"id": "1907.03289", "submitter": "Le Liang", "authors": "Le Liang, Hao Ye, Guanding Yu, Geoffrey Ye Li", "title": "Deep Learning based Wireless Resource Allocation with Application to\n  Vehicular Networks", "comments": "14 pages; 8 figures; 3 tables; submitted to Proceedings of IEEE", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It has been a long-held belief that judicious resource allocation is critical\nto mitigating interference, improving network efficiency, and ultimately\noptimizing wireless communication performance. The traditional wisdom is to\nexplicitly formulate resource allocation as an optimization problem and then\nexploit mathematical programming to solve the problem to a certain level of\noptimality. Nonetheless, as wireless networks become increasingly diverse and\ncomplex, e.g., in the high-mobility vehicular networks, the current design\nmethodologies face significant challenges and thus call for rethinking of the\ntraditional design philosophy. Meanwhile, deep learning, with many success\nstories in various disciplines, represents a promising alternative due to its\nremarkable power to leverage data for problem solving. In this paper, we\ndiscuss the key motivations and roadblocks of using deep learning for wireless\nresource allocation with application to vehicular networks. We review major\nrecent studies that mobilize the deep learning philosophy in wireless resource\nallocation and achieve impressive results. We first discuss deep learning\nassisted optimization for resource allocation. We then highlight the deep\nreinforcement learning approach to address resource allocation problems that\nare difficult to handle in the traditional optimization framework. We also\nidentify some research directions that deserve further investigation.\n", "versions": [{"version": "v1", "created": "Sun, 7 Jul 2019 13:41:13 GMT"}, {"version": "v2", "created": "Tue, 1 Oct 2019 17:55:23 GMT"}], "update_date": "2019-10-02", "authors_parsed": [["Liang", "Le", ""], ["Ye", "Hao", ""], ["Yu", "Guanding", ""], ["Li", "Geoffrey Ye", ""]]}, {"id": "1907.03313", "submitter": "Jacob Sakhnini", "authors": "Jacob Sakhnini and Hadis Karimipour and Ali Dehghantanha", "title": "Smart Grid Cyber Attacks Detection using Supervised Learning and\n  Heuristic Feature Selection", "comments": "5 pages (including references), 3 picture files in 1 figure, to\n  appear in the proceeding of IEEE SEGE 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  False Data Injection (FDI) attacks are a common form of Cyber-attack\ntargetting smart grids. Detection of stealthy FDI attacks is impossible by the\ncurrent bad data detection systems. Machine learning is one of the alternative\nmethods proposed to detect FDI attacks. This paper analyzes three various\nsupervised learning techniques, each to be used with three different feature\nselection (FS) techniques. These methods are tested on the IEEE 14-bus, 57-bus,\nand 118-bus systems for evaluation of versatility. Accuracy of the\nclassification is used as the main evaluation method for each detection\ntechnique. Simulation study clarify the supervised learning combined with\nheuristic FS methods result in an improved performance of the classification\nalgorithms for FDI attack detection.\n", "versions": [{"version": "v1", "created": "Sun, 7 Jul 2019 16:27:35 GMT"}], "update_date": "2019-07-09", "authors_parsed": [["Sakhnini", "Jacob", ""], ["Karimipour", "Hadis", ""], ["Dehghantanha", "Ali", ""]]}, {"id": "1907.03324", "submitter": "Hilde Weerts MSc", "authors": "Hilde J.P. Weerts and Werner van Ipenburg and Mykola Pechenizkiy", "title": "A Human-Grounded Evaluation of SHAP for Alert Processing", "comments": "Will be published in proceedings of KDD workshop on Explainable AI\n  2019 (KDD-XAI)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.HC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the past years, many new explanation methods have been proposed to achieve\ninterpretability of machine learning predictions. However, the utility of these\nmethods in practical applications has not been researched extensively. In this\npaper we present the results of a human-grounded evaluation of SHAP, an\nexplanation method that has been well-received in the XAI and related\ncommunities. In particular, we study whether this local model-agnostic\nexplanation method can be useful for real human domain experts to assess the\ncorrectness of positive predictions, i.e. alerts generated by a classifier. We\nperformed experimentation with three different groups of participants (159 in\ntotal), who had basic knowledge of explainable machine learning. We performed a\nqualitative analysis of recorded reflections of experiment participants\nperforming alert processing with and without SHAP information. The results\nsuggest that the SHAP explanations do impact the decision-making process,\nalthough the model's confidence score remains to be a leading source of\nevidence. We statistically test whether there is a significant difference in\ntask utility metrics between tasks for which an explanation was available and\ntasks in which it was not provided. As opposed to common intuitions, we did not\nfind a significant difference in alert processing performance when a SHAP\nexplanation is available compared to when it is not.\n", "versions": [{"version": "v1", "created": "Sun, 7 Jul 2019 17:50:06 GMT"}], "update_date": "2019-07-09", "authors_parsed": [["Weerts", "Hilde J. P.", ""], ["van Ipenburg", "Werner", ""], ["Pechenizkiy", "Mykola", ""]]}, {"id": "1907.03329", "submitter": "Kaung Khin", "authors": "Andrew Redd, Kaung Khin, Aldo Marini", "title": "Fast ES-RNN: A GPU Implementation of the ES-RNN Algorithm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to their prevalence, time series forecasting is crucial in multiple\ndomains. We seek to make state-of-the-art forecasting fast, accessible, and\ngeneralizable. ES-RNN is a hybrid between classical state space forecasting\nmodels and modern RNNs that achieved a 9.4% sMAPE improvement in the M4\ncompetition. Crucially, ES-RNN implementation requires per-time series\nparameters. By vectorizing the original implementation and porting the\nalgorithm to a GPU, we achieve up to 322x training speedup depending on batch\nsize with similar results as those reported in the original submission. Our\ncode can be found at: https://github.com/damitkwr/ESRNN-GPU\n", "versions": [{"version": "v1", "created": "Sun, 7 Jul 2019 18:23:17 GMT"}], "update_date": "2019-07-09", "authors_parsed": [["Redd", "Andrew", ""], ["Khin", "Kaung", ""], ["Marini", "Aldo", ""]]}, {"id": "1907.03334", "submitter": "Hilde Weerts MSc", "authors": "Hilde J.P. Weerts and Werner van Ipenburg and Mykola Pechenizkiy", "title": "Case-Based Reasoning for Assisting Domain Experts in Processing Fraud\n  Alerts of Black-Box Machine Learning Models", "comments": "Will be published in proceedings of KDD workshop on Anomaly Detection\n  in Finance 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.HC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many contexts, it can be useful for domain experts to understand to what\nextent predictions made by a machine learning model can be trusted. In\nparticular, estimates of trustworthiness can be useful for fraud analysts who\nprocess machine learning-generated alerts of fraudulent transactions. In this\nwork, we present a case-based reasoning (CBR) approach that provides evidence\non the trustworthiness of a prediction in the form of a visualization of\nsimilar previous instances. Different from previous works, we consider\nsimilarity of local post-hoc explanations of predictions and show empirically\nthat our visualization can be useful for processing alerts. Furthermore, our\napproach is perceived useful and easy to use by fraud analysts at a major Dutch\nbank.\n", "versions": [{"version": "v1", "created": "Sun, 7 Jul 2019 19:12:49 GMT"}], "update_date": "2019-07-09", "authors_parsed": [["Weerts", "Hilde J. P.", ""], ["van Ipenburg", "Werner", ""], ["Pechenizkiy", "Mykola", ""]]}, {"id": "1907.03336", "submitter": "Ronny Lempel", "authors": "Sonya Liberman, Shaked Bar, Raphael Vannerom, Danny Rosenstein, Ronny\n  Lempel", "title": "Search-Based Serving Architecture of Embeddings-Based Recommendations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the past 10 years, many recommendation techniques have been based on\nembedding users and items in latent vector spaces, where the inner product of a\n(user,item) pair of vectors represents the predicted affinity of the user to\nthe item. A wealth of literature has focused on the various modeling approaches\nthat result in embeddings, and has compared their quality metrics, learning\ncomplexity, etc. However, much less attention has been devoted to the issues\nsurrounding productization of an embeddings-based high throughput, low latency\nrecommender system. In particular, how the system might keep up with the\nchanging embeddings as new models are learnt. This paper describes a reference\narchitecture of a high-throughput, large scale recommendation service which\nleverages a search engine as its runtime core. We describe how the search index\nand the query builder adapt to changes in the embeddings, which often happen at\na different cadence than index builds. We provide solutions for both id-based\nand feature-based embeddings, as well as for batch indexing and incremental\nindexing setups. The described system is at the core of a Web content discovery\nservice that serves tens of billions recommendations per day in response to\nbillions of user requests.\n", "versions": [{"version": "v1", "created": "Sun, 7 Jul 2019 19:32:24 GMT"}], "update_date": "2019-07-09", "authors_parsed": [["Liberman", "Sonya", ""], ["Bar", "Shaked", ""], ["Vannerom", "Raphael", ""], ["Rosenstein", "Danny", ""], ["Lempel", "Ronny", ""]]}, {"id": "1907.03343", "submitter": "Fabi\\'an Latorre G\\'omez", "authors": "Fabian Latorre G\\'omez, Armin Eftekhari, Volkan Cevher", "title": "Fast and Provable ADMM for Learning with Generative Priors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we propose a (linearized) Alternating Direction\nMethod-of-Multipliers (ADMM) algorithm for minimizing a convex function subject\nto a nonconvex constraint. We focus on the special case where such constraint\narises from the specification that a variable should lie in the range of a\nneural network. This is motivated by recent successful applications of\nGenerative Adversarial Networks (GANs) in tasks like compressive sensing,\ndenoising and robustness against adversarial examples. The derived rates for\nour algorithm are characterized in terms of certain geometric properties of the\ngenerator network, which we show hold for feedforward architectures, under mild\nassumptions. Unlike gradient descent (GD), it can efficiently handle non-smooth\nobjectives as well as exploit efficient partial minimization procedures, thus\nbeing faster in many practical scenarios.\n", "versions": [{"version": "v1", "created": "Sun, 7 Jul 2019 20:09:58 GMT"}], "update_date": "2019-07-09", "authors_parsed": [["G\u00f3mez", "Fabian Latorre", ""], ["Eftekhari", "Armin", ""], ["Cevher", "Volkan", ""]]}, {"id": "1907.03346", "submitter": "Yogev Bar-On", "authors": "Yogev Bar-On and Yishay Mansour", "title": "Individual Regret in Cooperative Nonstochastic Multi-Armed Bandits", "comments": "To appear in Proc. Neural Information Processing Systems (NeurIPS),\n  2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study agents communicating over an underlying network by exchanging\nmessages, in order to optimize their individual regret in a common\nnonstochastic multi-armed bandit problem. We derive regret minimization\nalgorithms that guarantee for each agent $v$ an individual expected regret of\n$\\widetilde{O}\\left(\\sqrt{\\left(1+\\frac{K}{\\left|\\mathcal{N}\\left(v\\right)\\right|}\\right)T}\\right)$,\nwhere $T$ is the number of time steps, $K$ is the number of actions and\n$\\mathcal{N}\\left(v\\right)$ is the set of neighbors of agent $v$ in the\ncommunication graph. We present algorithms both for the case that the\ncommunication graph is known to all the agents, and for the case that the graph\nis unknown. When the graph is unknown, each agent knows only the set of its\nneighbors and an upper bound on the total number of agents. The individual\nregret between the models differs only by a logarithmic factor. Our work\nresolves an open problem from [Cesa-Bianchi et al., 2019b].\n", "versions": [{"version": "v1", "created": "Sun, 7 Jul 2019 20:58:29 GMT"}, {"version": "v2", "created": "Mon, 9 Sep 2019 16:03:02 GMT"}, {"version": "v3", "created": "Sat, 16 Nov 2019 22:13:25 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Bar-On", "Yogev", ""], ["Mansour", "Yishay", ""]]}, {"id": "1907.03355", "submitter": "Hung Ba", "authors": "Hung Ba", "title": "Improving Detection of Credit Card Fraudulent Transactions using\n  Generative Adversarial Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-fin.RM", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In this study, we employ Generative Adversarial Networks as an oversampling\nmethod to generate artificial data to assist with the classification of credit\ncard fraudulent transactions. GANs is a generative model based on the idea of\ngame theory, in which a generator G and a discriminator D are trying to\noutsmart each other. The objective of the generator is to confuse the\ndiscriminator. The objective of the discriminator is to distinguish the\ninstances coming from the generator and the instances coming from the original\ndataset. By training GANs on a set of credit card fraudulent transactions, we\nare able to improve the discriminatory power of classifiers. The experiment\nresults show that the Wasserstein-GAN is more stable in training and produce\nmore realistic fraudulent transactions than the other GANs. On the other hand,\nthe conditional version of GANs in which labels are set by k-means clustering\ndoes not necessarily improve the non-conditional versions of GANs.\n", "versions": [{"version": "v1", "created": "Sun, 7 Jul 2019 22:20:52 GMT"}], "update_date": "2019-07-09", "authors_parsed": [["Ba", "Hung", ""]]}, {"id": "1907.03361", "submitter": "Magnus Wiese", "authors": "Magnus Wiese, Robert Knobloch, Ralf Korn", "title": "Copula & Marginal Flows: Disentangling the Marginal from its Joint", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep generative networks such as GANs and normalizing flows flourish in the\ncontext of high-dimensional tasks such as image generation. However, so far\nexact modeling or extrapolation of distributional properties such as the tail\nasymptotics generated by a generative network is not available. In this paper,\nwe address this issue for the first time in the deep learning literature by\nmaking two novel contributions. First, we derive upper bounds for the tails\nthat can be expressed by a generative network and demonstrate Lp-space related\nproperties. There we show specifically that in various situations an optimal\ngenerative network does not exist. Second, we introduce and propose copula and\nmarginal generative flows (CM flows) which allow for an exact modeling of the\ntail and any prior assumption on the CDF up to an approximation of the uniform\ndistribution. Our numerical results support the use of CM flows.\n", "versions": [{"version": "v1", "created": "Sun, 7 Jul 2019 22:45:26 GMT"}], "update_date": "2019-07-09", "authors_parsed": [["Wiese", "Magnus", ""], ["Knobloch", "Robert", ""], ["Korn", "Ralf", ""]]}, {"id": "1907.03372", "submitter": "Ali Shahin Shamsabadi", "authors": "Nitin Agrawal, Ali Shahin Shamsabadi, Matt J. Kusner, Adri\\`a Gasc\\'on", "title": "QUOTIENT: Two-Party Secure Neural Network Training and Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, there has been a wealth of effort devoted to the design of secure\nprotocols for machine learning tasks. Much of this is aimed at enabling secure\nprediction from highly-accurate Deep Neural Networks (DNNs). However, as DNNs\nare trained on data, a key question is how such models can be also trained\nsecurely. The few prior works on secure DNN training have focused either on\ndesigning custom protocols for existing training algorithms, or on developing\ntailored training algorithms and then applying generic secure protocols. In\nthis work, we investigate the advantages of designing training algorithms\nalongside a novel secure protocol, incorporating optimizations on both fronts.\nWe present QUOTIENT, a new method for discretized training of DNNs, along with\na customized secure two-party protocol for it. QUOTIENT incorporates key\ncomponents of state-of-the-art DNN training such as layer normalization and\nadaptive gradient methods, and improves upon the state-of-the-art in DNN\ntraining in two-party computation. Compared to prior work, we obtain an\nimprovement of 50X in WAN time and 6% in absolute accuracy.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jul 2019 00:42:30 GMT"}], "update_date": "2019-07-09", "authors_parsed": [["Agrawal", "Nitin", ""], ["Shamsabadi", "Ali Shahin", ""], ["Kusner", "Matt J.", ""], ["Gasc\u00f3n", "Adri\u00e0", ""]]}, {"id": "1907.03373", "submitter": "Valentin Hartmann", "authors": "Valentin Hartmann, Konark Modi, Josep M. Pujol, Robert West", "title": "Privacy-Preserving Classification with Secret Vector Machines", "comments": "10 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Today, large amounts of valuable data are distributed among millions of\nuser-held devices, such as personal computers, phones, or Internet-of-things\ndevices. Many companies collect such data with the goal of using it for\ntraining machine learning models allowing them to improve their services.\nUser-held data is, however, often sensitive, and collecting it is problematic\nin terms of privacy. We address this issue by proposing a novel way of training\na supervised classifier in a distributed setting akin to the recently proposed\nfederated learning paradigm, but under the stricter privacy requirement that\nthe server that trains the model is assumed to be untrusted and potentially\nmalicious. We thus preserve user privacy by design, rather than by trust. In\nparticular, our framework, called secret vector machine (SecVM), provides an\nalgorithm for training linear support vector machines (SVM) in a setting in\nwhich data-holding clients communicate with an untrusted server by exchanging\nmessages designed to not reveal any personally identifiable information. We\nevaluate our model in two ways. First, in an offline evaluation, we train SecVM\nto predict user gender from tweets, showing that we can preserve user privacy\nwithout sacrificing classification performance. Second, we implement SecVM's\ndistributed framework for the Cliqz web browser and deploy it for predicting\nuser gender in a large-scale online evaluation with thousands of clients,\noutperforming baselines by a large margin and thus showcasing that SecVM is\nsuitable for production environments.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jul 2019 00:57:10 GMT"}, {"version": "v2", "created": "Wed, 19 Aug 2020 23:00:55 GMT"}], "update_date": "2020-08-21", "authors_parsed": [["Hartmann", "Valentin", ""], ["Modi", "Konark", ""], ["Pujol", "Josep M.", ""], ["West", "Robert", ""]]}, {"id": "1907.03381", "submitter": "Yanyan Xu", "authors": "Wuwei Lan, Yanyan Xu, Bin Zhao", "title": "Travel Time Estimation without Road Networks: An Urban Morphological\n  Layout Representation Approach", "comments": "Accepted at IJCAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Travel time estimation is a crucial task for not only personal travel\nscheduling but also city planning. Previous methods focus on modeling toward\nroad segments or sub-paths, then summing up for a final prediction, which have\nbeen recently replaced by deep neural models with end-to-end training. Usually,\nthese methods are based on explicit feature representations, including\nspatio-temporal features, traffic states, etc. Here, we argue that the local\ntraffic condition is closely tied up with the land-use and built environment,\ni.e., metro stations, arterial roads, intersections, commercial area,\nresidential area, and etc, yet the relation is time-varying and too complicated\nto model explicitly and efficiently. Thus, this paper proposes an end-to-end\nmulti-task deep neural model, named Deep Image to Time (DeepI2T), to learn the\ntravel time mainly from the built environment images, a.k.a. the morphological\nlayout images, and showoff the new state-of-the-art performance on real-world\ndatasets in two cities. Moreover, our model is designed to tackle both\npath-aware and path-blind scenarios in the testing phase. This work opens up\nnew opportunities of using the publicly available morphological layout images\nas considerable information in multiple geography-related smart city\napplications.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jul 2019 01:52:35 GMT"}], "update_date": "2019-07-09", "authors_parsed": [["Lan", "Wuwei", ""], ["Xu", "Yanyan", ""], ["Zhao", "Bin", ""]]}, {"id": "1907.03382", "submitter": "Atilim Gunes Baydin", "authors": "At{\\i}l{\\i}m G\\\"une\\c{s} Baydin, Lei Shao, Wahid Bhimji, Lukas\n  Heinrich, Lawrence Meadows, Jialin Liu, Andreas Munk, Saeid Naderiparizi,\n  Bradley Gram-Hansen, Gilles Louppe, Mingfei Ma, Xiaohui Zhao, Philip Torr,\n  Victor Lee, Kyle Cranmer, Prabhat, Frank Wood", "title": "Etalumis: Bringing Probabilistic Programming to Scientific Simulators at\n  Scale", "comments": "14 pages, 8 figures", "journal-ref": "Proceedings of the International Conference for High Performance\n  Computing, Networking, Storage, and Analysis (SC19), November 17--22, 2019", "doi": "10.1145/3295500.3356180", "report-no": null, "categories": "cs.LG cs.PF stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Probabilistic programming languages (PPLs) are receiving widespread attention\nfor performing Bayesian inference in complex generative models. However,\napplications to science remain limited because of the impracticability of\nrewriting complex scientific simulators in a PPL, the computational cost of\ninference, and the lack of scalable implementations. To address these, we\npresent a novel PPL framework that couples directly to existing scientific\nsimulators through a cross-platform probabilistic execution protocol and\nprovides Markov chain Monte Carlo (MCMC) and deep-learning-based inference\ncompilation (IC) engines for tractable inference. To guide IC inference, we\nperform distributed training of a dynamic 3DCNN--LSTM architecture with a\nPyTorch-MPI-based framework on 1,024 32-core CPU nodes of the Cori\nsupercomputer with a global minibatch size of 128k: achieving a performance of\n450 Tflop/s through enhancements to PyTorch. We demonstrate a Large Hadron\nCollider (LHC) use-case with the C++ Sherpa simulator and achieve the\nlargest-scale posterior inference in a Turing-complete PPL.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jul 2019 02:03:36 GMT"}, {"version": "v2", "created": "Tue, 27 Aug 2019 13:26:21 GMT"}], "update_date": "2020-04-17", "authors_parsed": [["Baydin", "At\u0131l\u0131m G\u00fcne\u015f", ""], ["Shao", "Lei", ""], ["Bhimji", "Wahid", ""], ["Heinrich", "Lukas", ""], ["Meadows", "Lawrence", ""], ["Liu", "Jialin", ""], ["Munk", "Andreas", ""], ["Naderiparizi", "Saeid", ""], ["Gram-Hansen", "Bradley", ""], ["Louppe", "Gilles", ""], ["Ma", "Mingfei", ""], ["Zhao", "Xiaohui", ""], ["Torr", "Philip", ""], ["Lee", "Victor", ""], ["Cranmer", "Kyle", ""], ["Prabhat", "", ""], ["Wood", "Frank", ""]]}, {"id": "1907.03389", "submitter": "Ziliang Chen", "authors": "Ziliang Chen, Jingyu Zhuang, Xiaodan Liang and Liang Lin", "title": "Blending-target Domain Adaptation by Adversarial Meta-Adaptation\n  Networks", "comments": "CVPR-19 (oral). Code is available at\n  http://github.com/zjy526223908/BTDA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  (Unsupervised) Domain Adaptation (DA) seeks for classifying target instances\nwhen solely provided with source labeled and target unlabeled examples for\ntraining. Learning domain-invariant features helps to achieve this goal,\nwhereas it underpins unlabeled samples drawn from a single or multiple explicit\ntarget domains (Multi-target DA). In this paper, we consider a more realistic\ntransfer scenario: our target domain is comprised of multiple sub-targets\nimplicitly blended with each other, so that learners could not identify which\nsub-target each unlabeled sample belongs to. This Blending-target Domain\nAdaptation (BTDA) scenario commonly appears in practice and threatens the\nvalidities of most existing DA algorithms, due to the presence of domain gaps\nand categorical misalignments among these hidden sub-targets.\n  To reap the transfer performance gains in this new scenario, we propose\nAdversarial Meta-Adaptation Network (AMEAN). AMEAN entails two adversarial\ntransfer learning processes. The first is a conventional adversarial transfer\nto bridge our source and mixed target domains. To circumvent the intra-target\ncategory misalignment, the second process presents as ``learning to adapt'': It\ndeploys an unsupervised meta-learner receiving target data and their ongoing\nfeature-learning feedbacks, to discover target clusters as our\n``meta-sub-target'' domains. These meta-sub-targets auto-design our\nmeta-sub-target DA loss, which empirically eliminates the implicit category\nmismatching in our mixed target. We evaluate AMEAN and a variety of DA\nalgorithms in three benchmarks under the BTDA setup. Empirical results show\nthat BTDA is a quite challenging transfer setup for most existing DA\nalgorithms, yet AMEAN significantly outperforms these state-of-the-art\nbaselines and effectively restrains the negative transfer effects in BTDA.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jul 2019 02:54:35 GMT"}], "update_date": "2019-07-09", "authors_parsed": [["Chen", "Ziliang", ""], ["Zhuang", "Jingyu", ""], ["Liang", "Xiaodan", ""], ["Lin", "Liang", ""]]}, {"id": "1907.03395", "submitter": "Vineet Kosaraju", "authors": "Vineet Kosaraju, Amir Sadeghian, Roberto Mart\\'in-Mart\\'in, Ian Reid,\n  S. Hamid Rezatofighi, Silvio Savarese", "title": "Social-BiGAT: Multimodal Trajectory Forecasting using Bicycle-GAN and\n  Graph Attention Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Predicting the future trajectories of multiple interacting agents in a scene\nhas become an increasingly important problem for many different applications\nranging from control of autonomous vehicles and social robots to security and\nsurveillance. This problem is compounded by the presence of social interactions\nbetween humans and their physical interactions with the scene. While the\nexisting literature has explored some of these cues, they mainly ignored the\nmultimodal nature of each human's future trajectory. In this paper, we present\nSocial-BiGAT, a graph-based generative adversarial network that generates\nrealistic, multimodal trajectory predictions by better modelling the social\ninteractions of pedestrians in a scene. Our method is based on a graph\nattention network (GAT) that learns reliable feature representations that\nencode the social interactions between humans in the scene, and a recurrent\nencoder-decoder architecture that is trained adversarially to predict, based on\nthe features, the humans' paths. We explicitly account for the multimodal\nnature of the prediction problem by forming a reversible transformation between\neach scene and its latent noise vector, as in Bicycle-GAN. We show that our\nframework achieves state-of-the-art performance comparing it to several\nbaselines on existing trajectory forecasting benchmarks.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jul 2019 23:48:07 GMT"}, {"version": "v2", "created": "Wed, 17 Jul 2019 01:05:26 GMT"}], "update_date": "2019-07-18", "authors_parsed": [["Kosaraju", "Vineet", ""], ["Sadeghian", "Amir", ""], ["Mart\u00edn-Mart\u00edn", "Roberto", ""], ["Reid", "Ian", ""], ["Rezatofighi", "S. Hamid", ""], ["Savarese", "Silvio", ""]]}, {"id": "1907.03402", "submitter": "Sepidehsadat Hosseini", "authors": "Sepidehsadat Hosseini, Mohammad Amin Shabani, Nam Ik Cho", "title": "Distill-2MD-MTL: Data Distillation based on Multi-Dataset Multi-Domain\n  Multi-Task Frame Work to Solve Face Related Tasksks, Multi Task Learning,\n  Semi-Supervised Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new semi-supervised learning method on face-related tasks based\non Multi-Task Learning (MTL) and data distillation. The proposed method\nexploits multiple datasets with different labels for different-but-related\ntasks such as simultaneous age, gender, race, facial expression estimation.\nSpecifically, when there are only a few well-labeled data for a specific task\namong the multiple related ones, we exploit the labels of other related tasks\nin different domains. Our approach is composed of (1) a new MTL method which\ncan deal with weakly labeled datasets and perform several tasks simultaneously,\nand (2) an MTL-based data distillation framework which enables network\ngeneralization for the training and test data from different domains.\nExperiments show that the proposed multi-task system performs each task better\nthan the baseline single task. It is also demonstrated that using different\ndomain datasets along with the main dataset can enhance network generalization\nand overcome the domain differences between datasets. Also, comparing data\ndistillation both on the baseline and MTL framework, the latter shows more\naccurate predictions on unlabeled data from different domains. Furthermore, by\nproposing a new learning-rate optimization method, our proposed network is able\nto dynamically tune its learning rate.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jul 2019 04:36:32 GMT"}, {"version": "v2", "created": "Tue, 9 Jul 2019 02:57:13 GMT"}], "update_date": "2019-07-10", "authors_parsed": [["Hosseini", "Sepidehsadat", ""], ["Shabani", "Mohammad Amin", ""], ["Cho", "Nam Ik", ""]]}, {"id": "1907.03411", "submitter": "Micha{\\l} Derezi\\'nski", "authors": "Micha{\\l} Derezi\\'nski, Manfred K. Warmuth and Daniel Hsu", "title": "Unbiased estimators for random design regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In linear regression we wish to estimate the optimum linear least squares\npredictor for a distribution over d-dimensional input points and real-valued\nresponses, based on a small sample. Under standard random design analysis,\nwhere the sample is drawn i.i.d. from the input distribution, the least squares\nsolution for that sample can be viewed as the natural estimator of the optimum.\nUnfortunately, this estimator almost always incurs an undesirable bias coming\nfrom the randomness of the input points. In this paper we show that it is\npossible to draw a non-i.i.d. sample of input points such that, regardless of\nthe response model, the least squares solution is an unbiased estimator of the\noptimum. Moreover, this sample can be produced efficiently by augmenting a\npreviously drawn i.i.d. sample with an additional set of d points drawn jointly\nfrom the input distribution rescaled by the squared volume spanned by the\npoints. Motivated by this, we develop a theoretical framework for studying\nvolume-rescaled sampling, and in the process prove a number of new matrix\nexpectation identities. We use them to show that for any input distribution and\n$\\epsilon>0$ there is a random design consisting of $O(d\\log d+ d/\\epsilon)$\npoints from which an unbiased estimator can be constructed whose square loss\nover the entire distribution is with high probability bounded by $1+\\epsilon$\ntimes the loss of the optimum. We provide efficient algorithms for generating\nsuch unbiased estimators in a number of practical settings and support our\nclaims experimentally.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jul 2019 06:01:19 GMT"}], "update_date": "2019-07-09", "authors_parsed": [["Derezi\u0144ski", "Micha\u0142", ""], ["Warmuth", "Manfred K.", ""], ["Hsu", "Daniel", ""]]}, {"id": "1907.03419", "submitter": "Sebastien Martin", "authors": "Dimitris Bertsimas, Arthur Delarue, Patrick Jaillet, Sebastien Martin", "title": "The Price of Interpretability", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When quantitative models are used to support decision-making on complex and\nimportant topics, understanding a model's ``reasoning'' can increase trust in\nits predictions, expose hidden biases, or reduce vulnerability to adversarial\nattacks. However, the concept of interpretability remains loosely defined and\napplication-specific. In this paper, we introduce a mathematical framework in\nwhich machine learning models are constructed in a sequence of interpretable\nsteps. We show that for a variety of models, a natural choice of interpretable\nsteps recovers standard interpretability proxies (e.g., sparsity in linear\nmodels). We then generalize these proxies to yield a parametrized family of\nconsistent measures of model interpretability. This formal definition allows us\nto quantify the ``price'' of interpretability, i.e., the tradeoff with\npredictive accuracy. We demonstrate practical algorithms to apply our framework\non real and synthetic datasets.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jul 2019 06:42:59 GMT"}], "update_date": "2019-07-09", "authors_parsed": [["Bertsimas", "Dimitris", ""], ["Delarue", "Arthur", ""], ["Jaillet", "Patrick", ""], ["Martin", "Sebastien", ""]]}, {"id": "1907.03423", "submitter": "Ashwin Balakrishna", "authors": "Ashwin Balakrishna, Brijen Thananjeyan, Jonathan Lee, Felix Li, Arsh\n  Zahed, Joseph E. Gonzalez, Ken Goldberg", "title": "On-Policy Robot Imitation Learning from a Converging Supervisor", "comments": "Conference on Robot Learning (CoRL) 2019 Oral. First two authors\n  contributed equally", "journal-ref": "3rd Conference on Robot Learning (CoRL 2019)", "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing on-policy imitation learning algorithms, such as DAgger, assume\naccess to a fixed supervisor. However, there are many settings where the\nsupervisor may evolve during policy learning, such as a human performing a\nnovel task or an improving algorithmic controller. We formalize imitation\nlearning from a \"converging supervisor\" and provide sublinear static and\ndynamic regret guarantees against the best policy in hindsight with labels from\nthe converged supervisor, even when labels during learning are only from\nintermediate supervisors. We then show that this framework is closely connected\nto a class of reinforcement learning (RL) algorithms known as dual policy\niteration (DPI), which alternate between training a reactive learner with\nimitation learning and a model-based supervisor with data from the learner.\nExperiments suggest that when this framework is applied with the\nstate-of-the-art deep model-based RL algorithm PETS as an improving supervisor,\nit outperforms deep RL baselines on continuous control tasks and provides up to\nan 80-fold speedup in policy evaluation.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jul 2019 07:02:57 GMT"}, {"version": "v2", "created": "Thu, 26 Sep 2019 07:21:21 GMT"}, {"version": "v3", "created": "Fri, 27 Sep 2019 00:45:26 GMT"}, {"version": "v4", "created": "Tue, 8 Oct 2019 06:43:52 GMT"}, {"version": "v5", "created": "Sun, 20 Oct 2019 03:48:12 GMT"}, {"version": "v6", "created": "Wed, 20 Nov 2019 09:17:16 GMT"}, {"version": "v7", "created": "Sat, 16 May 2020 00:01:35 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Balakrishna", "Ashwin", ""], ["Thananjeyan", "Brijen", ""], ["Lee", "Jonathan", ""], ["Li", "Felix", ""], ["Zahed", "Arsh", ""], ["Gonzalez", "Joseph E.", ""], ["Goldberg", "Ken", ""]]}, {"id": "1907.03426", "submitter": "Ziliang Chen", "authors": "Ziliang Chen, Zhanfu Yang, Xiaoxi Wang, Xiaodan Liang, Xiaopeng Yan,\n  Guanbin Li and Liang Lin", "title": "Multivariate-Information Adversarial Ensemble for Scalable Joint\n  Distribution Matching", "comments": "ICML-19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A broad range of cross-$m$-domain generation researches boil down to matching\na joint distribution by deep generative models (DGMs). Hitherto algorithms\nexcel in pairwise domains while as $m$ increases, remain struggling to scale\nthemselves to fit a joint distribution. In this paper, we propose a\ndomain-scalable DGM, i.e., MMI-ALI for $m$-domain joint distribution matching.\nAs an $m$-domain ensemble model of ALIs \\cite{dumoulin2016adversarially},\nMMI-ALI is adversarially trained with maximizing Multivariate Mutual\nInformation (MMI) w.r.t. joint variables of each pair of domains and their\nshared feature. The negative MMIs are upper bounded by a series of feasible\nlosses that provably lead to matching $m$-domain joint distributions. MMI-ALI\nlinearly scales as $m$ increases and thus, strikes a right balance between\nefficacy and scalability. We evaluate MMI-ALI in diverse challenging $m$-domain\nscenarios and verify its superiority.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jul 2019 07:11:54 GMT"}], "update_date": "2019-07-09", "authors_parsed": [["Chen", "Ziliang", ""], ["Yang", "Zhanfu", ""], ["Wang", "Xiaoxi", ""], ["Liang", "Xiaodan", ""], ["Yan", "Xiaopeng", ""], ["Li", "Guanbin", ""], ["Lin", "Liang", ""]]}, {"id": "1907.03451", "submitter": "Aahlad Manas Puli", "authors": "Aahlad Manas Puli and Rajesh Ranganath", "title": "General Control Functions for Causal Effect Estimation from Instrumental\n  Variables", "comments": "24 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Causal effect estimation relies on separating the variation in the outcome\ninto parts due to the treatment and due to the confounders. To achieve this\nseparation, practitioners often use external sources of randomness that only\ninfluence the treatment called instrumental variables (IVs). We study variables\nconstructed from treatment and IV that help estimate effects, called control\nfunctions. We characterize general control functions for effect estimation in a\nmeta-identification result. Then, we show that structural assumptions on the\ntreatment process allow the construction of general control functions, thereby\nguaranteeing identification. To construct general control functions and\nestimate effects, we develop the general control function method (GCFN). GCFN's\nfirst stage called variational decoupling (VDE) constructs general control\nfunctions by recovering the residual variation in the treatment given the IV.\nUsing VDE's control function, GCFN's second stage estimates effects via\nregression. Further, we develop semi-supervised GCFN to construct general\ncontrol functions using subsets of data that have both IV and confounders\nobserved as supervision; this needs no structural treatment process\nassumptions. We evaluate GCFN on low and high dimensional simulated data and on\nrecovering the causal effect of slave export on modern community trust.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jul 2019 08:27:12 GMT"}, {"version": "v2", "created": "Tue, 2 Feb 2021 05:37:18 GMT"}], "update_date": "2021-02-03", "authors_parsed": [["Puli", "Aahlad Manas", ""], ["Ranganath", "Rajesh", ""]]}, {"id": "1907.03452", "submitter": "Ariel Neufeld", "authors": "Christian Beck, Sebastian Becker, Patrick Cheridito, Arnulf Jentzen,\n  and Ariel Neufeld", "title": "Deep splitting method for parabolic PDEs", "comments": "25 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.LG cs.NA math.PR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we introduce a numerical method for nonlinear parabolic PDEs\nthat combines operator splitting with deep learning. It divides the PDE\napproximation problem into a sequence of separate learning problems. Since the\ncomputational graph for each of the subproblems is comparatively small, the\napproach can handle extremely high-dimensional PDEs. We test the method on\ndifferent examples from physics, stochastic control and mathematical finance.\nIn all cases, it yields very good results in up to 10,000 dimensions with short\nrun times.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jul 2019 08:30:23 GMT"}, {"version": "v2", "created": "Mon, 21 Jun 2021 15:36:53 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Beck", "Christian", ""], ["Becker", "Sebastian", ""], ["Cheridito", "Patrick", ""], ["Jentzen", "Arnulf", ""], ["Neufeld", "Ariel", ""]]}, {"id": "1907.03483", "submitter": "Iain Barclay", "authors": "Iain Barclay, Alun Preece, Ian Taylor and Dinesh Verma", "title": "Quantifying Transparency of Machine Learning Systems through Analysis of\n  Contributions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Increased adoption and deployment of machine learning (ML) models into\nbusiness, healthcare and other organisational processes, will result in a\ngrowing disconnect between the engineers and researchers who developed the\nmodels and the model's users and other stakeholders, such as regulators or\nauditors. This disconnect is inevitable, as models begin to be used over a\nnumber of years or are shared among third parties through user communities or\nvia commercial marketplaces, and it will become increasingly difficult for\nusers to maintain ongoing insight into the suitability of the parties who\ncreated the model, or the data that was used to train it. This could become\nproblematic, particularly where regulations change and once-acceptable\nstandards become outdated, or where data sources are discredited, perhaps\njudged to be biased or corrupted, either deliberately or unwittingly. In this\npaper we present a method for arriving at a quantifiable metric capable of\nranking the transparency of the process pipelines used to generate ML models\nand other data assets, such that users, auditors and other stakeholders can\ngain confidence that they will be able to validate and trust the data sources\nand human contributors in the systems that they rely on for their business\noperations. The methodology for calculating the transparency metric, and the\ntype of criteria that could be used to make judgements on the visibility of\ncontributions to systems are explained and illustrated through an example\nscenario.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jul 2019 09:57:12 GMT"}], "update_date": "2019-07-09", "authors_parsed": [["Barclay", "Iain", ""], ["Preece", "Alun", ""], ["Taylor", "Ian", ""], ["Verma", "Dinesh", ""]]}, {"id": "1907.03495", "submitter": "Isaac Shiri", "authors": "Ghasem Hajianfar, Isaac Shiri, Hassan Maleki, Niki Oveisi, Abbass\n  Haghparast, Hamid Abdollahi, Mehrdad Oveisi", "title": "Non-Invasive MGMT Status Prediction in GBM Cancer Using Magnetic\n  Resonance Images (MRI) Radiomics Features: Univariate and Multivariate\n  Machine Learning Radiogenomics Analysis", "comments": "28 Pages, 5 Figures, 3 Tables, 6 Supplemental Figure", "journal-ref": "https://doi.org/10.1016/j.wneu.2019.08.232", "doi": "10.1016/j.wneu.2019.08.232", "report-no": null, "categories": "physics.med-ph cs.LG eess.IV q-bio.GN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Background and aim: This study aimed to predict methylation status of the O-6\nmethyl guanine-DNA methyl transferase (MGMT) gene promoter status by using MRI\nradiomics features, as well as univariate and multivariate analysis.\n  Material and Methods: Eighty-two patients who had a MGMT methylation status\nwere include in this study. Tumor were manually segmented in the four regions\nof MR images, a) whole tumor, b) active/enhanced region, c) necrotic regions\nand d) edema regions (E). About seven thousand radiomics features were\nextracted for each patient. Feature selection and classifier were used to\npredict MGMT status through different machine learning algorithms. The area\nunder the curve (AUC) of receiver operating characteristic (ROC) curve was used\nfor model evaluations.\n  Results: Regarding univariate analysis, the Inverse Variance feature from\ngray level co-occurrence matrix (GLCM) in Whole Tumor segment with 4.5 mm Sigma\nof Laplacian of Gaussian filter with AUC: 0.71 (p-value: 0.002) was found to be\nthe best predictor. For multivariate analysis, the decision tree classifier\nwith Select from Model feature selector and LOG filter in Edema region had the\nhighest performance (AUC: 0.78), followed by Ada Boost classifier with Select\nfrom Model feature selector and LOG filter in Edema region (AUC: 0.74).\n  Conclusion: This study showed that radiomics using machine learning\nalgorithms is a feasible, noninvasive approach to predict MGMT methylation\nstatus in GBM cancer patients\n  Keywords: Radiomics, Radiogenomics, GBM, MRI, MGMT\n", "versions": [{"version": "v1", "created": "Mon, 8 Jul 2019 10:26:57 GMT"}], "update_date": "2019-09-27", "authors_parsed": [["Hajianfar", "Ghasem", ""], ["Shiri", "Isaac", ""], ["Maleki", "Hassan", ""], ["Oveisi", "Niki", ""], ["Haghparast", "Abbass", ""], ["Abdollahi", "Hamid", ""], ["Oveisi", "Mehrdad", ""]]}, {"id": "1907.03507", "submitter": "Vikas Dwivedi", "authors": "Vikas Dwivedi, Balaji Srinivasan", "title": "Physics Informed Extreme Learning Machine (PIELM) -- A rapid method for\n  the numerical solution of partial differential equations", "comments": "29 pages, 30 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG physics.comp-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There has been rapid progress recently on the application of deep networks to\nthe solution of partial differential equations, collectively labelled as\nPhysics Informed Neural Networks (PINNs). In this paper, we develop Physics\nInformed Extreme Learning Machine (PIELM), a rapid version of PINNs which can\nbe applied to stationary and time dependent linear partial differential\nequations. We demonstrate that PIELM matches or exceeds the accuracy of PINNs\non a range of problems. We also discuss the limitations of neural network based\napproaches, including our PIELM, in the solution of PDEs on large domains and\nsuggest an extension, a distributed version of our algorithm -{}- DPIELM. We\nshow that DPIELM produces excellent results comparable to conventional\nnumerical techniques in the solution of time-dependent problems. Collectively,\nthis work contributes towards making the use of neural networks in the solution\nof partial differential equations in complex domains as a competitive\nalternative to conventional discretization techniques.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jul 2019 11:02:08 GMT"}], "update_date": "2019-07-09", "authors_parsed": [["Dwivedi", "Vikas", ""], ["Srinivasan", "Balaji", ""]]}, {"id": "1907.03511", "submitter": "Nicolas Scheiner", "authors": "Nicolas Scheiner, Nils Appenrodt, J\\\"urgen Dickmann, Bernhard Sick", "title": "A Multi-Stage Clustering Framework for Automotive Radar Data", "comments": "8 pages, 5 figures, accepted paper for 2019 IEEE 22nd Intelligent\n  Transportation Systems Conference (ITSC), Auckland, New Zealand, October 2019", "journal-ref": null, "doi": "10.1109/ITSC.2019.8916873", "report-no": null, "categories": "cs.LG cs.RO eess.IV eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Radar sensors provide a unique method for executing environmental perception\ntasks towards autonomous driving. Especially their capability to perform well\nin adverse weather conditions often makes them superior to other sensors such\nas cameras or lidar. Nevertheless, the high sparsity and low dimensionality of\nthe commonly used detection data level is a major challenge for subsequent\nsignal processing. Therefore, the data points are often merged in order to form\nlarger entities from which more information can be gathered. The merging\nprocess is often implemented in form of a clustering algorithm. This article\ndescribes a novel approach for first filtering out static background data\nbefore applying a twostage clustering approach. The two-stage clustering\nfollows the same paradigm as the idea for data association itself: First,\nclustering what is ought to belong together in a low dimensional parameter\nspace, then, extracting additional features from the newly created clusters in\norder to perform a final clustering step. Parameters are optimized for\nfiltering and both clustering steps. All techniques are assessed both\nindividually and as a whole in order to demonstrate their effectiveness. Final\nresults indicate clear benefits of the first two methods and also the cluster\nmerging process under specific circumstances.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jul 2019 11:10:16 GMT"}], "update_date": "2020-01-20", "authors_parsed": [["Scheiner", "Nicolas", ""], ["Appenrodt", "Nils", ""], ["Dickmann", "J\u00fcrgen", ""], ["Sick", "Bernhard", ""]]}, {"id": "1907.03532", "submitter": "Sarwar Khan", "authors": "Sarwar Khan", "title": "DeepAcid: Classification of macromolecule type based on sequences of\n  amino acids", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.BM cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The study of the amino acid sequence is vital in life sciences. In this\npaper, we are using deep learning to solve macromolecule classification problem\nusing amino acids. Deep learning has emerged as a strong and efficient\nframework that can be applied to a broad spectrum of complex learning problems\nwhich were difficult to solve using traditional machine learning techniques in\nthe past. We are using word embedding from NLP to represent the amino acid\nsequence as vectors. We are using different deep learning model for\nclassification of macromolecules like CNN, LSTM, and GRU. Convolution neural\nnetwork can extract features from amino acid sequences which are represented by\nvectors. The extracted features will be feed to a different type of model to\ntrain a robust classifier. our results show that Word2vec as embedding combine\nwith VGG-16 has better performance than LSTM and GRU. our approach gets an\nerror rate of 1.5%. Code is available at https://github.com/say2sarwar/DeepAcid\n", "versions": [{"version": "v1", "created": "Mon, 1 Jul 2019 03:49:01 GMT"}], "update_date": "2019-07-09", "authors_parsed": [["Khan", "Sarwar", ""]]}, {"id": "1907.03540", "submitter": "Mohamed Abdelfattah", "authors": "{\\L}ukasz Dudziak, Mohamed S. Abdelfattah, Ravichander Vipperla,\n  Stefanos Laskaridis, Nicholas D. Lane", "title": "ShrinkML: End-to-End ASR Model Compression Using Reinforcement Learning", "comments": "INTERSPEECH 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  End-to-end automatic speech recognition (ASR) models are increasingly large\nand complex to achieve the best possible accuracy. In this paper, we build an\nAutoML system that uses reinforcement learning (RL) to optimize the per-layer\ncompression ratios when applied to a state-of-the-art attention based\nend-to-end ASR model composed of several LSTM layers. We use singular value\ndecomposition (SVD) low-rank matrix factorization as the compression method.\nFor our RL-based AutoML system, we focus on practical considerations such as\nthe choice of the reward/punishment functions, the formation of an effective\nsearch space, and the creation of a representative but small data set for quick\nevaluation between search steps. Finally, we present accuracy results on\nLibriSpeech of the model compressed by our AutoML system, and we compare it to\nmanually-compressed models. Our results show that in the absence of retraining\nour RL-based search is an effective and practical method to compress a\nproduction-grade ASR system. When retraining is possible, we show that our\nAutoML system can select better highly-compressed seed models compared to\nmanually hand-crafted rank selection, thus allowing for more compression than\npreviously possible.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jul 2019 12:10:18 GMT"}, {"version": "v2", "created": "Tue, 24 Sep 2019 10:06:29 GMT"}], "update_date": "2019-09-25", "authors_parsed": [["Dudziak", "\u0141ukasz", ""], ["Abdelfattah", "Mohamed S.", ""], ["Vipperla", "Ravichander", ""], ["Laskaridis", "Stefanos", ""], ["Lane", "Nicholas D.", ""]]}, {"id": "1907.03572", "submitter": "Shreyan Chowdhury", "authors": "Shreyan Chowdhury, Andreu Vall, Verena Haunschmid, Gerhard Widmer", "title": "Towards Explainable Music Emotion Recognition: The Route via Mid-level\n  Features", "comments": "International Society for Music Information Retrieval Conference,\n  Delft, The Netherlands, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Emotional aspects play an important part in our interaction with music.\nHowever, modelling these aspects in MIR systems have been notoriously\nchallenging since emotion is an inherently abstract and subjective experience,\nthus making it difficult to quantify or predict in the first place, and to make\nsense of the predictions in the next. In an attempt to create a model that can\ngive a musically meaningful and intuitive explanation for its predictions, we\npropose a VGG-style deep neural network that learns to predict emotional\ncharacteristics of a musical piece together with (and based on)\nhuman-interpretable, mid-level perceptual features. We compare this to\npredicting emotion directly with an identical network that does not take into\naccount the mid-level features and observe that the loss in predictive\nperformance of going through the mid-level features is surprisingly low, on\naverage. The design of our network allows us to visualize the effects of\nperceptual features on individual emotion predictions, and we argue that the\nsmall loss in performance in going through the mid-level features is justified\nby the gain in explainability of the predictions.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jul 2019 12:58:02 GMT"}], "update_date": "2019-07-09", "authors_parsed": [["Chowdhury", "Shreyan", ""], ["Vall", "Andreu", ""], ["Haunschmid", "Verena", ""], ["Widmer", "Gerhard", ""]]}, {"id": "1907.03576", "submitter": "Ashis Banerjee", "authors": "Ekta U. Samani, Wei Guo, and Ashis G. Banerjee", "title": "Deep Learning-Based Semantic Segmentation of Microscale Objects", "comments": "A condensed version of the paper is published in the Proceedings of\n  the 2019 International Conference on Manipulation, Automation and Robotics at\n  Small Scales", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurate estimation of the positions and shapes of microscale objects is\ncrucial for automated imaging-guided manipulation using a non-contact technique\nsuch as optical tweezers. Perception methods that use traditional computer\nvision algorithms tend to fail when the manipulation environments are crowded.\nIn this paper, we present a deep learning model for semantic segmentation of\nthe images representing such environments. Our model successfully performs\nsegmentation with a high mean Intersection Over Union score of 0.91.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jul 2019 23:07:01 GMT"}], "update_date": "2019-07-09", "authors_parsed": [["Samani", "Ekta U.", ""], ["Guo", "Wei", ""], ["Banerjee", "Ashis G.", ""]]}, {"id": "1907.03588", "submitter": "Aritra Mitra", "authors": "Aritra Mitra, John A. Richards and Shreyas Sundaram", "title": "A New Approach to Distributed Hypothesis Testing and Non-Bayesian\n  Learning: Improved Learning Rate and Byzantine-Resilience", "comments": "arXiv admin note: text overlap with arXiv:1903.05817", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.IT cs.LG cs.SY math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a setting where a group of agents, each receiving partially\ninformative private signals, seek to collaboratively learn the true underlying\nstate of the world (from a finite set of hypotheses) that generates their joint\nobservation profiles. To solve this problem, we propose a distributed learning\nrule that differs fundamentally from existing approaches, in that it does not\nemploy any form of \"belief-averaging\". Instead, agents update their beliefs\nbased on a min-rule. Under standard assumptions on the observation model and\nthe network structure, we establish that each agent learns the truth\nasymptotically almost surely. As our main contribution, we prove that with\nprobability 1, each false hypothesis is ruled out by every agent exponentially\nfast at a network-independent rate that is strictly larger than existing rates.\nWe then develop a computationally-efficient variant of our learning rule that\nis provably resilient to agents who do not behave as expected (as represented\nby a Byzantine adversary model) and deliberately try to spread misinformation.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jul 2019 17:16:14 GMT"}], "update_date": "2019-07-09", "authors_parsed": [["Mitra", "Aritra", ""], ["Richards", "John A.", ""], ["Sundaram", "Shreyas", ""]]}, {"id": "1907.03591", "submitter": "Junyu Chen", "authors": "Junyu Chen and Eric C. Frey", "title": "Feature-Based Image Clustering and Segmentation Using Wavelets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pixel intensity is a widely used feature for clustering and segmentation\nalgorithms, the resulting segmentation using only intensity values might suffer\nfrom noises and lack of spatial context information. Wavelet transform is often\nused for image denoising and classification. We proposed a novel method to\nincorporate Wavelet features in segmentation and clustering algorithms. The\nconventional K-means, Fuzzy c-means (FCM), and Active contour without edges\n(ACWE) algorithms were modified to adapt Wavelet features, leading to robust\nclustering/segmentation algorithms. A weighting parameter to control the weight\nof low-frequency sub-band information was also introduced. The new algorithms\nshowed the capability to converge to different segmentation results based on\nthe frequency information derived from the Wavelet sub-bands.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jul 2019 02:30:07 GMT"}], "update_date": "2019-07-09", "authors_parsed": [["Chen", "Junyu", ""], ["Frey", "Eric C.", ""]]}, {"id": "1907.03613", "submitter": "Yuxiang Yang", "authors": "Yuxiang Yang, Ken Caluwaerts, Atil Iscen, Tingnan Zhang, Jie Tan,\n  Vikas Sindhwani", "title": "Data Efficient Reinforcement Learning for Legged Robots", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a model-based framework for robot locomotion that achieves walking\nbased on only 4.5 minutes (45,000 control steps) of data collected on a\nquadruped robot. To accurately model the robot's dynamics over a long horizon,\nwe introduce a loss function that tracks the model's prediction over multiple\ntimesteps. We adapt model predictive control to account for planning latency,\nwhich allows the learned model to be used for real time control. Additionally,\nto ensure safe exploration during model learning, we embed prior knowledge of\nleg trajectories into the action space. The resulting system achieves fast and\nrobust locomotion. Unlike model-free methods, which optimize for a particular\ntask, our planner can use the same learned dynamics for various tasks, simply\nby changing the reward function. To the best of our knowledge, our approach is\nmore than an order of magnitude more sample efficient than current model-free\nmethods.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jul 2019 13:43:06 GMT"}, {"version": "v2", "created": "Sun, 6 Oct 2019 18:56:57 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Yang", "Yuxiang", ""], ["Caluwaerts", "Ken", ""], ["Iscen", "Atil", ""], ["Zhang", "Tingnan", ""], ["Tan", "Jie", ""], ["Sindhwani", "Vikas", ""]]}, {"id": "1907.03620", "submitter": "Gregor Ulm", "authors": "Gregor Ulm, Simon Smith, Adrian Nilsson, Emil Gustavsson, Mats\n  Jirstrand", "title": "Contraction Clustering (RASTER): A Very Fast Big Data Algorithm for\n  Sequential and Parallel Density-Based Clustering in Linear Time, Constant\n  Memory, and a Single Pass", "comments": "19 pages; journal paper extending a previous conference publication\n  (cf. https://doi.org/10.1007/978-3-319-72926-8_6)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clustering is an essential data mining tool for analyzing and grouping\nsimilar objects. In big data applications, however, many clustering algorithms\nare infeasible due to their high memory requirements and/or unfavorable runtime\ncomplexity. In contrast, Contraction Clustering (RASTER) is a single-pass\nalgorithm for identifying density-based clusters with linear time complexity.\nDue to its favorable runtime and the fact that its memory requirements are\nconstant, this algorithm is highly suitable for big data applications where the\namount of data to be processed is huge. It consists of two steps: (1) a\ncontraction step which projects objects onto tiles and (2) an agglomeration\nstep which groups tiles into clusters. This algorithm is extremely fast in both\nsequential and parallel execution. Our quantitative evaluation shows that a\nsequential implementation of RASTER performs significantly better than various\nstandard clustering algorithms. Furthermore, the parallel speedup is\nsignificant: on a contemporary workstation, an implementation in Rust processes\na batch of 500 million points with 1 million clusters in less than 50 seconds\non one core. With 8 cores, the algorithm is about four times faster.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jul 2019 14:00:07 GMT"}, {"version": "v2", "created": "Wed, 29 Jan 2020 15:50:32 GMT"}], "update_date": "2020-01-30", "authors_parsed": [["Ulm", "Gregor", ""], ["Smith", "Simon", ""], ["Nilsson", "Adrian", ""], ["Gustavsson", "Emil", ""], ["Jirstrand", "Mats", ""]]}, {"id": "1907.03626", "submitter": "Wei Dai", "authors": "Wei Dai and Daniel Berleant", "title": "Benchmarking Contemporary Deep Learning Hardware and Frameworks:A Survey\n  of Qualitative Metrics", "comments": "8 pages, 4 figures, 2 tables", "journal-ref": null, "doi": "10.1109/CogMI48466.2019.00029", "report-no": null, "categories": "cs.DC cs.LG cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper surveys benchmarking principles, machine learning devices\nincluding GPUs, FPGAs, and ASICs, and deep learning software frameworks. It\nalso reviews these technologies with respect to benchmarking from the\nperspectives of a 6-metric approach to frameworks and an 11-metric approach to\nhardware platforms. Because MLPerf is a benchmark organization working with\nindustry and academia, and offering deep learning benchmarks that evaluate\ntraining and inference on deep learning hardware devices, the survey also\nmentions MLPerf benchmark results, benchmark metrics, datasets, deep learning\nframeworks and algorithms. We summarize seven benchmarking principles,\ndifferential characteristics of mainstream AI devices, and qualitative\ncomparison of deep learning hardware and frameworks.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jul 2019 14:09:06 GMT"}, {"version": "v2", "created": "Tue, 9 Jul 2019 19:17:33 GMT"}, {"version": "v3", "created": "Sat, 19 Oct 2019 18:30:38 GMT"}, {"version": "v4", "created": "Sat, 23 Nov 2019 21:29:27 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Dai", "Wei", ""], ["Berleant", "Daniel", ""]]}, {"id": "1907.03641", "submitter": "Hossein Mohammadi Rouzbahani", "authors": "Hossein Mohammadi Rouzbahani, Abolfazl Rahimnezhad and Hadis\n  Karimipour", "title": "Smart Households Demand Response Management with Micro Grid", "comments": "ISGT 2018", "journal-ref": null, "doi": "10.1109/ISGT.2019.8791595", "report-no": null, "categories": "eess.SY cs.LG cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays the emerging smart grid technology opens up the possibility of\ntwo-way communication between customers and energy utilities. Demand Response\nManagement (DRM) offers the promise of saving money for commercial customers\nand households while helps utilities operate more efficiently. In this paper,\nan Incentive-based Demand Response Optimization (IDRO) model is proposed to\nefficiently schedule household appliances for minimum usage during peak hours.\nThe proposed method is a multi-objective optimization technique based on\nNonlinear Auto-Regressive Neural Network (NAR-NN) which considers energy\nprovided by the utility and rooftop installed photovoltaic (PV) system. The\nproposed method is tested and verified using 300 case studies (household). Data\nanalysis for a period of one year shows a noticeable improvement in power\nfactor and customers bill.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jul 2019 14:21:37 GMT"}], "update_date": "2019-12-06", "authors_parsed": [["Rouzbahani", "Hossein Mohammadi", ""], ["Rahimnezhad", "Abolfazl", ""], ["Karimipour", "Hadis", ""]]}, {"id": "1907.03651", "submitter": "Berk Gulmezoglu", "authors": "Berk Gulmezoglu, Ahmad Moghimi, Thomas Eisenbarth, Berk Sunar", "title": "FortuneTeller: Predicting Microarchitectural Attacks via Unsupervised\n  Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The growing security threat of microarchitectural attacks underlines the\nimportance of robust security sensors and detection mechanisms at the hardware\nlevel. While there are studies on runtime detection of cache attacks, a generic\nmodel to consider the broad range of existing and future attacks is missing.\nUnfortunately, previous approaches only consider either a single attack\nvariant, e.g. Prime+Probe, or specific victim applications such as\ncryptographic implementations. Furthermore, the state-of-the art anomaly\ndetection methods are based on coarse-grained statistical models, which are not\nsuccessful to detect anomalies in a large-scale real world systems. Thanks to\nthe memory capability of advanced Recurrent Neural Networks (RNNs) algorithms,\nboth short and long term dependencies can be learned more accurately.\nTherefore, we propose FortuneTeller, which for the first time leverages the\nsuperiority of RNNs to learn complex execution patterns and detects unseen\nmicroarchitectural attacks in real world systems. FortuneTeller models benign\nworkload pattern from a microarchitectural standpoint in an unsupervised\nfashion, and then, it predicts how upcoming benign executions are supposed to\nbehave. Potential attacks and malicious behaviors will be detected\nautomatically, when there is a discrepancy between the predicted execution\npattern and the runtime observation. We implement FortuneTeller based on the\navailable hardware performance counters on Intel processors and it is trained\nwith 10 million samples obtained from benign applications. For the first time,\nthe latest attacks such as Meltdown, Spectre, Rowhammer and Zombieload are\ndetected with one trained model and without observing these attacks during the\ntraining. We show that FortuneTeller achieves F-score of 0.9970.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jul 2019 14:40:08 GMT"}], "update_date": "2019-07-09", "authors_parsed": [["Gulmezoglu", "Berk", ""], ["Moghimi", "Ahmad", ""], ["Eisenbarth", "Thomas", ""], ["Sunar", "Berk", ""]]}, {"id": "1907.03680", "submitter": "Sarah Dean", "authors": "Sarah Dean, Nikolai Matni, Benjamin Recht, Vickie Ye", "title": "Robust Guarantees for Perception-Based Control", "comments": "This revision includes reframing the local generalization problem,\n  with relaxed the assumptions so that the robust problem depends on a local\n  slope bound rather than a Lipschitz constant, and provide a method for\n  learning the slope bound from data. We also include additional experiments\n  with a CNN perception module", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by vision-based control of autonomous vehicles, we consider the\nproblem of controlling a known linear dynamical system for which partial state\ninformation, such as vehicle position, is extracted from complex and nonlinear\ndata, such as a camera image. Our approach is to use a learned perception map\nthat predicts some linear function of the state and to design a corresponding\nsafe set and robust controller for the closed loop system with this sensing\nscheme. We show that under suitable smoothness assumptions on both the\nperception map and the generative model relating state to complex and nonlinear\ndata, parameters of the safe set can be learned via appropriately dense\nsampling of the state space. We then prove that the resulting\nperception-control loop has favorable generalization properties. We illustrate\nthe usefulness of our approach on a synthetic example and on the self-driving\ncar simulation platform CARLA.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jul 2019 15:35:56 GMT"}, {"version": "v2", "created": "Mon, 23 Dec 2019 13:46:56 GMT"}], "update_date": "2019-12-24", "authors_parsed": [["Dean", "Sarah", ""], ["Matni", "Nikolai", ""], ["Recht", "Benjamin", ""], ["Ye", "Vickie", ""]]}, {"id": "1907.03687", "submitter": "Hado van Hasselt", "authors": "Hado van Hasselt, John Quan, Matteo Hessel, Zhongwen Xu, Diana Borsa,\n  Andre Barreto", "title": "General non-linear Bellman equations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a general class of non-linear Bellman equations. These open up a\ndesign space of algorithms that have interesting properties, which has two\npotential advantages. First, we can perhaps better model natural phenomena. For\ninstance, hyperbolic discounting has been proposed as a mathematical model that\nmatches human and animal data well, and can therefore be used to explain\npreference orderings. We present a different mathematical model that matches\nthe same data, but that makes very different predictions under other\ncircumstances. Second, the larger design space can perhaps lead to algorithms\nthat perform better, similar to how discount factors are often used in practice\neven when the true objective is undiscounted. We show that many of the\nresulting Bellman operators still converge to a fixed point, and therefore that\nthe resulting algorithms are reasonable and inherit many beneficial properties\nof their linear counterparts.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jul 2019 15:51:01 GMT"}], "update_date": "2019-07-09", "authors_parsed": [["van Hasselt", "Hado", ""], ["Quan", "John", ""], ["Hessel", "Matteo", ""], ["Xu", "Zhongwen", ""], ["Borsa", "Diana", ""], ["Barreto", "Andre", ""]]}, {"id": "1907.03693", "submitter": "Bhaskar Mitra", "authors": "Bhaskar Mitra, Corby Rosset, David Hawking, Nick Craswell, Fernando\n  Diaz and Emine Yilmaz", "title": "Incorporating Query Term Independence Assumption for Efficient Retrieval\n  and Ranking using Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classical information retrieval (IR) methods, such as query likelihood and\nBM25, score documents independently w.r.t. each query term, and then accumulate\nthe scores. Assuming query term independence allows precomputing term-document\nscores using these models---which can be combined with specialized data\nstructures, such as inverted index, for efficient retrieval. Deep neural IR\nmodels, in contrast, compare the whole query to the document and are,\ntherefore, typically employed only for late stage re-ranking. We incorporate\nquery term independence assumption into three state-of-the-art neural IR\nmodels: BERT, Duet, and CKNRM---and evaluate their performance on a passage\nranking task. Surprisingly, we observe no significant loss in result quality\nfor Duet and CKNRM---and a small degradation in the case of BERT. However, by\noperating on each query term independently, these otherwise computationally\nintensive models become amenable to offline precomputation---dramatically\nreducing the cost of query evaluations employing state-of-the-art neural\nranking models. This strategy makes it practical to use deep models for\nretrieval from large collections---and not restrict their usage to late stage\nre-ranking.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jul 2019 15:58:11 GMT"}], "update_date": "2019-07-09", "authors_parsed": [["Mitra", "Bhaskar", ""], ["Rosset", "Corby", ""], ["Hawking", "David", ""], ["Craswell", "Nick", ""], ["Diaz", "Fernando", ""], ["Yilmaz", "Emine", ""]]}, {"id": "1907.03697", "submitter": "Natalia Efremova", "authors": "Natalia Efremova and Dmitry Zausaev and Gleb Antipov", "title": "Prediction of Soil Moisture Content Based On Satellite Data and\n  Sequence-to-Sequence Networks", "comments": "Presented on NeurIPS 2018 WiML workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The main objective of this study is to combine remote sensing and machine\nlearning to detect soil moisture content. Growing population and food\nconsumption has led to the need to improve agricultural yield and to reduce\nwastage of natural resources. In this paper, we propose a neural network\narchitecture, based on recent work by the research community, that can make a\nstrong social impact and aid United Nations Sustainable Development Goal of\nZero Hunger. The main aims here are to: improve efficiency of water usage;\nreduce dependence on irrigation; increase overall crop yield; minimise risk of\ncrop loss due to drought and extreme weather conditions. We achieve this by\napplying satellite imagery, crop segmentation, soil classification and NDVI and\nsoil moisture prediction on satellite data, ground truth and climate data\nrecords. By applying machine learning to sensor data and ground data, farm\nmanagement systems can evolve into a real time AI enabled platform that can\nprovide actionable recommendations and decision support tools to the farmers.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jun 2019 11:03:17 GMT"}], "update_date": "2019-07-09", "authors_parsed": [["Efremova", "Natalia", ""], ["Zausaev", "Dmitry", ""], ["Antipov", "Gleb", ""]]}, {"id": "1907.03698", "submitter": "Ts\\`i-U\\'i \\.Ik", "authors": "Yu-Chuan Huang, I-No Liao, Ching-Hsuan Chen, Ts\\`i-U\\'i \\.Ik, Wen-Chih\n  Peng", "title": "TrackNet: A Deep Learning Network for Tracking High-speed and Tiny\n  Objects in Sports Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.MM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ball trajectory data are one of the most fundamental and useful information\nin the evaluation of players' performance and analysis of game strategies.\nAlthough vision-based object tracking techniques have been developed to analyze\nsport competition videos, it is still challenging to recognize and position a\nhigh-speed and tiny ball accurately. In this paper, we develop a deep learning\nnetwork, called TrackNet, to track the tennis ball from broadcast videos in\nwhich the ball images are small, blurry, and sometimes with afterimage tracks\nor even invisible. The proposed heatmap-based deep learning network is trained\nto not only recognize the ball image from a single frame but also learn flying\npatterns from consecutive frames. TrackNet takes images with a size of\n$640\\times360$ to generate a detection heatmap from either a single frame or\nseveral consecutive frames to position the ball and can achieve high precision\neven on public domain videos. The network is evaluated on the video of the\nmen's singles final at the 2017 Summer Universiade, which is available on\nYouTube. The precision, recall, and F1-measure of TrackNet reach $99.7\\%$,\n$97.3\\%$, and $98.5\\%$, respectively. To prevent overfitting, 9 additional\nvideos are partially labeled together with a subset from the previous dataset\nto implement 10-fold cross-validation, and the precision, recall, and\nF1-measure are $95.3\\%$, $75.7\\%$, and $84.3\\%$, respectively. A conventional\nimage processing algorithm is also implemented to compare with TrackNet. Our\nexperiments indicate that TrackNet outperforms conventional method by a big\nmargin and achieves exceptional ball tracking performance. The dataset and demo\nvideo are available at https://nol.cs.nctu.edu.tw/ndo3je6av9/.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jul 2019 16:08:43 GMT"}], "update_date": "2019-07-09", "authors_parsed": [["Huang", "Yu-Chuan", ""], ["Liao", "I-No", ""], ["Chen", "Ching-Hsuan", ""], ["\u0130k", "Ts\u00ec-U\u00ed", ""], ["Peng", "Wen-Chih", ""]]}, {"id": "1907.03702", "submitter": "Nagesh Chandra Kanth", "authors": "Raghav Lakhotia, Chandra Kanth Nagesh, Krishna Madgula", "title": "Identifying Missing Component in the Bechdel Test Using Principal\n  Component Analysis Method", "comments": "8 pages, 6 images, Published in the Proceedings of International\n  Conference on Machine Learning and Applications (ICMLA), 324 - 331, June\n  2019, Copenhagen, Denmark, Recipient of the Best Paper Award", "journal-ref": "World Academy of Science, Engineering and Technology International\n  Journal of Computer and Systems Engineering Vol:13, No:6, 2019", "doi": "10.5281/zenodo.3299335", "report-no": null, "categories": "cs.CY cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A lot has been said and discussed regarding the rationale and significance of\nthe Bechdel Score. It became a digital sensation in 2013 when Swedish cinemas\nbegan to showcase the Bechdel test score of a film alongside its rating. The\ntest has drawn criticism from experts and the film fraternity regarding its use\nto rate the female presence in a movie. The pundits believe that the score is\ntoo simplified and the underlying criteria of a film to pass the test must\ninclude 1) at least two women, 2) who have at least one dialogue, 3) about\nsomething other than a man, is egregious. In this research, we have considered\na few more parameters which highlight how we represent females in film, like\nthe number of female dialogues in a movie, dialogue genre, and part of speech\ntags in the dialogue. The parameters were missing in the existing criteria to\ncalculate the Bechdel score. The research aims to analyze 342 movies scripts to\ntest a hypothesis if these extra parameters, above with the current Bechdel\ncriteria, are significant in calculating the female representation score. The\nresult of the Principal Component Analysis method concludes that the female\ndialogue content is a key component and should be considered while measuring\nthe representation of women in a work of fiction.\n", "versions": [{"version": "v1", "created": "Wed, 19 Jun 2019 15:09:35 GMT"}, {"version": "v2", "created": "Mon, 23 Nov 2020 06:52:51 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Lakhotia", "Raghav", ""], ["Nagesh", "Chandra Kanth", ""], ["Madgula", "Krishna", ""]]}, {"id": "1907.03712", "submitter": "Eric Mazumdar", "authors": "Eric Mazumdar, Lillian J. Ratliff, Michael I. Jordan, S. Shankar\n  Sastry", "title": "Policy-Gradient Algorithms Have No Guarantees of Convergence in Linear\n  Quadratic Games", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show by counterexample that policy-gradient algorithms have no guarantees\nof even local convergence to Nash equilibria in continuous action and state\nspace multi-agent settings. To do so, we analyze gradient-play in N-player\ngeneral-sum linear quadratic games, a classic game setting which is recently\nemerging as a benchmark in the field of multi-agent learning. In such games the\nstate and action spaces are continuous and global Nash equilibria can be found\nbe solving coupled Ricatti equations. Further, gradient-play in LQ games is\nequivalent to multi agent policy-gradient. We first show that these games are\nsurprisingly not convex games. Despite this, we are still able to show that the\nonly critical points of the gradient dynamics are global Nash equilibria. We\nthen give sufficient conditions under which policy-gradient will avoid the Nash\nequilibria, and generate a large number of general-sum linear quadratic games\nthat satisfy these conditions. In such games we empirically observe the players\nconverging to limit cycles for which the time average does not coincide with a\nNash equilibrium. The existence of such games indicates that one of the most\npopular approaches to solving reinforcement learning problems in the classic\nreinforcement learning setting has no local guarantee of convergence in\nmulti-agent settings. Further, the ease with which we can generate these\ncounterexamples suggests that such situations are not mere edge cases and are\nin fact quite common.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jul 2019 16:35:03 GMT"}, {"version": "v2", "created": "Mon, 16 Dec 2019 20:32:31 GMT"}], "update_date": "2019-12-18", "authors_parsed": [["Mazumdar", "Eric", ""], ["Ratliff", "Lillian J.", ""], ["Jordan", "Michael I.", ""], ["Sastry", "S. Shankar", ""]]}, {"id": "1907.03715", "submitter": "Junmei Zhong", "authors": "Junmei Zhong, William Li", "title": "Predicting Customer Call Intent by Analyzing Phone Call Transcripts\n  based on CNN for Multi-Class Classification", "comments": "12 pages, 4 figures. 8th International Conference on Soft Computing,\n  Artificial Intelligence and Applications (SAI 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Auto dealerships receive thousands of calls daily from customers who are\ninterested in sales, service, vendors and jobseekers. With so many calls, it is\nvery important for auto dealers to understand the intent of these calls to\nprovide positive customer experiences that ensure customer satisfaction, deep\ncustomer engagement to boost sales and revenue, and optimum allocation of\nagents or customer service representatives across the business. In this paper,\nwe define the problem of customer phone call intent as a multi-class\nclassification problem stemming from the large database of recorded phone call\ntranscripts. To solve this problem, we develop a convolutional neural network\n(CNN)-based supervised learning model to classify the customer calls into four\nintent categories: sales, service, vendor and jobseeker. Experimental results\nshow that with the thrust of our scalable data labeling method to provide\nsufficient training data, the CNN-based predictive model performs very well on\nlong text classification according to the quantitative metrics of F1-Score,\nprecision, recall, and accuracy.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jul 2019 16:39:23 GMT"}], "update_date": "2019-07-09", "authors_parsed": [["Zhong", "Junmei", ""], ["Li", "William", ""]]}, {"id": "1907.03741", "submitter": "Ivan Glasser", "authors": "Ivan Glasser, Ryan Sweke, Nicola Pancotti, Jens Eisert, J. Ignacio\n  Cirac", "title": "Expressive power of tensor-network factorizations for probabilistic\n  modeling, with applications from hidden Markov models to quantum machine\n  learning", "comments": "14 pages + 14 pages supplementary material, extended version, code\n  available at\n  http://github.com/glivan/tensor_networks_for_probabilistic_modeling", "journal-ref": "Advances in Neural Information Processing Systems 32, Proceedings\n  of the NeurIPS 2019 Conference", "doi": null, "report-no": null, "categories": "cs.LG cond-mat.str-el math.OC quant-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tensor-network techniques have enjoyed outstanding success in physics, and\nhave recently attracted attention in machine learning, both as a tool for the\nformulation of new learning algorithms and for enhancing the mathematical\nunderstanding of existing methods. Inspired by these developments, and the\nnatural correspondence between tensor networks and probabilistic graphical\nmodels, we provide a rigorous analysis of the expressive power of various\ntensor-network factorizations of discrete multivariate probability\ndistributions. These factorizations include non-negative tensor-trains/MPS,\nwhich are in correspondence with hidden Markov models, and Born machines, which\nare naturally related to local quantum circuits. When used to model probability\ndistributions, they exhibit tractable likelihoods and admit efficient learning\nalgorithms. Interestingly, we prove that there exist probability distributions\nfor which there are unbounded separations between the resource requirements of\nsome of these tensor-network factorizations. Particularly surprising is the\nfact that using complex instead of real tensors can lead to an arbitrarily\nlarge reduction in the number of parameters of the network. Additionally, we\nintroduce locally purified states (LPS), a new factorization inspired by\ntechniques for the simulation of quantum systems, with provably better\nexpressive power than all other representations considered. The ramifications\nof this result are explored through numerical experiments. Our findings imply\nthat LPS should be considered over hidden Markov models, and furthermore\nprovide guidelines for the design of local quantum circuits for probabilistic\nmodeling.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jul 2019 17:54:26 GMT"}, {"version": "v2", "created": "Fri, 29 Nov 2019 14:20:27 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Glasser", "Ivan", ""], ["Sweke", "Ryan", ""], ["Pancotti", "Nicola", ""], ["Eisert", "Jens", ""], ["Cirac", "J. Ignacio", ""]]}, {"id": "1907.03742", "submitter": "Stella Biderman", "authors": "Stella Rose Biderman", "title": "Neural Networks on Groups", "comments": "Under review at NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG math.FA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although neural networks traditionally are typically used to approximate\nfunctions defined over $\\mathbb{R}^n$, the successes of graph neural networks,\npoint-cloud neural networks, and manifold deep learning among other methods\nhave demonstrated the clear value of leveraging neural networks to approximate\nfunctions defined over more general spaces. The theory of neural networks has\nnot kept up however,and the relevant theoretical results (when they exist at\nall) have been proven on a case-by-case basis without a general theory or\nconnection to classical work. The process of deriving new theoretical backing\nfor each new type of network has become a bottleneck to understanding and\nvalidating new approaches.\n  In this paper we extend the definition of neural networks to general\ntopological groups and prove that neural networks with a single hidden layer\nand a bounded non-constant activation function can approximate any\n$\\mathcal{L}^p$ function defined over any locally compact Abelian group. This\nframework and universal approximation theorem encompass all of the\naforementioned contexts. We also derive important corollaries and extensions\nwith minor modification, including the case for approximating continuous\nfunctions on a compact subset, neural networks with ReLU activation functions\non a linearly bi-ordered group, and neural networks with affine transformations\non a vector space. Our work obtains as special cases the recent theorems of Qi\net al. [2017], Sennai et al. [2019], Keriven and Peyre [2019], and Maron et al.\n[2019]\n", "versions": [{"version": "v1", "created": "Thu, 13 Jun 2019 01:34:12 GMT"}, {"version": "v2", "created": "Tue, 9 Jul 2019 22:36:51 GMT"}], "update_date": "2019-07-11", "authors_parsed": [["Biderman", "Stella Rose", ""]]}, {"id": "1907.03748", "submitter": "Carolin Lawrence", "authors": "Laura Jehl, Carolin Lawrence, Stefan Riezler", "title": "Learning Neural Sequence-to-Sequence Models from Weak Feedback with\n  Bipolar Ramp Loss", "comments": "Transactions of the Association for Computational Linguistics 2019\n  Vol. 7, 233-248. Presented at ACL, Florence, Italy", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In many machine learning scenarios, supervision by gold labels is not\navailable and consequently neural models cannot be trained directly by maximum\nlikelihood estimation (MLE). In a weak supervision scenario, metric-augmented\nobjectives can be employed to assign feedback to model outputs, which can be\nused to extract a supervision signal for training. We present several\nobjectives for two separate weakly supervised tasks, machine translation and\nsemantic parsing. We show that objectives should actively discourage negative\noutputs in addition to promoting a surrogate gold structure. This notion of\nbipolarity is naturally present in ramp loss objectives, which we adapt to\nneural models. We show that bipolar ramp loss objectives outperform other\nnon-bipolar ramp loss objectives and minimum risk training (MRT) on both weakly\nsupervised tasks, as well as on a supervised machine translation task.\nAdditionally, we introduce a novel token-level ramp loss objective, which is\nable to outperform even the best sequence-level ramp loss on both weakly\nsupervised tasks.\n", "versions": [{"version": "v1", "created": "Sat, 6 Jul 2019 10:04:12 GMT"}], "update_date": "2019-07-10", "authors_parsed": [["Jehl", "Laura", ""], ["Lawrence", "Carolin", ""], ["Riezler", "Stefan", ""]]}, {"id": "1907.03750", "submitter": "Hongliang Dai", "authors": "Hongliang Dai and Yangqiu Song", "title": "Neural Aspect and Opinion Term Extraction with Mined Rules as Weak\n  Supervision", "comments": "ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Lack of labeled training data is a major bottleneck for neural network based\naspect and opinion term extraction on product reviews. To alleviate this\nproblem, we first propose an algorithm to automatically mine extraction rules\nfrom existing training examples based on dependency parsing results. The mined\nrules are then applied to label a large amount of auxiliary data. Finally, we\nstudy training procedures to train a neural model which can learn from both the\ndata automatically labeled by the rules and a small amount of data accurately\nannotated by human. Experimental results show that although the mined rules\nthemselves do not perform well due to their limited flexibility, the\ncombination of human annotated data and rule labeled auxiliary data can improve\nthe neural model and allow it to achieve performance better than or comparable\nwith the current state-of-the-art.\n", "versions": [{"version": "v1", "created": "Sun, 7 Jul 2019 12:59:04 GMT"}], "update_date": "2019-07-10", "authors_parsed": [["Dai", "Hongliang", ""], ["Song", "Yangqiu", ""]]}, {"id": "1907.03752", "submitter": "Vukosi Marivate", "authors": "Vukosi Marivate, Tshephisho Sefara", "title": "Improving short text classification through global augmentation methods", "comments": "Final version published in CD-MAKE 2020: Machine Learning and\n  Knowledge Extraction pp 385-399", "journal-ref": "Machine Learning and Knowledge Extraction. CD-MAKE 2020. Lecture\n  Notes in Computer Science, vol 12279 (2020)", "doi": "10.1007/978-3-030-57321-8_21", "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the effect of different approaches to text augmentation. To do this\nwe use 3 datasets that include social media and formal text in the form of news\narticles. Our goal is to provide insights for practitioners and researchers on\nmaking choices for augmentation for classification use cases. We observe that\nWord2vec-based augmentation is a viable option when one does not have access to\na formal synonym model (like WordNet-based augmentation). The use of\n\\emph{mixup} further improves performance of all text based augmentations and\nreduces the effects of overfitting on a tested deep learning model. Round-trip\ntranslation with a translation service proves to be harder to use due to cost\nand as such is less accessible for both normal and low resource use-cases.\n", "versions": [{"version": "v1", "created": "Sun, 7 Jul 2019 18:05:12 GMT"}, {"version": "v2", "created": "Thu, 10 Dec 2020 14:41:38 GMT"}], "update_date": "2020-12-11", "authors_parsed": [["Marivate", "Vukosi", ""], ["Sefara", "Tshephisho", ""]]}, {"id": "1907.03755", "submitter": "Ahmed BaniMustafa", "authors": "Ahmed BaniMustafa and Nigel Hardy", "title": "Applications of a Novel Knowledge Discovery and Data Mining Process\n  Model for Metabolomics", "comments": "references information updated", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.DB cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work demonstrates the execution of a novel process model for knowledge\ndiscovery and data mining for metabolomics (MeKDDaM). It aims to illustrate\nMeKDDaM process model applicability using four different real-world\napplications and to highlight its strengths and unique features. The\ndemonstrated applications provide coverage for metabolite profiling, target\nanalysis, and metabolic fingerprinting. The data analysed in these applications\nwere captured by chromatographic separation and mass spectrometry technique\n(LC-MS), Fourier transform infrared spectroscopy (FT-IR), and nuclear magnetic\nresonance spectroscopy (NMR) and involve the analysis of plant, animal, and\nhuman samples. The process was executed using both data-driven and\nhypothesis-driven data mining approaches in order to perform various data\nmining goals and tasks by applying a number of data mining techniques. The\napplications were selected to achieve a range of analytical goals and research\nquestions and to provide coverage for metabolite profiling, target analysis,\nand metabolic fingerprinting using datasets that were captured by NMR, LC-MS,\nand FT-IR using samples of a plant, animal, and human origin. The process was\napplied using an implementation environment which was created in order to\nprovide a computer-aided realisation of the process model execution.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jul 2019 01:14:55 GMT"}, {"version": "v2", "created": "Tue, 30 Jul 2019 07:57:31 GMT"}], "update_date": "2019-07-31", "authors_parsed": [["BaniMustafa", "Ahmed", ""], ["Hardy", "Nigel", ""]]}, {"id": "1907.03783", "submitter": "Guojun Zhang", "authors": "Guojun Zhang, Pascal Poupart and George Trimponias", "title": "Comparing EM with GD in Mixture Models of Two Components", "comments": "UAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The expectation-maximization (EM) algorithm has been widely used in\nminimizing the negative log likelihood (also known as cross entropy) of mixture\nmodels. However, little is understood about the goodness of the fixed points it\nconverges to. In this paper, we study the regions where one component is\nmissing in two-component mixture models, which we call one-cluster regions. We\nanalyze the propensity of such regions to trap EM and gradient descent (GD) for\nmixtures of two Gaussians and mixtures of two Bernoullis. In the case of\nGaussian mixtures, EM escapes one-cluster regions exponentially fast, while GD\nescapes them linearly fast. In the case of mixtures of Bernoullis, we find that\nthere exist one-cluster regions that are stable for GD and therefore trap GD,\nbut those regions are unstable for EM, allowing EM to escape. Those regions are\nlocal minima that appear universally in experiments and can be arbitrarily bad.\nThis work implies that EM is less likely than GD to converge to certain bad\nlocal optima in mixture models.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jul 2019 18:00:32 GMT"}, {"version": "v2", "created": "Fri, 19 Jul 2019 03:28:45 GMT"}, {"version": "v3", "created": "Tue, 29 Oct 2019 15:13:38 GMT"}], "update_date": "2019-10-30", "authors_parsed": [["Zhang", "Guojun", ""], ["Poupart", "Pascal", ""], ["Trimponias", "George", ""]]}, {"id": "1907.03792", "submitter": "Marc Lelarge", "authors": "Marc Lelarge and Leo Miolane", "title": "Asymptotic Bayes risk for Gaussian mixture in a semi-supervised setting", "comments": "13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semi-supervised learning (SSL) uses unlabeled data for training and has been\nshown to greatly improve performance when compared to a supervised approach on\nthe labeled data available. This claim depends both on the amount of labeled\ndata available and on the algorithm used.\n  In this paper, we compute analytically the gap between the best\nfully-supervised approach using only labeled data and the best semi-supervised\napproach using both labeled and unlabeled data. We quantify the best possible\nincrease in performance obtained thanks to the unlabeled data, i.e. we compute\nthe accuracy increase due to the information contained in the unlabeled data.\nOur work deals with a simple high-dimensional Gaussian mixture model for the\ndata in a Bayesian setting. Our rigorous analysis builds on recent theoretical\nbreakthroughs in high-dimensional inference and a large body of mathematical\ntools from statistical physics initially developed for spin glasses.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jul 2019 18:08:05 GMT"}, {"version": "v2", "created": "Sat, 28 Sep 2019 21:26:23 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Lelarge", "Marc", ""], ["Miolane", "Leo", ""]]}, {"id": "1907.03793", "submitter": "Quoc Tran-Dinh", "authors": "Quoc Tran-Dinh, Nhan H. Pham, Dzung T. Phan, and Lam M. Nguyen", "title": "A Hybrid Stochastic Optimization Framework for Stochastic Composite\n  Nonconvex Optimization", "comments": "49 pages, 2 tables, 9 figures", "journal-ref": null, "doi": null, "report-no": "UNC-STOR-2019.07.V1-03", "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new approach to develop stochastic optimization algorithms for\na class of stochastic composite and possibly nonconvex optimization problems.\nThe main idea is to combine two stochastic estimators to create a new hybrid\none. We first introduce our hybrid estimator and then investigate its\nfundamental properties to form a foundational theory for algorithmic\ndevelopment. Next, we apply our theory to develop several variants of\nstochastic gradient methods to solve both expectation and finite-sum composite\noptimization problems. Our first algorithm can be viewed as a variant of\nproximal stochastic gradient methods with a single-loop, but can achieve\n$\\mathcal{O}(\\sigma^3\\varepsilon^{-1} + \\sigma \\varepsilon^{-3})$-oracle\ncomplexity bound, matching the best-known ones from state-of-the-art\ndouble-loop algorithms in the literature, where $\\sigma > 0$ is the variance\nand $\\varepsilon$ is a desired accuracy. Then, we consider two different\nvariants of our method: adaptive step-size and restarting schemes that have\nsimilar theoretical guarantees as in our first algorithm. We also study two\nmini-batch variants of the proposed methods. In all cases, we achieve the\nbest-known complexity bounds under standard assumptions. We test our methods on\nseveral numerical examples with real datasets and compare them with\nstate-of-the-arts. Our numerical experiments show that the new methods are\ncomparable and, in many cases, outperform their competitors.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jul 2019 18:12:37 GMT"}, {"version": "v2", "created": "Sun, 3 May 2020 02:21:49 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Tran-Dinh", "Quoc", ""], ["Pham", "Nhan H.", ""], ["Phan", "Dzung T.", ""], ["Nguyen", "Lam M.", ""]]}, {"id": "1907.03799", "submitter": "Vincenzo Lomonaco PhD", "authors": "Vincenzo Lomonaco, Davide Maltoni, Lorenzo Pellegrini", "title": "Rehearsal-Free Continual Learning over Small Non-I.I.D. Batches", "comments": "Accepted in the CLVision Workshop at CVPR2020: 12 pages, 7 figures, 5\n  tables, 3 algorithms", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robotic vision is a field where continual learning can play a significant\nrole. An embodied agent operating in a complex environment subject to frequent\nand unpredictable changes is required to learn and adapt continuously. In the\ncontext of object recognition, for example, a robot should be able to learn\n(without forgetting) objects of never before seen classes as well as improving\nits recognition capabilities as new instances of already known classes are\ndiscovered. Ideally, continual learning should be triggered by the availability\nof short videos of single objects and performed on-line on on-board hardware\nwith fine-grained updates. In this paper, we introduce a novel continual\nlearning protocol based on the CORe50 benchmark and propose two rehearsal-free\ncontinual learning techniques, CWR* and AR1*, that can learn effectively even\nin the challenging case of nearly 400 small non-i.i.d. incremental batches. In\nparticular, our experiments show that AR1* can outperform other\nstate-of-the-art rehearsal-free techniques by more than 15% accuracy in some\ncases, with a very light and constant computational and memory overhead across\ntraining batches.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jul 2019 18:32:25 GMT"}, {"version": "v2", "created": "Mon, 2 Dec 2019 21:18:49 GMT"}, {"version": "v3", "created": "Tue, 21 Apr 2020 16:13:12 GMT"}], "update_date": "2020-04-22", "authors_parsed": [["Lomonaco", "Vincenzo", ""], ["Maltoni", "Davide", ""], ["Pellegrini", "Lorenzo", ""]]}, {"id": "1907.03802", "submitter": "Carlos Rodr\\'iguez - Pardo", "authors": "Carlos Rodr\\'iguez - Pardo and Hakan Bilen", "title": "Personalised aesthetics with residual adapters", "comments": "12 pages, 4 figures. In Iberian Conference on Pattern Recognition and\n  Image Analysis proceedings", "journal-ref": null, "doi": "10.1007/978-3-030-31332-6_44", "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The use of computational methods to evaluate aesthetics in photography has\ngained interest in recent years due to the popularization of convolutional\nneural networks and the availability of new annotated datasets. Most studies in\nthis area have focused on designing models that do not take into account\nindividual preferences for the prediction of the aesthetic value of pictures.\nWe propose a model based on residual learning that is capable of learning\nsubjective, user specific preferences over aesthetics in photography, while\nsurpassing the state-of-the-art methods and keeping a limited number of\nuser-specific parameters in the model. Our model can also be used for picture\nenhancement, and it is suitable for content-based or hybrid recommender systems\nin which the amount of computational resources is limited.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jul 2019 18:40:16 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Pardo", "Carlos Rodr\u00edguez -", ""], ["Bilen", "Hakan", ""]]}, {"id": "1907.03809", "submitter": "Mallesh Pai", "authors": "Jose Luis Montiel Olea, Pietro Ortoleva, Mallesh M Pai, Andrea Prat", "title": "Competing Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.TH cs.LG econ.EM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Agents compete to acquire an asset whose value depends on how well they can\npredict an unknown variable. Agents are Bayesian, observe identical data, but\nhave different models: they use different subsets of explanatory variables to\nmake their predictions. The winning model crucially depends on the sample size.\nWith small samples, we present a number of results suggesting it is an agent\nusing a low-dimensional model, in the sense of using a smaller number of\nvariables relative to the true data generating process. With large samples, we\nshow that it is generally an agent with a high-dimensional model, possibly\nincluding irrelevant variables, but never excluding relevant ones.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jul 2019 18:50:09 GMT"}, {"version": "v2", "created": "Thu, 17 Oct 2019 19:38:57 GMT"}, {"version": "v3", "created": "Thu, 18 Jun 2020 15:27:09 GMT"}, {"version": "v4", "created": "Wed, 10 Feb 2021 16:43:20 GMT"}], "update_date": "2021-02-11", "authors_parsed": [["Olea", "Jose Luis Montiel", ""], ["Ortoleva", "Pietro", ""], ["Pai", "Mallesh M", ""], ["Prat", "Andrea", ""]]}, {"id": "1907.03813", "submitter": "Xiaoyi Gu", "authors": "Xiaoyi Gu, Leman Akoglu, Alessandro Rinaldo", "title": "Statistical Analysis of Nearest Neighbor Methods for Anomaly Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Nearest-neighbor (NN) procedures are well studied and widely used in both\nsupervised and unsupervised learning problems. In this paper we are concerned\nwith investigating the performance of NN-based methods for anomaly detection.\nWe first show through extensive simulations that NN methods compare favorably\nto some of the other state-of-the-art algorithms for anomaly detection based on\na set of benchmark synthetic datasets. We further consider the performance of\nNN methods on real datasets, and relate it to the dimensionality of the\nproblem. Next, we analyze the theoretical properties of NN-methods for anomaly\ndetection by studying a more general quantity called distance-to-measure (DTM),\noriginally developed in the literature on robust geometric and topological\ninference. We provide finite-sample uniform guarantees for the empirical DTM\nand use them to derive misclassification rates for anomalous observations under\nvarious settings. In our analysis we rely on Huber's contamination model and\nformulate mild geometric regularity assumptions on the underlying distribution\nof the data.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jul 2019 18:58:35 GMT"}], "update_date": "2019-07-10", "authors_parsed": [["Gu", "Xiaoyi", ""], ["Akoglu", "Leman", ""], ["Rinaldo", "Alessandro", ""]]}, {"id": "1907.03816", "submitter": "Max Hopkins", "authors": "Max Hopkins, Daniel M. Kane, Shachar Lovett", "title": "The Power of Comparisons for Actively Learning Linear Classifiers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the world of big data, large but costly to label datasets dominate many\nfields. Active learning, a semi-supervised alternative to the standard\nPAC-learning model, was introduced to explore whether adaptive labeling could\nlearn concepts with exponentially fewer labeled samples. While previous results\nshow that active learning performs no better than its supervised alternative\nfor important concept classes such as linear separators, we show that by adding\nweak distributional assumptions and allowing comparison queries, active\nlearning requires exponentially fewer samples. Further, we show that these\nresults hold as well for a stronger model of learning called Reliable and\nProbably Useful (RPU) learning. In this model, our learner is not allowed to\nmake mistakes, but may instead answer \"I don't know.\" While previous negative\nresults showed this model to have intractably large sample complexity for label\nqueries, we show that comparison queries make RPU-learning at worst\nlogarithmically more expensive in both the passive and active regimes.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jul 2019 19:08:59 GMT"}, {"version": "v2", "created": "Sat, 30 May 2020 22:46:48 GMT"}], "update_date": "2020-06-02", "authors_parsed": [["Hopkins", "Max", ""], ["Kane", "Daniel M.", ""], ["Lovett", "Shachar", ""]]}, {"id": "1907.03821", "submitter": "Abhimanyu Dubey", "authors": "Abhimanyu Dubey and Alex Pentland", "title": "Thompson Sampling on Symmetric $\\alpha$-Stable Bandits", "comments": "IJCAI 2019 Camera Ready with appendix, updated Theorem 1", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Thompson Sampling provides an efficient technique to introduce prior\nknowledge in the multi-armed bandit problem, along with providing remarkable\nempirical performance. In this paper, we revisit the Thompson Sampling\nalgorithm under rewards drawn from symmetric $\\alpha$-stable distributions,\nwhich are a class of heavy-tailed probability distributions utilized in finance\nand economics, in problems such as modeling stock prices and human behavior. We\npresent an efficient framework for posterior inference, which leads to two\nalgorithms for Thompson Sampling in this setting. We prove finite-time regret\nbounds for both algorithms, and demonstrate through a series of experiments the\nstronger performance of Thompson Sampling in this setting. With our results, we\nprovide an exposition of symmetric $\\alpha$-stable distributions in sequential\ndecision-making, and enable sequential Bayesian inference in applications from\ndiverse fields in finance and complex systems that operate on heavy-tailed\nfeatures.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jul 2019 19:32:22 GMT"}, {"version": "v2", "created": "Thu, 5 Dec 2019 20:20:16 GMT"}], "update_date": "2019-12-09", "authors_parsed": [["Dubey", "Abhimanyu", ""], ["Pentland", "Alex", ""]]}, {"id": "1907.03827", "submitter": "An Yan", "authors": "An Yan, Bill Howe", "title": "FairST: Equitable Spatial and Temporal Demand Prediction for New\n  Mobility Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.LG stat.AP", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Emerging transportation modes, including car-sharing, bike-sharing, and\nride-hailing, are transforming urban mobility but have been shown to reinforce\nsocioeconomic inequities. Spatiotemporal demand prediction models for these new\nmobility regimes must therefore consider fairness as a first-class design\nrequirement. We present FairST, a fairness-aware model for predicting demand\nfor new mobility systems. Our approach utilizes 1D, 2D and 3D convolutions to\nintegrate various urban features and learn the spatial-temporal dynamics of a\nmobility system, but we include fairness metrics as a form of regularization to\nmake the predictions more equitable across demographic groups. We propose two\nnovel spatiotemporal fairness metrics, a region-based fairness gap (RFG) and an\nindividual-based fairness gap (IFG). Both quantify equity in a spatiotemporal\ncontext, but vary by whether demographics are labeled at the region level (RFG)\nor whether population distribution information is available (IFG). Experimental\nresults on real bike share and ride share datasets demonstrate the\neffectiveness of the proposed model: FairST not only reduces the fairness gap\nby more than 80%, but can surprisingly achieve better accuracy than\nstate-of-the-art yet fairness-oblivious methods including LSTMs, ConvLSTMs, and\n3D CNN.\n", "versions": [{"version": "v1", "created": "Fri, 21 Jun 2019 19:33:16 GMT"}], "update_date": "2019-07-10", "authors_parsed": [["Yan", "An", ""], ["Howe", "Bill", ""]]}, {"id": "1907.03848", "submitter": "Thilo Hagendorff", "authors": "Angela Daly, Thilo Hagendorff, Li Hui, Monique Mann, Vidushi Marda,\n  Ben Wagner, Wei Wang, Saskia Witteborn", "title": "Artificial Intelligence Governance and Ethics: Global Perspectives", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial intelligence (AI) is a technology which is increasingly being\nutilised in society and the economy worldwide, and its implementation is\nplanned to become more prevalent in coming years. AI is increasingly being\nembedded in our lives, supplementing our pervasive use of digital technologies.\nBut this is being accompanied by disquiet over problematic and dangerous\nimplementations of AI, or indeed, even AI itself deciding to do dangerous and\nproblematic actions, especially in fields such as the military, medicine and\ncriminal justice. These developments have led to concerns about whether and how\nAI systems adhere, and will adhere to ethical standards. These concerns have\nstimulated a global conversation on AI ethics, and have resulted in various\nactors from different countries and sectors issuing ethics and governance\ninitiatives and guidelines for AI. Such developments form the basis for our\nresearch in this report, combining our international and interdisciplinary\nexpertise to give an insight into what is happening in Australia, China,\nEurope, India and the US.\n", "versions": [{"version": "v1", "created": "Fri, 28 Jun 2019 07:42:48 GMT"}], "update_date": "2019-07-10", "authors_parsed": [["Daly", "Angela", ""], ["Hagendorff", "Thilo", ""], ["Hui", "Li", ""], ["Mann", "Monique", ""], ["Marda", "Vidushi", ""], ["Wagner", "Ben", ""], ["Wang", "Wei", ""], ["Witteborn", "Saskia", ""]]}, {"id": "1907.03870", "submitter": "Ana Fern\\'andez del R\\'io", "authors": "Ana Fern\\'andez del R\\'io, Pei Pei Chen and \\'Africa Peri\\'a\\~nez", "title": "Profiling Players with Engagement Predictions", "comments": "Accepted for IEEE Conference on Games (CoG) 2019", "journal-ref": "2019 IEEE Conference in Games (CoG)", "doi": "10.1109/CIG.2019.8848074", "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The possibility of using player engagement predictions to profile high\nspending video game users is explored. In particular, individual-player\nsurvival curves in terms of days after first login, game level reached and\naccumulated playtime are used to classify players into different groups.\nLifetime value predictions for each player---generated using a deep learning\nmethod based on long short-term memory---are also included in the analysis, and\nthe relations between all these variables are thoroughly investigated. Our\nresults suggest this constitutes a promising approach to user profiling.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jul 2019 01:13:38 GMT"}], "update_date": "2020-03-10", "authors_parsed": [["del R\u00edo", "Ana Fern\u00e1ndez", ""], ["Chen", "Pei Pei", ""], ["Peri\u00e1\u00f1ez", "\u00c1frica", ""]]}, {"id": "1907.03875", "submitter": "Lorenzo Rosasco", "authors": "Enrico Cecini and Ernesto De Vito and Lorenzo Rosasco", "title": "Multi-Scale Vector Quantization with Reconstruction Trees", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose and study a multi-scale approach to vector quantization. We\ndevelop an algorithm, dubbed reconstruction trees, inspired by decision trees.\nHere the objective is parsimonious reconstruction of unsupervised data, rather\nthan classification. Contrasted to more standard vector quantization methods,\nsuch as K-means, the proposed approach leverages a family of given partitions,\nto quickly explore the data in a coarse to fine-- multi-scale-- fashion. Our\nmain technical contribution is an analysis of the expected distortion achieved\nby the proposed algorithm, when the data are assumed to be sampled from a fixed\nunknown distribution. In this context, we derive both asymptotic and finite\nsample results under suitable regularity assumptions on the distribution. As a\nspecial case, we consider the setting where the data generating distribution is\nsupported on a compact Riemannian sub-manifold. Tools from differential\ngeometry and concentration of measure are useful in our analysis.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jul 2019 21:11:24 GMT"}, {"version": "v2", "created": "Wed, 4 Sep 2019 13:49:45 GMT"}], "update_date": "2019-09-05", "authors_parsed": [["Cecini", "Enrico", ""], ["De Vito", "Ernesto", ""], ["Rosasco", "Lorenzo", ""]]}, {"id": "1907.03876", "submitter": "Beren Millidge Mr", "authors": "Beren Millidge", "title": "Deep Active Inference as Variational Policy Gradients", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Active Inference is a theory of action arising from neuroscience which casts\naction and planning as a bayesian inference problem to be solved by minimizing\na single quantity - the variational free energy. Active Inference promises a\nunifying account of action and perception coupled with a biologically plausible\nprocess theory. Despite these potential advantages, current implementations of\nActive Inference can only handle small, discrete policy and state-spaces and\ntypically require the environmental dynamics to be known. In this paper we\npropose a novel deep Active Inference algorithm which approximates key\ndensities using deep neural networks as flexible function approximators, which\nenables Active Inference to scale to significantly larger and more complex\ntasks. We demonstrate our approach on a suite of OpenAIGym benchmark tasks and\nobtain performance comparable with common reinforcement learning baselines.\nMoreover, our algorithm shows similarities with maximum entropy reinforcement\nlearning and the policy gradients algorithm, which reveals interesting\nconnections between the Active Inference framework and reinforcement learning.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jul 2019 21:14:29 GMT"}], "update_date": "2019-07-10", "authors_parsed": [["Millidge", "Beren", ""]]}, {"id": "1907.03885", "submitter": "Hamidreza Ghader", "authors": "Hamidreza Ghader, Christof Monz", "title": "An Intrinsic Nearest Neighbor Analysis of Neural Machine Translation\n  Architectures", "comments": "To be presented at Machine Translation Summit 2019 (MTSUMMIT XVII),\n  Dublin, Ireland", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Earlier approaches indirectly studied the information captured by the hidden\nstates of recurrent and non-recurrent neural machine translation models by\nfeeding them into different classifiers. In this paper, we look at the encoder\nhidden states of both transformer and recurrent machine translation models from\nthe nearest neighbors perspective. We investigate to what extent the nearest\nneighbors share information with the underlying word embeddings as well as\nrelated WordNet entries. Additionally, we study the underlying syntactic\nstructure of the nearest neighbors to shed light on the role of syntactic\nsimilarities in bringing the neighbors together. We compare transformer and\nrecurrent models in a more intrinsic way in terms of capturing lexical\nsemantics and syntactic structures, in contrast to extrinsic approaches used by\nprevious works. In agreement with the extrinsic evaluations in the earlier\nworks, our experimental results show that transformers are superior in\ncapturing lexical semantics, but not necessarily better in capturing the\nunderlying syntax. Additionally, we show that the backward recurrent layer in a\nrecurrent model learns more about the semantics of words, whereas the forward\nrecurrent layer encodes more context.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jul 2019 21:39:29 GMT"}], "update_date": "2019-07-10", "authors_parsed": [["Ghader", "Hamidreza", ""], ["Monz", "Christof", ""]]}, {"id": "1907.03907", "submitter": "Yulia Rubanova", "authors": "Yulia Rubanova, Ricky T. Q. Chen, David Duvenaud", "title": "Latent ODEs for Irregularly-Sampled Time Series", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Time series with non-uniform intervals occur in many applications, and are\ndifficult to model using standard recurrent neural networks (RNNs). We\ngeneralize RNNs to have continuous-time hidden dynamics defined by ordinary\ndifferential equations (ODEs), a model we call ODE-RNNs. Furthermore, we use\nODE-RNNs to replace the recognition network of the recently-proposed Latent ODE\nmodel. Both ODE-RNNs and Latent ODEs can naturally handle arbitrary time gaps\nbetween observations, and can explicitly model the probability of observation\ntimes using Poisson processes. We show experimentally that these ODE-based\nmodels outperform their RNN-based counterparts on irregularly-sampled data.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jul 2019 23:21:32 GMT"}], "update_date": "2019-07-10", "authors_parsed": [["Rubanova", "Yulia", ""], ["Chen", "Ricky T. Q.", ""], ["Duvenaud", "David", ""]]}, {"id": "1907.03909", "submitter": "Mohammad Mohammadi Amiri Mr.", "authors": "Mohammad Mohammadi Amiri, Tolga M. Duman, Deniz Gunduz", "title": "Collaborative Machine Learning at the Wireless Edge with Blind\n  Transmitters", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.DC cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study wireless collaborative machine learning (ML), where mobile edge\ndevices, each with its own dataset, carry out distributed stochastic gradient\ndescent (DSGD) over-the-air with the help of a wireless access point acting as\nthe parameter server (PS). At each iteration of the DSGD algorithm wireless\ndevices compute gradient estimates with their local datasets, and send them to\nthe PS over a wireless fading multiple access channel (MAC). Motivated by the\nadditive nature of the wireless MAC, we propose an analog DSGD scheme, in which\nthe devices transmit scaled versions of their gradient estimates in an uncoded\nfashion. We assume that the channel state information (CSI) is available only\nat the PS. We instead allow the PS to employ multiple antennas to alleviate the\ndestructive fading effect, which cannot be cancelled by the transmitters due to\nthe lack of CSI. Theoretical analysis indicates that, with the proposed DSGD\nscheme, increasing the number of PS antennas mitigates the fading effect, and,\nin the limit, the effects of fading and noise disappear, and the PS receives\naligned signals used to update the model parameter. The theoretical results are\nthen corroborated with the experimental ones.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jul 2019 23:28:40 GMT"}], "update_date": "2019-07-10", "authors_parsed": [["Amiri", "Mohammad Mohammadi", ""], ["Duman", "Tolga M.", ""], ["Gunduz", "Deniz", ""]]}, {"id": "1907.03922", "submitter": "Chulhee Yun", "authors": "Chulhee Yun, Suvrit Sra, Ali Jadbabaie", "title": "Are deep ResNets provably better than linear predictors?", "comments": "15 pages. NeurIPS 2019 Camera-ready version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent results in the literature indicate that a residual network (ResNet)\ncomposed of a single residual block outperforms linear predictors, in the sense\nthat all local minima in its optimization landscape are at least as good as the\nbest linear predictor. However, these results are limited to a single residual\nblock (i.e., shallow ResNets), instead of the deep ResNets composed of multiple\nresidual blocks. We take a step towards extending this result to deep ResNets.\nWe start by two motivating examples. First, we show that there exist datasets\nfor which all local minima of a fully-connected ReLU network are no better than\nthe best linear predictor, whereas a ResNet has strictly better local minima.\nSecond, we show that even at the global minimum, the representation obtained\nfrom the residual block outputs of a 2-block ResNet do not necessarily improve\nmonotonically over subsequent blocks, which highlights a fundamental difficulty\nin analyzing deep ResNets. Our main theorem on deep ResNets shows under simple\ngeometric conditions that, any critical point in the optimization landscape is\neither (i) at least as good as the best linear predictor; or (ii) the Hessian\nat this critical point has a strictly negative eigenvalue. Notably, our theorem\nshows that a chain of multiple skip-connections can improve the optimization\nlandscape, whereas existing results study direct skip-connections to the last\nhidden layer or output layer. Finally, we complement our results by showing\nbenign properties of the \"near-identity regions\" of deep ResNets, showing\ndepth-independent upper bounds for the risk attained at critical points as well\nas the Rademacher complexity.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jul 2019 00:58:34 GMT"}, {"version": "v2", "created": "Tue, 29 Oct 2019 05:32:39 GMT"}], "update_date": "2019-10-30", "authors_parsed": [["Yun", "Chulhee", ""], ["Sra", "Suvrit", ""], ["Jadbabaie", "Ali", ""]]}, {"id": "1907.03925", "submitter": "Jiangteng Li", "authors": "Jiangteng Li, Fei Wang", "title": "Non-technical Loss Detection with Statistical Profile Images Based on\n  Semi-supervised Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to keep track of the operational state of power grid, the world's\nlargest sensor systems, smart grid, was built by deploying hundreds of millions\nof smart meters. Such system makes it possible to discover and make quick\nresponse to any hidden threat to the entire power grid. Non-technical losses\n(NTLs) have always been a major concern for its consequent security risks as\nwell as immeasurable revenue loss. However, various causes of NTL may have\ndifferent characteristics reflected in the data. Accurately capturing these\nanomalies faced with such large scale of collected data records is rather\ntricky as a result. In this paper, we proposed a new methodology of detecting\nabnormal electricity consumptions. We did a transformation of the collected\ntime-series data which turns it into an image representation that could well\nreflect users' relatively long term consumption behaviors. Inspired by the\nexcellent neural network architecture used for objective detection in computer\nvision domain, we designed our deep learning model that takes the transformed\nimages as input and yields joint featured inferred from the multiple aspects\nthe input provides. Considering the limited labeled samples, especially the\nabnormal ones, we used our model in a semi-supervised fashion that is brought\nout in recent years. The model is tested on samples which are verified by\non-field inspections and our method showed significant improvement.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jul 2019 01:06:03 GMT"}], "update_date": "2019-07-10", "authors_parsed": [["Li", "Jiangteng", ""], ["Wang", "Fei", ""]]}, {"id": "1907.03947", "submitter": "Anna Guitart Atienza", "authors": "Anna Guitart, Ana Fern\\'andez del R\\'io and \\'Africa Peri\\'a\\~nez", "title": "Understanding Player Engagement and In-Game Purchasing Behavior with\n  Ensemble Learning", "comments": "Churn Prediction, Ensemble Methods, Survival Analysis, On- line\n  Games, User Behavior", "journal-ref": "Proceedings of GAME-ON'2019 AI and Simulation in Games, September\n  2019, breda, the Netherlands. ISBN 978-94-92859-08-2", "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As video games attract more and more players, the major challenge for game\nstudios is to retain them. We present a deep behavioral analysis of churn (game\nabandonment) and what we called \"purchase churn\" (the transition from paying to\nnon-paying user). A series of churning behavior profiles are identified, which\nallows a classification of churners in terms of whether they eventually return\nto the game (false churners)--or start purchasing again (false purchase\nchurners)--and their subsequent behavior. The impact of excluding some or all\nof these churners from the training sample is then explored in several churn\nand purchase churn prediction models. Our results suggest that discarding\ncertain combinations of \"zombies\" (players whose activity is extremely\nsporadic) and false churners has a significant positive impact in all models\nconsidered.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jul 2019 02:40:40 GMT"}], "update_date": "2020-03-10", "authors_parsed": [["Guitart", "Anna", ""], ["del R\u00edo", "Ana Fern\u00e1ndez", ""], ["Peri\u00e1\u00f1ez", "\u00c1frica", ""]]}, {"id": "1907.03950", "submitter": "Drew A. Hudson", "authors": "Drew A. Hudson and Christopher D. Manning", "title": "Learning by Abstraction: The Neural State Machine", "comments": "Published as a conference paper at NeurIPS 2019 (spotlight)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the Neural State Machine, seeking to bridge the gap between the\nneural and symbolic views of AI and integrate their complementary strengths for\nthe task of visual reasoning. Given an image, we first predict a probabilistic\ngraph that represents its underlying semantics and serves as a structured world\nmodel. Then, we perform sequential reasoning over the graph, iteratively\ntraversing its nodes to answer a given question or draw a new inference. In\ncontrast to most neural architectures that are designed to closely interact\nwith the raw sensory data, our model operates instead in an abstract latent\nspace, by transforming both the visual and linguistic modalities into semantic\nconcept-based representations, thereby achieving enhanced transparency and\nmodularity. We evaluate our model on VQA-CP and GQA, two recent VQA datasets\nthat involve compositionality, multi-step inference and diverse reasoning\nskills, achieving state-of-the-art results in both cases. We provide further\nexperiments that illustrate the model's strong generalization capacity across\nmultiple dimensions, including novel compositions of concepts, changes in the\nanswer distribution, and unseen linguistic structures, demonstrating the\nqualities and efficacy of our approach.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jul 2019 03:08:41 GMT"}, {"version": "v2", "created": "Thu, 11 Jul 2019 17:14:03 GMT"}, {"version": "v3", "created": "Mon, 15 Jul 2019 09:33:51 GMT"}, {"version": "v4", "created": "Mon, 25 Nov 2019 10:02:05 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Hudson", "Drew A.", ""], ["Manning", "Christopher D.", ""]]}, {"id": "1907.03953", "submitter": "Young Jin Oh Mr.", "authors": "Tae Min Lee, Young Jin Oh, In-Kwon Lee", "title": "Efficient Cloth Simulation using Miniature Cloth and Upscaling Deep\n  Neural Networks", "comments": "11 pages, 15 figures, 8 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cloth simulation requires a fast and stable method for interactively and\nrealistically visualizing fabric materials using computer graphics. We propose\nan efficient cloth simulation method using miniature cloth simulation and\nupscaling Deep Neural Networks (DNN). The upscaling DNNs generate the target\ncloth simulation from the results of physically-based simulations of a\nminiature cloth that has similar physical properties to those of the target\ncloth. We have verified the utility of the proposed method through experiments,\nand the results demonstrate that it is possible to generate fast and stable\ncloth simulations under various conditions.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jul 2019 03:13:58 GMT"}], "update_date": "2019-07-10", "authors_parsed": [["Lee", "Tae Min", ""], ["Oh", "Young Jin", ""], ["Lee", "In-Kwon", ""]]}, {"id": "1907.03976", "submitter": "Daniel Brown", "authors": "Daniel S. Brown, Wonjoon Goo, and Scott Niekum", "title": "Better-than-Demonstrator Imitation Learning via Automatically-Ranked\n  Demonstrations", "comments": "In proceedings of 3rd Conference on Robot Learning (CoRL) 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The performance of imitation learning is typically upper-bounded by the\nperformance of the demonstrator. While recent empirical results demonstrate\nthat ranked demonstrations allow for better-than-demonstrator performance,\npreferences over demonstrations may be difficult to obtain, and little is known\ntheoretically about when such methods can be expected to successfully\nextrapolate beyond the performance of the demonstrator. To address these\nissues, we first contribute a sufficient condition for better-than-demonstrator\nimitation learning and provide theoretical results showing why preferences over\ndemonstrations can better reduce reward function ambiguity when performing\ninverse reinforcement learning. Building on this theory, we introduce\nDisturbance-based Reward Extrapolation (D-REX), a ranking-based imitation\nlearning method that injects noise into a policy learned through behavioral\ncloning to automatically generate ranked demonstrations. These ranked\ndemonstrations are used to efficiently learn a reward function that can then be\noptimized using reinforcement learning. We empirically validate our approach on\nsimulated robot and Atari imitation learning benchmarks and show that D-REX\noutperforms standard imitation learning approaches and can significantly\nsurpass the performance of the demonstrator. D-REX is the first imitation\nlearning approach to achieve significant extrapolation beyond the\ndemonstrator's performance without additional side-information or supervision,\nsuch as rewards or human preferences. By generating rankings automatically, we\nshow that preference-based inverse reinforcement learning can be applied in\ntraditional imitation learning settings where only unlabeled demonstrations are\navailable.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jul 2019 04:11:53 GMT"}, {"version": "v2", "created": "Sat, 13 Jul 2019 01:11:51 GMT"}, {"version": "v3", "created": "Mon, 14 Oct 2019 17:44:45 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Brown", "Daniel S.", ""], ["Goo", "Wonjoon", ""], ["Niekum", "Scott", ""]]}, {"id": "1907.03988", "submitter": "Zhenyu Tang", "authors": "Zhenyu Tang, Lianwu Chen, Bo Wu, Dong Yu, Dinesh Manocha", "title": "Improving Reverberant Speech Training Using Diffuse Acoustic Simulation", "comments": "Accepted to ICASSP 2020, impulse response generation code at\n  https://github.com/RoyJames/pygsound", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an efficient and realistic geometric acoustic simulation approach\nfor generating and augmenting training data in speech-related machine learning\ntasks. Our physically-based acoustic simulation method is capable of modeling\nocclusion, specular and diffuse reflections of sound in complicated acoustic\nenvironments, whereas the classical image method can only model specular\nreflections in simple room settings. We show that by using our synthetic\ntraining data, the same neural networks gain significant performance\nimprovement on real test sets in far-field speech recognition by 1.58% and\nkeyword spotting by 21%, without fine-tuning using real impulse responses.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jul 2019 05:26:52 GMT"}, {"version": "v2", "created": "Wed, 23 Oct 2019 21:35:16 GMT"}, {"version": "v3", "created": "Thu, 31 Oct 2019 20:01:36 GMT"}, {"version": "v4", "created": "Mon, 10 Feb 2020 15:59:52 GMT"}, {"version": "v5", "created": "Thu, 2 Apr 2020 18:25:46 GMT"}], "update_date": "2020-04-06", "authors_parsed": [["Tang", "Zhenyu", ""], ["Chen", "Lianwu", ""], ["Wu", "Bo", ""], ["Yu", "Dong", ""], ["Manocha", "Dinesh", ""]]}, {"id": "1907.03989", "submitter": "Jos\\'e Camacho", "authors": "J. Camacho, A.K. Smilde, E. Saccenti, J.A. Westerhuis", "title": "All Sparse PCA Models Are Wrong, But Some Are Useful. Part I:\n  Computation of Scores, Residuals and Explained Variance", "comments": null, "journal-ref": "Chemometrics and Intelligent Laboratory Systems, 2020, 196:\n  1039072-", "doi": "10.1016/j.chemolab.2019.103907", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sparse Principal Component Analysis (sPCA) is a popular matrix factorization\napproach based on Principal Component Analysis (PCA) that combines variance\nmaximization and sparsity with the ultimate goal of improving data\ninterpretation. When moving from PCA to sPCA, there are a number of\nimplications that the practitioner needs to be aware of. A relevant one is that\nscores and loadings in sPCA may not be orthogonal. For this reason, the\ntraditional way of computing scores, residuals and variance explained that is\nused in the classical PCA cannot directly be applied to sPCA models. This also\naffects how sPCA components should be visualized. In this paper we illustrate\nthis problem both theoretically and numerically using simulations for several\nstate-of-the-art sPCA algorithms, and provide proper computation of the\ndifferent elements mentioned. We show that sPCA approaches present disparate\nand limited performance when modeling noise-free, sparse data. In a follow-up\npaper, we discuss the theoretical properties that lead to this problem.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jul 2019 05:27:20 GMT"}], "update_date": "2020-11-19", "authors_parsed": [["Camacho", "J.", ""], ["Smilde", "A. K.", ""], ["Saccenti", "E.", ""], ["Westerhuis", "J. A.", ""]]}, {"id": "1907.04001", "submitter": "Ygor Sousa", "authors": "Ygor C. N. Sousa, Hansenclever F. Bassani", "title": "Incremental Semantic Mapping with Unsupervised On-line Learning", "comments": null, "journal-ref": "IEEE International Joint Conference on Neural Networks (IJCNN),\n  July 2018", "doi": "10.1109/IJCNN.2018.8489430", "report-no": null, "categories": "cs.RO cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This paper introduces an incremental semantic mapping approach, with on-line\nunsupervised learning, based on Self-Organizing Maps (SOM) for robotic agents.\nThe method includes a mapping module, which incrementally creates a topological\nmap of the environment, enriched with objects recognized around each\ntopological node, and a module of places categorization, endowed with an\nincremental unsupervised learning SOM with on-line training. The proposed\napproach was tested in experiments with real-world data, in which it\ndemonstrates promising capabilities of incremental acquisition of topological\nmaps enriched with semantic information, and for clustering together similar\nplaces based on this information. The approach was also able to continue\nlearning from newly visited environments without degrading the information\npreviously learned.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jul 2019 06:18:29 GMT"}, {"version": "v2", "created": "Thu, 11 Jul 2019 03:52:13 GMT"}], "update_date": "2019-07-12", "authors_parsed": [["Sousa", "Ygor C. N.", ""], ["Bassani", "Hansenclever F.", ""]]}, {"id": "1907.04003", "submitter": "Anand Subramanian", "authors": "Anand Krishnamoorthy Subramanian, Nak Young Chong", "title": "Mean Spectral Normalization of Deep Neural Networks for Embedded\n  Automation", "comments": "8 pagesm IEEE CASE 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Neural Networks (DNNs) have begun to thrive in the field of automation\nsystems, owing to the recent advancements in standardising various aspects such\nas architecture, optimization techniques, and regularization. In this paper, we\ntake a step towards a better understanding of Spectral Normalization (SN) and\nits potential for standardizing regularization of a wider range of Deep\nLearning models, following an empirical approach. We conduct several\nexperiments to study their training dynamics, in comparison with the ubiquitous\nBatch Normalization (BN) and show that SN increases the gradient sparsity and\ncontrols the gradient variance. Furthermore, we show that SN suffers from a\nphenomenon, we call the mean-drift effect, which mitigates its performance. We,\nthen, propose a weight reparameterization called as the Mean Spectral\nNormalization (MSN) to resolve the mean drift, thereby significantly improving\nthe network's performance. Our model performs ~16% faster as compared to BN in\npractice, and has fewer trainable parameters. We also show the performance of\nour MSN for small, medium, and large CNNs - 3-layer CNN, VGG7 and DenseNet-BC,\nrespectively - and unsupervised image generation tasks using Generative\nAdversarial Networks (GANs) to evaluate its applicability for a broad range of\nembedded automation tasks.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jul 2019 06:24:22 GMT"}], "update_date": "2019-07-10", "authors_parsed": [["Subramanian", "Anand Krishnamoorthy", ""], ["Chong", "Nak Young", ""]]}, {"id": "1907.04018", "submitter": "Ben Mussay", "authors": "Ben Mussay, Margarita Osadchy, Vladimir Braverman, Samson Zhou, Dan\n  Feldman", "title": "Data-Independent Neural Pruning via Coresets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Previous work showed empirically that large neural networks can be\nsignificantly reduced in size while preserving their accuracy. Model\ncompression became a central research topic, as it is crucial for deployment of\nneural networks on devices with limited computational and memory resources. The\nmajority of the compression methods are based on heuristics and offer no\nworst-case guarantees on the trade-off between the compression rate and the\napproximation error for an arbitrarily new sample. We propose the first\nefficient, data-independent neural pruning algorithm with a provable trade-off\nbetween its compression rate and the approximation error for any future test\nsample. Our method is based on the coreset framework, which finds a small\nweighted subset of points that provably approximates the original inputs.\nSpecifically, we approximate the output of a layer of neurons by a coreset of\nneurons in the previous layer and discard the rest. We apply this framework in\na layer-by-layer fashion from the top to the bottom. Unlike previous works, our\ncoreset is data independent, meaning that it provably guarantees the accuracy\nof the function for any input $x\\in \\mathbb{R}^d$, including an adversarial\none. We demonstrate the effectiveness of our method on popular network\narchitectures. In particular, our coresets yield 90\\% compression of the\nLeNet-300-100 architecture on MNIST while improving the accuracy.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jul 2019 07:11:39 GMT"}, {"version": "v2", "created": "Sun, 29 Sep 2019 10:40:25 GMT"}, {"version": "v3", "created": "Fri, 3 Jan 2020 05:42:38 GMT"}], "update_date": "2020-01-06", "authors_parsed": [["Mussay", "Ben", ""], ["Osadchy", "Margarita", ""], ["Braverman", "Vladimir", ""], ["Zhou", "Samson", ""], ["Feldman", "Dan", ""]]}, {"id": "1907.04021", "submitter": "Zheng Li", "authors": "Zheng Li, Shi Shu", "title": "SVGD: A Virtual Gradients Descent Method for Stochastic Optimization", "comments": "12 pages, 12 figures, conference papers", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inspired by dynamic programming, we propose Stochastic Virtual Gradient\nDescent (SVGD) algorithm where the Virtual Gradient is defined by computational\ngraph and automatic differentiation. The method is computationally efficient\nand has little memory requirements. We also analyze the theoretical convergence\nproperties and implementation of the algorithm. Experimental results on\nmultiple datasets and network models show that SVGD has advantages over other\nstochastic optimization methods.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jul 2019 07:28:13 GMT"}, {"version": "v2", "created": "Wed, 31 Jul 2019 11:13:32 GMT"}], "update_date": "2019-08-01", "authors_parsed": [["Li", "Zheng", ""], ["Shu", "Shi", ""]]}, {"id": "1907.04028", "submitter": "Bin Yang", "authors": "Sean Bin Yang, Bin Yang", "title": "PathRank: A Multi-Task Learning Framework to Rank Paths in Spatial\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DB stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern navigation services often provide multiple paths connecting the same\nsource and destination for users to select. Hence, ranking such paths becomes\nincreasingly important, which directly affects the service quality. We present\nPathRank, a data-driven framework for ranking paths based on historical\ntrajectories using multi-task learning. If a trajectory used path P from source\ns to destination d, PathRank considers this as an evidence that P is preferred\nover all other paths from s to d. Thus, a path that is similar to P should have\na larger ranking score than a path that is dissimilar to P. Based on this\nintuition, PathRank models path ranking as a regression problem, where each\npath is associated with a ranking score.\n  To enable PathRank, we first propose an effective method to generate a\ncompact set of training data: for each trajectory, we generate a small set of\ndiversified paths. Next, we propose a multi-task learning framework to solve\nthe regression problem. In particular, a spatial network embedding is proposed\nto embed each vertex to a feature vector by considering both road network\ntopology and spatial properties, such as distances and travel times. Since a\npath is represented by a sequence of vertices, which is now a sequence of\nfeature vectors after embedding, recurrent neural network is applied to model\nthe sequence. The objective function is designed to consider errors on both\nranking scores and spatial properties, making the framework a multi-task\nlearning framework. Empirical studies on a substantial trajectory data set\noffer insight into the designed properties of the proposed framework and\nindicating that it is effective and practical.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jul 2019 07:45:55 GMT"}], "update_date": "2019-07-10", "authors_parsed": [["Yang", "Sean Bin", ""], ["Yang", "Bin", ""]]}, {"id": "1907.04050", "submitter": "Luca Ambrogioni", "authors": "Luca Ambrogioni, Umut G\\\"u\\c{c}l\\\"u and Marcel van Gerven", "title": "k-GANs: Ensemble of Generative Models with Semi-Discrete Optimal\n  Transport", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative adversarial networks (GANs) are the state of the art in generative\nmodeling. Unfortunately, most GAN methods are susceptible to mode collapse,\nmeaning that they tend to capture only a subset of the modes of the true\ndistribution. A possible way of dealing with this problem is to use an ensemble\nof GANs, where (ideally) each network models a single mode. In this paper, we\nintroduce a principled method for training an ensemble of GANs using\nsemi-discrete optimal transport theory. In our approach, each generative\nnetwork models the transportation map between a point mass (Dirac measure) and\nthe restriction of the data distribution on a tile of a Voronoi tessellation\nthat is defined by the location of the point masses. We iteratively train the\ngenerative networks and the point masses until convergence. The resulting\nk-GANs algorithm has strong theoretical connection with the k-medoids\nalgorithm. In our experiments, we show that our ensemble method consistently\noutperforms baseline GANs.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jul 2019 08:57:49 GMT"}], "update_date": "2019-07-10", "authors_parsed": [["Ambrogioni", "Luca", ""], ["G\u00fc\u00e7l\u00fc", "Umut", ""], ["van Gerven", "Marcel", ""]]}, {"id": "1907.04061", "submitter": "Prerana Mukherjee", "authors": "Chandra Sekhar V., Anoushka Doctor, Prerana Mukherjee, Viswanath\n  Pulabaigiri", "title": "A Light weight and Hybrid Deep Learning Model based Online Signature\n  Verification", "comments": "accepted in ICDAR-WML: The 2nd International Workshop on Machine\n  Learning 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The augmented usage of deep learning-based models for various AI related\nproblems are as a result of modern architectures of deeper length and the\navailability of voluminous interpreted datasets. The models based on these\narchitectures require huge training and storage cost, which makes them\ninefficient to use in critical applications like online signature verification\n(OSV) and to deploy in resource constraint devices. As a solution, in this\nwork, our contribution is two-fold. 1) An efficient dimensionality reduction\ntechnique, to reduce the number of features to be considered and 2) a\nstate-of-the-art model CNN-LSTM based hybrid architecture for online signature\nverification. Thorough experiments on the publicly available datasets MCYT,\nSUSIG, SVC confirms that the proposed model achieves better accuracy even with\nas low as one training sample. The proposed models yield state-of-the-art\nperformance in various categories of all the three datasets.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jul 2019 09:55:38 GMT"}], "update_date": "2019-07-10", "authors_parsed": [["V.", "Chandra Sekhar", ""], ["Doctor", "Anoushka", ""], ["Mukherjee", "Prerana", ""], ["Pulabaigiri", "Viswanath", ""]]}, {"id": "1907.04064", "submitter": "Jens Petersen", "authors": "Jens Petersen, Paul F. J\\\"ager, Fabian Isensee, Simon A. A. Kohl, Ulf\n  Neuberger, Wolfgang Wick, J\\\"urgen Debus, Sabine Heiland, Martin Bendszus,\n  Philipp Kickingereder, Klaus H. Maier-Hein", "title": "Deep Probabilistic Modeling of Glioma Growth", "comments": "MICCAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing approaches to modeling the dynamics of brain tumor growth,\nspecifically glioma, employ biologically inspired models of cell diffusion,\nusing image data to estimate the associated parameters. In this work, we\npropose an alternative approach based on recent advances in probabilistic\nsegmentation and representation learning that implicitly learns growth dynamics\ndirectly from data without an underlying explicit model. We present evidence\nthat our approach is able to learn a distribution of plausible future tumor\nappearances conditioned on past observations of the same tumor.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jul 2019 10:00:33 GMT"}], "update_date": "2019-07-10", "authors_parsed": [["Petersen", "Jens", ""], ["J\u00e4ger", "Paul F.", ""], ["Isensee", "Fabian", ""], ["Kohl", "Simon A. A.", ""], ["Neuberger", "Ulf", ""], ["Wick", "Wolfgang", ""], ["Debus", "J\u00fcrgen", ""], ["Heiland", "Sabine", ""], ["Bendszus", "Martin", ""], ["Kickingereder", "Philipp", ""], ["Maier-Hein", "Klaus H.", ""]]}, {"id": "1907.04068", "submitter": "Alexis Bellot", "authors": "Alexis Bellot and Mihaela van der Schaar", "title": "Conditional Independence Testing using Generative Adversarial Networks", "comments": "Updated version published at NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the hypothesis testing problem of detecting conditional\ndependence, with a focus on high-dimensional feature spaces. Our contribution\nis a new test statistic based on samples from a generative adversarial network\ndesigned to approximate directly a conditional distribution that encodes the\nnull hypothesis, in a manner that maximizes power (the rate of true negatives).\nWe show that such an approach requires only that density approximation be\nviable in order to ensure that we control type I error (the rate of false\npositives); in particular, no assumptions need to be made on the form of the\ndistributions or feature dependencies. Using synthetic simulations with\nhigh-dimensional data we demonstrate significant gains in power over competing\nmethods. In addition, we illustrate the use of our test to discover causal\nmarkers of disease in genetic data.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jul 2019 10:24:40 GMT"}, {"version": "v2", "created": "Wed, 18 Dec 2019 19:03:57 GMT"}], "update_date": "2019-12-20", "authors_parsed": [["Bellot", "Alexis", ""], ["van der Schaar", "Mihaela", ""]]}, {"id": "1907.04091", "submitter": "Alberto Antonio Del Barrio", "authors": "Ra\\'ul Murillo Montero, Alberto A. Del Barrio, Guillermo Botella", "title": "Template-Based Posit Multiplication for Training and Inferring in Neural\n  Networks", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The posit number system is arguably the most promising and discussed topic in\nArithmetic nowadays. The recent breakthroughs claimed by the format proposed by\nJohn L. Gustafson have put posits in the spotlight. In this work, we first\ndescribe an algorithm for multiplying two posit numbers, even when the number\nof exponent bits is zero. This configuration, scarcely tackled in literature,\nis particularly interesting because it allows the deployment of a fast sigmoid\nfunction. The proposed multiplication algorithm is then integrated as a\ntemplate into the well-known FloPoCo framework. Synthesis results are shown to\ncompare with the floating point multiplication offered by FloPoCo as well.\nSecond, the performance of posits is studied in the scenario of Neural Networks\nin both training and inference stages. To the best of our knowledge, this is\nthe first time that training is done with posit format, achieving promising\nresults for a binary classification problem even with reduced posit\nconfigurations. In the inference stage, 8-bit posits are as good as floating\npoint when dealing with the MNIST dataset, but lose some accuracy with\nCIFAR-10.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jul 2019 11:36:19 GMT"}], "update_date": "2019-07-10", "authors_parsed": [["Montero", "Ra\u00fal Murillo", ""], ["Del Barrio", "Alberto A.", ""], ["Botella", "Guillermo", ""]]}, {"id": "1907.04092", "submitter": "Chunsheng Liu", "authors": "Chunsheng Liu, Hong Shan, Chunlei Chen", "title": "Tensor p-shrinkage nuclear norm for low-rank tensor completion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, a new definition of tensor p-shrinkage nuclear norm (p-TNN) is\nproposed based on tensor singular value decomposition (t-SVD). In particular,\nit can be proved that p-TNN is a better approximation of the tensor average\nrank than the tensor nuclear norm when p < 1. Therefore, by employing the\np-shrinkage nuclear norm, a novel low-rank tensor completion (LRTC) model is\nproposed to estimate a tensor from its partial observations. Statistically, the\nupper bound of recovery error is provided for the LRTC model. Furthermore, an\nefficient algorithm, accelerated by the adaptive momentum scheme, is developed\nto solve the resulting nonconvex optimization problem. It can be further\nguaranteed that the algorithm enjoys a global convergence rate under the\nsmoothness assumption. Numerical experiments conducted on both synthetic and\nreal-world data sets verify our results and demonstrate the superiority of our\np-TNN in LRTC problems over several state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jul 2019 11:37:15 GMT"}], "update_date": "2019-07-10", "authors_parsed": [["Liu", "Chunsheng", ""], ["Shan", "Hong", ""], ["Chen", "Chunlei", ""]]}, {"id": "1907.04102", "submitter": "Christian Wachinger", "authors": "Christian Wachinger, Benjamin Gutierrez Becker, Anna Rieckmann,\n  Sebastian P\\\"olsterl", "title": "Quantifying Confounding Bias in Neuroimaging Datasets with Causal\n  Inference", "comments": "MICCAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neuroimaging datasets keep growing in size to address increasingly complex\nmedical questions. However, even the largest datasets today alone are too small\nfor training complex machine learning models. A potential solution is to\nincrease sample size by pooling scans from several datasets. In this work, we\ncombine 12,207 MRI scans from 15 studies and show that simple pooling is often\nill-advised due to introducing various types of biases in the training data.\nFirst, we systematically define these biases. Second, we detect bias by\nexperimentally showing that scans can be correctly assigned to their respective\ndataset with 73.3% accuracy. Finally, we propose to tell causal from\nconfounding factors by quantifying the extent of confounding and causality in a\nsingle dataset using causal inference. We achieve this by finding the simplest\ngraphical model in terms of Kolmogorov complexity. As Kolmogorov complexity is\nnot directly computable, we employ the minimum description length to\napproximate it. We empirically show that our approach is able to estimate\nplausible causal relationships from real neuroimaging data.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jul 2019 11:57:22 GMT"}], "update_date": "2019-07-10", "authors_parsed": [["Wachinger", "Christian", ""], ["Becker", "Benjamin Gutierrez", ""], ["Rieckmann", "Anna", ""], ["P\u00f6lsterl", "Sebastian", ""]]}, {"id": "1907.04108", "submitter": "Konstantinos Spiliopoulos", "authors": "Justin Sirignano and Konstantinos Spiliopoulos", "title": "Scaling Limit of Neural Networks with the Xavier Initialization and\n  Convergence to a Global Minimum", "comments": "The results of this technical note have been extended and generalized\n  in arXiv:1911.07304. In the present note the full details for the proof of\n  the special case studied here are presented", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyze single-layer neural networks with the Xavier initialization in the\nasymptotic regime of large numbers of hidden units and large numbers of\nstochastic gradient descent training steps. The evolution of the neural network\nduring training can be viewed as a stochastic system and, using techniques from\nstochastic analysis, we prove the neural network converges in distribution to a\nrandom ODE with a Gaussian distribution. The limit is completely different than\nin the typical mean-field results for neural networks due to the\n$\\frac{1}{\\sqrt{N}}$ normalization factor in the Xavier initialization (versus\nthe $\\frac{1}{N}$ factor in the typical mean-field framework). Although the\npre-limit problem of optimizing a neural network is non-convex (and therefore\nthe neural network may converge to a local minimum), the limit equation\nminimizes a (quadratic) convex objective function and therefore converges to a\nglobal minimum. Furthermore, under reasonable assumptions, the matrix in the\nlimiting quadratic objective function is positive definite and thus the neural\nnetwork (in the limit) will converge to a global minimum with zero loss on the\ntraining set.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jul 2019 12:17:03 GMT"}, {"version": "v2", "created": "Tue, 19 Nov 2019 13:50:15 GMT"}], "update_date": "2019-11-20", "authors_parsed": [["Sirignano", "Justin", ""], ["Spiliopoulos", "Konstantinos", ""]]}, {"id": "1907.04135", "submitter": "James Wexler", "authors": "James Wexler, Mahima Pushkarna, Tolga Bolukbasi, Martin Wattenberg,\n  Fernanda Viegas, Jimbo Wilson", "title": "The What-If Tool: Interactive Probing of Machine Learning Models", "comments": "IEEE VIS (VAST) 2019", "journal-ref": null, "doi": "10.1109/TVCG.2019.2934619", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A key challenge in developing and deploying Machine Learning (ML) systems is\nunderstanding their performance across a wide range of inputs. To address this\nchallenge, we created the What-If Tool, an open-source application that allows\npractitioners to probe, visualize, and analyze ML systems, with minimal coding.\nThe What-If Tool lets practitioners test performance in hypothetical\nsituations, analyze the importance of different data features, and visualize\nmodel behavior across multiple models and subsets of input data. It also lets\npractitioners measure systems according to multiple ML fairness metrics. We\ndescribe the design of the tool, and report on real-life usage at different\norganizations.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jul 2019 13:16:24 GMT"}, {"version": "v2", "created": "Thu, 3 Oct 2019 17:00:59 GMT"}], "update_date": "2019-10-04", "authors_parsed": [["Wexler", "James", ""], ["Pushkarna", "Mahima", ""], ["Bolukbasi", "Tolga", ""], ["Wattenberg", "Martin", ""], ["Viegas", "Fernanda", ""], ["Wilson", "Jimbo", ""]]}, {"id": "1907.04138", "submitter": "Michael Oberst", "authors": "Michael Oberst, Fredrik D. Johansson, Dennis Wei, Tian Gao, Gabriel\n  Brat, David Sontag, Kush R. Varshney", "title": "Characterization of Overlap in Observational Studies", "comments": "To appear at AISTATS 2020", "journal-ref": "Proceedings of the Twenty Third International Conference on\n  Artificial Intelligence and Statistics, PMLR 108:788-798, 2020", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Overlap between treatment groups is required for non-parametric estimation of\ncausal effects. If a subgroup of subjects always receives the same\nintervention, we cannot estimate the effect of intervention changes on that\nsubgroup without further assumptions. When overlap does not hold globally,\ncharacterizing local regions of overlap can inform the relevance of causal\nconclusions for new subjects, and can help guide additional data collection. To\nhave impact, these descriptions must be interpretable for downstream users who\nare not machine learning experts, such as policy makers. We formalize overlap\nestimation as a problem of finding minimum volume sets subject to coverage\nconstraints and reduce this problem to binary classification with Boolean rule\nclassifiers. We then generalize this method to estimate overlap in off-policy\npolicy evaluation. In several real-world applications, we demonstrate that\nthese rules have comparable accuracy to black-box estimators and provide\nintuitive and informative explanations that can inform policy making.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jul 2019 13:18:47 GMT"}, {"version": "v2", "created": "Fri, 11 Oct 2019 07:49:35 GMT"}, {"version": "v3", "created": "Thu, 4 Jun 2020 01:46:10 GMT"}], "update_date": "2021-03-04", "authors_parsed": [["Oberst", "Michael", ""], ["Johansson", "Fredrik D.", ""], ["Wei", "Dennis", ""], ["Gao", "Tian", ""], ["Brat", "Gabriel", ""], ["Sontag", "David", ""], ["Varshney", "Kush R.", ""]]}, {"id": "1907.04150", "submitter": "Chong Peng", "authors": "Chong Peng, Zhao Kang, Chenglizhao Chen, and Qiang Cheng", "title": "Nonnegative Matrix Factorization with Local Similarity Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing nonnegative matrix factorization methods focus on learning global\nstructure of the data to construct basis and coefficient matrices, which\nignores the local structure that commonly exists among data. In this paper, we\npropose a new type of nonnegative matrix factorization method, which learns\nlocal similarity and clustering in a mutually enhancing way. The learned new\nrepresentation is more representative in that it better reveals inherent\ngeometric property of the data. Nonlinear expansion is given and efficient\nmultiplicative updates are developed with theoretical convergence guarantees.\nExtensive experimental results have confirmed the effectiveness of the proposed\nmodel.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jul 2019 13:25:50 GMT"}], "update_date": "2019-07-10", "authors_parsed": [["Peng", "Chong", ""], ["Kang", "Zhao", ""], ["Chen", "Chenglizhao", ""], ["Cheng", "Qiang", ""]]}, {"id": "1907.04152", "submitter": "Adam Dobrakowski", "authors": "Adam Gabriel Dobrakowski, Agnieszka Mykowiecka, Ma{\\l}gorzata\n  Marciniak, Wojciech Jaworski, Przemys{\\l}aw Biecek", "title": "Interpretable Segmentation of Medical Free-Text Records Based on Word\n  Embeddings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Is it true that patients with similar conditions get similar diagnoses? In\nthis paper we show NLP methods and a unique corpus of documents to validate\nthis claim. We (1) introduce a method for representation of medical visits\nbased on free-text descriptions recorded by doctors, (2) introduce a new method\nfor clustering of patients' visits and (3) present an~application of the\nproposed method on a corpus of 100,000 visits. With the proposed method we\nobtained stable and separated segments of visits which were positively\nvalidated against final medical diagnoses. We show how the presented algorithm\nmay be used to aid doctors during their practice.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jul 2019 15:22:04 GMT"}, {"version": "v2", "created": "Fri, 31 Jan 2020 11:13:32 GMT"}, {"version": "v3", "created": "Fri, 5 Jun 2020 10:09:48 GMT"}], "update_date": "2020-06-08", "authors_parsed": [["Dobrakowski", "Adam Gabriel", ""], ["Mykowiecka", "Agnieszka", ""], ["Marciniak", "Ma\u0142gorzata", ""], ["Jaworski", "Wojciech", ""], ["Biecek", "Przemys\u0142aw", ""]]}, {"id": "1907.04155", "submitter": "Vincent Fortuin", "authors": "Vincent Fortuin, Dmitry Baranchuk, Gunnar R\\\"atsch, Stephan Mandt", "title": "GP-VAE: Deep Probabilistic Time Series Imputation", "comments": "Accepted for publication at the 23rd International Conference on\n  Artificial Intelligence and Statistics (AISTATS 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multivariate time series with missing values are common in areas such as\nhealthcare and finance, and have grown in number and complexity over the years.\nThis raises the question whether deep learning methodologies can outperform\nclassical data imputation methods in this domain. However, naive applications\nof deep learning fall short in giving reliable confidence estimates and lack\ninterpretability. We propose a new deep sequential latent variable model for\ndimensionality reduction and data imputation. Our modeling assumption is simple\nand interpretable: the high dimensional time series has a lower-dimensional\nrepresentation which evolves smoothly in time according to a Gaussian process.\nThe non-linear dimensionality reduction in the presence of missing data is\nachieved using a VAE approach with a novel structured variational\napproximation. We demonstrate that our approach outperforms several classical\nand deep learning-based data imputation methods on high-dimensional data from\nthe domains of computer vision and healthcare, while additionally improving the\nsmoothness of the imputations and providing interpretable uncertainty\nestimates.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jul 2019 13:34:49 GMT"}, {"version": "v2", "created": "Thu, 11 Jul 2019 11:44:12 GMT"}, {"version": "v3", "created": "Fri, 12 Jul 2019 12:18:34 GMT"}, {"version": "v4", "created": "Sat, 19 Oct 2019 12:14:48 GMT"}, {"version": "v5", "created": "Thu, 20 Feb 2020 14:36:34 GMT"}], "update_date": "2020-02-21", "authors_parsed": [["Fortuin", "Vincent", ""], ["Baranchuk", "Dmitry", ""], ["R\u00e4tsch", "Gunnar", ""], ["Mandt", "Stephan", ""]]}, {"id": "1907.04164", "submitter": "Guodong Zhang", "authors": "Guodong Zhang, Lala Li, Zachary Nado, James Martens, Sushant Sachdeva,\n  George E. Dahl, Christopher J. Shallue, Roger Grosse", "title": "Which Algorithmic Choices Matter at Which Batch Sizes? Insights From a\n  Noisy Quadratic Model", "comments": "NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Increasing the batch size is a popular way to speed up neural network\ntraining, but beyond some critical batch size, larger batch sizes yield\ndiminishing returns. In this work, we study how the critical batch size changes\nbased on properties of the optimization algorithm, including acceleration and\npreconditioning, through two different lenses: large scale experiments, and\nanalysis of a simple noisy quadratic model (NQM). We experimentally demonstrate\nthat optimization algorithms that employ preconditioning, specifically Adam and\nK-FAC, result in much larger critical batch sizes than stochastic gradient\ndescent with momentum. We also demonstrate that the NQM captures many of the\nessential features of real neural network training, despite being drastically\nsimpler to work with. The NQM predicts our results with preconditioned\noptimizers, previous results with accelerated gradient descent, and other\nresults around optimal learning rates and large batch training, making it a\nuseful tool to generate testable predictions about neural network optimization.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jul 2019 13:44:10 GMT"}, {"version": "v2", "created": "Mon, 28 Oct 2019 14:28:48 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Zhang", "Guodong", ""], ["Li", "Lala", ""], ["Nado", "Zachary", ""], ["Martens", "James", ""], ["Sachdeva", "Sushant", ""], ["Dahl", "George E.", ""], ["Shallue", "Christopher J.", ""], ["Grosse", "Roger", ""]]}, {"id": "1907.04197", "submitter": "Desmond Ong", "authors": "Zhengxuan Wu, Xiyu Zhang, Tan Zhi-Xuan, Jamil Zaki, Desmond C. Ong", "title": "Attending to Emotional Narratives", "comments": "Accepted at IEEE Affective Computing and Intelligent Interaction\n  (ACII) 2019; 6 pages + 1 page ref; 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Attention mechanisms in deep neural networks have achieved excellent\nperformance on sequence-prediction tasks. Here, we show that these\nrecently-proposed attention-based mechanisms---in particular, the Transformer\nwith its parallelizable self-attention layers, and the Memory Fusion Network\nwith attention across modalities and time---also generalize well to multimodal\ntime-series emotion recognition. Using a recently-introduced dataset of\nemotional autobiographical narratives, we adapt and apply these two attention\nmechanisms to predict emotional valence over time. Our models perform extremely\nwell, in some cases reaching a performance comparable with human raters. We end\nwith a discussion of the implications of attention mechanisms to affective\ncomputing.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jul 2019 03:50:43 GMT"}], "update_date": "2019-07-10", "authors_parsed": [["Wu", "Zhengxuan", ""], ["Zhang", "Xiyu", ""], ["Zhi-Xuan", "Tan", ""], ["Zaki", "Jamil", ""], ["Ong", "Desmond C.", ""]]}, {"id": "1907.04198", "submitter": "Jennifer Gago", "authors": "Jennifer J. Gago, Valentina Vasco, Bartek {\\L}ukawski, Ugo Pattacini,\n  Vadim Tikhanoff, Juan G. Victores, Carlos Balaguer", "title": "Sequence-to-Sequence Natural Language to Humanoid Robot Sign Language", "comments": "13 pages, 8 figures, conference", "journal-ref": null, "doi": "10.11128/arep.58", "report-no": null, "categories": "cs.RO cs.CL cs.HC cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This paper presents a study on natural language to sign language translation\nwith human-robot interaction application purposes. By means of the presented\nmethodology, the humanoid robot TEO is expected to represent Spanish sign\nlanguage automatically by converting text into movements, thanks to the\nperformance of neural networks. Natural language to sign language translation\npresents several challenges to developers, such as the discordance between the\nlength of input and output data and the use of non-manual markers. Therefore,\nneural networks and, consequently, sequence-to-sequence models, are selected as\na data-driven system to avoid traditional expert system approaches or temporal\ndependencies limitations that lead to limited or too complex translation\nsystems. To achieve these objectives, it is necessary to find a way to perform\nhuman skeleton acquisition in order to collect the signing input data. OpenPose\nand skeletonRetriever are proposed for this purpose and a 3D sensor\nspecification study is developed to select the best acquisition hardware.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jul 2019 14:41:50 GMT"}], "update_date": "2019-07-10", "authors_parsed": [["Gago", "Jennifer J.", ""], ["Vasco", "Valentina", ""], ["\u0141ukawski", "Bartek", ""], ["Pattacini", "Ugo", ""], ["Tikhanoff", "Vadim", ""], ["Victores", "Juan G.", ""], ["Balaguer", "Carlos", ""]]}, {"id": "1907.04201", "submitter": "Cem Tekin", "authors": "Alihan H\\\"uy\\\"uk and Cem Tekin", "title": "Thompson Sampling for Combinatorial Network Optimization in Unknown\n  Environments", "comments": "14 pages, 3 figures. Accepted for publication in the IEEE/ACM\n  Transactions on Networking. arXiv admin note: text overlap with\n  arXiv:1809.02707", "journal-ref": "IEEE/ACM Transactions on Networking, vol. 28, no. 6, pp.\n  2836-2849, Dec. 2020", "doi": "10.1109/TNET.2020.3025904", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Influence maximization, adaptive routing, and dynamic spectrum allocation all\nrequire choosing the right action from a large set of alternatives. Thanks to\nthe advances in combinatorial optimization, these and many similar problems can\nbe efficiently solved given an environment with known stochasticity. In this\npaper, we take this one step further and focus on combinatorial optimization in\nunknown environments. We consider a very general learning framework called\ncombinatorial multi-armed bandit with probabilistically triggered arms and a\nvery powerful Bayesian algorithm called Combinatorial Thompson Sampling (CTS).\nUnder the semi-bandit feedback model and assuming access to an oracle without\nknowing the expected base arm outcomes beforehand, we show that when the\nexpected reward is Lipschitz continuous in the expected base arm outcomes CTS\nachieves $O(\\sum_{i =1}^m\\log T/(p_i\\Delta_i))$ regret and\n$O(\\max\\{\\mathbb{E}[m\\sqrt{T\\log T/p^*}],\\mathbb{E}[m^2/p^*]\\})$ Bayesian\nregret, where $m$ denotes the number of base arms, $p_i$ and $\\Delta_i$ denote\nthe minimum non-zero triggering probability and the minimum suboptimality gap\nof base arm $i$ respectively, $T$ denotes the time horizon, and $p^*$ denotes\nthe overall minimum non-zero triggering probability. We also show that when the\nexpected reward satisfies the triggering probability modulated Lipschitz\ncontinuity, CTS achieves $O(\\max\\{m\\sqrt{T\\log T},m^2\\})$ Bayesian regret, and\nwhen triggering probabilities are non-zero for all base arms, CTS achieves\n$O(1/p^*\\log(1/p^*))$ regret independent of the time horizon. Finally, we\nnumerically compare CTS with algorithms based on upper confidence bounds in\nseveral networking problems and show that CTS outperforms these algorithms by\nat least an order of magnitude in majority of the cases.\n", "versions": [{"version": "v1", "created": "Sun, 7 Jul 2019 17:03:00 GMT"}, {"version": "v2", "created": "Mon, 15 Jul 2019 09:25:32 GMT"}, {"version": "v3", "created": "Mon, 21 Sep 2020 17:22:06 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["H\u00fcy\u00fck", "Alihan", ""], ["Tekin", "Cem", ""]]}, {"id": "1907.04202", "submitter": "Masashi Okada Dr", "authors": "Masashi Okada, Tadahiro Taniguchi", "title": "Variational Inference MPC for Bayesian Model-based Reinforcement\n  Learning", "comments": "Accepted to CoRL2019. Camera-ready ver", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent studies on model-based reinforcement learning (MBRL), incorporating\nuncertainty in forward dynamics is a state-of-the-art strategy to enhance\nlearning performance, making MBRLs competitive to cutting-edge model free\nmethods, especially in simulated robotics tasks. Probabilistic ensembles with\ntrajectory sampling (PETS) is a leading type of MBRL, which employs Bayesian\ninference to dynamics modeling and model predictive control (MPC) with\nstochastic optimization via the cross entropy method (CEM). In this paper, we\npropose a novel extension to the uncertainty-aware MBRL. Our main contributions\nare twofold: Firstly, we introduce a variational inference MPC, which\nreformulates various stochastic methods, including CEM, in a Bayesian fashion.\nSecondly, we propose a novel instance of the framework, called probabilistic\naction ensembles with trajectory sampling (PaETS). As a result, our Bayesian\nMBRL can involve multimodal uncertainties both in dynamics and optimal\ntrajectories. In comparison to PETS, our method consistently improves\nasymptotic performance on several challenging locomotion tasks.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jul 2019 01:54:08 GMT"}, {"version": "v2", "created": "Mon, 7 Oct 2019 01:03:08 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Okada", "Masashi", ""], ["Taniguchi", "Tadahiro", ""]]}, {"id": "1907.04212", "submitter": "Koichi Tojo", "authors": "Koichi Tojo, Taro Yoshino", "title": "On a method to construct exponential families by representation theory", "comments": "Conference paper at Geometric Science of Information 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.RT cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Exponential family plays an important role in information geometry. In\narXiv:1811.01394, we introduced a method to construct an exponential family\n$\\mathcal{P}=\\{p_\\theta\\}_{\\theta\\in\\Theta}$ on a homogeneous space $G/H$ from\na pair $(V,v_0)$. Here $V$ is a representation of $G$ and $v_0$ is an $H$-fixed\nvector in $V$. Then the following questions naturally arise: (Q1) when is the\ncorrespondence $\\theta\\mapsto p_\\theta$ injective? (Q2) when do distinct pairs\n$(V,v_0)$ and $(V',v_0')$ generate the same family? In this paper, we answer\nthese two questions (Theorems 1 and 2). Moreover, in Section 3, we consider the\ncase $(G,H)=(\\mathbb{R}_{>0}, \\{1\\})$ with a certain representation on\n$\\mathbb{R}^2$. Then we see the family obtained by our method is essentially\ngeneralized inverse Gaussian distribution (GIG).\n", "versions": [{"version": "v1", "created": "Sat, 6 Jul 2019 06:43:58 GMT"}], "update_date": "2019-07-10", "authors_parsed": [["Tojo", "Koichi", ""], ["Yoshino", "Taro", ""]]}, {"id": "1907.04214", "submitter": "Boris Belousov", "authors": "Boris Belousov, Jan Peters", "title": "Entropic Regularization of Markov Decision Processes", "comments": "16 pages, 4 figures, updated formatting, arXiv admin note: text\n  overlap with arXiv:1801.00056", "journal-ref": "Entropy 2019, 21(7), 674", "doi": "10.3390/e21070674", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  An optimal feedback controller for a given Markov decision process (MDP) can\nin principle be synthesized by value or policy iteration. However, if the\nsystem dynamics and the reward function are unknown, a learning agent must\ndiscover an optimal controller via direct interaction with the environment.\nSuch interactive data gathering commonly leads to divergence towards dangerous\nor uninformative regions of the state space unless additional regularization\nmeasures are taken. Prior works proposed bounding the information loss measured\nby the Kullback-Leibler (KL) divergence at every policy improvement step to\neliminate instability in the learning dynamics. In this paper, we consider a\nbroader family of $f$-divergences, and more concretely $\\alpha$-divergences,\nwhich inherit the beneficial property of providing the policy improvement step\nin closed form at the same time yielding a corresponding dual objective for\npolicy evaluation. Such entropic proximal policy optimization view gives a\nunified perspective on compatible actor-critic architectures. In particular,\ncommon least-squares value function estimation coupled with advantage-weighted\nmaximum likelihood policy improvement is shown to correspond to the Pearson\n$\\chi^2$-divergence penalty. Other actor-critic pairs arise for various choices\nof the penalty-generating function $f$. On a concrete instantiation of our\nframework with the $\\alpha$-divergence, we carry out asymptotic analysis of the\nsolutions for different values of $\\alpha$ and demonstrate the effects of the\ndivergence function choice on common standard reinforcement learning problems.\n", "versions": [{"version": "v1", "created": "Sat, 6 Jul 2019 15:02:56 GMT"}, {"version": "v2", "created": "Thu, 18 Jul 2019 07:12:31 GMT"}], "update_date": "2019-07-19", "authors_parsed": [["Belousov", "Boris", ""], ["Peters", "Jan", ""]]}, {"id": "1907.04222", "submitter": "Vikas Ahuja", "authors": "Vijay Kumar Neeluru, Vikas Ahuja", "title": "Void region segmentation in ball grid array using u-net approach and\n  synthetic data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The quality inspection of solder balls by detecting and measuring the void is\nimportant to improve the board yield issues in electronic circuits. In general,\nthe inspection is carried out manually, based on 2D or 3D X-ray images. For\nhigh quality inspection, it is difficult to detect and measure voids accurately\nwith high repeatability through the manual inspection and the process is time\nconsuming. In need of high quality and fast inspection, various approaches were\nproposed, but, due to the various challenges like vias, reflections from the\nplating or vias, inconsistent lighting, noise and void-like artifacts makes\nthese approaches difficult to work in all these challenging conditions. In\nrecent times, deep learning approaches are providing the outstanding accuracy\nin various computer vision tasks. Considering the need of high quality and fast\ninspection, in this paper, we applied U-Net to segment the void regions in\nsoldering balls. As it is difficult to get the annotated dataset covering all\nthe variations of void, we proposed an approach to generated the synthetic\ndataset. The proposed approach is able to segment the voids and can be easily\nscaled to various electronic products.\n", "versions": [{"version": "v1", "created": "Sun, 7 Jul 2019 12:04:20 GMT"}], "update_date": "2019-07-10", "authors_parsed": [["Neeluru", "Vijay Kumar", ""], ["Ahuja", "Vikas", ""]]}, {"id": "1907.04223", "submitter": "Donald Hulsey", "authors": "Donald Waagen, Katie Rainey, Jamie Gantert, David Gray, Megan King, M.\n  Shane Thompson, Jonathan Barton, Will Waldron, Samantha Livingston, and Don\n  Hulsey", "title": "Characterizing Inter-Layer Functional Mappings of Deep Learning Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning architectures have demonstrated state-of-the-art performance\nfor object classification and have become ubiquitous in commercial products.\nThese methods are often applied without understanding (a) the difficulty of a\nclassification task given the input data, and (b) how a specific deep learning\narchitecture transforms that data. To answer (a) and (b), we illustrate the\nutility of a multivariate nonparametric estimator of class separation, the\nHenze-Penrose (HP) statistic, in the original as well as layer-induced\nrepresentations. Given an $N$-class problem, our contribution defines the\n$C(N,2)$ combinations of HP statistics as a sample from a distribution of\nclass-pair separations. This allows us to characterize the distributional\nchange to class separation induced at each layer of the model. Fisher\npermutation tests are used to detect statistically significant changes within a\nmodel. By comparing the HP statistic distributions between layers, one can\nstatistically characterize: layer adaptation during training, the contribution\nof each layer to the classification task, and the presence or absence of\nconsistency between training and validation data. This is demonstrated for a\nsimple deep neural network using CIFAR10 with random-labels, CIFAR10, and MNIST\ndatasets.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jul 2019 14:58:59 GMT"}, {"version": "v2", "created": "Mon, 23 Sep 2019 23:23:37 GMT"}], "update_date": "2019-09-25", "authors_parsed": [["Waagen", "Donald", ""], ["Rainey", "Katie", ""], ["Gantert", "Jamie", ""], ["Gray", "David", ""], ["King", "Megan", ""], ["Thompson", "M. Shane", ""], ["Barton", "Jonathan", ""], ["Waldron", "Will", ""], ["Livingston", "Samantha", ""], ["Hulsey", "Don", ""]]}, {"id": "1907.04232", "submitter": "Sebastian U. Stich", "authors": "Sebastian U. Stich", "title": "Unified Optimal Analysis of the (Stochastic) Gradient Method", "comments": "11 pages, version 2 fixes typos and case distinction in the proof", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA math.NA math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this note we give a simple proof for the convergence of stochastic\ngradient (SGD) methods on $\\mu$-convex functions under a (milder than standard)\n$L$-smoothness assumption. We show that for carefully chosen stepsizes SGD\nconverges after $T$ iterations as $O\\left( LR^2 \\exp\n\\bigl[-\\frac{\\mu}{4L}T\\bigr] + \\frac{\\sigma^2}{\\mu T} \\right)$ where $\\sigma^2$\nmeasures the variance in the stochastic noise. For deterministic gradient\ndescent (GD) and SGD in the interpolation setting we have $\\sigma^2 =0$ and we\nrecover the exponential convergence rate. The bound matches with the best known\niteration complexity of GD and SGD, up to constants.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jul 2019 15:14:25 GMT"}, {"version": "v2", "created": "Mon, 23 Dec 2019 13:14:42 GMT"}], "update_date": "2019-12-24", "authors_parsed": [["Stich", "Sebastian U.", ""]]}, {"id": "1907.04233", "submitter": "Richard Hugh Moulton", "authors": "Richard Hugh Moulton, Herna L. Viktor, Nathalie Japkowicz, Jo\\~ao Gama", "title": "Contextual One-Class Classification in Data Streams", "comments": "49 pages, 18 figures, 2 appendices", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In machine learning, the one-class classification problem occurs when\ntraining instances are only available from one class. It has been observed that\nmaking use of this class's structure, or its different contexts, may improve\none-class classifier performance. Although this observation has been\ndemonstrated for static data, a rigorous application of the idea within the\ndata stream environment is lacking. To address this gap, we propose the use of\ncontext to guide one-class classifier learning in data streams, paying\nparticular attention to the challenges presented by the dynamic learning\nenvironment. We present three frameworks that learn contexts and conduct\nexperiments with synthetic and benchmark data streams. We conclude that the\nparadigm of contexts in data streams can be used to improve the performance of\nstreaming one-class classifiers.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jul 2019 15:14:38 GMT"}], "update_date": "2019-07-10", "authors_parsed": [["Moulton", "Richard Hugh", ""], ["Viktor", "Herna L.", ""], ["Japkowicz", "Nathalie", ""], ["Gama", "Jo\u00e3o", ""]]}, {"id": "1907.04240", "submitter": "Xihaier Luo", "authors": "Xihaier Luo, Ahsan Kareem", "title": "Bayesian deep learning with hierarchical prior: Predictions from limited\n  and noisy data", "comments": "33 pages, 11 figures", "journal-ref": "Structural Safety, 84, p.101918 (2020)", "doi": "10.1016/j.strusafe.2019.101918", "report-no": null, "categories": "stat.ML cs.LG eess.SP physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Datasets in engineering applications are often limited and contaminated,\nmainly due to unavoidable measurement noise and signal distortion. Thus, using\nconventional data-driven approaches to build a reliable discriminative model,\nand further applying this identified surrogate to uncertainty analysis remains\nto be very challenging. A deep learning approach is presented to provide\npredictions based on limited and noisy data. To address noise perturbation, the\nBayesian learning method that naturally facilitates an automatic updating\nmechanism is considered to quantify and propagate model uncertainties into\npredictive quantities. Specifically, hierarchical Bayesian modeling (HBM) is\nfirst adopted to describe model uncertainties, which allows the prior\nassumption to be less subjective, while also makes the proposed surrogate more\nrobust. Next, the Bayesian inference is seamlessly integrated into the DL\nframework, which in turn supports probabilistic programming by yielding a\nprobability distribution of the quantities of interest rather than their point\nestimates. Variational inference (VI) is implemented for the posterior\ndistribution analysis where the intractable marginalization of the likelihood\nfunction over parameter space is framed in an optimization format, and\nstochastic gradient descent method is applied to solve this optimization\nproblem. Finally, Monte Carlo simulation is used to obtain an unbiased\nestimator in the predictive phase of Bayesian inference, where the proposed\nBayesian deep learning (BDL) scheme is able to offer confidence bounds for the\noutput estimation by analyzing propagated uncertainties. The effectiveness of\nBayesian shrinkage is demonstrated in improving predictive performance using\ncontaminated data, and various examples are provided to illustrate concepts,\nmethodologies, and algorithms of this proposed BDL modeling technique.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jul 2019 15:37:40 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Luo", "Xihaier", ""], ["Kareem", "Ahsan", ""]]}, {"id": "1907.04246", "submitter": "Laurent Gomez", "authors": "Laurent Gomez, Marcus Wilhelm, Jos\\'e M\\'arquez and Patrick Duverger", "title": "Security for Distributed Deep Neural Networks Towards Data\n  Confidentiality & Intellectual Property Protection", "comments": null, "journal-ref": "Proceedings of the 16th International Joint Conference on\n  e-Business and Telecommunications, ICETE 2019", "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current developments in Enterprise Systems observe a paradigm shift, moving\nthe needle from the backend to the edge sectors of those; by distributing data,\ndecentralizing applications and integrating novel components seamlessly to the\ncentral systems. Distributively deployed AI capabilities will thrust this\ntransition. Several non-functional requirements arise along with these\ndevelopments, security being at the center of the discussions. Bearing those\nrequirements in mind, hereby we propose an approach to holistically protect\ndistributed Deep Neural Network (DNN) based/enhanced software assets, i.e.\nconfidentiality of their input & output data streams as well as safeguarding\ntheir Intellectual Property. Making use of Fully Homomorphic Encryption (FHE),\nour approach enables the protection of Distributed Neural Networks, while\nprocessing encrypted data. On that respect we evaluate the feasibility of this\nsolution on a Convolutional Neuronal Network (CNN) for image classification\ndeployed on distributed infrastructures.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jul 2019 15:29:42 GMT"}], "update_date": "2019-07-10", "authors_parsed": [["Gomez", "Laurent", ""], ["Wilhelm", "Marcus", ""], ["M\u00e1rquez", "Jos\u00e9", ""], ["Duverger", "Patrick", ""]]}, {"id": "1907.04251", "submitter": "Melanie Beckerleg", "authors": "Melanie Beckerleg and Andrew Thompson", "title": "A divide-and-conquer algorithm for binary matrix completion", "comments": "14 pages,4 figures", "journal-ref": "Linear Algebra and its Applications, Volume 601, 2020, Pages\n  113-133", "doi": "10.1016/j.laa.2020.04.017", "report-no": null, "categories": "math.NA cs.LG cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an algorithm for low rank matrix completion for matrices with\nbinary entries which obtains explicit binary factors. Our algorithm, which we\ncall TBMC (\\emph{Tiling for Binary Matrix Completion}), gives interpretable\noutput in the form of binary factors which represent a decomposition of the\nmatrix into tiles. Our approach is inspired by a popular algorithm from the\ndata mining community called PROXIMUS: it adopts the same recursive\npartitioning approach while extending to missing data. The algorithm relies\nupon rank-one approximations of incomplete binary matrices, and we propose a\nlinear programming (LP) approach for solving this subproblem. We also prove a\n$2$-approximation result for the LP approach which holds for any level of\nsubsampling and for any subsampling pattern. Our numerical experiments show\nthat TBMC outperforms existing methods on recommender systems arising in the\ncontext of real datasets.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jul 2019 15:33:06 GMT"}, {"version": "v2", "created": "Fri, 19 Jun 2020 21:40:10 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Beckerleg", "Melanie", ""], ["Thompson", "Andrew", ""]]}, {"id": "1907.04275", "submitter": "Seonguk Seo", "authors": "Seonguk Seo, Yumin Suh, Dongwan Kim, Geeho Kim, Jongwoo Han, Bohyung\n  Han", "title": "Learning to Optimize Domain Specific Normalization for Domain\n  Generalization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a simple but effective multi-source domain generalization\ntechnique based on deep neural networks by incorporating optimized\nnormalization layers that are specific to individual domains. Our approach\nemploys multiple normalization methods while learning separate affine\nparameters per domain. For each domain, the activations are normalized by a\nweighted average of multiple normalization statistics. The normalization\nstatistics are kept track of separately for each normalization type if\nnecessary. Specifically, we employ batch and instance normalizations in our\nimplementation to identify the best combination of these two normalization\nmethods in each domain. The optimized normalization layers are effective to\nenhance the generalizability of the learned model. We demonstrate the\nstate-of-the-art accuracy of our algorithm in the standard domain\ngeneralization benchmarks, as well as viability to further tasks such as\nmulti-source domain adaptation and domain generalization in the presence of\nlabel noise.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jul 2019 16:24:31 GMT"}, {"version": "v2", "created": "Mon, 23 Sep 2019 15:56:47 GMT"}, {"version": "v3", "created": "Tue, 21 Jul 2020 07:10:51 GMT"}], "update_date": "2020-07-22", "authors_parsed": [["Seo", "Seonguk", ""], ["Suh", "Yumin", ""], ["Kim", "Dongwan", ""], ["Kim", "Geeho", ""], ["Han", "Jongwoo", ""], ["Han", "Bohyung", ""]]}, {"id": "1907.04276", "submitter": "V\\'ictor Gallego-Fontenla", "authors": "V\\'ictor Gallego-Fontenla, Juan C. Vidal and Manuel Lama", "title": "A Conformance Checking-based Approach for Drift Detection in Business\n  Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Real life business processes change over time, in both planned and unexpected\nways. The detection of these changes is crucial for organizations to ensure\nthat the expected and the real behavior are as similar as possible. These\nchanges over time are called concept drift and its detection is a big challenge\nin process mining since the inherent complexity of the data makes difficult\ndistinguishing between a change and an anomalous execution. In this paper, we\npresent C2D2 (Conformance Checking-based Drift Detection), a new approach to\ndetect sudden control-flow changes in the process models from event traces.\nC2D2 combines discovery techniques with conformance checking methods to perform\nan offline detection. Our approach has been validated with a synthetic\nbenchmarking dataset formed by 68 logs, showing an improvement in the accuracy\nwhile maintaining a minimum delay in the drift detection.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jul 2019 16:24:33 GMT"}], "update_date": "2019-07-10", "authors_parsed": [["Gallego-Fontenla", "V\u00edctor", ""], ["Vidal", "Juan C.", ""], ["Lama", "Manuel", ""]]}, {"id": "1907.04281", "submitter": "Giulia Cisotto", "authors": "Matteo Gadaleta, Giulia Cisotto, Michele Rossi, Rana Zia Ur Rehman,\n  Lynn Rochester, Silvia Del Din", "title": "Deep Learning Techniques for Improving Digital Gait Segmentation", "comments": null, "journal-ref": "2019 41st Annual International Conference of the IEEE Engineering\n  in Medicine and Biology Society (EMBC)", "doi": "10.1109/EMBC.2019.8856685", "report-no": null, "categories": "eess.SP cs.LG cs.NE eess.IV q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Wearable technology for the automatic detection of gait events has recently\ngained growing interest, enabling advanced analyses that were previously\nlimited to specialist centres and equipment (e.g., instrumented walkway). In\nthis study, we present a novel method based on dilated convolutions for an\naccurate detection of gait events (initial and final foot contacts) from\nwearable inertial sensors. A rich dataset has been used to validate the method,\nfeaturing 71 people with Parkinson's disease (PD) and 67 healthy control\nsubjects. Multiple sensors have been considered, one located on the fifth\nlumbar vertebrae and two on the ankles. The aims of this study were: (i) to\napply deep learning (DL) techniques on wearable sensor data for gait\nsegmentation and quantification in older adults and in people with PD; (ii) to\nvalidate the proposed technique for measuring gait against traditional gold\nstandard laboratory reference and a widely used algorithm based on wavelet\ntransforms (WT); (iii) to assess the performance of DL methods in assessing\nhigh-level gait characteristics, with focus on stride, stance and swing related\nfeatures. The results showed a high reliability of the proposed approach, which\nachieves temporal errors considerably smaller than WT, in particular for the\ndetection of final contacts, with an inter-quartile range below 70 ms in the\nworst case. This study showes encouraging results, and paves the road for\nfurther research, addressing the effectiveness and the generalization of\ndata-driven learning systems for accurate event detection in challenging\nconditions.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jul 2019 16:29:58 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Gadaleta", "Matteo", ""], ["Cisotto", "Giulia", ""], ["Rossi", "Michele", ""], ["Rehman", "Rana Zia Ur", ""], ["Rochester", "Lynn", ""], ["Del Din", "Silvia", ""]]}, {"id": "1907.04286", "submitter": "William Kearns", "authors": "William R. Kearns, Wilson Lau, Jason A. Thomas", "title": "UW-BHI at MEDIQA 2019: An Analysis of Representation Methods for Medical\n  Natural Language Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in distributed language modeling have led to large\nperformance increases on a variety of natural language processing (NLP) tasks.\nHowever, it is not well understood how these methods may be augmented by\nknowledge-based approaches. This paper compares the performance and internal\nrepresentation of an Enhanced Sequential Inference Model (ESIM) between three\nexperimental conditions based on the representation method: Bidirectional\nEncoder Representations from Transformers (BERT), Embeddings of Semantic\nPredications (ESP), or Cui2Vec. The methods were evaluated on the Medical\nNatural Language Inference (MedNLI) subtask of the MEDIQA 2019 shared task.\nThis task relied heavily on semantic understanding and thus served as a\nsuitable evaluation set for the comparison of these representation methods.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jul 2019 16:47:50 GMT"}], "update_date": "2019-07-10", "authors_parsed": [["Kearns", "William R.", ""], ["Lau", "Wilson", ""], ["Thomas", "Jason A.", ""]]}, {"id": "1907.04298", "submitter": "Pedro F. Proen\\c{c}a", "authors": "Pedro F. Proenca and Yang Gao", "title": "Deep Learning for Spacecraft Pose Estimation from Photorealistic\n  Rendering", "comments": "* Adding more related work and references", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  On-orbit proximity operations in space rendezvous, docking and debris removal\nrequire precise and robust 6D pose estimation under a wide range of lighting\nconditions and against highly textured background, i.e., the Earth. This paper\ninvestigates leveraging deep learning and photorealistic rendering for\nmonocular pose estimation of known uncooperative spacecrafts. We first present\na simulator built on Unreal Engine 4, named URSO, to generate labeled images of\nspacecrafts orbiting the Earth, which can be used to train and evaluate neural\nnetworks. Secondly, we propose a deep learning framework for pose estimation\nbased on orientation soft classification, which allows modelling orientation\nambiguity as a mixture of Gaussians. This framework was evaluated both on URSO\ndatasets and the ESA pose estimation challenge. In this competition, our best\nmodel achieved 3rd place on the synthetic test set and 2nd place on the real\ntest set. Moreover, our results show the impact of several architectural and\ntraining aspects, and we demonstrate qualitatively how models learned on URSO\ndatasets can perform on real images from space.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jul 2019 17:32:38 GMT"}, {"version": "v2", "created": "Thu, 29 Aug 2019 16:03:11 GMT"}], "update_date": "2019-08-30", "authors_parsed": [["Proenca", "Pedro F.", ""], ["Gao", "Yang", ""]]}, {"id": "1907.04312", "submitter": "Boyi Li", "authors": "Boyi Li and Felix Wu and Kilian Q. Weinberger and Serge Belongie", "title": "Positional Normalization", "comments": "Accepted to NeurIPS 2019 (spotlight)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A popular method to reduce the training time of deep neural networks is to\nnormalize activations at each layer. Although various normalization schemes\nhave been proposed, they all follow a common theme: normalize across spatial\ndimensions and discard the extracted statistics. In this paper, we propose an\nalternative normalization method that noticeably departs from this convention\nand normalizes exclusively across channels. We argue that the channel dimension\nis naturally appealing as it allows us to extract the first and second moments\nof features extracted at a particular image position. These moments capture\nstructural information about the input image and extracted features, which\nopens a new avenue along which a network can benefit from feature\nnormalization: Instead of disregarding the normalization constants, we propose\nto re-inject them into later layers to preserve or transfer structural\ninformation in generative networks. Codes are available at\nhttps://github.com/Boyiliee/PONO.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jul 2019 17:52:01 GMT"}, {"version": "v2", "created": "Thu, 19 Dec 2019 18:58:04 GMT"}], "update_date": "2019-12-20", "authors_parsed": [["Li", "Boyi", ""], ["Wu", "Felix", ""], ["Weinberger", "Kilian Q.", ""], ["Belongie", "Serge", ""]]}, {"id": "1907.04318", "submitter": "Ahmed BaniMustafa Dr.", "authors": "Ahmed BaniMustafa and Nigel Hardy", "title": "Computer-Aided Data Mining: Automating a Novel Knowledge Discovery and\n  Data Mining Process Model for Metabolomics", "comments": "arXiv admin note: text overlap with arXiv:1907.03755", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.DB cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work presents MeKDDaM-SAGA, computer-aided automation software for\nimplementing a novel knowledge discovery and data mining process model that was\ndesigned for performing justifiable, traceable and reproducible metabolomics\ndata analysis. The process model focuses on achieving metabolomics analytical\nobjectives and on considering the nature of its involved data. MeKDDaM-SAGA was\nsuccessfully used for guiding the process model execution in a number of\nmetabolomics applications. It satisfies the requirements of the proposed\nprocess model design and execution. The software realises the process model\nlayout, structure and flow and it enables its execution externally using\nvarious data mining and machine learning tools or internally using a number of\nembedded facilities that were built for performing a number of automated\nactivities such as data preprocessing, data exploration, data acclimatization,\nmodelling, evaluation and visualization. MeKDDaM-SAGA was developed using\nobject-oriented software engineering methodology and was constructed in Java.\nIt consists of 241 design classes that were designed to implement 27 use-cases.\nThe software uses an XML database to guarantee portability and uses a GUI\ninterface to ensure its user-friendliness. It implements an internal embedded\nversion control system that is used to realise and manage the process flow,\nfeedback and iterations and to enable undoing and redoing the execution of the\nprocess phases, activities, and the internal tasks within its phases.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jul 2019 01:14:53 GMT"}], "update_date": "2019-07-11", "authors_parsed": [["BaniMustafa", "Ahmed", ""], ["Hardy", "Nigel", ""]]}, {"id": "1907.04352", "submitter": "Nicholas Meade", "authors": "Nicholas Meade, Nicholas Barreyre, Scott C. Lowe, Sageev Oore", "title": "Exploring Conditioning for Generative Music Systems with\n  Human-Interpretable Controls", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Performance RNN is a machine-learning system designed primarily for the\ngeneration of solo piano performances using an event-based (rather than audio)\nrepresentation. More specifically, Performance RNN is a long short-term memory\n(LSTM) based recurrent neural network that models polyphonic music with\nexpressive timing and dynamics (Oore et al., 2018). The neural network uses a\nsimple language model based on the Musical Instrument Digital Interface (MIDI)\nfile format. Performance RNN is trained on the e-Piano Junior Competition\nDataset (International Piano e-Competition, 2018), a collection of solo piano\nperformances by expert pianists. As an artistic tool, one of the limitations of\nthe original model has been the lack of useable controls. The standard form of\nPerformance RNN can generate interesting pieces, but little control is provided\nover what specifically is generated. This paper explores a set of\nconditioning-based controls used to influence the generation process.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jul 2019 18:20:05 GMT"}, {"version": "v2", "created": "Thu, 11 Jul 2019 13:50:53 GMT"}, {"version": "v3", "created": "Sun, 4 Aug 2019 00:40:23 GMT"}], "update_date": "2019-08-06", "authors_parsed": [["Meade", "Nicholas", ""], ["Barreyre", "Nicholas", ""], ["Lowe", "Scott C.", ""], ["Oore", "Sageev", ""]]}, {"id": "1907.04355", "submitter": "Wei-Ning Hsu", "authors": "Wei-Ning Hsu, David Harwath, James Glass", "title": "Transfer Learning from Audio-Visual Grounding to Speech Recognition", "comments": "Accepted to Interspeech 2019. 4 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transfer learning aims to reduce the amount of data required to excel at a\nnew task by re-using the knowledge acquired from learning other related tasks.\nThis paper proposes a novel transfer learning scenario, which distills robust\nphonetic features from grounding models that are trained to tell whether a pair\nof image and speech are semantically correlated, without using any textual\ntranscripts. As semantics of speech are largely determined by its lexical\ncontent, grounding models learn to preserve phonetic information while\ndisregarding uncorrelated factors, such as speaker and channel. To study the\nproperties of features distilled from different layers, we use them as input\nseparately to train multiple speech recognition models. Empirical results\ndemonstrate that layers closer to input retain more phonetic information, while\nfollowing layers exhibit greater invariance to domain shift. Moreover, while\nmost previous studies include training data for speech recognition for feature\nextractor training, our grounding models are not trained on any of those data,\nindicating more universal applicability to new domains.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jul 2019 18:23:32 GMT"}], "update_date": "2019-07-11", "authors_parsed": [["Hsu", "Wei-Ning", ""], ["Harwath", "David", ""], ["Glass", "James", ""]]}, {"id": "1907.04371", "submitter": "Kenji Kawaguchi", "authors": "Kenji Kawaguchi, Haihao Lu", "title": "Ordered SGD: A New Stochastic Optimization Framework for Empirical Risk\n  Minimization", "comments": "Accepted in AISTATS 2020. Code available at:\n  https://github.com/k9k2/qSGD", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new stochastic optimization framework for empirical risk\nminimization problems such as those that arise in machine learning. The\ntraditional approaches, such as (mini-batch) stochastic gradient descent (SGD),\nutilize an unbiased gradient estimator of the empirical average loss. In\ncontrast, we develop a computationally efficient method to construct a gradient\nestimator that is purposely biased toward those observations with higher\ncurrent losses. On the theory side, we show that the proposed method minimizes\na new ordered modification of the empirical average loss, and is guaranteed to\nconverge at a sublinear rate to a global optimum for convex loss and to a\ncritical point for weakly convex (non-convex) loss. Furthermore, we prove a new\ngeneralization bound for the proposed algorithm. On the empirical side, the\nnumerical experiments show that our proposed method consistently improves the\ntest errors compared with the standard mini-batch SGD in various models\nincluding SVM, logistic regression, and deep learning problems.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jul 2019 19:09:51 GMT"}, {"version": "v2", "created": "Mon, 7 Oct 2019 20:01:12 GMT"}, {"version": "v3", "created": "Thu, 9 Jan 2020 19:04:14 GMT"}, {"version": "v4", "created": "Wed, 15 Jan 2020 22:52:03 GMT"}, {"version": "v5", "created": "Sat, 1 Feb 2020 21:34:16 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Kawaguchi", "Kenji", ""], ["Lu", "Haihao", ""]]}, {"id": "1907.04373", "submitter": "Souradeep Chakraborty", "authors": "Souradeep Chakraborty", "title": "Capturing Financial markets to apply Deep Reinforcement Learning", "comments": "17 pages, 3 figures, 3 tables, accepted to be presented at the India\n  Finance Conference, IIM Ahmedabad, December 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.CP cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper we explore the usage of deep reinforcement learning algorithms\nto automatically generate consistently profitable, robust, uncorrelated trading\nsignals in any general financial market. In order to do this, we present a\nnovel Markov decision process (MDP) model to capture the financial trading\nmarkets. We review and propose various modifications to existing approaches and\nexplore different techniques like the usage of technical indicators, to\nsuccinctly capture the market dynamics to model the markets. We then go on to\nuse deep reinforcement learning to enable the agent (the algorithm) to learn\nhow to take profitable trades in any market on its own, while suggesting\nvarious methodology changes and leveraging the unique representation of the\nFMDP (financial MDP) to tackle the primary challenges faced in similar works.\nThrough our experimentation results, we go on to show that our model could be\neasily extended to two very different financial markets and generates a\npositively robust performance in all conducted experiments.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jul 2019 19:18:34 GMT"}, {"version": "v2", "created": "Thu, 25 Jul 2019 14:32:26 GMT"}, {"version": "v3", "created": "Sun, 15 Dec 2019 05:13:52 GMT"}], "update_date": "2019-12-17", "authors_parsed": [["Chakraborty", "Souradeep", ""]]}, {"id": "1907.04377", "submitter": "Nhat Ho", "authors": "Nhat Ho and Chiao-Yu Yang and Michael I. Jordan", "title": "Convergence Rates for Gaussian Mixtures of Experts", "comments": "55 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide a theoretical treatment of over-specified Gaussian mixtures of\nexperts with covariate-free gating networks. We establish the convergence rates\nof the maximum likelihood estimation (MLE) for these models. Our proof\ntechnique is based on a novel notion of \\emph{algebraic independence} of the\nexpert functions. Drawing on optimal transport theory, we establish a\nconnection between the algebraic independence and a certain class of partial\ndifferential equations (PDEs). Exploiting this connection allows us to derive\nconvergence rates and minimax lower bounds for parameter estimation.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jul 2019 19:31:37 GMT"}], "update_date": "2019-07-11", "authors_parsed": [["Ho", "Nhat", ""], ["Yang", "Chiao-Yu", ""], ["Jordan", "Michael I.", ""]]}, {"id": "1907.04378", "submitter": "Shuang Ma", "authors": "Shuang Ma, Daniel McDuff, Yale Song", "title": "M3D-GAN: Multi-Modal Multi-Domain Translation with Universal Attention", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG eess.AS eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative adversarial networks have led to significant advances in\ncross-modal/domain translation. However, typically these networks are designed\nfor a specific task (e.g., dialogue generation or image synthesis, but not\nboth). We present a unified model, M3D-GAN, that can translate across a wide\nrange of modalities (e.g., text, image, and speech) and domains (e.g.,\nattributes in images or emotions in speech). Our model consists of modality\nsubnets that convert data from different modalities into unified\nrepresentations, and a unified computing body where data from different\nmodalities share the same network architecture. We introduce a universal\nattention module that is jointly trained with the whole network and learns to\nencode a large range of domain information into a highly structured latent\nspace. We use this to control synthesis in novel ways, such as producing\ndiverse realistic pictures from a sketch or varying the emotion of synthesized\nspeech. We evaluate our approach on extensive benchmark tasks, including\nimage-to-image, text-to-image, image captioning, text-to-speech, speech\nrecognition, and machine translation. Our results show state-of-the-art\nperformance on some of the tasks.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jul 2019 19:33:01 GMT"}], "update_date": "2019-07-11", "authors_parsed": [["Ma", "Shuang", ""], ["McDuff", "Daniel", ""], ["Song", "Yale", ""]]}, {"id": "1907.04409", "submitter": "Brendon G. Anderson", "authors": "Brendon G. Anderson, Somayeh Sojoudi", "title": "Global Optimality Guarantees for Nonconvex Unsupervised Video\n  Segmentation", "comments": "Proceedings of the 57th Annual Allerton Conference on Communication,\n  Control, and Computing, 2019; added funding source information and notation\n  definitions", "journal-ref": "Proceedings of the 57th Annual Allerton Conference on\n  Communication, Control, and Computing, pp. 965--972, 2019", "doi": null, "report-no": null, "categories": "cs.LG cs.CV math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider the problem of unsupervised video object\nsegmentation via background subtraction. Specifically, we pose the nonsemantic\nextraction of a video's moving objects as a nonconvex optimization problem via\na sum of sparse and low-rank matrices. The resulting formulation, a nonnegative\nvariant of robust principal component analysis, is more computationally\ntractable than its commonly employed convex relaxation, although not generally\nsolvable to global optimality. In spite of this limitation, we derive intuitive\nand interpretable conditions on the video data under which the uniqueness and\nglobal optimality of the object segmentation are guaranteed using local search\nmethods. We illustrate these novel optimality criteria through example\nsegmentations using real video data.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jul 2019 20:53:13 GMT"}, {"version": "v2", "created": "Sat, 22 Feb 2020 21:45:47 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Anderson", "Brendon G.", ""], ["Sojoudi", "Somayeh", ""]]}, {"id": "1907.04428", "submitter": "Nikhil Chawla", "authors": "Nikhil Chawla, Arvind Singh, Monodeep Kar and Saibal Mukhopadhyay", "title": "Application Inference using Machine Learning based Side Channel Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The proliferation of ubiquitous computing requires energy-efficient as well\nas secure operation of modern processors. Side channel attacks are becoming a\ncritical threat to security and privacy of devices embedded in modern computing\ninfrastructures. Unintended information leakage via physical signatures such as\npower consumption, electromagnetic emission (EM) and execution time have\nemerged as a key security consideration for SoCs. Also, information published\non purpose at user privilege level accessible through software interfaces\nresults in software only attacks. In this paper, we used a supervised learning\nbased approach for inferring applications executing on android platform based\non features extracted from EM side-channel emissions and software exposed\ndynamic voltage frequency scaling(DVFS) states. We highlight the importance of\nmachine learning based approach in utilizing these multi-dimensional features\non a complex SoC, against profiling-based approaches. We also show that\nlearning the instantaneous frequency states polled from onboard frequency\ndriver (cpufreq) is adequate to identify a known application and flag\npotentially malicious unknown application. The experimental results on\nbenchmarking applications running on ARMv8 processor in Snapdragon 820 board\ndemonstrates early detection of these apps, and atleast 85% accuracy in\ndetecting unknown applications. Overall, the highlight is to utilize a\nlow-complexity path to application inference attacks through learning\ninstantaneous frequency states pattern of CPU core.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jul 2019 21:48:08 GMT"}], "update_date": "2019-07-11", "authors_parsed": [["Chawla", "Nikhil", ""], ["Singh", "Arvind", ""], ["Kar", "Monodeep", ""], ["Mukhopadhyay", "Saibal", ""]]}, {"id": "1907.04433", "submitter": "Aston Zhang", "authors": "Jian Guo, He He, Tong He, Leonard Lausen, Mu Li, Haibin Lin, Xingjian\n  Shi, Chenguang Wang, Junyuan Xie, Sheng Zha, Aston Zhang, Hang Zhang, Zhi\n  Zhang, Zhongyue Zhang, Shuai Zheng, Yi Zhu", "title": "GluonCV and GluonNLP: Deep Learning in Computer Vision and Natural\n  Language Processing", "comments": null, "journal-ref": "Journal of Machine Learning Research 21 (2020) 1-7", "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present GluonCV and GluonNLP, the deep learning toolkits for computer\nvision and natural language processing based on Apache MXNet (incubating).\nThese toolkits provide state-of-the-art pre-trained models, training scripts,\nand training logs, to facilitate rapid prototyping and promote reproducible\nresearch. We also provide modular APIs with flexible building blocks to enable\nefficient customization. Leveraging the MXNet ecosystem, the deep learning\nmodels in GluonCV and GluonNLP can be deployed onto a variety of platforms with\ndifferent programming languages. The Apache 2.0 license has been adopted by\nGluonCV and GluonNLP to allow for software distribution, modification, and\nusage.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jul 2019 21:59:44 GMT"}, {"version": "v2", "created": "Thu, 13 Feb 2020 00:54:42 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["Guo", "Jian", ""], ["He", "He", ""], ["He", "Tong", ""], ["Lausen", "Leonard", ""], ["Li", "Mu", ""], ["Lin", "Haibin", ""], ["Shi", "Xingjian", ""], ["Wang", "Chenguang", ""], ["Xie", "Junyuan", ""], ["Zha", "Sheng", ""], ["Zhang", "Aston", ""], ["Zhang", "Hang", ""], ["Zhang", "Zhi", ""], ["Zhang", "Zhongyue", ""], ["Zheng", "Shuai", ""], ["Zhu", "Yi", ""]]}, {"id": "1907.04457", "submitter": "Hanna Kurniawati", "authors": "Nicholas Collins and Hanna Kurniawati", "title": "Partially Observable Planning and Learning for Systems with Non-Uniform\n  Dynamics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a neural network architecture, called TransNet, that combines\nplanning and model learning for solving Partially Observable Markov Decision\nProcesses (POMDPs) with non-uniform system dynamics. The past decade has seen a\nsubstantial advancement in solving POMDP problems. However, constructing a\nsuitable POMDP model remains difficult. Recently, neural network architectures\nhave been proposed to alleviate the difficulty in acquiring such models.\nAlthough the results are promising, existing architectures restrict the type of\nsystem dynamics that can be learned --that is, system dynamics must be the same\nin all parts of the state space. TransNet relaxes such a restriction. Key to\nthis relaxation is a novel neural network module that classifies the state\nspace into classes and then learns the system dynamics of the different\nclasses. TransNet uses this module together with the overall architecture of\nQMDP-Net[1] to allow solving POMDPs that have more expressive dynamic models,\nwhile maintaining efficient data requirement. Its evaluation on typical\nbenchmarks in robot navigation with initially unknown system and environment\nmodels indicates that TransNet substantially out-performs the quality of the\ngenerated policies and learning efficiency of the state-of-the-art method\nQMDP-Net.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jul 2019 23:22:42 GMT"}], "update_date": "2019-07-11", "authors_parsed": [["Collins", "Nicholas", ""], ["Kurniawati", "Hanna", ""]]}, {"id": "1907.04461", "submitter": "Przemyslaw Biecek", "authors": "Przemyslaw Biecek", "title": "Model Development Process", "comments": "6 pages, process definition", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predictive modeling has an increasing number of applications in various\nfields. High demand for predictive models drives creation of tools that\nautomate and support work of data scientist on the model development. To better\nunderstand what can be automated we need first a description of the model\nlife-cycle. In this paper we propose a generic Model Development Process (MDP).\nThis process is inspired by Rational Unified Process (RUP) which was designed\nfor software development. There are other approached to process description,\nlike CRISP DM or ASUM DM, in this paper we discuss similarities and differences\nbetween these methodologies. We believe that the proposed open standard for\nmodel development will facilitate creation of tools for automation of model\ntraining, testing and maintaining.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jul 2019 23:41:29 GMT"}], "update_date": "2019-07-11", "authors_parsed": [["Biecek", "Przemyslaw", ""]]}, {"id": "1907.04462", "submitter": "Kexin Zhao", "authors": "Jihyun Park, Kexin Zhao, Kainan Peng, Wei Ping", "title": "Multi-Speaker End-to-End Speech Synthesis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we extend ClariNet (Ping et al., 2019), a fully end-to-end\nspeech synthesis model (i.e., text-to-wave), to generate high-fidelity speech\nfrom multiple speakers. To model the unique characteristic of different voices,\nlow dimensional trainable speaker embeddings are shared across each component\nof ClariNet and trained together with the rest of the model. We demonstrate\nthat the multi-speaker ClariNet outperforms state-of-the-art systems in terms\nof naturalness, because the whole model is jointly optimized in an end-to-end\nmanner.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jul 2019 23:53:39 GMT"}], "update_date": "2019-07-11", "authors_parsed": [["Park", "Jihyun", ""], ["Zhao", "Kexin", ""], ["Peng", "Kainan", ""], ["Ping", "Wei", ""]]}, {"id": "1907.04463", "submitter": "Nathan Brugnone", "authors": "Nathan Brugnone (1), Alex Gonopolskiy (2), Mark W. Moyle (3), Manik\n  Kuchroo (3), David van Dijk (3), Kevin R. Moon (4), Daniel Colon-Ramos (3),\n  Guy Wolf (5), Matthew J. Hirn (1) and Smita Krishnaswamy (3) ((1) Michigan\n  State University, (2) PicnicHealth, (3) Yale University, (4) Utah State\n  University, (5) Universit\\'e de Montr\\'eal)", "title": "Coarse Graining of Data via Inhomogeneous Diffusion Condensation", "comments": "14 pages, 7 figures", "journal-ref": "Proceedings of the 2019 IEEE International Conference on Big Data,\n  pages 2624-2633, 2019", "doi": "10.1109/BigData47090.2019.9006013", "report-no": null, "categories": "cs.HC cs.CV cs.LG q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Big data often has emergent structure that exists at multiple levels of\nabstraction, which are useful for characterizing complex interactions and\ndynamics of the observations. Here, we consider multiple levels of abstraction\nvia a multiresolution geometry of data points at different granularities. To\nconstruct this geometry we define a time-inhomogeneous diffusion process that\neffectively condenses data points together to uncover nested groupings at\nlarger and larger granularities. This inhomogeneous process creates a deep\ncascade of intrinsic low pass filters on the data affinity graph that are\napplied in sequence to gradually eliminate local variability while adjusting\nthe learned data geometry to increasingly coarser resolutions. We provide\nvisualizations to exhibit our method as a continuously-hierarchical clustering\nwith directions of eliminated variation highlighted at each step. The utility\nof our algorithm is demonstrated via neuronal data condensation, where the\nconstructed multiresolution data geometry uncovers the organization, grouping,\nand connectivity between neurons.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jul 2019 00:08:07 GMT"}, {"version": "v2", "created": "Sun, 22 Sep 2019 23:43:22 GMT"}, {"version": "v3", "created": "Mon, 9 Mar 2020 20:12:26 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Brugnone", "Nathan", ""], ["Gonopolskiy", "Alex", ""], ["Moyle", "Mark W.", ""], ["Kuchroo", "Manik", ""], ["van Dijk", "David", ""], ["Moon", "Kevin R.", ""], ["Colon-Ramos", "Daniel", ""], ["Wolf", "Guy", ""], ["Hirn", "Matthew J.", ""], ["Krishnaswamy", "Smita", ""]]}, {"id": "1907.04471", "submitter": "Cong Li", "authors": "Manas R. Joglekar, Cong Li, Jay K. Adams, Pranav Khaitan, Quoc V. Le", "title": "Neural Input Search for Large Scale Recommendation Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recommendation problems with large numbers of discrete items, such as\nproducts, webpages, or videos, are ubiquitous in the technology industry. Deep\nneural networks are being increasingly used for these recommendation problems.\nThese models use embeddings to represent discrete items as continuous vectors,\nand the vocabulary sizes and embedding dimensions, although heavily influence\nthe model's accuracy, are often manually selected in a heuristical manner. We\npresent Neural Input Search (NIS), a technique for learning the optimal\nvocabulary sizes and embedding dimensions for categorical features. The goal is\nto maximize prediction accuracy subject to a constraint on the total memory\nused by all embeddings. Moreover, we argue that the traditional Single-size\nEmbedding (SE), which uses the same embedding dimension for all values of a\nfeature, suffers from inefficient usage of model capacity and training data. We\npropose a novel type of embedding, namely Multi-size Embedding (ME), which\nallows the embedding dimension to vary for different values of the feature.\nDuring training we use reinforcement learning to find the optimal vocabulary\nsize for each feature and embedding dimension for each value of the feature. In\nexperiments on two common types of large scale recommendation problems, i.e.\nretrieval and ranking problems, NIS automatically found better vocabulary and\nembedding sizes that result in $6.8\\%$ and $1.8\\%$ relative improvements on\nRecall@1 and ROC-AUC over manually optimized ones.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jul 2019 00:49:06 GMT"}], "update_date": "2019-07-11", "authors_parsed": [["Joglekar", "Manas R.", ""], ["Li", "Cong", ""], ["Adams", "Jay K.", ""], ["Khaitan", "Pranav", ""], ["Le", "Quoc V.", ""]]}, {"id": "1907.04476", "submitter": "Yuxin Peng", "authors": "Xiangteng He, Yuxin Peng and Liu Xie", "title": "A New Benchmark and Approach for Fine-grained Cross-media Retrieval", "comments": "9 pages, ACM MM 2019", "journal-ref": null, "doi": "10.1145/3343031.3350974", "report-no": null, "categories": "cs.IR cs.CV cs.LG cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cross-media retrieval is to return the results of various media types\ncorresponding to the query of any media type. Existing researches generally\nfocus on coarse-grained cross-media retrieval. When users submit an image of\n\"Slaty-backed Gull\" as a query, coarse-grained cross-media retrieval treats it\nas \"Bird\", so that users can only get the results of \"Bird\", which may include\nother bird species with similar appearance (image and video), descriptions\n(text) or sounds (audio), such as \"Herring Gull\". Such coarse-grained\ncross-media retrieval is not consistent with human lifestyle, where we\ngenerally have the fine-grained requirement of returning the exactly relevant\nresults of \"Slaty-backed Gull\" instead of \"Herring Gull\". However, few\nresearches focus on fine-grained cross-media retrieval, which is a highly\nchallenging and practical task. Therefore, in this paper, we first construct a\nnew benchmark for fine-grained cross-media retrieval, which consists of 200\nfine-grained subcategories of the \"Bird\", and contains 4 media types, including\nimage, text, video and audio. To the best of our knowledge, it is the first\nbenchmark with 4 media types for fine-grained cross-media retrieval. Then, we\npropose a uniform deep model, namely FGCrossNet, which simultaneously learns 4\ntypes of media without discriminative treatments. We jointly consider three\nconstraints for better common representation learning: classification\nconstraint ensures the learning of discriminative features, center constraint\nensures the compactness characteristic of the features of the same subcategory,\nand ranking constraint ensures the sparsity characteristic of the features of\ndifferent subcategories. Extensive experiments verify the usefulness of the new\nbenchmark and the effectiveness of our FGCrossNet. They will be made available\nat https://github.com/PKU-ICST-MIPL/FGCrossNet_ACMMM2019.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jul 2019 01:15:22 GMT"}, {"version": "v2", "created": "Thu, 31 Oct 2019 06:37:53 GMT"}], "update_date": "2019-11-01", "authors_parsed": [["He", "Xiangteng", ""], ["Peng", "Yuxin", ""], ["Xie", "Liu", ""]]}, {"id": "1907.04481", "submitter": "Marcus A. Brubaker", "authors": "Priyank Jaini, Ivan Kobyzev, Yaoliang Yu, Marcus Brubaker", "title": "Tails of Lipschitz Triangular Flows", "comments": "Published at the 37th International Conference of Machine Learning,\n  (ICML 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the ability of popular flow based methods to capture\ntail-properties of a target density by studying the increasing triangular maps\nused in these flow methods acting on a tractable source density. We show that\nthe density quantile functions of the source and target density provide a\nprecise characterization of the slope of transformation required to capture\ntails in a target density. We further show that any Lipschitz-continuous\ntransport map acting on a source density will result in a density with similar\ntail properties as the source, highlighting the trade-off between a complex\nsource density and a sufficiently expressive transformation to capture\ndesirable properties of a target density. Subsequently, we illustrate that flow\nmodels like Real-NVP, MAF, and Glow as implemented originally lack the ability\nto capture a distribution with non-Gaussian tails. We circumvent this problem\nby proposing tail-adaptive flows consisting of a source distribution that can\nbe learned simultaneously with the triangular map to capture tail-properties of\na target density. We perform several synthetic and real-world experiments to\ncompliment our theoretical findings.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jul 2019 01:46:39 GMT"}, {"version": "v2", "created": "Sat, 6 Jun 2020 10:27:13 GMT"}, {"version": "v3", "created": "Fri, 18 Sep 2020 18:05:25 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Jaini", "Priyank", ""], ["Kobyzev", "Ivan", ""], ["Yu", "Yaoliang", ""], ["Brubaker", "Marcus", ""]]}, {"id": "1907.04482", "submitter": "Cheng He", "authors": "Cheng He, Shihua Huang, Ran Cheng, Kay Chen Tan, and Yaochu Jin", "title": "Evolutionary Multi-Objective Optimization Driven by Generative\n  Adversarial Networks", "comments": "This is a redundant version of 1910.04966", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, more and more works have proposed to drive evolutionary algorithms\nusing machine learning models.Usually, the performance of such model based\nevolutionary algorithms is highly dependent on the training qualities of the\nadopted models.Since it usually requires a certain amount of data (i.e. the\ncandidate solutions generated by the algorithms) for model training, the\nperformance deteriorates rapidly with the increase of the problem scales, due\nto the curse of dimensionality.To address this issue, we propose a\nmulti-objective evolutionary algorithm driven by the generative adversarial\nnetworks (GANs).At each generation of the proposed algorithm, the parent\nsolutions are first classified into \\emph{real} and \\emph{fake} samples to\ntrain the GANs; then the offspring solutions are sampled by the trained\nGANs.Thanks to the powerful generative ability of the GANs, our proposed\nalgorithm is capable of generating promising offspring solutions in\nhigh-dimensional decision space with limited training data.The proposed\nalgorithm is tested on 10 benchmark problems with up to 200 decision\nvariables.Experimental results on these test problems demonstrate the\neffectiveness of the proposed algorithm.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jul 2019 01:50:20 GMT"}, {"version": "v2", "created": "Tue, 7 Apr 2020 02:24:47 GMT"}], "update_date": "2020-04-08", "authors_parsed": [["He", "Cheng", ""], ["Huang", "Shihua", ""], ["Cheng", "Ran", ""], ["Tan", "Kay Chen", ""], ["Jin", "Yaochu", ""]]}, {"id": "1907.04483", "submitter": "Roy Freedman", "authors": "Roy S. Freedman", "title": "Copula Representations and Error Surface Projections for the Exclusive\n  Or Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The exclusive or (xor) function is one of the simplest examples that\nillustrate why nonlinear feedforward networks are superior to linear regression\nfor machine learning applications. We review the xor representation and\napproximation problems and discuss their solutions in terms of probabilistic\nlogic and associative copula functions. After briefly reviewing the\nspecification of feedforward networks, we compare the dynamics of learned error\nsurfaces with different activation functions such as RELU and tanh through a\nset of colorful three-dimensional charts. The copula representations extend xor\nfrom Boolean to real values, thereby providing a convenient way to demonstrate\nthe concept of cross-validation on in-sample and out-sample data sets. Our\napproach is pedagogical and is meant to be a machine learning prolegomenon.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jul 2019 00:20:25 GMT"}], "update_date": "2019-07-11", "authors_parsed": [["Freedman", "Roy S.", ""]]}, {"id": "1907.04484", "submitter": "Jialin Song", "authors": "Jialin Song, Ravi Lanka, Yisong Yue, Masahiro Ono", "title": "Co-training for Policy Learning", "comments": "UAI 2019, oral presentation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of learning sequential decision-making policies in\nsettings with multiple state-action representations. Such settings naturally\narise in many domains, such as planning (e.g., multiple integer programming\nformulations) and various combinatorial optimization problems (e.g., those with\nboth integer programming and graph-based formulations). Inspired by the\nclassical co-training framework for classification, we study the problem of\nco-training for policy learning. We present sufficient conditions under which\nlearning from two views can improve upon learning from a single view alone.\nMotivated by these theoretical insights, we present a meta-algorithm for\nco-training for sequential decision making. Our framework is compatible with\nboth reinforcement learning and imitation learning. We validate the\neffectiveness of our approach across a wide range of tasks, including\ndiscrete/continuous control and combinatorial optimization.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jul 2019 02:54:13 GMT"}], "update_date": "2019-07-11", "authors_parsed": [["Song", "Jialin", ""], ["Lanka", "Ravi", ""], ["Yue", "Yisong", ""], ["Ono", "Masahiro", ""]]}, {"id": "1907.04489", "submitter": "Michael Lutter", "authors": "Michael Lutter, Kim Listmann, Jan Peters", "title": "Deep Lagrangian Networks for end-to-end learning of energy-based control\n  for under-actuated systems", "comments": "Published at IROS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Applying Deep Learning to control has a lot of potential for enabling the\nintelligent design of robot control laws. Unfortunately common deep learning\napproaches to control, such as deep reinforcement learning, require an\nunrealistic amount of interaction with the real system, do not yield any\nperformance guarantees, and do not make good use of extensive insights from\nmodel-based control. In particular, common black-box approaches -- that abandon\nall insight from control -- are not suitable for complex robot systems. We\npropose a deep control approach as a bridge between the solid theoretical\nfoundations of energy-based control and the flexibility of deep learning. To\naccomplish this goal, we extend Deep Lagrangian Networks (DeLaN) to not only\nadhere to Lagrangian Mechanics but also ensure conservation of energy and\npassivity of the learned representation. This novel extension is embedded\nwithin generic model-based control laws to enable energy control of\nunder-actuated systems. The resulting DeLaN for energy control (DeLaN 4EC) is\nthe first model learning approach using generic function approximation that is\ncapable of learning energy control. DeLaN 4EC exhibits excellent real-time\ncontrol on the physical Furuta Pendulum and learns to swing-up the pendulum\nwhile the control law using system identification does not.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jul 2019 02:26:37 GMT"}, {"version": "v2", "created": "Sat, 3 Aug 2019 08:56:13 GMT"}], "update_date": "2019-08-06", "authors_parsed": [["Lutter", "Michael", ""], ["Listmann", "Kim", ""], ["Peters", "Jan", ""]]}, {"id": "1907.04490", "submitter": "Michael Lutter", "authors": "Michael Lutter, Christian Ritter, Jan Peters", "title": "Deep Lagrangian Networks: Using Physics as Model Prior for Deep Learning", "comments": "Published at ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning has achieved astonishing results on many tasks with large\namounts of data and generalization within the proximity of training data. For\nmany important real-world applications, these requirements are unfeasible and\nadditional prior knowledge on the task domain is required to overcome the\nresulting problems. In particular, learning physics models for model-based\ncontrol requires robust extrapolation from fewer samples - often collected\nonline in real-time - and model errors may lead to drastic damages of the\nsystem. Directly incorporating physical insight has enabled us to obtain a\nnovel deep model learning approach that extrapolates well while requiring fewer\nsamples. As a first example, we propose Deep Lagrangian Networks (DeLaN) as a\ndeep network structure upon which Lagrangian Mechanics have been imposed. DeLaN\ncan learn the equations of motion of a mechanical system (i.e., system\ndynamics) with a deep network efficiently while ensuring physical plausibility.\nThe resulting DeLaN network performs very well at robot tracking control. The\nproposed method did not only outperform previous model learning approaches at\nlearning speed but exhibits substantially improved and more robust\nextrapolation to novel trajectories and learns online in real-time\n", "versions": [{"version": "v1", "created": "Wed, 10 Jul 2019 02:31:51 GMT"}], "update_date": "2019-07-11", "authors_parsed": [["Lutter", "Michael", ""], ["Ritter", "Christian", ""], ["Peters", "Jan", ""]]}, {"id": "1907.04502", "submitter": "Lu Lu", "authors": "Lu Lu, Xuhui Meng, Zhiping Mao, and George E. Karniadakis", "title": "DeepXDE: A deep learning library for solving differential equations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG physics.comp-ph stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Deep learning has achieved remarkable success in diverse applications;\nhowever, its use in solving partial differential equations (PDEs) has emerged\nonly recently. Here, we present an overview of physics-informed neural networks\n(PINNs), which embed a PDE into the loss of the neural network using automatic\ndifferentiation. The PINN algorithm is simple, and it can be applied to\ndifferent types of PDEs, including integro-differential equations, fractional\nPDEs, and stochastic PDEs. Moreover, from the implementation point of view,\nPINNs solve inverse problems as easily as forward problems. We propose a new\nresidual-based adaptive refinement (RAR) method to improve the training\nefficiency of PINNs. For pedagogical reasons, we compare the PINN algorithm to\na standard finite element method. We also present a Python library for PINNs,\nDeepXDE, which is designed to serve both as an education tool to be used in the\nclassroom as well as a research tool for solving problems in computational\nscience and engineering. Specifically, DeepXDE can solve forward problems given\ninitial and boundary conditions, as well as inverse problems given some extra\nmeasurements. DeepXDE supports complex-geometry domains based on the technique\nof constructive solid geometry, and enables the user code to be compact,\nresembling closely the mathematical formulation. We introduce the usage of\nDeepXDE and its customizability, and we also demonstrate the capability of\nPINNs and the user-friendliness of DeepXDE for five different examples. More\nbroadly, DeepXDE contributes to the more rapid development of the emerging\nScientific Machine Learning field.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jul 2019 04:06:21 GMT"}, {"version": "v2", "created": "Fri, 14 Feb 2020 23:05:44 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Lu", "Lu", ""], ["Meng", "Xuhui", ""], ["Mao", "Zhiping", ""], ["Karniadakis", "George E.", ""]]}, {"id": "1907.04514", "submitter": "Tianming Wang", "authors": "Tianming Wang, Wenjie Lu, Zheng Yan, Dikai Liu", "title": "DOB-Net: Actively Rejecting Unknown Excessive Time-Varying Disturbances", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents an observer-integrated Reinforcement Learning (RL)\napproach, called Disturbance OBserver Network (DOB-Net), for robots operating\nin environments where disturbances are unknown and time-varying, and may\nfrequently exceed robot control capabilities. The DOB-Net integrates a\ndisturbance dynamics observer network and a controller network. Originated from\nconventional DOB mechanisms, the observer is built and enhanced via Recurrent\nNeural Networks (RNNs), encoding estimation of past values and prediction of\nfuture values of unknown disturbances in RNN hidden state. Such encoding allows\nthe controller generate optimal control signals to actively reject\ndisturbances, under the constraints of robot control capabilities. The observer\nand the controller are jointly learned within policy optimization by advantage\nactor critic. Numerical simulations on position regulation tasks have\ndemonstrated that the proposed DOB-Net significantly outperforms a conventional\nfeedback controller and classical RL algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jul 2019 05:31:35 GMT"}, {"version": "v2", "created": "Wed, 29 Jan 2020 05:41:15 GMT"}], "update_date": "2020-01-30", "authors_parsed": [["Wang", "Tianming", ""], ["Lu", "Wenjie", ""], ["Yan", "Zheng", ""], ["Liu", "Dikai", ""]]}, {"id": "1907.04519", "submitter": "Andrey Savchenko", "authors": "A.V. Savchenko, K.V. Demochkin, I.S. Grechikhin", "title": "Preferences Prediction using a Gallery of Mobile Device based on Scene\n  Recognition and Object Detection", "comments": "19 pages; 9 figures, preprint submitter to Pattern Recognition\n  journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper user modeling task is examined by processing a gallery of\nphotos and videos on a mobile device. We propose novel engine for user\npreference prediction based on scene recognition, object detection and facial\nanalysis. At first, all faces in a gallery are clustered and all private photos\nand videos with faces from large clusters are processed on the embedded system\nin offline mode. Other photos may be sent to the remote server to be analyzed\nby very deep models. The visual features of each photo are obtained from scene\nrecognition and object detection models. These features are aggregated into a\nsingle user descriptor in the neural attention block. The proposed pipeline is\nimplemented for the Android mobile platform. Experimental results with a subset\nof Photo Event Collection, Web Image Dataset for Event Recognition and Amazon\nFashion datasets demonstrate the possibility to process images very efficiently\nwithout significant accuracy degradation. The source code of Android mobile\napplication is publicly available at\nhttps://github.com/HSE-asavchenko/mobile-visual-preferences.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jul 2019 05:45:08 GMT"}, {"version": "v2", "created": "Sun, 18 Apr 2021 13:33:11 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Savchenko", "A. V.", ""], ["Demochkin", "K. V.", ""], ["Grechikhin", "I. S.", ""]]}, {"id": "1907.04523", "submitter": "Yue Wang", "authors": "Yue Wang, Jianghao Shen, Ting-Kuei Hu, Pengfei Xu, Tan Nguyen, Richard\n  Baraniuk, Zhangyang Wang, and Yingyan Lin", "title": "Dual Dynamic Inference: Enabling More Efficient, Adaptive and\n  Controllable Deep Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  State-of-the-art convolutional neural networks (CNNs) yield record-breaking\npredictive performance, yet at the cost of high-energy-consumption inference,\nthat prohibits their widely deployments in resource-constrained Internet of\nThings (IoT) applications. We propose a dual dynamic inference (DDI) framework\nthat highlights the following aspects: 1) we integrate both input-dependent and\nresource-dependent dynamic inference mechanisms under a unified framework in\norder to fit the varying IoT resource requirements in practice. DDI is able to\nboth constantly suppress unnecessary costs for easy samples, and to halt\ninference for all samples to meet hard resource constraints enforced; 2) we\npropose a flexible multi-grained learning to skip (MGL2S) approach for\ninput-dependent inference which allows simultaneous layer-wise and channel-wise\nskipping; 3) we extend DDI to complex CNN backbones such as DenseNet and show\nthat DDI can be applied towards optimizing any specific resource goals\nincluding inference latency or energy cost. Extensive experiments demonstrate\nthe superior inference accuracy-resource trade-off achieved by DDI, as well as\nthe flexibility to control such trade-offs compared to existing peer methods.\nSpecifically, DDI can achieve up to 4 times computational savings with the same\nor even higher accuracy as compared to existing competitive baselines.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jul 2019 05:56:33 GMT"}, {"version": "v2", "created": "Wed, 17 Jul 2019 21:03:16 GMT"}, {"version": "v3", "created": "Fri, 3 Jan 2020 02:03:15 GMT"}], "update_date": "2020-01-06", "authors_parsed": [["Wang", "Yue", ""], ["Shen", "Jianghao", ""], ["Hu", "Ting-Kuei", ""], ["Xu", "Pengfei", ""], ["Nguyen", "Tan", ""], ["Baraniuk", "Richard", ""], ["Wang", "Zhangyang", ""], ["Lin", "Yingyan", ""]]}, {"id": "1907.04524", "submitter": "Andre Goncalves", "authors": "Andre Goncalves, Xiaoli Liu, Arindam Banerjee", "title": "Two-block vs. Multi-block ADMM: An empirical evaluation of convergence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Alternating Direction Method of Multipliers (ADMM) has become a widely used\noptimization method for convex problems, particularly in the context of data\nmining in which large optimization problems are often encountered. ADMM has\nseveral desirable properties, including the ability to decompose large problems\ninto smaller tractable sub-problems and ease of parallelization, that are\nessential in these scenarios. The most common form of ADMM is the two-block, in\nwhich two sets of primal variables are updated alternatingly. Recent years have\nseen advances in multi-block ADMM, which update more than two blocks of primal\nvariables sequentially. In this paper, we study the empirical question: {\\em Is\ntwo-block ADMM always comparable with sequential multi-block ADMM solving an\nequivalent problem?} In the context of optimization problems arising in\nmulti-task learning, through a comprehensive set of experiments we surprisingly\nshow that multi-block ADMM consistently outperformed two-block ADMM on\noptimization performance, and as a consequence on prediction performance,\nacross all datasets and for the entire range of dual step sizes. Our results\nhave an important practical implication: rather than simply using the popular\ntwo-block ADMM, one may considerably benefit from experimenting with\nmulti-block ADMM applied to an equivalent problem.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jul 2019 05:57:36 GMT"}], "update_date": "2019-07-11", "authors_parsed": [["Goncalves", "Andre", ""], ["Liu", "Xiaoli", ""], ["Banerjee", "Arindam", ""]]}, {"id": "1907.04536", "submitter": "Ruisen Luo", "authors": "Ruisen Luo, Tianran Sun, Chen Wang, Miao Du, Zuodong Tang, Kai Zhou,\n  and Xiaofeng Gong, and Xiaomei Yang", "title": "Multi-layer Attention Mechanism for Speech Keyword Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SD eess.AS stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  As an important part of speech recognition technology, automatic speech\nkeyword recognition has been intensively studied in recent years. Such\ntechnology becomes especially pivotal under situations with limited\ninfrastructures and computational resources, such as voice command recognition\nin vehicles and robot interaction. At present, the mainstream methods in\nautomatic speech keyword recognition are based on long short-term memory (LSTM)\nnetworks with attention mechanism. However, due to inevitable information\nlosses for the LSTM layer caused during feature extraction, the calculated\nattention weights are biased. In this paper, a novel approach, namely\nMulti-layer Attention Mechanism, is proposed to handle the inaccurate attention\nweights problem. The key idea is that, in addition to the conventional\nattention mechanism, information of layers prior to feature extraction and LSTM\nare introduced into attention weights calculations. Therefore, the attention\nweights are more accurate because the overall model can have more precise and\nfocused areas. We conduct a comprehensive comparison and analysis on the\nkeyword spotting performances on convolution neural network, bi-directional\nLSTM cyclic neural network, and cyclic neural network with the proposed\nattention mechanism on Google Speech Command datasets V2 datasets. Experimental\nresults indicate favorable results for the proposed method and demonstrate the\nvalidity of the proposed method. The proposed multi-layer attention methods can\nbe useful for other researches related to object spotting.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jul 2019 06:57:01 GMT"}], "update_date": "2019-07-11", "authors_parsed": [["Luo", "Ruisen", ""], ["Sun", "Tianran", ""], ["Wang", "Chen", ""], ["Du", "Miao", ""], ["Tang", "Zuodong", ""], ["Zhou", "Kai", ""], ["Gong", "Xiaofeng", ""], ["Yang", "Xiaomei", ""]]}, {"id": "1907.04539", "submitter": "Ali Marjaninejad", "authors": "Ali Marjaninejad, Dar\\'io Urbina-Mel\\'endez, Francisco J.\n  Valero-Cuevas", "title": "Simple Kinematic Feedback Enhances Autonomous Learning in Bio-Inspired\n  Tendon-Driven Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Error feedback is known to improve performance by correcting control signals\nin response to perturbations. Here we show how adding simple error feedback can\nalso accelerate and robustify autonomous learning in a tendon-driven robot. We\nimplemented two versions of the General-to-Particular (G2P) autonomous learning\nalgorithm to produce multiple movement tasks using a tendon-driven leg with two\njoints and three tendons: one with and one without kinematic feedback. As\nexpected, feedback improved performance in simulation and hardware. However, we\nsee these improvements even in the presence of sensory delays of up to 100 ms\nand when experiencing substantial contact collisions. Importantly, feedback\naccelerates learning and enhances G2P's continual refinement of the initial\ninverse map by providing the system with more relevant data to train on. This\nallows the system to perform well even after only 60 seconds of initial motor\nbabbling.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jul 2019 07:06:46 GMT"}, {"version": "v2", "created": "Fri, 27 Sep 2019 00:07:41 GMT"}], "update_date": "2019-09-30", "authors_parsed": [["Marjaninejad", "Ali", ""], ["Urbina-Mel\u00e9ndez", "Dar\u00edo", ""], ["Valero-Cuevas", "Francisco J.", ""]]}, {"id": "1907.04543", "submitter": "Rishabh Agarwal", "authors": "Rishabh Agarwal, Dale Schuurmans, Mohammad Norouzi", "title": "An Optimistic Perspective on Offline Reinforcement Learning", "comments": "ICML 2020. An earlier version was titled \"Striving for Simplicity in\n  Off-Policy Deep Reinforcement Learning\". Project Website:\n  https://offline-rl.github.io", "journal-ref": "Proceedings of the 37th International Conference on Machine\n  Learning, PMLR 119:104-114, 2020", "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Off-policy reinforcement learning (RL) using a fixed offline dataset of\nlogged interactions is an important consideration in real world applications.\nThis paper studies offline RL using the DQN replay dataset comprising the\nentire replay experience of a DQN agent on 60 Atari 2600 games. We demonstrate\nthat recent off-policy deep RL algorithms, even when trained solely on this\nfixed dataset, outperform the fully trained DQN agent. To enhance\ngeneralization in the offline setting, we present Random Ensemble Mixture\n(REM), a robust Q-learning algorithm that enforces optimal Bellman consistency\non random convex combinations of multiple Q-value estimates. Offline REM\ntrained on the DQN replay dataset surpasses strong RL baselines. Ablation\nstudies highlight the role of offline dataset size and diversity as well as the\nalgorithm choice in our positive results. Overall, the results here present an\noptimistic view that robust RL algorithms trained on sufficiently large and\ndiverse offline datasets can lead to high quality policies. The DQN replay\ndataset can serve as an offline RL benchmark and is open-sourced.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jul 2019 07:23:27 GMT"}, {"version": "v2", "created": "Tue, 1 Oct 2019 16:35:52 GMT"}, {"version": "v3", "created": "Fri, 6 Mar 2020 00:35:57 GMT"}, {"version": "v4", "created": "Mon, 22 Jun 2020 04:32:50 GMT"}], "update_date": "2020-11-25", "authors_parsed": [["Agarwal", "Rishabh", ""], ["Schuurmans", "Dale", ""], ["Norouzi", "Mohammad", ""]]}, {"id": "1907.04553", "submitter": "Thao Minh Le", "authors": "Thao Minh Le, Vuong Le, Svetha Venkatesh, Truyen Tran", "title": "Neural Reasoning, Fast and Slow, for Video Question Answering", "comments": null, "journal-ref": "International Joint Conference on Neural Networks (IJCNN) 2020", "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  What does it take to design a machine that learns to answer natural questions\nabout a video? A Video QA system must simultaneously understand language,\nrepresent visual content over space-time, and iteratively transform these\nrepresentations in response to lingual content in the query, and finally\narriving at a sensible answer. While recent advances in lingual and visual\nquestion answering have enabled sophisticated representations and neural\nreasoning mechanisms, major challenges in Video QA remain on dynamic grounding\nof concepts, relations and actions to support the reasoning process. Inspired\nby the dual-process account of human reasoning, we design a dual process neural\narchitecture, which is composed of a question-guided video processing module\n(System 1, fast and reactive) followed by a generic reasoning module (System 2,\nslow and deliberative). System 1 is a hierarchical model that encodes visual\npatterns about objects, actions and relations in space-time given the textual\ncues from the question. The encoded representation is a set of high-level\nvisual features, which are then passed to System 2. Here multi-step inference\nfollows to iteratively chain visual elements as instructed by the textual\nelements. The system is evaluated on the SVQA (synthetic) and TGIF-QA datasets\n(real), demonstrating competitive results, with a large margin in the case of\nmulti-step reasoning.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jul 2019 07:53:17 GMT"}, {"version": "v2", "created": "Sat, 11 Apr 2020 00:30:34 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Le", "Thao Minh", ""], ["Le", "Vuong", ""], ["Venkatesh", "Svetha", ""], ["Tran", "Truyen", ""]]}, {"id": "1907.04563", "submitter": "Thomas Kurmann", "authors": "Thomas Kurmann and Pablo Marquez Neila and Sebastian Wolf and Raphael\n  Sznitman", "title": "Deep Multi Label Classification in Affine Subspaces", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-label classification (MLC) problems are becoming increasingly popular\nin the context of medical imaging. This has in part been driven by the fact\nthat acquiring annotations for MLC is far less burdensome than for semantic\nsegmentation and yet provides more expressiveness than multi-class\nclassification. However, to train MLCs, most methods have resorted to similar\nobjective functions as with traditional multi-class classification settings. We\nshow in this work that such approaches are not optimal and instead propose a\nnovel deep MLC classification method in affine subspace. At its core, the\nmethod attempts to pull features of class-labels towards different affine\nsubspaces while maximizing the distance between them. We evaluate the method\nusing two MLC medical imaging datasets and show a large performance increase\ncompared to previous multi-label frameworks. This method can be seen as a\nplug-in replacement loss function and is trainable in an end-to-end fashion.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jul 2019 08:16:27 GMT"}], "update_date": "2019-07-11", "authors_parsed": [["Kurmann", "Thomas", ""], ["Neila", "Pablo Marquez", ""], ["Wolf", "Sebastian", ""], ["Sznitman", "Raphael", ""]]}, {"id": "1907.04572", "submitter": "Yujia Huang", "authors": "Yujia Huang, Sihui Dai, Tan Nguyen, Richard G. Baraniuk, Anima\n  Anandkumar", "title": "Out-of-Distribution Detection Using Neural Rendering Generative Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Out-of-distribution (OoD) detection is a natural downstream task for deep\ngenerative models, due to their ability to learn the input probability\ndistribution. There are mainly two classes of approaches for OoD detection\nusing deep generative models, viz., based on likelihood measure and the\nreconstruction loss. However, both approaches are unable to carry out OoD\ndetection effectively, especially when the OoD samples have smaller variance\nthan the training samples. For instance, both flow based and VAE models assign\nhigher likelihood to images from SVHN when trained on CIFAR-10 images. We use a\nrecently proposed generative model known as neural rendering model (NRM) and\nderive metrics for OoD. We show that NRM unifies both approaches since it\nprovides a likelihood estimate and also carries out reconstruction in each\nlayer of the neural network. Among various measures, we found the joint\nlikelihood of latent variables to be the most effective one for OoD detection.\nOur results show that when trained on CIFAR-10, lower likelihood (of latent\nvariables) is assigned to SVHN images. Additionally, we show that this metric\nis consistent across other OoD datasets. To the best of our knowledge, this is\nthe first work to show consistently lower likelihood for OoD data with smaller\nvariance with deep generative models.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jul 2019 08:32:53 GMT"}], "update_date": "2019-07-11", "authors_parsed": [["Huang", "Yujia", ""], ["Dai", "Sihui", ""], ["Nguyen", "Tan", ""], ["Baraniuk", "Richard G.", ""], ["Anandkumar", "Anima", ""]]}, {"id": "1907.04595", "submitter": "Colin Wei", "authors": "Yuanzhi Li, Colin Wei, Tengyu Ma", "title": "Towards Explaining the Regularization Effect of Initial Large Learning\n  Rate in Training Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic gradient descent with a large initial learning rate is widely used\nfor training modern neural net architectures. Although a small initial learning\nrate allows for faster training and better test performance initially, the\nlarge learning rate achieves better generalization soon after the learning rate\nis annealed. Towards explaining this phenomenon, we devise a setting in which\nwe can prove that a two layer network trained with large initial learning rate\nand annealing provably generalizes better than the same network trained with a\nsmall learning rate from the start. The key insight in our analysis is that the\norder of learning different types of patterns is crucial: because the small\nlearning rate model first memorizes easy-to-generalize, hard-to-fit patterns,\nit generalizes worse on hard-to-generalize, easier-to-fit patterns than its\nlarge learning rate counterpart. This concept translates to a larger-scale\nsetting: we demonstrate that one can add a small patch to CIFAR-10 images that\nis immediately memorizable by a model with small initial learning rate, but\nignored by the model with large learning rate until after annealing. Our\nexperiments show that this causes the small learning rate model's accuracy on\nunmodified images to suffer, as it relies too much on the patch early on.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jul 2019 09:47:43 GMT"}, {"version": "v2", "created": "Sat, 25 Apr 2020 06:30:13 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Li", "Yuanzhi", ""], ["Wei", "Colin", ""], ["Ma", "Tengyu", ""]]}, {"id": "1907.04613", "submitter": "Jind\\v{r}ich Libovick\\'y", "authors": "Jind\\v{r}ich Libovick\\'y", "title": "Neural Networks as Explicit Word-Based Rules", "comments": "3 pages; extended abstract at BlackboxNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Filters of convolutional networks used in computer vision are often\nvisualized as image patches that maximize the response of the filter. We use\nthe same approach to interpret weight matrices in simple architectures for\nnatural language processing tasks. We interpret a convolutional network for\nsentiment classification as word-based rules. Using the rule, we recover the\nperformance of the original model.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jul 2019 10:50:22 GMT"}], "update_date": "2019-07-11", "authors_parsed": [["Libovick\u00fd", "Jind\u0159ich", ""]]}, {"id": "1907.04632", "submitter": "Wei Peng", "authors": "Wei Peng, Xiaopeng Hong, Guoying Zhao", "title": "Video Action Recognition Via Neural Architecture Searching", "comments": "Accepted by IEEE ICIP2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Deep neural networks have achieved great success for video analysis and\nunderstanding. However, designing a high-performance neural architecture\nrequires substantial efforts and expertise. In this paper, we make the first\nattempt to let algorithm automatically design neural networks for video action\nrecognition tasks. Specifically, a spatio-temporal network is developed in a\ndifferentiable space modeled by a directed acyclic graph, thus a gradient-based\nstrategy can be performed to search an optimal architecture. Nonetheless, it is\ncomputationally expensive, since the computational burden to evaluate each\narchitecture candidate is still heavy. To alleviate this issue, we, for the\nvideo input, introduce a temporal segment approach to reduce the computational\ncost without losing global video information. For the architecture, we explore\nin an efficient search space by introducing pseudo 3D operators. Experiments\nshow that, our architecture outperforms popular neural architectures, under the\ntraining from scratch protocol, on the challenging UCF101 dataset,\nsurprisingly, with only around one percentage of parameters of its\nmanual-design counterparts.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jul 2019 11:44:28 GMT"}], "update_date": "2019-07-11", "authors_parsed": [["Peng", "Wei", ""], ["Hong", "Xiaopeng", ""], ["Zhao", "Guoying", ""]]}, {"id": "1907.04648", "submitter": "Yanqi Zhou", "authors": "Yanqi Zhou, Peng Wang, Sercan Arik, Haonan Yu, Syed Zawad, Feng Yan,\n  Greg Diamos", "title": "EPNAS: Efficient Progressive Neural Architecture Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose Efficient Progressive Neural Architecture Search\n(EPNAS), a neural architecture search (NAS) that efficiently handles large\nsearch space through a novel progressive search policy with performance\nprediction based on REINFORCE~\\cite{Williams.1992.PG}. EPNAS is designed to\nsearch target networks in parallel, which is more scalable on parallel systems\nsuch as GPU/TPU clusters. More importantly, EPNAS can be generalized to\narchitecture search with multiple resource constraints, \\eg, model size,\ncompute complexity or intensity, which is crucial for deployment in widespread\nplatforms such as mobile and cloud. We compare EPNAS against other\nstate-of-the-art (SoTA) network architectures (\\eg,\nMobileNetV2~\\cite{mobilenetv2}) and efficient NAS algorithms (\\eg,\nENAS~\\cite{pham2018efficient}, and PNAS~\\cite{Liu2017b}) on image recognition\ntasks using CIFAR10 and ImageNet. On both datasets, EPNAS is superior \\wrt\narchitecture searching speed and recognition accuracy.\n", "versions": [{"version": "v1", "created": "Sun, 7 Jul 2019 03:50:42 GMT"}], "update_date": "2019-07-11", "authors_parsed": [["Zhou", "Yanqi", ""], ["Wang", "Peng", ""], ["Arik", "Sercan", ""], ["Yu", "Haonan", ""], ["Zawad", "Syed", ""], ["Yan", "Feng", ""], ["Diamos", "Greg", ""]]}, {"id": "1907.04650", "submitter": "Weiwen Jiang", "authors": "Weiwen Jiang, Lei Yang, Edwin Sha, Qingfeng Zhuge, Shouzhen Gu,\n  Sakyasingha Dasgupta, Yiyu Shi, Jingtong Hu", "title": "Hardware/Software Co-Exploration of Neural Architectures", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel hardware and software co-exploration framework for\nefficient neural architecture search (NAS). Different from existing\nhardware-aware NAS which assumes a fixed hardware design and explores the\nneural architecture search space only, our framework simultaneously explores\nboth the architecture search space and the hardware design space to identify\nthe best neural architecture and hardware pairs that maximize both test\naccuracy and hardware efficiency. Such a practice greatly opens up the design\nfreedom and pushes forward the Pareto frontier between hardware efficiency and\ntest accuracy for better design tradeoffs. The framework iteratively performs a\ntwo-level (fast and slow) exploration. Without lengthy training, the fast\nexploration can effectively fine-tune hyperparameters and prune inferior\narchitectures in terms of hardware specifications, which significantly\naccelerates the NAS process. Then, the slow exploration trains candidates on a\nvalidation set and updates a controller using the reinforcement learning to\nmaximize the expected accuracy together with the hardware efficiency.\nExperiments on ImageNet show that our co-exploration NAS can find the neural\narchitectures and associated hardware design with the same accuracy, 35.24%\nhigher throughput, 54.05% higher energy efficiency and 136x reduced search\ntime, compared with the state-of-the-art hardware-aware NAS.\n", "versions": [{"version": "v1", "created": "Sat, 6 Jul 2019 14:16:51 GMT"}, {"version": "v2", "created": "Sat, 11 Jan 2020 14:15:01 GMT"}], "update_date": "2020-01-14", "authors_parsed": [["Jiang", "Weiwen", ""], ["Yang", "Lei", ""], ["Sha", "Edwin", ""], ["Zhuge", "Qingfeng", ""], ["Gu", "Shouzhen", ""], ["Dasgupta", "Sakyasingha", ""], ["Shi", "Yiyu", ""], ["Hu", "Jingtong", ""]]}, {"id": "1907.04651", "submitter": "Brendan Bennett", "authors": "Brendan Bennett, Wesley Chung, Muhammad Zaheer, Vincent Liu", "title": "Incrementally Learning Functions of the Return", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Temporal difference methods enable efficient estimation of value functions in\nreinforcement learning in an incremental fashion, and are of broader interest\nbecause they correspond learning as observed in biological systems. Standard\nvalue functions correspond to the expected value of a sum of discounted\nreturns. While this formulation is often sufficient for many purposes, it would\noften be useful to be able to represent functions of the return as well.\nUnfortunately, most such functions cannot be estimated directly using TD\nmethods. We propose a means of estimating functions of the return using its\nmoments, which can be learned online using a modified TD algorithm. The moments\nof the return are then used as part of a Taylor expansion to approximate\nanalytic functions of the return.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jul 2019 22:33:36 GMT"}], "update_date": "2019-07-11", "authors_parsed": [["Bennett", "Brendan", ""], ["Chung", "Wesley", ""], ["Zaheer", "Muhammad", ""], ["Liu", "Vincent", ""]]}, {"id": "1907.04652", "submitter": "Hongyang Gao", "authors": "Hongyang Gao and Shuiwang Ji", "title": "Graph Representation Learning via Hard and Channel-Wise Attention\n  Networks", "comments": "9 pages, KDD19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Attention operators have been widely applied in various fields, including\ncomputer vision, natural language processing, and network embedding learning.\nAttention operators on graph data enables learnable weights when aggregating\ninformation from neighboring nodes. However, graph attention operators (GAOs)\nconsume excessive computational resources, preventing their applications on\nlarge graphs. In addition, GAOs belong to the family of soft attention, instead\nof hard attention, which has been shown to yield better performance. In this\nwork, we propose novel hard graph attention operator (hGAO) and channel-wise\ngraph attention operator (cGAO). hGAO uses the hard attention mechanism by\nattending to only important nodes. Compared to GAO, hGAO improves performance\nand saves computational cost by only attending to important nodes. To further\nreduce the requirements on computational resources, we propose the cGAO that\nperforms attention operations along channels. cGAO avoids the dependency on the\nadjacency matrix, leading to dramatic reductions in computational resource\nrequirements. Experimental results demonstrate that our proposed deep models\nwith the new operators achieve consistently better performance. Comparison\nresults also indicates that hGAO achieves significantly better performance than\nGAO on both node and graph embedding tasks. Efficiency comparison shows that\nour cGAO leads to dramatic savings in computational resources, making them\napplicable to large graphs.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jul 2019 20:04:14 GMT"}], "update_date": "2019-07-11", "authors_parsed": [["Gao", "Hongyang", ""], ["Ji", "Shuiwang", ""]]}, {"id": "1907.04658", "submitter": "Jeffrey Barratt", "authors": "Jeffrey Barratt, Chuanbo Pan", "title": "Playing Go without Game Tree Search Using Convolutional Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The game of Go has a long history in East Asian countries, but the field of\nComputer Go has yet to catch up to humans until the past couple of years. While\nthe rules of Go are simple, the strategy and combinatorics of the game are\nimmensely complex. Even within the past couple of years, new programs that rely\non neural networks to evaluate board positions still explore many orders of\nmagnitude more board positions per second than a professional can. We attempt\nto mimic human intuition in the game by creating a convolutional neural policy\nnetwork which, without any sort of tree search, should play the game at or\nabove the level of most humans. We introduce three structures and training\nmethods that aim to create a strong Go player: non-rectangular convolutions,\nwhich will better learn the shapes on the board, supervised learning, training\non a data set of 53,000 professional games, and reinforcement learning,\ntraining on games played between different versions of the network. Our network\nhas already surpassed the skill level of intermediate amateurs simply using\nsupervised learning. Further training and implementation of non-rectangular\nconvolutions and reinforcement learning will likely increase this skill level\nmuch further.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jul 2019 19:12:38 GMT"}], "update_date": "2019-07-12", "authors_parsed": [["Barratt", "Jeffrey", ""], ["Pan", "Chuanbo", ""]]}, {"id": "1907.04662", "submitter": "Mirco Mutti", "authors": "Mirco Mutti, Marcello Restelli", "title": "An Intrinsically-Motivated Approach for Learning Highly Exploring and\n  Fast Mixing Policies", "comments": "In 34th AAAI Conference on Artificial Intelligence (AAAI 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  What is a good exploration strategy for an agent that interacts with an\nenvironment in the absence of external rewards? Ideally, we would like to get a\npolicy driving towards a uniform state-action visitation (highly exploring) in\na minimum number of steps (fast mixing), in order to ease efficient learning of\nany goal-conditioned policy later on. Unfortunately, it is remarkably arduous\nto directly learn an optimal policy of this nature. In this paper, we propose a\nnovel surrogate objective for learning highly exploring and fast mixing\npolicies, which focuses on maximizing a lower bound to the entropy of the\nsteady-state distribution induced by the policy. In particular, we introduce\nthree novel lower bounds, that lead to as many optimization problems, that\ntradeoff the theoretical guarantees with computational complexity. Then, we\npresent a model-based reinforcement learning algorithm, IDE$^{3}$AL, to learn\nan optimal policy according to the introduced objective. Finally, we provide an\nempirical evaluation of this algorithm on a set of hard-exploration tasks.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jul 2019 12:28:37 GMT"}, {"version": "v2", "created": "Thu, 19 Dec 2019 10:49:28 GMT"}], "update_date": "2019-12-20", "authors_parsed": [["Mutti", "Mirco", ""], ["Restelli", "Marcello", ""]]}, {"id": "1907.04666", "submitter": "Paul Compagnon", "authors": "Paul Compagnon (imagine), Gr\\'egoire Lefebvre, Stefan Duffner\n  (imagine), Christophe Garcia (imagine)", "title": "Routine Modeling with Time Series Metric Learning", "comments": null, "journal-ref": "28th International Conference on Artificial Neural Networks, Sep\n  2019, Munich, Germany", "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditionally, the automatic recognition of human activities is performed\nwith supervised learning algorithms on limited sets of specific activities.\nThis work proposes to recognize recurrent activity patterns, called routines,\ninstead of precisely defined activities. The modeling of routines is defined as\na metric learning problem, and an architecture, called SS2S, based on\nsequence-to-sequence models is proposed to learn a distance between time\nseries. This approach only relies on inertial data and is thus non intrusive\nand preserves privacy. Experimental results show that a clustering algorithm\nprovided with the learned distance is able to recover daily routines.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jul 2019 14:10:01 GMT"}], "update_date": "2019-07-11", "authors_parsed": [["Compagnon", "Paul", "", "imagine"], ["Lefebvre", "Gr\u00e9goire", "", "imagine"], ["Duffner", "Stefan", "", "imagine"], ["Garcia", "Christophe", "", "imagine"]]}, {"id": "1907.04667", "submitter": "Wentao Ouyang", "authors": "Wentao Ouyang, Xiuwu Zhang, Shukui Ren, Li Li, Zhaojie Liu, Yanlong Du", "title": "Click-Through Rate Prediction with the User Memory Network", "comments": "Accepted by DLP-KDD 2019 (1st International Workshop on Deep Learning\n  Practice for High-Dimensional Sparse Data; with KDD 2019). arXiv admin note:\n  text overlap with arXiv:1906.04365, arXiv:1906.03776", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Click-through rate (CTR) prediction is a critical task in online advertising\nsystems. Models like Deep Neural Networks (DNNs) are simple but stateless. They\nconsider each target ad independently and cannot directly extract useful\ninformation contained in users' historical ad impressions and clicks. In\ncontrast, models like Recurrent Neural Networks (RNNs) are stateful but\ncomplex. They model temporal dependency between users' sequential behaviors and\ncan achieve improved prediction performance than DNNs. However, both the\noffline training and online prediction process of RNNs are much more complex\nand time-consuming. In this paper, we propose Memory Augmented DNN (MA-DNN) for\npractical CTR prediction services. In particular, we create two external memory\nvectors for each user, memorizing high-level abstractions of what a user\npossibly likes and dislikes. The proposed MA-DNN achieves a good compromise\nbetween DNN and RNN. It is as simple as DNN, but has certain ability to exploit\nuseful information contained in users' historical behaviors as RNN. Both\noffline and online experiments demonstrate the effectiveness of MA-DNN for\npractical CTR prediction services. Actually, the memory component can be\naugmented to other models as well (e.g., the Wide&Deep model).\n", "versions": [{"version": "v1", "created": "Tue, 9 Jul 2019 03:40:07 GMT"}, {"version": "v2", "created": "Sat, 20 Jul 2019 00:30:26 GMT"}], "update_date": "2019-07-23", "authors_parsed": [["Ouyang", "Wentao", ""], ["Zhang", "Xiuwu", ""], ["Ren", "Shukui", ""], ["Li", "Li", ""], ["Liu", "Zhaojie", ""], ["Du", "Yanlong", ""]]}, {"id": "1907.04669", "submitter": "Sebastien Martin", "authors": "Dimitris Bertsimas, Arthur Delarue, Patrick Jaillet, Sebastien Martin", "title": "Optimal Explanations of Linear Models", "comments": "arXiv admin note: substantial text overlap with arXiv:1907.03419", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When predictive models are used to support complex and important decisions,\nthe ability to explain a model's reasoning can increase trust, expose hidden\nbiases, and reduce vulnerability to adversarial attacks. However, attempts at\ninterpreting models are often ad hoc and application-specific, and the concept\nof interpretability itself is not well-defined. We propose a general\noptimization framework to create explanations for linear models. Our\nmethodology decomposes a linear model into a sequence of models of increasing\ncomplexity using coordinate updates on the coefficients. Computing this\ndecomposition optimally is a difficult optimization problem for which we\npropose exact algorithms and scalable heuristics. By solving this problem, we\ncan derive a parametrized family of interpretability metrics for linear models\nthat generalizes typical proxies, and study the tradeoff between\ninterpretability and predictive accuracy.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jul 2019 06:59:05 GMT"}], "update_date": "2019-07-11", "authors_parsed": [["Bertsimas", "Dimitris", ""], ["Delarue", "Arthur", ""], ["Jaillet", "Patrick", ""], ["Martin", "Sebastien", ""]]}, {"id": "1907.04670", "submitter": "Larkin Liu", "authors": "Larkin Liu, Yu-Chung Lin, Joshua Reid", "title": "Improving the Performance of the LSTM and HMM Model via Hybridization", "comments": "Working Manuscript", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.CO stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Language models based on deep neural networks and traditional stochastic\nmodelling have become both highly functional and effective in recent times. In\nthis work, a general survey into the two types of language modelling is\nconducted. We investigate the effectiveness of the Hidden Markov Model (HMM),\nand the Long Short-Term Memory Model (LSTM). We analyze the hidden state\nstructures common to both models, and present an analysis on structural\nsimilarity of the hidden states, common to both HMM's and LSTM's. We compare\nthe LSTM's predictive accuracy and hidden state output with respect to the HMM\nfor a varying number of hidden states. In this work, we justify that the less\ncomplex HMM can serve as an appropriate approximation of the LSTM model.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jul 2019 15:12:51 GMT"}, {"version": "v2", "created": "Mon, 14 Oct 2019 21:05:24 GMT"}, {"version": "v3", "created": "Wed, 16 Oct 2019 10:56:06 GMT"}, {"version": "v4", "created": "Sun, 28 Feb 2021 13:16:57 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Liu", "Larkin", ""], ["Lin", "Yu-Chung", ""], ["Reid", "Joshua", ""]]}, {"id": "1907.04675", "submitter": "S\\\"oren Dittmer", "authors": "S\\\"oren Dittmer and Peter Maass", "title": "A Projectional Ansatz to Reconstruction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV math.FA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently the field of inverse problems has seen a growing usage of\nmathematically only partially understood learned and non-learned priors. Based\non first principles, we develop a projectional approach to inverse problems\nthat addresses the incorporation of these priors, while still guaranteeing data\nconsistency. We implement this projectional method (PM) on the one hand via\nvery general Plug-and-Play priors and on the other hand, via an end-to-end\ntraining approach. To this end, we introduce a novel alternating neural\narchitecture, allowing for the incorporation of highly customized priors from\ndata in a principled manner. We also show how the recent success of\nRegularization by Denoising (RED) can, at least to some extent, be explained as\nan approximation of the PM. Furthermore, we demonstrate how the idea can be\napplied to stop the degradation of Deep Image Prior (DIP) reconstructions over\ntime.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jul 2019 12:49:07 GMT"}, {"version": "v2", "created": "Tue, 6 Aug 2019 11:36:52 GMT"}], "update_date": "2019-08-07", "authors_parsed": [["Dittmer", "S\u00f6ren", ""], ["Maass", "Peter", ""]]}, {"id": "1907.04685", "submitter": "Fabio Muratore", "authors": "Fabio Muratore, Michael Gienger, Jan Peters", "title": "Assessing Transferability from Simulation to Reality for Reinforcement\n  Learning", "comments": null, "journal-ref": null, "doi": "10.1109/TPAMI.2019.2952353", "report-no": null, "categories": "cs.RO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning robot control policies from physics simulations is of great interest\nto the robotics community as it may render the learning process faster,\ncheaper, and safer by alleviating the need for expensive real-world\nexperiments. However, the direct transfer of learned behavior from simulation\nto reality is a major challenge. Optimizing a policy on a slightly faulty\nsimulator can easily lead to the maximization of the `Simulation Optimization\nBias` (SOB). In this case, the optimizer exploits modeling errors of the\nsimulator such that the resulting behavior can potentially damage the robot. We\ntackle this challenge by applying domain randomization, i.e., randomizing the\nparameters of the physics simulations during learning. We propose an algorithm\ncalled Simulation-based Policy Optimization with Transferability Assessment\n(SPOTA) which uses an estimator of the SOB to formulate a stopping criterion\nfor training. The introduced estimator quantifies the over-fitting to the set\nof domains experienced while training. Our experimental results on two\ndifferent second order nonlinear systems show that the new simulation-based\npolicy search algorithm is able to learn a control policy exclusively from a\nrandomized simulator, which can be applied directly to real systems without any\nadditional training.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jul 2019 12:56:28 GMT"}, {"version": "v2", "created": "Mon, 21 Oct 2019 11:58:28 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Muratore", "Fabio", ""], ["Gienger", "Michael", ""], ["Peters", "Jan", ""]]}, {"id": "1907.04699", "submitter": "Yunyi Li", "authors": "Yunyi Li, Guan Gui, Xiefeng Cheng", "title": "From Group Sparse Coding to Rank Minimization: A Novel Denoising Model\n  for Low-level Image Restoration", "comments": "Accepted by Signal Processing", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, low-rank matrix recovery theory has been emerging as a significant\nprogress for various image processing problems. Meanwhile, the group sparse\ncoding (GSC) theory has led to great successes in image restoration (IR)\nproblem with each group contains low-rank property. In this paper, we propose a\nnovel low-rank minimization based denoising model for IR tasks under the\nperspective of GSC, an important connection between our denoising model and\nrank minimization problem has been put forward. To overcome the bias problem\ncaused by convex nuclear norm minimization (NNM) for rank approximation, a more\ngeneralized and flexible rank relaxation function is employed, namely weighted\nnonconvex relaxation. Accordingly, an efficient iteratively-reweighted\nalgorithm is proposed to handle the resulting minimization problem combing with\nthe popular L_(1/2) and L_(2/3) thresholding operators. Finally, our proposed\ndenoising model is applied to IR problems via an alternating direction method\nof multipliers (ADMM) strategy. Typical IR experiments on image compressive\nsensing (CS), inpainting, deblurring and impulsive noise removal demonstrate\nthat our proposed method can achieve significantly higher PSNR/FSIM values than\nmany relevant state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jul 2019 13:10:27 GMT"}, {"version": "v2", "created": "Sat, 13 Jul 2019 08:04:10 GMT"}, {"version": "v3", "created": "Sat, 23 May 2020 05:40:49 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Li", "Yunyi", ""], ["Gui", "Guan", ""], ["Cheng", "Xiefeng", ""]]}, {"id": "1907.04707", "submitter": "Hao Chen", "authors": "Hao Chen, Yue Xu, Feiran Huang, Zengde Deng, Wenbing Huang, Senzhang\n  Wang, Peng He, Zhoujun Li", "title": "Label-Aware Graph Convolutional Networks", "comments": "Accepted by CIKM 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in Graph Convolutional Networks (GCNs) have led to\nstate-of-the-art performance on various graph-related tasks. However, most\nexisting GCN models do not explicitly identify whether all the aggregated\nneighbors are valuable to the learning tasks, which may harm the learning\nperformance. In this paper, we consider the problem of node classification and\npropose the Label-Aware Graph Convolutional Network (LAGCN) framework which can\ndirectly identify valuable neighbors to enhance the performance of existing GCN\nmodels. Our contribution is three-fold. First, we propose a label-aware edge\nclassifier that can filter distracting neighbors and add valuable neighbors for\neach node to refine the original graph into a label-aware~(LA) graph. Existing\nGCN models can directly learn from the LA graph to improve the performance\nwithout changing their model architectures. Second, we introduce the concept of\npositive ratio to evaluate the density of valuable neighbors in the LA graph.\nTheoretical analysis reveals that using the edge classifier to increase the\npositive ratio can improve the learning performance of existing GCN models.\nThird, we conduct extensive node classification experiments on benchmark\ndatasets. The results verify that LAGCN can improve the performance of existing\nGCN models considerably, in terms of node classification.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jul 2019 13:20:49 GMT"}, {"version": "v2", "created": "Sat, 5 Sep 2020 07:01:37 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Chen", "Hao", ""], ["Xu", "Yue", ""], ["Huang", "Feiran", ""], ["Deng", "Zengde", ""], ["Huang", "Wenbing", ""], ["Wang", "Senzhang", ""], ["He", "Peng", ""], ["Li", "Zhoujun", ""]]}, {"id": "1907.04708", "submitter": "Martin Tappler", "authors": "Bernhard K. Aichernig and Roderick Bloem and Masoud Ebrahimi and\n  Martin Horn and Franz Pernkopf and Wolfgang Roth and Astrid Rupp and Martin\n  Tappler and Markus Tranninger", "title": "Learning a Behavior Model of Hybrid Systems Through Combining\n  Model-Based Testing and Machine Learning (Full Version)", "comments": "This is an extended version of the conference paper \"Learning a\n  Behavior Model of Hybrid Systems Through Combining Model-Based Testing and\n  Machine Learning\" accepted for presentation at IFIP-ICTSS 2019, the 31st\n  International Conference on Testing Software and Systems in Paris, France", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Models play an essential role in the design process of cyber-physical\nsystems. They form the basis for simulation and analysis and help in\nidentifying design problems as early as possible. However, the construction of\nmodels that comprise physical and digital behavior is challenging. Therefore,\nthere is considerable interest in learning such hybrid behavior by means of\nmachine learning which requires sufficient and representative training data\ncovering the behavior of the physical system adequately. In this work, we\nexploit a combination of automata learning and model-based testing to generate\nsufficient training data fully automatically.\n  Experimental results on a platooning scenario show that recurrent neural\nnetworks learned with this data achieved significantly better results compared\nto models learned from randomly generated data. In particular, the\nclassification error for crash detection is reduced by a factor of five and a\nsimilar F1-score is obtained with up to three orders of magnitude fewer\ntraining samples.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jul 2019 13:22:32 GMT"}], "update_date": "2019-07-11", "authors_parsed": [["Aichernig", "Bernhard K.", ""], ["Bloem", "Roderick", ""], ["Ebrahimi", "Masoud", ""], ["Horn", "Martin", ""], ["Pernkopf", "Franz", ""], ["Roth", "Wolfgang", ""], ["Rupp", "Astrid", ""], ["Tappler", "Martin", ""], ["Tranninger", "Markus", ""]]}, {"id": "1907.04710", "submitter": "Oleg Arenz", "authors": "Oleg Arenz, Mingjun Zhong and Gerhard Neumann", "title": "Trust-Region Variational Inference with Gaussian Mixture Models", "comments": null, "journal-ref": "Journal of Machine Learning Research. 21(163):1-60, 2020", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many methods for machine learning rely on approximate inference from\nintractable probability distributions. Variational inference approximates such\ndistributions by tractable models that can be subsequently used for approximate\ninference. Learning sufficiently accurate approximations requires a rich model\nfamily and careful exploration of the relevant modes of the target\ndistribution. We propose a method for learning accurate GMM approximations of\nintractable probability distributions based on insights from policy search by\nusing information-geometric trust regions for principled exploration. For\nefficient improvement of the GMM approximation, we derive a lower bound on the\ncorresponding optimization objective enabling us to update the components\nindependently. Our use of the lower bound ensures convergence to a stationary\npoint of the original objective. The number of components is adapted online by\nadding new components in promising regions and by deleting components with\nnegligible weight. We demonstrate on several domains that we can learn\napproximations of complex, multimodal distributions with a quality that is\nunmet by previous variational inference methods, and that the GMM approximation\ncan be used for drawing samples that are on par with samples created by\nstate-of-the-art MCMC samplers while requiring up to three orders of magnitude\nless computational resources.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jul 2019 13:31:17 GMT"}, {"version": "v2", "created": "Tue, 4 Aug 2020 12:43:25 GMT"}], "update_date": "2020-10-08", "authors_parsed": [["Arenz", "Oleg", ""], ["Zhong", "Mingjun", ""], ["Neumann", "Gerhard", ""]]}, {"id": "1907.04711", "submitter": "Paulo Roberto De Oliveira Da Costa", "authors": "Paulo R. de O. da Costa, J. Rhuggenaath, Y. Zhang, A. Akcay, W. Lee\n  and U. Kaymak", "title": "Data-driven Policy on Feasibility Determination for the Train Shunting\n  Problem", "comments": "Accepted as conference paper at ECML PKDD 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Parking, matching, scheduling, and routing are common problems in train\nmaintenance. In particular, train units are commonly maintained and cleaned at\ndedicated shunting yards. The planning problem that results from such\nsituations is referred to as the Train Unit Shunting Problem (TUSP). This\nproblem involves matching arriving train units to service tasks and determining\nthe schedule for departing trains. The TUSP is an important problem as it is\nused to determine the capacity of shunting yards and arises as a sub-problem of\nmore general scheduling and planning problems. In this paper, we consider the\ncase of the Dutch Railways (NS) TUSP. As the TUSP is complex, NS currently uses\na local search (LS) heuristic to determine if an instance of the TUSP has a\nfeasible solution. Given the number of shunting yards and the size of the\nplanning problems, improving the evaluation speed of the LS brings significant\ncomputational gain. In this work, we use a machine learning approach that\ncomplements the LS and accelerates the search process. We use a Deep Graph\nConvolutional Neural Network (DGCNN) model to predict the feasibility of\nsolutions obtained during the run of the LS heuristic. We use this model to\ndecide whether to continue or abort the search process. In this way, the\ncomputation time is used more efficiently as it is spent on instances that are\nmore likely to be feasible. Using simulations based on real-life instances of\nthe TUSP, we show how our approach improves upon the previous method on\nprediction accuracy and leads to computational gains for the decision-making\nprocess.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jul 2019 13:32:14 GMT"}], "update_date": "2019-07-11", "authors_parsed": [["da Costa", "Paulo R. de O.", ""], ["Rhuggenaath", "J.", ""], ["Zhang", "Y.", ""], ["Akcay", "A.", ""], ["Lee", "W.", ""], ["Kaymak", "U.", ""]]}, {"id": "1907.04723", "submitter": "Firas Jarboui", "authors": "Firas Jarboui, C\\'elya Gruson-daniel, Pierre Chanial, Alain Durmus,\n  Vincent Rocchisani, Sophie-helene Goulet Ebongue, Anneliese Depoux, Wilfried\n  Kirschenmann, Vianney Perchet", "title": "Markov Decision Process for MOOC users behavioral inference", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-030-19875-6_9", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Studies on massive open online courses (MOOCs) users discuss the existence of\ntypical profiles and their impact on the learning process of the students.\nHowever defining the typical behaviors as well as classifying the users\naccordingly is a difficult task. In this paper we suggest two methods to model\nMOOC users behaviour given their log data. We mold their behavior into a Markov\nDecision Process framework. We associate the user's intentions with the MDP\nreward and argue that this allows us to classify them.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jul 2019 13:43:48 GMT"}, {"version": "v2", "created": "Wed, 10 Mar 2021 16:05:36 GMT"}], "update_date": "2021-03-11", "authors_parsed": [["Jarboui", "Firas", ""], ["Gruson-daniel", "C\u00e9lya", ""], ["Chanial", "Pierre", ""], ["Durmus", "Alain", ""], ["Rocchisani", "Vincent", ""], ["Ebongue", "Sophie-helene Goulet", ""], ["Depoux", "Anneliese", ""], ["Kirschenmann", "Wilfried", ""], ["Perchet", "Vianney", ""]]}, {"id": "1907.04728", "submitter": "Congcong Liu", "authors": "Congcong Liu, Yuying Chen, Lei Tai, Ming Liu, Bertram Shi", "title": "Utilizing Eye Gaze to Enhance the Generalization of Imitation Networks\n  to Unseen Environments", "comments": "4 pages, 3 figures, accepted by ICML 2019 Workshop on Understanding\n  and Improving Generalization in Deep Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Vision-based autonomous driving through imitation learning mimics the\nbehaviors of human drivers by training on pairs of data of raw driver-view\nimages and actions. However, there are other cues, e.g. gaze behavior,\navailable from human drivers that have yet to be exploited. Previous research\nhas shown that novice human learners can benefit from observing experts' gaze\npatterns. We show here that deep neural networks can also benefit from this. We\ndemonstrate different approaches to integrating gaze information into imitation\nnetworks. Our results show that the integration of gaze information improves\nthe generalization performance of networks to unseen environments.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jul 2019 13:55:05 GMT"}, {"version": "v2", "created": "Tue, 27 Aug 2019 03:51:20 GMT"}], "update_date": "2019-08-28", "authors_parsed": [["Liu", "Congcong", ""], ["Chen", "Yuying", ""], ["Tai", "Lei", ""], ["Liu", "Ming", ""], ["Shi", "Bertram", ""]]}, {"id": "1907.04761", "submitter": "Luca Cavalli", "authors": "Luca Cavalli, Gianpaolo Di Pietro, Matteo Matteucci", "title": "Towards Affordance Prediction with Vision via Task Oriented Grasp\n  Quality Metrics", "comments": "8 pages, presented at the Second International Workshop on\n  Computational Models of Affordance in Robotics", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While many quality metrics exist to evaluate the quality of a grasp by\nitself, no clear quantification of the quality of a grasp relatively to the\ntask the grasp is used for has been defined yet. In this paper we propose a\nframework to extend the concept of grasp quality metric to task-oriented\ngrasping by defining affordance functions via basic grasp metrics for an open\nset of task affordances. We evaluate both the effectivity of the proposed task\noriented metrics and their practical applicability by learning to infer them\nfrom vision. Indeed, we assess the validity of our novel framework both in the\ncontext of perfect information, i.e., known object model, and in the partial\ninformation context, i.e., inferring task oriented metrics from vision,\nunderlining advantages and limitations of both situations. In the former,\nphysical metrics of grasp hypotheses on an object are defined and computed in\nknown object model simulation, in the latter deep models are trained to infer\nsuch properties from partial information in the form of synthesized range\nimages.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jul 2019 14:45:37 GMT"}], "update_date": "2019-07-11", "authors_parsed": [["Cavalli", "Luca", ""], ["Di Pietro", "Gianpaolo", ""], ["Matteucci", "Matteo", ""]]}, {"id": "1907.04774", "submitter": "Rohan Reddy Mekala", "authors": "Rohan Reddy Mekala, Gudjon Einar Magnusson, Adam Porter, Mikael\n  Lindvall, Madeline Diep", "title": "Metamorphic Detection of Adversarial Examples in Deep Learning Models\n  With Affine Transformations", "comments": null, "journal-ref": null, "doi": "10.1109/MET.2019.00016", "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial attacks are small, carefully crafted perturbations, imperceptible\nto the naked eye; that when added to an image cause deep learning models to\nmisclassify the image with potentially detrimental outcomes. With the rise of\nartificial intelligence models in consumer safety and security intensive\nindustries such as self-driving cars, camera surveillance and face recognition,\nthere is a growing need for guarding against adversarial attacks. In this\npaper, we present an approach that uses metamorphic testing principles to\nautomatically detect such adversarial attacks. The approach can detect image\nmanipulations that are so small, that they are impossible to detect by a human\nthrough visual inspection. By applying metamorphic relations based on distance\nratio preserving affine image transformations which compare the behavior of the\noriginal and transformed image; we show that our proposed approach can\ndetermine whether or not the input image is adversarial with a high degree of\naccuracy.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jul 2019 15:04:18 GMT"}], "update_date": "2019-07-11", "authors_parsed": [["Mekala", "Rohan Reddy", ""], ["Magnusson", "Gudjon Einar", ""], ["Porter", "Adam", ""], ["Lindvall", "Mikael", ""], ["Diep", "Madeline", ""]]}, {"id": "1907.04786", "submitter": "Yuguang Wang", "authors": "Ming Li, Zheng Ma, Yu Guang Wang, Xiaosheng Zhuang", "title": "Fast Haar Transforms for Graph Neural Networks", "comments": "24 pages, 5 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph Neural Networks (GNNs) have become a topic of intense research recently\ndue to their powerful capability in high-dimensional classification and\nregression tasks for graph-structured data. However, as GNNs typically define\nthe graph convolution by the orthonormal basis for the graph Laplacian, they\nsuffer from high computational cost when the graph size is large. This paper\nintroduces Haar basis which is a sparse and localized orthonormal system for a\ncoarse-grained chain on graph. The graph convolution under Haar basis, called\nHaar convolution, can be defined accordingly for GNNs. The sparsity and\nlocality of the Haar basis allow Fast Haar Transforms (FHTs) on graph, by which\na fast evaluation of Haar convolution between graph data and filters can be\nachieved. We conduct experiments on GNNs equipped with Haar convolution, which\ndemonstrates state-of-the-art results on graph-based regression and node\nclassification tasks.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jul 2019 15:22:37 GMT"}, {"version": "v2", "created": "Tue, 23 Jul 2019 11:22:02 GMT"}, {"version": "v3", "created": "Wed, 30 Oct 2019 16:57:18 GMT"}], "update_date": "2019-10-31", "authors_parsed": [["Li", "Ming", ""], ["Ma", "Zheng", ""], ["Wang", "Yu Guang", ""], ["Zhuang", "Xiaosheng", ""]]}, {"id": "1907.04788", "submitter": "Tong Wu", "authors": "Tong Wu, Yang Gu, Yiqiang Chen, Yunlong Xiao, and Jiwei Wang", "title": "A Mobile Cloud Collaboration Fall Detection System Based on Ensemble\n  Learning", "comments": "7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Falls are one of the important causes of accidental or unintentional injury\ndeath worldwide. Therefore, this paper presents a reliable fall detection\nalgorithm and a mobile cloud collaboration system for fall detection. The\nalgorithm is an ensemble learning method based on decision tree, named\nFalldetection Ensemble Decision Tree (FEDT). The mobile cloud collaboration\nsystem can be divided into three stages: 1) mobile stage: use a light-weighted\nthreshold method to filter out the activities of daily livings (ADLs), 2)\ncollaboration stage: transmit data to cloud and meanwhile extract features in\nthe cloud, 3) cloud stage: deploy the model trained by FEDT to give the final\ndetection result with the extracted features. Experiments show that the\nperformance of the proposed FEDT outperforms the others' over 1-3% both on\nsensitivity and specificity, and more importantly, the system can provide\nreliable fall detection in practical scenario.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jul 2019 11:57:06 GMT"}], "update_date": "2019-07-11", "authors_parsed": [["Wu", "Tong", ""], ["Gu", "Yang", ""], ["Chen", "Yiqiang", ""], ["Xiao", "Yunlong", ""], ["Wang", "Jiwei", ""]]}, {"id": "1907.04796", "submitter": "Rika Antonova", "authors": "Rika Antonova, Akshara Rai, Tianyu Li, Danica Kragic", "title": "Bayesian Optimization in Variational Latent Spaces with Dynamic\n  Compression", "comments": "(Rika Antonova and Akshara Rai contributed equally)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data-efficiency is crucial for autonomous robots to adapt to new tasks and\nenvironments. In this work we focus on robotics problems with a budget of only\n10-20 trials. This is a very challenging setting even for data-efficient\napproaches like Bayesian optimization (BO), especially when optimizing\nhigher-dimensional controllers. Simulated trajectories can be used to construct\ninformed kernels for BO. However, previous work employed supervised ways of\nextracting low-dimensional features for these. We propose a model and\narchitecture for a sequential variational autoencoder that embeds the space of\nsimulated trajectories into a lower-dimensional space of latent paths in an\nunsupervised way. We further compress the search space for BO by reducing\nexploration in parts of the state space that are undesirable, without requiring\nexplicit constraints on controller parameters. We validate our approach with\nhardware experiments on a Daisy hexapod robot and an ABB Yumi manipulator. We\nalso present simulation experiments with further comparisons to several\nbaselines on Daisy and two manipulators. Our experiments indicate the proposed\ntrajectory-based kernel with dynamic compression can offer ultra data-efficient\noptimization.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jul 2019 15:34:06 GMT"}], "update_date": "2019-07-11", "authors_parsed": [["Antonova", "Rika", ""], ["Rai", "Akshara", ""], ["Li", "Tianyu", ""], ["Kragic", "Danica", ""]]}, {"id": "1907.04799", "submitter": "Hao-Tien Lewis Chiang", "authors": "Hao-Tien Lewis Chiang, Jasmine Hsu, Marek Fiser, Lydia Tapia,\n  Aleksandra Faust", "title": "RL-RRT: Kinodynamic Motion Planning via Learning Reachability Estimators\n  from RL Policies", "comments": "Accepted to Robotics and Automation Letters in June 2019", "journal-ref": "Robotics and Automation Letters 2019", "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses two challenges facing sampling-based kinodynamic motion\nplanning: a way to identify good candidate states for local transitions and the\nsubsequent computationally intractable steering between these candidate states.\nThrough the combination of sampling-based planning, a Rapidly Exploring\nRandomized Tree (RRT) and an efficient kinodynamic motion planner through\nmachine learning, we propose an efficient solution to long-range planning for\nkinodynamic motion planning. First, we use deep reinforcement learning to learn\nan obstacle-avoiding policy that maps a robot's sensor observations to actions,\nwhich is used as a local planner during planning and as a controller during\nexecution. Second, we train a reachability estimator in a supervised manner,\nwhich predicts the RL policy's time to reach a state in the presence of\nobstacles. Lastly, we introduce RL-RRT that uses the RL policy as a local\nplanner, and the reachability estimator as the distance function to bias\ntree-growth towards promising regions. We evaluate our method on three\nkinodynamic systems, including physical robot experiments. Results across all\nthree robots tested indicate that RL-RRT outperforms state of the art\nkinodynamic planners in efficiency, and also provides a shorter path finish\ntime than a steering function free method. The learned local planner policy and\naccompanying reachability estimator demonstrate transferability to the\npreviously unseen experimental environments, making RL-RRT fast because the\nexpensive computations are replaced with simple neural network inference.\nVideo: https://youtu.be/dDMVMTOI8KY\n", "versions": [{"version": "v1", "created": "Wed, 10 Jul 2019 15:36:03 GMT"}, {"version": "v2", "created": "Fri, 12 Jul 2019 17:55:01 GMT"}], "update_date": "2019-07-15", "authors_parsed": [["Chiang", "Hao-Tien Lewis", ""], ["Hsu", "Jasmine", ""], ["Fiser", "Marek", ""], ["Tapia", "Lydia", ""], ["Faust", "Aleksandra", ""]]}, {"id": "1907.04805", "submitter": "Amit Sharma", "authors": "Rathin Desai and Amit Sharma", "title": "Quantifying Error in the Presence of Confounders for Causal Inference", "comments": "13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Estimating average causal effect (ACE) is useful whenever we want to know the\neffect of an intervention on a given outcome. In the absence of a randomized\nexperiment, many methods such as stratification and inverse propensity\nweighting have been proposed to estimate ACE. However, it is hard to know which\nmethod is optimal for a given dataset or which hyperparameters to use for a\nchosen method. To this end, we provide a framework to characterize the loss of\na causal inference method against the true ACE, by framing causal inference as\na representation learning problem. We show that many popular methods, including\nback-door methods can be considered as weighting or representation learning\nalgorithms, and provide general error bounds for their causal estimates. In\naddition, we consider the case when unobserved variables can confound the\ncausal estimate and extend proposed bounds using principles of robust\nstatistics, considering confounding as contamination under the Huber\ncontamination model. These bounds are also estimable; as an example, we provide\nempirical bounds for the Inverse Propensity Weighting (IPW) estimator and show\nhow the bounds can be used to optimize the threshold of clipping extreme\npropensity scores. Our work provides a new way to reason about competing\nestimators, and opens up the potential of deriving new methods by minimizing\nthe proposed error bounds.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jul 2019 15:53:07 GMT"}], "update_date": "2019-07-11", "authors_parsed": [["Desai", "Rathin", ""], ["Sharma", "Amit", ""]]}, {"id": "1907.04809", "submitter": "Ilyes Khemakhem", "authors": "Ilyes Khemakhem, Diederik P. Kingma, Ricardo Pio Monti, Aapo\n  Hyv\\\"arinen", "title": "Variational Autoencoders and Nonlinear ICA: A Unifying Framework", "comments": "Accepted for publication at AISTATS 2020. This is a slightly updated\n  version of the published manuscript; see Corrigendum at the end of the paper", "journal-ref": "Proceedings of the Twenty Third International Conference on\n  Artificial Intelligence and Statistics, pages 2207-2217, year 2020", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The framework of variational autoencoders allows us to efficiently learn deep\nlatent-variable models, such that the model's marginal distribution over\nobserved variables fits the data. Often, we're interested in going a step\nfurther, and want to approximate the true joint distribution over observed and\nlatent variables, including the true prior and posterior distributions over\nlatent variables. This is known to be generally impossible due to\nunidentifiability of the model. We address this issue by showing that for a\nbroad family of deep latent-variable models, identification of the true joint\ndistribution over observed and latent variables is actually possible up to very\nsimple transformations, thus achieving a principled and powerful form of\ndisentanglement. Our result requires a factorized prior distribution over the\nlatent variables that is conditioned on an additionally observed variable, such\nas a class label or almost any other observation. We build on recent\ndevelopments in nonlinear ICA, which we extend to the case with noisy,\nundercomplete or discrete observations, integrated in a maximum likelihood\nframework. The result also trivially contains identifiable flow-based\ngenerative models as a special case.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jul 2019 16:08:32 GMT"}, {"version": "v2", "created": "Wed, 9 Oct 2019 09:50:03 GMT"}, {"version": "v3", "created": "Wed, 26 Feb 2020 13:49:16 GMT"}, {"version": "v4", "created": "Mon, 21 Dec 2020 10:20:53 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Khemakhem", "Ilyes", ""], ["Kingma", "Diederik P.", ""], ["Monti", "Ricardo Pio", ""], ["Hyv\u00e4rinen", "Aapo", ""]]}, {"id": "1907.04831", "submitter": "Muhammad R. A. Khandaker PhD", "authors": "Tian-Hao Li, Muhammad R. A. Khandaker, Faisal Tariq, Kai-Kit Wong and\n  Risala T. Khan", "title": "Learning the Wireless V2I Channels Using Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.IT cs.LG math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For high data rate wireless communication systems, developing an efficient\nchannel estimation approach is extremely vital for channel detection and signal\nrecovery. With the trend of high-mobility wireless communications between\nvehicles and vehicles-to-infrastructure (V2I), V2I communications pose\nadditional challenges to obtaining real-time channel measurements. Deep\nlearning (DL) techniques, in this context, offer learning ability and\noptimization capability that can approximate many kinds of functions. In this\npaper, we develop a DL-based channel prediction method to estimate channel\nresponses for V2I communications. We have demonstrated how fast neural networks\ncan learn V2I channel properties and the changing trend. The network is trained\nwith a series of channel responses and known pilots, which then speculates the\nnext channel response based on the acquired knowledge. The predicted channel is\nthen used to evaluate the system performance.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jul 2019 17:24:45 GMT"}], "update_date": "2019-07-11", "authors_parsed": [["Li", "Tian-Hao", ""], ["Khandaker", "Muhammad R. A.", ""], ["Tariq", "Faisal", ""], ["Wong", "Kai-Kit", ""], ["Khan", "Risala T.", ""]]}, {"id": "1907.04840", "submitter": "Tim Dettmers", "authors": "Tim Dettmers, Luke Zettlemoyer", "title": "Sparse Networks from Scratch: Faster Training without Losing Performance", "comments": "9 page NeurIPS 2019 submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We demonstrate the possibility of what we call sparse learning: accelerated\ntraining of deep neural networks that maintain sparse weights throughout\ntraining while achieving dense performance levels. We accomplish this by\ndeveloping sparse momentum, an algorithm which uses exponentially smoothed\ngradients (momentum) to identify layers and weights which reduce the error\nefficiently. Sparse momentum redistributes pruned weights across layers\naccording to the mean momentum magnitude of each layer. Within a layer, sparse\nmomentum grows weights according to the momentum magnitude of zero-valued\nweights. We demonstrate state-of-the-art sparse performance on MNIST, CIFAR-10,\nand ImageNet, decreasing the mean error by a relative 8%, 15%, and 6% compared\nto other sparse algorithms. Furthermore, we show that sparse momentum reliably\nreproduces dense performance levels while providing up to 5.61x faster\ntraining. In our analysis, ablations show that the benefits of momentum\nredistribution and growth increase with the depth and size of the network.\nAdditionally, we find that sparse momentum is insensitive to the choice of its\nhyperparameters suggesting that sparse momentum is robust and easy to use.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jul 2019 17:40:20 GMT"}, {"version": "v2", "created": "Fri, 23 Aug 2019 18:30:16 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["Dettmers", "Tim", ""], ["Zettlemoyer", "Luke", ""]]}, {"id": "1907.04846", "submitter": "Alina Oprea", "authors": "Talha Ongun, Timothy Sakharaov, Simona Boboila, Alina Oprea, and Tina\n  Eliassi-Rad", "title": "On Designing Machine Learning Models for Malicious Network Traffic\n  Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning (ML) started to become widely deployed in cyber security\nsettings for shortening the detection cycle of cyber attacks. To date, most\nML-based systems are either proprietary or make specific choices of feature\nrepresentations and machine learning models. The success of these techniques is\ndifficult to assess as public benchmark datasets are currently unavailable. In\nthis paper, we provide concrete guidelines and recommendations for using\nsupervised ML in cyber security. As a case study, we consider the problem of\nbotnet detection from network traffic data. Among our findings we highlight\nthat: (1) feature representations should take into consideration attack\ncharacteristics; (2) ensemble models are well-suited to handle class imbalance;\n(3) the granularity of ground truth plays an important role in the success of\nthese methods.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jul 2019 17:50:34 GMT"}], "update_date": "2019-07-11", "authors_parsed": [["Ongun", "Talha", ""], ["Sakharaov", "Timothy", ""], ["Boboila", "Simona", ""], ["Oprea", "Alina", ""], ["Eliassi-Rad", "Tina", ""]]}, {"id": "1907.04868", "submitter": "Chris Donahue", "authors": "Chris Donahue, Huanru Henry Mao, Yiting Ethan Li, Garrison W.\n  Cottrell, Julian McAuley", "title": "LakhNES: Improving multi-instrumental music generation with cross-domain\n  pre-training", "comments": "Published as a conference paper at ISMIR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG cs.MM eess.AS stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We are interested in the task of generating multi-instrumental music scores.\nThe Transformer architecture has recently shown great promise for the task of\npiano score generation; here we adapt it to the multi-instrumental setting.\nTransformers are complex, high-dimensional language models which are capable of\ncapturing long-term structure in sequence data, but require large amounts of\ndata to fit. Their success on piano score generation is partially explained by\nthe large volumes of symbolic data readily available for that domain. We\nleverage the recently-introduced NES-MDB dataset of four-instrument scores from\nan early video game sound synthesis chip (the NES), which we find to be\nwell-suited to training with the Transformer architecture. To further improve\nthe performance of our model, we propose a pre-training technique to leverage\nthe information in a large collection of heterogeneous music, namely the Lakh\nMIDI dataset. Despite differences between the two corpora, we find that this\ntransfer learning procedure improves both quantitative and qualitative\nperformance for our primary task.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jul 2019 18:00:04 GMT"}], "update_date": "2019-07-12", "authors_parsed": [["Donahue", "Chris", ""], ["Mao", "Huanru Henry", ""], ["Li", "Yiting Ethan", ""], ["Cottrell", "Garrison W.", ""], ["McAuley", "Julian", ""]]}, {"id": "1907.04882", "submitter": "Xiaodong Cui", "authors": "Xiaodong Cui and Michael Picheny", "title": "Acoustic Model Optimization Based On Evolutionary Stochastic Gradient\n  Descent with Anchors for Automatic Speech Recognition", "comments": "Interspeech 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Evolutionary stochastic gradient descent (ESGD) was proposed as a\npopulation-based approach that combines the merits of gradient-aware and\ngradient-free optimization algorithms for superior overall optimization\nperformance. In this paper we investigate a variant of ESGD for optimization of\nacoustic models for automatic speech recognition (ASR). In this variant, we\nassume the existence of a well-trained acoustic model and use it as an anchor\nin the parent population whose good \"gene\" will propagate in the evolution to\nthe offsprings. We propose an ESGD algorithm leveraging the anchor models such\nthat it guarantees the best fitness of the population will never degrade from\nthe anchor model. Experiments on 50-hour Broadcast News (BN50) and 300-hour\nSwitchboard (SWB300) show that the ESGD with anchors can further improve the\nloss and ASR performance over the existing well-trained acoustic models.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jul 2019 18:38:44 GMT"}], "update_date": "2019-07-12", "authors_parsed": [["Cui", "Xiaodong", ""], ["Picheny", "Michael", ""]]}, {"id": "1907.04884", "submitter": "Ronny Lempel", "authors": "David Abensur, Ivan Balashov, Shaked Bar, Ronny Lempel, Nurit\n  Moscovici, Ilan Orlov, Danny Rosenstein, Ido Tamir", "title": "Productization Challenges of Contextual Multi-Armed Bandits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Contextual Multi-Armed Bandits is a well-known and accepted online\noptimization algorithm, that is used in many Web experiences to tailor content\nor presentation to users' traffic. Much has been published on theoretical\nguarantees (e.g. regret bounds) of proposed algorithmic variants, but\nrelatively little attention has been devoted to the challenges encountered\nwhile productizing contextual bandits schemes in large scale settings. This\nwork enumerates several productization challenges we encountered while\nleveraging contextual bandits for two concrete use cases at scale. We discuss\nhow to (1) determine the context (engineer the features) that model the bandit\narms; (2) sanity check the health of the optimization process; (3) evaluate the\nprocess in an offline manner; (4) add potential actions (arms) on the fly to a\nrunning process; (5) subject the decision process to constraints; and (6)\niteratively improve the online learning algorithm. For each such challenge, we\nexplain the issue, provide our approach, and relate to prior art where\napplicable.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jul 2019 18:45:40 GMT"}], "update_date": "2019-07-12", "authors_parsed": [["Abensur", "David", ""], ["Balashov", "Ivan", ""], ["Bar", "Shaked", ""], ["Lempel", "Ronny", ""], ["Moscovici", "Nurit", ""], ["Orlov", "Ilan", ""], ["Rosenstein", "Danny", ""], ["Tamir", "Ido", ""]]}, {"id": "1907.04895", "submitter": "Hrushikesh Mhaskar", "authors": "H. N. Mhaskar", "title": "Super-resolution meets machine learning: approximation of measures", "comments": "14 pages, To appear in Journal of Fourier Analysis and Applications", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.FA cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of super-resolution in general terms is to recuperate a finitely\nsupported measure $\\mu$ given finitely many of its coefficients $\\hat{\\mu}(k)$\nwith respect to some orthonormal system. The interesting case concerns\nsituations, where the number of coefficients required is substantially smaller\nthan a power of the reciprocal of the minimal separation among the points in\nthe support of $\\mu$. In this paper, we consider the more severe problem of\nrecuperating $\\mu$ approximately without any assumption on $\\mu$ beyond having\na finite total variation. In particular, $\\mu$ may be supported on a continuum,\nso that the minimal separation among the points in the support of $\\mu$ is $0$.\nA variant of this problem is also of interest in machine learning as well as\nthe inverse problem of de-convolution. We define an appropriate notion of a\ndistance between the target measure and its recuperated version, give an\nexplicit expression for the recuperation operator, and estimate the distance\nbetween $\\mu$ and its approximation. We show that these estimates are the best\npossible in many different ways. We also explain why for a finitely supported\nmeasure the approximation quality of its recuperation is bounded from below if\nthe amount of information is smaller than what is demanded in the\nsuper-resolution problem.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jul 2019 19:15:24 GMT"}], "update_date": "2019-07-12", "authors_parsed": [["Mhaskar", "H. N.", ""]]}, {"id": "1907.04902", "submitter": "Markus Kaiser", "authors": "Markus Kaiser, Clemens Otte, Thomas Runkler, Carl Henrik Ek", "title": "Interpretable Dynamics Models for Data-Efficient Reinforcement Learning", "comments": "ESANN 2019 proceedings, European Symposium on Artificial Neural\n  Networks, Computational Intelligence and Machine Learning. Bruges (Belgium),\n  24-26 April 2019, i6doc.com publ., ISBN 978-287-587-065-0", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a Bayesian view on model-based reinforcement\nlearning. We use expert knowledge to impose structure on the transition model\nand present an efficient learning scheme based on variational inference. This\nscheme is applied to a heteroskedastic and bimodal benchmark problem on which\nwe compare our results to NFQ and show how our approach yields\nhuman-interpretable insight about the underlying dynamics while also increasing\ndata-efficiency.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jul 2019 19:50:45 GMT"}], "update_date": "2019-07-12", "authors_parsed": [["Kaiser", "Markus", ""], ["Otte", "Clemens", ""], ["Runkler", "Thomas", ""], ["Ek", "Carl Henrik", ""]]}, {"id": "1907.04905", "submitter": "Rogerio Bonatti", "authors": "Rogerio Bonatti and Arthur Gola de Paula", "title": "Development of email classifier in Brazilian Portuguese using feature\n  selection for automatic response", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic email categorization is an important application of text\nclassification. We study the automatic reply of email business messages in\nBrazilian Portuguese. We present a novel corpus containing messages from a real\napplication, and baseline categorization experiments using Naive Bayes and\nsupport Vector Machines. We then discuss the effect of lemmatization and the\nrole of part-of-speech tagging filtering on precision and recall. Support\nVector Machines classification coupled with nonlemmatized selection of verbs,\nnouns and adjectives was the best approach, with 87.3% maximum accuracy.\nStraightforward lemmatization in Portuguese led to the lowest classification\nresults in the group, with 85.3% and 81.7% precision in SVM and Naive Bayes\nrespectively. Thus, while lemmatization reduced precision and recall,\npart-of-speech filtering improved overall results.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jul 2019 03:24:53 GMT"}], "update_date": "2019-07-12", "authors_parsed": [["Bonatti", "Rogerio", ""], ["de Paula", "Arthur Gola", ""]]}, {"id": "1907.04907", "submitter": "Adji Bousso Dieng", "authors": "Adji B. Dieng, Francisco J. R. Ruiz, and David M. Blei", "title": "Topic Modeling in Embedding Spaces", "comments": "Code can be found at https://github.com/adjidieng/ETM", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Topic modeling analyzes documents to learn meaningful patterns of words.\nHowever, existing topic models fail to learn interpretable topics when working\nwith large and heavy-tailed vocabularies. To this end, we develop the Embedded\nTopic Model (ETM), a generative model of documents that marries traditional\ntopic models with word embeddings. In particular, it models each word with a\ncategorical distribution whose natural parameter is the inner product between a\nword embedding and an embedding of its assigned topic. To fit the ETM, we\ndevelop an efficient amortized variational inference algorithm. The ETM\ndiscovers interpretable topics even with large vocabularies that include rare\nwords and stop words. It outperforms existing document models, such as latent\nDirichlet allocation (LDA), in terms of both topic quality and predictive\nperformance.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jul 2019 03:50:57 GMT"}], "update_date": "2019-07-12", "authors_parsed": [["Dieng", "Adji B.", ""], ["Ruiz", "Francisco J. R.", ""], ["Blei", "David M.", ""]]}, {"id": "1907.04911", "submitter": "Michaela Mila", "authors": "Michaela Hardt, Alvin Rajkomar, Gerardo Flores, Andrew Dai, Michael\n  Howell, Greg Corrado, Claire Cui and Moritz Hardt", "title": "Explaining an increase in predicted risk for clinical alerts", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Much work aims to explain a model's prediction on a static input. We consider\nexplanations in a temporal setting where a stateful dynamical model produces a\nsequence of risk estimates given an input at each time step. When the estimated\nrisk increases, the goal of the explanation is to attribute the increase to a\nfew relevant inputs from the past. While our formal setup and techniques are\ngeneral, we carry out an in-depth case study in a clinical setting. The goal\nhere is to alert a clinician when a patient's risk of deterioration rises. The\nclinician then has to decide whether to intervene and adjust the treatment.\nGiven a potentially long sequence of new events since she last saw the patient,\na concise explanation helps her to quickly triage the alert. We develop methods\nto lift static attribution techniques to the dynamical setting, where we\nidentify and address challenges specific to dynamics. We then experimentally\nassess the utility of different explanations of clinical alerts through expert\nevaluation.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jul 2019 20:26:43 GMT"}], "update_date": "2019-07-12", "authors_parsed": [["Hardt", "Michaela", ""], ["Rajkomar", "Alvin", ""], ["Flores", "Gerardo", ""], ["Dai", "Andrew", ""], ["Howell", "Michael", ""], ["Corrado", "Greg", ""], ["Cui", "Claire", ""], ["Hardt", "Moritz", ""]]}, {"id": "1907.04913", "submitter": "Amir Mosavi", "authors": "Danial Mohammadzadeh, Seyed-Farzan Kazemi, Amir Mosavi, Ehsan\n  Nasseralshariati, Joseph H. M. Tah", "title": "Prediction of Compression Index of Fine-Grained Soils Using a Gene\n  Expression Programming Model", "comments": "8 figures, 5 tables, 12 pages", "journal-ref": "Infrastructures 2019, 4, 26", "doi": "10.3390/infrastructures4020026", "report-no": null, "categories": "stat.AP cs.LG cs.NE stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In construction projects, estimation of the settlement of fine-grained soils\nis of critical importance, and yet is a challenging task. The coefficient of\nconsolidation for the compression index (Cc) is a key parameter in modeling the\nsettlement of fine-grained soil layers. However, the estimation of this\nparameter is costly, time-consuming, and requires skilled technicians. To\novercome these drawbacks, we aimed to predict Cc through other soil parameters,\ni.e., the liquid limit (LL), plastic limit (PL), and initial void ratio (e0).\nUsing these parameters is more convenient and requires substantially less time\nand cost compared to the conventional tests to estimate Cc. This study presents\na novel prediction model for the Cc of fine-grained soils using gene expression\nprogramming (GEP). A database consisting of 108 different data points was used\nto develop the model. A closed-form equation solution was derived to estimate\nCc based on LL, PL, and e0. The performance of the developed GEP-based model\nwas evaluated through the coefficient of determination (R2), the root mean\nsquared error (RMSE), and the mean average error (MAE). The proposed model\nperformed better in terms of R2, RMSE, and MAE compared to the other models.\n", "versions": [{"version": "v1", "created": "Sun, 26 May 2019 07:12:35 GMT"}], "update_date": "2019-07-12", "authors_parsed": [["Mohammadzadeh", "Danial", ""], ["Kazemi", "Seyed-Farzan", ""], ["Mosavi", "Amir", ""], ["Nasseralshariati", "Ehsan", ""], ["Tah", "Joseph H. M.", ""]]}, {"id": "1907.04916", "submitter": "Felix Weninger", "authors": "Felix Weninger, Jes\\'us Andr\\'es-Ferrer, Xinwei Li, Puming Zhan", "title": "Listen, Attend, Spell and Adapt: Speaker Adapted Sequence-to-Sequence\n  ASR", "comments": "To appear in INTERSPEECH 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sequence-to-sequence (seq2seq) based ASR systems have shown state-of-the-art\nperformances while having clear advantages in terms of simplicity. However,\ncomparisons are mostly done on speaker independent (SI) ASR systems, though\nspeaker adapted conventional systems are commonly used in practice for\nimproving robustness to speaker and environment variations. In this paper, we\napply speaker adaptation to seq2seq models with the goal of matching the\nperformance of conventional ASR adaptation. Specifically, we investigate\nKullback-Leibler divergence (KLD) as well as Linear Hidden Network (LHN) based\nadaptation for seq2seq ASR, using different amounts (up to 20 hours) of\nadaptation data per speaker. Our SI models are trained on large amounts of\ndictation data and achieve state-of-the-art results. We obtained 25% relative\nword error rate (WER) improvement with KLD adaptation of the seq2seq model vs.\n18.7% gain from acoustic model adaptation in the conventional system. We also\nshow that the WER of the seq2seq model decreases log-linearly with the amount\nof adaptation data. Finally, we analyze adaptation based on the minimum WER\ncriterion and adapting the language model (LM) for score fusion with the\nspeaker adapted seq2seq model, which result in further improvements of the\nseq2seq system performance.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jul 2019 15:09:40 GMT"}], "update_date": "2019-07-12", "authors_parsed": [["Weninger", "Felix", ""], ["Andr\u00e9s-Ferrer", "Jes\u00fas", ""], ["Li", "Xinwei", ""], ["Zhan", "Puming", ""]]}, {"id": "1907.04919", "submitter": "Stefanos Poulis", "authors": "Sanjoy Dasgupta, Stefanos Poulis, Christopher Tosh", "title": "Interactive Topic Modeling with Anchor Words", "comments": "presented at 2019 ICML Workshop on Human in the Loop Learning (HILL\n  2019), Long Beach, USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The formalism of anchor words has enabled the development of fast topic\nmodeling algorithms with provable guarantees. In this paper, we introduce a\nprotocol that allows users to interact with anchor words to build customized\nand interpretable topic models. Experimental evidence validating the usefulness\nof our approach is also presented.\n", "versions": [{"version": "v1", "created": "Tue, 18 Jun 2019 23:42:23 GMT"}], "update_date": "2019-07-12", "authors_parsed": [["Dasgupta", "Sanjoy", ""], ["Poulis", "Stefanos", ""], ["Tosh", "Christopher", ""]]}, {"id": "1907.04924", "submitter": "Xichen Ding", "authors": "Xichen Ding, Jie Tang, Tracy Liu, Cheng Xu, Yaping Zhang, Feng Shi,\n  Qixia Jiang, Dan Shen", "title": "Infer Implicit Contexts in Real-time Online-to-Offline Recommendation", "comments": "9 pages,KDD,KDD2019", "journal-ref": null, "doi": "10.1145/3292500.3330716", "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding users' context is essential for successful recommendations,\nespecially for Online-to-Offline (O2O) recommendation, such as Yelp, Groupon,\nand Koubei. Different from traditional recommendation where individual\npreference is mostly static, O2O recommendation should be dynamic to capture\nvariation of users' purposes across time and location. However, precisely\ninferring users' real-time contexts information, especially those implicit\nones, is extremely difficult, and it is a central challenge for O2O\nrecommendation. In this paper, we propose a new approach, called Mixture\nAttentional Constrained Denoise AutoEncoder (MACDAE), to infer implicit\ncontexts and consequently, to improve the quality of real-time O2O\nrecommendation. In MACDAE, we first leverage the interaction among users,\nitems, and explicit contexts to infer users' implicit contexts, then combine\nthe learned implicit-context representation into an end-to-end model to make\nthe recommendation. MACDAE works quite well in the real system. We conducted\nboth offline and online evaluations of the proposed approach. Experiments on\nseveral real-world datasets (Yelp, Dianping, and Koubei) show our approach\ncould achieve significant improvements over state-of-the-arts. Furthermore,\nonline A/B test suggests a 2.9% increase for click-through rate and 5.6%\nimprovement for conversion rate in real-world traffic. Our model has been\ndeployed in the product of \"Guess You Like\" recommendation in Koubei.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jul 2019 05:37:30 GMT"}], "update_date": "2019-07-12", "authors_parsed": [["Ding", "Xichen", ""], ["Tang", "Jie", ""], ["Liu", "Tracy", ""], ["Xu", "Cheng", ""], ["Zhang", "Yaping", ""], ["Shi", "Feng", ""], ["Jiang", "Qixia", ""], ["Shen", "Dan", ""]]}, {"id": "1907.04927", "submitter": "Archit Gupta", "authors": "Archit Gupta, Brendan Shillingford, Yannis Assael, Thomas C. Walters", "title": "Speech bandwidth extension with WaveNet", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large-scale mobile communication systems tend to contain legacy transmission\nchannels with narrowband bottlenecks, resulting in characteristic\n\"telephone-quality\" audio. While higher quality codecs exist, due to the scale\nand heterogeneity of the networks, transmitting higher sample rate audio with\nmodern high-quality audio codecs can be difficult in practice. This paper\nproposes an approach where a communication node can instead extend the\nbandwidth of a band-limited incoming speech signal that may have been passed\nthrough a low-rate codec. To this end, we propose a WaveNet-based model\nconditioned on a log-mel spectrogram representation of a bandwidth-constrained\nspeech audio signal of 8 kHz and audio with artifacts from GSM full-rate (FR)\ncompression to reconstruct the higher-resolution signal. In our experimental\nMUSHRA evaluation, we show that a model trained to upsample to 24kHz speech\nsignals from audio passed through the 8kHz GSM-FR codec is able to reconstruct\naudio only slightly lower in quality to that of the Adaptive Multi-Rate\nWideband audio codec (AMR-WB) codec at 16kHz, and closes around half the gap in\nperceptual quality between the original encoded signal and the original speech\nsampled at 24kHz. We further show that when the same model is passed 8kHz audio\nthat has not been compressed, is able to again reconstruct audio of slightly\nbetter quality than 16kHz AMR-WB, in the same MUSHRA evaluation.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jul 2019 20:17:31 GMT"}], "update_date": "2019-07-12", "authors_parsed": [["Gupta", "Archit", ""], ["Shillingford", "Brendan", ""], ["Assael", "Yannis", ""], ["Walters", "Thomas C.", ""]]}, {"id": "1907.04928", "submitter": "Alessandro Lameiras Koerich", "authors": "Mohammed Senoussaoui, Patrick Cardinal, Alessandro Lameiras Koerich", "title": "Bag-of-Audio-Words based on Autoencoder Codebook for Continuous Emotion\n  Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present a novel approach for extracting a Bag-of-Words (BoW)\nrepresentation based on a Neural Network codebook. The conventional BoW model\nis based on a dictionary (codebook) built from elementary representations which\nare selected randomly or by using a clustering algorithm on a training dataset.\nA metric is then used to assign unseen elementary representations to the\nclosest dictionary entries in order to produce a histogram. In the proposed\napproach, an autoencoder (AE) encompasses the role of both the dictionary\ncreation and the assignment metric. The dimension of the encoded layer of the\nAE corresponds to the size of the dictionary and the output of its neurons\nrepresents the assignment metric. Experimental results for the continuous\nemotion prediction task on the AVEC 2017 audio dataset have shown an\nimprovement of the Concordance Correlation Coefficient (CCC) from 0.225 to\n0.322 for arousal dimension and from 0.244 to 0.368 for valence dimension\nrelative to the conventional BoW version implemented in a baseline system.\n", "versions": [{"version": "v1", "created": "Sat, 6 Jul 2019 21:16:53 GMT"}], "update_date": "2019-07-12", "authors_parsed": [["Senoussaoui", "Mohammed", ""], ["Cardinal", "Patrick", ""], ["Koerich", "Alessandro Lameiras", ""]]}, {"id": "1907.04931", "submitter": "Hanqing Zeng", "authors": "Hanqing Zeng, Hongkuan Zhou, Ajitesh Srivastava, Rajgopal Kannan,\n  Viktor Prasanna", "title": "GraphSAINT: Graph Sampling Based Inductive Learning Method", "comments": "Published at ICLR 2020; Code release:\n  github.com/GraphSAINT/GraphSAINT", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph Convolutional Networks (GCNs) are powerful models for learning\nrepresentations of attributed graphs. To scale GCNs to large graphs,\nstate-of-the-art methods use various layer sampling techniques to alleviate the\n\"neighbor explosion\" problem during minibatch training. We propose GraphSAINT,\na graph sampling based inductive learning method that improves training\nefficiency and accuracy in a fundamentally different way. By changing\nperspective, GraphSAINT constructs minibatches by sampling the training graph,\nrather than the nodes or edges across GCN layers. Each iteration, a complete\nGCN is built from the properly sampled subgraph. Thus, we ensure fixed number\nof well-connected nodes in all layers. We further propose normalization\ntechnique to eliminate bias, and sampling algorithms for variance reduction.\nImportantly, we can decouple the sampling from the forward and backward\npropagation, and extend GraphSAINT with many architecture variants (e.g., graph\nattention, jumping connection). GraphSAINT demonstrates superior performance in\nboth accuracy and training time on five large graphs, and achieves new\nstate-of-the-art F1 scores for PPI (0.995) and Reddit (0.970).\n", "versions": [{"version": "v1", "created": "Wed, 10 Jul 2019 21:11:13 GMT"}, {"version": "v2", "created": "Sun, 29 Sep 2019 08:36:31 GMT"}, {"version": "v3", "created": "Fri, 27 Dec 2019 23:58:33 GMT"}, {"version": "v4", "created": "Sun, 16 Feb 2020 00:42:48 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Zeng", "Hanqing", ""], ["Zhou", "Hongkuan", ""], ["Srivastava", "Ajitesh", ""], ["Kannan", "Rajgopal", ""], ["Prasanna", "Viktor", ""]]}, {"id": "1907.04944", "submitter": "Nishant Subramani", "authors": "Nishant Subramani, Samuel R. Bowman, Kyunghyun Cho", "title": "Can Unconditional Language Models Recover Arbitrary Sentences?", "comments": "NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural network-based generative language models like ELMo and BERT can work\neffectively as general purpose sentence encoders in text classification without\nfurther fine-tuning. Is it possible to adapt them in a similar way for use as\ngeneral-purpose decoders? For this to be possible, it would need to be the case\nthat for any target sentence of interest, there is some continuous\nrepresentation that can be passed to the language model to cause it to\nreproduce that sentence. We set aside the difficult problem of designing an\nencoder that can produce such representations and, instead, ask directly\nwhether such representations exist at all. To do this, we introduce a pair of\neffective, complementary methods for feeding representations into pretrained\nunconditional language models and a corresponding set of methods to map\nsentences into and out of this representation space, the reparametrized\nsentence space. We then investigate the conditions under which a language model\ncan be made to generate a sentence through the identification of a point in\nsuch a space and find that it is possible to recover arbitrary sentences nearly\nperfectly with language models and representations of moderate size without\nmodifying any model parameters.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jul 2019 22:13:48 GMT"}, {"version": "v2", "created": "Thu, 9 Jan 2020 23:03:30 GMT"}], "update_date": "2020-01-13", "authors_parsed": [["Subramani", "Nishant", ""], ["Bowman", "Samuel R.", ""], ["Cho", "Kyunghyun", ""]]}, {"id": "1907.04964", "submitter": "Nicholas Charles Landolfi", "authors": "Nicholas C. Landolfi and Garrett Thomas and Tengyu Ma", "title": "A Model-based Approach for Sample-efficient Multi-task Reinforcement\n  Learning", "comments": "13 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The aim of multi-task reinforcement learning is two-fold: (1) efficiently\nlearn by training against multiple tasks and (2) quickly adapt, using limited\nsamples, to a variety of new tasks. In this work, the tasks correspond to\nreward functions for environments with the same (or similar) dynamical models.\nWe propose to learn a dynamical model during the training process and use this\nmodel to perform sample-efficient adaptation to new tasks at test time. We use\nsignificantly fewer samples by performing policy optimization only in a\n\"virtual\" environment whose transitions are given by our learned dynamical\nmodel. Our algorithm sequentially trains against several tasks. Upon\nencountering a new task, we first warm-up a policy on our learned dynamical\nmodel, which requires no new samples from the environment. We then adapt the\ndynamical model with samples from this policy in the real environment. We\nevaluate our approach on several continuous control benchmarks and demonstrate\nits efficacy over MAML, a state-of-the-art meta-learning algorithm, on these\ntasks.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jul 2019 00:45:44 GMT"}, {"version": "v2", "created": "Mon, 15 Jul 2019 05:35:35 GMT"}, {"version": "v3", "created": "Sun, 3 Nov 2019 20:30:47 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Landolfi", "Nicholas C.", ""], ["Thomas", "Garrett", ""], ["Ma", "Tengyu", ""]]}, {"id": "1907.04967", "submitter": "Ye Yuan", "authors": "Ye Yuan, Kris Kitani", "title": "Diverse Trajectory Forecasting with Determinantal Point Processes", "comments": "ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability to forecast a set of likely yet diverse possible future behaviors\nof an agent (e.g., future trajectories of a pedestrian) is essential for\nsafety-critical perception systems (e.g., autonomous vehicles). In particular,\na set of possible future behaviors generated by the system must be diverse to\naccount for all possible outcomes in order to take necessary safety\nprecautions. It is not sufficient to maintain a set of the most likely future\noutcomes because the set may only contain perturbations of a single outcome.\nWhile generative models such as variational autoencoders (VAEs) have been shown\nto be a powerful tool for learning a distribution over future trajectories,\nrandomly drawn samples from the learned implicit likelihood model may not be\ndiverse -- the likelihood model is derived from the training data distribution\nand the samples will concentrate around the major mode that has most data. In\nthis work, we propose to learn a diversity sampling function (DSF) that\ngenerates a diverse and likely set of future trajectories. The DSF maps\nforecasting context features to a set of latent codes which can be decoded by a\ngenerative model (e.g., VAE) into a set of diverse trajectory samples.\nConcretely, the process of identifying the diverse set of samples is posed as a\nparameter estimation of the DSF. To learn the parameters of the DSF, the\ndiversity of the trajectory samples is evaluated by a diversity loss based on a\ndeterminantal point process (DPP). Gradient descent is performed over the DSF\nparameters, which in turn move the latent codes of the sample set to find an\noptimal diverse and likely set of trajectories. Our method is a novel\napplication of DPPs to optimize a set of items (trajectories) in continuous\nspace. We demonstrate the diversity of the trajectories produced by our\napproach on both low-dimensional 2D trajectory data and high-dimensional human\nmotion data.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jul 2019 00:59:22 GMT"}, {"version": "v2", "created": "Mon, 23 Dec 2019 10:23:40 GMT"}], "update_date": "2019-12-24", "authors_parsed": [["Yuan", "Ye", ""], ["Kitani", "Kris", ""]]}, {"id": "1907.04980", "submitter": "Chieh-Fang Teng", "authors": "Chieh-Fang Teng, Han-Mo Ou, and An-Yeu Wu", "title": "Neural Network-based Equalizer by Utilizing Coding Gain in Advance", "comments": "5 pages, 4 figures, accepted by the 2019 Seventh IEEE Global\n  Conference on Signal and Information Processing", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, deep learning has been exploited in many fields with revolutionary\nbreakthroughs. In the light of this, deep learning-assisted communication\nsystems have also attracted much attention in recent years and have potential\nto break down the conventional design rule for communication systems. In this\nwork, we propose two kinds of neural network-based equalizers to exploit\ndifferent characteristics between convolutional neural networks and recurrent\nneural networks. The equalizer in conventional block-based design may destroy\nthe code structure and degrade the capacity of coding gain for decoder. On the\ncontrary, our proposed approach not only eliminates channel fading, but also\nexploits the code structure with utilization of coding gain in advance, which\ncan effectively increase the overall utilization of coding gain with more than\n1.5 dB gain.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jul 2019 03:14:27 GMT"}, {"version": "v2", "created": "Sat, 31 Aug 2019 06:40:20 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Teng", "Chieh-Fang", ""], ["Ou", "Han-Mo", ""], ["Wu", "An-Yeu", ""]]}, {"id": "1907.05008", "submitter": "Nima Dehmamy", "authors": "Nima Dehmamy, Albert-L\\'aszl\\'o Barab\\'asi, Rose Yu", "title": "Understanding the Representation Power of Graph Neural Networks in\n  Learning Graph Topology", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG physics.data-an stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To deepen our understanding of graph neural networks, we investigate the\nrepresentation power of Graph Convolutional Networks (GCN) through the looking\nglass of graph moments, a key property of graph topology encoding path of\nvarious lengths. We find that GCNs are rather restrictive in learning graph\nmoments. Without careful design, GCNs can fail miserably even with multiple\nlayers and nonlinear activation functions. We analyze theoretically the\nexpressiveness of GCNs, concluding a modular GCN design, using different\npropagation rules with residual connections could significantly improve the\nperformance of GCN. We demonstrate that such modular designs are capable of\ndistinguishing graphs from different graph generation models for surprisingly\nsmall graphs, a notoriously difficult problem in network science. Our\ninvestigation suggests that, depth is much more influential than width, with\ndeeper GCNs being more capable of learning higher order graph moments.\nAdditionally, combining GCN modules with different propagation rules is\ncritical to the representation power of GCNs.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jul 2019 05:59:38 GMT"}, {"version": "v2", "created": "Thu, 31 Oct 2019 20:38:40 GMT"}], "update_date": "2019-11-04", "authors_parsed": [["Dehmamy", "Nima", ""], ["Barab\u00e1si", "Albert-L\u00e1szl\u00f3", ""], ["Yu", "Rose", ""]]}, {"id": "1907.05012", "submitter": "Antonio Ginart", "authors": "Antonio Ginart, Melody Y. Guan, Gregory Valiant, James Zou", "title": "Making AI Forget You: Data Deletion in Machine Learning", "comments": "To appear in NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Intense recent discussions have focused on how to provide individuals with\ncontrol over when their data can and cannot be used --- the EU's Right To Be\nForgotten regulation is an example of this effort. In this paper we initiate a\nframework studying what to do when it is no longer permissible to deploy models\nderivative from specific user data. In particular, we formulate the problem of\nefficiently deleting individual data points from trained machine learning\nmodels. For many standard ML models, the only way to completely remove an\nindividual's data is to retrain the whole model from scratch on the remaining\ndata, which is often not computationally practical. We investigate algorithmic\nprinciples that enable efficient data deletion in ML. For the specific setting\nof k-means clustering, we propose two provably efficient deletion algorithms\nwhich achieve an average of over 100X improvement in deletion efficiency across\n6 datasets, while producing clusters of comparable statistical quality to a\ncanonical k-means++ baseline.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jul 2019 06:19:51 GMT"}, {"version": "v2", "created": "Mon, 4 Nov 2019 23:20:07 GMT"}], "update_date": "2019-11-06", "authors_parsed": [["Ginart", "Antonio", ""], ["Guan", "Melody Y.", ""], ["Valiant", "Gregory", ""], ["Zou", "James", ""]]}, {"id": "1907.05013", "submitter": "Toshio Endo", "authors": "Yuki Ito, Haruki Imai, Tung Le Duc, Yasushi Negishi, Kiyokuni\n  Kawachiya, Ryo Matsumiya, Toshio Endo", "title": "Profiling based Out-of-core Hybrid Method for Large Neural Networks", "comments": "15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  GPUs are widely used to accelerate deep learning with NNs (NNs). On the other\nhand, since GPU memory capacity is limited, it is difficult to implement\nefficient programs that compute large NNs on GPU. To compute NNs exceeding GPU\nmemory capacity, data-swapping method and recomputing method have been proposed\nin existing work. However, in these methods, performance overhead occurs due to\ndata movement or increase of computation. In order to reduce the overhead, it\nis important to consider characteristics of each layer such as sizes and cost\nfor recomputation. Based on this direction, we proposed Profiling based\nout-of-core Hybrid method (PoocH). PoocH determines target layers of swapping\nor recomputing based on runtime profiling. We implemented PoocH by extending a\ndeep learning framework, Chainer, and we evaluated its performance. With PoocH,\nwe successfully computed an NN requiring 50 GB memory on a single GPU with 16\nGB memory. Compared with in-core cases, performance degradation was 38 \\% on\nx86 machine and 28 \\% on POWER9 machine.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jul 2019 06:31:38 GMT"}], "update_date": "2019-07-12", "authors_parsed": [["Ito", "Yuki", ""], ["Imai", "Haruki", ""], ["Duc", "Tung Le", ""], ["Negishi", "Yasushi", ""], ["Kawachiya", "Kiyokuni", ""], ["Matsumiya", "Ryo", ""], ["Endo", "Toshio", ""]]}, {"id": "1907.05019", "submitter": "Orhan Firat", "authors": "Naveen Arivazhagan, Ankur Bapna, Orhan Firat, Dmitry Lepikhin, Melvin\n  Johnson, Maxim Krikun, Mia Xu Chen, Yuan Cao, George Foster, Colin Cherry,\n  Wolfgang Macherey, Zhifeng Chen, Yonghui Wu", "title": "Massively Multilingual Neural Machine Translation in the Wild: Findings\n  and Challenges", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce our efforts towards building a universal neural machine\ntranslation (NMT) system capable of translating between any language pair. We\nset a milestone towards this goal by building a single massively multilingual\nNMT model handling 103 languages trained on over 25 billion examples. Our\nsystem demonstrates effective transfer learning ability, significantly\nimproving translation quality of low-resource languages, while keeping\nhigh-resource language translation quality on-par with competitive bilingual\nbaselines. We provide in-depth analysis of various aspects of model building\nthat are crucial to achieving quality and practicality in universal NMT. While\nwe prototype a high-quality universal translation system, our extensive\nempirical analysis exposes issues that need to be further addressed, and we\nsuggest directions for future research.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jul 2019 06:47:30 GMT"}], "update_date": "2019-07-12", "authors_parsed": [["Arivazhagan", "Naveen", ""], ["Bapna", "Ankur", ""], ["Firat", "Orhan", ""], ["Lepikhin", "Dmitry", ""], ["Johnson", "Melvin", ""], ["Krikun", "Maxim", ""], ["Chen", "Mia Xu", ""], ["Cao", "Yuan", ""], ["Foster", "George", ""], ["Cherry", "Colin", ""], ["Macherey", "Wolfgang", ""], ["Chen", "Zhifeng", ""], ["Wu", "Yonghui", ""]]}, {"id": "1907.05079", "submitter": "Kimia Nadjahi", "authors": "Kimia Nadjahi, Romain Laroche, R\\'emi Tachet des Combes", "title": "Safe Policy Improvement with Soft Baseline Bootstrapping", "comments": "Accepted paper at ECML-PKDD2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Batch Reinforcement Learning (Batch RL) consists in training a policy using\ntrajectories collected with another policy, called the behavioural policy. Safe\npolicy improvement (SPI) provides guarantees with high probability that the\ntrained policy performs better than the behavioural policy, also called\nbaseline in this setting. Previous work shows that the SPI objective improves\nmean performance as compared to using the basic RL objective, which boils down\nto solving the MDP with maximum likelihood. Here, we build on that work and\nimprove more precisely the SPI with Baseline Bootstrapping algorithm (SPIBB) by\nallowing the policy search over a wider set of policies. Instead of binarily\nclassifying the state-action pairs into two sets (the \\textit{uncertain} and\nthe \\textit{safe-to-train-on} ones), we adopt a softer strategy that controls\nthe error in the value estimates by constraining the policy change according to\nthe local model uncertainty. The method can take more risks on uncertain\nactions all the while remaining provably-safe, and is therefore less\nconservative than the state-of-the-art methods. We propose two algorithms (one\noptimal and one approximate) to solve this constrained optimization problem and\nempirically show a significant improvement over existing SPI algorithms both on\nfinite MDPs and on infinite MDPs with a neural network function approximation.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jul 2019 09:59:10 GMT"}], "update_date": "2019-07-12", "authors_parsed": [["Nadjahi", "Kimia", ""], ["Laroche", "Romain", ""], ["Combes", "R\u00e9mi Tachet des", ""]]}, {"id": "1907.05092", "submitter": "Shizhe Chen", "authors": "Shizhe Chen, Yuqing Song, Yida Zhao, Qin Jin, Zhaoyang Zeng, Bei Liu,\n  Jianlong Fu, and Alexander Hauptmann", "title": "Activitynet 2019 Task 3: Exploring Contexts for Dense Captioning Events\n  in Videos", "comments": "Winner solution in CVPR 2019 Activitynet Dense Video Captioning\n  challenge", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Contextual reasoning is essential to understand events in long untrimmed\nvideos. In this work, we systematically explore different captioning models\nwith various contexts for the dense-captioning events in video task, which aims\nto generate captions for different events in the untrimmed video. We propose\nfive types of contexts as well as two categories of event captioning models,\nand evaluate their contributions for event captioning from both accuracy and\ndiversity aspects. The proposed captioning models are plugged into our pipeline\nsystem for the dense video captioning challenge. The overall system achieves\nthe state-of-the-art performance on the dense-captioning events in video task\nwith 9.91 METEOR score on the challenge testing set.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jul 2019 10:29:04 GMT"}], "update_date": "2019-07-12", "authors_parsed": [["Chen", "Shizhe", ""], ["Song", "Yuqing", ""], ["Zhao", "Yida", ""], ["Jin", "Qin", ""], ["Zeng", "Zhaoyang", ""], ["Liu", "Bei", ""], ["Fu", "Jianlong", ""], ["Hauptmann", "Alexander", ""]]}, {"id": "1907.05094", "submitter": "Melanie Schmidt", "authors": "Anna Gro{\\ss}wendt, Heiko R\\\"oglin, Melanie Schmidt", "title": "Analysis of Ward's Method", "comments": "appeared at SODA 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CG cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study Ward's method for the hierarchical $k$-means problem. This popular\ngreedy heuristic is based on the \\emph{complete linkage} paradigm: Starting\nwith all data points as singleton clusters, it successively merges two clusters\nto form a clustering with one cluster less. The pair of clusters is chosen to\n(locally) minimize the $k$-means cost of the clustering in the next step.\n  Complete linkage algorithms are very popular for hierarchical clustering\nproblems, yet their theoretical properties have been studied relatively little.\nFor the Euclidean $k$-center problem, Ackermann et al. show that the\n$k$-clustering in the hierarchy computed by complete linkage has a worst-case\napproximation ratio of $\\Theta(\\log k)$. If the data lies in $\\mathbb{R}^d$ for\nconstant dimension $d$, the guarantee improves to $\\mathcal{O}(1)$, but the\n$\\mathcal{O}$-notation hides a linear dependence on $d$. Complete linkage for\n$k$-median or $k$-means has not been analyzed so far.\n  In this paper, we show that Ward's method computes a $2$-approximation with\nrespect to the $k$-means objective function if the optimal $k$-clustering is\nwell separated. If additionally the optimal clustering also satisfies a balance\ncondition, then Ward's method fully recovers the optimum solution. These\nresults hold in arbitrary dimension. We accompany our positive results with a\nlower bound of $\\Omega((3/2)^d)$ for data sets in $\\mathbb{R}^d$ that holds if\nno separation is guaranteed, and with lower bounds when the guaranteed\nseparation is not sufficiently strong. Finally, we show that Ward produces an\n$\\mathcal{O}(1)$-approximative clustering for one-dimensional data sets.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jul 2019 10:35:03 GMT"}], "update_date": "2019-07-12", "authors_parsed": [["Gro\u00dfwendt", "Anna", ""], ["R\u00f6glin", "Heiko", ""], ["Schmidt", "Melanie", ""]]}, {"id": "1907.05103", "submitter": "Przemys{\\l}aw Sadowski", "authors": "Przemys{\\l}aw Sadowski", "title": "Machine Learning Kernel Method from a Quantum Generative Model", "comments": "14 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently the use of Noisy Intermediate Scale Quantum (NISQ) devices for\nmachine learning tasks has been proposed. The propositions often perform poorly\ndue to various restrictions. However, the quantum devices should perform well\nin sampling tasks. Thus, we recall theory of sampling-based approach to machine\nlearning and propose a quantum sampling based classifier. Namely, we use\nrandomized feature map approach. We propose a method of quantum sampling based\non random quantum circuits with parametrized rotations distribution. We obtain\nsimple to use method with intuitive hyper-parameters that performs at least\nequally well as top out-of-the-box classical methods. In short we obtain a\ncompetitive quantum classifier with crucial component being quantum sampling --\na promising task for quantum supremacy.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jul 2019 10:59:30 GMT"}], "update_date": "2019-07-12", "authors_parsed": [["Sadowski", "Przemys\u0142aw", ""]]}, {"id": "1907.05106", "submitter": "Alessandro Betti", "authors": "Alessandro Betti, Marco Gori", "title": "Spatiotemporal Local Propagation", "comments": "9 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes an in-depth re-thinking of neural computation that\nparallels apparently unrelated laws of physics, that are formulated in the\nvariational framework of the least action principle. The theory holds for\nneural networks that are also based on any digraph, and the resulting\ncomputational scheme exhibits the intriguing property of being truly\nbiologically plausible. The scheme, which is referred to as SpatioTemporal\nLocal Propagation (STLP), is local in both space and time. Space locality comes\nfrom the expression of the network connections by an appropriate Lagrangian\nterm, so as the corresponding computational scheme does not need the\nbackpropagation (BP) of the error, while temporal locality is the outcome of\nthe variational formulation of the problem. Overall, in addition to conquering\nthe often invoked biological plausibility missed by BP, the locality in both\nspace and time that arises from the proposed theory can neither be exhibited by\nBackpropagation Through Time (BPTT) nor by Real-Time Recurrent Learning (RTRL).\n", "versions": [{"version": "v1", "created": "Thu, 11 Jul 2019 11:03:09 GMT"}], "update_date": "2019-07-12", "authors_parsed": [["Betti", "Alessandro", ""], ["Gori", "Marco", ""]]}, {"id": "1907.05127", "submitter": "Weiming Zhi", "authors": "Weiming Zhi, Lionel Ott, Fabio Ramos", "title": "Kernel Trajectory Maps for Multi-Modal Probabilistic Motion Prediction", "comments": "To appear in Conference on Robot Learning 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Understanding the dynamics of an environment, such as the movement of humans\nand vehicles, is crucial for agents to achieve long-term autonomy in urban\nenvironments. This requires the development of methods to capture the\nmulti-modal and probabilistic nature of motion patterns. We present Kernel\nTrajectory Maps (KTM) to capture the trajectories of movement in an\nenvironment. KTMs leverage the expressiveness of kernels from non-parametric\nmodelling by projecting input trajectories onto a set of representative\ntrajectories, to condition on a sequence of observed waypoint coordinates, and\npredict a multi-modal distribution over possible future trajectories. The\noutput is a mixture of continuous stochastic processes, where each realisation\nis a continuous functional trajectory, which can be queried at arbitrarily fine\ntime steps.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jul 2019 11:56:44 GMT"}, {"version": "v2", "created": "Mon, 7 Oct 2019 13:09:59 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Zhi", "Weiming", ""], ["Ott", "Lionel", ""], ["Ramos", "Fabio", ""]]}, {"id": "1907.05131", "submitter": "Christoph Kinkeldey", "authors": "Christoph Kinkeldey, Claudia M\\\"uller-Birn, Tom G\\\"ulenman, Jesse\n  Josua Benjamin and Aaron Halfaker", "title": "PreCall: A Visual Interface for Threshold Optimization in ML Model\n  Selection", "comments": "HCML Perspectives Workshop at CHI 2019, May 04, 2019, Glasgow", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning systems are ubiquitous in various kinds of digital\napplications and have a huge impact on our everyday life. But a lack of\nexplainability and interpretability of such systems hinders meaningful\nparticipation by people, especially by those without a technical background.\nInteractive visual interfaces (e.g., providing means for manipulating\nparameters in the user interface) can help tackle this challenge. In this paper\nwe present PreCall, an interactive visual interface for ORES, a machine\nlearning-based web service for Wikimedia projects such as Wikipedia. While ORES\ncan be used for a number of settings, it can be challenging to translate\nrequirements from the application domain into formal parameter sets needed to\nconfigure the ORES models. Assisting Wikipedia editors in finding damaging\nedits, for example, can be realized at various stages of automatization, which\nmight impact the precision of the applied model. Our prototype PreCall attempts\nto close this translation gap by interactively visualizing the relationship\nbetween major model metrics (recall, precision, false positive rate) and a\nparameter (the threshold between valuable and damaging edits). Furthermore,\nPreCall visualizes the probable results for the current model configuration to\nimprove the human's understanding of the relationship between metrics and\noutcome when using ORES. We describe PreCall's components and present a use\ncase that highlights the benefits of our approach. Finally, we pose further\nresearch questions we would like to discuss during the workshop.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jul 2019 12:03:57 GMT"}], "update_date": "2019-07-12", "authors_parsed": [["Kinkeldey", "Christoph", ""], ["M\u00fcller-Birn", "Claudia", ""], ["G\u00fclenman", "Tom", ""], ["Benjamin", "Jesse Josua", ""], ["Halfaker", "Aaron", ""]]}, {"id": "1907.05143", "submitter": "Melanie Lubrano", "authors": "Melanie Lubrano di Scandalea, Christian S. Perone, Mathieu Boudreau,\n  Julien Cohen-Adad", "title": "Deep Active Learning for Axon-Myelin Segmentation on Histology Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semantic segmentation is a crucial task in biomedical image processing, which\nrecent breakthroughs in deep learning have allowed to improve. However, deep\nlearning methods in general are not yet widely used in practice since they\nrequire large amount of data for training complex models. This is particularly\nchallenging for biomedical images, because data and ground truths are a scarce\nresource. Annotation efforts for biomedical images come with a real cost, since\nexperts have to manually label images at pixel-level on samples usually\ncontaining many instances of the target anatomy (e.g. in histology samples:\nneurons, astrocytes, mitochondria, etc.). In this paper we provide a framework\nfor Deep Active Learning applied to a real-world scenario. Our framework relies\non the U-Net architecture and overall uncertainty measure to suggest which\nsample to annotate. It takes advantage of the uncertainty measure obtained by\ntaking Monte Carlo samples while using Dropout regularization scheme.\nExperiments were done on spinal cord and brain microscopic histology samples to\nperform a myelin segmentation task. Two realistic small datasets of 14 and 24\nimages were used, from different acquisition settings (Serial Block-Face\nElectron Microscopy and Transmitting Electron Microscopy) and showed that our\nmethod reached a maximum Dice value after adding 3 uncertainty-selected samples\nto the initial training set, versus 15 randomly-selected samples, thereby\nsignificantly reducing the annotation effort. We focused on a plausible\nscenario and showed evidence that this straightforward implementation achieves\na high segmentation performance with very few labelled samples. We believe our\nframework may benefit any biomedical researcher willing to obtain fast and\naccurate image segmentation on their own dataset. The code is freely available\nat https://github.com/neuropoly/deep-active-learning.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jul 2019 12:31:30 GMT"}], "update_date": "2019-07-12", "authors_parsed": [["di Scandalea", "Melanie Lubrano", ""], ["Perone", "Christian S.", ""], ["Boudreau", "Mathieu", ""], ["Cohen-Adad", "Julien", ""]]}, {"id": "1907.05146", "submitter": "Mathias Kraus", "authors": "Mathias Kraus and Stefan Feuerriegel", "title": "Forecasting remaining useful life: Interpretable deep learning approach\n  via variational Bayesian inferences", "comments": null, "journal-ref": null, "doi": "10.1016/j.dss.2019.113100", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predicting the remaining useful life of machinery, infrastructure, or other\nequipment can facilitate preemptive maintenance decisions, whereby a failure is\nprevented through timely repair or replacement. This allows for a better\ndecision support by considering the anticipated time-to-failure and thus\npromises to reduce costs. Here a common baseline may be derived by fitting a\nprobability density function to past lifetimes and then utilizing the\n(conditional) expected remaining useful life as a prognostic. This approach\nfinds widespread use in practice because of its high explanatory power. A more\naccurate alternative is promised by machine learning, where forecasts\nincorporate deterioration processes and environmental variables through sensor\ndata. However, machine learning largely functions as a black-box method and its\nforecasts thus forfeit most of the desired interpretability. As our primary\ncontribution, we propose a structured-effect neural network for predicting the\nremaining useful life which combines the favorable properties of both\napproaches: its key innovation is that it offers both a high accountability and\nthe flexibility of deep learning. The parameters are estimated via variational\nBayesian inferences. The different approaches are compared based on the actual\ntime-to-failure for aircraft engines. This demonstrates the performance and\nsuperior interpretability of our method, while we finally discuss implications\nfor decision support.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jul 2019 12:33:45 GMT"}, {"version": "v2", "created": "Fri, 19 Jul 2019 14:46:08 GMT"}], "update_date": "2019-07-22", "authors_parsed": [["Kraus", "Mathias", ""], ["Feuerriegel", "Stefan", ""]]}, {"id": "1907.05156", "submitter": "Sai Praneeth Karimireddy", "authors": "Elo\\\"ise Berthier and Sai Praneeth Karimireddy", "title": "Amplifying R\\'enyi Differential Privacy via Shuffling", "comments": "This version has incorrect proofs! We are currently working on fixing\n  these", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Differential privacy is a useful tool to build machine learning models which\ndo not release too much information about the training data. We study the\nR\\'enyi differential privacy of stochastic gradient descent when each training\nexample is sampled without replacement (also known as cyclic SGD). Cyclic SGD\nis typically faster than traditional SGD and is the algorithm of choice in\nlarge-scale implementations. We recover privacy guarantees for cyclic SGD which\nare competitive with those known for sampling with replacement. Our proof\ntechniques make no assumptions on the model or on the data and are hence widely\napplicable.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jul 2019 12:44:27 GMT"}, {"version": "v2", "created": "Fri, 26 Jul 2019 14:56:19 GMT"}, {"version": "v3", "created": "Mon, 17 Feb 2020 13:29:15 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Berthier", "Elo\u00efse", ""], ["Karimireddy", "Sai Praneeth", ""]]}, {"id": "1907.05159", "submitter": "Marcus Hutter", "authors": "Marcus Hutter", "title": "Fairness without Regret", "comments": "11 pages, 2 figures, 1 table, keywords: utility, objective, optimal,\n  fair/equitable/just, cost/regret, uncertainty", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A popular approach of achieving fairness in optimization problems is by\nconstraining the solution space to \"fair\" solutions, which unfortunately\ntypically reduces solution quality. In practice, the ultimate goal is often an\naggregate of sub-goals without a unique or best way of combining them or which\nis otherwise only partially known. I turn this problem into a feature and\nsuggest to use a parametrized objective and vary the parameters within\nreasonable ranges to get a \"set\" of optimal solutions, which can then be\noptimized using secondary criteria such as fairness without compromising the\nprimary objective, i.e. without regret (societal cost).\n", "versions": [{"version": "v1", "created": "Thu, 11 Jul 2019 12:49:27 GMT"}], "update_date": "2019-07-12", "authors_parsed": [["Hutter", "Marcus", ""]]}, {"id": "1907.05164", "submitter": "Mark Graham", "authors": "Kanwal K. Bhatia, Mark S. Graham, Louise Terry, Ashley Wood, Paris\n  Tranos, Sameer Trikha, Nicolas Jaccard", "title": "Disease classification of macular Optical Coherence Tomography scans\n  using deep learning software: validation on independent, multi-centre data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Purpose: To evaluate Pegasus-OCT, a clinical decision support software for\nthe identification of features of retinal disease from macula OCT scans, across\nheterogenous populations involving varying patient demographics, device\nmanufacturers, acquisition sites and operators.\n  Methods: 5,588 normal and anomalous macular OCT volumes (162,721 B-scans),\nacquired at independent centres in five countries, were processed using the\nsoftware. Results were evaluated against ground truth provided by the dataset\nowners.\n  Results: Pegasus-OCT performed with AUROCs of at least 98% for all datasets\nin the detection of general macular anomalies. For scans of sufficient quality,\nthe AUROCs for general AMD and DME detection were found to be at least 99% and\n98%, respectively.\n  Conclusions: The ability of a clinical decision support system to cater for\ndifferent populations is key to its adoption. Pegasus-OCT was shown to be able\nto detect AMD, DME and general anomalies in OCT volumes acquired across\nmultiple independent sites with high performance. Its use thus offers\nsubstantial promise, with the potential to alleviate the burden of growing\ndemand in eye care services caused by retinal disease.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jul 2019 12:53:17 GMT"}], "update_date": "2019-07-12", "authors_parsed": [["Bhatia", "Kanwal K.", ""], ["Graham", "Mark S.", ""], ["Terry", "Louise", ""], ["Wood", "Ashley", ""], ["Tranos", "Paris", ""], ["Trikha", "Sameer", ""], ["Jaccard", "Nicolas", ""]]}, {"id": "1907.05171", "submitter": "Chen Xu", "authors": "Chen Xu, Quan Li, Junfeng Ge, Jinyang Gao, Xiaoyong Yang, Changhua\n  Pei, Fei Sun, Jian Wu, Hanxiao Sun, and Wenwu Ou", "title": "Privileged Features Distillation at Taobao Recommendations", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Features play an important role in the prediction tasks of e-commerce\nrecommendations. To guarantee the consistency of off-line training and on-line\nserving, we usually utilize the same features that are both available. However,\nthe consistency in turn neglects some discriminative features. For example,\nwhen estimating the conversion rate (CVR), i.e., the probability that a user\nwould purchase the item if she clicked it, features like dwell time on the item\ndetailed page are informative. However, CVR prediction should be conducted for\non-line ranking before the click happens. Thus we cannot get such post-event\nfeatures during serving.\n  We define the features that are discriminative but only available during\ntraining as the privileged features. Inspired by the distillation techniques\nwhich bridge the gap between training and inference, in this work, we propose\nprivileged features distillation (PFD). We train two models, i.e., a student\nmodel that is the same as the original one and a teacher model that\nadditionally utilizes the privileged features. Knowledge distilled from the\nmore accurate teacher is transferred to the student to improve its accuracy.\nDuring serving, only the student part is extracted and it relies on no\nprivileged features. We conduct experiments on two fundamental prediction tasks\nat Taobao recommendations, i.e., click-through rate (CTR) at coarse-grained\nranking and CVR at fine-grained ranking. By distilling the interacted features\nthat are prohibited during serving for CTR and the post-event features for CVR,\nwe achieve significant improvements over their strong baselines. During the\non-line A/B tests, the click metric is improved by +5.0% in the CTR task. And\nthe conversion metric is improved by +2.3% in the CVR task. Besides, by\naddressing several issues of training PFD, we obtain comparable training speed\nas the baselines without any distillation.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jul 2019 13:05:51 GMT"}, {"version": "v2", "created": "Wed, 26 Feb 2020 03:21:01 GMT"}], "update_date": "2020-02-27", "authors_parsed": [["Xu", "Chen", ""], ["Li", "Quan", ""], ["Ge", "Junfeng", ""], ["Gao", "Jinyang", ""], ["Yang", "Xiaoyong", ""], ["Pei", "Changhua", ""], ["Sun", "Fei", ""], ["Wu", "Jian", ""], ["Sun", "Hanxiao", ""], ["Ou", "Wenwu", ""]]}, {"id": "1907.05181", "submitter": "Andrea Tacchetti", "authors": "Andrea Tacchetti and DJ Strouse and Marta Garnelo and Thore Graepel\n  and Yoram Bachrach", "title": "A Neural Architecture for Designing Truthful and Efficient Auctions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Auctions are protocols to allocate goods to buyers who have preferences over\nthem, and collect payments in return. Economists have invested significant\neffort in designing auction rules that result in allocations of the goods that\nare desirable for the group as a whole. However, for settings where\nparticipants' valuations of the items on sale are their private information,\nthe rules of the auction must deter buyers from misreporting their preferences,\nso as to maximize their own utility, since misreported preferences hinder the\nability for the auctioneer to allocate goods to those who want them most.\nManual auction design has yielded excellent mechanisms for specific settings,\nbut requires significant effort when tackling new domains. We propose a deep\nlearning based approach to automatically design auctions in a wide variety of\ndomains, shifting the design work from human to machine. We assume that\nparticipants' valuations for the items for sale are independently sampled from\nan unknown but fixed distribution. Our system receives a data-set consisting of\nsuch valuation samples, and outputs an auction rule encoding the desired\nincentive structure. We focus on producing truthful and efficient auctions that\nminimize the economic burden on participants. We evaluate the auctions designed\nby our framework on well-studied domains, such as multi-unit and combinatorial\nauctions, showing that they outperform known auction designs in terms of the\neconomic burden placed on participants.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jul 2019 13:22:37 GMT"}], "update_date": "2019-07-12", "authors_parsed": [["Tacchetti", "Andrea", ""], ["Strouse", "DJ", ""], ["Garnelo", "Marta", ""], ["Graepel", "Thore", ""], ["Bachrach", "Yoram", ""]]}, {"id": "1907.05195", "submitter": "Stephen Odaibo", "authors": "Stephen G. Odaibo", "title": "retina-VAE: Variationally Decoding the Spectrum of Macular Disease", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG q-bio.TO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we seek a clinically-relevant latent code for representing the\nspectrum of macular disease. Towards this end, we construct retina-VAE, a\nvariational autoencoder-based model that accepts a patient profile vector\n(pVec) as input. The pVec components include clinical exam findings and\ndemographic information. We evaluate the model on a subspectrum of the retinal\nmaculopathies, in particular, exudative age-related macular degeneration,\ncentral serous chorioretinopathy, and polypoidal choroidal vasculopathy. For\nthese three maculopathies, a database of 3000 6-dimensional pVecs (1000 each)\nwas synthetically generated based on known disease statistics in the\nliterature. The database was then used to train the VAE and generate latent\nvector representations. We found training performance to be best for a\n3-dimensional latent vector architecture compared to 2 or 4 dimensional\nlatents. Additionally, for the 3D latent architecture, we discovered that the\nresulting latent vectors were strongly clustered spontaneously into one of 14\nclusters. Kmeans was then used only to identify members of each cluster and to\ninspect cluster properties. These clusters suggest underlying disease subtypes\nwhich may potentially respond better or worse to particular pharmaceutical\ntreatments such as anti-vascular endothelial growth factor variants. The\nretina-VAE framework will potentially yield new fundamental insights into the\nmechanisms and manifestations of disease. And will potentially facilitate the\ndevelopment of personalized pharmaceuticals and gene therapies.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jul 2019 13:49:25 GMT"}], "update_date": "2019-07-12", "authors_parsed": [["Odaibo", "Stephen G.", ""]]}, {"id": "1907.05200", "submitter": "Francisco Yepes Barrera Dr.", "authors": "Francisco Yepes Barrera", "title": "Eigen Artificial Neural Networks", "comments": "45 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work has its origin in intuitive physical and statistical\nconsiderations. The problem of optimizing an artificial neural network is\ntreated as a physical system, composed of a conservative vector force field.\nThe derived scalar potential is a measure of the potential energy of the\nnetwork, a function of the distance between predictions and targets.\n  Starting from some analogies with wave mechanics, the description of the\nsystem is justified with an eigenvalue equation that is a variant of the\nSchr\\~odinger equation, in which the potential is defined by the mutual\ninformation between inputs and targets. The weights and parameters of the\nnetwork, as well as those of the state function, are varied so as to minimize\nenergy, using an equivalent of the variational theorem of wave mechanics. The\nminimum energy thus obtained implies the principle of minimum mutual\ninformation (MinMI). We also propose a definition of the potential work\nproduced by the force field to bring a network from an arbitrary probability\ndistribution to the potential-constrained system, which allows to establish a\nmeasure of the complexity of the system. At the end of the discussion we expose\na recursive procedure that allows to refine the state function and bypass some\ninitial assumptions, as well as a discussion of some topics in quantum\nmechanics applied to the formalism, such as the uncertainty principle and the\ntemporal evolution of the system.\n  Results demonstrate how the minimization of energy effectively leads to a\ndecrease in the average error between network predictions and targets.\n", "versions": [{"version": "v1", "created": "Wed, 22 May 2019 21:31:52 GMT"}, {"version": "v2", "created": "Sat, 14 Sep 2019 13:35:47 GMT"}, {"version": "v3", "created": "Fri, 31 Jan 2020 21:36:01 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Barrera", "Francisco Yepes", ""]]}, {"id": "1907.05226", "submitter": "Bharath Sriperumbudur", "authors": "Nicholas Sterge, Bharath Sriperumbudur, Lorenzo Rosasco and Alessandro\n  Rudi", "title": "Gain with no Pain: Efficient Kernel-PCA by Nystr\\\"om Sampling", "comments": "19 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose and study a Nystr\\\"om based approach to efficient\nlarge scale kernel principal component analysis (PCA). The latter is a natural\nnonlinear extension of classical PCA based on considering a nonlinear feature\nmap or the corresponding kernel. Like other kernel approaches, kernel PCA\nenjoys good mathematical and statistical properties but, numerically, it scales\npoorly with the sample size. Our analysis shows that Nystr\\\"om sampling greatly\nimproves computational efficiency without incurring any loss of statistical\naccuracy. While similar effects have been observed in supervised learning, this\nis the first such result for PCA. Our theoretical findings, which are also\nillustrated by numerical results, are based on a combination of analytic and\nconcentration of measure techniques. Our study is more broadly motivated by the\nquestion of understanding the interplay between statistical and computational\nrequirements for learning.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jul 2019 14:16:25 GMT"}], "update_date": "2019-07-12", "authors_parsed": [["Sterge", "Nicholas", ""], ["Sriperumbudur", "Bharath", ""], ["Rosasco", "Lorenzo", ""], ["Rudi", "Alessandro", ""]]}, {"id": "1907.05231", "submitter": "Shuai Ma", "authors": "Shuai Ma and Jia Yuan Yu", "title": "Variance-Based Risk Estimations in Markov Processes via Transformation\n  with State Lumping", "comments": "7 pages, 7 figures, SMC 2019 accepted. arXiv admin note: text overlap\n  with arXiv:1907.04269", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variance plays a crucial role in risk-sensitive reinforcement learning, and\nmost risk measures can be analyzed via variance. In this paper, we consider two\nlaw-invariant risks as examples: mean-variance risk and exponential utility\nrisk. With the aid of the state-augmentation transformation (SAT), we show\nthat, the two risks can be estimated in Markov decision processes (MDPs) with a\nstochastic transition-based reward and a randomized policy. To relieve the\nenlarged state space, a novel definition of isotopic states is proposed for\nstate lumping, considering the special structure of the transformed transition\nprobability. In the numerical experiment, we illustrate state lumping in the\nSAT, errors from a naive reward simplification, and the validity of the SAT for\nthe two risk estimations.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jul 2019 16:04:33 GMT"}], "update_date": "2019-07-12", "authors_parsed": [["Ma", "Shuai", ""], ["Yu", "Jia Yuan", ""]]}, {"id": "1907.05234", "submitter": "Chainarong Amornbunchornvej", "authors": "Chainarong Amornbunchornvej, Navaporn Surasvadi, Anon Plangprasopchok,\n  and Suttipong Thajchayapong", "title": "Identifying Linear Models in Multi-Resolution Population Data using\n  Minimum Description Length Principle to Predict Household Income", "comments": "This is the accepted manuscript for publication in TKDD. The R\n  package is available at https://github.com/DarkEyes/MRReg", "journal-ref": "ACM Transactions on Knowledge Discovery from Data (TKDD), 15(2),\n  15 (2021)", "doi": "10.1145/3424670", "report-no": null, "categories": "cs.LG cs.CY stat.AP stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One shirt size cannot fit everybody, while we cannot make a unique shirt that\nfits perfectly for everyone because of resource limitation. This analogy is\ntrue for the policy making. Policy makers cannot establish a single policy to\nsolve all problems for all regions because each region has its own unique\nissue. In the other extreme, policy makers also cannot create a policy for each\nsmall village due to the resource limitation. Would it be better if we can find\na set of largest regions such that the population of each region within this\nset has common issues and we can establish a single policy for them? In this\nwork, we propose a framework using regression analysis and minimum description\nlength (MDL) to find a set of largest areas that have common indicators, which\ncan be used to predict household incomes efficiently. Given a set of household\nfeatures, and a multi-resolution partition that represents administrative\ndivisions, our framework reports a set C* of largest subdivisions that have a\ncommon model for population-income prediction. We formalize a problem of\nfinding C* and propose the algorithm as a solution. We use both simulation\ndatasets as well as a real-world dataset of Thailand's population household\ninformation to demonstrate our framework performance and application. The\nresults show that our framework performance is better than the baseline\nmethods. We show the results of our method can be used to find indicators of\nincome prediction for many areas in Thailand. By increasing these indicator\nvalues, we expect people in these areas to gain more incomes. Hence, the policy\nmakers can plan to establish the policies by using these indicators in our\nresults as a guideline to solve low-income issues. Our framework can be used to\nsupport policy makers to establish policies regarding any other dependent\nvariable beyond incomes in order to combat poverty and other issues.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jul 2019 03:08:31 GMT"}, {"version": "v2", "created": "Wed, 27 May 2020 15:32:25 GMT"}, {"version": "v3", "created": "Wed, 6 Jan 2021 08:39:38 GMT"}], "update_date": "2021-01-07", "authors_parsed": [["Amornbunchornvej", "Chainarong", ""], ["Surasvadi", "Navaporn", ""], ["Plangprasopchok", "Anon", ""], ["Thajchayapong", "Suttipong", ""]]}, {"id": "1907.05242", "submitter": "Guillaume Lample", "authors": "Guillaume Lample, Alexandre Sablayrolles, Marc'Aurelio Ranzato,\n  Ludovic Denoyer, Herv\\'e J\\'egou", "title": "Large Memory Layers with Product Keys", "comments": "Advances in Neural Information Processing Systems, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a structured memory which can be easily integrated into\na neural network. The memory is very large by design and significantly\nincreases the capacity of the architecture, by up to a billion parameters with\na negligible computational overhead. Its design and access pattern is based on\nproduct keys, which enable fast and exact nearest neighbor search. The ability\nto increase the number of parameters while keeping the same computational\nbudget lets the overall system strike a better trade-off between prediction\naccuracy and computation efficiency both at training and test time. This memory\nlayer allows us to tackle very large scale language modeling tasks. In our\nexperiments we consider a dataset with up to 30 billion words, and we plug our\nmemory layer in a state-of-the-art transformer-based architecture. In\nparticular, we found that a memory augmented model with only 12 layers\noutperforms a baseline transformer model with 24 layers, while being twice\nfaster at inference time. We release our code for reproducibility purposes.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jul 2019 14:52:12 GMT"}, {"version": "v2", "created": "Mon, 16 Dec 2019 03:46:57 GMT"}], "update_date": "2019-12-17", "authors_parsed": [["Lample", "Guillaume", ""], ["Sablayrolles", "Alexandre", ""], ["Ranzato", "Marc'Aurelio", ""], ["Denoyer", "Ludovic", ""], ["J\u00e9gou", "Herv\u00e9", ""]]}, {"id": "1907.05246", "submitter": "Konstantinos Makantasis", "authors": "Konstantinos Makantasis, Maria Kontorinaki, Ioannis Nikolos", "title": "Deep Reinforcement-Learning-based Driving Policy for Autonomous Road\n  Vehicles", "comments": "19 pages. arXiv admin note: substantial text overlap with\n  arXiv:1905.09046", "journal-ref": null, "doi": "10.1049/iet-its.2019.0249", "report-no": null, "categories": "cs.RO cs.AI cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work the problem of path planning for an autonomous vehicle that\nmoves on a freeway is considered. The most common approaches that are used to\naddress this problem are based on optimal control methods, which make\nassumptions about the model of the environment and the system dynamics. On the\ncontrary, this work proposes the development of a driving policy based on\nreinforcement learning. In this way, the proposed driving policy makes minimal\nor no assumptions about the environment, since a priori knowledge about the\nsystem dynamics is not required. Driving scenarios where the road is occupied\nboth by autonomous and manual driving vehicles are considered. To the best of\nour knowledge, this is one of the first approaches that propose a reinforcement\nlearning driving policy for mixed driving environments. The derived\nreinforcement learning policy, firstly, is compared against an optimal policy\nderived via dynamic programming, and, secondly, its efficiency is evaluated\nunder realistic scenarios generated by the established SUMO microscopic traffic\nflow simulator. Finally, some initial results regarding the effect of\nautonomous vehicles' behavior on the overall traffic flow are presented.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jul 2019 11:44:09 GMT"}, {"version": "v2", "created": "Tue, 18 Feb 2020 09:22:25 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Makantasis", "Konstantinos", ""], ["Kontorinaki", "Maria", ""], ["Nikolos", "Ioannis", ""]]}, {"id": "1907.05251", "submitter": "Karl {\\O}yvind Mikalsen", "authors": "Karl {\\O}yvind Mikalsen, Cristina Soguero-Ruiz, Filippo Maria Bianchi,\n  Arthur Revhaug, Robert Jenssen", "title": "Time series cluster kernels to exploit informative missingness and\n  incomplete label information", "comments": "arXiv admin note: text overlap with arXiv:1803.07879", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The time series cluster kernel (TCK) provides a powerful tool for analysing\nmultivariate time series subject to missing data. TCK is designed using an\nensemble learning approach in which Bayesian mixture models form the base\nmodels. Because of the Bayesian approach, TCK can naturally deal with missing\nvalues without resorting to imputation and the ensemble strategy ensures\nrobustness to hyperparameters, making it particularly well suited for\nunsupervised learning.\n  However, TCK assumes missing at random and that the underlying missingness\nmechanism is ignorable, i.e. uninformative, an assumption that does not hold in\nmany real-world applications, such as e.g. medicine. To overcome this\nlimitation, we present a kernel capable of exploiting the potentially rich\ninformation in the missing values and patterns, as well as the information from\nthe observed data. In our approach, we create a representation of the missing\npattern, which is incorporated into mixed mode mixture models in such a way\nthat the information provided by the missing patterns is effectively exploited.\nMoreover, we also propose a semi-supervised kernel, capable of taking advantage\nof incomplete label information to learn more accurate similarities.\n  Experiments on benchmark data, as well as a real-world case study of patients\ndescribed by longitudinal electronic health record data who potentially suffer\nfrom hospital-acquired infections, demonstrate the effectiveness of the\nproposed methods.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jul 2019 08:05:15 GMT"}], "update_date": "2019-07-12", "authors_parsed": [["Mikalsen", "Karl \u00d8yvind", ""], ["Soguero-Ruiz", "Cristina", ""], ["Bianchi", "Filippo Maria", ""], ["Revhaug", "Arthur", ""], ["Jenssen", "Robert", ""]]}, {"id": "1907.05267", "submitter": "Helena Andres Terre", "authors": "Helena Andr\\'es-Terr\\'e, Pietro Li\\'o", "title": "Perturbation theory approach to study the latent space degeneracy of\n  Variational Autoencoders", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG physics.data-an stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The use of Variational Autoencoders in different Machine Learning tasks has\ndrastically increased in the last years. They have been developed as denoising,\nclustering and generative tools, highlighting a large potential in a wide range\nof fields. Their embeddings are able to extract relevant information from\nhighly dimensional inputs, but the converged models can differ significantly\nand lead to degeneracy on the latent space. We leverage the relation between\ntheoretical physics and machine learning to explain this behaviour, and\nintroduce a new approach to correct for degeneration by using perturbation\ntheory. The re-formulation of the embedding as multi-dimensional generative\ndistribution, allows mapping to a new set of functions and their corresponding\nenergy spectrum. We optimise for a perturbed Hamiltonian, with an additional\nenergy potential that is related to the unobserved topology of the data. Our\nresults show the potential of a new theoretical approach that can be used to\ninterpret the latent space and generative nature of unsupervised learning,\nwhile the energy landscapes defined by the perturbations can be further used\nfor modelling and dynamical purposes.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jul 2019 16:14:13 GMT"}], "update_date": "2019-07-12", "authors_parsed": [["Andr\u00e9s-Terr\u00e9", "Helena", ""], ["Li\u00f3", "Pietro", ""]]}, {"id": "1907.05269", "submitter": "Leszek Pecyna", "authors": "Leszek Pecyna, Angelo Cangelosi", "title": "Influence of Pointing on Learning to Count: A Neuro-Robotics Model", "comments": "8 pages, 5 figures. In Proceedings of the 2018 IEEE Symposium Series\n  on Computational Intelligence (SSCI) (pp. 358-365). IEEE", "journal-ref": null, "doi": "10.1109/SSCI.2018.8628811", "report-no": null, "categories": "cs.CV cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper a neuro-robotics model capable of counting using gestures is\nintroduced. The contribution of gestures to learning to count is tested with\nvarious model and training conditions. Two studies were presented in this\narticle. In the first, we combine different modalities of the robot's neural\nnetwork, in the second, a novel training procedure for it is proposed. The\nmodel is trained with pointing data from an iCub robot simulator. The behaviour\nof the model is in line with that of human children in terms of performance\nchange depending on gesture production.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jul 2019 13:59:36 GMT"}], "update_date": "2019-07-12", "authors_parsed": [["Pecyna", "Leszek", ""], ["Cangelosi", "Angelo", ""]]}, {"id": "1907.05270", "submitter": "Leszek Pecyna", "authors": "Leszek Pecyna, Angelo Cangelosi, Alessandro Di Nuovo", "title": "A Deep Neural Network for Finger Counting and Numerosity Estimation", "comments": "8 pages, accepted and presented on a conference. In Proceedings of\n  the 2019 IEEE Symposium Series on Computational Intelligence (SSCI)", "journal-ref": "2019 IEEE Symposium Series on Computational Intelligence", "doi": "10.1109/SSCI44817.2019.9002694", "report-no": null, "categories": "cs.CV cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present neuro-robotics models with a deep artificial neural\nnetwork capable of generating finger counting positions and number estimation.\nWe first train the model in an unsupervised manner where each layer is treated\nas a Restricted Boltzmann Machine or an autoencoder. Such a model is further\ntrained in a supervised way. This type of pre-training is tested on our\nbaseline model and two methods of pre-training are compared. The network is\nextended to produce finger counting positions. The performance in number\nestimation of such an extended model is evaluated. We test the hypothesis if\nthe subitizing process can be obtained by one single model used also for\nestimation of higher numerosities. The results confirm the importance of\nunsupervised training in our enumeration task and show some similarities to\nhuman behaviour in the case of subitizing.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jul 2019 13:10:28 GMT"}, {"version": "v2", "created": "Tue, 14 Jan 2020 17:33:53 GMT"}], "update_date": "2020-05-28", "authors_parsed": [["Pecyna", "Leszek", ""], ["Cangelosi", "Angelo", ""], ["Di Nuovo", "Alessandro", ""]]}, {"id": "1907.05274", "submitter": "Letao Liu", "authors": "Letao Liu, Martin Saerbeck, Justin Dauwels", "title": "Affine Disentangled GAN for Interpretable and Robust AV Perception", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autonomous vehicles (AV) have progressed rapidly with the advancements in\ncomputer vision algorithms. The deep convolutional neural network as the main\ncontributor to this advancement has boosted the classification accuracy\ndramatically. However, the discovery of adversarial examples reveals the\ngeneralization gap between dataset and the real world. Furthermore, affine\ntransformations may also confuse computer vision based object detectors. The\ndegradation of the perception system is undesirable for safety critical systems\nsuch as autonomous vehicles. In this paper, a deep learning system is proposed:\nAffine Disentangled GAN (ADIS-GAN), which is robust against affine\ntransformations and adversarial attacks. It is demonstrated that conventional\ndata augmentation for affine transformation and adversarial attacks are\northogonal, while ADIS-GAN can handle both attacks at the same time. Useful\ninformation such as image rotation angle and scaling factor are also generated\nin ADIS-GAN. On MNIST dataset, ADIS-GAN can achieve over 98 percent\nclassification accuracy within 30 degrees rotation, and over 90 percent\nclassification accuracy against FGSM and PGD adversarial attack.\n", "versions": [{"version": "v1", "created": "Sat, 6 Jul 2019 04:53:49 GMT"}], "update_date": "2019-07-12", "authors_parsed": [["Liu", "Letao", ""], ["Saerbeck", "Martin", ""], ["Dauwels", "Justin", ""]]}, {"id": "1907.05276", "submitter": "Matt Groh", "authors": "Matthew Groh, Ziv Epstein, Nick Obradovich, Manuel Cebrian, Iyad\n  Rahwan", "title": "Human detection of machine manipulated media", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in neural networks for content generation enable artificial\nintelligence (AI) models to generate high-quality media manipulations. Here we\nreport on a randomized experiment designed to study the effect of exposure to\nmedia manipulations on over 15,000 individuals' ability to discern\nmachine-manipulated media. We engineer a neural network to plausibly and\nautomatically remove objects from images, and we deploy this neural network\nonline with a randomized experiment where participants can guess which image\nout of a pair of images has been manipulated. The system provides participants\nfeedback on the accuracy of each guess. In the experiment, we randomize the\norder in which images are presented, allowing causal identification of the\nlearning curve surrounding participants' ability to detect fake content. We\nfind sizable and robust evidence that individuals learn to detect fake content\nthrough exposure to manipulated media when provided iterative feedback on their\ndetection attempts. Over a succession of only ten images, participants increase\ntheir rating accuracy by over ten percentage points. Our study provides initial\nevidence that human ability to detect fake, machine-generated content may\nincrease alongside the prevalence of such media online.\n", "versions": [{"version": "v1", "created": "Sat, 6 Jul 2019 02:52:42 GMT"}, {"version": "v2", "created": "Fri, 8 Nov 2019 15:22:26 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Groh", "Matthew", ""], ["Epstein", "Ziv", ""], ["Obradovich", "Nick", ""], ["Cebrian", "Manuel", ""], ["Rahwan", "Iyad", ""]]}, {"id": "1907.05278", "submitter": "Youssef Mourchid", "authors": "Youssef Mourchid, Mohammed El Hassouni, Hocine Cherifi", "title": "A General Framework for Complex Network-Based Image Segmentation", "comments": null, "journal-ref": "Multimedia Tools and Applications (2019)", "doi": "10.1007/s11042-019-7304-2", "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the recent advances in complex networks theory, graph-based techniques\nfor image segmentation has attracted great attention recently. In order to\nsegment the image into meaningful connected components, this paper proposes an\nimage segmentation general framework using complex networks based community\ndetection algorithms. If we consider regions as communities, using community\ndetection algorithms directly can lead to an over-segmented image. To address\nthis problem, we start by splitting the image into small regions using an\ninitial segmentation. The obtained regions are used for building the complex\nnetwork. To produce meaningful connected components and detect homogeneous\ncommunities, some combinations of color and texture based features are employed\nin order to quantify the regions similarities. To sum up, the network of\nregions is constructed adaptively to avoid many small regions in the image, and\nthen, community detection algorithms are applied on the resulting adaptive\nsimilarity matrix to obtain the final segmented image. Experiments are\nconducted on Berkeley Segmentation Dataset and four of the most influential\ncommunity detection algorithms are tested. Experimental results have shown that\nthe proposed general framework increases the segmentation performances compared\nto some existing methods.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jul 2019 11:59:42 GMT"}], "update_date": "2019-07-12", "authors_parsed": [["Mourchid", "Youssef", ""], ["Hassouni", "Mohammed El", ""], ["Cherifi", "Hocine", ""]]}, {"id": "1907.05279", "submitter": "Lukas Prantl", "authors": "Lukas Prantl, Nuttapong Chentanez, Stefan Jeschke, and Nils Thuerey", "title": "Tranquil Clouds: Neural Networks for Learning Temporally Coherent\n  Features in Point Clouds", "comments": "Further information and videos at\n  https://ge.in.tum.de/publications/2020-iclr-prantl/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.GR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Point clouds, as a form of Lagrangian representation, allow for powerful and\nflexible applications in a large number of computational disciplines. We\npropose a novel deep-learning method to learn stable and temporally coherent\nfeature spaces for points clouds that change over time. We identify a set of\ninherent problems with these approaches: without knowledge of the time\ndimension, the inferred solutions can exhibit strong flickering, and easy\nsolutions to suppress this flickering can result in undesirable local minima\nthat manifest themselves as halo structures. We propose a novel temporal loss\nfunction that takes into account higher time derivatives of the point\npositions, and encourages mingling, i.e., to prevent the aforementioned halos.\nWe combine these techniques in a super-resolution method with a truncation\napproach to flexibly adapt the size of the generated positions. We show that\nour method works for large, deforming point sets from different sources to\ndemonstrate the flexibility of our approach.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jul 2019 18:54:02 GMT"}, {"version": "v2", "created": "Wed, 29 Jan 2020 10:55:16 GMT"}], "update_date": "2020-01-30", "authors_parsed": [["Prantl", "Lukas", ""], ["Chentanez", "Nuttapong", ""], ["Jeschke", "Stefan", ""], ["Thuerey", "Nils", ""]]}, {"id": "1907.05280", "submitter": "Maximilian Bachl", "authors": "Maximilian Bachl and Daniel C. Ferreira", "title": "City-GAN: Learning architectural styles using a custom Conditional GAN\n  architecture", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.GR cs.LG eess.IV stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Generative Adversarial Networks (GANs) are a well-known technique that is\ntrained on samples (e.g. pictures of fruits) and which after training is able\nto generate realistic new samples. Conditional GANs (CGANs) additionally\nprovide label information for subclasses (e.g. apple, orange, pear) which\nenables the GAN to learn more easily and increase the quality of its output\nsamples. We use GANs to learn architectural features of major cities and to\ngenerate images of buildings which do not exist. We show that currently\navailable GAN and CGAN architectures are unsuited for this task and propose a\ncustom architecture and demonstrate that our architecture has superior\nperformance for this task and verify its capabilities with extensive\nexperiments.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jul 2019 11:43:36 GMT"}, {"version": "v2", "created": "Tue, 26 May 2020 20:19:30 GMT"}], "update_date": "2020-05-28", "authors_parsed": [["Bachl", "Maximilian", ""], ["Ferreira", "Daniel C.", ""]]}, {"id": "1907.05282", "submitter": "Zhuangzi Li", "authors": "Zhuangzi Li", "title": "Image Super-Resolution Using Attention Based DenseNet with Residual\n  Deconvolution", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Image super-resolution is a challenging task and has attracted increasing\nattention in research and industrial communities. In this paper, we propose a\nnovel end-to-end Attention-based DenseNet with Residual Deconvolution named as\nADRD. In our ADRD, a weighted dense block, in which the current layer receives\nweighted features from all previous levels, is proposed to capture valuable\nfeatures rely in dense layers adaptively. And a novel spatial attention module\nis presented to generate a group of attentive maps for emphasizing informative\nregions. In addition, we design an innovative strategy to upsample residual\ninformation via the deconvolution layer, so that the high-frequency details can\nbe accurately upsampled. Extensive experiments conducted on publicly available\ndatasets demonstrate the promising performance of the proposed ADRD against the\nstate-of-the-arts, both quantitatively and qualitatively.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jul 2019 08:28:13 GMT"}], "update_date": "2019-07-12", "authors_parsed": [["Li", "Zhuangzi", ""]]}, {"id": "1907.05283", "submitter": "Cem Sahin", "authors": "Evan Koester, Cem Safak Sahin", "title": "A Comparison of Super-Resolution and Nearest Neighbors Interpolation\n  Applied to Object Detection on Satellite Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As Super-Resolution (SR) has matured as a research topic, it has been applied\nto additional topics beyond image reconstruction. In particular, combining\nclassification or object detection tasks with a super-resolution preprocessing\nstage has yielded improvements in accuracy especially with objects that are\nsmall relative to the scene. While SR has shown promise, a study comparing SR\nand naive upscaling methods such as Nearest Neighbors (NN) interpolation when\napplied as a preprocessing step for object detection has not been performed. We\napply the topic to satellite data and compare the Multi-scale Deep\nSuper-Resolution (MDSR) system to NN on the xView challenge dataset. To do so,\nwe propose a pipeline for processing satellite data that combines multi-stage\nimage tiling and upscaling, the YOLOv2 object detection architecture, and label\nstitching. We compare the effects of training models using an upscaling factor\nof 4, upscaling images from 30cm Ground Sample Distance (GSD) to an effective\nGSD of 7.5cm. Upscaling by this factor significantly improves detection\nresults, increasing Average Precision (AP) of a generalized vehicle class by 23\npercent. We demonstrate that while SR produces upscaled images that are more\nvisually pleasing than their NN counterparts, object detection networks see\nlittle difference in accuracy with images upsampled using NN obtaining nearly\nidentical results to the MDSRx4 enhanced images with a difference of 0.0002 AP\nbetween the two methods.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jul 2019 17:03:12 GMT"}], "update_date": "2019-07-12", "authors_parsed": [["Koester", "Evan", ""], ["Sahin", "Cem Safak", ""]]}, {"id": "1907.05286", "submitter": "Bei Wang", "authors": "Bei Wang, Jianping An and Jiayan Cao", "title": "Voxel-FPN: multi-scale voxel feature aggregation in 3D object detection\n  from point clouds", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Object detection in point cloud data is one of the key components in computer\nvision systems, especially for autonomous driving applications. In this work,\nwe present Voxel-FPN, a novel one-stage 3D object detector that utilizes raw\ndata from LIDAR sensors only. The core framework consists of an encoder network\nand a corresponding decoder followed by a region proposal network. Encoder\nextracts multi-scale voxel information in a bottom-up manner while decoder\nfuses multiple feature maps from various scales in a top-down way. Extensive\nexperiments show that the proposed method has better performance on extracting\nfeatures from point data and demonstrates its superiority over some baselines\non the challenging KITTI-3D benchmark, obtaining good performance on both speed\nand accuracy in real-world scenarios.\n", "versions": [{"version": "v1", "created": "Fri, 28 Jun 2019 09:49:10 GMT"}, {"version": "v2", "created": "Tue, 16 Jul 2019 08:22:44 GMT"}], "update_date": "2019-07-17", "authors_parsed": [["Wang", "Bei", ""], ["An", "Jianping", ""], ["Cao", "Jiayan", ""]]}, {"id": "1907.05297", "submitter": "Mariel Pettee", "authors": "Mariel Pettee, Chase Shimmin, Douglas Duhaime, Ilya Vidrin", "title": "Beyond Imitation: Generative and Variational Choreography via Machine\n  Learning", "comments": "8 pages, 11 figures, presented at the 10th International Conference\n  on Computational Creativity (ICCC 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.MM stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Our team of dance artists, physicists, and machine learning researchers has\ncollectively developed several original, configurable machine-learning tools to\ngenerate novel sequences of choreography as well as tunable variations on input\nchoreographic sequences. We use recurrent neural network and autoencoder\narchitectures from a training dataset of movements captured as 53\nthree-dimensional points at each timestep. Sample animations of generated\nsequences and an interactive version of our model can be found at http:\n//www.beyondimitation.com.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jul 2019 15:12:10 GMT"}], "update_date": "2019-07-12", "authors_parsed": [["Pettee", "Mariel", ""], ["Shimmin", "Chase", ""], ["Duhaime", "Douglas", ""], ["Vidrin", "Ilya", ""]]}, {"id": "1907.05317", "submitter": "Tenavi Nakamura-Zimmerer", "authors": "Tenavi Nakamura-Zimmerer, Qi Gong, Wei Kang", "title": "Adaptive Deep Learning for High-Dimensional Hamilton-Jacobi-Bellman\n  Equations", "comments": "Added section on validation error computation. Updated convergence\n  test formula and associated results", "journal-ref": "SIAM Journal on Scientific Computing 43 (2021) A1221-A1247", "doi": "10.1137/19M1288802", "report-no": null, "categories": "math.OC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computing optimal feedback controls for nonlinear systems generally requires\nsolving Hamilton-Jacobi-Bellman (HJB) equations, which are notoriously\ndifficult when the state dimension is large. Existing strategies for\nhigh-dimensional problems often rely on specific, restrictive problem\nstructures, or are valid only locally around some nominal trajectory. In this\npaper, we propose a data-driven method to approximate semi-global solutions to\nHJB equations for general high-dimensional nonlinear systems and compute\ncandidate optimal feedback controls in real-time. To accomplish this, we model\nsolutions to HJB equations with neural networks (NNs) trained on data generated\nwithout discretizing the state space. Training is made more effective and\ndata-efficient by leveraging the known physics of the problem and using the\npartially-trained NN to aid in adaptive data generation. We demonstrate the\neffectiveness of our method by learning solutions to HJB equations\ncorresponding to the attitude control of a six-dimensional nonlinear rigid\nbody, and nonlinear systems of dimension up to 30 arising from the\nstabilization of a Burgers'-type partial differential equation. The trained NNs\nare then used for real-time feedback control of these systems.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jul 2019 15:44:30 GMT"}, {"version": "v2", "created": "Fri, 12 Jul 2019 01:05:37 GMT"}, {"version": "v3", "created": "Fri, 20 Sep 2019 20:11:16 GMT"}, {"version": "v4", "created": "Sun, 7 Jun 2020 23:40:10 GMT"}, {"version": "v5", "created": "Mon, 8 Feb 2021 19:42:52 GMT"}], "update_date": "2021-04-09", "authors_parsed": [["Nakamura-Zimmerer", "Tenavi", ""], ["Gong", "Qi", ""], ["Kang", "Wei", ""]]}, {"id": "1907.05321", "submitter": "Seyed Mehran Kazemi", "authors": "Seyed Mehran Kazemi, Rishab Goel, Sepehr Eghbali, Janahan Ramanan,\n  Jaspreet Sahota, Sanjay Thakur, Stella Wu, Cathal Smyth, Pascal Poupart,\n  Marcus Brubaker", "title": "Time2Vec: Learning a Vector Representation of Time", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Time is an important feature in many applications involving events that occur\nsynchronously and/or asynchronously. To effectively consume time information,\nrecent studies have focused on designing new architectures. In this paper, we\ntake an orthogonal but complementary approach by providing a model-agnostic\nvector representation for time, called Time2Vec, that can be easily imported\ninto many existing and future architectures and improve their performances. We\nshow on a range of models and problems that replacing the notion of time with\nits Time2Vec representation improves the performance of the final model.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jul 2019 15:47:39 GMT"}], "update_date": "2019-07-12", "authors_parsed": [["Kazemi", "Seyed Mehran", ""], ["Goel", "Rishab", ""], ["Eghbali", "Sepehr", ""], ["Ramanan", "Janahan", ""], ["Sahota", "Jaspreet", ""], ["Thakur", "Sanjay", ""], ["Wu", "Stella", ""], ["Smyth", "Cathal", ""], ["Poupart", "Pascal", ""], ["Brubaker", "Marcus", ""]]}, {"id": "1907.05325", "submitter": "Andrew McRae", "authors": "Andrew D. McRae and Mark A. Davenport", "title": "Low-rank matrix completion and denoising under Poisson noise", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers the problem of estimating a low-rank matrix from the\nobservation of all or a subset of its entries in the presence of Poisson noise.\nWhen we observe all entries, this is a problem of matrix denoising; when we\nobserve only a subset of the entries, this is a problem of matrix completion.\nIn both cases, we exploit an assumption that the underlying matrix is low-rank.\nSpecifically, we analyze several estimators, including a constrained\nnuclear-norm minimization program, nuclear-norm regularized least squares, and\na nonconvex constrained low-rank optimization problem. We show that for all\nthree estimators, with high probability, we have an upper error bound (in the\nFrobenius norm error metric) that depends on the matrix rank, the fraction of\nthe elements observed, and maximal row and column sums of the true matrix. We\nfurthermore show that the above results are minimax optimal (within a universal\nconstant) in classes of matrices with low rank and bounded row and column sums.\nWe also extend these results to handle the case of matrix multinomial denoising\nand completion.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jul 2019 16:00:42 GMT"}, {"version": "v2", "created": "Thu, 30 Apr 2020 16:20:17 GMT"}], "update_date": "2020-05-01", "authors_parsed": [["McRae", "Andrew D.", ""], ["Davenport", "Mark A.", ""]]}, {"id": "1907.05327", "submitter": "Ying Peng", "authors": "Shaolin Ji, Shige Peng, Ying Peng, Xichuan Zhang", "title": "Three algorithms for solving high-dimensional fully-coupled FBSDEs\n  through deep learning", "comments": "24 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.LG cs.NA math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, the deep learning method has been used for solving forward-backward\nstochastic differential equations (FBSDEs) and parabolic partial differential\nequations (PDEs). It has good accuracy and performance for high-dimensional\nproblems. In this paper, we mainly solve fully coupled FBSDEs through deep\nlearning and provide three algorithms. Several numerical results show\nremarkable performance especially for high-dimensional cases.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jul 2019 16:03:31 GMT"}, {"version": "v2", "created": "Wed, 17 Jul 2019 14:23:57 GMT"}, {"version": "v3", "created": "Fri, 6 Sep 2019 09:39:24 GMT"}, {"version": "v4", "created": "Sun, 2 Feb 2020 08:48:43 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Ji", "Shaolin", ""], ["Peng", "Shige", ""], ["Peng", "Ying", ""], ["Zhang", "Xichuan", ""]]}, {"id": "1907.05336", "submitter": "Mojtaba Nayyeri", "authors": "Mojtaba Nayyeri, Xiaotian Zhou, Sahar Vahdati, Hamed Shariat Yazdi,\n  Jens Lehmann", "title": "Adaptive Margin Ranking Loss for Knowledge Graph Embeddings via a\n  Correntropy Objective Function", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Translation-based embedding models have gained significant attention in link\nprediction tasks for knowledge graphs. TransE is the primary model among\ntranslation-based embeddings and is well-known for its low complexity and high\nefficiency. Therefore, most of the earlier works have modified the score\nfunction of the TransE approach in order to improve the performance of link\nprediction tasks. Nevertheless, proven theoretically and experimentally, the\nperformance of TransE strongly depends on the loss function. Margin Ranking\nLoss (MRL) has been one of the earlier loss functions which is widely used for\ntraining TransE. However, the scores of positive triples are not necessarily\nenforced to be sufficiently small to fulfill the translation from head to tail\nby using relation vector (original assumption of TransE). To tackle this\nproblem, several loss functions have been proposed recently by adding upper\nbounds and lower bounds to the scores of positive and negative samples.\nAlthough highly effective, previously developed models suffer from an expansion\nin search space for a selection of the hyperparameters (in particular the upper\nand lower bounds of scores) on which the performance of the translation-based\nmodels is highly dependent. In this paper, we propose a new loss function\ndubbed Adaptive Margin Loss (AML) for training translation-based embedding\nmodels. The formulation of the proposed loss function enables an adaptive and\nautomated adjustment of the margin during the learning process. Therefore,\ninstead of obtaining two values (upper bound and lower bound), only the center\nof a margin needs to be determined. During learning, the margin is expanded\nautomatically until it converges. In our experiments on a set of standard\nbenchmark datasets including Freebase and WordNet, the effectiveness of AML is\nconfirmed for training TransE on link prediction tasks.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jul 2019 12:32:40 GMT"}], "update_date": "2019-07-12", "authors_parsed": [["Nayyeri", "Mojtaba", ""], ["Zhou", "Xiaotian", ""], ["Vahdati", "Sahar", ""], ["Yazdi", "Hamed Shariat", ""], ["Lehmann", "Jens", ""]]}, {"id": "1907.05338", "submitter": "Ran Wang", "authors": "Ran Wang, Haibo Su, Chunye Wang, Kailin Ji, Jupeng Ding", "title": "To Tune or Not To Tune? How About the Best of Both Worlds?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  The introduction of pre-trained language models has revolutionized natural\nlanguage research communities. However, researchers still know relatively\nlittle regarding their theoretical and empirical properties. In this regard,\nPeters et al. perform several experiments which demonstrate that it is better\nto adapt BERT with a light-weight task-specific head, rather than building a\ncomplex one on top of the pre-trained language model, and freeze the parameters\nin the said language model. However, there is another option to adopt. In this\npaper, we propose a new adaptation method which we first train the task model\nwith the BERT parameters frozen and then fine-tune the entire model together.\nOur experimental results show that our model adaptation method can achieve 4.7%\naccuracy improvement in semantic similarity task, 0.99% accuracy improvement in\nsequence labeling task and 0.72% accuracy improvement in the text\nclassification task.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jul 2019 04:46:31 GMT"}], "update_date": "2019-07-12", "authors_parsed": [["Wang", "Ran", ""], ["Su", "Haibo", ""], ["Wang", "Chunye", ""], ["Ji", "Kailin", ""], ["Ding", "Jupeng", ""]]}, {"id": "1907.05339", "submitter": "Hainan Zhang", "authors": "Hainan Zhang, Yanyan Lan, Liang Pang, Jiafeng Guo and Xueqi Cheng", "title": "ReCoSa: Detecting the Relevant Contexts with Self-Attention for\n  Multi-turn Dialogue Generation", "comments": null, "journal-ref": "ACL2019", "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In multi-turn dialogue generation, response is usually related with only a\nfew contexts. Therefore, an ideal model should be able to detect these relevant\ncontexts and produce a suitable response accordingly. However, the widely used\nhierarchical recurrent encoderdecoder models just treat all the contexts\nindiscriminately, which may hurt the following response generation process.\nSome researchers try to use the cosine similarity or the traditional attention\nmechanism to find the relevant contexts, but they suffer from either\ninsufficient relevance assumption or position bias problem. In this paper, we\npropose a new model, named ReCoSa, to tackle this problem. Firstly, a word\nlevel LSTM encoder is conducted to obtain the initial representation of each\ncontext. Then, the self-attention mechanism is utilized to update both the\ncontext and masked response representation. Finally, the attention weights\nbetween each context and response representations are computed and used in the\nfurther decoding process. Experimental results on both Chinese customer\nservices dataset and English Ubuntu dialogue dataset show that ReCoSa\nsignificantly outperforms baseline models, in terms of both metric-based and\nhuman evaluations. Further analysis on attention shows that the detected\nrelevant contexts by ReCoSa are highly coherent with human's understanding,\nvalidating the correctness and interpretability of ReCoSa.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jul 2019 04:11:15 GMT"}], "update_date": "2019-07-12", "authors_parsed": [["Zhang", "Hainan", ""], ["Lan", "Yanyan", ""], ["Pang", "Liang", ""], ["Guo", "Jiafeng", ""], ["Cheng", "Xueqi", ""]]}, {"id": "1907.05346", "submitter": "Jiahuan Pei", "authors": "Jiahuan Pei, Pengjie Ren, Maarten de Rijke", "title": "A Modular Task-oriented Dialogue System Using a Neural\n  Mixture-of-Experts", "comments": "Proceedings of the 2019 SIGIR Workshop WCIS: Workshop on\n  Conversational Interaction Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  End-to-end Task-oriented Dialogue Systems (TDSs) have attracted a lot of\nattention for their superiority (e.g., in terms of global optimization) over\npipeline modularized TDSs. Previous studies on end-to-end TDSs use a\nsingle-module model to generate responses for complex dialogue contexts.\nHowever, no model consistently outperforms the others in all cases. We propose\na neural Modular Task-oriented Dialogue System(MTDS) framework, in which a few\nexpert bots are combined to generate the response for a given dialogue context.\nMTDS consists of a chair bot and several expert bots. Each expert bot is\nspecialized for a particular situation, e.g., one domain, one type of action of\na system, etc. The chair bot coordinates multiple expert bots and adaptively\nselects an expert bot to generate the appropriate response. We further propose\na Token-level Mixture-of-Expert (TokenMoE) model to implement MTDS, where the\nexpert bots predict multiple tokens at each timestamp and the chair bot\ndetermines the final generated token by fully taking into consideration the\noutputs of all expert bots. Both the chair bot and the expert bots are jointly\ntrained in an end-to-end fashion. To verify the effectiveness of TokenMoE, we\ncarry out extensive experiments on a benchmark dataset. Compared with the\nbaseline using a single-module model, our TokenMoE improves the performance by\n8.1% of inform rate and 0.8% of success rate.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jul 2019 13:25:50 GMT"}], "update_date": "2019-07-12", "authors_parsed": [["Pei", "Jiahuan", ""], ["Ren", "Pengjie", ""], ["de Rijke", "Maarten", ""]]}, {"id": "1907.05358", "submitter": "Ankit Gupta", "authors": "Ankit Gupta", "title": "StrokeSave: A Novel, High-Performance Mobile Application for Stroke\n  Diagnosis using Deep Learning and Computer Vision", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  According to the WHO, Cerebrovascular Stroke, or CS, is the second largest\ncause of death worldwide. Current diagnosis of CS relies on labor and cost\nintensive neuroimaging techniques, unsuitable for areas with inadequate access\nto quality medical facilities. Thus, there is a great need for an efficient\ndiagnosis alternative. StrokeSave is a platform for users to self-diagnose for\nprevalence to stroke. The mobile app is continuously updated with heart rate,\nblood pressure, and blood oxygen data from sensors on the patient wrist. Once\nthese measurements reach a threshold for possible stroke, the patient takes\nfacial images and vocal recordings to screen for paralysis attributed to\nstroke. A custom designed lens attached to a phone's camera then takes retinal\nimages for the deep learning model to classify based on presence of retinopathy\nand sends a comprehensive diagnosis. The deep learning model, which consists of\na RNN trained on 100 voice slurred audio files, a SVM trained on 410 vascular\ndata points, and a CNN trained on 520 retinopathy images, achieved a holistic\naccuracy of 95.0 percent when validated on 327 samples. This value exceeds that\nof clinical examination accuracy, which is around 40 to 89 percent, further\ndemonstrating the vital utility of such a medical device. Through this\nautomated platform, users receive efficient, highly accurate diagnosis without\nprofessional medical assistance, revolutionizing medical diagnosis of CS and\npotentially saving millions of lives.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jul 2019 21:01:58 GMT"}], "update_date": "2019-07-12", "authors_parsed": [["Gupta", "Ankit", ""]]}, {"id": "1907.05363", "submitter": "Gianluca Truda", "authors": "Gianluca Truda, Patrick Marais", "title": "Warfarin dose estimation on multiple datasets with automated\n  hyperparameter optimisation and a novel software framework", "comments": "19 pages, 4 tables, 3 figures", "journal-ref": "Journal of Biomedical Informatics, 2020", "doi": "10.1016/j.jbi.2020.103634", "report-no": null, "categories": "q-bio.QM cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Warfarin is an effective preventative treatment for arterial and venous\nthromboembolism, but requires individualised dosing due to its narrow\ntherapeutic range and high individual variation. Many machine learning\ntechniques have been demonstrated in this domain. This study evaluated the\naccuracy of the most promising algorithms on the International Warfarin\nPharmacogenetics Consortium dataset and a novel clinical dataset of South\nAfrican patients. Support vectors and linear regression were amongst the top\nperformers in both datasets and performed comparably to recent stacked ensemble\napproaches, whilst neural networks were one of the worst performers in both\ndatasets. We also introduced genetic programming to automatically optimise\nmodel architectures and hyperparameters without human guidance. Remarkably, the\ngenerated models were found to match the performance of the best models\nhand-crafted by human experts. Finally, we present a novel software framework\n(Warfit-learn) for warfarin dosing research. It leverages the most successful\ntechniques in preprocessing, imputation, and parallel evaluation, with the goal\nof accelerating research and making results in this domain more reproducible.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jul 2019 16:35:28 GMT"}, {"version": "v2", "created": "Sat, 23 Nov 2019 14:48:30 GMT"}, {"version": "v3", "created": "Thu, 23 Jul 2020 15:01:04 GMT"}, {"version": "v4", "created": "Mon, 26 Oct 2020 20:38:08 GMT"}], "update_date": "2020-12-02", "authors_parsed": [["Truda", "Gianluca", ""], ["Marais", "Patrick", ""]]}, {"id": "1907.05364", "submitter": "Felix Batsch", "authors": "Felix Batsch, Alireza Daneshkhah, Madeline Cheah, Stratis Kanarachos,\n  Anthony Baxendale", "title": "Performance Boundary Identification for the Evaluation of Automated\n  Vehicles using Gaussian Process Classification", "comments": "6 pages, 5 figures, accepted at 2019 IEEE Intelligent Transportation\n  Systems Conference - ITSC 2019, Auckland, New Zealand, October 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Safety is an essential aspect in the facilitation of automated vehicle\ndeployment. Current testing practices are not enough, and going beyond them\nleads to infeasible testing requirements, such as needing to drive billions of\nkilometres on public roads. Automated vehicles are exposed to an indefinite\nnumber of scenarios. Handling of the most challenging scenarios should be\ntested, which leads to the question of how such corner cases can be determined.\nWe propose an approach to identify the performance boundary, where these corner\ncases are located, using Gaussian Process Classification. We also demonstrate\nthe classification on an exemplary traffic jam approach scenario, showing that\nit is feasible and would lead to more efficient testing practices.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jul 2019 16:35:59 GMT"}], "update_date": "2019-07-12", "authors_parsed": [["Batsch", "Felix", ""], ["Daneshkhah", "Alireza", ""], ["Cheah", "Madeline", ""], ["Kanarachos", "Stratis", ""], ["Baxendale", "Anthony", ""]]}, {"id": "1907.05375", "submitter": "Tarlan Suleymanov", "authors": "Tarlan Suleymanov, Lars Kunze and Paul Newman", "title": "Online Inference and Detection of Curbs in Partially Occluded Scenes\n  with Sparse LIDAR", "comments": "Accepted at the 22nd IEEE Intelligent Transportation Systems\n  Conference (ITSC19), October, 2019, Auckland, New Zealand", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Road boundaries, or curbs, provide autonomous vehicles with essential\ninformation when interpreting road scenes and generating behaviour plans.\nAlthough curbs convey important information, they are difficult to detect in\ncomplex urban environments (in particular in comparison to other elements of\nthe road such as traffic signs and road markings). These difficulties arise\nfrom occlusions by other traffic participants as well as changing lighting\nand/or weather conditions. Moreover, road boundaries have various shapes,\ncolours and structures while motion planning algorithms require accurate and\nprecise metric information in real-time to generate their plans.\n  In this paper, we present a real-time LIDAR-based approach for accurate curb\ndetection around the vehicle (360 degree). Our approach deals with both\nocclusions from traffic and changing environmental conditions. To this end, we\nproject 3D LIDAR pointcloud data into 2D bird's-eye view images (akin to\nInverse Perspective Mapping). These images are then processed by trained deep\nnetworks to infer both visible and occluded road boundaries. Finally, a\npost-processing step filters detected curb segments and tracks them over time.\nExperimental results demonstrate the effectiveness of the proposed approach on\nreal-world driving data. Hence, we believe that our LIDAR-based approach\nprovides an efficient and effective way to detect visible and occluded curbs\naround the vehicles in challenging driving scenarios.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jul 2019 16:50:38 GMT"}], "update_date": "2019-07-12", "authors_parsed": [["Suleymanov", "Tarlan", ""], ["Kunze", "Lars", ""], ["Newman", "Paul", ""]]}, {"id": "1907.05378", "submitter": "Yassine Hamoudi", "authors": "Yassine Hamoudi, Patrick Rebentrost, Ansis Rosmanis, Miklos Santha", "title": "Quantum and Classical Algorithms for Approximate Submodular Function\n  Minimization", "comments": "24 pages, Journal version", "journal-ref": "Quantum Information & Computation, vol. 19, pp. 1325-1349 (2019)", "doi": null, "report-no": null, "categories": "cs.DS cs.LG math.OC quant-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Submodular functions are set functions mapping every subset of some ground\nset of size $n$ into the real numbers and satisfying the diminishing returns\nproperty. Submodular minimization is an important field in discrete\noptimization theory due to its relevance for various branches of mathematics,\ncomputer science and economics. The currently fastest strongly polynomial\nalgorithm for exact minimization [LSW15] runs in time $\\widetilde{O}(n^3 \\cdot\n\\mathrm{EO} + n^4)$ where $\\mathrm{EO}$ denotes the cost to evaluate the\nfunction on any set. For functions with range $[-1,1]$, the best\n$\\epsilon$-additive approximation algorithm [CLSW17] runs in time\n$\\widetilde{O}(n^{5/3}/\\epsilon^{2} \\cdot \\mathrm{EO})$. In this paper we\npresent a classical and a quantum algorithm for approximate submodular\nminimization. Our classical result improves on the algorithm of [CLSW17] and\nruns in time $\\widetilde{O}(n^{3/2}/\\epsilon^2 \\cdot \\mathrm{EO})$. Our quantum\nalgorithm is, up to our knowledge, the first attempt to use quantum computing\nfor submodular optimization. The algorithm runs in time\n$\\widetilde{O}(n^{5/4}/\\epsilon^{5/2} \\cdot \\log(1/\\epsilon) \\cdot\n\\mathrm{EO})$. The main ingredient of the quantum result is a new method for\nsampling with high probability $T$ independent elements from any discrete\nprobability distribution of support size $n$ in time $O(\\sqrt{Tn})$. Previous\nquantum algorithms for this problem were of complexity $O(T\\sqrt{n})$.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jul 2019 16:54:20 GMT"}, {"version": "v2", "created": "Wed, 15 Jan 2020 10:42:39 GMT"}], "update_date": "2020-01-16", "authors_parsed": [["Hamoudi", "Yassine", ""], ["Rebentrost", "Patrick", ""], ["Rosmanis", "Ansis", ""], ["Santha", "Miklos", ""]]}, {"id": "1907.05380", "submitter": "Marija Vella", "authors": "Marija Vella, Jo\\~ao F. C. Mota", "title": "Single Image Super-Resolution via CNN Architectures and TV-TV\n  Minimization", "comments": "Accepted to BMVC 2019; v2 contains updated results and minor bug\n  fixes", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Super-resolution (SR) is a technique that allows increasing the resolution of\na given image. Having applications in many areas, from medical imaging to\nconsumer electronics, several SR methods have been proposed. Currently, the\nbest performing methods are based on convolutional neural networks (CNNs) and\nrequire extensive datasets for training. However, at test time, they fail to\nimpose consistency between the super-resolved image and the given\nlow-resolution image, a property that classic reconstruction-based algorithms\nnaturally enforce in spite of having poorer performance. Motivated by this\nobservation, we propose a new framework that joins both approaches and produces\nimages with superior quality than any of the prior methods. Although our\nframework requires additional computation, our experiments on Set5, Set14, and\nBSD100 show that it systematically produces images with better peak signal to\nnoise ratio (PSNR) and structural similarity (SSIM) than the current\nstate-of-the-art CNN architectures for SR.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jul 2019 16:57:59 GMT"}, {"version": "v2", "created": "Wed, 27 Nov 2019 21:32:39 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Vella", "Marija", ""], ["Mota", "Jo\u00e3o F. C.", ""]]}, {"id": "1907.05388", "submitter": "Chi Jin", "authors": "Chi Jin, Zhuoran Yang, Zhaoran Wang, Michael I. Jordan", "title": "Provably Efficient Reinforcement Learning with Linear Function\n  Approximation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern Reinforcement Learning (RL) is commonly applied to practical problems\nwith an enormous number of states, where function approximation must be\ndeployed to approximate either the value function or the policy. The\nintroduction of function approximation raises a fundamental set of challenges\ninvolving computational and statistical efficiency, especially given the need\nto manage the exploration/exploitation tradeoff. As a result, a core RL\nquestion remains open: how can we design provably efficient RL algorithms that\nincorporate function approximation? This question persists even in a basic\nsetting with linear dynamics and linear rewards, for which only linear function\napproximation is needed.\n  This paper presents the first provable RL algorithm with both polynomial\nruntime and polynomial sample complexity in this linear setting, without\nrequiring a \"simulator\" or additional assumptions. Concretely, we prove that an\noptimistic modification of Least-Squares Value Iteration (LSVI)---a classical\nalgorithm frequently studied in the linear setting---achieves\n$\\tilde{\\mathcal{O}}(\\sqrt{d^3H^3T})$ regret, where $d$ is the ambient\ndimension of feature space, $H$ is the length of each episode, and $T$ is the\ntotal number of steps. Importantly, such regret is independent of the number of\nstates and actions.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jul 2019 17:06:11 GMT"}, {"version": "v2", "created": "Thu, 8 Aug 2019 07:23:12 GMT"}], "update_date": "2019-08-09", "authors_parsed": [["Jin", "Chi", ""], ["Yang", "Zhuoran", ""], ["Wang", "Zhaoran", ""], ["Jordan", "Michael I.", ""]]}, {"id": "1907.05401", "submitter": "Omid Etesami", "authors": "Omid Etesami, Saeed Mahloujifar, Mohammad Mahmoody", "title": "Computational Concentration of Measure: Optimal Bounds, Reductions, and\n  More", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.CG cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Product measures of dimension $n$ are known to be concentrated in Hamming\ndistance: for any set $S$ in the product space of probability $\\epsilon$, a\nrandom point in the space, with probability $1-\\delta$, has a neighbor in $S$\nthat is different from the original point in only\n$O(\\sqrt{n\\ln(1/(\\epsilon\\delta))})$ coordinates. We obtain the tight\ncomputational version of this result, showing how given a random point and\naccess to an $S$-membership oracle, we can find such a close point in\npolynomial time. This resolves an open question of [Mahloujifar and Mahmoody,\nALT 2019]. As corollaries, we obtain polynomial-time poisoning and (in certain\nsettings) evasion attacks against learning algorithms when the original\nvulnerabilities have any cryptographically non-negligible probability.\n  We call our algorithm MUCIO (\"MUltiplicative Conditional Influence\nOptimizer\") since proceeding through the coordinates, it decides to change each\ncoordinate of the given point based on a multiplicative version of the\ninfluence of that coordinate, where influence is computed conditioned on\npreviously updated coordinates.\n  We also define a new notion of algorithmic reduction between computational\nconcentration of measure in different metric probability spaces. As an\napplication, we get computational concentration of measure for high-dimensional\nGaussian distributions under the $\\ell_1$ metric.\n  We prove several extensions to the results above: (1) Our computational\nconcentration result is also true when the Hamming distance is weighted. (2) We\nobtain an algorithmic version of concentration around mean, more specifically,\nMcDiarmid's inequality. (3) Our result generalizes to discrete random\nprocesses, and this leads to new tampering algorithms for collective coin\ntossing protocols. (4) We prove exponential lower bounds on the average running\ntime of non-adaptive query algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jul 2019 17:33:03 GMT"}], "update_date": "2019-07-12", "authors_parsed": [["Etesami", "Omid", ""], ["Mahloujifar", "Saeed", ""], ["Mahmoody", "Mohammad", ""]]}, {"id": "1907.05409", "submitter": "Solt Kov\\'acs", "authors": "Malte Londschien, Solt Kov\\'acs, Peter B\\\"uhlmann", "title": "Change point detection for graphical models in the presence of missing\n  values", "comments": "14 pages, 6 figures, 3 tables, hdcd R package; added explanations and\n  clarifications, methodology and simulation results unchanged", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose estimation methods for change points in high-dimensional\ncovariance structures with an emphasis on challenging scenarios with missing\nvalues. We advocate three imputation like methods and investigate their\nimplications on common losses used for change point detection. We also discuss\nhow model selection methods have to be adapted to the setting of incomplete\ndata. The methods are compared in a simulation study and applied to a time\nseries from an environmental monitoring system. An implementation of our\nproposals within the R-package hdcd is available via the Supplementary\nmaterials.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jul 2019 17:50:47 GMT"}, {"version": "v2", "created": "Thu, 22 Oct 2020 20:51:57 GMT"}], "update_date": "2020-10-26", "authors_parsed": [["Londschien", "Malte", ""], ["Kov\u00e1cs", "Solt", ""], ["B\u00fchlmann", "Peter", ""]]}, {"id": "1907.05415", "submitter": "Guillaume Verdon", "authors": "Guillaume Verdon, Michael Broughton, Jarrod R. McClean, Kevin J. Sung,\n  Ryan Babbush, Zhang Jiang, Hartmut Neven, Masoud Mohseni", "title": "Learning to learn with quantum neural networks via classical neural\n  networks", "comments": "12 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantum Neural Networks (QNNs) are a promising variational learning paradigm\nwith applications to near-term quantum processors, however they still face some\nsignificant challenges. One such challenge is finding good parameter\ninitialization heuristics that ensure rapid and consistent convergence to local\nminima of the parameterized quantum circuit landscape. In this work, we train\nclassical neural networks to assist in the quantum learning process, also know\nas meta-learning, to rapidly find approximate optima in the parameter landscape\nfor several classes of quantum variational algorithms. Specifically, we train\nclassical recurrent neural networks to find approximately optimal parameters\nwithin a small number of queries of the cost function for the Quantum\nApproximate Optimization Algorithm (QAOA) for MaxCut, QAOA for\nSherrington-Kirkpatrick Ising model, and for a Variational Quantum Eigensolver\nfor the Hubbard model. By initializing other optimizers at parameter values\nsuggested by the classical neural network, we demonstrate a significant\nimprovement in the total number of optimization iterations required to reach a\ngiven accuracy. We further demonstrate that the optimization strategies learned\nby the neural network generalize well across a range of problem instance sizes.\nThis opens up the possibility of training on small, classically simulatable\nproblem instances, in order to initialize larger, classically intractably\nsimulatable problem instances on quantum devices, thereby significantly\nreducing the number of required quantum-classical optimization iterations.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jul 2019 17:57:56 GMT"}], "update_date": "2019-07-12", "authors_parsed": [["Verdon", "Guillaume", ""], ["Broughton", "Michael", ""], ["McClean", "Jarrod R.", ""], ["Sung", "Kevin J.", ""], ["Babbush", "Ryan", ""], ["Jiang", "Zhang", ""], ["Neven", "Hartmut", ""], ["Mohseni", "Masoud", ""]]}, {"id": "1907.05418", "submitter": "Dawei Yang", "authors": "Yulong Cao, Chaowei Xiao, Dawei Yang, Jing Fang, Ruigang Yang, Mingyan\n  Liu, Bo Li", "title": "Adversarial Objects Against LiDAR-Based Autonomous Driving Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) are found to be vulnerable against adversarial\nexamples, which are carefully crafted inputs with a small magnitude of\nperturbation aiming to induce arbitrarily incorrect predictions. Recent studies\nshow that adversarial examples can pose a threat to real-world\nsecurity-critical applications: a \"physical adversarial Stop Sign\" can be\nsynthesized such that the autonomous driving cars will misrecognize it as\nothers (e.g., a speed limit sign). However, these image-space adversarial\nexamples cannot easily alter 3D scans of widely equipped LiDAR or radar on\nautonomous vehicles. In this paper, we reveal the potential vulnerabilities of\nLiDAR-based autonomous driving detection systems, by proposing an optimization\nbased approach LiDAR-Adv to generate adversarial objects that can evade the\nLiDAR-based detection system under various conditions. We first show the\nvulnerabilities using a blackbox evolution-based algorithm, and then explore\nhow much a strong adversary can do, using our gradient-based approach\nLiDAR-Adv. We test the generated adversarial objects on the Baidu Apollo\nautonomous driving platform and show that such physical systems are indeed\nvulnerable to the proposed attacks. We also 3D-print our adversarial objects\nand perform physical experiments to illustrate that such vulnerability exists\nin the real world. Please find more visualizations and results on the anonymous\nwebsite: https://sites.google.com/view/lidar-adv.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jul 2019 17:59:13 GMT"}], "update_date": "2019-07-12", "authors_parsed": [["Cao", "Yulong", ""], ["Xiao", "Chaowei", ""], ["Yang", "Dawei", ""], ["Fang", "Jing", ""], ["Yang", "Ruigang", ""], ["Liu", "Mingyan", ""], ["Li", "Bo", ""]]}, {"id": "1907.05431", "submitter": "Abhinav Verma", "authors": "Abhinav Verma, Hoang M. Le, Yisong Yue, Swarat Chaudhuri", "title": "Imitation-Projected Programmatic Reinforcement Learning", "comments": "Published in Advances in Neural Information Processing Systems\n  (NeurIPS) 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.PL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of programmatic reinforcement learning, in which\npolicies are represented as short programs in a symbolic language. Programmatic\npolicies can be more interpretable, generalizable, and amenable to formal\nverification than neural policies; however, designing rigorous learning\napproaches for such policies remains a challenge. Our approach to this\nchallenge -- a meta-algorithm called PROPEL -- is based on three insights.\nFirst, we view our learning task as optimization in policy space, modulo the\nconstraint that the desired policy has a programmatic representation, and solve\nthis optimization problem using a form of mirror descent that takes a gradient\nstep into the unconstrained policy space and then projects back onto the\nconstrained space. Second, we view the unconstrained policy space as mixing\nneural and programmatic representations, which enables employing\nstate-of-the-art deep policy gradient approaches. Third, we cast the projection\nstep as program synthesis via imitation learning, and exploit contemporary\ncombinatorial methods for this task. We present theoretical convergence results\nfor PROPEL and empirically evaluate the approach in three continuous control\ndomains. The experiments show that PROPEL can significantly outperform\nstate-of-the-art approaches for learning programmatic policies.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jul 2019 18:00:56 GMT"}, {"version": "v2", "created": "Wed, 23 Oct 2019 05:14:08 GMT"}, {"version": "v3", "created": "Mon, 4 Nov 2019 12:32:34 GMT"}, {"version": "v4", "created": "Tue, 19 Jan 2021 20:52:42 GMT"}], "update_date": "2021-01-21", "authors_parsed": [["Verma", "Abhinav", ""], ["Le", "Hoang M.", ""], ["Yue", "Yisong", ""], ["Chaudhuri", "Swarat", ""]]}, {"id": "1907.05442", "submitter": "Farig Sadeque", "authors": "Farig Sadeque, Steven Bethard", "title": "Predicting engagement in online social networks: Challenges and\n  opportunities", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CY cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Since the introduction of social media, user participation or engagement has\nreceived little research attention. In this survey article, we establish the\nnotion of participation in social media and main challenges that researchers\nmay face while exploring this phenomenon. We surveyed a handful of research\narticles that had been done in this area, and tried to extract, analyze and\nsummarize the techniques performed by the researchers. We classified these\nworks based on our task definitions, and explored the machine learning models\nthat have been used for any kind of participation prediction. We also explored\nthe vast amount of features that have been proven useful, and classified them\ninto categories for better understanding and ease of re-implementation. We have\nfound that the success of a technique mostly depends on the type of the network\nthat has been researched on, and there is no universal machine learning\nalgorithm or feature sets that works reasonably well in all types of social\nmedia. There is a lack of attempts in implementing state-of-the-art machine\nlearning techniques like neural networks, and the possibility of transfer\nlearning and domain adaptation has not been explored.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jul 2019 18:27:40 GMT"}], "update_date": "2019-07-15", "authors_parsed": [["Sadeque", "Farig", ""], ["Bethard", "Steven", ""]]}, {"id": "1907.05443", "submitter": "Stratos Idreos", "authors": "Stratos Idreos, Niv Dayan, Wilson Qin, Mali Akmanalp, Sophie Hilgard,\n  Andrew Ross, James Lennon, Varun Jain, Harshita Gupta, David Li, Zichen Zhu", "title": "Learning Key-Value Store Design", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the concept of design continuums for the data layout of\nkey-value stores. A design continuum unifies major distinct data structure\ndesigns under the same model. The critical insight and potential long-term\nimpact is that such unifying models 1) render what we consider up to now as\nfundamentally different data structures to be seen as views of the very same\noverall design space, and 2) allow seeing new data structure designs with\nperformance properties that are not feasible by existing designs. The core\nintuition behind the construction of design continuums is that all data\nstructures arise from the very same set of fundamental design principles, i.e.,\na small set of data layout design concepts out of which we can synthesize any\ndesign that exists in the literature as well as new ones. We show how to\nconstruct, evaluate, and expand, design continuums and we also present the\nfirst continuum that unifies major data structure designs, i.e., B+tree,\nB-epsilon-tree, LSM-tree, and LSH-table.\n  The practical benefit of a design continuum is that it creates a fast\ninference engine for the design of data structures. For example, we can predict\nnear instantly how a specific design change in the underlying storage of a data\nsystem would affect performance, or reversely what would be the optimal data\nstructure (from a given set of designs) given workload characteristics and a\nmemory budget. In turn, these properties allow us to envision a new class of\nself-designing key-value stores with a substantially improved ability to adapt\nto workload and hardware changes by transitioning between drastically different\ndata structure designs to assume a diverse set of performance properties at\nwill.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jul 2019 18:35:39 GMT"}], "update_date": "2019-07-15", "authors_parsed": [["Idreos", "Stratos", ""], ["Dayan", "Niv", ""], ["Qin", "Wilson", ""], ["Akmanalp", "Mali", ""], ["Hilgard", "Sophie", ""], ["Ross", "Andrew", ""], ["Lennon", "James", ""], ["Jain", "Varun", ""], ["Gupta", "Harshita", ""], ["Li", "David", ""], ["Zhu", "Zichen", ""]]}, {"id": "1907.05444", "submitter": "Alon Brutzkus", "authors": "Alon Brutzkus, Amit Daniely, Eran Malach", "title": "On the Optimality of Trees Generated by ID3", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Since its inception in the 1980s, ID3 has become one of the most successful\nand widely used algorithms for learning decision trees. However, its\ntheoretical properties remain poorly understood. In this work, we introduce a\nnovel metric of a decision tree algorithm's performance, called mean iteration\nstatistical consistency (MIC), which measures optimality of trees generated by\nID3. As opposed to previous metrics, MIC can differentiate between different\ndecision tree algorithms and compare their performance. We provide theoretical\nand empirical evidence that the TopDown variant of ID3, introduced by Kearns\nand Mansour (1996), has near-optimal MIC in various settings for learning\nread-once DNFs under product distributions. In contrast, another widely used\nvariant of ID3 has MIC which is not near-optimal. We show that the MIC analysis\npredicts well the performance of these algorithms in practice. Our results\npresent a novel view of decision tree algorithms which may lead to better and\nmore practical guarantees for these algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jul 2019 18:40:25 GMT"}, {"version": "v2", "created": "Sun, 23 Feb 2020 09:55:17 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Brutzkus", "Alon", ""], ["Daniely", "Amit", ""], ["Malach", "Eran", ""]]}, {"id": "1907.05447", "submitter": "John Hooker", "authors": "Tae Wan Kim, Thomas Donaldson, John Hooker", "title": "Grounding Value Alignment with Ethical Principles", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An important step in the development of value alignment (VA) systems in AI is\nunderstanding how values can interrelate with facts. Designers of future VA\nsystems will need to utilize a hybrid approach in which ethical reasoning and\nempirical observation interrelate successfully in machine behavior. In this\narticle we identify two problems about this interrelation that have been\noverlooked by AI discussants and designers. The first problem is that many AI\ndesigners commit inadvertently a version of what has been called by moral\nphilosophers the \"naturalistic fallacy,\" that is, they attempt to derive an\n\"ought\" from an \"is.\" We illustrate when and why this occurs. The second\nproblem is that AI designers adopt training routines that fail fully to\nsimulate human ethical reasoning in the integration of ethical principles and\nfacts. Using concepts of quantified modal logic, we proceed to offer an\napproach that promises to simulate ethical reasoning in humans by connecting\nethical principles on the one hand and propositions about states of affairs on\nthe other.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jul 2019 18:55:47 GMT"}], "update_date": "2019-07-15", "authors_parsed": [["Kim", "Tae Wan", ""], ["Donaldson", "Thomas", ""], ["Hooker", "John", ""]]}, {"id": "1907.05476", "submitter": "Marco Loog", "authors": "Marco Loog, Tom Viering, Alexander Mey", "title": "Minimizers of the Empirical Risk and Risk Monotonicity", "comments": "New version fixes some minor issues especially in the proof of\n  Theorem 1", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Plotting a learner's average performance against the number of training\nsamples results in a learning curve. Studying such curves on one or more data\nsets is a way to get to a better understanding of the generalization properties\nof this learner. The behavior of learning curves is, however, not very well\nunderstood and can display (for most researchers) quite unexpected behavior.\nOur work introduces the formal notion of \\emph{risk monotonicity}, which asks\nthe risk to not deteriorate with increasing training set sizes in expectation\nover the training samples. We then present the surprising result that various\nstandard learners, specifically those that minimize the empirical risk, can act\n\\emph{non}monotonically irrespective of the training sample size. We provide a\ntheoretical underpinning for specific instantiations from classification,\nregression, and density estimation. Altogether, the proposed monotonicity\nnotion opens up a whole new direction of research.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jul 2019 20:18:19 GMT"}, {"version": "v2", "created": "Sat, 21 Sep 2019 11:33:19 GMT"}, {"version": "v3", "created": "Mon, 6 Jan 2020 16:18:37 GMT"}, {"version": "v4", "created": "Fri, 13 Mar 2020 08:36:37 GMT"}], "update_date": "2020-03-16", "authors_parsed": [["Loog", "Marco", ""], ["Viering", "Tom", ""], ["Mey", "Alexander", ""]]}, {"id": "1907.05496", "submitter": "Hai Xiao", "authors": "Hai Xiao", "title": "Online Learning to Estimate Warfarin Dose with Contextual Linear Bandits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Warfarin is one of the most commonly used oral blood anticoagulant agent in\nthe world, the proper dose of Warfarin is difficult to establish not only\nbecause it is substantially variant among patients, but also adverse even\nsevere consequences of taking an incorrect dose. Typical practice is to\nprescribe an initial dose, then doctor closely monitor patient response and\nadjust accordingly to the correct dosage. The three commonly used strategies\nfor an initial dosage are the fixed-dose approach, the Warfarin Clinical\nalgorithm, and the Pharmacogenetic algorithm developed by the IWPC\n(International Warfarin Pharmacogenetics Consortium). It is always best to\nprescribe correct initial dosage, motivated by this challenge, this work\nexplores the performance of multi-armed bandit algorithms to best predict the\ncorrect dosage of Warfarin instead of trial-and-error procedure. Real data from\nthe Pharmacogenetics and Pharmacogenomics Knowledge Base (PharmGKB) is used,\nwith it a series of linear bandit algorithms and variants are developed and\nevaluated on Warfarin dataset. All proposed algorithms outperformed the\nfixed-dose baseline algorithm, and some even matched up the Warfarin Clinical\nDosing Algorithm. In addition, a few promising future directions are given for\nfurther exploration and development.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jul 2019 21:27:24 GMT"}], "update_date": "2019-07-15", "authors_parsed": [["Xiao", "Hai", ""]]}, {"id": "1907.05505", "submitter": "Iman Tabrizian", "authors": "Saeedeh Parsaeefard, Iman Tabrizian, Alberto Leon-Garcia", "title": "Artificial Intelligence as a Services (AI-aaS) on Software-Defined\n  Infrastructure", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates a paradigm for offering artificial intelligence as a\nservice (AI-aaS) on software-defined infrastructures (SDIs). The increasing\ncomplexity of networking and computing infrastructures is already driving the\nintroduction of automation in networking and cloud computing management\nsystems. Here we consider how these automation mechanisms can be leveraged to\noffer AI-aaS. Use cases for AI-aaS are easily found in addressing smart\napplications in sectors such as transportation, manufacturing, energy, water,\nair quality, and emissions. We propose an architectural scheme based on SDIs\nwhere each AI-aaS application is comprised of a monitoring, analysis, policy,\nexecution plus knowledge (MAPE-K) loop (MKL). Each application is composed as\none or more specific service chains embedded in SDI, some of which will include\na Machine Learning (ML) pipeline. Our model includes a new training plane and\nan AI-aaS plane to deal with the model-development and operational phases of AI\napplications. We also consider the role of an ML/MKL sandbox in ensuring\ncoherency and consistency in the operation of multiple parallel MKL loops. We\npresent experimental measurement results for three AI-aaS applications deployed\non the SAVI testbed: 1. Compressing monitored data in SDI using autoencoders;\n2. Traffic monitoring to allocate CPUs resources to VNFs; and 3. Highway\nsegment classification in smart transportation.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jul 2019 22:02:18 GMT"}], "update_date": "2019-07-15", "authors_parsed": [["Parsaeefard", "Saeedeh", ""], ["Tabrizian", "Iman", ""], ["Leon-Garcia", "Alberto", ""]]}, {"id": "1907.05514", "submitter": "Sing-Ho Bae", "authors": "Abdul Muqeet, Md Tauhid Bin Iqbal, and Sung-Ho Bae", "title": "Hybrid Residual Attention Network for Single Image Super Resolution", "comments": "12 pages, 5 figures", "journal-ref": null, "doi": "10.1109/ACCESS.2019.2942346", "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The extraction and proper utilization of convolution neural network (CNN)\nfeatures have a significant impact on the performance of image super-resolution\n(SR). Although CNN features contain both the spatial and channel information,\ncurrent deep techniques on SR often suffer to maximize performance due to using\neither the spatial or channel information. Moreover, they integrate such\ninformation within a deep or wide network rather than exploiting all the\navailable features, eventually resulting in high computational complexity. To\naddress these issues, we present a binarized feature fusion (BFF) structure\nthat utilizes the extracted features from residual groups (RG) in an effective\nway. Each residual group (RG) consists of multiple hybrid residual attention\nblocks (HRAB) that effectively integrates the multiscale feature extraction\nmodule and channel attention mechanism in a single block. Furthermore, we use\ndilated convolutions with different dilation factors to extract multiscale\nfeatures. We also propose to adopt global, short and long skip connections and\nresidual groups (RG) structure to ease the flow of information without losing\nimportant features details. In the paper, we call this overall network\narchitecture as hybrid residual attention network (HRAN). In the experiment, we\nhave observed the efficacy of our method against the state-of-the-art methods\nfor both the quantitative and qualitative comparisons.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jul 2019 22:48:23 GMT"}], "update_date": "2019-10-23", "authors_parsed": [["Muqeet", "Abdul", ""], ["Iqbal", "Md Tauhid Bin", ""], ["Bae", "Sung-Ho", ""]]}, {"id": "1907.05520", "submitter": "Shuang Li", "authors": "Shuang Li, Gongguo Tang, and Michael B. Wakin", "title": "The Landscape of Non-convex Empirical Risk with Degenerate Population\n  Risk", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.IT cs.LG math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The landscape of empirical risk has been widely studied in a series of\nmachine learning problems, including low-rank matrix factorization, matrix\nsensing, matrix completion, and phase retrieval. In this work, we focus on the\nsituation where the corresponding population risk is a degenerate non-convex\nloss function, namely, the Hessian of the population risk can have zero\neigenvalues. Instead of analyzing the non-convex empirical risk directly, we\nfirst study the landscape of the corresponding population risk, which is\nusually easier to characterize, and then build a connection between the\nlandscape of the empirical risk and its population risk. In particular, we\nestablish a correspondence between the critical points of the empirical risk\nand its population risk without the strongly Morse assumption, which is\nrequired in existing literature but not satisfied in degenerate scenarios. We\nalso apply the theory to matrix sensing and phase retrieval to demonstrate how\nto infer the landscape of empirical risk from that of the corresponding\npopulation risk.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jul 2019 23:16:30 GMT"}, {"version": "v2", "created": "Mon, 28 Oct 2019 02:02:56 GMT"}, {"version": "v3", "created": "Fri, 8 Nov 2019 19:56:34 GMT"}, {"version": "v4", "created": "Tue, 3 Dec 2019 17:48:28 GMT"}], "update_date": "2019-12-04", "authors_parsed": [["Li", "Shuang", ""], ["Tang", "Gongguo", ""], ["Wakin", "Michael B.", ""]]}, {"id": "1907.05550", "submitter": "Dami Choi", "authors": "Dami Choi, Alexandre Passos, Christopher J. Shallue, George E. Dahl", "title": "Faster Neural Network Training with Data Echoing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the twilight of Moore's law, GPUs and other specialized hardware\naccelerators have dramatically sped up neural network training. However,\nearlier stages of the training pipeline, such as disk I/O and data\npreprocessing, do not run on accelerators. As accelerators continue to improve,\nthese earlier stages will increasingly become the bottleneck. In this paper, we\nintroduce \"data echoing,\" which reduces the total computation used by earlier\npipeline stages and speeds up training whenever computation upstream from\naccelerators dominates the training time. Data echoing reuses (or \"echoes\")\nintermediate outputs from earlier pipeline stages in order to reclaim idle\ncapacity. We investigate the behavior of different data echoing algorithms on\nvarious workloads, for various amounts of echoing, and for various batch sizes.\nWe find that in all settings, at least one data echoing algorithm can match the\nbaseline's predictive performance using less upstream computation. We measured\na factor of 3.25 decrease in wall-clock time for ResNet-50 on ImageNet when\nreading training data over a network.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jul 2019 02:17:12 GMT"}, {"version": "v2", "created": "Sat, 4 Jan 2020 05:44:48 GMT"}, {"version": "v3", "created": "Fri, 8 May 2020 01:38:51 GMT"}], "update_date": "2020-05-11", "authors_parsed": [["Choi", "Dami", ""], ["Passos", "Alexandre", ""], ["Shallue", "Christopher J.", ""], ["Dahl", "George E.", ""]]}, {"id": "1907.05552", "submitter": "Usman Nazir", "authors": "Usman Nazir, Numan Khurshid, Muhammad Ahmed Bhimra, Murtaza Taj", "title": "Tiny-Inception-ResNet-v2: Using Deep Learning for Eliminating Bonded\n  Labors of Brick Kilns in South Asia", "comments": null, "journal-ref": "CVPR 2019 workshop", "doi": null, "report-no": null, "categories": "cs.CV cs.GR cs.LG", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  This paper proposes to employ a Inception-ResNet inspired deep learning\narchitecture called Tiny-Inception-ResNet-v2 to eliminate bonded labor by\nidentifying brick kilns within \"Brick-Kiln-Belt\" of South Asia. The framework\nis developed by training a network on the satellite imagery consisting of 11\ndifferent classes of South Asian region. The dataset developed during the\nprocess includes the geo-referenced images of brick kilns, houses, roads,\ntennis courts, farms, sparse trees, dense trees, orchards, parking lots, parks\nand barren lands. The dataset is made publicly available for further research.\nOur proposed network architecture with very fewer learning parameters\noutperforms all state-of-the-art architectures employed for recognition of\nbrick kilns. Our proposed solution would enable regional monitoring and\nevaluation mechanisms for the Sustainable Development Goals.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jul 2019 07:43:42 GMT"}], "update_date": "2019-07-15", "authors_parsed": [["Nazir", "Usman", ""], ["Khurshid", "Numan", ""], ["Bhimra", "Muhammad Ahmed", ""], ["Taj", "Murtaza", ""]]}, {"id": "1907.05553", "submitter": "Aras Dargazany", "authors": "Aras R. Dargazany", "title": "MLR (Memory, Learning and Recognition): A General Cognitive Model --\n  applied to Intelligent Robots and Systems Control", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CV cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a new perspective of intelligent robots and systems\ncontrol. The presented and proposed cognitive model: Memory, Learning and\nRecognition (MLR), is an effort to bridge the gap between Robotics, AI,\nCognitive Science, and Neuroscience. The currently existing gap prevents us\nfrom integrating the current advancement and achievements of these four\nresearch fields which are actively trying to define intelligence in either\napplication-based way or in generic way. This cognitive model defines\nintelligence more specifically, parametrically and detailed. The proposed MLR\nmodel helps us create a general control model for robots and systems\nindependent of their application domains and platforms since it is mainly based\non the dataset provided for robots and systems controls. This paper is mainly\nproposing and introducing this concept and trying to prove this concept in a\nsmall scale, firstly through experimentation. The proposed concept is also\napplicable to other different platforms in real-time as well as in simulation.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jul 2019 02:40:37 GMT"}], "update_date": "2019-07-15", "authors_parsed": [["Dargazany", "Aras R.", ""]]}, {"id": "1907.05572", "submitter": "Zhiwei Wang", "authors": "Zhiwei Wang, Yao Ma, Zitao Liu, Jiliang Tang", "title": "R-Transformer: Recurrent Neural Network Enhanced Transformer", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.CV eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent Neural Networks have long been the dominating choice for sequence\nmodeling. However, it severely suffers from two issues: impotent in capturing\nvery long-term dependencies and unable to parallelize the sequential\ncomputation procedure. Therefore, many non-recurrent sequence models that are\nbuilt on convolution and attention operations have been proposed recently.\nNotably, models with multi-head attention such as Transformer have demonstrated\nextreme effectiveness in capturing long-term dependencies in a variety of\nsequence modeling tasks. Despite their success, however, these models lack\nnecessary components to model local structures in sequences and heavily rely on\nposition embeddings that have limited effects and require a considerable amount\nof design efforts. In this paper, we propose the R-Transformer which enjoys the\nadvantages of both RNNs and the multi-head attention mechanism while avoids\ntheir respective drawbacks. The proposed model can effectively capture both\nlocal structures and global long-term dependencies in sequences without any use\nof position embeddings. We evaluate R-Transformer through extensive experiments\nwith data from a wide range of domains and the empirical results show that\nR-Transformer outperforms the state-of-the-art methods by a large margin in\nmost of the tasks. We have made the code publicly available at\n\\url{https://github.com/DSE-MSU/R-transformer}.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jul 2019 04:01:57 GMT"}], "update_date": "2019-07-15", "authors_parsed": [["Wang", "Zhiwei", ""], ["Ma", "Yao", ""], ["Liu", "Zitao", ""], ["Tang", "Jiliang", ""]]}, {"id": "1907.05576", "submitter": "Chuhan Wu", "authors": "Chuhan Wu, Fangzhao Wu, Mingxiao An, Jianqiang Huang, Yongfeng Huang,\n  Xing Xie", "title": "Neural News Recommendation with Attentive Multi-View Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Personalized news recommendation is very important for online news platforms\nto help users find interested news and improve user experience. News and user\nrepresentation learning is critical for news recommendation. Existing news\nrecommendation methods usually learn these representations based on single news\ninformation, e.g., title, which may be insufficient. In this paper we propose a\nneural news recommendation approach which can learn informative representations\nof users and news by exploiting different kinds of news information. The core\nof our approach is a news encoder and a user encoder. In the news encoder we\npropose an attentive multi-view learning model to learn unified news\nrepresentations from titles, bodies and topic categories by regarding them as\ndifferent views of news. In addition, we apply both word-level and view-level\nattention mechanism to news encoder to select important words and views for\nlearning informative news representations. In the user encoder we learn the\nrepresentations of users based on their browsed news and apply attention\nmechanism to select informative news for user representation learning.\nExtensive experiments on a real-world dataset show our approach can effectively\nimprove the performance of news recommendation.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jul 2019 04:50:33 GMT"}], "update_date": "2019-07-15", "authors_parsed": [["Wu", "Chuhan", ""], ["Wu", "Fangzhao", ""], ["An", "Mingxiao", ""], ["Huang", "Jianqiang", ""], ["Huang", "Yongfeng", ""], ["Xie", "Xing", ""]]}, {"id": "1907.05579", "submitter": "Yu Wang", "authors": "Yu Wang, Fengjuan Gao, Linzhang Wang, Ke Wang", "title": "Learning a Static Bug Finder from Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an alternative approach to creating static bug finders. Instead of\nrelying on human expertise, we utilize deep neural networks to train static\nanalyzers directly from data. In particular, we frame the problem of bug\nfinding as a classification task and train a classifier to differentiate the\nbuggy from non-buggy programs using Graph Neural Network (GNN). Crucially, we\npropose a novel interval-based propagation mechanism that leads to a\nsignificantly more efficient, accurate and scalable generalization of GNN.\n  We have realized our approach into a framework, NeurSA, and extensively\nevaluated it. In a cross-project prediction task, three neural bug detectors we\ninstantiate from NeurSA are effective in catching null pointer dereference,\narray index out of bound and class cast bugs in unseen code. We compare NeurSA\nagainst several static analyzers (e.g. Facebook Infer and Pinpoint) on a set of\nnull pointer dereference bugs. Results show that NeurSA is more precise in\ncatching the real bugs and suppressing the spurious warnings. We also apply\nNeurSA to several popular Java projects on GitHub and discover 50 new bugs,\namong which 9 have been fixed, and 3 have been confirmed.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jul 2019 05:34:20 GMT"}, {"version": "v2", "created": "Mon, 15 Jul 2019 03:15:19 GMT"}, {"version": "v3", "created": "Fri, 27 Mar 2020 03:35:07 GMT"}], "update_date": "2020-03-30", "authors_parsed": [["Wang", "Yu", ""], ["Gao", "Fengjuan", ""], ["Wang", "Linzhang", ""], ["Wang", "Ke", ""]]}, {"id": "1907.05584", "submitter": "Harishchandra Dubey", "authors": "Harishchandra Dubey, Abhijeet Sangwan and John Hansen", "title": "Toeplitz Inverse Covariance based Robust Speaker Clustering for\n  Naturalistic Audio Streams", "comments": "6 Pages, 3 Fiigures, 5 Equations", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Speaker diarization determines who spoke and when? in an audio stream. In\nthis study, we propose a model-based approach for robust speaker clustering\nusing i-vectors. The ivectors extracted from different segments of same speaker\nare correlated. We model this correlation with a Markov Random Field (MRF)\nnetwork. Leveraging the advancements in MRF modeling, we used Toeplitz Inverse\nCovariance (TIC) matrix to represent the MRF correlation network for each\nspeaker. This approaches captures the sequential structure of i-vectors (or\nequivalent speaker turns) belonging to same speaker in an audio stream. A\nvariant of standard Expectation Maximization (EM) algorithm is adopted for\nderiving closed-form solution using dynamic programming (DP) and the\nalternating direction method of multiplier (ADMM). Our diarization system has\nfour steps: (1) ground-truth segmentation; (2) i-vector extraction; (3)\npost-processing (mean subtraction, principal component analysis, and\nlength-normalization) ; and (4) proposed speaker clustering. We employ cosine\nK-means and movMF speaker clustering as baseline approaches. Our evaluation\ndata is derived from: (i) CRSS-PLTL corpus, and (ii) two meetings subset of the\nAMI corpus. Relative reduction in diarization error rate (DER) for CRSS-PLTL\ncorpus is 43.22% using the proposed advancements as compared to baseline. For\nAMI meetings IS1000a and IS1003b, relative DER reduction is 29.37% and 9.21%,\nrespectively.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jul 2019 05:54:33 GMT"}], "update_date": "2019-07-15", "authors_parsed": [["Dubey", "Harishchandra", ""], ["Sangwan", "Abhijeet", ""], ["Hansen", "John", ""]]}, {"id": "1907.05587", "submitter": "Steven C Chen", "authors": "Steven Chen, Nicholas Carlini, and David Wagner", "title": "Stateful Detection of Black-Box Adversarial Attacks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of adversarial examples, evasion attacks on machine learning\nclassifiers, has proven extremely difficult to solve. This is true even when,\nas is the case in many practical settings, the classifier is hosted as a remote\nservice and so the adversary does not have direct access to the model\nparameters.\n  This paper argues that in such settings, defenders have a much larger space\nof actions than have been previously explored. Specifically, we deviate from\nthe implicit assumption made by prior work that a defense must be a stateless\nfunction that operates on individual examples, and explore the possibility for\nstateful defenses.\n  To begin, we develop a defense designed to detect the process of adversarial\nexample generation. By keeping a history of the past queries, a defender can\ntry to identify when a sequence of queries appears to be for the purpose of\ngenerating an adversarial example. We then introduce query blinding, a new\nclass of attacks designed to bypass defenses that rely on such a defense\napproach.\n  We believe that expanding the study of adversarial examples from stateless\nclassifiers to stateful systems is not only more realistic for many black-box\nsettings, but also gives the defender a much-needed advantage in responding to\nthe adversary.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jul 2019 06:12:18 GMT"}], "update_date": "2019-07-15", "authors_parsed": [["Chen", "Steven", ""], ["Carlini", "Nicholas", ""], ["Wagner", "David", ""]]}, {"id": "1907.05597", "submitter": "Alireza Ghods", "authors": "Alireza Ghods and Diane J. Cook", "title": "Activity2Vec: Learning ADL Embeddings from Sensor Data with a\n  Sequence-to-Sequence Model", "comments": "4 pages, 2 figures, DSHealth: 2019 KDD workshop on Applied data\n  science in Healthcare", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recognizing activities of daily living (ADLs) plays an essential role in\nanalyzing human health and behavior. The widespread availability of sensors\nimplanted in homes, smartphones, and smart watches have engendered collection\nof big datasets that reflect human behavior. To obtain a machine learning model\nbased on these data,researchers have developed multiple feature extraction\nmethods. In this study, we investigate a method for automatically extracting\nuniversal and meaningful features that are applicable across similar time\nseries-based learning tasks such as activity recognition and fall detection. We\npropose creating a sequence-to-sequence (seq2seq) model to perform this feature\nlearning. Beside avoiding feature engineering, the meaningful features learned\nby the seq2seq model can also be utilized for semi-supervised learning. We\nevaluate both of these benefits on datasets collected from wearable and ambient\nsensors.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jul 2019 07:19:05 GMT"}], "update_date": "2019-07-15", "authors_parsed": [["Ghods", "Alireza", ""], ["Cook", "Diane J.", ""]]}, {"id": "1907.05599", "submitter": "Tianyu Zhao", "authors": "Tianyu Zhao and Tatsuya Kawahara", "title": "Effective Incorporation of Speaker Information in Utterance Encoding in\n  Dialog", "comments": "8+1 pages, 3 figures, and 5 tables. Rejected by SIGDIAL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In dialog studies, we often encode a dialog using a hierarchical encoder\nwhere each utterance is converted into an utterance vector, and then a sequence\nof utterance vectors is converted into a dialog vector. Since knowing who\nproduced which utterance is essential to understanding a dialog, conventional\nmethods tried integrating speaker labels into utterance vectors. We found the\nmethod problematic in some cases where speaker annotations are inconsistent\namong different dialogs. A relative speaker modeling method is proposed to\naddress the problem. Experimental evaluations on dialog act recognition and\nresponse generation show that the proposed method yields superior and more\nconsistent performances.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jul 2019 07:37:00 GMT"}], "update_date": "2019-07-15", "authors_parsed": [["Zhao", "Tianyu", ""], ["Kawahara", "Tatsuya", ""]]}, {"id": "1907.05600", "submitter": "Yang Song", "authors": "Yang Song and Stefano Ermon", "title": "Generative Modeling by Estimating Gradients of the Data Distribution", "comments": "NeurIPS 2019 (Oral)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new generative model where samples are produced via Langevin\ndynamics using gradients of the data distribution estimated with score\nmatching. Because gradients can be ill-defined and hard to estimate when the\ndata resides on low-dimensional manifolds, we perturb the data with different\nlevels of Gaussian noise, and jointly estimate the corresponding scores, i.e.,\nthe vector fields of gradients of the perturbed data distribution for all noise\nlevels. For sampling, we propose an annealed Langevin dynamics where we use\ngradients corresponding to gradually decreasing noise levels as the sampling\nprocess gets closer to the data manifold. Our framework allows flexible model\narchitectures, requires no sampling during training or the use of adversarial\nmethods, and provides a learning objective that can be used for principled\nmodel comparisons. Our models produce samples comparable to GANs on MNIST,\nCelebA and CIFAR-10 datasets, achieving a new state-of-the-art inception score\nof 8.87 on CIFAR-10. Additionally, we demonstrate that our models learn\neffective representations via image inpainting experiments.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jul 2019 07:37:26 GMT"}, {"version": "v2", "created": "Tue, 29 Oct 2019 07:10:40 GMT"}, {"version": "v3", "created": "Sat, 10 Oct 2020 07:46:19 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Song", "Yang", ""], ["Ermon", "Stefano", ""]]}, {"id": "1907.05628", "submitter": "Vikash Singh", "authors": "Vikash Singh, Pietro Lio'", "title": "Towards Probabilistic Generative Models Harnessing Graph Neural Networks\n  for Disease-Gene Prediction", "comments": "Workshop on Computational Biology (WCB) at ICML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Disease-gene prediction (DGP) refers to the computational challenge of\npredicting associations between genes and diseases. Effective solutions to the\nDGP problem have the potential to accelerate the therapeutic development\npipeline at early stages via efficient prioritization of candidate genes for\nvarious diseases. In this work, we introduce the variational graph auto-encoder\n(VGAE) as a promising unsupervised approach for learning powerful latent\nembeddings in disease-gene networks that can be used for the DGP problem, the\nfirst approach using a generative model involving graph neural networks (GNNs).\nIn addition to introducing the VGAE as a promising approach to the DGP problem,\nwe further propose an extension (constrained-VGAE or C-VGAE) which adapts the\nlearning algorithm for link prediction between two distinct node types in\nheterogeneous graphs. We evaluate and demonstrate the effectiveness of the VGAE\non general link prediction in a disease-gene association network and the C-VGAE\non disease-gene prediction in the same network, using popular random walk\ndriven methods as baselines. While the methodology presented demonstrates\npotential solely based on utilizing the topology of a disease-gene association\nnetwork, it can be further enhanced and explored through the integration of\nadditional biological networks such as gene/protein interaction networks and\nadditional biological features pertaining to the diseases and genes represented\nin the disease-gene association network.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jul 2019 08:47:05 GMT"}], "update_date": "2019-07-15", "authors_parsed": [["Singh", "Vikash", ""], ["Lio'", "Pietro", ""]]}, {"id": "1907.05632", "submitter": "Kaige Yang Mr", "authors": "Kaige Yang and Xiaowen Dong and Laura Toni", "title": "Laplacian-regularized graph bandits: Algorithms and theoretical analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We consider a stochastic linear bandit problem with multiple users, where the\nrelationship between users is captured by an underlying graph and user\npreferences are represented as smooth signals on the graph. We introduce a\nnovel bandit algorithm where the smoothness prior is imposed via the\nrandom-walk graph Laplacian, which leads to a single-user cumulative regret\nscaling as $\\tilde{\\mathcal{O}}(\\Psi d \\sqrt{T})$ with time horizon $T$,\nfeature dimensionality $d$, and the scalar parameter $\\Psi \\in (0,1)$ that\ndepends on the graph connectivity. This is an improvement over\n$\\tilde{\\mathcal{O}}(d \\sqrt{T})$ in \\algo{LinUCB}~\\Ccite{li2010contextual},\nwhere user relationship is not taken into account. In terms of network regret\n(sum of cumulative regret over $n$ users), the proposed algorithm leads to a\nscaling as $\\tilde{\\mathcal{O}}(\\Psi d\\sqrt{nT})$, which is a significant\nimprovement over $\\tilde{\\mathcal{O}}(nd\\sqrt{T})$ in the state-of-the-art\nalgorithm \\algo{Gob.Lin} \\Ccite{cesa2013gang}. To improve scalability, we\nfurther propose a simplified algorithm with a linear computational complexity\nwith respect to the number of users, while maintaining the same regret.\nFinally, we present a finite-time analysis on the proposed algorithms, and\ndemonstrate their advantage in comparison with state-of-the-art graph-based\nbandit algorithms on both synthetic and real-world data.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jul 2019 08:57:26 GMT"}, {"version": "v2", "created": "Mon, 14 Oct 2019 11:22:30 GMT"}, {"version": "v3", "created": "Mon, 10 Feb 2020 18:24:44 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Yang", "Kaige", ""], ["Dong", "Xiaowen", ""], ["Toni", "Laura", ""]]}, {"id": "1907.05634", "submitter": "Yuping Luo", "authors": "Yuping Luo, Huazhe Xu, Tengyu Ma", "title": "Learning Self-Correctable Policies and Value Functions from\n  Demonstrations with Negative Sampling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Imitation learning, followed by reinforcement learning algorithms, is a\npromising paradigm to solve complex control tasks sample-efficiently. However,\nlearning from demonstrations often suffers from the covariate shift problem,\nwhich results in cascading errors of the learned policy. We introduce a notion\nof conservatively-extrapolated value functions, which provably lead to policies\nwith self-correction. We design an algorithm Value Iteration with Negative\nSampling (VINS) that practically learns such value functions with conservative\nextrapolation. We show that VINS can correct mistakes of the behavioral cloning\npolicy on simulated robotics benchmark tasks. We also propose the algorithm of\nusing VINS to initialize a reinforcement learning algorithm, which is shown to\noutperform significantly prior works in sample efficiency.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jul 2019 09:00:49 GMT"}, {"version": "v2", "created": "Thu, 1 Aug 2019 00:43:42 GMT"}, {"version": "v3", "created": "Fri, 11 Oct 2019 05:44:14 GMT"}], "update_date": "2019-10-14", "authors_parsed": [["Luo", "Yuping", ""], ["Xu", "Huazhe", ""], ["Ma", "Tengyu", ""]]}, {"id": "1907.05638", "submitter": "Prateek Jain", "authors": "Chirag Pabbaraju, Prateek Jain", "title": "Learning Functions over Sets via Permutation Adversarial Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider the problem of learning functions over sets, i.e.,\nfunctions that are invariant to permutations of input set items. Recent\napproaches of pooling individual element embeddings can necessitate extremely\nlarge embedding sizes for challenging functions. We address this challenge by\nallowing standard neural networks like LSTMs to succinctly capture the function\nover the set. However, to ensure invariance with respect to permutations of set\nelements, we propose a novel architecture called SPAN that simultaneously\nlearns the function as well as adversarial or worst-case permutations for each\ninput set. The learning problem reduces to a min-max optimization problem that\nis solved via a simple alternating block coordinate descent technique. We\nconduct extensive experiments on a variety of set-learning tasks and\ndemonstrate that SPAN learns nearly permutation-invariant functions while still\nensuring accuracy on test data. On a variety of tasks sampled from the domains\nof statistics, graph functions and linear algebra, we show that our method can\nsignificantly outperform state-of-the-art methods such as DeepSets and Janossy\nPooling. Finally, we present a case study of how learning set-functions can\nhelp extract powerful features for recommendation systems, and show that such a\nmethod can be as much as 2% more accurate than carefully hand-tuned features on\na real-world recommendation system.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jul 2019 09:20:29 GMT"}, {"version": "v2", "created": "Fri, 10 Jan 2020 14:59:28 GMT"}], "update_date": "2020-01-13", "authors_parsed": [["Pabbaraju", "Chirag", ""], ["Jain", "Prateek", ""]]}, {"id": "1907.05664", "submitter": "David Tuckey", "authors": "David Tuckey, Krysia Broda, Alessandra Russo", "title": "Saliency Maps Generation for Automatic Text Summarization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Saliency map generation techniques are at the forefront of explainable AI\nliterature for a broad range of machine learning applications. Our goal is to\nquestion the limits of these approaches on more complex tasks. In this paper we\napply Layer-Wise Relevance Propagation (LRP) to a sequence-to-sequence\nattention model trained on a text summarization dataset. We obtain unexpected\nsaliency maps and discuss the rightfulness of these \"explanations\". We argue\nthat we need a quantitative way of testing the counterfactual case to judge the\ntruthfulness of the saliency maps. We suggest a protocol to check the validity\nof the importance attributed to the input and show that the saliency maps\nobtained sometimes capture the real use of the input features by the network,\nand sometimes do not. We use this example to discuss how careful we need to be\nwhen accepting them as explanation.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jul 2019 10:28:00 GMT"}], "update_date": "2019-07-15", "authors_parsed": [["Tuckey", "David", ""], ["Broda", "Krysia", ""], ["Russo", "Alessandra", ""]]}, {"id": "1907.05671", "submitter": "Graham Spinks", "authors": "Graham Spinks, Marie-Francine Moens", "title": "Justifying Diagnosis Decisions by Deep Neural Networks", "comments": null, "journal-ref": null, "doi": "10.1016/j.jbi.2019.103248", "report-no": null, "categories": "cs.LG cs.CL cs.HC eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An integrated approach is proposed across visual and textual data to both\ndetermine and justify a medical diagnosis by a neural network. As deep learning\ntechniques improve, interest grows to apply them in medical applications. To\nenable a transition to workflows in a medical context that are aided by machine\nlearning, the need exists for such algorithms to help justify the obtained\noutcome so human clinicians can judge their validity. In this work, deep\nlearning methods are used to map a frontal X-Ray image to a continuous textual\nrepresentation. This textual representation is decoded into a diagnosis and the\nassociated textual justification that will help a clinician evaluate the\noutcome. Additionally, more explanatory data is provided for the diagnosis by\ngenerating a realistic X-Ray that belongs to the nearest alternative diagnosis.\nWith a clinical expert opinion study on a subset of the X-Ray data set from the\nIndiana University hospital network, we demonstrate that our justification\nmechanism significantly outperforms existing methods that use saliency maps.\nWhile performing multi-task training with multiple loss functions, our method\nachieves excellent diagnosis accuracy and captioning quality when compared to\ncurrent state-of-the-art single-task methods.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jul 2019 10:51:48 GMT"}], "update_date": "2019-07-15", "authors_parsed": [["Spinks", "Graham", ""], ["Moens", "Marie-Francine", ""]]}, {"id": "1907.05674", "submitter": "Apdullah Yayik", "authors": "Apdullah Yay{\\i}k, Yakup Kutlu, G\\\"okhan Altan", "title": "Deep Learning with ConvNET Predicts Imagery Tasks Through EEG", "comments": "5 pages, 2 figures, springer", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.HC cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deep learning with convolutional neural networks (ConvNets) have dramatically\nimproved learning capabilities of computer vision applications just through\nconsidering raw data without any prior feature extraction. Nowadays, there is\nrising curiosity in interpreting and analyzing electroencephalography (EEG)\ndynamics with ConvNets. Our study focused on ConvNets of different structures,\nconstructed for predicting imagined left and right movements on a\nsubject-independent basis through raw EEG data. Results showed that recently\nadvanced methods in machine learning field, i.e. adaptive moments and batch\nnormalization together with dropout strategy, improved ConvNets predicting\nability, outperforming that of conventional fully-connected neural networks\nwith widely-used spectral features.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jul 2019 11:10:05 GMT"}], "update_date": "2019-07-15", "authors_parsed": [["Yay\u0131k", "Apdullah", ""], ["Kutlu", "Yakup", ""], ["Altan", "G\u00f6khan", ""]]}, {"id": "1907.05681", "submitter": "D\\'avid Terj\\'ek", "authors": "D\\'avid Terj\\'ek", "title": "Adversarial Lipschitz Regularization", "comments": "ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative adversarial networks (GANs) are one of the most popular approaches\nwhen it comes to training generative models, among which variants of\nWasserstein GANs are considered superior to the standard GAN formulation in\nterms of learning stability and sample quality. However, Wasserstein GANs\nrequire the critic to be 1-Lipschitz, which is often enforced implicitly by\npenalizing the norm of its gradient, or by globally restricting its Lipschitz\nconstant via weight normalization techniques. Training with a regularization\nterm penalizing the violation of the Lipschitz constraint explicitly, instead\nof through the norm of the gradient, was found to be practically infeasible in\nmost situations. Inspired by Virtual Adversarial Training, we propose a method\ncalled Adversarial Lipschitz Regularization, and show that using an explicit\nLipschitz penalty is indeed viable and leads to competitive performance when\napplied to Wasserstein GANs, highlighting an important connection between\nLipschitz regularization and adversarial training.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jul 2019 11:41:18 GMT"}, {"version": "v2", "created": "Thu, 2 Jan 2020 16:02:17 GMT"}, {"version": "v3", "created": "Fri, 3 Jan 2020 09:11:31 GMT"}], "update_date": "2020-01-06", "authors_parsed": [["Terj\u00e9k", "D\u00e1vid", ""]]}, {"id": "1907.05690", "submitter": "Hiroshi Yonai", "authors": "Hiroshi Yonai, Yasuhiro Hayase, Hiroyuki Kitagawa", "title": "Mercem: Method Name Recommendation Based on Call Graph Embedding", "comments": "9 pages, 9 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.LG cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Comprehensibility of source code is strongly affected by identifier names,\ntherefore software developers need to give good (e.g. meaningful but short)\nnames to identifiers. On the other hand, giving a good name is sometimes a\ndifficult and time-consuming task even for experienced developers. To support\nnaming identifiers, several techniques for recommending identifier name\ncandidates have been proposed. These techniques, however, still have challenges\non the goodness of suggested candidates and limitations on applicable\nsituations. This paper proposes a new approach to recommending method names by\napplying graph embedding techniques to the method call graph. The evaluation\nexperiment confirms that the proposed technique can suggest more appropriate\nmethod name candidates in difficult situations than the state of the art\napproach.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jul 2019 12:06:50 GMT"}], "update_date": "2019-07-15", "authors_parsed": [["Yonai", "Hiroshi", ""], ["Hayase", "Yasuhiro", ""], ["Kitagawa", "Hiroyuki", ""]]}, {"id": "1907.05697", "submitter": "Enrique A. S\\'anchez-P\\'erez", "authors": "J.M. Calabuig, H. Falciani and E.A. S\\'anchez-P\\'erez", "title": "Dreaming machine learning: Lipschitz extensions for reinforcement\n  learning on financial markets", "comments": "20 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST cs.LG math.FA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a quasi-metric topological structure for the construction of a\nnew reinforcement learning model in the framework of financial markets. It is\nbased on a Lipschitz type extension of reward functions defined in metric\nspaces. Specifically, the McShane and Whitney extensions are considered for a\nreward function which is defined by the total evaluation of the benefits\nproduced by the investment decision at a given time. We define the metric as a\nlinear combination of a Euclidean distance and an angular metric component. All\ninformation about the evolution of the system from the beginning of the time\ninterval is used to support the extension of the reward function, but in\naddition this data set is enriched by adding some artificially produced states.\nThus, the main novelty of our method is the way we produce more states -- which\nwe call \"dreams\" -- to enrich learning. Using some known states of the\ndynamical system that represents the evolution of the financial market, we use\nour technique to simulate new states by interpolating real states and\nintroducing some random variables. These new states are used to feed a learning\nalgorithm designed to improve the investment strategy by following a typical\nreinforcement learning scheme.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jul 2019 12:33:01 GMT"}, {"version": "v2", "created": "Sat, 28 Mar 2020 13:01:42 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Calabuig", "J. M.", ""], ["Falciani", "H.", ""], ["S\u00e1nchez-P\u00e9rez", "E. A.", ""]]}, {"id": "1907.05701", "submitter": "Wei Zhang", "authors": "Wei Zhang, Xiaodong Cui, Ulrich Finkler, George Saon, Abdullah Kayi,\n  Alper Buyuktosunoglu, Brian Kingsbury, David Kung, Michael Picheny", "title": "A Highly Efficient Distributed Deep Learning System For Automatic Speech\n  Recognition", "comments": null, "journal-ref": "INTERSPEECH 2019", "doi": null, "report-no": null, "categories": "eess.AS cs.DC cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern Automatic Speech Recognition (ASR) systems rely on distributed deep\nlearning to for quick training completion. To enable efficient distributed\ntraining, it is imperative that the training algorithms can converge with a\nlarge mini-batch size. In this work, we discovered that Asynchronous\nDecentralized Parallel Stochastic Gradient Descent (ADPSGD) can work with much\nlarger batch size than commonly used Synchronous SGD (SSGD) algorithm. On\ncommonly used public SWB-300 and SWB-2000 ASR datasets, ADPSGD can converge\nwith a batch size 3X as large as the one used in SSGD, thus enable training at\na much larger scale. Further, we proposed a Hierarchical-ADPSGD (H-ADPSGD)\nsystem in which learners on the same computing node construct a super learner\nvia a fast allreduce implementation, and super learners deploy ADPSGD algorithm\namong themselves. On a 64 Nvidia V100 GPU cluster connected via a 100Gb/s\nEthernet network, our system is able to train SWB-2000 to reach a 7.6% WER on\nthe Hub5-2000 Switchboard (SWB) test-set and a 13.2% WER on the Call-home (CH)\ntest-set in 5.2 hours. To the best of our knowledge, this is the fastest ASR\ntraining system that attains this level of model accuracy for SWB-2000 task to\nbe ever reported in the literature.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jul 2019 14:32:59 GMT"}], "update_date": "2019-07-15", "authors_parsed": [["Zhang", "Wei", ""], ["Cui", "Xiaodong", ""], ["Finkler", "Ulrich", ""], ["Saon", "George", ""], ["Kayi", "Abdullah", ""], ["Buyuktosunoglu", "Alper", ""], ["Kingsbury", "Brian", ""], ["Kung", "David", ""], ["Picheny", "Michael", ""]]}, {"id": "1907.05707", "submitter": "Jianhong Wang", "authors": "Jianhong Wang, Yuan Zhang, Tae-Kyun Kim, Yunjie Gu", "title": "Shapley Q-value: A Local Reward Approach to Solve Global Reward Games", "comments": null, "journal-ref": "AAAI2020", "doi": "10.1609/aaai.v34i05.6220", "report-no": null, "categories": "cs.LG cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cooperative game is a critical research area in the multi-agent reinforcement\nlearning (MARL). Global reward game is a subclass of cooperative games, where\nall agents aim to maximize the global reward. Credit assignment is an important\nproblem studied in the global reward game. Most of previous works stood by the\nview of non-cooperative-game theoretical framework with the shared reward\napproach, i.e., each agent being assigned a shared global reward directly.\nThis, however, may give each agent an inaccurate reward on its contribution to\nthe group, which could cause inefficient learning. To deal with this problem,\nwe i) introduce a cooperative-game theoretical framework called extended convex\ngame (ECG) that is a superset of global reward game, and ii) propose a local\nreward approach called Shapley Q-value. Shapley Q-value is able to distribute\nthe global reward, reflecting each agent's own contribution in contrast to the\nshared reward approach. Moreover, we derive an MARL algorithm called Shapley\nQ-value deep deterministic policy gradient (SQDDPG), using Shapley Q-value as\nthe critic for each agent. We evaluate SQDDPG on Cooperative Navigation,\nPrey-and-Predator and Traffic Junction, compared with the state-of-the-art\nalgorithms, e.g., MADDPG, COMA, Independent DDPG and Independent A2C. In the\nexperiments, SQDDPG shows a significant improvement on the convergence rate.\nFinally, we plot Shapley Q-value and validate the property of fair credit\nassignment.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jul 2019 15:12:33 GMT"}, {"version": "v2", "created": "Mon, 9 Sep 2019 09:25:00 GMT"}, {"version": "v3", "created": "Thu, 21 Nov 2019 21:19:38 GMT"}, {"version": "v4", "created": "Mon, 25 Nov 2019 11:26:06 GMT"}, {"version": "v5", "created": "Tue, 24 Nov 2020 17:03:53 GMT"}], "update_date": "2020-11-25", "authors_parsed": [["Wang", "Jianhong", ""], ["Zhang", "Yuan", ""], ["Kim", "Tae-Kyun", ""], ["Gu", "Yunjie", ""]]}, {"id": "1907.05708", "submitter": "Andrea Tagarelli", "authors": "Diego Perna, Andrea Tagarelli", "title": "Deep auscultation: Predicting respiratory anomalies and diseases via\n  recurrent neural networks", "comments": "Paper accepted for publication with Procs. of the 32th IEEE CBMS\n  International Symposium on Computer-Based Medical Systems (CBMS 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Respiratory diseases are among the most common causes of severe illness and\ndeath worldwide. Prevention and early diagnosis are essential to limit or even\nreverse the trend that characterizes the diffusion of such diseases. In this\nregard, the development of advanced computational tools for the analysis of\nrespiratory auscultation sounds can become a game changer for detecting\ndisease-related anomalies, or diseases themselves. In this work, we propose a\nnovel learning framework for respiratory auscultation sound data. Our approach\ncombines state-of-the-art feature extraction techniques and advanced\ndeep-neural-network architectures. Remarkably, to the best of our knowledge, we\nare the first to model a recurrent-neural-network based learning framework to\nsupport the clinician in detecting respiratory diseases, at either level of\nabnormal sounds or pathology classes. Results obtained on the ICBHI benchmark\ndataset show that our approach outperforms competing methods on both\nanomaly-driven and pathology-driven prediction tasks, thus advancing the\nstate-of-the-art in respiratory disease analysis.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jul 2019 17:16:42 GMT"}], "update_date": "2019-07-15", "authors_parsed": [["Perna", "Diego", ""], ["Tagarelli", "Andrea", ""]]}, {"id": "1907.05715", "submitter": "Arthur Jacot", "authors": "Arthur Jacot, Franck Gabriel, Fran\\c{c}ois Ged, Cl\\'ement Hongler", "title": "Order and Chaos: NTK views on DNN Normalization, Checkerboard and\n  Boundary Artifacts", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyze architectural features of Deep Neural Networks (DNNs) using the\nso-called Neural Tangent Kernel (NTK), which describes the training and\ngeneralization of DNNs in the infinite-width setting. In this setting, we show\nthat for fully-connected DNNs, as the depth grows, two regimes appear: \"order\",\nwhere the (scaled) NTK converges to a constant, and \"chaos\", where it converges\nto a Kronecker delta. Extreme order slows down training while extreme chaos\nhinders generalization. Using the scaled ReLU as a nonlinearity, we end up in\nthe ordered regime. In contrast, Layer Normalization brings the network into\nthe chaotic regime. We observe a similar effect for Batch Normalization (BN)\napplied after the last nonlinearity. We uncover the same order and chaos modes\nin Deep Deconvolutional Networks (DC-NNs). Our analysis explains the appearance\nof so-called checkerboard patterns and border artifacts. Moving the network\ninto the chaotic regime prevents checkerboard patterns; we propose a\ngraph-based parametrization which eliminates border artifacts; finally, we\nintroduce a new layer-dependent learning rate to improve the convergence of\nDC-NNs. We illustrate our findings on DCGANs: the ordered regime leads to a\ncollapse of the generator to a checkerboard mode, which can be avoided by\ntuning the nonlinearity to reach the chaotic regime. As a result, we are able\nto obtain good quality samples for DCGANs without BN.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jul 2019 10:55:39 GMT"}, {"version": "v2", "created": "Mon, 22 Jun 2020 16:39:39 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Jacot", "Arthur", ""], ["Gabriel", "Franck", ""], ["Ged", "Fran\u00e7ois", ""], ["Hongler", "Cl\u00e9ment", ""]]}, {"id": "1907.05718", "submitter": "Ziv Katzir", "authors": "Ziv Katzir, Yuval Elovici", "title": "Why Blocking Targeted Adversarial Perturbations Impairs the Ability to\n  Learn", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite their accuracy, neural network-based classifiers are still prone to\nmanipulation through adversarial perturbations. Those perturbations are\ndesigned to be misclassified by the neural network, while being perceptually\nidentical to some valid input. The vast majority of attack methods rely on\nwhite-box conditions, where the attacker has full knowledge of the attacked\nnetwork's parameters. This allows the attacker to calculate the network's loss\ngradient with respect to some valid input and use this gradient in order to\ncreate an adversarial example. The task of blocking white-box attacks has\nproven difficult to solve. While a large number of defense methods have been\nsuggested, they have had limited success. In this work we examine this\ndifficulty and try to understand it. We systematically explore the abilities\nand limitations of defensive distillation, one of the most promising defense\nmechanisms against adversarial perturbations suggested so far in order to\nunderstand the defense challenge. We show that contrary to commonly held\nbelief, the ability to bypass defensive distillation is not dependent on an\nattack's level of sophistication. In fact, simple approaches, such as the\nTargeted Gradient Sign Method, are capable of effectively bypassing defensive\ndistillation. We prove that defensive distillation is highly effective against\nnon-targeted attacks but is unsuitable for targeted attacks. This discovery\nleads us to realize that targeted attacks leverage the same input gradient that\nallows a network to be trained. This implies that blocking them will require\nlosing the network's ability to learn, presenting an impossible tradeoff to the\nresearch community.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jul 2019 06:28:25 GMT"}], "update_date": "2019-07-15", "authors_parsed": [["Katzir", "Ziv", ""], ["Elovici", "Yuval", ""]]}, {"id": "1907.05720", "submitter": "Sam Allison", "authors": "Sam Allison, He Bai and Balaji Jayaraman", "title": "Wind Estimation Using Quadcopter Motion: A Machine Learning Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article, we study the well known problem of wind estimation in\natmospheric turbulence using small unmanned aerial systems (sUAS). We present a\nmachine learning approach to wind velocity estimation based on quadcopter state\nmeasurements without a wind sensor. We accomplish this by training a long\nshort-term memory (LSTM) neural network (NN) on roll and pitch angles and\nquadcopter position inputs with forcing wind velocities as the targets. The\ndatasets are generated using a simulated quadcopter in turbulent wind fields.\nThe trained neural network is deployed to estimate the turbulent winds as\ngenerated by the Dryden gust model as well as a realistic large eddy simulation\n(LES) of a near-neutral atmospheric boundary layer (ABL) over flat terrain. The\nresulting NN predictions are compared to a wind triangle approach that uses\ntilt angle as an approximation of airspeed. Results from this study indicate\nthat the LSTM-NN based approach predicts lower errors in both the mean and\nvariance of the local wind field as compared to the wind triangle approach. The\nwork reported in this article demonstrates the potential of machine learning\nfor sensor-less wind estimation and has strong implications to large-scale\nlow-altitude atmospheric sensing using sUAS for environmental and autonomous\nnavigation applications.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jul 2019 04:03:27 GMT"}], "update_date": "2019-07-15", "authors_parsed": [["Allison", "Sam", ""], ["Bai", "He", ""], ["Jayaraman", "Balaji", ""]]}, {"id": "1907.05737", "submitter": "Lingxi Xie", "authors": "Yuhui Xu, Lingxi Xie, Xiaopeng Zhang, Xin Chen, Guo-Jun Qi, Qi Tian,\n  Hongkai Xiong", "title": "PC-DARTS: Partial Channel Connections for Memory-Efficient Architecture\n  Search", "comments": "Accepted by ICLR2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Differentiable architecture search (DARTS) provided a fast solution in\nfinding effective network architectures, but suffered from large memory and\ncomputing overheads in jointly training a super-network and searching for an\noptimal architecture. In this paper, we present a novel approach, namely,\nPartially-Connected DARTS, by sampling a small part of super-network to reduce\nthe redundancy in exploring the network space, thereby performing a more\nefficient search without comprising the performance. In particular, we perform\noperation search in a subset of channels while bypassing the held out part in a\nshortcut. This strategy may suffer from an undesired inconsistency on selecting\nthe edges of super-net caused by sampling different channels. We alleviate it\nusing edge normalization, which adds a new set of edge-level parameters to\nreduce uncertainty in search. Thanks to the reduced memory cost, PC-DARTS can\nbe trained with a larger batch size and, consequently, enjoys both faster speed\nand higher training stability. Experimental results demonstrate the\neffectiveness of the proposed method. Specifically, we achieve an error rate of\n2.57% on CIFAR10 with merely 0.1 GPU-days for architecture search, and a\nstate-of-the-art top-1 error rate of 24.2% on ImageNet (under the mobile\nsetting) using 3.8 GPU-days for search. Our code has been made available at:\nhttps://github.com/yuhuixu1993/PC-DARTS.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jul 2019 13:26:09 GMT"}, {"version": "v2", "created": "Mon, 13 Jan 2020 19:26:34 GMT"}, {"version": "v3", "created": "Thu, 30 Jan 2020 03:53:42 GMT"}, {"version": "v4", "created": "Tue, 7 Apr 2020 06:20:35 GMT"}], "update_date": "2020-04-08", "authors_parsed": [["Xu", "Yuhui", ""], ["Xie", "Lingxi", ""], ["Zhang", "Xiaopeng", ""], ["Chen", "Xin", ""], ["Qi", "Guo-Jun", ""], ["Tian", "Qi", ""], ["Xiong", "Hongkai", ""]]}, {"id": "1907.05740", "submitter": "Towaki Takikawa", "authors": "Towaki Takikawa, David Acuna, Varun Jampani, Sanja Fidler", "title": "Gated-SCNN: Gated Shape CNNs for Semantic Segmentation", "comments": "Project Website: https://nv-tlabs.github.io/GSCNN/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current state-of-the-art methods for image segmentation form a dense image\nrepresentation where the color, shape and texture information are all processed\ntogether inside a deep CNN. This however may not be ideal as they contain very\ndifferent type of information relevant for recognition. Here, we propose a new\ntwo-stream CNN architecture for semantic segmentation that explicitly wires\nshape information as a separate processing branch, i.e. shape stream, that\nprocesses information in parallel to the classical stream. Key to this\narchitecture is a new type of gates that connect the intermediate layers of the\ntwo streams. Specifically, we use the higher-level activations in the classical\nstream to gate the lower-level activations in the shape stream, effectively\nremoving noise and helping the shape stream to only focus on processing the\nrelevant boundary-related information. This enables us to use a very shallow\narchitecture for the shape stream that operates on the image-level resolution.\nOur experiments show that this leads to a highly effective architecture that\nproduces sharper predictions around object boundaries and significantly boosts\nperformance on thinner and smaller objects. Our method achieves\nstate-of-the-art performance on the Cityscapes benchmark, in terms of both mask\n(mIoU) and boundary (F-score) quality, improving by 2% and 4% over strong\nbaselines.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jul 2019 13:37:46 GMT"}], "update_date": "2019-07-15", "authors_parsed": [["Takikawa", "Towaki", ""], ["Acuna", "David", ""], ["Jampani", "Varun", ""], ["Fidler", "Sanja", ""]]}, {"id": "1907.05743", "submitter": "Kaisheng Gao", "authors": "Kaisheng Gao, Jing Zhang, Cangqi Zhou", "title": "Semi-Supervised Graph Embedding for Multi-Label Graph Node\n  Classification", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The graph convolution network (GCN) is a widely-used facility to realize\ngraph-based semi-supervised learning, which usually integrates node features\nand graph topologic information to build learning models. However, as for\nmulti-label learning tasks, the supervision part of GCN simply minimizes the\ncross-entropy loss between the last layer outputs and the ground-truth label\ndistribution, which tends to lose some useful information such as label\ncorrelations, so that prevents from obtaining high performance. In this paper,\nwe pro-pose a novel GCN-based semi-supervised learning approach for multi-label\nclassification, namely ML-GCN. ML-GCN first uses a GCN to embed the node\nfeatures and graph topologic information. Then, it randomly generates a label\nmatrix, where each row (i.e., label vector) represents a kind of labels. The\ndimension of the label vector is the same as that of the node vector before the\nlast convolution operation of GCN. That is, all labels and nodes are embedded\nin a uniform vector space. Finally, during the ML-GCN model training, label\nvectors and node vectors are concatenated to serve as the inputs of the relaxed\nskip-gram model to detect the node-label correlation as well as the label-label\ncorrelation. Experimental results on several graph classification datasets show\nthat the proposed ML-GCN outperforms four state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jul 2019 13:43:04 GMT"}], "update_date": "2019-07-15", "authors_parsed": [["Gao", "Kaisheng", ""], ["Zhang", "Jing", ""], ["Zhou", "Cangqi", ""]]}, {"id": "1907.05765", "submitter": "Luca Mossina", "authors": "Andrea Lodi and Luca Mossina and Emmanuel Rachelson", "title": "Learning to Handle Parameter Perturbations in Combinatorial\n  Optimization: an Application to Facility Location", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an approach to couple the resolution of Combinatorial Optimization\nproblems with methods from Machine Learning, applied to the single source,\ncapacitated, facility location problem. Our study is framed in the context\nwhere a reference facility location optimization problem is given. Assuming\nthere exist data for many variations of the reference problem (historical or\nsimulated) along with their optimal solution, we study how one can exploit\nthese to make predictions about an unseen new instance. We demonstrate how a\nclassifier can be built from these data to determine whether the solution to\nthe reference problem still applies to a new instance. In case the reference\nsolution is partially applicable, we build a regressor indicating the magnitude\nof the expected change, and conversely how much of it can be kept for the new\ninstance. This insight, derived from a priori information, is expressed via an\nadditional constraint in the original mathematical programming formulation. We\npresent an empirical evaluation and discuss the benefits, drawbacks and\nperspectives of such an approach. Although presented through the application to\nthe facility location problem, the approach developed here is general and\nexplores a new perspective on the exploitation of past experience in\ncombinatorial optimization.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jul 2019 14:25:51 GMT"}], "update_date": "2019-07-15", "authors_parsed": [["Lodi", "Andrea", ""], ["Mossina", "Luca", ""], ["Rachelson", "Emmanuel", ""]]}, {"id": "1907.05772", "submitter": "Tor Lattimore", "authors": "Tor Lattimore and Csaba Szepesvari", "title": "Exploration by Optimisation in Partial Monitoring", "comments": "high probability bounds, experiments and simplified\n  algorithms/analysis", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide a simple and efficient algorithm for adversarial $k$-action\n$d$-outcome non-degenerate locally observable partial monitoring game for which\nthe $n$-round minimax regret is bounded by $6(d+1) k^{3/2} \\sqrt{n \\log(k)}$,\nmatching the best known information-theoretic upper bound. The same algorithm\nalso achieves near-optimal regret for full information, bandit and globally\nobservable games.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jul 2019 14:46:50 GMT"}, {"version": "v2", "created": "Wed, 24 Jul 2019 10:40:25 GMT"}, {"version": "v3", "created": "Fri, 25 Oct 2019 10:54:52 GMT"}], "update_date": "2019-10-28", "authors_parsed": [["Lattimore", "Tor", ""], ["Szepesvari", "Csaba", ""]]}, {"id": "1907.05783", "submitter": "Daniel Alcaide", "authors": "Daniel Alcaide, and Jan Aerts", "title": "Improving the Projection of Global Structures in Data through Spanning\n  Trees", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The connection of edges in a graph generates a structure that is independent\nof a coordinate system. This visual metaphor allows creating a more flexible\nrepresentation of data than a two-dimensional scatterplot. In this work, we\npresent STAD (Spanning Trees as Approximation of Data), a dimensionality\nreduction method to approximate the high-dimensional structure into a graph\nwith or without formulating prior hypotheses. STAD generates an abstract\nrepresentation of high-dimensional data by giving each data point a location in\na graph which preserves the distances in the original high-dimensional space.\nThe STAD graph is built upon the Minimum Spanning Tree (MST) to which new edges\nare added until the correlation between the distances from the graph and the\noriginal dataset is maximized. Additionally, STAD supports the inclusion of\nadditional functions to focus the exploration and allow the analysis of data\nfrom new perspectives, emphasizing traits in data which otherwise would remain\nhidden. We demonstrate the effectiveness of our method by applying it to two\nreal-world datasets: traffic density in Barcelona and temporal measurements of\nair quality in Castile and Le\\'on in Spain.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jul 2019 15:11:19 GMT"}], "update_date": "2019-07-15", "authors_parsed": [["Alcaide", "Daniel", ""], ["Aerts", "Jan", ""]]}, {"id": "1907.05790", "submitter": "Christophe Servan", "authors": "Estelle Maudet, Oralie Cattan, Maureen de Seyssel, Christophe Servan", "title": "Qwant Research @DEFT 2019: Document matching and information retrieval\n  using clinical cases", "comments": "Article accepted at the workshop DEfi fouille de Texte (DEFT 2019).\n  Article in French", "journal-ref": "DEFT 2019", "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper reports on Qwant Research contribution to tasks 2 and 3 of the\nDEFT 2019's challenge, focusing on French clinical cases analysis. Task 2 is a\ntask on semantic similarity between clinical cases and discussions. For this\ntask, we propose an approach based on language models and evaluate the impact\non the results of different preprocessings and matching techniques. For task 3,\nwe have developed an information extraction system yielding very encouraging\nresults accuracy-wise. We have experimented two different approaches, one based\non the exclusive use of neural networks, the other based on a linguistic\nanalysis.\n", "versions": [{"version": "v1", "created": "Sat, 6 Jul 2019 08:29:21 GMT"}], "update_date": "2019-07-15", "authors_parsed": [["Maudet", "Estelle", ""], ["Cattan", "Oralie", ""], ["de Seyssel", "Maureen", ""], ["Servan", "Christophe", ""]]}, {"id": "1907.05813", "submitter": "Antonis Danelakis", "authors": "Giorgos Bouritsas, Stelios Daveas, Antonios Danelakis, Constantinos\n  Rizogiannis and Stelios C. A. Thomopoulos", "title": "Automated Real-time Anomaly Detection in Human Trajectories using\n  Sequence to Sequence Networks", "comments": "AVSS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Detection of anomalous trajectories is an important problem with potential\napplications to various domains, such as video surveillance, risk assessment,\nvessel monitoring and high-energy physics. Modeling the distribution of\ntrajectories with statistical approaches has been a challenging task due to the\nfact that such time series are usually non stationary and highly dimensional.\nHowever, modern machine learning techniques provide robust approaches for\ndata-driven modeling and critical information extraction. In this paper, we\npropose a Sequence to Sequence architecture for real-time detection of\nanomalies in human trajectories, in the context of risk-based security. Our\ndetection scheme is tested on a synthetic dataset of diverse and realistic\ntrajectories generated by the ISL iCrowd simulator. The experimental results\nindicate that our scheme accurately detects motion patterns that deviate from\nnormal behaviors and is promising for future real-world applications.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jul 2019 16:04:32 GMT"}, {"version": "v2", "created": "Mon, 15 Jul 2019 14:14:51 GMT"}], "update_date": "2019-07-16", "authors_parsed": [["Bouritsas", "Giorgos", ""], ["Daveas", "Stelios", ""], ["Danelakis", "Antonios", ""], ["Rizogiannis", "Constantinos", ""], ["Thomopoulos", "Stelios C. A.", ""]]}, {"id": "1907.05830", "submitter": "Mathurin Massias", "authors": "Mathurin Massias and Samuel Vaiter and Alexandre Gramfort and Joseph\n  Salmon", "title": "Dual Extrapolation for Sparse Generalized Linear Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generalized Linear Models (GLM) form a wide class of regression and\nclassification models, where prediction is a function of a linear combination\nof the input variables. For statistical inference in high dimension, sparsity\ninducing regularizations have proven to be useful while offering statistical\nguarantees. However, solving the resulting optimization problems can be\nchallenging: even for popular iterative algorithms such as coordinate descent,\none needs to loop over a large number of variables. To mitigate this,\ntechniques known as screening rules and working sets diminish the size of the\noptimization problem at hand, either by progressively removing variables, or by\nsolving a growing sequence of smaller problems. For both techniques,\nsignificant variables are identified thanks to convex duality arguments. In\nthis paper, we show that the dual iterates of a GLM exhibit a Vector\nAutoRegressive (VAR) behavior after sign identification, when the primal\nproblem is solved with proximal gradient descent or cyclic coordinate descent.\nExploiting this regularity, one can construct dual points that offer tighter\ncertificates of optimality, enhancing the performance of screening rules and\nhelping to design competitive working set algorithms.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jul 2019 16:35:39 GMT"}, {"version": "v2", "created": "Wed, 4 Mar 2020 11:01:52 GMT"}], "update_date": "2020-03-05", "authors_parsed": [["Massias", "Mathurin", ""], ["Vaiter", "Samuel", ""], ["Gramfort", "Alexandre", ""], ["Salmon", "Joseph", ""]]}, {"id": "1907.05839", "submitter": "Giorgio Magri", "authors": "Arto Anttila, Scott Borgeson, Giorgio Magri", "title": "Equiprobable mappings in weighted constraint grammars", "comments": "10 pages; Proceedings of ACL Sigmorphon 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that MaxEnt is so rich that it can distinguish between any two\ndifferent mappings: there always exists a nonnegative weight vector which\nassigns them different MaxEnt probabilities. Stochastic HG instead does admit\nequiprobable mappings and we give a complete formal characterization of them.\nWe compare these different predictions of the two frameworks on a test case of\nFinnish stress.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jul 2019 17:02:14 GMT"}], "update_date": "2019-07-15", "authors_parsed": [["Anttila", "Arto", ""], ["Borgeson", "Scott", ""], ["Magri", "Giorgio", ""]]}, {"id": "1907.05855", "submitter": "Timoth\\'ee Lesort", "authors": "Ren\\'e Traor\\'e, Hugo Caselles-Dupr\\'e, Timoth\\'ee Lesort, Te Sun,\n  Guanghang Cai, Natalia D\\'iaz-Rodr\\'iguez, David Filliat", "title": "DisCoRL: Continual Reinforcement Learning via Policy Distillation", "comments": "arXiv admin note: text overlap with arXiv:1906.04452", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In multi-task reinforcement learning there are two main challenges: at\ntraining time, the ability to learn different policies with a single model; at\ntest time, inferring which of those policies applying without an external\nsignal. In the case of continual reinforcement learning a third challenge\narises: learning tasks sequentially without forgetting the previous ones. In\nthis paper, we tackle these challenges by proposing DisCoRL, an approach\ncombining state representation learning and policy distillation. We experiment\non a sequence of three simulated 2D navigation tasks with a 3 wheel\nomni-directional robot. Moreover, we tested our approach's robustness by\ntransferring the final policy into a real life setting. The policy can solve\nall tasks and automatically infer which one to run.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jul 2019 09:12:42 GMT"}], "update_date": "2019-07-15", "authors_parsed": [["Traor\u00e9", "Ren\u00e9", ""], ["Caselles-Dupr\u00e9", "Hugo", ""], ["Lesort", "Timoth\u00e9e", ""], ["Sun", "Te", ""], ["Cai", "Guanghang", ""], ["D\u00edaz-Rodr\u00edguez", "Natalia", ""], ["Filliat", "David", ""]]}, {"id": "1907.05878", "submitter": "Adithya Murali", "authors": "Adithya Murali and P. Madhusudan", "title": "Augmenting Neural Nets with Symbolic Synthesis: Applications to Few-Shot\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose symbolic learning as extensions to standard inductive learning\nmodels such as neural nets as a means to solve few shot learning problems. We\ndevice a class of visual discrimination puzzles that calls for recognizing\nobjects and object relationships as well learning higher-level concepts from\nvery few images. We propose a two-phase learning framework that combines models\nlearned from large data sets using neural nets and symbolic first-order logic\nformulas learned from a few shot learning instance. We develop first-order\nlogic synthesis techniques for discriminating images by using symbolic search\nand logic constraint solvers. By augmenting neural nets with them, we develop\nand evaluate a tool that can solve few shot visual discrimination puzzles with\ninterpretable concepts.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jul 2019 17:50:31 GMT"}], "update_date": "2019-07-15", "authors_parsed": [["Murali", "Adithya", ""], ["Madhusudan", "P.", ""]]}, {"id": "1907.05885", "submitter": "Joberto Martins Prof. Dr.", "authors": "Flavio G. Calhau and Joberto S. B. Martins", "title": "A Electric Network Reconfiguration Strategy with Case-Based Reasoning\n  for the Smart Grid", "comments": "6 pages", "journal-ref": null, "doi": "10.5281/zenodo.3277282", "report-no": null, "categories": "cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The complexity, heterogeneity and scale of electrical networks have grown far\nbeyond the limits of exclusively human-based management at the Smart Grid (SG).\nLikewise, researchers cogitate the use of artificial intelligence and\nheuristics techniques to create cognitive and autonomic management tools that\naim better assist and enhance SG management processes like in the grid\nreconfiguration. The development of self-healing management approaches towards\na cognitive and autonomic distribution power network reconfiguration is a\nscenario in which the scalability and on-the-fly computation are issues. This\npaper proposes the use of Case-Based Reasoning (CBR) coupled with the HATSGA\nalgorithm for the fast reconfiguration of large distribution power networks.\nThe suitability and the scalability of the CBR-based reconfiguration strategy\nusing HATSGA algorithm are evaluated. The evaluation indicates that the adopted\nHATSGA algorithm computes new reconfiguration topologies with a feasible\ncomputational time for large networks. The CBR strategy looks for managerial\nacceptable reconfiguration solutions at the CBR database and, as such,\ncontributes to reduce the required number of reconfiguration computation using\nHATSGA. This suggests CBR can be applied with a fast reconfiguration algorithm\nresulting in more efficient, dynamic and cognitive grid recovery strategy.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jul 2019 23:42:55 GMT"}], "update_date": "2019-07-16", "authors_parsed": [["Calhau", "Flavio G.", ""], ["Martins", "Joberto S. B.", ""]]}, {"id": "1907.05888", "submitter": "Apdullah Yayik", "authors": "Apdullah Yay{\\i}k, Yakup Kutlu, G\\\"okhan Altan", "title": "Regularized HessELM and Inclined Entropy Measurement for Congestive\n  Heart Failure Prediction", "comments": "9 pages, 3 figures, neuroprocessing letter", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.HC cs.NA eess.SP math.NA physics.med-ph", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Our study concerns with automated predicting of congestive heart failure\n(CHF) through the analysis of electrocardiography (ECG) signals. A novel\nmachine learning approach, regularized hessenberg decomposition based extreme\nlearning machine (R-HessELM), and feature models; squared, circled, inclined\nand grid entropy measurement were introduced and used for prediction of CHF.\nThis study proved that inclined entropy measurements features well represent\ncharacteristics of ECG signals and together with R-HessELM approach overall\naccuracy of 98.49% was achieved.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jul 2019 11:11:02 GMT"}], "update_date": "2019-07-16", "authors_parsed": [["Yay\u0131k", "Apdullah", ""], ["Kutlu", "Yakup", ""], ["Altan", "G\u00f6khan", ""]]}, {"id": "1907.05905", "submitter": "Pavol Harar", "authors": "Pavol Harar, Jesus B. Alonso-Hernandez, Jiri Mekyska, Zoltan Galaz,\n  Radim Burget and Zdenek Smekal", "title": "Voice Pathology Detection Using Deep Learning: a Preliminary Study", "comments": "4 pages, 1 figure, 5 tables", "journal-ref": "In 2017 international conference and workshop on bioinspired\n  intelligence (IWOBI), pp. 1-4. IEEE, 2017", "doi": "10.1109/IWOBI.2017.7985525", "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes a preliminary investigation of Voice Pathology Detection\nusing Deep Neural Networks (DNN). We used voice recordings of sustained vowel\n/a/ produced at normal pitch from German corpus Saarbruecken Voice Database\n(SVD). This corpus contains voice recordings and electroglottograph signals of\nmore than 2 000 speakers. The idea behind this experiment is the use of\nconvolutional layers in combination with recurrent Long-Short-Term-Memory\n(LSTM) layers on raw audio signal. Each recording was split into 64 ms Hamming\nwindowed segments with 30 ms overlap. Our trained model achieved 71.36%\naccuracy with 65.04% sensitivity and 77.67% specificity on 206 validation files\nand 68.08% accuracy with 66.75% sensitivity and 77.89% specificity on 874\ntesting files. This is a promising result in favor of this approach because it\nis comparable to similar previously published experiment that used different\nmethodology. Further investigation is needed to achieve the state-of-the-art\nresults.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jul 2019 18:06:02 GMT"}], "update_date": "2019-07-16", "authors_parsed": [["Harar", "Pavol", ""], ["Alonso-Hernandez", "Jesus B.", ""], ["Mekyska", "Jiri", ""], ["Galaz", "Zoltan", ""], ["Burget", "Radim", ""], ["Smekal", "Zdenek", ""]]}, {"id": "1907.05911", "submitter": "Namuk Park", "authors": "Namuk Park, Taekyu Lee, Songkuk Kim", "title": "Vector Quantized Bayesian Neural Network Inference for Data Streams", "comments": "AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian neural networks (BNN) can estimate the uncertainty in predictions,\nas opposed to non-Bayesian neural networks (NNs). However, BNNs have been far\nless widely used than non-Bayesian NNs in practice since they need iterative NN\nexecutions to predict a result for one data, and it gives rise to prohibitive\ncomputational cost. This computational burden is a critical problem when\nprocessing data streams with low-latency. To address this problem, we propose a\nnovel model VQ-BNN, which approximates BNN inference for data streams. In order\nto reduce the computational burden, VQ-BNN inference predicts NN only once and\ncompensates the result with previously memorized predictions. To be specific,\nVQ-BNN inference for data streams is given by temporal exponential smoothing of\nrecent predictions. The computational cost of this model is almost the same as\nthat of non-Bayesian NNs. Experiments including semantic segmentation on\nreal-world data show that this model performs significantly faster than BNNs\nwhile estimating predictive results comparable to or superior to the results of\nBNNs.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jul 2019 18:15:56 GMT"}, {"version": "v2", "created": "Fri, 11 Sep 2020 16:12:37 GMT"}, {"version": "v3", "created": "Mon, 25 Jan 2021 07:15:21 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Park", "Namuk", ""], ["Lee", "Taekyu", ""], ["Kim", "Songkuk", ""]]}, {"id": "1907.05912", "submitter": "Aaron Ferber", "authors": "Aaron Ferber, Bryan Wilder, Bistra Dilkina, Milind Tambe", "title": "MIPaaL: Mixed Integer Program as a Layer", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning components commonly appear in larger decision-making\npipelines; however, the model training process typically focuses only on a loss\nthat measures accuracy between predicted values and ground truth values.\nDecision-focused learning explicitly integrates the downstream decision problem\nwhen training the predictive model, in order to optimize the quality of\ndecisions induced by the predictions. It has been successfully applied to\nseveral limited combinatorial problem classes, such as those that can be\nexpressed as linear programs (LP), and submodular optimization. However, these\nprevious applications have uniformly focused on problems from specific classes\nwith simple constraints. Here, we enable decision-focused learning for the\nbroad class of problems that can be encoded as a Mixed Integer Linear Program\n(MIP), hence supporting arbitrary linear constraints over discrete and\ncontinuous variables. We show how to differentiate through a MIP by employing a\ncutting planes solution approach, which is an exact algorithm that iteratively\nadds constraints to a continuous relaxation of the problem until an integral\nsolution is found. We evaluate our new end-to-end approach on several real\nworld domains and show that it outperforms the standard two phase approaches\nthat treat prediction and prescription separately, as well as a baseline\napproach of simply applying decision-focused learning to the LP relaxation of\nthe MIP.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jul 2019 18:22:09 GMT"}, {"version": "v2", "created": "Wed, 17 Jul 2019 18:48:17 GMT"}], "update_date": "2019-07-19", "authors_parsed": [["Ferber", "Aaron", ""], ["Wilder", "Bryan", ""], ["Dilkina", "Bistra", ""], ["Tambe", "Milind", ""]]}, {"id": "1907.05928", "submitter": "Prashant Kumar", "authors": "Prashant Kumar, Kushal Sinha, Nandkishor Nere, Yujin Shin, Raimundo\n  Ho, Ahmad Sheikh, Laurie Mlinar", "title": "A machine learning framework for computationally expensive transient\n  models", "comments": "25 pages and 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.data-an cs.LG physics.app-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The promise of machine learning has been explored in a variety of scientific\ndisciplines in the last few years, however, its application on first-principles\nbased computationally expensive tools is still in nascent stage. Even with the\nadvances in computational resources and power, transient simulations of\nlarge-scale dynamic systems using a variety of the first-principles based\ncomputational tools are still limited. In this work, we propose an ensemble\napproach where we combine one such computationally expensive tool, called\ndiscrete element method (DEM), with a time-series forecasting method called\nauto-regressive integrated moving average (ARIMA) and machine-learning methods\nto significantly reduce the computational burden while retaining model accuracy\nand performance. The developed machine-learning model shows good predictability\nand agreement with the literature, demonstrating its tremendous potential in\nscientific computing.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jul 2019 19:47:31 GMT"}], "update_date": "2019-07-16", "authors_parsed": [["Kumar", "Prashant", ""], ["Sinha", "Kushal", ""], ["Nere", "Nandkishor", ""], ["Shin", "Yujin", ""], ["Ho", "Raimundo", ""], ["Sheikh", "Ahmad", ""], ["Mlinar", "Laurie", ""]]}, {"id": "1907.05943", "submitter": "Sanjay Chakraborty", "authors": "Agnip Dasgupta, Ardhendu Banerjee, Aniket Ghosh Dastidar, Antara\n  Barman, Sanjay Chakraborty", "title": "A Study and Analysis of a Feature Subset Selection Technique using\n  Penguin Search Optimization Algorithm (FS-PeSOA)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In today world of enormous amounts of data, it is very important to extract\nuseful knowledge from it. This can be accomplished by feature subset selection.\nFeature subset selection is a method of selecting a minimum number of features\nwith the help of which our machine can learn and predict which class a\nparticular data belongs to. We will introduce a new adaptive algorithm called\nFeature selection Penguin Search optimization algorithm which is a\nmetaheuristic approach. It is adapted from the natural hunting strategy of\npenguins in which a group of penguins take jumps at random depths and come back\nand share the status of food availability with other penguins and in this way,\nthe global optimum solution is found. In order to explore the feature subset\ncandidates, the bioinspired approach Penguin Search optimization algorithm\ngenerates during the process a trial feature subset and estimates its fitness\nvalue by using three different classifiers for each case: Random Forest,\nNearest Neighbour and Support Vector Machines. However, we are planning to\nimplement our proposed approach Feature selection Penguin Search optimization\nalgorithm on some well known benchmark datasets collected from the UCI\nrepository and also try to evaluate and compare its classification accuracy\nwith some state of art algorithms.\n", "versions": [{"version": "v1", "created": "Sat, 13 Jul 2019 05:27:57 GMT"}], "update_date": "2019-07-16", "authors_parsed": [["Dasgupta", "Agnip", ""], ["Banerjee", "Ardhendu", ""], ["Dastidar", "Aniket Ghosh", ""], ["Barman", "Antara", ""], ["Chakraborty", "Sanjay", ""]]}, {"id": "1907.05944", "submitter": "Nguyen Kim Thang", "authors": "Evripidis Bampis, Dimitris Christou, Bruno Escoffier, Nguyen Kim Thang", "title": "Online learning for min-max discrete problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study various discrete nonlinear combinatorial optimization problems in an\nonline learning framework. In the first part, we address the question of\nwhether there are negative results showing that getting a vanishing (or even\nvanishing approximate) regret is computational hard. We provide a general\nreduction showing that many (min-max) polynomial time solvable problems not\nonly do not have a vanishing regret, but also no vanishing approximation\n$\\alpha$-regret, for some $\\alpha$ (unless $NP=BPP$). Then, we focus on a\nparticular min-max problem, the min-max version of the vertex cover problem\nwhich is solvable in polynomial time in the offline case. The previous\nreduction proves that there is no $(2-\\epsilon)$-regret online algorithm,\nunless Unique Game is in $BPP$; we prove a matching upper bound providing an\nonline algorithm based on the online gradient descent method. Then, we turn our\nattention to online learning algorithms that are based on an offline\noptimization oracle that, given a set of instances of the problem, is able to\ncompute the optimum static solution. We show that for different nonlinear\ndiscrete optimization problems, it is strongly $NP$-hard to solve the offline\noptimization oracle, even for problems that can be solved in polynomial time in\nthe static case (e.g. min-max vertex cover, min-max perfect matching, etc.). On\nthe positive side, we present an online algorithm with vanishing regret that is\nbased on the follow the perturbed leader algorithm for a generalized knapsack\nproblem.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jul 2019 20:37:07 GMT"}, {"version": "v2", "created": "Tue, 23 Jun 2020 07:37:51 GMT"}], "update_date": "2020-06-24", "authors_parsed": [["Bampis", "Evripidis", ""], ["Christou", "Dimitris", ""], ["Escoffier", "Bruno", ""], ["Thang", "Nguyen Kim", ""]]}, {"id": "1907.05964", "submitter": "Sandip Sinha", "authors": "Frank Ban, Xi Chen, Rocco A. Servedio, Sandip Sinha", "title": "Efficient average-case population recovery in the presence of insertions\n  and deletions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Several recent works have considered the \\emph{trace reconstruction problem},\nin which an unknown source string $x\\in\\{0,1\\}^n$ is transmitted through a\nprobabilistic channel which may randomly delete coordinates or insert random\nbits, resulting in a \\emph{trace} of $x$. The goal is to reconstruct the\noriginal string~$x$ from independent traces of $x$. While the best algorithms\nknown for worst-case strings use $\\exp(O(n^{1/3}))$ traces\n\\cite{DOS17,NazarovPeres17}, highly efficient algorithms are known\n\\cite{PZ17,HPP18} for the \\emph{average-case} version, in which $x$ is\nuniformly random. We consider a generalization of this average-case trace\nreconstruction problem, which we call \\emph{average-case population recovery in\nthe presence of insertions and deletions}. In this problem, there is an unknown\ndistribution $\\cal{D}$ over $s$ unknown source strings $x^1,\\dots,x^s \\in\n\\{0,1\\}^n$, and each sample is independently generated by drawing some $x^i$\nfrom $\\cal{D}$ and returning an independent trace of $x^i$.\n  Building on \\cite{PZ17} and \\cite{HPP18}, we give an efficient algorithm for\nthis problem. For any support size $s \\leq \\smash{\\exp(\\Theta(n^{1/3}))}$, for\na $1-o(1)$ fraction of all $s$-element support sets $\\{x^1,\\dots,x^s\\} \\subset\n\\{0,1\\}^n$, for every distribution $\\cal{D}$ supported on $\\{x^1,\\dots,x^s\\}$,\nour algorithm efficiently recovers ${\\cal D}$ up to total variation distance\n$\\epsilon$ with high probability, given access to independent traces of\nindependent draws from $\\cal{D}$. The algorithm runs in time\npoly$(n,s,1/\\epsilon)$ and its sample complexity is\npoly$(s,1/\\epsilon,\\exp(\\log^{1/3}n)).$ This polynomial dependence on the\nsupport size $s$ is in sharp contrast with the \\emph{worst-case} version (when\n$x^1,\\dots,x^s$ may be any strings in $\\{0,1\\}^n$), in which the sample\ncomplexity of the most efficient known algorithm \\cite{BCFSS19} is doubly\nexponential in $s$.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jul 2019 21:39:43 GMT"}], "update_date": "2019-07-16", "authors_parsed": [["Ban", "Frank", ""], ["Chen", "Xi", ""], ["Servedio", "Rocco A.", ""], ["Sinha", "Sandip", ""]]}, {"id": "1907.05980", "submitter": "Mathieu Lauri\\`ere", "authors": "Ren\\'e Carmona, Mathieu Lauri\\`ere", "title": "Convergence Analysis of Machine Learning Algorithms for the Numerical\n  Solution of Mean Field Control and Games: I -- The Ergodic Case", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose two algorithms for the solution of the optimal control of ergodic\nMcKean-Vlasov dynamics. Both algorithms are based on approximations of the\ntheoretical solutions by neural networks, the latter being characterized by\ntheir architecture and a set of parameters. This allows the use of modern\nmachine learning tools, and efficient implementations of stochastic gradient\ndescent.The first algorithm is based on the idiosyncrasies of the ergodic\noptimal control problem. We provide a mathematical proof of the convergence of\nthe approximation scheme, and we analyze rigorously the approximation by\ncontrolling the different sources of error. The second method is an adaptation\nof the deep Galerkin method to the system of partial differential equations\nissued from the optimality condition. We demonstrate the efficiency of these\nalgorithms on several numerical examples, some of them being chosen to show\nthat our algorithms succeed where existing ones failed. We also argue that both\nmethods can easily be applied to problems in dimensions larger than what can be\nfound in the existing literature. Finally, we illustrate the fact that,\nalthough the first algorithm is specifically designed for mean field control\nproblems, the second one is more general and can also be applied to the partial\ndifferential equation systems arising in the theory of mean field games.\n", "versions": [{"version": "v1", "created": "Sat, 13 Jul 2019 00:18:45 GMT"}, {"version": "v2", "created": "Mon, 29 Mar 2021 17:35:42 GMT"}], "update_date": "2021-03-30", "authors_parsed": [["Carmona", "Ren\u00e9", ""], ["Lauri\u00e8re", "Mathieu", ""]]}, {"id": "1907.05982", "submitter": "Stefan Lattner", "authors": "Stefan Lattner, Monika D\\\"orfler, Andreas Arzt", "title": "Learning Complex Basis Functions for Invariant Representations of Audio", "comments": "Paper accepted at the 20th International Society for Music\n  Information Retrieval Conference, ISMIR 2019, Delft, The Netherlands,\n  November 4-8; 8 pages, 4 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.CV cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning features from data has shown to be more successful than using\nhand-crafted features for many machine learning tasks. In music information\nretrieval (MIR), features learned from windowed spectrograms are highly variant\nto transformations like transposition or time-shift. Such variances are\nundesirable when they are irrelevant for the respective MIR task. We propose an\narchitecture called Complex Autoencoder (CAE) which learns features invariant\nto orthogonal transformations. Mapping signals onto complex basis functions\nlearned by the CAE results in a transformation-invariant \"magnitude space\" and\na transformation-variant \"phase space\". The phase space is useful to infer\ntransformations between data pairs. When exploiting the invariance-property of\nthe magnitude space, we achieve state-of-the-art results in audio-to-score\nalignment and repeated section discovery for audio. A PyTorch implementation of\nthe CAE, including the repeated section discovery method, is available online.\n", "versions": [{"version": "v1", "created": "Sat, 13 Jul 2019 00:23:26 GMT"}], "update_date": "2019-07-16", "authors_parsed": [["Lattner", "Stefan", ""], ["D\u00f6rfler", "Monika", ""], ["Arzt", "Andreas", ""]]}, {"id": "1907.05984", "submitter": "Burak Bartan", "authors": "Burak Bartan, Mert Pilanci", "title": "Distributed Black-Box Optimization via Error Correcting Codes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a novel distributed derivative-free optimization framework that\nis resilient to stragglers. The proposed method employs coded search directions\nat which the objective function is evaluated, and a decoding step to find the\nnext iterate. Our framework can be seen as an extension of evolution strategies\nand structured exploration methods where structured search directions were\nutilized. As an application, we consider black-box adversarial attacks on deep\nconvolutional neural networks. Our numerical experiments demonstrate a\nsignificant improvement in the computation times.\n", "versions": [{"version": "v1", "created": "Sat, 13 Jul 2019 00:36:17 GMT"}], "update_date": "2019-07-16", "authors_parsed": [["Bartan", "Burak", ""], ["Pilanci", "Mert", ""]]}, {"id": "1907.05991", "submitter": "Yusuke Kawamoto", "authors": "Yusuke Kawamoto and Takao Murakami", "title": "Local Distribution Obfuscation via Probability Coupling", "comments": "Full version of Allerton 2019 paper (This paper extends some part of\n  the unpublished v3 of arXiv:1812.00939, while v4 of arXiv:1812.00939 extends\n  the other part and is published in ESORICS'19.)", "journal-ref": null, "doi": "10.1109/ALLERTON.2019.8919803", "report-no": null, "categories": "cs.CR cs.DB cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a general model for the local obfuscation of probability\ndistributions by probabilistic perturbation, e.g., by adding differentially\nprivate noise, and investigate its theoretical properties. Specifically, we\nrelax a notion of distribution privacy (DistP) by generalizing it to\ndivergence, and propose local obfuscation mechanisms that provide divergence\ndistribution privacy. To provide f-divergence distribution privacy, we prove\nthat probabilistic perturbation noise should be added proportionally to the\nEarth mover's distance between the probability distributions that we want to\nmake indistinguishable. Furthermore, we introduce a local obfuscation\nmechanism, which we call a coupling mechanism, that provides divergence\ndistribution privacy while optimizing the utility of obfuscated data by using\nexact/approximate auxiliary information on the input distributions we want to\nprotect.\n", "versions": [{"version": "v1", "created": "Sat, 13 Jul 2019 01:13:40 GMT"}, {"version": "v2", "created": "Mon, 30 Sep 2019 14:32:11 GMT"}], "update_date": "2019-12-16", "authors_parsed": [["Kawamoto", "Yusuke", ""], ["Murakami", "Takao", ""]]}, {"id": "1907.06010", "submitter": "George Monta\\~nez", "authors": "George D. Montanez, Jonathan Hayase, Julius Lauw, Dominique Macias,\n  Akshay Trikha, Julia Vendemiatti", "title": "The Futility of Bias-Free Learning and Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Building on the view of machine learning as search, we demonstrate the\nnecessity of bias in learning, quantifying the role of bias (measured relative\nto a collection of possible datasets, or more generally, information resources)\nin increasing the probability of success. For a given degree of bias towards a\nfixed target, we show that the proportion of favorable information resources is\nstrictly bounded from above. Furthermore, we demonstrate that bias is a\nconserved quantity, such that no algorithm can be favorably biased towards many\ndistinct targets simultaneously. Thus bias encodes trade-offs. The probability\nof success for a task can also be measured geometrically, as the angle of\nagreement between what holds for the actual task and what is assumed by the\nalgorithm, represented in its bias. Lastly, finding a favorably biasing\ndistribution over a fixed set of information resources is provably difficult,\nunless the set of resources itself is already favorable with respect to the\ngiven task and algorithm.\n", "versions": [{"version": "v1", "created": "Sat, 13 Jul 2019 05:16:39 GMT"}], "update_date": "2019-07-16", "authors_parsed": [["Montanez", "George D.", ""], ["Hayase", "Jonathan", ""], ["Lauw", "Julius", ""], ["Macias", "Dominique", ""], ["Trikha", "Akshay", ""], ["Vendemiatti", "Julia", ""]]}, {"id": "1907.06011", "submitter": "Peter Y. Lu", "authors": "Peter Y. Lu, Samuel Kim, Marin Solja\\v{c}i\\'c", "title": "Extracting Interpretable Physical Parameters from Spatiotemporal Systems\n  using Unsupervised Learning", "comments": "19 pages, 9 figures, 2 tables", "journal-ref": "Phys. Rev. X 10, 031056 (2020)", "doi": "10.1103/PhysRevX.10.031056", "report-no": null, "categories": "physics.comp-ph cs.LG physics.data-an stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Experimental data is often affected by uncontrolled variables that make\nanalysis and interpretation difficult. For spatiotemporal systems, this problem\nis further exacerbated by their intricate dynamics. Modern machine learning\nmethods are particularly well-suited for analyzing and modeling complex\ndatasets, but to be effective in science, the result needs to be interpretable.\nWe demonstrate an unsupervised learning technique for extracting interpretable\nphysical parameters from noisy spatiotemporal data and for building a\ntransferable model of the system. In particular, we implement a\nphysics-informed architecture based on variational autoencoders that is\ndesigned for analyzing systems governed by partial differential equations\n(PDEs). The architecture is trained end-to-end and extracts latent parameters\nthat parameterize the dynamics of a learned predictive model for the system. To\ntest our method, we train our model on simulated data from a variety of PDEs\nwith varying dynamical parameters that act as uncontrolled variables. Numerical\nexperiments show that our method can accurately identify relevant parameters\nand extract them from raw and even noisy spatiotemporal data (tested with\nroughly 10% added noise). These extracted parameters correlate well (linearly\nwith $R^2 > 0.95$) with the ground truth physical parameters used to generate\nthe datasets. We then apply this method to nonlinear fiber propagation data,\ngenerated by an ab-initio simulation, to demonstrate its capabilities on a more\nrealistic dataset. Our method for discovering interpretable latent parameters\nin spatiotemporal systems will allow us to better analyze and understand\nreal-world phenomena and datasets, which often have unknown and uncontrolled\nvariables that alter the system dynamics and cause varying behaviors that are\ndifficult to disentangle.\n", "versions": [{"version": "v1", "created": "Sat, 13 Jul 2019 05:21:05 GMT"}, {"version": "v2", "created": "Mon, 19 Aug 2019 04:42:36 GMT"}, {"version": "v3", "created": "Mon, 14 Sep 2020 19:04:01 GMT"}], "update_date": "2020-09-16", "authors_parsed": [["Lu", "Peter Y.", ""], ["Kim", "Samuel", ""], ["Solja\u010di\u0107", "Marin", ""]]}, {"id": "1907.06013", "submitter": "Ahmed Qureshi", "authors": "Ahmed H. Qureshi, Yinglong Miao, Anthony Simeonov and Michael C. Yip", "title": "Motion Planning Networks: Bridging the Gap Between Learning-based and\n  Classical Motion Planners", "comments": "Supplementary material including implementation parameters and\n  project videos are available at https://sites.google.com/view/mpnet/home.\n  This work has been accepted for publication at IEEE Transactions on Robotics", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes Motion Planning Networks (MPNet), a computationally\nefficient, learning-based neural planner for solving motion planning problems.\nMPNet uses neural networks to learn general near-optimal heuristics for path\nplanning in seen and unseen environments. It takes environment information such\nas raw point-cloud from depth sensors, as well as a robot's initial and desired\ngoal configurations and recursively calls itself to bidirectionally generate\nconnectable paths. In addition to finding directly connectable and near-optimal\npaths in a single pass, we show that worst-case theoretical guarantees can be\nproven if we merge this neural network strategy with classical sample-based\nplanners in a hybrid approach while still retaining significant computational\nand optimality improvements. To train the MPNet models, we present an active\ncontinual learning approach that enables MPNet to learn from streaming data and\nactively ask for expert demonstrations when needed, drastically reducing data\nfor training. We validate MPNet against gold-standard and state-of-the-art\nplanning methods in a variety of problems from 2D to 7D robot configuration\nspaces in challenging and cluttered environments, with results showing\nsignificant and consistently stronger performance metrics, and motivating\nneural planning in general as a modern strategy for solving motion planning\nproblems efficiently.\n", "versions": [{"version": "v1", "created": "Sat, 13 Jul 2019 05:34:01 GMT"}, {"version": "v2", "created": "Mon, 30 Dec 2019 21:38:01 GMT"}, {"version": "v3", "created": "Sat, 27 Jun 2020 19:14:00 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Qureshi", "Ahmed H.", ""], ["Miao", "Yinglong", ""], ["Simeonov", "Anthony", ""], ["Yip", "Michael C.", ""]]}, {"id": "1907.06014", "submitter": "Qipei Mei", "authors": "Qipei Mei and Mustafa G\\\"ul", "title": "A Cost Effective Solution for Road Crack Inspection using Cameras and\n  Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic crack detection on pavement surfaces is an important research field\nin the scope of developing an intelligent transportation infrastructure system.\nIn this paper, a cost effective solution for road crack inspection by mounting\ncommercial grade sport camera, GoPro, on the rear of the moving vehicle is\nintroduced. Also, a novel method called ConnCrack combining conditional\nWasserstein generative adversarial network and connectivity maps is proposed\nfor road crack detection. In this method, a 121-layer densely connected neural\nnetwork with deconvolution layers for multi-level feature fusion is used as\ngenerator, and a 5-layer fully convolutional network is used as discriminator.\nTo overcome the scattered output issue related to deconvolution layers,\nconnectivity maps are introduced to represent the crack information within the\nproposed ConnCrack. The proposed method is tested on a publicly available\ndataset as well our collected data. The results show that the proposed method\nachieves state-of-the-art performance compared with other existing methods in\nterms of precision, recall and F1 score.\n", "versions": [{"version": "v1", "created": "Sat, 13 Jul 2019 05:43:06 GMT"}, {"version": "v2", "created": "Tue, 22 Oct 2019 04:29:26 GMT"}], "update_date": "2019-10-23", "authors_parsed": [["Mei", "Qipei", ""], ["G\u00fcl", "Mustafa", ""]]}, {"id": "1907.06022", "submitter": "Yantao Wei", "authors": "Yantao Wei, Shujian Yu, Luis Sanchez Giraldo, Jose C. Principe", "title": "Multiscale Principle of Relevant Information for Hyperspectral Image\n  Classification", "comments": "Mansucript to be published in Machine Learning Journal (Springer).\n  Code available at\n  https://github.com/SJYuCNEL/Principle-of-Relevant-Information-and-HSI-Classification", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a novel architecture, termed multiscale principle of\nrelevant information (MPRI), to learn discriminative spectral-spatial features\nfor hyperspectral image (HSI) classification. MPRI inherits the merits of the\nprinciple of relevant information (PRI) to effectively extract multiscale\ninformation embedded in the given data, and also takes advantage of the\nmultilayer structure to learn representations in a coarse-to-fine manner.\nSpecifically, MPRI performs spectral-spatial pixel characterization (using PRI)\nand feature dimensionality reduction (using regularized linear discriminant\nanalysis) iteratively and successively. Extensive experiments on three\nbenchmark data sets demonstrate that MPRI outperforms existing state-of-the-art\nmethods (including deep learning based ones) qualitatively and quantitatively,\nespecially in the scenario of limited training samples. Code of MPRI is\navailable at \\url{http://bit.ly/MPRI_HSI}.\n", "versions": [{"version": "v1", "created": "Sat, 13 Jul 2019 07:29:42 GMT"}, {"version": "v2", "created": "Fri, 15 May 2020 17:12:17 GMT"}, {"version": "v3", "created": "Sat, 5 Jun 2021 01:39:18 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Wei", "Yantao", ""], ["Yu", "Shujian", ""], ["Giraldo", "Luis Sanchez", ""], ["Principe", "Jose C.", ""]]}, {"id": "1907.06032", "submitter": "Yuqing Xia", "authors": "Zhenyue Zhang and Yuqing Xia", "title": "Minimal Sample Subspace Learning: Theory and Algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Subspace segmentation or subspace learning is a challenging and complicated\ntask in machine learning. This paper builds a primary frame and solid\ntheoretical bases for the minimal subspace segmentation (MSS) of finite\nsamples. Existence and conditional uniqueness of MSS are discussed with\nconditions generally satisfied in applications. Utilizing weak prior\ninformation of MSS, the minimality inspection of segments is further simplified\nto the prior detection of partitions. The MSS problem is then modeled as a\ncomputable optimization problem via self-expressiveness of samples. A closed\nform of representation matrices is first given for the self-expressiveness, and\nthe connection of diagonal blocks is then addressed. The MSS model uses a rank\nrestriction on the sum of segment ranks. Theoretically, it can retrieve the\nminimal sample subspaces that could be heavily intersected. The optimization\nproblem is solved via a basic manifold conjugate gradient algorithm,\nalternative optimization and hybrid optimization, taking into account of\nsolving both the primal MSS problem and its pseudo-dual problem. The MSS model\nis further modified for handling noisy data, and solved by an ADMM algorithm.\nThe reported experiments show the strong ability of the MSS method on\nretrieving minimal sample subspaces that are heavily intersected.\n", "versions": [{"version": "v1", "created": "Sat, 13 Jul 2019 09:15:02 GMT"}, {"version": "v2", "created": "Sun, 8 Sep 2019 04:13:06 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Zhang", "Zhenyue", ""], ["Xia", "Yuqing", ""]]}, {"id": "1907.06034", "submitter": "Fan Mo", "authors": "Fan Mo, Ali Shahin Shamsabadi, Kleomenis Katevas, Andrea Cavallaro,\n  Hamed Haddadi", "title": "Towards Characterizing and Limiting Information Exposure in DNN Layers", "comments": "5 pages, 6 figures, CCS PPML workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pre-trained Deep Neural Network (DNN) models are increasingly used in\nsmartphones and other user devices to enable prediction services, leading to\npotential disclosures of (sensitive) information from training data captured\ninside these models. Based on the concept of generalization error, we propose a\nframework to measure the amount of sensitive information memorized in each\nlayer of a DNN. Our results show that, when considered individually, the last\nlayers encode a larger amount of information from the training data compared to\nthe first layers. We find that, while the neuron of convolutional layers can\nexpose more (sensitive) information than that of fully connected layers, the\nsame DNN architecture trained with different datasets has similar exposure per\nlayer. We evaluate an architecture to protect the most sensitive layers within\nthe memory limits of Trusted Execution Environment (TEE) against potential\nwhite-box membership inference attacks without the significant computational\noverhead.\n", "versions": [{"version": "v1", "created": "Sat, 13 Jul 2019 09:17:57 GMT"}], "update_date": "2019-07-16", "authors_parsed": [["Mo", "Fan", ""], ["Shamsabadi", "Ali Shahin", ""], ["Katevas", "Kleomenis", ""], ["Cavallaro", "Andrea", ""], ["Haddadi", "Hamed", ""]]}, {"id": "1907.06040", "submitter": "Yuqing Du", "authors": "Qunsong Zeng, Yuqing Du, Kin K. Leung, and Kaibin Huang", "title": "Energy-Efficient Radio Resource Allocation for Federated Edge Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Edge machine learning involves the development of learning algorithms at the\nnetwork edge to leverage massive distributed data and computation resources.\nAmong others, the framework of federated edge learning (FEEL) is particularly\npromising for its data-privacy preservation. FEEL coordinates global model\ntraining at a server and local model training at edge devices over wireless\nlinks. In this work, we explore the new direction of energy-efficient radio\nresource management (RRM) for FEEL. To reduce devices' energy consumption, we\npropose energy-efficient strategies for bandwidth allocation and scheduling.\nThey adapt to devices' channel states and computation capacities so as to\nreduce their sum energy consumption while warranting learning performance. In\ncontrast with the traditional rate-maximization designs, the derived optimal\npolicies allocate more bandwidth to those scheduled devices with weaker\nchannels or poorer computation capacities, which are the bottlenecks of\nsynchronized model updates in FEEL. On the other hand, the scheduling priority\nfunction derived in closed form gives preferences to devices with better\nchannels and computation capacities. Substantial energy reduction contributed\nby the proposed strategies is demonstrated in learning experiments.\n", "versions": [{"version": "v1", "created": "Sat, 13 Jul 2019 09:57:12 GMT"}], "update_date": "2019-07-16", "authors_parsed": [["Zeng", "Qunsong", ""], ["Du", "Yuqing", ""], ["Leung", "Kin K.", ""], ["Huang", "Kaibin", ""]]}, {"id": "1907.06048", "submitter": "Abhijit Mahalunkar", "authors": "Abhijit Mahalunkar and John D. Kelleher", "title": "Multi-Element Long Distance Dependencies: Using SPk Languages to Explore\n  the Characteristics of Long-Distance Dependencies", "comments": "To appear in ACL 2019 workshop on Deep Learning and Formal Languages:\n  Building Bridges. arXiv admin note: substantial text overlap with\n  arXiv:1810.02966", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.FL stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  In order to successfully model Long Distance Dependencies (LDDs) it is\nnecessary to understand the full-range of the characteristics of the LDDs\nexhibited in a target dataset. In this paper, we use Strictly k-Piecewise\nlanguages to generate datasets with various properties. We then compute the\ncharacteristics of the LDDs in these datasets using mutual information and\nanalyze the impact of factors such as (i) k, (ii) length of LDDs, (iii)\nvocabulary size, (iv) forbidden subsequences, and (v) dataset size. This\nanalysis reveal that the number of interacting elements in a dependency is an\nimportant characteristic of LDDs. This leads us to the challenge of modelling\nmulti-element long-distance dependencies. Our results suggest that attention\nmechanisms in neural networks may aide in modeling datasets with multi-element\nlong-distance dependencies. However, we conclude that there is a need to\ndevelop more efficient attention mechanisms to address this issue.\n", "versions": [{"version": "v1", "created": "Sat, 13 Jul 2019 11:27:13 GMT"}], "update_date": "2020-12-09", "authors_parsed": [["Mahalunkar", "Abhijit", ""], ["Kelleher", "John D.", ""]]}, {"id": "1907.06051", "submitter": "Giannis Nikolentzos", "authors": "Giannis Nikolentzos, George Dasoulas, Michalis Vazirgiannis", "title": "k-hop Graph Neural Networks", "comments": "Accepted at Neural Networks", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph neural networks (GNNs) have emerged recently as a powerful architecture\nfor learning node and graph representations. Standard GNNs have the same\nexpressive power as the Weisfeiler-Leman test of graph isomorphism in terms of\ndistinguishing non-isomorphic graphs. However, it was recently shown that this\ntest cannot identify fundamental graph properties such as connectivity and\ntriangle freeness. We show that GNNs also suffer from the same limitation. To\naddress this limitation, we propose a more expressive architecture, k-hop GNNs,\nwhich updates a node's representation by aggregating information not only from\nits direct neighbors, but from its k-hop neighborhood. We show that the\nproposed architecture can identify fundamental graph properties. We evaluate\nthe proposed architecture on standard node classification and graph\nclassification datasets. Our experimental evaluation confirms our theoretical\nfindings since the proposed model achieves performance better or comparable to\nstandard GNNs and to state-of-the-art algorithms.\n", "versions": [{"version": "v1", "created": "Sat, 13 Jul 2019 11:31:57 GMT"}, {"version": "v2", "created": "Sun, 9 Aug 2020 21:50:43 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Nikolentzos", "Giannis", ""], ["Dasoulas", "George", ""], ["Vazirgiannis", "Michalis", ""]]}, {"id": "1907.06053", "submitter": "Marek Kopicki", "authors": "Marek Kopicki, Dominik Belter and Jeremy L. Wyatt", "title": "Learning better generative models for dexterous, single-view grasping of\n  novel objects", "comments": "19 pages, 15 figures, 7 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper concerns the problem of how to learn to grasp dexterously, so as\nto be able to then grasp novel objects seen only from a single view-point.\nRecently, progress has been made in data-efficient learning of generative grasp\nmodels which transfer well to novel objects. These generative grasp models are\nlearned from demonstration (LfD). One weakness is that, as this paper shall\nshow, grasp transfer under challenging single view conditions is unreliable.\nSecond, the number of generative model elements rises linearly in the number of\ntraining examples. This, in turn, limits the potential of these generative\nmodels for generalisation and continual improvement. In this paper, it is shown\nhow to address these problems. Several technical contributions are made: (i) a\nview-based model of a grasp; (ii) a method for combining and compressing\nmultiple grasp models; (iii) a new way of evaluating contacts that is used both\nto generate and to score grasps. These, together, improve both grasp\nperformance and reduce the number of models learned for grasp transfer. These\nadvances, in turn, also allow the introduction of autonomous training, in which\nthe robot learns from self-generated grasps. Evaluation on a challenging test\nset shows that, with innovations (i)-(iii) deployed, grasp transfer success\nrises from 55.1% to 81.6%. By adding autonomous training this rises to 87.8%.\nThese differences are statistically significant. In total, across all\nexperiments, 539 test grasps were executed on real objects.\n", "versions": [{"version": "v1", "created": "Sat, 13 Jul 2019 11:37:32 GMT"}], "update_date": "2019-07-16", "authors_parsed": [["Kopicki", "Marek", ""], ["Belter", "Dominik", ""], ["Wyatt", "Jeremy L.", ""]]}, {"id": "1907.06058", "submitter": "Maria Bampa", "authors": "Maria Bampa and Panagiotis Papapetrou", "title": "Aggregate-Eliminate-Predict: Detecting Adverse Drug Events from\n  Heterogeneous Electronic Health Records", "comments": "4 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of detecting adverse drug events in electronic\nhealthcare records. The challenge in this work is to aggregate heterogeneous\ndata types involving diagnosis codes, drug codes, as well as lab measurements.\nAn earlier framework proposed for the same problem demonstrated promising\npredictive performance for the random forest classifier by using only lab\nmeasurements as data features. We extend this framework, by additionally\nincluding diagnosis and drug prescription codes, concurrently. In addition, we\nemploy a recursive feature selection mechanism on top, that extracts the top-k\nmost important features. Our experimental evaluation on five medical datasets\nof adverse drug events and six different classifiers, suggests that the\nintegration of these additional features provides substantial and statistically\nsignificant improvements in terms of AUC, while employing medically relevant\nfeatures.\n", "versions": [{"version": "v1", "created": "Sat, 13 Jul 2019 11:46:19 GMT"}], "update_date": "2019-07-16", "authors_parsed": [["Bampa", "Maria", ""], ["Papapetrou", "Panagiotis", ""]]}, {"id": "1907.06062", "submitter": "Nibaran Das", "authors": "Bodhisatwa Mandal, Swarnendu Ghosh, Ritesh Sarkhel, Nibaran Das, Mita\n  Nasipuri", "title": "Using dynamic routing to extract intermediate features for developing\n  scalable capsule networks", "comments": "Second International Conference on Advanced Computational and\n  Communication Paradigms held at Sikkim Manipal Institute of Technology,\n  Sikkim, India during February 25 - 28 , 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Capsule networks have gained a lot of popularity in short time due to its\nunique approach to model equivariant class specific properties as capsules from\nimages. However the dynamic routing algorithm comes with a steep computational\ncomplexity. In the proposed approach we aim to create scalable versions of the\ncapsule networks that are much faster and provide better accuracy in problems\nwith higher number of classes. By using dynamic routing to extract intermediate\nfeatures instead of generating output class specific capsules, a large increase\nin the computational speed has been observed. Moreover, by extracting\nequivariant feature capsules instead of class specific capsules, the\ngeneralization capability of the network has also increased as a result of\nwhich there is a boost in accuracy.\n", "versions": [{"version": "v1", "created": "Sat, 13 Jul 2019 12:12:36 GMT"}], "update_date": "2019-07-16", "authors_parsed": [["Mandal", "Bodhisatwa", ""], ["Ghosh", "Swarnendu", ""], ["Sarkhel", "Ritesh", ""], ["Das", "Nibaran", ""], ["Nasipuri", "Mita", ""]]}, {"id": "1907.06064", "submitter": "Islem Rekik", "authors": "Can Gafuroglu and Islem Rekik", "title": "Image Evolution Trajectory Prediction and Classification from Baseline\n  using Learning-based Patch Atlas Selection for Early Diagnosis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Patients initially diagnosed with early mild cognitive impairment (eMCI) are\nknown to be a clinically heterogeneous group with very subtle patterns of brain\natrophy. To examine the boarders between normal controls (NC) and eMCI,\nMagnetic Resonance Imaging (MRI) was extensively used as a non-invasive imaging\nmodality to pin-down subtle changes in brain images of MCI patients. However,\neMCI research remains limited by the number of available MRI acquisition\ntimepoints. Ideally, one would learn how to diagnose MCI patients in an early\nstage from MRI data acquired at a single timepoint, while leveraging\n'non-existing' follow-up observations. To this aim, we propose novel supervised\nand unsupervised frameworks that learn how to jointly predict and label the\nevolution trajectory of intensity patches, each seeded at a specific brain\nlandmark, from a baseline intensity patch. Specifically, both strategies aim to\nidentify the best training atlas patches at baseline timepoint to predict and\nclassify the evolution trajectory of a given testing baseline patch. The\nsupervised technique learns how to select the best atlas patches by training\nbidirectional mappings from the space of pairwise patch similarities to their\ncorresponding prediction errors -when one patch was used to predict the other.\nOn the other hand, the unsupervised technique learns a manifold of baseline\natlas and testing patches using multiple kernels to well capture patch\ndistributions at multiple scales. Once the best baseline atlas patches are\nselected, we retrieve their evolution trajectories and average them to predict\nthe evolution trajectory of the testing baseline patch. Next, we input the\npredicted trajectories to an ensemble of linear classifiers, each trained at a\nspecific landmark. Our classification accuracy increased by up to 10% points in\ncomparison to single timepoint-based classification methods.\n", "versions": [{"version": "v1", "created": "Sat, 13 Jul 2019 12:17:00 GMT"}], "update_date": "2019-07-16", "authors_parsed": [["Gafuroglu", "Can", ""], ["Rekik", "Islem", ""]]}, {"id": "1907.06065", "submitter": "Yehui Tang", "authors": "Yehui Tang, Shan You, Chang Xu, Boxin Shi and Chao Xu", "title": "Bringing Giant Neural Networks Down to Earth with Unlabeled Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Compressing giant neural networks has gained much attention for their\nextensive applications on edge devices such as cellphones. During the\ncompressing process, one of the most important procedures is to retrain the\npre-trained models using the original training dataset. However, due to the\nconsideration of security, privacy or commercial profits, in practice, only a\nfraction of sample training data are made available, which makes the retraining\ninfeasible. To solve this issue, this paper proposes to resort to unlabeled\ndata in hand that can be cheaper to acquire. Specifically, we exploit the\nunlabeled data to mimic the classification characteristics of giant networks,\nso that the original capacity can be preserved nicely. Nevertheless, there\nexists a dataset bias between the labeled and unlabeled data, which may disturb\nthe training and degrade the performance. We thus fix this bias by an\nadversarial loss to make an alignment on the distributions of their low-level\nfeature representations. We further provide theoretical discussions about how\nthe unlabeled data help compressed networks to generalize better. Experimental\nresults demonstrate that the unlabeled data can significantly improve the\nperformance of the compressed networks.\n", "versions": [{"version": "v1", "created": "Sat, 13 Jul 2019 12:24:37 GMT"}, {"version": "v2", "created": "Fri, 20 Dec 2019 14:25:16 GMT"}], "update_date": "2019-12-23", "authors_parsed": [["Tang", "Yehui", ""], ["You", "Shan", ""], ["Xu", "Chang", ""], ["Shi", "Boxin", ""], ["Xu", "Chao", ""]]}, {"id": "1907.06066", "submitter": "Simo S\\\"arkk\\\"a", "authors": "Simo S\\\"arkk\\\"a", "title": "The Use of Gaussian Processes in System Identification", "comments": "To appear in Encyclopedia of systems and control, 2nd edition", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gaussian processes are used in machine learning to learn input-output\nmappings from observed data. Gaussian process regression is based on imposing a\nGaussian process prior on the unknown regressor function and statistically\nconditioning it on the observed data. In system identification, Gaussian\nprocesses are used to form time series prediction models such as non-linear\nfinite-impulse response (NFIR) models as well as non-linear autoregressive\n(NARX) models. Gaussian process state-space models (GPSS) can be used to learn\nthe dynamic and measurement models for a state-space representation of the\ninput-output data. Temporal and spatio-temporal Gaussian processes can be\ndirectly used to form regressor on the data in the time domain. The aim of this\narticle is to briefly outline the main directions in system identification\nmethods using Gaussian processes.\n", "versions": [{"version": "v1", "created": "Sat, 13 Jul 2019 12:28:11 GMT"}], "update_date": "2019-07-16", "authors_parsed": [["S\u00e4rkk\u00e4", "Simo", ""]]}, {"id": "1907.06090", "submitter": "Jesse Clifton", "authors": "Jesse Clifton, Lili Wu, Eric Laber", "title": "Parameterized Exploration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce Parameterized Exploration (PE), a simple family of methods for\nmodel-based tuning of the exploration schedule in sequential decision problems.\nUnlike common heuristics for exploration, our method accounts for the time\nhorizon of the decision problem as well as the agent's current state of\nknowledge of the dynamics of the decision problem. We show our method as\napplied to several common exploration techniques has superior performance\nrelative to un-tuned counterparts in Bernoulli and Gaussian multi-armed\nbandits, contextual bandits, and a Markov decision process based on a mobile\nhealth (mHealth) study. We also examine the effects of the accuracy of the\nestimated dynamics model on the performance of PE.\n", "versions": [{"version": "v1", "created": "Sat, 13 Jul 2019 14:55:11 GMT"}], "update_date": "2019-07-16", "authors_parsed": [["Clifton", "Jesse", ""], ["Wu", "Lili", ""], ["Laber", "Eric", ""]]}, {"id": "1907.06098", "submitter": "Brian Gaudet", "authors": "Brian Gaudet, Richard Linares, Roberto Furfaro", "title": "Seeker based Adaptive Guidance via Reinforcement Meta-Learning Applied\n  to Asteroid Close Proximity Operations", "comments": "Accepted for 2020 AAS Conference", "journal-ref": null, "doi": "10.1016/j.actaastro.2020.02.036", "report-no": null, "categories": "eess.SY astro-ph.IM cs.LG cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current practice for asteroid close proximity maneuvers requires extremely\naccurate characterization of the environmental dynamics and precise spacecraft\npositioning prior to the maneuver. This creates a delay of several months\nbetween the spacecraft's arrival and the ability to safely complete close\nproximity maneuvers. In this work we develop an adaptive integrated guidance,\nnavigation, and control system that can complete these maneuvers in\nenvironments with unknown dynamics, with initial conditions spanning a large\ndeployment region, and without a shape model of the asteroid. The system is\nimplemented as a policy optimized using reinforcement meta-learning. The\nspacecraft is equipped with an optical seeker that locks to either a terrain\nfeature, back-scattered light from a targeting laser, or an active beacon, and\nthe policy maps observations consisting of seeker angles and LIDAR range\nreadings directly to engine thrust commands. The policy implements a recurrent\nnetwork layer that allows the deployed policy to adapt real time to both\nenvironmental forces acting on the agent and internal disturbances such as\nactuator failure and center of mass variation. We validate the guidance system\nthrough simulated landing maneuvers in a six degrees-of-freedom simulator. The\nsimulator randomizes the asteroid's characteristics such as solar radiation\npressure, density, spin rate, and nutation angle, requiring the guidance and\ncontrol system to adapt to the environment. We also demonstrate robustness to\nactuator failure, sensor bias, and changes in the spacecraft's center of mass\nand inertia tensor. Finally, we suggest a concept of operations for asteroid\nclose proximity maneuvers that is compatible with the guidance system.\n", "versions": [{"version": "v1", "created": "Sat, 13 Jul 2019 15:41:46 GMT"}], "update_date": "2020-09-16", "authors_parsed": [["Gaudet", "Brian", ""], ["Linares", "Richard", ""], ["Furfaro", "Roberto", ""]]}, {"id": "1907.06099", "submitter": "Yueming Jin", "authors": "Yueming Jin, Huaxia Li, Qi Dou, Hao Chen, Jing Qin, Chi-Wing Fu,\n  Pheng-Ann Heng", "title": "Multi-Task Recurrent Convolutional Network with Correlation Loss for\n  Surgical Video Analysis", "comments": "Minor Revision at Medical Image Analysis", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Surgical tool presence detection and surgical phase recognition are two\nfundamental yet challenging tasks in surgical video analysis and also very\nessential components in various applications in modern operating rooms. While\nthese two analysis tasks are highly correlated in clinical practice as the\nsurgical process is well-defined, most previous methods tackled them\nseparately, without making full use of their relatedness. In this paper, we\npresent a novel method by developing a multi-task recurrent convolutional\nnetwork with correlation loss (MTRCNet-CL) to exploit their relatedness to\nsimultaneously boost the performance of both tasks. Specifically, our proposed\nMTRCNet-CL model has an end-to-end architecture with two branches, which share\nearlier feature encoders to extract general visual features while holding\nrespective higher layers targeting for specific tasks. Given that temporal\ninformation is crucial for phase recognition, long-short term memory (LSTM) is\nexplored to model the sequential dependencies in the phase recognition branch.\nMore importantly, a novel and effective correlation loss is designed to model\nthe relatedness between tool presence and phase identification of each video\nframe, by minimizing the divergence of predictions from the two branches.\nMutually leveraging both low-level feature sharing and high-level prediction\ncorrelating, our MTRCNet-CL method can encourage the interactions between the\ntwo tasks to a large extent, and hence can bring about benefits to each other.\nExtensive experiments on a large surgical video dataset (Cholec80) demonstrate\noutstanding performance of our proposed method, consistently exceeding the\nstate-of-the-art methods by a large margin (e.g., 89.1% v.s. 81.0% for the mAP\nin tool presence detection and 87.4% v.s. 84.5% for F1 score in phase\nrecognition). The code can be found on our project website.\n", "versions": [{"version": "v1", "created": "Sat, 13 Jul 2019 15:49:00 GMT"}], "update_date": "2019-07-16", "authors_parsed": [["Jin", "Yueming", ""], ["Li", "Huaxia", ""], ["Dou", "Qi", ""], ["Chen", "Hao", ""], ["Qin", "Jing", ""], ["Fu", "Chi-Wing", ""], ["Heng", "Pheng-Ann", ""]]}, {"id": "1907.06119", "submitter": "Nibaran Das", "authors": "Swarnendu Ghosh, Nibaran Das, Ishita Das, Ujjwal Maulik", "title": "Understanding Deep Learning Techniques for Image Segmentation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The machine learning community has been overwhelmed by a plethora of deep\nlearning based approaches. Many challenging computer vision tasks such as\ndetection, localization, recognition and segmentation of objects in\nunconstrained environment are being efficiently addressed by various types of\ndeep neural networks like convolutional neural networks, recurrent networks,\nadversarial networks, autoencoders and so on. While there have been plenty of\nanalytical studies regarding the object detection or recognition domain, many\nnew deep learning techniques have surfaced with respect to image segmentation\ntechniques. This paper approaches these various deep learning techniques of\nimage segmentation from an analytical perspective. The main goal of this work\nis to provide an intuitive understanding of the major techniques that has made\nsignificant contribution to the image segmentation domain. Starting from some\nof the traditional image segmentation approaches, the paper progresses\ndescribing the effect deep learning had on the image segmentation domain.\nThereafter, most of the major segmentation algorithms have been logically\ncategorized with paragraphs dedicated to their unique contribution. With an\nample amount of intuitive explanations, the reader is expected to have an\nimproved ability to visualize the internal dynamics of these processes.\n", "versions": [{"version": "v1", "created": "Sat, 13 Jul 2019 19:23:42 GMT"}], "update_date": "2019-07-16", "authors_parsed": [["Ghosh", "Swarnendu", ""], ["Das", "Nibaran", ""], ["Das", "Ishita", ""], ["Maulik", "Ujjwal", ""]]}, {"id": "1907.06123", "submitter": "Viktor Bengs", "authors": "Viktor Bengs and Eyke H\\\"ullermeier", "title": "Preselection Bandits under the Plackett-Luce Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce the Preselection Bandit problem, in which the\nlearner preselects a subset of arms (choice alternatives) for a user, which\nthen chooses the final arm from this subset. The learner is not aware of the\nuser's preferences, but can learn them from observed choices. In our concrete\nsetting, we allow these choices to be stochastic and model the user's actions\nby means of the Plackett-Luce model. The learner's main task is to preselect\nsubsets that eventually lead to highly preferred choices. To formalize this\ngoal, we introduce a reasonable notion of regret and derive lower bounds on the\nexpected regret. Moreover, we propose algorithms for which the upper bound on\nexpected regret matches the lower bound up to a logarithmic term of the time\nhorizon.\n", "versions": [{"version": "v1", "created": "Sat, 13 Jul 2019 20:27:15 GMT"}], "update_date": "2019-07-16", "authors_parsed": [["Bengs", "Viktor", ""], ["H\u00fcllermeier", "Eyke", ""]]}, {"id": "1907.06129", "submitter": "Pavol Harar", "authors": "Pavol Harar, Zoltan Galaz, Jesus B. Alonso-Hernandez, Jiri Mekyska,\n  Radim Burget, Zdenek Smekal", "title": "Towards Robust Voice Pathology Detection", "comments": "11 pages, 1 figure, 10 tables. Keywords: Voice pathology detection,\n  deep learning, gradient boosting, anomaly detection", "journal-ref": "Neural Computing and Applications (2018): 1-11", "doi": "10.1007/s00521-018-3464-7", "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic objective non-invasive detection of pathological voice based on\ncomputerized analysis of acoustic signals can play an important role in early\ndiagnosis, progression tracking and even effective treatment of pathological\nvoices. In search towards such a robust voice pathology detection system we\ninvestigated 3 distinct classifiers within supervised learning and anomaly\ndetection paradigms. We conducted a set of experiments using a variety of input\ndata such as raw waveforms, spectrograms, mel-frequency cepstral coefficients\n(MFCC) and conventional acoustic (dysphonic) features (AF). In comparison with\npreviously published works, this article is the first to utilize combination of\n4 different databases comprising normophonic and pathological recordings of\nsustained phonation of the vowel /a/ unrestricted to a subset of vocal\npathologies. Furthermore, to our best knowledge, this article is the first to\nexplore gradient boosted trees and deep learning for this application. The\nfollowing best classification performances measured by F1 score on dedicated\ntest set were achieved: XGBoost (0.733) using AF and MFCC, DenseNet (0.621)\nusing MFCC, and Isolation Forest (0.610) using AF. Even though these results\nare of exploratory character, conducted experiments do show promising potential\nof gradient boosting and deep learning methods to robustly detect voice\npathologies.\n", "versions": [{"version": "v1", "created": "Sat, 13 Jul 2019 21:09:40 GMT"}], "update_date": "2019-07-16", "authors_parsed": [["Harar", "Pavol", ""], ["Galaz", "Zoltan", ""], ["Alonso-Hernandez", "Jesus B.", ""], ["Mekyska", "Jiri", ""], ["Burget", "Radim", ""], ["Smekal", "Zdenek", ""]]}, {"id": "1907.06134", "submitter": "Peiye Zhuang", "authors": "Peiye Zhuang, Alexander G. Schwing, Sanmi Koyejo", "title": "FMRI data augmentation via synthesis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an empirical evaluation of fMRI data augmentation via synthesis.\nFor synthesis we use generative mod-els trained on real neuroimaging data to\nproduce novel task-dependent functional brain images. Analyzed generative\nmod-els include classic approaches such as the Gaussian mixture model (GMM),\nand modern implicit generative models such as the generative adversarial\nnetwork (GAN) and the variational auto-encoder (VAE). In particular, the\nproposed GAN and VAE models utilize 3-dimensional convolutions, which enables\nmodeling of high-dimensional brain image tensors with structured spatial\ncorrelations. The synthesized datasets are then used to augment classifiers\ndesigned to predict cognitive and behavioural outcomes. Our results suggest\nthat the proposed models are able to generate high-quality synthetic brain\nimages which are diverse and task-dependent. Perhaps most importantly, the\nperformance improvements of data aug-mentation via synthesis are shown to be\ncomplementary to the choice of the predictive model. Thus, our results suggest\nthat data augmentation via synthesis is a promising approach to address the\nlimited availability of fMRI data, and to improve the quality of predictive\nfMRI models.\n", "versions": [{"version": "v1", "created": "Sat, 13 Jul 2019 21:30:41 GMT"}], "update_date": "2019-07-16", "authors_parsed": [["Zhuang", "Peiye", ""], ["Schwing", "Alexander G.", ""], ["Koyejo", "Sanmi", ""]]}, {"id": "1907.06138", "submitter": "Ji Liu", "authors": "Wesley Suttle, Zhuoran Yang, Kaiqing Zhang, Ji Liu", "title": "A Convergence Result for Regularized Actor-Critic Methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a probability one convergence proof, under suitable\nconditions, of a certain class of actor-critic algorithms for finding\napproximate solutions to entropy-regularized MDPs using the machinery of\nstochastic approximation. To obtain this overall result, we prove the\nconvergence of policy evaluation with general regularizers when using linear\napproximation architectures and show convergence of entropy-regularized policy\nimprovement.\n", "versions": [{"version": "v1", "created": "Sat, 13 Jul 2019 21:58:06 GMT"}, {"version": "v2", "created": "Tue, 22 Oct 2019 17:16:14 GMT"}], "update_date": "2019-10-23", "authors_parsed": [["Suttle", "Wesley", ""], ["Yang", "Zhuoran", ""], ["Zhang", "Kaiqing", ""], ["Liu", "Ji", ""]]}, {"id": "1907.06142", "submitter": "Linfeng Song", "authors": "Linfeng Song", "title": "Tackling Graphical NLP problems with Graph Recurrent Networks", "comments": "Ph.D. thesis", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How to properly model graphs is a long-existing and important problem in NLP\narea, where several popular types of graphs are knowledge graphs, semantic\ngraphs and dependency graphs. Comparing with other data structures, such as\nsequences and trees, graphs are generally more powerful in representing complex\ncorrelations among entities. For example, a knowledge graph stores real-word\nentities (such as \"Barack_Obama\" and \"U.S.\") and their relations (such as\n\"live_in\" and \"lead_by\"). Properly encoding a knowledge graph is beneficial to\nuser applications, such as question answering and knowledge discovery. Modeling\ngraphs is also very challenging, probably because graphs usually contain\nmassive and cyclic relations.\n  Recent years have witnessed the success of deep learning, especially\nRNN-based models, on many NLP problems. Besides, RNNs and their variations have\nbeen extensively studied on several graph problems and showed preliminary\nsuccesses. Despite the successes that have been achieved, RNN-based models\nsuffer from several major drawbacks on graphs. First, they can only consume\nsequential data, thus linearization is required to serialize input graphs,\nresulting in the loss of important structural information. Second, the\nserialization results are usually very long, so it takes a long time for RNNs\nto encode them.\n  In this thesis, we propose a novel graph neural network, named graph\nrecurrent network (GRN). We study our GRN model on 4 very different tasks, such\nas machine reading comprehension, relation extraction and machine translation.\nSome take undirected graphs without edge labels, while the others have directed\nones with edge labels. To consider these important differences, we gradually\nenhance our GRN model, such as further considering edge labels and adding an\nRNN decoder. Carefully designed experiments show the effectiveness of GRN on\nall these tasks.\n", "versions": [{"version": "v1", "created": "Sat, 13 Jul 2019 22:48:31 GMT"}], "update_date": "2019-07-16", "authors_parsed": [["Song", "Linfeng", ""]]}, {"id": "1907.06143", "submitter": "Andong Cao", "authors": "Lingzhi Zhang, Andong Cao, Rui Li, Jianbo Shi", "title": "Neural Embedding for Physical Manipulations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In common real-world robotic operations, action and state spaces can be vast\nand sometimes unknown, and observations are often relatively sparse. How do we\nlearn the full topology of action and state spaces when given only few and\nsparse observations? Inspired by the properties of grid cells in mammalian\nbrains, we build a generative model that enforces a normalized pairwise\ndistance constraint between the latent space and output space to achieve\ndata-efficient discovery of output spaces. This method achieves substantially\nbetter results than prior generative models, such as Generative Adversarial\nNetworks (GANs) and Variational Auto-Encoders (VAEs). Prior models have the\ncommon issue of mode collapse and thus fail to explore the full topology of\noutput space. We demonstrate the effectiveness of our model on various datasets\nboth qualitatively and quantitatively.\n", "versions": [{"version": "v1", "created": "Sat, 13 Jul 2019 22:57:23 GMT"}], "update_date": "2019-07-16", "authors_parsed": [["Zhang", "Lingzhi", ""], ["Cao", "Andong", ""], ["Li", "Rui", ""], ["Shi", "Jianbo", ""]]}, {"id": "1907.06162", "submitter": "Riyi Qiu", "authors": "Riyi Qiu, Yugang Jia, Mirsad Hadzikadic, Michael Dulin, Xi Niu, and\n  Xin Wang", "title": "Modeling the Uncertainty in Electronic Health Records: a Bayesian Deep\n  Learning Approach", "comments": "4 pages, 3 figures, 2 tables. 2019 KDD Workshop on Applied Data\n  Science for Healthcare. Anchorage, AK, USA, August 5, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning models have exhibited superior performance in predictive tasks\nwith the explosively increasing Electronic Health Records (EHR). However, due\nto the lack of transparency, behaviors of deep learning models are difficult to\ninterpret. Without trustworthiness, deep learning models will not be able to\nassist in the real-world decision-making process of healthcare issues. We\npropose a deep learning model based on Bayesian Neural Networks (BNN) to\npredict uncertainty induced by data noise. The uncertainty is introduced to\nprovide model predictions with an extra level of confidence. Our experiments\nverify that instances with high uncertainty are harmful to model performance.\nMoreover, by investigating the distributions of model prediction and\nuncertainty, we show that it is possible to identify a group of patients for\ntimely intervention, such that decreasing data noise will benefit more on the\nprediction accuracy for these patients.\n", "versions": [{"version": "v1", "created": "Sun, 14 Jul 2019 03:50:38 GMT"}], "update_date": "2019-07-16", "authors_parsed": [["Qiu", "Riyi", ""], ["Jia", "Yugang", ""], ["Hadzikadic", "Mirsad", ""], ["Dulin", "Michael", ""], ["Niu", "Xi", ""], ["Wang", "Xin", ""]]}, {"id": "1907.06166", "submitter": "Yuantao Gu", "authors": "Yuchen Jiao, Gen Li, and Yuantao Gu", "title": "Compressed Subspace Learning Based on Canonical Angle Preserving\n  Property", "comments": "38 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Union of Subspaces (UoS) is a popular model to describe the underlying\nlow-dimensional structure of data. The fine details of UoS structure can be\ndescribed in terms of canonical angles (also known as principal angles) between\nsubspaces, which is a well-known characterization for relative subspace\npositions. In this paper, we prove that random projection with the so-called\nJohnson-Lindenstrauss (JL) property approximately preserves canonical angles\nbetween subspaces with overwhelming probability. This result indicates that\nrandom projection approximately preserves the UoS structure. Inspired by this\nresult, we propose a framework of Compressed Subspace Learning (CSL), which\nenables to extract useful information from the UoS structure of data in a\ngreatly reduced dimension. We demonstrate the effectiveness of CSL in various\nsubspace-related tasks such as subspace visualization, active subspace\ndetection, and subspace clustering.\n", "versions": [{"version": "v1", "created": "Sun, 14 Jul 2019 05:01:05 GMT"}, {"version": "v2", "created": "Wed, 24 Jul 2019 09:31:31 GMT"}], "update_date": "2019-07-25", "authors_parsed": [["Jiao", "Yuchen", ""], ["Li", "Gen", ""], ["Gu", "Yuantao", ""]]}, {"id": "1907.06173", "submitter": "Eric Balkanski", "authors": "Adam Breuer, Eric Balkanski, Yaron Singer", "title": "The FAST Algorithm for Submodular Maximization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we describe a new algorithm called Fast Adaptive Sequencing\nTechnique (FAST) for maximizing a monotone submodular function under a\ncardinality constraint $k$ whose approximation ratio is arbitrarily close to\n$1-1/e$, is $O(\\log(n) \\log^2(\\log k))$ adaptive, and uses a total of $O(n\n\\log\\log(k))$ queries. Recent algorithms have comparable guarantees in terms of\nasymptotic worst case analysis, but their actual number of rounds and query\ncomplexity depend on very large constants and polynomials in terms of precision\nand confidence, making them impractical for large data sets. Our main\ncontribution is a design that is extremely efficient both in terms of its\nnon-asymptotic worst case query complexity and number of rounds, and in terms\nof its practical runtime. We show that this algorithm outperforms any algorithm\nfor submodular maximization we are aware of, including hyper-optimized parallel\nversions of state-of-the-art serial algorithms, by running experiments on large\ndata sets. These experiments show FAST is orders of magnitude faster than the\nstate-of-the-art.\n", "versions": [{"version": "v1", "created": "Sun, 14 Jul 2019 06:37:24 GMT"}], "update_date": "2019-07-16", "authors_parsed": [["Breuer", "Adam", ""], ["Balkanski", "Eric", ""], ["Singer", "Yaron", ""]]}, {"id": "1907.06194", "submitter": "Weilin Fu", "authors": "Weilin Fu, Katharina Breininger, Roman Schaffert, Nishant Ravikumar,\n  Andreas Maier", "title": "A Divide-and-Conquer Approach towards Understanding Deep Networks", "comments": "This paper is accepted in MICCAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks have achieved tremendous success in various fields\nincluding medical image segmentation. However, they have long been criticized\nfor being a black-box, in that interpretation, understanding and correcting\narchitectures is difficult as there is no general theory for deep neural\nnetwork design. Previously, precision learning was proposed to fuse deep\narchitectures and traditional approaches. Deep networks constructed in this way\nbenefit from the original known operator, have fewer parameters, and improved\ninterpretability. However, they do not yield state-of-the-art performance in\nall applications. In this paper, we propose to analyze deep networks using\nknown operators, by adopting a divide-and-conquer strategy to replace network\ncomponents, whilst retaining its performance. The task of retinal vessel\nsegmentation is investigated for this purpose. We start with a high-performance\nU-Net and show by step-by-step conversion that we are able to divide the\nnetwork into modules of known operators. The results indicate that a\ncombination of a trainable guided filter and a trainable version of the Frangi\nfilter yields a performance at the level of U-Net (AUC 0.974 vs. 0.972) with a\ntremendous reduction in parameters (111,536 vs. 9,575). In addition, the\ntrained layers can be mapped back into their original algorithmic\ninterpretation and analyzed using standard tools of signal processing.\n", "versions": [{"version": "v1", "created": "Sun, 14 Jul 2019 09:50:45 GMT"}], "update_date": "2019-07-16", "authors_parsed": [["Fu", "Weilin", ""], ["Breininger", "Katharina", ""], ["Schaffert", "Roman", ""], ["Ravikumar", "Nishant", ""], ["Maier", "Andreas", ""]]}, {"id": "1907.06198", "submitter": "Alessandro Betti", "authors": "Alessandro Betti, Marco Gori", "title": "On the Role of Time in Learning", "comments": "7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  By and large the process of learning concepts that are embedded in time is\nregarded as quite a mature research topic. Hidden Markov models, recurrent\nneural networks are, amongst others, successful approaches to learning from\ntemporal data. In this paper, we claim that the dominant approach minimizing\nappropriate risk functions defined over time by classic stochastic gradient\nmight miss the deep interpretation of time given in other fields like physics.\nWe show that a recent reformulation of learning according to the principle of\nLeast Cognitive Action is better suited whenever time is involved in learning.\nThe principle gives rise to a learning process that is driven by differential\nequations, that can somehow descrive the process within the same framework as\nother laws of nature.\n", "versions": [{"version": "v1", "created": "Sun, 14 Jul 2019 10:10:28 GMT"}], "update_date": "2019-07-16", "authors_parsed": [["Betti", "Alessandro", ""], ["Gori", "Marco", ""]]}, {"id": "1907.06205", "submitter": "Venkatesh Theru Mohan", "authors": "Venkatesh Theru Mohan and Ali Jannesari", "title": "Automatic Repair and Type Binding of Undeclared Variables using Neural\n  Networks", "comments": "16 pages, 16 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.CL cs.FL cs.LG cs.PL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning had been used in program analysis for the prediction of hidden\nsoftware defects using software defect datasets, security vulnerabilities using\ngenerative adversarial networks as well as identifying syntax errors by\nlearning a trained neural machine translation on program codes. However, all\nthese approaches either require defect datasets or bug-free source codes that\nare executable for training the deep learning model. Our neural network model\nis neither trained with any defect datasets nor bug-free programming source\ncodes, instead it is trained using structural semantic details of Abstract\nSyntax Tree (AST) where each node represents a construct appearing in the\nsource code. This model is implemented to fix one of the most common semantic\nerrors, such as undeclared variable errors as well as infer their type\ninformation before program compilation. By this approach, the model has\nachieved in correctly locating and identifying 81% of the programs on prutor\ndataset of 1059 programs with only undeclared variable errors and also\ninferring their types correctly in 80% of the programs.\n", "versions": [{"version": "v1", "created": "Sun, 14 Jul 2019 11:14:14 GMT"}], "update_date": "2019-07-16", "authors_parsed": [["Mohan", "Venkatesh Theru", ""], ["Jannesari", "Ali", ""]]}, {"id": "1907.06214", "submitter": "John Glover", "authors": "John Glover and Chris Hokamp", "title": "Task Selection Policies for Multitask Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the questions that arises when designing models that learn to solve\nmultiple tasks simultaneously is how much of the available training budget\nshould be devoted to each individual task. We refer to any formalized approach\nto addressing this problem (learned or otherwise) as a task selection policy.\nIn this work we provide an empirical evaluation of the performance of some\ncommon task selection policies in a synthetic bandit-style setting, as well as\non the GLUE benchmark for natural language understanding. We connect task\nselection policy learning to existing work on automated curriculum learning and\noff-policy evaluation, and suggest a method based on counterfactual estimation\nthat leads to improved model performance in our experimental settings.\n", "versions": [{"version": "v1", "created": "Sun, 14 Jul 2019 12:22:57 GMT"}], "update_date": "2019-07-16", "authors_parsed": [["Glover", "John", ""], ["Hokamp", "Chris", ""]]}, {"id": "1907.06246", "submitter": "Zhuoran Yang", "authors": "Zhuoran Yang, Yongxin Chen, Mingyi Hong, Zhaoran Wang", "title": "On the Global Convergence of Actor-Critic: A Case for Linear Quadratic\n  Regulator with Ergodic Cost", "comments": "41 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the empirical success of the actor-critic algorithm, its theoretical\nunderstanding lags behind. In a broader context, actor-critic can be viewed as\nan online alternating update algorithm for bilevel optimization, whose\nconvergence is known to be fragile. To understand the instability of\nactor-critic, we focus on its application to linear quadratic regulators, a\nsimple yet fundamental setting of reinforcement learning. We establish a\nnonasymptotic convergence analysis of actor-critic in this setting. In\nparticular, we prove that actor-critic finds a globally optimal pair of actor\n(policy) and critic (action-value function) at a linear rate of convergence.\nOur analysis may serve as a preliminary step towards a complete theoretical\nunderstanding of bilevel optimization with nonconvex subproblems, which is\nNP-hard in the worst case and is often solved using heuristics.\n", "versions": [{"version": "v1", "created": "Sun, 14 Jul 2019 16:50:26 GMT"}], "update_date": "2019-07-16", "authors_parsed": [["Yang", "Zhuoran", ""], ["Chen", "Yongxin", ""], ["Hong", "Mingyi", ""], ["Wang", "Zhaoran", ""]]}, {"id": "1907.06249", "submitter": "Feras Saad", "authors": "Feras A. Saad, Marco F. Cusumano-Towner, Ulrich Schaechtle, Martin C.\n  Rinard, Vikash K. Mansinghka", "title": "Bayesian Synthesis of Probabilistic Programs for Automatic Data Modeling", "comments": null, "journal-ref": "Proc. ACM Program. Lang. 3, POPL, Article 37 (January 2019)", "doi": "10.1145/3290350", "report-no": null, "categories": "cs.PL cs.AI cs.LG stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present new techniques for automatically constructing probabilistic\nprograms for data analysis, interpretation, and prediction. These techniques\nwork with probabilistic domain-specific data modeling languages that capture\nkey properties of a broad class of data generating processes, using Bayesian\ninference to synthesize probabilistic programs in these modeling languages\ngiven observed data. We provide a precise formulation of Bayesian synthesis for\nautomatic data modeling that identifies sufficient conditions for the resulting\nsynthesis procedure to be sound. We also derive a general class of synthesis\nalgorithms for domain-specific languages specified by probabilistic\ncontext-free grammars and establish the soundness of our approach for these\nlanguages. We apply the techniques to automatically synthesize probabilistic\nprograms for time series data and multivariate tabular data. We show how to\nanalyze the structure of the synthesized programs to compute, for key\nqualitative properties of interest, the probability that the underlying data\ngenerating process exhibits each of these properties. Second, we translate\nprobabilistic programs in the domain-specific language into probabilistic\nprograms in Venture, a general-purpose probabilistic programming system. The\ntranslated Venture programs are then executed to obtain predictions of new time\nseries data and new multivariate data records. Experimental results show that\nour techniques can accurately infer qualitative structure in multiple\nreal-world data sets and outperform standard data analysis methods in\nforecasting and predicting new data.\n", "versions": [{"version": "v1", "created": "Sun, 14 Jul 2019 17:12:55 GMT"}], "update_date": "2019-07-16", "authors_parsed": [["Saad", "Feras A.", ""], ["Cusumano-Towner", "Marco F.", ""], ["Schaechtle", "Ulrich", ""], ["Rinard", "Martin C.", ""], ["Mansinghka", "Vikash K.", ""]]}, {"id": "1907.06257", "submitter": "Zhuoran Yang", "authors": "Xinyang Yi, Zhaoran Wang, Zhuoran Yang, Constantine Caramanis, Han Liu", "title": "More Supervision, Less Computation: Statistical-Computational Tradeoffs\n  in Weakly Supervised Learning", "comments": "This work has been published in NeurIPS 2016. The first three authors\n  contribute equally", "journal-ref": "Advances in Neural Information Processing Systems (2016):\n  4482-4490", "doi": null, "report-no": null, "categories": "cs.LG cs.CC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the weakly supervised binary classification problem where the\nlabels are randomly flipped with probability $1- {\\alpha}$. Although there\nexist numerous algorithms for this problem, it remains theoretically unexplored\nhow the statistical accuracies and computational efficiency of these algorithms\ndepend on the degree of supervision, which is quantified by ${\\alpha}$. In this\npaper, we characterize the effect of ${\\alpha}$ by establishing the\ninformation-theoretic and computational boundaries, namely, the minimax-optimal\nstatistical accuracy that can be achieved by all algorithms, and\npolynomial-time algorithms under an oracle computational model. For small\n${\\alpha}$, our result shows a gap between these two boundaries, which\nrepresents the computational price of achieving the information-theoretic\nboundary due to the lack of supervision. Interestingly, we also show that this\ngap narrows as ${\\alpha}$ increases. In other words, having more supervision,\ni.e., more correct labels, not only improves the optimal statistical accuracy\nas expected, but also enhances the computational efficiency for achieving such\naccuracy.\n", "versions": [{"version": "v1", "created": "Sun, 14 Jul 2019 18:34:44 GMT"}], "update_date": "2019-07-16", "authors_parsed": [["Yi", "Xinyang", ""], ["Wang", "Zhaoran", ""], ["Yang", "Zhuoran", ""], ["Caramanis", "Constantine", ""], ["Liu", "Han", ""]]}, {"id": "1907.06258", "submitter": "Jose Ortiz-Bejar", "authors": "Jose Ortiz-Bejar, Eric S. Tellez and Mario Graff", "title": "Improving classification performance by feature space transformations\n  and model selection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Improving the performance of classifiers is the realm of feature mapping,\nprototype selection, and kernel function transformations; these techniques aim\nfor reducing the complexity, and also, improving the accuracy of models. In\nparticular, our objective is to combine them to transform data's shape into\nanother more convenient distribution; such that some simple algorithms, such as\nNa\\\"ive Bayes or k-Nearest Neighbors, can produce competitive classifiers. In\nthis paper, we introduce a family of classifiers based on feature mapping and\nkernel functions, orchestrated by a model selection scheme that excels in\nperformance. We provide an extensive experimental comparison of our methods\nwith sixteen popular classifiers on more than thirty benchmarks supporting our\nclaims. In addition to their competitive performance, our statistical tests\nalso found that our methods are different among them, supporting our claim of a\ncompelling family of classifiers.\n", "versions": [{"version": "v1", "created": "Sun, 14 Jul 2019 18:35:58 GMT"}, {"version": "v2", "created": "Tue, 1 Oct 2019 19:57:28 GMT"}, {"version": "v3", "created": "Thu, 3 Oct 2019 02:03:56 GMT"}], "update_date": "2019-10-04", "authors_parsed": [["Ortiz-Bejar", "Jose", ""], ["Tellez", "Eric S.", ""], ["Graff", "Mario", ""]]}, {"id": "1907.06260", "submitter": "Stephen Pfohl", "authors": "Stephen Pfohl, Tony Duan, Daisy Yi Ding, Nigam H. Shah", "title": "Counterfactual Reasoning for Fair Clinical Risk Prediction", "comments": "Machine Learning for Healthcare 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The use of machine learning systems to support decision making in healthcare\nraises questions as to what extent these systems may introduce or exacerbate\ndisparities in care for historically underrepresented and mistreated groups,\ndue to biases implicitly embedded in observational data in electronic health\nrecords. To address this problem in the context of clinical risk prediction\nmodels, we develop an augmented counterfactual fairness criteria to extend the\ngroup fairness criteria of equalized odds to an individual level. We do so by\nrequiring that the same prediction be made for a patient, and a counterfactual\npatient resulting from changing a sensitive attribute, if the factual and\ncounterfactual outcomes do not differ. We investigate the extent to which the\naugmented counterfactual fairness criteria may be applied to develop fair\nmodels for prolonged inpatient length of stay and mortality with observational\nelectronic health records data. As the fairness criteria is ill-defined without\nknowledge of the data generating process, we use a variational autoencoder to\nperform counterfactual inference in the context of an assumed causal graph.\nWhile our technique provides a means to trade off maintenance of fairness with\nreduction in predictive performance in the context of a learned generative\nmodel, further work is needed to assess the generality of this approach.\n", "versions": [{"version": "v1", "created": "Sun, 14 Jul 2019 18:44:09 GMT"}], "update_date": "2019-07-16", "authors_parsed": [["Pfohl", "Stephen", ""], ["Duan", "Tony", ""], ["Ding", "Daisy Yi", ""], ["Shah", "Nigam H.", ""]]}, {"id": "1907.06274", "submitter": "Moein Owhadi Kareshk", "authors": "Moein Owhadi-Kareshk, Sarah Nadi, Julia Rubin", "title": "Predicting Merge Conflicts in Collaborative Software Development", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Background. During collaborative software development, developers often use\nbranches to add features or fix bugs. When merging changes from two branches,\nconflicts may occur if the changes are inconsistent. Developers need to resolve\nthese conflicts before completing the merge, which is an error-prone and\ntime-consuming process. Early detection of merge conflicts, which warns\ndevelopers about resolving conflicts before they become large and complicated,\nis among the ways of dealing with this problem. Existing techniques do this by\ncontinuously pulling and merging all combinations of branches in the background\nto notify developers as soon as a conflict occurs, which is a computationally\nexpensive process. One potential way for reducing this cost is to use a\nmachine-learning based conflict predictor that filters out the merge scenarios\nthat are not likely to have conflicts, ie safe merge scenarios. Aims. In this\npaper, we assess if conflict prediction is feasible. Method. We design a\nclassifier for predicting merge conflicts, based on 9 light-weight Git feature\nsets. To evaluate our predictor, we perform a large-scale study on 267, 657\nmerge scenarios from 744 GitHub repositories in seven programming languages.\nResults. Our results show that we achieve high f1-scores, varying from 0.95 to\n0.97 for different programming languages, when predicting safe merge scenarios.\nThe f1-score is between 0.57 and 0.68 for the conflicting merge scenarios.\nConclusions. Predicting merge conflicts is feasible in practice, especially in\nthe context of predicting safe merge scenarios as a pre-filtering step for\nspeculative merging.\n", "versions": [{"version": "v1", "created": "Sun, 14 Jul 2019 20:06:53 GMT"}], "update_date": "2019-07-16", "authors_parsed": [["Owhadi-Kareshk", "Moein", ""], ["Nadi", "Sarah", ""], ["Rubin", "Julia", ""]]}, {"id": "1907.06286", "submitter": "Viktor Toth", "authors": "Viktor T\\'oth, Lauri Parkkonen", "title": "Autoencoding sensory substitution", "comments": null, "journal-ref": null, "doi": "10.13140/RG.2.2.10576.87048", "report-no": null, "categories": "q-bio.NC cs.CV cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tens of millions of people live blind, and their number is ever increasing.\nVisual-to-auditory sensory substitution (SS) encompasses a family of cheap,\ngeneric solutions to assist the visually impaired by conveying visual\ninformation through sound. The required SS training is lengthy: months of\neffort is necessary to reach a practical level of adaptation. There are two\nreasons for the tedious training process: the elongated substituting audio\nsignal, and the disregard for the compressive characteristics of the human\nhearing system. To overcome these obstacles, we developed a novel class of SS\nmethods, by training deep recurrent autoencoders for image-to-sound conversion.\nWe successfully trained deep learning models on different datasets to execute\nvisual-to-auditory stimulus conversion. By constraining the visual space, we\ndemonstrated the viability of shortened substituting audio signals, while\nproposing mechanisms, such as the integration of computational hearing models,\nto optimally convey visual features in the substituting stimulus as\nperceptually discernible auditory components. We tested our approach in two\nseparate cases. In the first experiment, the author went blindfolded for 5\ndays, while performing SS training on hand posture discrimination. The second\nexperiment assessed the accuracy of reaching movements towards objects on a\ntable. In both test cases, above-chance-level accuracy was attained after a few\nhours of training. Our novel SS architecture broadens the horizon of\nrehabilitation methods engineered for the visually impaired. Further\nimprovements on the proposed model shall yield hastened rehabilitation of the\nblind and a wider adaptation of SS devices as a consequence.\n", "versions": [{"version": "v1", "created": "Sun, 14 Jul 2019 21:58:10 GMT"}], "update_date": "2019-07-16", "authors_parsed": [["T\u00f3th", "Viktor", ""], ["Parkkonen", "Lauri", ""]]}, {"id": "1907.06288", "submitter": "Yao-Hung Tsai", "authors": "Han Zhao and Yao-Hung Hubert Tsai and Ruslan Salakhutdinov and\n  Geoffrey J. Gordon", "title": "Learning Neural Networks with Adaptive Regularization", "comments": "Camera ready version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Feed-forward neural networks can be understood as a combination of an\nintermediate representation and a linear hypothesis. While most previous works\naim to diversify the representations, we explore the complementary direction by\nperforming an adaptive and data-dependent regularization motivated by the\nempirical Bayes method. Specifically, we propose to construct a matrix-variate\nnormal prior (on weights) whose covariance matrix has a Kronecker product\nstructure. This structure is designed to capture the correlations in neurons\nthrough backpropagation. Under the assumption of this Kronecker factorization,\nthe prior encourages neurons to borrow statistical strength from one another.\nHence, it leads to an adaptive and data-dependent regularization when training\nnetworks on small datasets. To optimize the model, we present an efficient\nblock coordinate descent algorithm with analytical solutions. Empirically, we\ndemonstrate that the proposed method helps networks converge to local optima\nwith smaller stable ranks and spectral norms. These properties suggest better\ngeneralizations and we present empirical results to support this expectation.\nWe also verify the effectiveness of the approach on multiclass classification\nand multitask regression problems with various network structures.\n", "versions": [{"version": "v1", "created": "Sun, 14 Jul 2019 22:07:15 GMT"}, {"version": "v2", "created": "Wed, 23 Oct 2019 04:17:02 GMT"}], "update_date": "2019-10-24", "authors_parsed": [["Zhao", "Han", ""], ["Tsai", "Yao-Hung Hubert", ""], ["Salakhutdinov", "Ruslan", ""], ["Gordon", "Geoffrey J.", ""]]}, {"id": "1907.06290", "submitter": "Harsh Gupta", "authors": "Harsh Gupta, R. Srikant and Lei Ying", "title": "Finite-Time Performance Bounds and Adaptive Learning Rate Selection for\n  Two Time-Scale Reinforcement Learning", "comments": "17 pages, 3 figures, preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study two time-scale linear stochastic approximation algorithms, which can\nbe used to model well-known reinforcement learning algorithms such as GTD,\nGTD2, and TDC. We present finite-time performance bounds for the case where the\nlearning rate is fixed. The key idea in obtaining these bounds is to use a\nLyapunov function motivated by singular perturbation theory for linear\ndifferential equations. We use the bound to design an adaptive learning rate\nscheme which significantly improves the convergence rate over the known optimal\npolynomial decay rule in our experiments, and can be used to potentially\nimprove the performance of any other schedule where the learning rate is\nchanged at pre-determined time instants.\n", "versions": [{"version": "v1", "created": "Sun, 14 Jul 2019 22:20:46 GMT"}], "update_date": "2019-07-16", "authors_parsed": [["Gupta", "Harsh", ""], ["Srikant", "R.", ""], ["Ying", "Lei", ""]]}, {"id": "1907.06291", "submitter": "Deyan Petrov", "authors": "Deyan Petrov, Timothy M. Hospedales", "title": "Measuring the Transferability of Adversarial Examples", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Adversarial examples are of wide concern due to their impact on the\nreliability of contemporary machine learning systems. Effective adversarial\nexamples are mostly found via white-box attacks. However, in some cases they\ncan be transferred across models, thus enabling them to attack black-box\nmodels. In this work we evaluate the transferability of three adversarial\nattacks - the Fast Gradient Sign Method, the Basic Iterative Method, and the\nCarlini & Wagner method, across two classes of models - the VGG class(using\nVGG16, VGG19 and an ensemble of VGG16 and VGG19), and the Inception\nclass(Inception V3, Xception, Inception Resnet V2, and an ensemble of the\nthree). We also outline the problems with the assessment of transferability in\nthe current body of research and attempt to amend them by picking specific\n\"strong\" parameters for the attacks, and by using a L-Infinity clipping\ntechnique and the SSIM metric for the final evaluation of the attack\ntransferability.\n", "versions": [{"version": "v1", "created": "Sun, 14 Jul 2019 22:20:58 GMT"}], "update_date": "2019-07-16", "authors_parsed": [["Petrov", "Deyan", ""], ["Hospedales", "Timothy M.", ""]]}, {"id": "1907.06312", "submitter": "Xiaoyan Li", "authors": "Xiaoyan Li, Iluju Kiringa, Tet Yeap, Xiaodan Zhu, Yifeng Li", "title": "Exploring Deep Anomaly Detection Methods Based on Capsule Net", "comments": "Presented in the \"ICML 2019 Workshop on Uncertainty & Robustness in\n  Deep Learning\", June 14, Long Beach, California, USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we develop and explore deep anomaly detection techniques based\non the capsule network (CapsNet) for image data. Being able to encoding\nintrinsic spatial relationship between parts and a whole, CapsNet has been\napplied as both a classifier and deep autoencoder. This inspires us to design a\nprediction-probability-based and a reconstruction-error-based normality score\nfunctions for evaluating the \"outlierness\" of unseen images. Our results on\nthree datasets demonstrate that the prediction-probability-based method\nperforms consistently well, while the reconstruction-error-based approach is\nrelatively sensitive to the similarity between labeled and unlabeled images.\nFurthermore, both of the CapsNet-based methods outperform the principled\nbenchmark methods in many cases.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jul 2019 02:15:58 GMT"}], "update_date": "2019-07-16", "authors_parsed": [["Li", "Xiaoyan", ""], ["Kiringa", "Iluju", ""], ["Yeap", "Tet", ""], ["Zhu", "Xiaodan", ""], ["Li", "Yifeng", ""]]}, {"id": "1907.06323", "submitter": "Jianxun Lian", "authors": "Zheng Liu, Yu Xing, Jianxun Lian, Defu Lian, Ziyao Li and Xing Xie", "title": "A Novel User Representation Paradigm for Making Personalized Candidate\n  Retrieval", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Candidate retrieval is a fundamental issue in recommendation system. Given\nuser's recommendation request, relevant candidates need to be retrieved in\nrealtime for subsequent ranking operations. Considering that the retrieval\noperation is conducted over considerable items, it has to be both precise and\nscalable so that high-quality candidates can be acquired within tolerable\nlatency. Unfortunately, conventional methods would trade off precision for high\nrunning efficiency, which leads to inferior retrieval quality. In contrast,\nthose deep learning-based approaches can be highly accurate in identifying\nrelevant items; yet, they are unsuitable for candidate retrieval due to their\ninherent limitation on scalability.\n  In this work, a novel framework is proposed to address the above challenges.\nThe underlying intuition is to rely on a well-trained ranking model for the\nsupervision of an efficient retrieval model, such that it will unify the\nscalability and precision as a whole. We have implemented our conceptual\nframework and made comprehensive evaluation for it, where promising results are\nachieved against representative baselines.\n  Our work is undergoing a anonymous review, and it will soon be released after\nthe notification. If you're also interested in this problem, please feel free\nto contact us.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jul 2019 03:29:45 GMT"}, {"version": "v2", "created": "Sun, 20 Oct 2019 02:47:42 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Liu", "Zheng", ""], ["Xing", "Yu", ""], ["Lian", "Jianxun", ""], ["Lian", "Defu", ""], ["Li", "Ziyao", ""], ["Xie", "Xing", ""]]}, {"id": "1907.06327", "submitter": "Rohan Lekhwani", "authors": "Rohan Lekhwani, Bhupendra Singh", "title": "FastV2C-HandNet: Fast Voxel to Coordinate Hand Pose Estimation with 3D\n  Convolutional Neural Networks", "comments": "13 pages, 5 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.HC cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hand pose estimation from monocular depth images has been an important and\nchallenging problem in the Computer Vision community. In this paper, we present\na novel approach to estimate 3D hand joint locations from 2D depth images.\nUnlike most of the previous methods, our model captures the 3D spatial\ninformation from a depth image thereby giving it a greater understanding of the\ninput. We voxelize the input depth map to capture the 3D features of the input\nand perform 3D data augmentations to make our network robust to real-world\nimages. Our network is trained in an end-to-end manner which reduces time and\nspace complexity significantly when compared to other methods. Through\nextensive experiments, we show that our model outperforms state-of-the-art\nmethods with respect to the time it takes to train and predict 3D hand joint\nlocations. This makes our method more suitable for real-world hand pose\nestimation scenarios.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jul 2019 04:04:01 GMT"}, {"version": "v2", "created": "Tue, 17 Sep 2019 07:06:18 GMT"}, {"version": "v3", "created": "Thu, 20 Feb 2020 14:31:45 GMT"}], "update_date": "2020-02-21", "authors_parsed": [["Lekhwani", "Rohan", ""], ["Singh", "Bhupendra", ""]]}, {"id": "1907.06330", "submitter": "Prateek Verma", "authors": "Prateek Verma, Aliasgar Kutiyanawala, Ke Shen", "title": "Ranking sentences from product description & bullets for better search", "comments": "Accepted at SIGIR eCom'19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Products in an ecommerce catalog contain information-rich fields like\ndescription and bullets that can be useful to extract entities (attributes)\nusing NER based systems. However, these fields are often verbose and contain\nlot of information that is not relevant from a search perspective. Treating\neach sentence within these fields equally can lead to poor full text match and\nintroduce problems in extracting attributes to develop ontologies, semantic\nsearch etc. To address this issue, we describe two methods based on extractive\nsummarization with reinforcement learning by leveraging information in product\ntitles and search click through logs to rank sentences from bullets,\ndescription, etc. Finally, we compare the accuracy of these two models.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jul 2019 04:48:34 GMT"}], "update_date": "2019-07-16", "authors_parsed": [["Verma", "Prateek", ""], ["Kutiyanawala", "Aliasgar", ""], ["Shen", "Ke", ""]]}, {"id": "1907.06333", "submitter": "Sedrick Scott Keh", "authors": "Sedrick Scott Keh, I-Tsun Cheng", "title": "Myers-Briggs Personality Classification and Personality-Specific\n  Language Generation Using Pre-trained Language Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Myers-Briggs Type Indicator (MBTI) is a popular personality metric that\nuses four dichotomies as indicators of personality traits. This paper examines\nthe use of pre-trained language models to predict MBTI personality types based\non scraped labeled texts. The proposed model reaches an accuracy of $0.47$ for\ncorrectly predicting all 4 types and $0.86$ for correctly predicting at least 2\ntypes. Furthermore, we investigate the possible uses of a fine-tuned BERT model\nfor personality-specific language generation. This is a task essential for both\nmodern psychology and for intelligent empathetic systems.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jul 2019 05:04:39 GMT"}], "update_date": "2019-07-16", "authors_parsed": [["Keh", "Sedrick Scott", ""], ["Cheng", "I-Tsun", ""]]}, {"id": "1907.06341", "submitter": "Shota Saito", "authors": "Shota Saito, Shinichi Shirakawa", "title": "Controlling Model Complexity in Probabilistic Model-Based Dynamic\n  Optimization of Neural Network Structures", "comments": "Accepted as a conference paper at the 28th International Conference\n  on Artificial Neural Networks (ICANN 2019). The final authenticated\n  publication will be available in the Springer Lecture Notes in Computer\n  Science (LNCS). 13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A method of simultaneously optimizing both the structure of neural networks\nand the connection weights in a single training loop can reduce the enormous\ncomputational cost of neural architecture search. We focus on the probabilistic\nmodel-based dynamic neural network structure optimization that considers the\nprobability distribution of structure parameters and simultaneously optimizes\nboth the distribution parameters and connection weights based on gradient\nmethods. Since the existing algorithm searches for the structures that only\nminimize the training loss, this method might find overly complicated\nstructures. In this paper, we propose the introduction of a penalty term to\ncontrol the model complexity of obtained structures. We formulate a penalty\nterm using the number of weights or units and derive its analytical natural\ngradient. The proposed method minimizes the objective function injected the\npenalty term based on the stochastic gradient descent. We apply the proposed\nmethod in the unit selection of a fully-connected neural network and the\nconnection selection of a convolutional neural network. The experimental\nresults show that the proposed method can control model complexity while\nmaintaining performance.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jul 2019 06:28:40 GMT"}], "update_date": "2019-07-16", "authors_parsed": [["Saito", "Shota", ""], ["Shirakawa", "Shinichi", ""]]}, {"id": "1907.06347", "submitter": "Daniel Gissin", "authors": "Daniel Gissin, Shai Shalev-Shwartz", "title": "Discriminative Active Learning", "comments": "11 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new batch mode active learning algorithm designed for neural\nnetworks and large query batch sizes. The method, Discriminative Active\nLearning (DAL), poses active learning as a binary classification task,\nattempting to choose examples to label in such a way as to make the labeled set\nand the unlabeled pool indistinguishable. Experimenting on image classification\ntasks, we empirically show our method to be on par with state of the art\nmethods in medium and large query batch sizes, while being simple to implement\nand also extend to other domains besides classification tasks. Our experiments\nalso show that none of the state of the art methods of today are clearly better\nthan uncertainty sampling when the batch size is relatively large, negating\nsome of the reported results in the recent literature.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jul 2019 06:47:58 GMT"}], "update_date": "2019-07-16", "authors_parsed": [["Gissin", "Daniel", ""], ["Shalev-Shwartz", "Shai", ""]]}, {"id": "1907.06356", "submitter": "Marian-Andrei Rizoiu", "authors": "Adriana-Simona Mihaita, Haowen Li, Zongyang He, Marian-Andrei Rizoiu", "title": "Motorway Traffic Flow Prediction using Advanced Deep Learning", "comments": "Published in the Proceedings of the 22nd IEEE Intelligent\n  Transportation Systems Conference (ITSC'19). Auckland, New Zealand", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Congestion prediction represents a major priority for traffic management\ncentres around the world to ensure timely incident response handling. The\nincreasing amounts of generated traffic data have been used to train machine\nlearning predictors for traffic, however this is a challenging task due to\ninter-dependencies of traffic flow both in time and space. Recently, deep\nlearning techniques have shown significant prediction improvements over\ntraditional models, however open questions remain around their applicability,\naccuracy and parameter tuning. This paper proposes an advanced deep learning\nframework for simultaneously predicting the traffic flow on a large number of\nmonitoring stations along a highly circulated motorway in Sydney, Australia,\nincluding exit and entry loop count stations, and over varying training and\nprediction time horizons. The spatial and temporal features extracted from the\n36.34 million data points are used in various deep learning architectures that\nexploit their spatial structure (convolutional neuronal networks), their\ntemporal dynamics (recurrent neuronal networks), or both through a hybrid\nspatio-temporal modelling (CNN-LSTM). We show that our deep learning models\nconsistently outperform traditional methods, and we conduct a comparative\nanalysis of the optimal time horizon of historical data required to predict\ntraffic flow at different time points in the future.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jul 2019 08:05:08 GMT"}, {"version": "v2", "created": "Tue, 16 Jul 2019 09:45:41 GMT"}, {"version": "v3", "created": "Wed, 17 Jul 2019 02:07:05 GMT"}], "update_date": "2019-07-18", "authors_parsed": [["Mihaita", "Adriana-Simona", ""], ["Li", "Haowen", ""], ["He", "Zongyang", ""], ["Rizoiu", "Marian-Andrei", ""]]}, {"id": "1907.06374", "submitter": "Timothy Lillicrap", "authors": "Timothy P. Lillicrap and Konrad P. Kording", "title": "What does it mean to understand a neural network?", "comments": "9 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We can define a neural network that can learn to recognize objects in less\nthan 100 lines of code. However, after training, it is characterized by\nmillions of weights that contain the knowledge about many object types across\nvisual scenes. Such networks are thus dramatically easier to understand in\nterms of the code that makes them than the resulting properties, such as tuning\nor connections. In analogy, we conjecture that rules for development and\nlearning in brains may be far easier to understand than their resulting\nproperties. The analogy suggests that neuroscience would benefit from a focus\non learning and development.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jul 2019 08:58:26 GMT"}], "update_date": "2019-07-16", "authors_parsed": [["Lillicrap", "Timothy P.", ""], ["Kording", "Konrad P.", ""]]}, {"id": "1907.06377", "submitter": "Bin Liu", "authors": "Bin Liu, Yu Qi, Ke-Jia Chen", "title": "Sequential online prediction in the presence of outliers and change\n  points: an instant temporal structure learning approach", "comments": "43 pages, 14 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider sequential online prediction (SOP) for streaming\ndata in the presence of outliers and change points. We propose an INstant\nTEmporal structure Learning (INTEL) algorithm to address this problem. Our\nINTEL algorithm is developed based on a full consideration of the duality\nbetween online prediction and anomaly detection. We first employ a mixture of\nweighted Gaussian process models (WGPs) to cover the expected possible temporal\nstructures of the data. Then, based on the rich modeling capacity of this WGP\nmixture, we develop an efficient technique to instantly learn (capture) the\ntemporal structure of the data that follows a regime shift. This instant\nlearning is achieved only by adjusting one hyper-parameter value of the mixture\nmodel. A weighted generalization of the product of experts (POE) model is used\nfor fusing predictions yielded from multiple GP models. An outlier is declared\nonce a real observation seriously deviates from the fused prediction. If a\ncertain number of outliers are consecutively declared, then a change point is\ndeclared. Extensive experiments are performed using a diverse of real datasets.\nResults show that the proposed algorithm is significantly better than benchmark\nmethods for SOP in the presence of outliers and change points.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jul 2019 09:05:05 GMT"}, {"version": "v2", "created": "Tue, 11 Feb 2020 03:21:25 GMT"}], "update_date": "2020-02-12", "authors_parsed": [["Liu", "Bin", ""], ["Qi", "Yu", ""], ["Chen", "Ke-Jia", ""]]}, {"id": "1907.06382", "submitter": "Peter Tino", "authors": "Peter Tino", "title": "Dynamical Systems as Temporal Feature Spaces", "comments": "45 pages, 17 figures, accepted", "journal-ref": "JMLR, 2020", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Parameterized state space models in the form of recurrent networks are often\nused in machine learning to learn from data streams exhibiting temporal\ndependencies. To break the black box nature of such models it is important to\nunderstand the dynamical features of the input driving time series that are\nformed in the state space. We propose a framework for rigorous analysis of such\nstate representations in vanishing memory state space models such as echo state\nnetworks (ESN). In particular, we consider the state space a temporal feature\nspace and the readout mapping from the state space a kernel machine operating\nin that feature space. We show that: (1) The usual ESN strategy of randomly\ngenerating input-to-state, as well as state coupling leads to shallow memory\ntime series representations, corresponding to cross-correlation operator with\nfast exponentially decaying coefficients; (2) Imposing symmetry on dynamic\ncoupling yields a constrained dynamic kernel matching the input time series\nwith straightforward exponentially decaying motifs or exponentially decaying\nmotifs of the highest frequency; (3) Simple cycle high-dimensional reservoir\ntopology specified only through two free parameters can implement deep memory\ndynamic kernels with a rich variety of matching motifs. We quantify richness of\nfeature representations imposed by dynamic kernels and demonstrate that for\ndynamic kernel associated with cycle reservoir topology, the kernel richness\nundergoes a phase transition close to the edge of stability.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jul 2019 09:19:56 GMT"}, {"version": "v2", "created": "Tue, 24 Dec 2019 10:17:25 GMT"}, {"version": "v3", "created": "Sat, 15 Feb 2020 11:17:48 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Tino", "Peter", ""]]}, {"id": "1907.06385", "submitter": "Angela Fan", "authors": "Sidak Pal Singh, Angela Fan, Michael Auli", "title": "GLOSS: Generative Latent Optimization of Sentence Representations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a method to learn unsupervised sentence representations in a\nnon-compositional manner based on Generative Latent Optimization. Our approach\ndoes not impose any assumptions on how words are to be combined into a sentence\nrepresentation. We discuss a simple Bag of Words model as well as a variant\nthat models word positions. Both are trained to reconstruct the sentence based\non a latent code and our model can be used to generate text. Experiments show\nlarge improvements over the related Paragraph Vectors. Compared to uSIF, we\nachieve a relative improvement of 5% when trained on the same data and our\nmethod performs competitively to Sent2vec while trained on 30 times less data.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jul 2019 09:23:49 GMT"}], "update_date": "2019-08-14", "authors_parsed": [["Singh", "Sidak Pal", ""], ["Fan", "Angela", ""], ["Auli", "Michael", ""]]}, {"id": "1907.06396", "submitter": "Wonshick Ko", "authors": "Wonshick Ko, Dong Eui Chang", "title": "A Dual Memory Structure for Efficient Use of Replay Memory in Deep\n  Reinforcement Learning", "comments": "4 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a dual memory structure for reinforcement learning\nalgorithms with replay memory. The dual memory consists of a main memory that\nstores various data and a cache memory that manages the data and trains the\nreinforcement learning agent efficiently. Experimental results show that the\ndual memory structure achieves higher training and test scores than the\nconventional single memory structure in three selected environments of OpenAI\nGym. This implies that the dual memory structure enables better and more\nefficient training than the single memory structure.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jul 2019 09:45:54 GMT"}], "update_date": "2019-07-16", "authors_parsed": [["Ko", "Wonshick", ""], ["Chang", "Dong Eui", ""]]}, {"id": "1907.06414", "submitter": "Tatiana Fountoukidou", "authors": "Tatiana Fountoukidou and Raphael Sznitman", "title": "Concept-Centric Visual Turing Tests for Method Validation", "comments": "9 pages, 8 figures", "journal-ref": null, "doi": "10.1007/978-3-030-32254-0_29", "report-no": null, "categories": "cs.LG eess.IV stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Recent advances in machine learning for medical imaging have led to\nimpressive increases in model complexity and overall capabilities. However, the\nability to discern the precise information a machine learning method is using\nto make decisions has lagged behind and it is often unclear how these\nperformances are in fact achieved. Conventional evaluation metrics that reduce\nmethod performance to a single number or a curve only provide limited insights.\nYet, systems used in clinical practice demand thorough validation that such\ncrude characterizations miss. To this end, we present a framework to evaluate\nclassification methods based on a number of interpretable concepts that are\ncrucial for a clinical task. Our approach is inspired by the Turing Test\nconcept and how to devise a test that adaptively questions a method for its\nability to interpret medical images. To do this, we make use of a Twenty\nQuestions paradigm whereby we use a probabilistic model to characterize the\nmethod's capacity to grasp task-specific concepts, and we introduce a strategy\nto sequentially query the method according to its previous answers. The results\nshow that the probabilistic model is able to expose both the dataset's and the\nmethod's biases, and can be used to reduced the number of queries needed for\nconfident performance evaluation.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jul 2019 10:21:54 GMT"}, {"version": "v2", "created": "Sun, 15 Mar 2020 11:04:20 GMT"}], "update_date": "2020-03-17", "authors_parsed": [["Fountoukidou", "Tatiana", ""], ["Sznitman", "Raphael", ""]]}, {"id": "1907.06426", "submitter": "Eunjeong Jeong", "authors": "Eunjeong Jeong, Seungeun Oh, Jihong Park, Hyesung Kim, Mehdi Bennis,\n  Seong-Lyun Kim", "title": "Multi-hop Federated Private Data Augmentation with Sample Compression", "comments": "to be presented at the 28th International Joint Conference on\n  Artificial Intelligence (IJCAI-19), 1st International Workshop on Federated\n  Machine Learning for User Privacy and Data Confidentiality (FML'19), Macao,\n  China", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NI eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  On-device machine learning (ML) has brought about the accessibility to a\ntremendous amount of data from the users while keeping their local data private\ninstead of storing it in a central entity. However, for privacy guarantee, it\nis inevitable at each device to compensate for the quality of data or learning\nperformance, especially when it has a non-IID training dataset. In this paper,\nwe propose a data augmentation framework using a generative model: multi-hop\nfederated augmentation with sample compression (MultFAug). A multi-hop protocol\nspeeds up the end-to-end over-the-air transmission of seed samples by enhancing\nthe transport capacity. The relaying devices guarantee stronger privacy\npreservation as well since the origin of each seed sample is hidden in those\nparticipants. For further privatization on the individual sample level, the\ndevices compress their data samples. The devices sparsify their data samples\nprior to transmissions to reduce the sample size, which impacts the\ncommunication payload. This preprocessing also strengthens the privacy of each\nsample, which corresponds to the input perturbation for preserving sample\nprivacy. The numerical evaluations show that the proposed framework\nsignificantly improves privacy guarantee, transmission delay, and local\ntraining performance with adjustment to the number of hops and compression\nrate.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jul 2019 10:54:18 GMT"}], "update_date": "2019-07-16", "authors_parsed": [["Jeong", "Eunjeong", ""], ["Oh", "Seungeun", ""], ["Park", "Jihong", ""], ["Kim", "Hyesung", ""], ["Bennis", "Mehdi", ""], ["Kim", "Seong-Lyun", ""]]}, {"id": "1907.06430", "submitter": "Silvia Chiappa", "authors": "Silvia Chiappa and William S. Isaac", "title": "A Causal Bayesian Networks Viewpoint on Fairness", "comments": null, "journal-ref": "Privacy and Identity Management. Fairness, Accountability, and\n  Transparency in the Age of Big Data. IFIP Advances in Information and\n  Communication Technology, vol 547. Springer, Cham, 2019", "doi": "10.1007/978-3-030-16744-8_1", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We offer a graphical interpretation of unfairness in a dataset as the\npresence of an unfair causal path in the causal Bayesian network representing\nthe data-generation mechanism. We use this viewpoint to revisit the recent\ndebate surrounding the COMPAS pretrial risk assessment tool and, more\ngenerally, to point out that fairness evaluation on a model requires careful\nconsiderations on the patterns of unfairness underlying the training data. We\nshow that causal Bayesian networks provide us with a powerful tool to measure\nunfairness in a dataset and to design fair models in complex unfairness\nscenarios.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jul 2019 11:06:06 GMT"}], "update_date": "2019-07-16", "authors_parsed": [["Chiappa", "Silvia", ""], ["Isaac", "William S.", ""]]}, {"id": "1907.06441", "submitter": "Zishuo Zhao", "authors": "Zishuo Zhao", "title": "Noise-Stable Rigid Graphs for Euclidean Embedding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.DM cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We proposed a new criterion \\textit{noise-stability}, which revised the\nclassical rigidity theory, for evaluation of MDS algorithms which can\ntruthfully represent the fidelity of global structure reconstruction; then we\nproved the noise-stability of the cMDS algorithm in generic conditions, which\nprovides a rigorous theoretical guarantee for the precision and theoretical\nbounds for Euclidean embedding and its application in fields including wireless\nsensor network localization and satellite positioning.\n  Furthermore, we looked into previous work about minimum-cost globally rigid\nspanning subgraph, and proposed an algorithm to construct a minimum-cost\nnoise-stable spanning graph in the Euclidean space, which enabled reliable\nlocalization on sparse graphs of noisy distance constraints with linear numbers\nof edges and sublinear costs in total edge lengths. Additionally, this\nalgorithm also suggests a scheme to reconstruct point clouds from pairwise\ndistances at a minimum of $O(n)$ time complexity, down from $O(n^3)$ for cMDS.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jul 2019 11:32:31 GMT"}, {"version": "v2", "created": "Tue, 30 Jul 2019 09:10:36 GMT"}, {"version": "v3", "created": "Wed, 31 Jul 2019 01:39:39 GMT"}, {"version": "v4", "created": "Tue, 6 Aug 2019 15:30:20 GMT"}], "update_date": "2019-08-07", "authors_parsed": [["Zhao", "Zishuo", ""]]}, {"id": "1907.06458", "submitter": "Bla\\v{z} \\v{S}krlj", "authors": "Bla\\v{z} \\v{S}krlj, Andra\\v{z} Repar and Senja Pollak", "title": "RaKUn: Rank-based Keyword extraction via Unsupervised learning and Meta\n  vertex aggregation", "comments": "The final authenticated publication is available online at\n  https://doi.org/10.1007/978-3-030-31372-2_26", "journal-ref": "Statistical Language and Speech Processing 2019 Proceedings", "doi": "10.1007/978-3-030-31372-2_26", "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Keyword extraction is used for summarizing the content of a document and\nsupports efficient document retrieval, and is as such an indispensable part of\nmodern text-based systems. We explore how load centrality, a graph-theoretic\nmeasure applied to graphs derived from a given text can be used to efficiently\nidentify and rank keywords. Introducing meta vertices (aggregates of existing\nvertices) and systematic redundancy filters, the proposed method performs on\npar with state-of-the-art for the keyword extraction task on 14 diverse\ndatasets. The proposed method is unsupervised, interpretable and can also be\nused for document visualization.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jul 2019 12:10:24 GMT"}, {"version": "v2", "created": "Thu, 17 Oct 2019 19:02:55 GMT"}, {"version": "v3", "created": "Mon, 11 Nov 2019 12:13:37 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["\u0160krlj", "Bla\u017e", ""], ["Repar", "Andra\u017e", ""], ["Pollak", "Senja", ""]]}, {"id": "1907.06479", "submitter": "Zhenyu Zhang", "authors": "Zhenyu Zhang, Xiangfeng Luo, Tong Liu, Shaorong Xie, Jianshu Wang, Wei\n  Wang, Yang Li and Yan Peng", "title": "Proximal Policy Optimization with Mixed Distributed Training", "comments": "ICTAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Instability and slowness are two main problems in deep reinforcement\nlearning. Even if proximal policy optimization (PPO) is the state of the art,\nit still suffers from these two problems. We introduce an improved algorithm\nbased on proximal policy optimization, mixed distributed proximal policy\noptimization (MDPPO), and show that it can accelerate and stabilize the\ntraining process. In our algorithm, multiple different policies train\nsimultaneously and each of them controls several identical agents that interact\nwith environments. Actions are sampled by each policy separately as usual, but\nthe trajectories for the training process are collected from all agents,\ninstead of only one policy. We find that if we choose some auxiliary\ntrajectories elaborately to train policies, the algorithm will be more stable\nand quicker to converge especially in the environments with sparse rewards.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jul 2019 12:56:38 GMT"}, {"version": "v2", "created": "Sun, 8 Sep 2019 01:06:28 GMT"}, {"version": "v3", "created": "Mon, 30 Sep 2019 07:45:09 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Zhang", "Zhenyu", ""], ["Luo", "Xiangfeng", ""], ["Liu", "Tong", ""], ["Xie", "Shaorong", ""], ["Wang", "Jianshu", ""], ["Wang", "Wei", ""], ["Li", "Yang", ""], ["Peng", "Yan", ""]]}, {"id": "1907.06481", "submitter": "Gabriel Michau Dr.", "authors": "Gabriel Michau and Olga Fink", "title": "Unsupervised Fault Detection in Varying Operating Conditions", "comments": null, "journal-ref": "Proceedings of the 2019 IEEE International Conference on\n  Prognostics and Health Management, San Francisco", "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training data-driven approaches for complex industrial system health\nmonitoring is challenging. When data on faulty conditions are rare or not\navailable, the training has to be performed in a unsupervised manner. In\naddition, when the observation period, used for training, is kept short, to be\nable to monitor the system in its early life, the training data might not be\nrepresentative of all the system normal operating conditions. In this paper, we\npropose five approaches to perform fault detection in such context. Two\napproaches rely on the data from the unit to be monitored only: the baseline is\ntrained on the early life of the unit. An incremental learning procedure tries\nto learn new operating conditions as they arise. Three other approaches take\nadvantage of data from other similar units within a fleet. In two cases, units\nare directly compared to each other with similarity measures, and the data from\nsimilar units are combined in the training set. We propose, in the third case,\na new deep-learning methodology to perform, first, a feature alignment of\ndifferent units with an Unsupervised Feature Alignment Network (UFAN). Then,\nfeatures of both units are combined in the training set of the fault detection\nneural network.\n  The approaches are tested on a fleet comprising 112 units, observed over one\nyear of data. All approaches proposed here are an improvement to the baseline,\ntrained with two months of data only. As units in the fleet are found to be\nvery dissimilar, the new architecture UFAN, that aligns units in the feature\nspace, is outperforming others.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jul 2019 13:01:26 GMT"}], "update_date": "2019-07-23", "authors_parsed": [["Michau", "Gabriel", ""], ["Fink", "Olga", ""]]}, {"id": "1907.06483", "submitter": "Egor Ershov I", "authors": "A.~Savchik, E.~Ershov, S.~Karpenko", "title": "Color Cerberus", "comments": null, "journal-ref": null, "doi": "10.1109/ISPA.2019.8868425", "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Simple convolutional neural network was able to win ISISPA color constancy\ncompetition. Partial reimplementation of (Bianco, 2017) neural architecture\nwould have shown even better results in this setup.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jul 2019 13:04:31 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["~Savchik", "A.", ""], ["~Ershov", "E.", ""], ["~Karpenko", "S.", ""]]}, {"id": "1907.06484", "submitter": "Zeon Trevor Fernando", "authors": "Zeon Trevor Fernando, Jaspreet Singh, Avishek Anand", "title": "A study on the Interpretability of Neural Retrieval Models using\n  DeepSHAP", "comments": "4 pages; SIGIR 2019 Short Paper", "journal-ref": null, "doi": "10.1145/3331184.3331312", "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A recent trend in IR has been the usage of neural networks to learn retrieval\nmodels for text based adhoc search. While various approaches and architectures\nhave yielded significantly better performance than traditional retrieval models\nsuch as BM25, it is still difficult to understand exactly why a document is\nrelevant to a query. In the ML community several approaches for explaining\ndecisions made by deep neural networks have been proposed -- including DeepSHAP\nwhich modifies the DeepLift algorithm to estimate the relative importance\n(shapley values) of input features for a given decision by comparing the\nactivations in the network for a given image against the activations caused by\na reference input. In image classification, the reference input tends to be a\nplain black image. While DeepSHAP has been well studied for image\nclassification tasks, it remains to be seen how we can adapt it to explain the\noutput of Neural Retrieval Models (NRMs). In particular, what is a good \"black\"\nimage in the context of IR? In this paper we explored various reference input\ndocument construction techniques. Additionally, we compared the explanations\ngenerated by DeepSHAP to LIME (a model agnostic approach) and found that the\nexplanations differ considerably. Our study raises concerns regarding the\nrobustness and accuracy of explanations produced for NRMs. With this paper we\naim to shed light on interesting problems surrounding interpretability in NRMs\nand highlight areas of future work.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jul 2019 13:09:18 GMT"}], "update_date": "2019-07-16", "authors_parsed": [["Fernando", "Zeon Trevor", ""], ["Singh", "Jaspreet", ""], ["Anand", "Avishek", ""]]}, {"id": "1907.06490", "submitter": "Diego Valsesia", "authors": "Andrea Bordone Molini, Diego Valsesia, Giulia Fracastoro, Enrico Magli", "title": "DeepSUM: Deep neural network for Super-resolution of Unregistered\n  Multitemporal images", "comments": null, "journal-ref": null, "doi": "10.1109/TGRS.2019.2959248", "report-no": null, "categories": "eess.IV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, convolutional neural networks (CNN) have been successfully applied\nto many remote sensing problems. However, deep learning techniques for\nmulti-image super-resolution from multitemporal unregistered imagery have\nreceived little attention so far. This work proposes a novel CNN-based\ntechnique that exploits both spatial and temporal correlations to combine\nmultiple images. This novel framework integrates the spatial registration task\ndirectly inside the CNN, and allows to exploit the representation learning\ncapabilities of the network to enhance registration accuracy. The entire\nsuper-resolution process relies on a single CNN with three main stages: shared\n2D convolutions to extract high-dimensional features from the input images; a\nsubnetwork proposing registration filters derived from the high-dimensional\nfeature representations; 3D convolutions for slow fusion of the features from\nmultiple images. The whole network can be trained end-to-end to recover a\nsingle high resolution image from multiple unregistered low resolution images.\nThe method presented in this paper is the winner of the PROBA-V\nsuper-resolution challenge issued by the European Space Agency.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jul 2019 13:21:43 GMT"}, {"version": "v2", "created": "Wed, 15 Jan 2020 10:49:54 GMT"}], "update_date": "2020-01-16", "authors_parsed": [["Molini", "Andrea Bordone", ""], ["Valsesia", "Diego", ""], ["Fracastoro", "Giulia", ""], ["Magli", "Enrico", ""]]}, {"id": "1907.06496", "submitter": "Reuben Feinman", "authors": "Reuben Feinman, Nikhil Parthasarathy", "title": "A Linear Systems Theory of Normalizing Flows", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Normalizing Flows are a promising new class of algorithms for unsupervised\nlearning based on maximum likelihood optimization with change of variables.\nThey offer to learn a factorized component representation for complex nonlinear\ndata and, simultaneously, yield a density function that can evaluate\nlikelihoods and generate samples. Despite these diverse offerings, applications\nof Normalizing Flows have focused primarily on sampling and likelihoods, with\nlittle emphasis placed on feature representation. A lack of theoretical\nfoundation has left many open questions about how to interpret and apply the\nlearned components of the model. We provide a new theoretical perspective of\nNormalizing Flows using the lens of linear systems theory, showing that optimal\nflows learn to represent the local covariance at each region of input space.\nUsing this insight, we develop a new algorithm to extract interpretable\ncomponent representations from the learned model, where components correspond\nto Cartesian dimensions and are scaled according to their manifold\nsignificance. In addition, we highlight a stability concern for the learning\nalgorithm that was previously unaddressed, providing a theoretically-grounded\nsolution to mediate the problem. Experiments with toy manifold learning\ndatasets, as well as the MNIST image dataset, provide convincing support for\nour theory and tools.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jul 2019 13:28:27 GMT"}, {"version": "v2", "created": "Thu, 18 Jul 2019 16:31:17 GMT"}, {"version": "v3", "created": "Tue, 11 Feb 2020 20:42:01 GMT"}, {"version": "v4", "created": "Fri, 14 Feb 2020 17:30:42 GMT"}], "update_date": "2020-02-17", "authors_parsed": [["Feinman", "Reuben", ""], ["Parthasarathy", "Nikhil", ""]]}, {"id": "1907.06508", "submitter": "Wolfgang Konen K", "authors": "Wolfgang Konen", "title": "General Board Game Playing for Education and Research in Generic AI Game\n  Learning", "comments": "8 pages, for: Conference on Games (CoG), London, 2019. Index Terms:\n  game learning, general game playing, AI, temporal difference learning, board\n  games, n-tuple systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new general board game (GBG) playing and learning framework. GBG\ndefines the common interfaces for board games, game states and their AI agents.\nIt allows one to run competitions of different agents on different games. It\nstandardizes those parts of board game playing and learning that otherwise\nwould be tedious and repetitive parts in coding. GBG is suitable for arbitrary\n1-, 2-, ..., N-player board games. It makes a generic TD($\\lambda$)-n-tuple\nagent for the first time available to arbitrary games. On various games,\nTD($\\lambda$)-n-tuple is found to be superior to other generic agents like\nMCTS. GBG aims at the educational perspective, where it helps students to start\nfaster in the area of game learning. GBG aims as well at the research\nperspective by collecting a growing set of games and AI agents to assess their\nstrengths and generalization capabilities in meaningful competitions. Initial\nsuccessful educational and research results are reported.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jul 2019 13:02:25 GMT"}], "update_date": "2019-07-16", "authors_parsed": [["Konen", "Wolfgang", ""]]}, {"id": "1907.06511", "submitter": "Xingyou Song", "authors": "Xingyou Song, Krzysztof Choromanski, Jack Parker-Holder, Yunhao Tang,\n  Wenbo Gao, Aldo Pacchiano, Tamas Sarlos, Deepali Jain, Yuxiang Yang", "title": "Reinforcement Learning with Chromatic Networks for Compact Architecture\n  Search", "comments": "Published at ICLR 2020 Neural Architecture Search Workshop. This\n  paper is deprecated; please see arXiv:2101.07415 for the newer version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a neural architecture search algorithm to construct compact\nreinforcement learning (RL) policies, by combining ENAS and ES in a highly\nscalable and intuitive way. By defining the combinatorial search space of NAS\nto be the set of different edge-partitionings (colorings) into same-weight\nclasses, we represent compact architectures via efficient learned\nedge-partitionings. For several RL tasks, we manage to learn colorings\ntranslating to effective policies parameterized by as few as $17$ weight\nparameters, providing >90% compression over vanilla policies and 6x compression\nover state-of-the-art compact policies based on Toeplitz matrices, while still\nmaintaining good reward. We believe that our work is one of the first attempts\nto propose a rigorous approach to training structured neural network\narchitectures for RL problems that are of interest especially in mobile\nrobotics with limited storage and computational resources.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jul 2019 16:57:50 GMT"}, {"version": "v2", "created": "Wed, 25 Sep 2019 16:04:11 GMT"}, {"version": "v3", "created": "Mon, 2 Mar 2020 22:37:04 GMT"}, {"version": "v4", "created": "Tue, 6 Apr 2021 17:00:42 GMT"}], "update_date": "2021-04-07", "authors_parsed": [["Song", "Xingyou", ""], ["Choromanski", "Krzysztof", ""], ["Parker-Holder", "Jack", ""], ["Tang", "Yunhao", ""], ["Gao", "Wenbo", ""], ["Pacchiano", "Aldo", ""], ["Sarlos", "Tamas", ""], ["Jain", "Deepali", ""], ["Yang", "Yuxiang", ""]]}, {"id": "1907.06536", "submitter": "Han Cha", "authors": "Han Cha, Jihong Park, Hyesung Kim, Seong-Lyun Kim, Mehdi Bennis", "title": "Federated Reinforcement Distillation with Proxy Experience Memory", "comments": "To be presented at the 28th International Joint Conference on\n  Artificial Intelligence (IJCAI-19), 1st International Workshop on Federated\n  Machine Learning for User Privacy and Data Confidentiality (FML'19), Macao,\n  China", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.MA cs.NI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In distributed reinforcement learning, it is common to exchange the\nexperience memory of each agent and thereby collectively train their local\nmodels. The experience memory, however, contains all the preceding state\nobservations and their corresponding policies of the host agent, which may\nviolate the privacy of the agent. To avoid this problem, in this work, we\npropose a privacy-preserving distributed reinforcement learning (RL) framework,\ntermed federated reinforcement distillation (FRD). The key idea is to exchange\na proxy experience memory comprising a pre-arranged set of states and\ntime-averaged policies, thereby preserving the privacy of actual experiences.\nBased on an advantage actor-critic RL architecture, we numerically evaluate the\neffectiveness of FRD and investigate how the performance of FRD is affected by\nthe proxy memory structure and different memory exchanging rules.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jul 2019 15:03:14 GMT"}, {"version": "v2", "created": "Mon, 13 Apr 2020 06:33:38 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Cha", "Han", ""], ["Park", "Jihong", ""], ["Kim", "Hyesung", ""], ["Kim", "Seong-Lyun", ""], ["Bennis", "Mehdi", ""]]}, {"id": "1907.06543", "submitter": "Sophia Bano Dr", "authors": "Sophia Bano, Francisco Vasconcelos, Marcel Tella Amo, George Dwyer,\n  Caspar Gruijthuijsen, Jan Deprest, Sebastien Ourselin, Emmanuel Vander\n  Poorten, Tom Vercauteren, Danail Stoyanov", "title": "Deep Sequential Mosaicking of Fetoscopic Videos", "comments": "Accepted at MICCAI 2019", "journal-ref": null, "doi": "10.1007/978-3-030-32239-7_35", "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Twin-to-twin transfusion syndrome treatment requires fetoscopic laser\nphotocoagulation of placental vascular anastomoses to regulate blood flow to\nboth fetuses. Limited field-of-view (FoV) and low visual quality during\nfetoscopy make it challenging to identify all vascular connections. Mosaicking\ncan align multiple overlapping images to generate an image with increased FoV,\nhowever, existing techniques apply poorly to fetoscopy due to the low visual\nquality, texture paucity, and hence fail in longer sequences due to the drift\naccumulated over time. Deep learning techniques can facilitate in overcoming\nthese challenges. Therefore, we present a new generalized Deep Sequential\nMosaicking (DSM) framework for fetoscopic videos captured from different\nsettings such as simulation, phantom, and real environments. DSM extends an\nexisting deep image-based homography model to sequential data by proposing\ncontrolled data augmentation and outlier rejection methods. Unlike existing\nmethods, DSM can handle visual variations due to specular highlights and\nreflection across adjacent frames, hence reducing the accumulated drift. We\nperform experimental validation and comparison using 5 diverse fetoscopic\nvideos to demonstrate the robustness of our framework.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jul 2019 15:11:09 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Bano", "Sophia", ""], ["Vasconcelos", "Francisco", ""], ["Amo", "Marcel Tella", ""], ["Dwyer", "George", ""], ["Gruijthuijsen", "Caspar", ""], ["Deprest", "Jan", ""], ["Ourselin", "Sebastien", ""], ["Poorten", "Emmanuel Vander", ""], ["Vercauteren", "Tom", ""], ["Stoyanov", "Danail", ""]]}, {"id": "1907.06550", "submitter": "Wenhao Li", "authors": "Wenhao Li, Ningyuan Chen, L.Jeff Hong", "title": "A Dimension-free Algorithm for Contextual Continuum-armed Bandits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In contextual continuum-armed bandits, the contexts $x$ and the arms $y$ are\nboth continuous and drawn from high-dimensional spaces. The payoff function to\nlearn $f(x,y)$ does not have a particular parametric form. The literature has\nshown that for Lipschitz-continuous functions, the optimal regret is\n$\\tilde{O}(T^{\\frac{d_x+d_y+1}{d_x+d_y+2}})$, where $d_x$ and $d_y$ are the\ndimensions of contexts and arms, and thus suffers from the curse of\ndimensionality. We develop an algorithm that achieves regret\n$\\tilde{O}(T^{\\frac{d_x+1}{d_x+2}})$ when $f$ is globally concave in $y$. The\nglobal concavity is a common assumption in many applications. The algorithm is\nbased on stochastic approximation and estimates the gradient information in an\nonline fashion. Our results generate a valuable insight that the curse of\ndimensionality of the arms can be overcome with some mild structures of the\npayoff function.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jul 2019 15:27:30 GMT"}, {"version": "v2", "created": "Thu, 18 Jul 2019 06:30:54 GMT"}], "update_date": "2019-07-19", "authors_parsed": [["Li", "Wenhao", ""], ["Chen", "Ningyuan", ""], ["Hong", "L. Jeff", ""]]}, {"id": "1907.06558", "submitter": "Sofia Ira Ktena", "authors": "Sofia Ira Ktena, Alykhan Tejani, Lucas Theis, Pranay Kumar Myana,\n  Deepak Dilipkumar, Ferenc Huszar, Steven Yoo, Wenzhe Shi", "title": "Addressing Delayed Feedback for Continuous Training with Neural Networks\n  in CTR prediction", "comments": "Accepted at RecSys '19", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the challenges in display advertising is that the distribution of\nfeatures and click through rate (CTR) can exhibit large shifts over time due to\nseasonality, changes to ad campaigns and other factors. The predominant\nstrategy to keep up with these shifts is to train predictive models\ncontinuously, on fresh data, in order to prevent them from becoming stale.\nHowever, in many ad systems positive labels are only observed after a possibly\nlong and random delay. These delayed labels pose a challenge to data freshness\nin continuous training: fresh data may not have complete label information at\nthe time they are ingested by the training algorithm. Naive strategies which\nconsider any data point a negative example until a positive label becomes\navailable tend to underestimate CTR, resulting in inferior user experience and\nsuboptimal performance for advertisers. The focus of this paper is to identify\nthe best combination of loss functions and models that enable large-scale\nlearning from a continuous stream of data in the presence of delayed labels. In\nthis work, we compare 5 different loss functions, 3 of them applied to this\nproblem for the first time. We benchmark their performance in offline settings\non both public and proprietary datasets in conjunction with shallow and deep\nmodel architectures. We also discuss the engineering cost associated with\nimplementing each loss function in a production environment. Finally, we\ncarried out online experiments with the top performing methods, in order to\nvalidate their performance in a continuous training scheme. While training on\n668 million in-house data points offline, our proposed methods outperform\nprevious state-of-the-art by 3% relative cross entropy (RCE). During online\nexperiments, we observed 55% gain in revenue per thousand requests (RPMq)\nagainst naive log loss.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jul 2019 15:56:49 GMT"}, {"version": "v2", "created": "Fri, 23 Apr 2021 18:39:39 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Ktena", "Sofia Ira", ""], ["Tejani", "Alykhan", ""], ["Theis", "Lucas", ""], ["Myana", "Pranay Kumar", ""], ["Dilipkumar", "Deepak", ""], ["Huszar", "Ferenc", ""], ["Yoo", "Steven", ""], ["Shi", "Wenzhe", ""]]}, {"id": "1907.06565", "submitter": "Jasjeet Dhaliwal", "authors": "Jasjeet Dhaliwal, Kyle Hambrook", "title": "Recovery Guarantees for Compressible Signals with Adversarial Noise", "comments": "Theorem 1 updated, \\ell_\\infty defense added, Lemma 9 added, comp.\n  section updated, abstract updated, and other minor writing edits", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR cs.DS cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide recovery guarantees for compressible signals that have been\ncorrupted with noise and extend the framework introduced in\n\\cite{bafna2018thwarting} to defend neural networks against $\\ell_0$-norm,\n$\\ell_2$-norm, and $\\ell_{\\infty}$-norm attacks. Our results are general as\nthey can be applied to most unitary transforms used in practice and hold for\n$\\ell_0$-norm, $\\ell_2$-norm, and $\\ell_\\infty$-norm bounded noise. In the case\nof $\\ell_0$-norm noise, we prove recovery guarantees for Iterative Hard\nThresholding (IHT) and Basis Pursuit (BP). For $\\ell_2$-norm bounded noise, we\nprovide recovery guarantees for BP and for the case of $\\ell_\\infty$-norm\nbounded noise, we provide recovery guarantees for Dantzig Selector (DS). These\nguarantees theoretically bolster the defense framework introduced in\n\\cite{bafna2018thwarting} for defending neural networks against adversarial\ninputs. Finally, we experimentally demonstrate the effectiveness of this\ndefense framework against an array of $\\ell_0$, $\\ell_2$ and $\\ell_\\infty$ norm\nattacks.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jul 2019 16:15:12 GMT"}, {"version": "v2", "created": "Fri, 19 Jul 2019 12:56:03 GMT"}, {"version": "v3", "created": "Wed, 7 Aug 2019 16:53:34 GMT"}], "update_date": "2019-08-08", "authors_parsed": [["Dhaliwal", "Jasjeet", ""], ["Hambrook", "Kyle", ""]]}, {"id": "1907.06566", "submitter": "Haisheng Fu", "authors": "Haisheng Fu, Feng Liang, Bo Lei, Nai Bian, Qian zhang, Mohammad\n  Akbari, Jie Liang and Chengjie Tu", "title": "Improved Hybrid Layered Image Compression using Deep Learning and\n  Traditional Codecs", "comments": "Submitted to Signal Processing: Image Communication", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently deep learning-based methods have been applied in image compression\nand achieved many promising results. In this paper, we propose an improved\nhybrid layered image compression framework by combining deep learning and the\ntraditional image codecs. At the encoder, we first use a convolutional neural\nnetwork (CNN) to obtain a compact representation of the input image, which is\nlosslessly encoded by the FLIF codec as the base layer of the bit stream. A\ncoarse reconstruction of the input is obtained by another CNN from the\nreconstructed compact representation. The residual between the input and the\ncoarse reconstruction is then obtained and encoded by the H.265/HEVC-based BPG\ncodec as the enhancement layer of the bit stream. Experimental results using\nthe Kodak and Tecnick datasets show that the proposed scheme outperforms the\nstate-of-the-art deep learning-based layered coding scheme and traditional\ncodecs including BPG in both PSNR and MS-SSIM metrics across a wide range of\nbit rates, when the images are coded in the RGB444 domain.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jul 2019 16:16:21 GMT"}], "update_date": "2019-07-16", "authors_parsed": [["Fu", "Haisheng", ""], ["Liang", "Feng", ""], ["Lei", "Bo", ""], ["Bian", "Nai", ""], ["zhang", "Qian", ""], ["Akbari", "Mohammad", ""], ["Liang", "Jie", ""], ["Tu", "Chengjie", ""]]}, {"id": "1907.06571", "submitter": "Aidan Clark", "authors": "Aidan Clark, Jeff Donahue, Karen Simonyan", "title": "Adversarial Video Generation on Complex Datasets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative models of natural images have progressed towards high fidelity\nsamples by the strong leveraging of scale. We attempt to carry this success to\nthe field of video modeling by showing that large Generative Adversarial\nNetworks trained on the complex Kinetics-600 dataset are able to produce video\nsamples of substantially higher complexity and fidelity than previous work. Our\nproposed model, Dual Video Discriminator GAN (DVD-GAN), scales to longer and\nhigher resolution videos by leveraging a computationally efficient\ndecomposition of its discriminator. We evaluate on the related tasks of video\nsynthesis and video prediction, and achieve new state-of-the-art Fr\\'echet\nInception Distance for prediction for Kinetics-600, as well as state-of-the-art\nInception Score for synthesis on the UCF-101 dataset, alongside establishing a\nstrong baseline for synthesis on Kinetics-600.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jul 2019 16:27:04 GMT"}, {"version": "v2", "created": "Wed, 25 Sep 2019 16:37:55 GMT"}], "update_date": "2019-09-26", "authors_parsed": [["Clark", "Aidan", ""], ["Donahue", "Jeff", ""], ["Simonyan", "Karen", ""]]}, {"id": "1907.06572", "submitter": "Xiao Dong", "authors": "X. Dong and L. Zhou", "title": "Deep network as memory space: complexity, generalization, disentangled\n  representation and interpretability", "comments": "11 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  By bridging deep networks and physics, the programme of geometrization of\ndeep networks was proposed as a framework for the interpretability of deep\nlearning systems. Following this programme we can apply two key ideas of\nphysics, the geometrization of physics and the least action principle, on deep\nnetworks and deliver a new picture of deep networks: deep networks as memory\nspace of information, where the capacity, robustness and efficiency of the\nmemory are closely related with the complexity, generalization and\ndisentanglement of deep networks. The key components of this understanding\ninclude:(1) a Fisher metric based formulation of the network complexity; (2)the\nleast action (complexity=action) principle on deep networks and (3)the geometry\nbuilt on deep network configurations. We will show how this picture will bring\nus a new understanding of the interpretability of deep learning systems.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jul 2019 12:55:59 GMT"}], "update_date": "2019-07-16", "authors_parsed": [["Dong", "X.", ""], ["Zhou", "L.", ""]]}, {"id": "1907.06582", "submitter": "Lin Guo", "authors": "Zheng Gao, Lin Guo, Chi Ma, Xiao Ma, Kai Sun, Hang Xiang, Xiaoqiang\n  Zhu, Hongsong Li, Xiaozhong Liu", "title": "AMAD: Adversarial Multiscale Anomaly Detection on High-Dimensional and\n  Time-Evolving Categorical Data", "comments": "Accepted by 2019 KDD Workshop on Deep Learning Practice for\n  High-Dimensional Sparse Data", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Anomaly detection is facing with emerging challenges in many important\nindustry domains, such as cyber security and online recommendation and\nadvertising. The recent trend in these areas calls for anomaly detection on\ntime-evolving data with high-dimensional categorical features without labeled\nsamples. Also, there is an increasing demand for identifying and monitoring\nirregular patterns at multiple resolutions. In this work, we propose a unified\nend-to-end approach to solve these challenges by combining the advantages of\nAdversarial Autoencoder and Recurrent Neural Network. The model learns data\nrepresentations cross different scales with attention mechanisms, on which an\nenhanced two-resolution anomaly detector is developed for both instances and\ndata blocks. Extensive experiments are performed over three types of datasets\nto demonstrate the efficacy of our method and its superiority over the\nstate-of-art approaches.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jul 2019 05:51:33 GMT"}], "update_date": "2019-07-16", "authors_parsed": [["Gao", "Zheng", ""], ["Guo", "Lin", ""], ["Ma", "Chi", ""], ["Ma", "Xiao", ""], ["Sun", "Kai", ""], ["Xiang", "Hang", ""], ["Zhu", "Xiaoqiang", ""], ["Li", "Hongsong", ""], ["Liu", "Xiaozhong", ""]]}, {"id": "1907.06584", "submitter": "Yang Yu", "authors": "Wenjie Shang, Yang Yu, Qingyang Li, Zhiwei Qin, Yiping Meng, Jieping\n  Ye", "title": "Environment Reconstruction with Hidden Confounders for Reinforcement\n  Learning based Recommendation", "comments": "Appears in KDD 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning aims at searching the best policy model for decision\nmaking, and has been shown powerful for sequential recommendations. The\ntraining of the policy by reinforcement learning, however, is placed in an\nenvironment. In many real-world applications, however, the policy training in\nthe real environment can cause an unbearable cost, due to the exploration in\nthe environment. Environment reconstruction from the past data is thus an\nappealing way to release the power of reinforcement learning in these\napplications. The reconstruction of the environment is, basically, to extract\nthe casual effect model from the data. However, real-world applications are\noften too complex to offer fully observable environment information. Therefore,\nquite possibly there are unobserved confounding variables lying behind the\ndata. The hidden confounder can obstruct an effective reconstruction of the\nenvironment. In this paper, by treating the hidden confounder as a hidden\npolicy, we propose a deconfounded multi-agent environment reconstruction\n(DEMER) approach in order to learn the environment together with the hidden\nconfounder. DEMER adopts a multi-agent generative adversarial imitation\nlearning framework. It proposes to introduce the confounder embedded policy,\nand use the compatible discriminator for training the policies. We then apply\nDEMER in an application of driver program recommendation. We firstly use an\nartificial driver program recommendation environment, abstracted from the real\napplication, to verify and analyze the effectiveness of DEMER. We then test\nDEMER in the real application of Didi Chuxing. Experiment results show that\nDEMER can effectively reconstruct the hidden confounder, and thus can build the\nenvironment better. DEMER also derives a recommendation policy with a\nsignificantly improved performance in the test phase of the real application.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jul 2019 10:13:05 GMT"}], "update_date": "2019-07-16", "authors_parsed": [["Shang", "Wenjie", ""], ["Yu", "Yang", ""], ["Li", "Qingyang", ""], ["Qin", "Zhiwei", ""], ["Meng", "Yiping", ""], ["Ye", "Jieping", ""]]}, {"id": "1907.06589", "submitter": "Aleksey Fedorov", "authors": "E.S. Tiunov, V.V. Tiunova (Vyborova), A.E. Ulanov, A.I. Lvovsky, and\n  A.K. Fedorov", "title": "Experimental quantum homodyne tomography via machine learning", "comments": "7+4 pages, 4+2 figures", "journal-ref": "Optica 7, 448 (2020)", "doi": "10.1364/OPTICA.389482", "report-no": null, "categories": "quant-ph cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Complete characterization of states and processes that occur within quantum\ndevices is crucial for understanding and testing their potential to outperform\nclassical technologies for communications and computing. However, solving this\ntask with current state-of-the-art techniques becomes unwieldy for large and\ncomplex quantum systems. Here we realize and experimentally demonstrate a\nmethod for complete characterization of a quantum harmonic oscillator based on\nan artificial neural network known as the restricted Boltzmann machine. We\napply the method to optical homodyne tomography and show it to allow full\nestimation of quantum states based on a smaller amount of experimental data\ncompared to state-of-the-art methods. We link this advantage to reduced\noverfitting. Although our experiment is in the optical domain, our method\nprovides a way of exploring quantum resources in a broad class of large-scale\nphysical systems, such as superconducting circuits, atomic and molecular\nensembles, and optomechanical systems.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jul 2019 16:46:21 GMT"}, {"version": "v2", "created": "Thu, 1 Aug 2019 11:29:11 GMT"}, {"version": "v3", "created": "Wed, 6 May 2020 07:12:54 GMT"}], "update_date": "2020-05-07", "authors_parsed": [["Tiunov", "E. S.", "", "Vyborova"], ["Tiunova", "V. V.", "", "Vyborova"], ["Ulanov", "A. E.", ""], ["Lvovsky", "A. I.", ""], ["Fedorov", "A. K.", ""]]}, {"id": "1907.06592", "submitter": "Paschalis Bizopoulos", "authors": "Paschalis Bizopoulos, and Dimitrios Koutsouris", "title": "Sparsely Activated Networks", "comments": "10 pages, 5 figures, 4 algorithms, 4 tables, submission to IEEE\n  Transactions on Neural Networks and Learning Systems", "journal-ref": null, "doi": "10.1109/TNNLS.2020.2984514", "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Previous literature on unsupervised learning focused on designing structural\npriors with the aim of learning meaningful features. However, this was done\nwithout considering the description length of the learned representations which\nis a direct and unbiased measure of the model complexity. In this paper, first\nwe introduce the $\\varphi$ metric that evaluates unsupervised models based on\ntheir reconstruction accuracy and the degree of compression of their internal\nrepresentations. We then present and define two activation functions (Identity,\nReLU) as base of reference and three sparse activation functions (top-k\nabsolutes, Extrema-Pool indices, Extrema) as candidate structures that minimize\nthe previously defined $\\varphi$. We lastly present Sparsely Activated Networks\n(SANs) that consist of kernels with shared weights that, during encoding, are\nconvolved with the input and then passed through a sparse activation function.\nDuring decoding, the same weights are convolved with the sparse activation map\nand subsequently the partial reconstructions from each weight are summed to\nreconstruct the input. We compare SANs using the five previously defined\nactivation functions on a variety of datasets (Physionet, UCI-epilepsy, MNIST,\nFMNIST) and show that models that are selected using $\\varphi$ have small\ndescription representation length and consist of interpretable kernels.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jul 2019 08:01:47 GMT"}, {"version": "v2", "created": "Tue, 22 Oct 2019 14:24:02 GMT"}, {"version": "v3", "created": "Sun, 2 Feb 2020 13:05:55 GMT"}, {"version": "v4", "created": "Wed, 3 Feb 2021 16:25:28 GMT"}], "update_date": "2021-02-04", "authors_parsed": [["Bizopoulos", "Paschalis", ""], ["Koutsouris", "Dimitrios", ""]]}, {"id": "1907.06594", "submitter": "Shuhao Xia", "authors": "Shuhao Xia and Yuanming Shi", "title": "Learning One-hidden-layer neural networks via Provable Gradient Descent\n  with Random Initialization", "comments": "the provement need to be corrected", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although deep learning has shown its powerful performance in many\napplications, the mathematical principles behind neural networks are still\nmysterious. In this paper, we consider the problem of learning a\none-hidden-layer neural network with quadratic activations. We focus on the\nunder-parameterized regime where the number of hidden units is smaller than the\ndimension of the inputs. We shall propose to solve the problem via a provable\ngradient-based method with random initialization. For the non-convex neural\nnetworks training problem we reveal that the gradient descent iterates are able\nto enter a local region that enjoys strong convexity and smoothness within a\nfew iterations, and then provably converges to a globally optimal model at a\nlinear rate with near-optimal sample complexity. We further corroborate our\ntheoretical findings via various experiments.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jul 2019 08:50:04 GMT"}, {"version": "v2", "created": "Tue, 16 Jul 2019 01:37:41 GMT"}], "update_date": "2019-07-17", "authors_parsed": [["Xia", "Shuhao", ""], ["Shi", "Yuanming", ""]]}, {"id": "1907.06600", "submitter": "Qiuyue Zhong", "authors": "Qiu-Yue Zhong, Andrew H. Fairless, Jasmine M. McCammon, Farbod\n  Rahmanian", "title": "Medical Concept Representation Learning from Claims Data and Application\n  to Health Plan Payment Risk Adjustment", "comments": "Accepted as a poster presentation at the 2019 KDD Workshop on Applied\n  Data Science for Healthcare (KDD-DSHealth2019), Aug 5, 2019, Anchorage,\n  Alaska USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Risk adjustment has become an increasingly important tool in healthcare. It\nhas been extensively applied to payment adjustment for health plans to reflect\nthe expected cost of providing coverage for members. Risk adjustment models are\ntypically estimated using linear regression, which does not fully exploit the\ninformation in claims data. Moreover, the development of such linear regression\nmodels requires substantial domain expert knowledge and computational effort\nfor data preprocessing. In this paper, we propose a novel approach for risk\nadjustment that uses semantic embeddings to represent patient medical\nhistories. Embeddings efficiently represent medical concepts learned from\ndiagnostic, procedure, and prescription codes in patients' medical histories.\nThis approach substantially reduces the need for feature engineering. Our\nresults show that models using embeddings had better performance than a\ncommercial risk adjustment model on the task of prospective risk score\nprediction.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jul 2019 16:53:43 GMT"}], "update_date": "2019-07-16", "authors_parsed": [["Zhong", "Qiu-Yue", ""], ["Fairless", "Andrew H.", ""], ["McCammon", "Jasmine M.", ""], ["Rahmanian", "Farbod", ""]]}, {"id": "1907.06607", "submitter": "Matthew Spellings", "authors": "Matthew Spellings", "title": "Agglomerative Attention", "comments": "7 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Neural networks using transformer-based architectures have recently\ndemonstrated great power and flexibility in modeling sequences of many types.\nOne of the core components of transformer networks is the attention layer,\nwhich allows contextual information to be exchanged among sequence elements.\nWhile many of the prevalent network structures thus far have utilized full\nattention -- which operates on all pairs of sequence elements -- the quadratic\nscaling of this attention mechanism significantly constrains the size of models\nthat can be trained. In this work, we present an attention model that has only\nlinear requirements in memory and computation time. We show that, despite the\nsimpler attention model, networks using this attention mechanism can attain\ncomparable performance to full attention networks on language modeling tasks.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jul 2019 17:11:05 GMT"}], "update_date": "2019-07-16", "authors_parsed": [["Spellings", "Matthew", ""]]}, {"id": "1907.06614", "submitter": "Argyris Kalogeratos", "authors": "Ioannis Bargiotas, Argyris Kalogeratos, Myrto Limnios, Pierre-Paul\n  Vidal, Damien Ricard, Nicolas Vayatis", "title": "Revealing posturographic features associated with the risk of falling in\n  patients with Parkinsonian syndromes via machine learning", "comments": "16 pages, 11 figures (plots, tables, algorithms)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Falling in Parkinsonian syndromes (PS) is associated with postural\ninstability and consists a common cause of disability among PS patients.\nCurrent posturographic practices record the body's center-of-pressure\ndisplacement (statokinesigram) while the patient stands on a force platform.\nStatokinesigrams, after appropriate signal processing, can offer numerous\nposturographic features, which however challenges the efforts for valid\nstatistics via standard univariate approaches. In this work, we present the\nts-AUC, a non-parametric multivariate two-sample test, which we employ to\nanalyze statokinesigram differences among PS patients that are fallers (PSf)\nand non-fallers (PSNF). We included 123 PS patients who were classified into\nPSF or PSNF based on clinical assessment and underwent simple Romberg Test\n(eyes open/eyes closed). We analyzed posturographic features using both\nmultiple testing with p-value adjustment and the ts-AUC. While the ts-AUC\nshowed significant difference between groups (p-value = 0.01), multiple testing\ndid not show any such difference. Interestingly, significant difference between\nthe two groups was found only using the open-eyes protocol. PSF showed\nsignificantly increased antero-posterior movements as well as increased\nposturographic area, compared to PSNF. Our study demonstrates the superiority\nof the ts-AUC test compared to standard statistical tools in distinguishing PSF\nand PSNF in the multidimensional feature space. This result highlights more\ngenerally the fact that machine learning-based statistical tests can be seen as\na natural extension of classical statistical approaches and should be\nconsidered, especially when dealing with multifactorial assessments.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jul 2019 17:21:13 GMT"}], "update_date": "2019-07-16", "authors_parsed": [["Bargiotas", "Ioannis", ""], ["Kalogeratos", "Argyris", ""], ["Limnios", "Myrto", ""], ["Vidal", "Pierre-Paul", ""], ["Ricard", "Damien", ""], ["Vayatis", "Nicolas", ""]]}, {"id": "1907.06627", "submitter": "Babak Ehteshami Bejnordi", "authors": "Babak Ehteshami Bejnordi, Tijmen Blankevoort and Max Welling", "title": "Batch-Shaping for Learning Conditional Channel Gated Networks", "comments": "Published as a conference paper at ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a method that trains large capacity neural networks with\nsignificantly improved accuracy and lower dynamic computational cost. We\nachieve this by gating the deep-learning architecture on a fine-grained-level.\nIndividual convolutional maps are turned on/off conditionally on features in\nthe network. To achieve this, we introduce a new residual block architecture\nthat gates convolutional channels in a fine-grained manner. We also introduce a\ngenerally applicable tool $batch$-$shaping$ that matches the marginal aggregate\nposteriors of features in a neural network to a pre-specified prior\ndistribution. We use this novel technique to force gates to be more conditional\non the data. We present results on CIFAR-10 and ImageNet datasets for image\nclassification, and Cityscapes for semantic segmentation. Our results show that\nour method can slim down large architectures conditionally, such that the\naverage computational cost on the data is on par with a smaller architecture,\nbut with higher accuracy. In particular, on ImageNet, our ResNet50 and ResNet34\ngated networks obtain 74.60% and 72.55% top-1 accuracy compared to the 69.76%\naccuracy of the baseline ResNet18 model, for similar complexity. We also show\nthat the resulting networks automatically learn to use more features for\ndifficult examples and fewer features for simple examples.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jul 2019 17:58:04 GMT"}, {"version": "v2", "created": "Sun, 6 Oct 2019 12:13:32 GMT"}, {"version": "v3", "created": "Thu, 19 Mar 2020 09:10:52 GMT"}, {"version": "v4", "created": "Fri, 3 Apr 2020 08:42:24 GMT"}], "update_date": "2020-04-06", "authors_parsed": [["Bejnordi", "Babak Ehteshami", ""], ["Blankevoort", "Tijmen", ""], ["Welling", "Max", ""]]}, {"id": "1907.06632", "submitter": "Anurag Dwarakanath", "authors": "Anurag Dwarakanath, Manish Ahuja, Sanjay Podder, Silja Vinu, Arijit\n  Naskar, Koushik MV", "title": "Metamorphic Testing of a Deep Learning based Forecaster", "comments": "Paper published at the 2019 IEEE/ACM 4th International Workshop on\n  Metamorphic Testing (MET)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present the Metamorphic Testing of an in-use deep learning\nbased forecasting application. The application looks at the past data of system\ncharacteristics (e.g. `memory allocation') to predict outages in the future. We\nfocus on two statistical / machine learning based components - a) detection of\nco-relation between system characteristics and b) estimating the future value\nof a system characteristic using an LSTM (a deep learning architecture). In\ntotal, 19 Metamorphic Relations have been developed and we provide proofs &\nalgorithms where applicable. We evaluated our method through two settings. In\nthe first, we executed the relations on the actual application and uncovered 8\nissues not known before. Second, we generated hypothetical bugs, through\nMutation Testing, on a reference implementation of the LSTM based forecaster\nand found that 65.9% of the bugs were caught through the relations.\n", "versions": [{"version": "v1", "created": "Sat, 13 Jul 2019 14:04:15 GMT"}], "update_date": "2019-07-17", "authors_parsed": [["Dwarakanath", "Anurag", ""], ["Ahuja", "Manish", ""], ["Podder", "Sanjay", ""], ["Vinu", "Silja", ""], ["Naskar", "Arijit", ""], ["MV", "Koushik", ""]]}, {"id": "1907.06633", "submitter": "Apdullah Yayik", "authors": "Apdullah Yay{\\i}k, Yakup Kutlu, G\\\"okhan Altan", "title": "On improving learning capability of ELM and an application to\n  brain-computer interface", "comments": "11 pages, 6 figures, Neural Computing and Application, Springer\n  (under-review)", "journal-ref": null, "doi": "10.13140/RG.2.2.30778.34248", "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  As a type of pseudoinverse learning, extreme learning machine (ELM) is able\nto achieve high performances in a rapid pace on benchmark datasets. However,\nwhen it is applied to real life large data, decline related to low-convergence\nof singular value decomposition (SVD) method occurs. Our study aims to resolve\nthis issue via replacing SVD with theoretically and empirically much efficient\n5 number of methods: lower upper triangularization, Hessenberg decomposition,\nSchur decomposition, modified Gram Schmidt algorithm and Householder\nreflection. Comparisons were made on electroencephalography based\nbrain-computer interface classification problem to decide which method is the\nmost useful. Results of subject-based classifications suggested that if\npriority was given to training pace, Hessenberg decomposition method, whereas\nif priority was given to performances Householder reflection method should be\npreferred.\n", "versions": [{"version": "v1", "created": "Sun, 14 Jul 2019 09:28:07 GMT"}], "update_date": "2019-07-29", "authors_parsed": [["Yay\u0131k", "Apdullah", ""], ["Kutlu", "Yakup", ""], ["Altan", "G\u00f6khan", ""]]}, {"id": "1907.06637", "submitter": "Cheng-Zhi Anna Huang", "authors": "Cheng-Zhi Anna Huang, Curtis Hawthorne, Adam Roberts, Monica\n  Dinculescu, James Wexler, Leon Hong, Jacob Howcroft", "title": "The Bach Doodle: Approachable music composition with machine learning at\n  scale", "comments": "Proceedings of the 18th International Society for Music Information\n  Retrieval Conference, ISMIR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.HC cs.LG eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To make music composition more approachable, we designed the first AI-powered\nGoogle Doodle, the Bach Doodle, where users can create their own melody and\nhave it harmonized by a machine learning model Coconet (Huang et al., 2017) in\nthe style of Bach. For users to input melodies, we designed a simplified\nsheet-music based interface. To support an interactive experience at scale, we\nre-implemented Coconet in TensorFlow.js (Smilkov et al., 2019) to run in the\nbrowser and reduced its runtime from 40s to 2s by adopting dilated depth-wise\nseparable convolutions and fusing operations. We also reduced the model\ndownload size to approximately 400KB through post-training weight quantization.\nWe calibrated a speed test based on partial model evaluation time to determine\nif the harmonization request should be performed locally or sent to remote TPU\nservers. In three days, people spent 350 years worth of time playing with the\nBach Doodle, and Coconet received more than 55 million queries. Users could\nchoose to rate their compositions and contribute them to a public dataset,\nwhich we are releasing with this paper. We hope that the community finds this\ndataset useful for applications ranging from ethnomusicological studies, to\nmusic education, to improving machine learning models.\n", "versions": [{"version": "v1", "created": "Sun, 14 Jul 2019 23:39:12 GMT"}], "update_date": "2019-07-17", "authors_parsed": [["Huang", "Cheng-Zhi Anna", ""], ["Hawthorne", "Curtis", ""], ["Roberts", "Adam", ""], ["Dinculescu", "Monica", ""], ["Wexler", "James", ""], ["Hong", "Leon", ""], ["Howcroft", "Jacob", ""]]}, {"id": "1907.06639", "submitter": "Hangting Chen", "authors": "Hangting Chen, Zuozhen Liu, Zongming Liu, Pengyuan Zhang, Yonghong Yan", "title": "Integrating the Data Augmentation Scheme with Various Classifiers for\n  Acoustic Scene Modeling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This technical report describes the IOA team's submission for TASK1A of\nDCASE2019 challenge. Our acoustic scene classification (ASC) system adopts a\ndata augmentation scheme employing generative adversary networks. Two major\nclassifiers, 1D deep convolutional neural network integrated with scalogram\nfeatures and 2D fully convolutional neural network integrated with Mel filter\nbank features, are deployed in the scheme. Other approaches, such as adversary\ncity adaptation, temporal module based on discrete cosine transform and hybrid\narchitectures, have been developed for further fusion. The results of our\nexperiments indicates that the final fusion systems A-D could achieve an\naccuracy higher than 85% on the officially provided fold 1 evaluation dataset.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jul 2019 08:17:34 GMT"}], "update_date": "2019-07-17", "authors_parsed": [["Chen", "Hangting", ""], ["Liu", "Zuozhen", ""], ["Liu", "Zongming", ""], ["Zhang", "Pengyuan", ""], ["Yan", "Yonghong", ""]]}, {"id": "1907.06671", "submitter": "Sim\\~ao Eduardo", "authors": "Sim\\~ao Eduardo, Alfredo Naz\\'abal, Christopher K. I. Williams,\n  Charles Sutton", "title": "Robust Variational Autoencoders for Outlier Detection and Repair of\n  Mixed-Type Data", "comments": "Accepted for publication at AISTATS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We focus on the problem of unsupervised cell outlier detection and repair in\nmixed-type tabular data. Traditional methods are concerned only with detecting\nwhich rows in the dataset are outliers. However, identifying which cells are\ncorrupted in a specific row is an important problem in practice, and the very\nfirst step towards repairing them. We introduce the Robust Variational\nAutoencoder (RVAE), a deep generative model that learns the joint distribution\nof the clean data while identifying the outlier cells, allowing their\nimputation (repair). RVAE explicitly learns the probability of each cell being\nan outlier, balancing different likelihood models in the row outlier score,\nmaking the method suitable for outlier detection in mixed-type datasets. We\nshow experimentally that not only RVAE performs better than several\nstate-of-the-art methods in cell outlier detection and repair for tabular data,\nbut also that is robust against the initial hyper-parameter selection.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jul 2019 18:06:49 GMT"}, {"version": "v2", "created": "Tue, 3 Mar 2020 23:50:11 GMT"}], "update_date": "2020-03-05", "authors_parsed": [["Eduardo", "Sim\u00e3o", ""], ["Naz\u00e1bal", "Alfredo", ""], ["Williams", "Christopher K. I.", ""], ["Sutton", "Charles", ""]]}, {"id": "1907.06673", "submitter": "Magnus Wiese", "authors": "Magnus Wiese, Robert Knobloch, Ralf Korn, Peter Kretschmer", "title": "Quant GANs: Deep Generation of Financial Time Series", "comments": "Corrected typos. Added section 2 as an overview of existing\n  literature. Added section 5.3 to clarify the modeling assumptions. Appendix B\n  now contains more details on the neural network architectures used. Changed\n  latex template", "journal-ref": "Quantitative Finance, 2020", "doi": "10.1080/14697688.2020.1730426", "report-no": null, "categories": "q-fin.MF cs.LG q-fin.CP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modeling financial time series by stochastic processes is a challenging task\nand a central area of research in financial mathematics. As an alternative, we\nintroduce Quant GANs, a data-driven model which is inspired by the recent\nsuccess of generative adversarial networks (GANs). Quant GANs consist of a\ngenerator and discriminator function, which utilize temporal convolutional\nnetworks (TCNs) and thereby achieve to capture long-range dependencies such as\nthe presence of volatility clusters. The generator function is explicitly\nconstructed such that the induced stochastic process allows a transition to its\nrisk-neutral distribution. Our numerical results highlight that distributional\nproperties for small and large lags are in an excellent agreement and\ndependence properties such as volatility clusters, leverage effects, and serial\nautocorrelations can be generated by the generator function of Quant GANs,\ndemonstrably in high fidelity.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jul 2019 18:08:43 GMT"}, {"version": "v2", "created": "Sat, 21 Dec 2019 10:59:00 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Wiese", "Magnus", ""], ["Knobloch", "Robert", ""], ["Korn", "Ralf", ""], ["Kretschmer", "Peter", ""]]}, {"id": "1907.06679", "submitter": "Falcon Dai", "authors": "Falcon Z. Dai, Zheng Cai", "title": "Towards Near-imperceptible Steganographic Text", "comments": "To appear at ACL 2019. Code available", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that the imperceptibility of several existing linguistic\nsteganographic systems (Fang et al., 2017; Yang et al., 2018) relies on\nimplicit assumptions on statistical behaviors of fluent text. We formally\nanalyze them and empirically evaluate these assumptions. Furthermore, based on\nthese observations, we propose an encoding algorithm called patient-Huffman\nwith improved near-imperceptible guarantees.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jul 2019 18:17:13 GMT"}, {"version": "v2", "created": "Mon, 29 Jul 2019 22:28:16 GMT"}], "update_date": "2019-07-31", "authors_parsed": [["Dai", "Falcon Z.", ""], ["Cai", "Zheng", ""]]}, {"id": "1907.06690", "submitter": "Haruna Isah", "authors": "Shihao Ge, Haruna Isah, Farhana Zulkernine and Shahzad Khan", "title": "A Scalable Framework for Multilevel Streaming Data Analytics using Deep\n  Learning", "comments": null, "journal-ref": null, "doi": "10.1109/COMPSAC.2019.10205", "report-no": null, "categories": "eess.SY cs.LG cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The rapid growth of data in velocity, volume, value, variety, and veracity\nhas enabled exciting new opportunities and presented big challenges for\nbusinesses of all types. Recently, there has been considerable interest in\ndeveloping systems for processing continuous data streams with the increasing\nneed for real-time analytics for decision support in the business, healthcare,\nmanufacturing, and security. The analytics of streaming data usually relies on\nthe output of offline analytics on static or archived data. However, businesses\nand organizations like our industry partner Gnowit, strive to provide their\ncustomers with real time market information and continuously look for a unified\nanalytics framework that can integrate both streaming and offline analytics in\na seamless fashion to extract knowledge from large volumes of hybrid streaming\ndata. We present our study on designing a multilevel streaming text data\nanalytics framework by comparing leading edge scalable open-source,\ndistributed, and in-memory technologies. We demonstrate the functionality of\nthe framework for a use case of multilevel text analytics using deep learning\nfor language understanding and sentiment analysis including data indexing and\nquery processing. Our framework combines Spark streaming for real time text\nprocessing, the Long Short Term Memory (LSTM) deep learning model for higher\nlevel sentiment analysis, and other tools for SQL-based analytical processing\nto provide a scalable solution for multilevel streaming text analytics.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jul 2019 18:44:20 GMT"}], "update_date": "2019-07-23", "authors_parsed": [["Ge", "Shihao", ""], ["Isah", "Haruna", ""], ["Zulkernine", "Farhana", ""], ["Khan", "Shahzad", ""]]}, {"id": "1907.06698", "submitter": "Terence Parr", "authors": "Terence Parr and James D. Wilson", "title": "Technical Report: Partial Dependence through Stratification", "comments": "Tweaks/clarifications, added ntrials optional hyper parameter,\n  corrected interpretation of Integrated Gradients technique. For code, see\n  repo https://github.com/parrt/stratx", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Partial dependence curves (FPD) introduced by Friedman, are an important\nmodel interpretation tool, but are often not accessible to business analysts\nand scientists who typically lack the skills to choose, tune, and assess\nmachine learning models. It is also common for the same partial dependence\nalgorithm on the same data to give meaningfully different curves for different\nmodels, which calls into question their precision. Expertise is required to\ndistinguish between model artifacts and true relationships in the data.\n  In this paper, we contribute methods for computing partial dependence curves,\nfor both numerical (StratPD) and categorical explanatory variables\n(CatStratPD), that work directly from training data rather than predictions of\na model. Our methods provide a direct estimate of partial dependence, and rely\non approximating the partial derivative of an unknown regression function\nwithout first fitting a model and then approximating its partial derivative. We\ninvestigate settings where contemporary partial dependence methods---including\nFPD, ALE, and SHAP methods---give biased results. Furthermore, we demonstrate\nthat our approach works correctly on synthetic and plausibly on real data sets.\nOur goal is not to argue that model-based techniques are not useful. Rather, we\nhope to open a new line of inquiry into nonparametric partial dependence.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jul 2019 19:04:42 GMT"}, {"version": "v2", "created": "Thu, 19 Sep 2019 17:22:36 GMT"}, {"version": "v3", "created": "Mon, 13 Apr 2020 17:00:10 GMT"}, {"version": "v4", "created": "Fri, 24 Apr 2020 21:31:34 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Parr", "Terence", ""], ["Wilson", "James D.", ""]]}, {"id": "1907.06704", "submitter": "Joe Booth", "authors": "Joe Booth", "title": "PPO Dash: Improving Generalization in Deep Reinforcement Learning", "comments": "8 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning is prone to overfitting, and traditional\nbenchmarks such as Atari 2600 benchmark can exacerbate this problem. The\nObstacle Tower Challenge addresses this by using randomized environments and\nseparate seeds for training, validation, and test runs. This paper examines\nvarious improvements and best practices to the PPO algorithm using the Obstacle\nTower Challenge to empirically study their impact with regards to\ngeneralization. Our experiments show that the combination provides\nstate-of-the-art performance on the Obstacle Tower Challenge.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jul 2019 19:15:17 GMT"}, {"version": "v2", "created": "Wed, 17 Jul 2019 07:17:42 GMT"}, {"version": "v3", "created": "Thu, 25 Jul 2019 22:50:02 GMT"}], "update_date": "2019-07-29", "authors_parsed": [["Booth", "Joe", ""]]}, {"id": "1907.06725", "submitter": "Sayanti Roy", "authors": "Sayanti Roy, Emily Kieson, Charles Abramson, Christopher Crick", "title": "Mutual Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, collaborative robots have begun to train humans to achieve complex\ntasks, and the mutual information exchange between them can lead to successful\nrobot-human collaborations. In this paper we demonstrate the application and\neffectiveness of a new approach called mutual reinforcement learning (MRL),\nwhere both humans and autonomous agents act as reinforcement learners in a\nskill transfer scenario over continuous communication and feedback. An\nautonomous agent initially acts as an instructor who can teach a novice human\nparticipant complex skills using the MRL strategy. While teaching skills in a\nphysical (block-building) ($n=34$) or simulated (Tetris) environment ($n=31$),\nthe expert tries to identify appropriate reward channels preferred by each\nindividual and adapts itself accordingly using an exploration-exploitation\nstrategy. These reward channel preferences can identify important behaviors of\nthe human participants, because they may well exercise the same behaviors in\nsimilar situations later. In this way, skill transfer takes place between an\nexpert system and a novice human operator. We divided the subject population\ninto three groups and observed the skill transfer phenomenon, analyzing it with\nSimpson\"s psychometric model. 5-point Likert scales were also used to identify\nthe cognitive models of the human participants. We obtained a shared cognitive\nmodel which not only improves human cognition but enhances the robot's\ncognitive strategy to understand the mental model of its human partners while\nbuilding a successful robot-human collaborative framework.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jul 2019 20:10:29 GMT"}, {"version": "v2", "created": "Wed, 7 Aug 2019 00:42:57 GMT"}, {"version": "v3", "created": "Fri, 20 Sep 2019 19:52:13 GMT"}], "update_date": "2019-09-24", "authors_parsed": [["Roy", "Sayanti", ""], ["Kieson", "Emily", ""], ["Abramson", "Charles", ""], ["Crick", "Christopher", ""]]}, {"id": "1907.06727", "submitter": "Aydogan Ozcan", "authors": "Tairan Liu, Zhensong Wei, Yair Rivenson, Kevin de Haan, Yibo Zhang,\n  Yichen Wu, Aydogan Ozcan", "title": "Deep learning-based color holographic microscopy", "comments": "25 pages, 8 Figures, 2 Tables", "journal-ref": "Journal of Biophotonics (2019)", "doi": "10.1002/jbio.201900107", "report-no": null, "categories": "eess.IV cs.CV cs.LG physics.optics", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We report a framework based on a generative adversarial network (GAN) that\nperforms high-fidelity color image reconstruction using a single hologram of a\nsample that is illuminated simultaneously by light at three different\nwavelengths. The trained network learns to eliminate missing-phase-related\nartifacts, and generates an accurate color transformation for the reconstructed\nimage. Our framework is experimentally demonstrated using lung and prostate\ntissue sections that are labeled with different histological stains. This\nframework is envisaged to be applicable to point-of-care histopathology, and\npresents a significant improvement in the throughput of coherent microscopy\nsystems given that only a single hologram of the specimen is required for\naccurate color imaging.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jul 2019 20:15:21 GMT"}], "update_date": "2019-07-17", "authors_parsed": [["Liu", "Tairan", ""], ["Wei", "Zhensong", ""], ["Rivenson", "Yair", ""], ["de Haan", "Kevin", ""], ["Zhang", "Yibo", ""], ["Wu", "Yichen", ""], ["Ozcan", "Aydogan", ""]]}, {"id": "1907.06732", "submitter": "Alejandro Molina", "authors": "Alejandro Molina, Patrick Schramowski, Kristian Kersting", "title": "Pad\\'e Activation Units: End-to-end Learning of Flexible Activation\n  Functions in Deep Networks", "comments": "17 Pages, 8 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The performance of deep network learning strongly depends on the choice of\nthe non-linear activation function associated with each neuron. However,\ndeciding on the best activation is non-trivial, and the choice depends on the\narchitecture, hyper-parameters, and even on the dataset. Typically these\nactivations are fixed by hand before training. Here, we demonstrate how to\neliminate the reliance on first picking fixed activation functions by using\nflexible parametric rational functions instead. The resulting Pad\\'e Activation\nUnits (PAUs) can both approximate common activation functions and also learn\nnew ones while providing compact representations. Our empirical evidence shows\nthat end-to-end learning deep networks with PAUs can increase the predictive\nperformance. Moreover, PAUs pave the way to approximations with provable\nrobustness. https://github.com/ml-research/pau\n", "versions": [{"version": "v1", "created": "Mon, 15 Jul 2019 20:24:22 GMT"}, {"version": "v2", "created": "Fri, 31 Jan 2020 10:05:39 GMT"}, {"version": "v3", "created": "Tue, 4 Feb 2020 11:25:30 GMT"}], "update_date": "2020-02-05", "authors_parsed": [["Molina", "Alejandro", ""], ["Schramowski", "Patrick", ""], ["Kersting", "Kristian", ""]]}, {"id": "1907.06745", "submitter": "Mayank Kejriwal", "authors": "Mayank Kejriwal and Peilin Zhou", "title": "Low-supervision urgency detection and transfer in short crisis messages", "comments": "8 pages, short version published in ASONAM 2019", "journal-ref": null, "doi": "10.1145/3341161.3342936", "report-no": null, "categories": "cs.CL cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humanitarian disasters have been on the rise in recent years due to the\neffects of climate change and socio-political situations such as the refugee\ncrisis. Technology can be used to best mobilize resources such as food and\nwater in the event of a natural disaster, by semi-automatically flagging tweets\nand short messages as indicating an urgent need. The problem is challenging not\njust because of the sparseness of data in the immediate aftermath of a\ndisaster, but because of the varying characteristics of disasters in developing\ncountries (making it difficult to train just one system) and the noise and\nquirks in social media. In this paper, we present a robust, low-supervision\nsocial media urgency system that adapts to arbitrary crises by leveraging both\nlabeled and unlabeled data in an ensemble setting. The system is also able to\nadapt to new crises where an unlabeled background corpus may not be available\nyet by utilizing a simple and effective transfer learning methodology.\nExperimentally, our transfer learning and low-supervision approaches are found\nto outperform viable baselines with high significance on myriad disaster\ndatasets.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jul 2019 20:43:53 GMT"}], "update_date": "2019-07-17", "authors_parsed": [["Kejriwal", "Mayank", ""], ["Zhou", "Peilin", ""]]}, {"id": "1907.06771", "submitter": "Ruben Becker", "authors": "Ruben Becker, Imane Hafnaoui, Michael E. Houle, Pan Li, Arthur Zimek", "title": "Subspace Determination through Local Intrinsic Dimensional\n  Decomposition: Theory and Experimentation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Axis-aligned subspace clustering generally entails searching through enormous\nnumbers of subspaces (feature combinations) and evaluation of cluster quality\nwithin each subspace. In this paper, we tackle the problem of identifying\nsubsets of features with the most significant contribution to the formation of\nthe local neighborhood surrounding a given data point. For each point, the\nrecently-proposed Local Intrinsic Dimension (LID) model is used in identifying\nthe axis directions along which features have the greatest local\ndiscriminability, or equivalently, the fewest number of components of LID that\ncapture the local complexity of the data. In this paper, we develop an\nestimator of LID along axis projections, and provide preliminary evidence that\nthis LID decomposition can indicate axis-aligned data subspaces that support\nthe formation of clusters.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jul 2019 22:13:00 GMT"}], "update_date": "2019-07-17", "authors_parsed": [["Becker", "Ruben", ""], ["Hafnaoui", "Imane", ""], ["Houle", "Michael E.", ""], ["Li", "Pan", ""], ["Zimek", "Arthur", ""]]}, {"id": "1907.06795", "submitter": "Mark Koren", "authors": "Mark Koren and Mykel Kochenderfer", "title": "Efficient Autonomy Validation in Simulation with Adaptive Stress Testing", "comments": "Submitted to IEEE ITSC 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO cs.SE cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  During the development of autonomous systems such as driverless cars, it is\nimportant to characterize the scenarios that are most likely to result in\nfailure. Adaptive Stress Testing (AST) provides a way to search for the\nmost-likely failure scenario as a Markov decision process (MDP). Our previous\nwork used a deep reinforcement learning (DRL) solver to identify likely failure\nscenarios. However, the solver's use of a feed-forward neural network with a\ndiscretized space of possible initial conditions poses two major problems.\nFirst, the system is not treated as a black box, in that it requires analyzing\nthe internal state of the system, which leads to considerable implementation\ncomplexities. Second, in order to simulate realistic settings, a new instance\nof the solver needs to be run for each initial condition. Running a new solver\nfor each initial condition not only significantly increases the computational\ncomplexity, but also disregards the underlying relationship between similar\ninitial conditions. We provide a solution to both problems by employing a\nrecurrent neural network that takes a set of initial conditions from a\ncontinuous space as input. This approach enables robust and efficient detection\nof failures because the solution generalizes across the entire space of initial\nconditions. By simulating an instance where an autonomous car drives while a\npedestrian is crossing a road, we demonstrate the solver is now capable of\nfinding solutions for problems that would have previously been intractable.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jul 2019 00:12:09 GMT"}], "update_date": "2019-07-17", "authors_parsed": [["Koren", "Mark", ""], ["Kochenderfer", "Mykel", ""]]}, {"id": "1907.06800", "submitter": "Bao Wang", "authors": "Bao Wang and Stanley J. Osher", "title": "Graph Interpolating Activation Improves Both Natural and Robust\n  Accuracies in Data-Efficient Deep Learning", "comments": "34 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA math.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Improving the accuracy and robustness of deep neural nets (DNNs) and adapting\nthem to small training data are primary tasks in deep learning research. In\nthis paper, we replace the output activation function of DNNs, typically the\ndata-agnostic softmax function, with a graph Laplacian-based high dimensional\ninterpolating function which, in the continuum limit, converges to the solution\nof a Laplace-Beltrami equation on a high dimensional manifold. Furthermore, we\npropose end-to-end training and testing algorithms for this new architecture.\nThe proposed DNN with graph interpolating activation integrates the advantages\nof both deep learning and manifold learning. Compared to the conventional DNNs\nwith the softmax function as output activation, the new framework demonstrates\nthe following major advantages: First, it is better applicable to\ndata-efficient learning in which we train high capacity DNNs without using a\nlarge number of training data. Second, it remarkably improves both natural\naccuracy on the clean images and robust accuracy on the adversarial images\ncrafted by both white-box and black-box adversarial attacks. Third, it is a\nnatural choice for semi-supervised learning. For reproducibility, the code is\navailable at \\url{https://github.com/BaoWangMath/DNN-DataDependentActivation}.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jul 2019 00:28:19 GMT"}], "update_date": "2019-07-17", "authors_parsed": [["Wang", "Bao", ""], ["Osher", "Stanley J.", ""]]}, {"id": "1907.06814", "submitter": "Yuxuan Du", "authors": "Yuxuan Du, Min-Hsiu Hsieh, Tongliang Liu, Dacheng Tao", "title": "A Quantum-inspired Algorithm for General Minimum Conical Hull Problems", "comments": null, "journal-ref": "Phys. Rev. Research 2, 033199 (2020)", "doi": "10.1103/PhysRevResearch.2.033199", "report-no": null, "categories": "cs.LG cs.CG cs.DS quant-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A wide range of fundamental machine learning tasks that are addressed by the\nmaximum a posteriori estimation can be reduced to a general minimum conical\nhull problem. The best-known solution to tackle general minimum conical hull\nproblems is the divide-and-conquer anchoring learning scheme (DCA), whose\nruntime complexity is polynomial in size. However, big data is pushing these\npolynomial algorithms to their performance limits. In this paper, we propose a\nsublinear classical algorithm to tackle general minimum conical hull problems\nwhen the input has stored in a sample-based low-overhead data structure. The\nalgorithm's runtime complexity is polynomial in the rank and polylogarithmic in\nsize. The proposed algorithm achieves the exponential speedup over DCA and,\ntherefore, provides advantages for high dimensional problems.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jul 2019 02:42:19 GMT"}], "update_date": "2020-08-12", "authors_parsed": [["Du", "Yuxuan", ""], ["Hsieh", "Min-Hsiu", ""], ["Liu", "Tongliang", ""], ["Tao", "Dacheng", ""]]}, {"id": "1907.06831", "submitter": "Fan Yang", "authors": "Fan Yang, Mengnan Du, Xia Hu", "title": "Evaluating Explanation Without Ground Truth in Interpretable Machine\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.HC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interpretable Machine Learning (IML) has become increasingly important in\nmany real-world applications, such as autonomous cars and medical diagnosis,\nwhere explanations are significantly preferred to help people better understand\nhow machine learning systems work and further enhance their trust towards\nsystems. However, due to the diversified scenarios and subjective nature of\nexplanations, we rarely have the ground truth for benchmark evaluation in IML\non the quality of generated explanations. Having a sense of explanation quality\nnot only matters for assessing system boundaries, but also helps to realize the\ntrue benefits to human users in practical settings. To benchmark the evaluation\nin IML, in this article, we rigorously define the problem of evaluating\nexplanations, and systematically review the existing efforts from\nstate-of-the-arts. Specifically, we summarize three general aspects of\nexplanation (i.e., generalizability, fidelity and persuasibility) with formal\ndefinitions, and respectively review the representative methodologies for each\nof them under different tasks. Further, a unified evaluation framework is\ndesigned according to the hierarchical needs from developers and end-users,\nwhich could be easily adopted for different scenarios in practice. In the end,\nopen problems are discussed, and several limitations of current evaluation\ntechniques are raised for future explorations.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jul 2019 04:25:39 GMT"}, {"version": "v2", "created": "Thu, 15 Aug 2019 21:13:50 GMT"}], "update_date": "2019-08-19", "authors_parsed": [["Yang", "Fan", ""], ["Du", "Mengnan", ""], ["Hu", "Xia", ""]]}, {"id": "1907.06835", "submitter": "Sung-Ho Bae", "authors": "Kang-Ho Lee, JoonHyun Jeong, and Sung-Ho Bae", "title": "An Inter-Layer Weight Prediction and Quantization for Deep Neural\n  Networks based on a Smoothly Varying Weight Hypothesis", "comments": "12 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to a resource-constrained environment, network compression has become an\nimportant part of deep neural networks research. In this paper, we propose a\nnew compression method, \\textit{Inter-Layer Weight Prediction} (ILWP) and\nquantization method which quantize the predicted residuals between the weights\nin all convolution layers based on an inter-frame prediction method in\nconventional video coding schemes. Furthermore, we found a phenomenon\n\\textit{Smoothly Varying Weight Hypothesis} (SVWH) which is that the weights in\nadjacent convolution layers share strong similarity in shapes and values, i.e.,\nthe weights tend to vary smoothly along with the layers. Based on SVWH, we\npropose a second ILWP and quantization method which quantize the predicted\nresiduals between the weights in adjacent convolution layers. Since the\npredicted weight residuals tend to follow Laplace distributions with very low\nvariance, the weight quantization can more effectively be applied, thus\nproducing more zero weights and enhancing the weight compression ratio. In\naddition, we propose a new \\textit{inter-layer loss} for eliminating\nnon-texture bits, which enabled us to more effectively store only texture bits.\nThat is, the proposed loss regularizes the weights such that the collocated\nweights between the adjacent two layers have the same values. Finally, we\npropose an ILWP with an inter-layer loss and quantization method. Our\ncomprehensive experiments show that the proposed method achieves a much higher\nweight compression rate at the same accuracy level compared with the previous\nquantization-based compression methods in deep neural networks.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jul 2019 04:44:59 GMT"}, {"version": "v2", "created": "Thu, 20 Aug 2020 02:32:12 GMT"}], "update_date": "2020-08-21", "authors_parsed": [["Lee", "Kang-Ho", ""], ["Jeong", "JoonHyun", ""], ["Bae", "Sung-Ho", ""]]}, {"id": "1907.06837", "submitter": "Shalini Pandey", "authors": "Shalini Pandey, George Karypis", "title": "A Self-Attentive model for Knowledge Tracing", "comments": "International Conference on Education Data Mining", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge tracing is the task of modeling each student's mastery of knowledge\nconcepts (KCs) as (s)he engages with a sequence of learning activities. Each\nstudent's knowledge is modeled by estimating the performance of the student on\nthe learning activities. It is an important research area for providing a\npersonalized learning platform to students. In recent years, methods based on\nRecurrent Neural Networks (RNN) such as Deep Knowledge Tracing (DKT) and\nDynamic Key-Value Memory Network (DKVMN) outperformed all the traditional\nmethods because of their ability to capture complex representation of human\nlearning. However, these methods face the issue of not generalizing well while\ndealing with sparse data which is the case with real-world data as students\ninteract with few KCs. In order to address this issue, we develop an approach\nthat identifies the KCs from the student's past activities that are\n\\textit{relevant} to the given KC and predicts his/her mastery based on the\nrelatively few KCs that it picked. Since predictions are made based on\nrelatively few past activities, it handles the data sparsity problem better\nthan the methods based on RNN. For identifying the relevance between the KCs,\nwe propose a self-attention based approach, Self Attentive Knowledge Tracing\n(SAKT). Extensive experimentation on a variety of real-world dataset shows that\nour model outperforms the state-of-the-art models for knowledge tracing,\nimproving AUC by 4.43% on average.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jul 2019 04:47:35 GMT"}], "update_date": "2019-07-17", "authors_parsed": [["Pandey", "Shalini", ""], ["Karypis", "George", ""]]}, {"id": "1907.06838", "submitter": "Tianqi Wang", "authors": "Tianqi Wang, Dong Eui Chang", "title": "Improved Reinforcement Learning through Imitation Learning Pretraining\n  Towards Image-based Autonomous Driving", "comments": "5 pages, 2019 19th International Conference on Control, Automation\n  and Systems (ICCAS 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a training pipeline for the autonomous driving task given the\ncurrent camera image and vehicle speed as the input to produce the throttle,\nbrake, and steering control output. The simulator Airsim's convenient weather\nand lighting API provides a sufficient diversity during training which can be\nvery helpful to increase the trained policy's robustness. In order to not limit\nthe possible policy's performance, we use a continuous and deterministic\ncontrol policy setting. We utilize ResNet-34 as our actor and critic networks\nwith some slight changes in the fully connected layers. Considering human's\nmastery of this task and the high-complexity nature of this task, we first use\nimitation learning to mimic the given human policy and leverage the trained\npolicy and its weights to the reinforcement learning phase for which we use\nDDPG. This combination shows a considerable performance boost comparing to both\npure imitation learning and pure DDPG for the autonomous driving task.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jul 2019 04:48:52 GMT"}], "update_date": "2019-07-17", "authors_parsed": [["Wang", "Tianqi", ""], ["Chang", "Dong Eui", ""]]}, {"id": "1907.06840", "submitter": "Kamil Khadiev", "authors": "Kamil Khadiev, Ilnaz Mannapov and Liliya Safina", "title": "The Quantum Version Of Classification Decision Tree Constructing\n  Algorithm C5.0", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG quant-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the paper, we focus on complexity of C5.0 algorithm for constructing\ndecision tree classifier that is the models for the classification problem from\nmachine learning. In classical case the decision tree is constructed in\n$O(hd(NM+N \\log N))$ running time, where $M$ is a number of classes, $N$ is the\nsize of a training data set, $d$ is a number of attributes of each element, $h$\nis a tree height. Firstly, we improved the classical version, the running time\nof the new version is $O(h\\cdot d\\cdot N\\log N)$. Secondly, we suggest a\nquantum version of this algorithm, which uses quantum subroutines like the\namplitude amplification and the D{\\\"u}rr-H{\\o}yer minimum search algorithms\nthat are based on Grover's algorithm. The running time of the quantum algorithm\nis $O\\big(h\\cdot \\sqrt{d}\\log d \\cdot N \\log N\\big)$ that is better than\ncomplexity of the classical algorithm.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jul 2019 04:53:48 GMT"}], "update_date": "2019-07-17", "authors_parsed": [["Khadiev", "Kamil", ""], ["Mannapov", "Ilnaz", ""], ["Safina", "Liliya", ""]]}, {"id": "1907.06845", "submitter": "Gabriel Loaiza-Ganem", "authors": "Gabriel Loaiza-Ganem, John P. Cunningham", "title": "The continuous Bernoulli: fixing a pervasive error in variational\n  autoencoders", "comments": "Accepted at NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variational autoencoders (VAE) have quickly become a central tool in machine\nlearning, applicable to a broad range of data types and latent variable models.\nBy far the most common first step, taken by seminal papers and by core software\nlibraries alike, is to model MNIST data using a deep network parameterizing a\nBernoulli likelihood. This practice contains what appears to be and what is\noften set aside as a minor inconvenience: the pixel data is [0,1] valued, not\n{0,1} as supported by the Bernoulli likelihood. Here we show that, far from\nbeing a triviality or nuisance that is convenient to ignore, this error has\nprofound importance to VAE, both qualitative and quantitative. We introduce and\nfully characterize a new [0,1]-supported, single parameter distribution: the\ncontinuous Bernoulli, which patches this pervasive bug in VAE. This\ndistribution is not nitpicking; it produces meaningful performance improvements\nacross a range of metrics and datasets, including sharper image samples, and\nsuggests a broader class of performant VAE.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jul 2019 05:11:46 GMT"}, {"version": "v2", "created": "Tue, 23 Jul 2019 04:45:07 GMT"}, {"version": "v3", "created": "Fri, 27 Sep 2019 19:59:42 GMT"}, {"version": "v4", "created": "Wed, 2 Oct 2019 00:11:02 GMT"}, {"version": "v5", "created": "Sun, 29 Dec 2019 23:44:06 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Loaiza-Ganem", "Gabriel", ""], ["Cunningham", "John P.", ""]]}, {"id": "1907.06870", "submitter": "Zhenhui Xu", "authors": "Zhenhui Xu, Guolin Ke, Jia Zhang, Jiang Bian, Tie-Yan Liu", "title": "Light Multi-segment Activation for Model Compression", "comments": null, "journal-ref": "Thirty-Fourth AAAI Conference on Artificial Intelligence. 2020", "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model compression has become necessary when applying neural networks (NN)\ninto many real application tasks that can accept slightly-reduced model\naccuracy with strict tolerance to model complexity. Recently, Knowledge\nDistillation, which distills the knowledge from well-trained and highly complex\nteacher model into a compact student model, has been widely used for model\ncompression. However, under the strict requirement on the resource cost, it is\nquite challenging to achieve comparable performance with the teacher model,\nessentially due to the drastically-reduced expressiveness ability of the\ncompact student model. Inspired by the nature of the expressiveness ability in\nNeural Networks, we propose to use multi-segment activation, which can\nsignificantly improve the expressiveness ability with very little cost, in the\ncompact student model. Specifically, we propose a highly efficient\nmulti-segment activation, called Light Multi-segment Activation (LMA), which\ncan rapidly produce multiple linear regions with very few parameters by\nleveraging the statistical information. With using LMA, the compact student\nmodel is capable of achieving much better performance effectively and\nefficiently, than the ReLU-equipped one with same model scale. Furthermore, the\nproposed method is compatible with other model compression techniques, such as\nquantization, which means they can be used jointly for better compression\nperformance. Experiments on state-of-the-art NN architectures over the\nreal-world tasks demonstrate the effectiveness and extensibility of the LMA.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jul 2019 07:29:03 GMT"}, {"version": "v2", "created": "Mon, 25 Nov 2019 06:35:17 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Xu", "Zhenhui", ""], ["Ke", "Guolin", ""], ["Zhang", "Jia", ""], ["Bian", "Jiang", ""], ["Liu", "Tie-Yan", ""]]}, {"id": "1907.06901", "submitter": "Pankaj Malhotra", "authors": "Vishnu TV, Pankaj Malhotra, Jyoti Narwariya, Lovekesh Vig, Gautam\n  Shroff", "title": "Meta-Learning for Black-box Optimization", "comments": "Accepted at ECML-PKDD 2019 Research Track", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, neural networks trained as optimizers under the \"learning to learn\"\nor meta-learning framework have been shown to be effective for a broad range of\noptimization tasks including derivative-free black-box function optimization.\nRecurrent neural networks (RNNs) trained to optimize a diverse set of synthetic\nnon-convex differentiable functions via gradient descent have been effective at\noptimizing derivative-free black-box functions. In this work, we propose\nRNN-Opt: an approach for learning RNN-based optimizers for optimizing\nreal-parameter single-objective continuous functions under limited budget\nconstraints. Existing approaches utilize an observed improvement based\nmeta-learning loss function for training such models. We propose training\nRNN-Opt by using synthetic non-convex functions with known (approximate)\noptimal values by directly using discounted regret as our meta-learning loss\nfunction. We hypothesize that a regret-based loss function mimics typical\ntesting scenarios, and would therefore lead to better optimizers compared to\noptimizers trained only to propose queries that improve over previous queries.\nFurther, RNN-Opt incorporates simple yet effective enhancements during training\nand inference procedures to deal with the following practical challenges: i)\nUnknown range of possible values for the black-box function to be optimized,\nand ii) Practical and domain-knowledge based constraints on the input\nparameters. We demonstrate the efficacy of RNN-Opt in comparison to existing\nmethods on several synthetic as well as standard benchmark black-box functions\nalong with an anonymized industrial constrained optimization problem.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jul 2019 09:10:50 GMT"}, {"version": "v2", "created": "Wed, 2 Oct 2019 06:25:39 GMT"}], "update_date": "2019-10-03", "authors_parsed": [["TV", "Vishnu", ""], ["Malhotra", "Pankaj", ""], ["Narwariya", "Jyoti", ""], ["Vig", "Lovekesh", ""], ["Shroff", "Gautam", ""]]}, {"id": "1907.06902", "submitter": "Maurizio Ferrari Dacrema", "authors": "Maurizio Ferrari Dacrema, Paolo Cremonesi and Dietmar Jannach", "title": "Are We Really Making Much Progress? A Worrying Analysis of Recent Neural\n  Recommendation Approaches", "comments": "Source code available at:\n  https://github.com/MaurizioFD/RecSys2019_DeepLearning_Evaluation", "journal-ref": "Proceedings of the 13th ACM Conference on Recommender Systems\n  (RecSys 2019)", "doi": "10.1145/3298689.3347058", "report-no": null, "categories": "cs.IR cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning techniques have become the method of choice for researchers\nworking on algorithmic aspects of recommender systems. With the strongly\nincreased interest in machine learning in general, it has, as a result, become\ndifficult to keep track of what represents the state-of-the-art at the moment,\ne.g., for top-n recommendation tasks. At the same time, several recent\npublications point out problems in today's research practice in applied machine\nlearning, e.g., in terms of the reproducibility of the results or the choice of\nthe baselines when proposing new models. In this work, we report the results of\na systematic analysis of algorithmic proposals for top-n recommendation tasks.\nSpecifically, we considered 18 algorithms that were presented at top-level\nresearch conferences in the last years. Only 7 of them could be reproduced with\nreasonable effort. For these methods, it however turned out that 6 of them can\noften be outperformed with comparably simple heuristic methods, e.g., based on\nnearest-neighbor or graph-based techniques. The remaining one clearly\noutperformed the baselines but did not consistently outperform a well-tuned\nnon-neural linear ranking method. Overall, our work sheds light on a number of\npotential problems in today's machine learning scholarship and calls for\nimproved scientific practices in this area. Source code of our experiments and\nfull results are available at:\nhttps://github.com/MaurizioFD/RecSys2019_DeepLearning_Evaluation.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jul 2019 09:11:07 GMT"}, {"version": "v2", "created": "Mon, 29 Jul 2019 09:44:36 GMT"}, {"version": "v3", "created": "Fri, 16 Aug 2019 18:20:03 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Dacrema", "Maurizio Ferrari", ""], ["Cremonesi", "Paolo", ""], ["Jannach", "Dietmar", ""]]}, {"id": "1907.06916", "submitter": "Mark McDonnell", "authors": "Mark D. McDonnell, Hesham Mostafa, Runchun Wang and Andre van Schaik", "title": "Single-bit-per-weight deep convolutional neural networks without\n  batch-normalization layers for embedded systems", "comments": "8 pages, published IEEE conference paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Batch-normalization (BN) layers are thought to be an integrally important\nlayer type in today's state-of-the-art deep convolutional neural networks for\ncomputer vision tasks such as classification and detection. However, BN layers\nintroduce complexity and computational overheads that are highly undesirable\nfor training and/or inference on low-power custom hardware implementations of\nreal-time embedded vision systems such as UAVs, robots and Internet of Things\n(IoT) devices. They are also problematic when batch sizes need to be very small\nduring training, and innovations such as residual connections introduced more\nrecently than BN layers could potentially have lessened their impact. In this\npaper we aim to quantify the benefits BN layers offer in image classification\nnetworks, in comparison with alternative choices. In particular, we study\nnetworks that use shifted-ReLU layers instead of BN layers. We found, following\nexperiments with wide residual networks applied to the ImageNet, CIFAR 10 and\nCIFAR 100 image classification datasets, that BN layers do not consistently\noffer a significant advantage. We found that the accuracy margin offered by BN\nlayers depends on the data set, the network size, and the bit-depth of weights.\nWe conclude that in situations where BN layers are undesirable due to speed,\nmemory or complexity costs, that using shifted-ReLU layers instead should be\nconsidered; we found they can offer advantages in all these areas, and often do\nnot impose a significant accuracy cost.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jul 2019 09:42:02 GMT"}, {"version": "v2", "created": "Mon, 22 Jul 2019 13:04:27 GMT"}], "update_date": "2019-07-23", "authors_parsed": [["McDonnell", "Mark D.", ""], ["Mostafa", "Hesham", ""], ["Wang", "Runchun", ""], ["van Schaik", "Andre", ""]]}, {"id": "1907.06923", "submitter": "Hyenkyun Woo", "authors": "Hyenkyun Woo", "title": "The Bregman-Tweedie Classification Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work proposes the Bregman-Tweedie classification model and analyzes the\ndomain structure of the extended exponential function, an extension of the\nclassic generalized exponential function with additional scaling parameter, and\nrelated high-level mathematical structures, such as the Bregman-Tweedie loss\nfunction and the Bregman-Tweedie divergence. The base function of this\ndivergence is the convex function of Legendre type induced from the extended\nexponential function. The Bregman-Tweedie loss function of the proposed\nclassification model is the regular Legendre transformation of the\nBregman-Tweedie divergence. This loss function is a polynomial parameterized\nfunction between unhinge loss and the logistic loss function. Actually, we have\ntwo sub-models of the Bregman-Tweedie classification model; H-Bregman with\nhinge-like loss function and L-Bregman with logistic-like loss function.\nAlthough the proposed classification model is nonconvex and unbounded,\nempirically, we have observed that the H-Bregman and L-Bregman outperform, in\nterms of the Friedman ranking, logistic regression and SVM and show reasonable\nperformance in terms of the classification accuracy in the category of the\nbinary linear classification problem.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jul 2019 09:59:09 GMT"}], "update_date": "2019-07-17", "authors_parsed": [["Woo", "Hyenkyun", ""]]}, {"id": "1907.06943", "submitter": "John M. O' Toole", "authors": "John M. O'Toole and Geraldine B. Boylan", "title": "Machine learning without a feature set for detecting bursts in the EEG\n  of preterm infants", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG physics.med-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks enable learning directly on the data without the domain\nknowledge needed to construct a feature set. This approach has been extremely\nsuccessful in almost all machine learning applications. We propose a new\nframework that also learns directly from the data, without extracting a feature\nset. We apply this framework to detecting bursts in the EEG of premature\ninfants. The EEG is recorded within days of birth in a cohort of infants\nwithout significant brain injury and born <30 weeks of gestation. The method\nfirst transforms the time-domain signal to the time--frequency domain and then\ntrains a machine learning method, a gradient boosting machine, on each\ntime-slice of the time--frequency distribution. We control for oversampling the\ntime--frequency distribution with a significant reduction (<1%) in memory and\ncomputational complexity. The proposed method achieves similar accuracy to an\nexisting multi-feature approach: area under the characteristic curve of 0.98\n(with 95% confidence interval of 0.96 to 0.99), with a median sensitivity of\n95% and median specificity of 94%. The proposed framework presents an accurate,\nsimple, and computational efficient implementation as an alternative to both\nthe deep learning approach and to the manual generation of a feature set.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jul 2019 11:27:47 GMT"}], "update_date": "2019-07-17", "authors_parsed": [["O'Toole", "John M.", ""], ["Boylan", "Geraldine B.", ""]]}, {"id": "1907.06949", "submitter": "Guangxi Li", "authors": "Guangxi Li, Youle Wang, Yu Luo, Yuan Feng", "title": "Quantum Data Fitting Algorithm for Non-sparse Matrices", "comments": "5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a quantum data fitting algorithm for non-sparse matrices, which is\nbased on the Quantum Singular Value Estimation (QSVE) subroutine and a novel\nefficient method for recovering the signs of eigenvalues. Our algorithm\ngeneralizes the quantum data fitting algorithm of Wiebe, Braun, and Lloyd for\nsparse and well-conditioned matrices by adding a regularization term to avoid\nthe over-fitting problem, which is a very important problem in machine\nlearning. As a result, the algorithm achieves a sparsity-independent runtime of\n$O(\\kappa^2\\sqrt{N}\\mathrm{polylog}(N)/(\\epsilon\\log\\kappa))$ for an $N\\times\nN$ dimensional Hermitian matrix $\\bm{F}$, where $\\kappa$ denotes the condition\nnumber of $\\bm{F}$ and $\\epsilon$ is the precision parameter. This amounts to a\npolynomial speedup on the dimension of matrices when compared with the\nclassical data fitting algorithms, and a strictly less than quadratic\ndependence on $\\kappa$.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jul 2019 11:50:31 GMT"}], "update_date": "2019-07-17", "authors_parsed": [["Li", "Guangxi", ""], ["Wang", "Youle", ""], ["Luo", "Yu", ""], ["Feng", "Yuan", ""]]}, {"id": "1907.06955", "submitter": "Thomas Kurmann", "authors": "Thomas Kurmann and Pablo M\\'arquez-Neila and Siqing Yu and Marion Munk\n  and Sebastian Wolf and Raphael Sznitman", "title": "Fused Detection of Retinal Biomarkers in OCT Volumes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optical Coherence Tomography (OCT) is the primary imaging modality for\ndetecting pathological biomarkers associated to retinal diseases such as\nAge-Related Macular Degeneration. In practice, clinical diagnosis and treatment\nstrategies are closely linked to biomarkers visible in OCT volumes and the\nability to identify these plays an important role in the development of\nophthalmic pharmaceutical products. In this context, we present a method that\nautomatically predicts the presence of biomarkers in OCT cross-sections by\nincorporating information from the entire volume. We do so by adding a\nbidirectional LSTM to fuse the outputs of a Convolutional Neural Network that\npredicts individual biomarkers. We thus avoid the need to use pixel-wise\nannotations to train our method, and instead provide fine-grained biomarker\ninformation regardless. On a dataset of 416 volumes, we show that our approach\nimposes coherence between biomarker predictions across volume slices and our\npredictions are superior to several existing approaches.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jul 2019 12:12:57 GMT"}], "update_date": "2019-07-17", "authors_parsed": [["Kurmann", "Thomas", ""], ["M\u00e1rquez-Neila", "Pablo", ""], ["Yu", "Siqing", ""], ["Munk", "Marion", ""], ["Wolf", "Sebastian", ""], ["Sznitman", "Raphael", ""]]}, {"id": "1907.06969", "submitter": "Dennis Rohde", "authors": "Stefan Meintrup, Alexander Munteanu, Dennis Rohde", "title": "Random Projections and Sampling Algorithms for Clustering of\n  High-Dimensional Polygonal Curves", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the $k$-median clustering problem for high-dimensional polygonal\ncurves with finite but unbounded number of vertices. We tackle the\ncomputational issue that arises from the high number of dimensions by defining\na Johnson-Lindenstrauss projection for polygonal curves. We analyze the\nresulting error in terms of the Fr\\'echet distance, which is a tractable and\nnatural dissimilarity measure for curves. Our clustering algorithms achieve\nsublinear dependency on the number of input curves via subsampling. Also, we\nshow that the Fr\\'echet distance can not be approximated within any factor of\nless than $\\sqrt{2}$ by probabilistically reducing the dependency on the number\nof vertices of the curves. As a consequence we provide a fast,\nCUDA-parallelized version of the Alt and Godau algorithm for computing the\nFr\\'echet distance and use it to evaluate our results empirically.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jul 2019 12:52:34 GMT"}, {"version": "v2", "created": "Fri, 25 Oct 2019 15:28:33 GMT"}, {"version": "v3", "created": "Mon, 24 Aug 2020 08:31:20 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Meintrup", "Stefan", ""], ["Munteanu", "Alexander", ""], ["Rohde", "Dennis", ""]]}, {"id": "1907.06994", "submitter": "Faicel Chamroukhi", "authors": "Bao Tuyen Huynh and Faicel Chamroukhi", "title": "Estimation and Feature Selection in Mixtures of Generalized Linear\n  Experts Models", "comments": "arXiv admin note: text overlap with arXiv:1810.12161", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.LG stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mixtures-of-Experts (MoE) are conditional mixture models that have shown\ntheir performance in modeling heterogeneity in data in many statistical\nlearning approaches for prediction, including regression and classification, as\nwell as for clustering. Their estimation in high-dimensional problems is still\nhowever challenging. We consider the problem of parameter estimation and\nfeature selection in MoE models with different generalized linear experts\nmodels, and propose a regularized maximum likelihood estimation that\nefficiently encourages sparse solutions for heterogeneous data with\nhigh-dimensional predictors. The developed proximal-Newton EM algorithm\nincludes proximal Newton-type procedures to update the model parameter by\nmonotonically maximizing the objective function and allows to perform efficient\nestimation and feature selection. An experimental study shows the good\nperformance of the algorithms in terms of recovering the actual sparse\nsolutions, parameter estimation, and clustering of heterogeneous regression\ndata, compared to the main state-of-the art competitors.\n", "versions": [{"version": "v1", "created": "Sun, 14 Jul 2019 10:58:31 GMT"}], "update_date": "2019-07-17", "authors_parsed": [["Huynh", "Bao Tuyen", ""], ["Chamroukhi", "Faicel", ""]]}, {"id": "1907.07001", "submitter": "Xiaowei Zhou", "authors": "Xiaowei Zhou, Ivor W. Tsang, Jie Yin", "title": "Latent Adversarial Defence with Boundary-guided Generation", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Neural Networks (DNNs) have recently achieved great success in many\ntasks, which encourages DNNs to be widely used as a machine learning service in\nmodel sharing scenarios. However, attackers can easily generate adversarial\nexamples with a small perturbation to fool the DNN models to predict wrong\nlabels. To improve the robustness of shared DNN models against adversarial\nattacks, we propose a novel method called Latent Adversarial Defence (LAD). The\nproposed LAD method improves the robustness of a DNN model through adversarial\ntraining on generated adversarial examples. Different from popular attack\nmethods which are carried in the input space and only generate adversarial\nexamples of repeating patterns, LAD generates myriad of adversarial examples\nthrough adding perturbations to latent features along the normal of the\ndecision boundary which is constructed by an SVM with an attention mechanism.\nOnce adversarial examples are generated, we adversarially train the model\nthrough augmenting the training data with generated adversarial examples.\nExtensive experiments on the MNIST, SVHN, and CelebA dataset demonstrate the\neffectiveness of our model in defending against different types of adversarial\nattacks.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jul 2019 13:49:43 GMT"}], "update_date": "2019-07-17", "authors_parsed": [["Zhou", "Xiaowei", ""], ["Tsang", "Ivor W.", ""], ["Yin", "Jie", ""]]}, {"id": "1907.07023", "submitter": "Panagiotis Meletis", "authors": "Panagiotis Meletis and Rob Romijnders and Gijs Dubbelman", "title": "Data Selection for training Semantic Segmentation CNNs with\n  cross-dataset weak supervision", "comments": "IEEE ITSC 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Training convolutional networks for semantic segmentation with strong\n(per-pixel) and weak (per-bounding-box) supervision requires a large amount of\nweakly labeled data. We propose two methods for selecting the most relevant\ndata with weak supervision. The first method is designed for finding visually\nsimilar images without the need of labels and is based on modeling image\nrepresentations with a Gaussian Mixture Model (GMM). As a byproduct of GMM\nmodeling, we present useful insights on characterizing the data generating\ndistribution. The second method aims at finding images with high object\ndiversity and requires only the bounding box labels. Both methods are developed\nin the context of automated driving and experimentation is conducted on\nCityscapes and Open Images datasets. We demonstrate performance gains by\nreducing the amount of employed weakly labeled images up to 100 times for Open\nImages and up to 20 times for Cityscapes.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jul 2019 14:17:06 GMT"}], "update_date": "2019-07-17", "authors_parsed": [["Meletis", "Panagiotis", ""], ["Romijnders", "Rob", ""], ["Dubbelman", "Gijs", ""]]}, {"id": "1907.07029", "submitter": "Rituraj Kaushik", "authors": "Rituraj Kaushik, Pierre Desreumaux, Jean-Baptiste Mouret", "title": "Adaptive Prior Selection for Repertoire-based Online Adaptation in\n  Robotics", "comments": "Frontiers in Robotics and AI. Vol. 6, p. 151, 2020. Video :\n  http://tiny.cc/aprol_video", "journal-ref": "Frontiers in Robotics and AI. 6 (2020) 151", "doi": "10.3389/frobt.2019.00151", "report-no": null, "categories": "cs.RO cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Repertoire-based learning is a data-efficient adaptation approach based on a\ntwo-step process in which (1) a large and diverse set of policies is learned in\nsimulation, and (2) a planning or learning algorithm chooses the most\nappropriate policies according to the current situation (e.g., a damaged robot,\na new object, etc.). In this paper, we relax the assumption of previous works\nthat a single repertoire is enough for adaptation. Instead, we generate\nrepertoires for many different situations (e.g., with a missing leg, on\ndifferent floors, etc.) and let our algorithm selects the most useful prior.\nOur main contribution is an algorithm, APROL (Adaptive Prior selection for\nRepertoire-based Online Learning) to plan the next action by incorporating\nthese priors when the robot has no information about the current situation. We\nevaluate APROL on two simulated tasks: (1) pushing unknown objects of various\nshapes and sizes with a robotic arm and (2) a goal reaching task with a damaged\nhexapod robot. We compare with \"Reset-free Trial and Error\" (RTE) and various\nsingle repertoire-based baselines. The results show that APROL solves both the\ntasks in less interaction time than the baselines. Additionally, we demonstrate\nAPROL on a real, damaged hexapod that quickly learns to pick compensatory\npolicies to reach a goal by avoiding obstacles in the path.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jul 2019 14:26:13 GMT"}, {"version": "v2", "created": "Thu, 24 Oct 2019 11:13:57 GMT"}, {"version": "v3", "created": "Tue, 3 Mar 2020 22:25:25 GMT"}], "update_date": "2020-03-05", "authors_parsed": [["Kaushik", "Rituraj", ""], ["Desreumaux", "Pierre", ""], ["Mouret", "Jean-Baptiste", ""]]}, {"id": "1907.07033", "submitter": "Sooji Han", "authors": "Sooji Han, Jie Gao, Fabio Ciravegna", "title": "Neural Language Model Based Training Data Augmentation for Weakly\n  Supervised Early Rumor Detection", "comments": "8 pages", "journal-ref": "The 2019 IEEE/ACM International Conference on Advances in Social\n  Networks Analysis and Mining", "doi": "10.1145/3341161.3342892", "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The scarcity and class imbalance of training data are known issues in current\nrumor detection tasks. We propose a straight-forward and general-purpose data\naugmentation technique which is beneficial to early rumor detection relying on\nevent propagation patterns. The key idea is to exploit massive unlabeled event\ndata sets on social media to augment limited labeled rumor source tweets. This\nwork is based on rumor spreading patterns revealed by recent rumor studies and\nsemantic relatedness between labeled and unlabeled data. A state-of-the-art\nneural language model (NLM) and large credibility-focused Twitter corpora are\nemployed to learn context-sensitive representations of rumor tweets. Six\ndifferent real-world events based on three publicly available rumor datasets\nare employed in our experiments to provide a comparative evaluation of the\neffectiveness of the method. The results show that our method can expand the\nsize of an existing rumor data set nearly by 200% and corresponding social\ncontext (i.e., conversational threads) by 100% with reasonable quality.\nPreliminary experiments with a state-of-the-art deep learning-based rumor\ndetection model show that augmented data can alleviate over-fitting and class\nimbalance caused by limited train data and can help to train complex neural\nnetworks (NNs). With augmented data, the performance of rumor detection can be\nimproved by 12.1% in terms of F-score. Our experiments also indicate that\naugmented training data can help to generalize rumor detection models on unseen\nrumors.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jul 2019 14:32:33 GMT"}], "update_date": "2019-07-17", "authors_parsed": [["Han", "Sooji", ""], ["Gao", "Jie", ""], ["Ciravegna", "Fabio", ""]]}, {"id": "1907.07035", "submitter": "Sebastian Curi", "authors": "Silvan Melchior, Sebastian Curi, Felix Berkenkamp, Andreas Krause", "title": "Structured Variational Inference in Unstable Gaussian Process State\n  Space Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new variational inference algorithm for learning in Gaussian\nProcess State-Space Models (GPSSMs). Our algorithm enables learning of unstable\nand partially observable systems, where previous algorithms fail. Our main\nalgorithmic contribution is a novel approximate posterior that can be\ncalculated efficiently using a single forward and backward pass along the\ntraining trajectories. The forward-backward pass is inspired on Kalman\nsmoothing for linear dynamical systems but generalizes to GPSSMs. Our second\ncontribution is a modification of the conditioning step that effectively lowers\nthe Kalman gain. This modification is crucial to attaining good test\nperformance where no measurements are available. Finally, we show\nexperimentally that our learning algorithm performs well in stable and unstable\nreal systems with hidden states.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jul 2019 14:34:47 GMT"}, {"version": "v2", "created": "Tue, 31 Mar 2020 12:11:49 GMT"}, {"version": "v3", "created": "Wed, 10 Jun 2020 07:06:25 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Melchior", "Silvan", ""], ["Curi", "Sebastian", ""], ["Berkenkamp", "Felix", ""], ["Krause", "Andreas", ""]]}, {"id": "1907.07045", "submitter": "Borna Bi\\'cani\\'c", "authors": "Borna Bi\\'cani\\'c, Marin Or\\v{s}i\\'c, Ivan Markovi\\'c, Sini\\v{s}a\n  \\v{S}egvi\\'c, Ivan Petrovi\\'c", "title": "Pedestrian Tracking by Probabilistic Data Association and Correspondence\n  Embeddings", "comments": null, "journal-ref": "22nd International Conference on Information Fusion (FUSION)\n  (2019)", "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies the interplay between kinematics (position and velocity)\nand appearance cues for establishing correspondences in multi-target pedestrian\ntracking. We investigate tracking-by-detection approaches based on a deep\nlearning detector, joint integrated probabilistic data association (JIPDA), and\nappearance-based tracking of deep correspondence embeddings. We first addressed\nthe fixed-camera setup by fine-tuning a convolutional detector for accurate\npedestrian detection and combining it with kinematic-only JIPDA. The resulting\nsubmission ranked first on the 3DMOT2015 benchmark. However, in sequences with\na moving camera and unknown ego-motion, we achieved the best results by\nreplacing kinematic cues with global nearest neighbor tracking of deep\ncorrespondence embeddings. We trained the embeddings by fine-tuning features\nfrom the second block of ResNet-18 using angular loss extended by a margin\nterm. We note that integrating deep correspondence embeddings directly in JIPDA\ndid not bring significant improvement. It appears that geometry of deep\ncorrespondence embeddings for soft data association needs further investigation\nin order to obtain the best from both worlds.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jul 2019 14:58:37 GMT"}], "update_date": "2019-07-17", "authors_parsed": [["Bi\u0107ani\u0107", "Borna", ""], ["Or\u0161i\u0107", "Marin", ""], ["Markovi\u0107", "Ivan", ""], ["\u0160egvi\u0107", "Sini\u0161a", ""], ["Petrovi\u0107", "Ivan", ""]]}, {"id": "1907.07063", "submitter": "Jarek Duda Dr", "authors": "Jarek Duda", "title": "SGD momentum optimizer with step estimation by online parabola model", "comments": "7 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In stochastic gradient descent, especially for neural network training, there\nare currently dominating first order methods: not modeling local distance to\nminimum. This information required for optimal step size is provided by second\norder methods, however, they have many difficulties, starting with full Hessian\nhaving square of dimension number of coefficients.\n  This article proposes a minimal step from successful first order momentum\nmethod toward second order: online parabola modelling in just a single\ndirection: normalized $\\hat{v}$ from momentum method. It is done by estimating\nlinear trend of gradients $\\vec{g}=\\nabla F(\\vec{\\theta})$ in $\\hat{v}$\ndirection: such that $g(\\vec{\\theta}_\\bot+\\theta\\hat{v})\\approx \\lambda (\\theta\n-p)$ for $\\theta = \\vec{\\theta}\\cdot \\hat{v}$, $g= \\vec{g}\\cdot \\hat{v}$,\n$\\vec{\\theta}_\\bot=\\vec{\\theta}-\\theta\\hat{v}$. Using linear regression,\n$\\lambda$, $p$ are MSE estimated by just updating four averages (of $g$,\n$\\theta$, $g\\theta$, $\\theta^2$) in the considered direction. Exponential\nmoving averages allow here for inexpensive online estimation, weakening\ncontribution of the old gradients. Controlling sign of curvature $\\lambda$, we\ncan repel from saddles in contrast to attraction in standard Newton method. In\nthe remaining directions: not considered in second order model, we can\nsimultaneously perform e.g. gradient descent.\n  There is also discussed its learning rate approximation as $\\mu=\\sigma_\\theta\n/ \\sigma_g$, allowing e.g. for adaptive SGD - with learning rate separately\noptimized (2nd order) for each parameter.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jul 2019 15:22:34 GMT"}, {"version": "v2", "created": "Mon, 2 Dec 2019 16:18:44 GMT"}, {"version": "v3", "created": "Mon, 9 Dec 2019 15:09:21 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["Duda", "Jarek", ""]]}, {"id": "1907.07066", "submitter": "Mario Graff", "authors": "Claudia N. S\\'anchez and Mario Graff", "title": "Selection Heuristics on Semantic Genetic Programming for Classification\n  Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Individual's semantics have been used for guiding the learning process of\nGenetic Programming solving supervised learning problems. The semantics has\nbeen used to proposed novel genetic operators as well as different ways of\nperforming parent selection. The latter is the focus of this contribution by\nproposing three heuristics for parent selection that replace the fitness\nfunction on the selection mechanism entirely. These heuristics complement\nprevious work by being inspired in the characteristics of the addition, Naive\nBayes, and Nearest Centroid functions and applying them only when the function\nis used to create an offspring. These heuristics use different similarity\nmeasures among the parents to decide which of them is more appropriate given a\nfunction. The similarity functions considered are the cosine similarity,\nPearson's correlation, and agreement. We analyze these heuristics' performance\nagainst random selection, state-of-the-art selection schemes, and 18\nclassifiers, including auto-machine-learning techniques, on 30 classification\nproblems with a variable number of samples, variables, and classes. The result\nindicated that the combination of parent selection based on agreement and\nrandom selection to replace an individual in the population produces\nstatistically better results than the classical selection and state-of-the-art\nschemes, and it is competitive with state-of-the-art classifiers. Finally, the\ncode is released as open-source software.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jul 2019 15:25:01 GMT"}, {"version": "v2", "created": "Tue, 24 Sep 2019 15:12:15 GMT"}, {"version": "v3", "created": "Tue, 2 Jun 2020 03:10:59 GMT"}, {"version": "v4", "created": "Fri, 2 Apr 2021 18:48:49 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["S\u00e1nchez", "Claudia N.", ""], ["Graff", "Mario", ""]]}, {"id": "1907.07103", "submitter": "Jean Barbier Dr.", "authors": "Jean Barbier", "title": "Concentration of the matrix-valued minimum mean-square error in optimal\n  Bayesian inference", "comments": "arXiv admin note: text overlap with arXiv:1904.02808", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG eess.SP math.IT math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider Bayesian inference of signals with vector-valued entries.\nExtending concentration techniques from the mathematical physics of spin\nglasses, we show that the matrix-valued minimum mean-square error concentrates\nwhen the size of the problem increases. Such results are often crucial for\nproving single-letter formulas for the mutual information when they exist. Our\nproof is valid in the optimal Bayesian inference setting, meaning that it\nrelies on the assumption that the model and all its hyper-parameters are known.\nExamples of inference and learning problems covered by our results are spiked\nmatrix and tensor models, the committee machine neural network with few hidden\nneurons in the teacher-student scenario, or multi-layers generalized linear\nmodels.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jul 2019 16:18:09 GMT"}], "update_date": "2019-07-17", "authors_parsed": [["Barbier", "Jean", ""]]}, {"id": "1907.07129", "submitter": "Kin Sum Liu", "authors": "Kin Sum Liu, Chien-Chun Ni, Yu-Yao Lin, Jie Gao", "title": "Topology Based Scalable Graph Kernels", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new graph kernel for graph classification and comparison using\nOllivier Ricci curvature. The Ricci curvature of an edge in a graph describes\nthe connectivity in the local neighborhood. An edge in a densely connected\nneighborhood has positive curvature and an edge serving as a local bridge has\nnegative curvature. We use the edge curvature distribution to form a graph\nkernel which is then used to compare and cluster graphs. The curvature kernel\nuses purely the graph topology and thereby works for settings when node\nattributes are not available.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jul 2019 00:23:17 GMT"}], "update_date": "2019-07-17", "authors_parsed": [["Liu", "Kin Sum", ""], ["Ni", "Chien-Chun", ""], ["Lin", "Yu-Yao", ""], ["Gao", "Jie", ""]]}, {"id": "1907.07131", "submitter": "Ying Da Wang", "authors": "Ying Da Wang, Ryan T. Armstrong, Peyman Mostaghimi", "title": "Boosting Resolution and Recovering Texture of micro-CT Images with Deep\n  Learning", "comments": "\\keywords{Digital Rock Imaging \\and Super Resolution \\and\n  Convolutional Neural Networks \\and Generative Adversarial Networks}", "journal-ref": null, "doi": "10.1029/2019WR026052", "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Digital Rock Imaging is constrained by detector hardware, and a trade-off\nbetween the image field of view (FOV) and the image resolution must be made.\nThis can be compensated for with super resolution (SR) techniques that take a\nwide FOV, low resolution (LR) image, and super resolve a high resolution (HR),\nhigh FOV image. The Enhanced Deep Super Resolution Generative Adversarial\nNetwork (EDSRGAN) is trained on the Deep Learning Digital Rock Super Resolution\nDataset, a diverse compilation 12000 of raw and processed uCT images. The\nnetwork shows comparable performance of 50% to 70% reduction in relative error\nover bicubic interpolation. GAN performance in recovering texture shows\nsuperior visual similarity compared to SRCNN and other methods. Difference maps\nindicate that the SRCNN section of the SRGAN network recovers large scale edge\n(grain boundaries) features while the GAN network regenerates perceptually\nindistinguishable high frequency texture. Network performance is generalised\nwith augmentation, showing high adaptability to noise and blur. HR images are\nfed into the network, generating HR-SR images to extrapolate network\nperformance to sub-resolution features present in the HR images themselves.\nResults show that under-resolution features such as dissolved minerals and thin\nfractures are regenerated despite the network operating outside of trained\nspecifications. Comparison with Scanning Electron Microscope images shows\ndetails are consistent with the underlying geometry of the sample. Recovery of\ntextures benefits the characterisation of digital rocks with a high proportion\nof under-resolution micro-porous features, such as carbonate and coal samples.\nImages that are normally constrained by the mineralogy of the rock (coal), by\nfast transient imaging (waterflooding), or by the energy of the source\n(microporosity), can be super resolved accurately for further analysis\ndownstream.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jul 2019 04:32:50 GMT"}, {"version": "v2", "created": "Wed, 17 Jul 2019 06:17:34 GMT"}, {"version": "v3", "created": "Sat, 27 Jul 2019 01:37:33 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Da Wang", "Ying", ""], ["Armstrong", "Ryan T.", ""], ["Mostaghimi", "Peyman", ""]]}, {"id": "1907.07148", "submitter": "Ping Li", "authors": "Martin Slawski, Emanuel Ben-David, Ping Li", "title": "A Two-Stage Approach to Multivariate Linear Regression with Sparsely\n  Mismatched Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IT cs.LG math.IT stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A tacit assumption in linear regression is that (response, predictor)-pairs\ncorrespond to identical observational units. A series of recent works have\nstudied scenarios in which this assumption is violated under terms such as\n``Unlabeled Sensing and ``Regression with Unknown Permutation''. In this paper,\nwe study the setup of multiple response variables and a notion of mismatches\nthat generalizes permutations in order to allow for missing matches as well as\nfor one-to-many matches. A two-stage method is proposed under the assumption\nthat most pairs are correctly matched. In the first stage, the regression\nparameter is estimated by handling mismatches as contaminations, and\nsubsequently the generalized permutation is estimated by a basic variant of\nmatching. The approach is both computationally convenient and equipped with\nfavorable statistical guarantees. Specifically, it is shown that the conditions\nfor permutation recovery become considerably less stringent as the number of\nresponses $m$ per observation increase. Particularly, for $m = \\Omega(\\log n)$,\nthe required signal-to-noise ratio no longer depends on the sample size $n$.\nNumerical results on synthetic and real data are presented to support the main\nfindings of our analysis.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jul 2019 17:12:19 GMT"}, {"version": "v2", "created": "Sun, 28 Jun 2020 15:28:13 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Slawski", "Martin", ""], ["Ben-David", "Emanuel", ""], ["Li", "Ping", ""]]}, {"id": "1907.07156", "submitter": "Dmitrii Marin", "authors": "Dmitrii Marin, Zijian He, Peter Vajda, Priyam Chatterjee, Sam Tsai,\n  Fei Yang, Yuri Boykov", "title": "Efficient Segmentation: Learning Downsampling Near Semantic Boundaries", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many automated processes such as auto-piloting rely on a good semantic\nsegmentation as a critical component. To speed up performance, it is common to\ndownsample the input frame. However, this comes at the cost of missed small\nobjects and reduced accuracy at semantic boundaries. To address this problem,\nwe propose a new content-adaptive downsampling technique that learns to favor\nsampling locations near semantic boundaries of target classes. Cost-performance\nanalysis shows that our method consistently outperforms the uniform sampling\nimproving balance between accuracy and computational efficiency. Our adaptive\nsampling gives segmentation with better quality of boundaries and more reliable\nsupport for smaller-size objects.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jul 2019 17:27:21 GMT"}], "update_date": "2019-07-17", "authors_parsed": [["Marin", "Dmitrii", ""], ["He", "Zijian", ""], ["Vajda", "Peter", ""], ["Chatterjee", "Priyam", ""], ["Tsai", "Sam", ""], ["Yang", "Fei", ""], ["Boykov", "Yuri", ""]]}, {"id": "1907.07157", "submitter": "Mengwei Yang", "authors": "Mengwei Yang, Linqi Song, Jie Xu, Congduan Li, Guozhen Tan", "title": "The Tradeoff Between Privacy and Accuracy in Anomaly Detection Using\n  Federated XGBoost", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Privacy has raised considerable concerns recently, especially with the advent\nof information explosion and numerous data mining techniques to explore the\ninformation inside large volumes of data. In this context, a new distributed\nlearning paradigm termed federated learning becomes prominent recently to\ntackle the privacy issues in distributed learning, where only learning models\nwill be transmitted from the distributed nodes to servers without revealing\nusers' own data and hence protecting the privacy of users.\n  In this paper, we propose a horizontal federated XGBoost algorithm to solve\nthe federated anomaly detection problem, where the anomaly detection aims to\nidentify abnormalities from extremely unbalanced datasets and can be considered\nas a special classification problem. Our proposed federated XGBoost algorithm\nincorporates data aggregation and sparse federated update processes to balance\nthe tradeoff between privacy and learning performance. In particular, we\nintroduce the virtual data sample by aggregating a group of users' data\ntogether at a single distributed node. We compute parameters based on these\nvirtual data samples in the local nodes and aggregate the learning model in the\ncentral server. In the learning model upgrading process, we focus more on the\nwrongly classified data before in the virtual sample and hence to generate\nsparse learning model parameters. By carefully controlling the size of these\ngroups of samples, we can achieve a tradeoff between privacy and learning\nperformance. Our experimental results show the effectiveness of our proposed\nscheme by comparing with existing state-of-the-arts.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jul 2019 17:30:42 GMT"}, {"version": "v2", "created": "Mon, 14 Oct 2019 13:22:57 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Yang", "Mengwei", ""], ["Song", "Linqi", ""], ["Xu", "Jie", ""], ["Li", "Congduan", ""], ["Tan", "Guozhen", ""]]}, {"id": "1907.07165", "submitter": "Yash Goyal", "authors": "Yash Goyal, Amir Feder, Uri Shalit, Been Kim", "title": "Explaining Classifiers with Causal Concept Effect (CaCE)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How can we understand classification decisions made by deep neural networks?\nMany existing explainability methods rely solely on correlations and fail to\naccount for confounding, which may result in potentially misleading\nexplanations. To overcome this problem, we define the Causal Concept Effect\n(CaCE) as the causal effect of (the presence or absence of) a\nhuman-interpretable concept on a deep neural net's predictions. We show that\nthe CaCE measure can avoid errors stemming from confounding. Estimating CaCE is\ndifficult in situations where we cannot easily simulate the do-operator. To\nmitigate this problem, we use a generative model, specifically a Variational\nAutoEncoder (VAE), to measure VAE-CaCE. In an extensive experimental analysis,\nwe show that the VAE-CaCE is able to estimate the true concept causal effect,\ncompared to baselines for a number of datasets including high dimensional\nimages.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jul 2019 17:47:43 GMT"}, {"version": "v2", "created": "Fri, 28 Feb 2020 18:56:14 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Goyal", "Yash", ""], ["Feder", "Amir", ""], ["Shalit", "Uri", ""], ["Kim", "Been", ""]]}, {"id": "1907.07167", "submitter": "Deeksha Adil", "authors": "Deeksha Adil, Richard Peng, Sushant Sachdeva", "title": "Fast, Provably convergent IRLS Algorithm for p-norm Linear Regression", "comments": "Code for this work is available at\n  https://github.com/utoronto-theory/pIRLS", "journal-ref": "In Advances in Neural Information Processing Systems (pp.\n  14166-14177) 2019", "doi": null, "report-no": null, "categories": "cs.DS cs.LG cs.NA math.NA math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Linear regression in $\\ell_p$-norm is a canonical optimization problem that\narises in several applications, including sparse recovery, semi-supervised\nlearning, and signal processing. Generic convex optimization algorithms for\nsolving $\\ell_p$-regression are slow in practice. Iteratively Reweighted Least\nSquares (IRLS) is an easy to implement family of algorithms for solving these\nproblems that has been studied for over 50 years. However, these algorithms\noften diverge for p > 3, and since the work of Osborne (1985), it has been an\nopen problem whether there is an IRLS algorithm that is guaranteed to converge\nrapidly for p > 3. We propose p-IRLS, the first IRLS algorithm that provably\nconverges geometrically for any $p \\in [2,\\infty).$ Our algorithm is simple to\nimplement and is guaranteed to find a $(1+\\varepsilon)$-approximate solution in\n$O(p^{3.5} m^{\\frac{p-2}{2(p-1)}} \\log \\frac{m}{\\varepsilon}) \\le O_p(\\sqrt{m}\n\\log \\frac{m}{\\varepsilon} )$ iterations. Our experiments demonstrate that it\nperforms even better than our theoretical bounds, beats the standard Matlab/CVX\nimplementation for solving these problems by 10--50x, and is the fastest among\navailable implementations in the high-accuracy regime.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jul 2019 17:50:45 GMT"}, {"version": "v2", "created": "Fri, 10 Jan 2020 09:31:08 GMT"}], "update_date": "2020-01-13", "authors_parsed": [["Adil", "Deeksha", ""], ["Peng", "Richard", ""], ["Sachdeva", "Sushant", ""]]}, {"id": "1907.07171", "submitter": "Lucy Chai", "authors": "Ali Jahanian, Lucy Chai, Phillip Isola", "title": "On the \"steerability\" of generative adversarial networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An open secret in contemporary machine learning is that many models work\nbeautifully on standard benchmarks but fail to generalize outside the lab. This\nhas been attributed to biased training data, which provide poor coverage over\nreal world events. Generative models are no exception, but recent advances in\ngenerative adversarial networks (GANs) suggest otherwise - these models can now\nsynthesize strikingly realistic and diverse images. Is generative modeling of\nphotos a solved problem? We show that although current GANs can fit standard\ndatasets very well, they still fall short of being comprehensive models of the\nvisual manifold. In particular, we study their ability to fit simple\ntransformations such as camera movements and color changes. We find that the\nmodels reflect the biases of the datasets on which they are trained (e.g.,\ncentered objects), but that they also exhibit some capacity for generalization:\nby \"steering\" in latent space, we can shift the distribution while still\ncreating realistic images. We hypothesize that the degree of distributional\nshift is related to the breadth of the training data distribution. Thus, we\nconduct experiments to quantify the limits of GAN transformations and introduce\ntechniques to mitigate the problem. Code is released on our project page:\nhttps://ali-design.github.io/gan_steerability/\n", "versions": [{"version": "v1", "created": "Tue, 16 Jul 2019 17:55:07 GMT"}, {"version": "v2", "created": "Wed, 30 Oct 2019 21:28:26 GMT"}, {"version": "v3", "created": "Fri, 14 Feb 2020 05:45:54 GMT"}, {"version": "v4", "created": "Mon, 17 Feb 2020 01:13:18 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Jahanian", "Ali", ""], ["Chai", "Lucy", ""], ["Isola", "Phillip", ""]]}, {"id": "1907.07174", "submitter": "Dan Hendrycks", "authors": "Dan Hendrycks, Kevin Zhao, Steven Basart, Jacob Steinhardt, Dawn Song", "title": "Natural Adversarial Examples", "comments": "CVPR 2021; dataset and code available at\n  https://github.com/hendrycks/natural-adv-examples", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce two challenging datasets that reliably cause machine learning\nmodel performance to substantially degrade. The datasets are collected with a\nsimple adversarial filtration technique to create datasets with limited\nspurious cues. Our datasets' real-world, unmodified examples transfer to\nvarious unseen models reliably, demonstrating that computer vision models have\nshared weaknesses. The first dataset is called ImageNet-A and is like the\nImageNet test set, but it is far more challenging for existing models. We also\ncurate an adversarial out-of-distribution detection dataset called ImageNet-O,\nwhich is the first out-of-distribution detection dataset created for ImageNet\nmodels. On ImageNet-A a DenseNet-121 obtains around 2% accuracy, an accuracy\ndrop of approximately 90%, and its out-of-distribution detection performance on\nImageNet-O is near random chance levels. We find that existing data\naugmentation techniques hardly boost performance, and using other public\ntraining datasets provides improvements that are limited. However, we find that\nimprovements to computer vision architectures provide a promising path towards\nrobust models.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jul 2019 17:56:30 GMT"}, {"version": "v2", "created": "Thu, 18 Jul 2019 16:32:28 GMT"}, {"version": "v3", "created": "Wed, 8 Jan 2020 01:30:54 GMT"}, {"version": "v4", "created": "Thu, 4 Mar 2021 21:56:19 GMT"}], "update_date": "2021-03-08", "authors_parsed": [["Hendrycks", "Dan", ""], ["Zhao", "Kevin", ""], ["Basart", "Steven", ""], ["Steinhardt", "Jacob", ""], ["Song", "Dawn", ""]]}, {"id": "1907.07178", "submitter": "Juliana Ferreira J", "authors": "Rafael Brand\\~ao, Joel Carbonera, Clarisse de Souza, Juliana Ferreira,\n  Bernardo Gon\\c{c}alves, Carla Leit\\~ao", "title": "Mediation Challenges and Socio-Technical Gaps for Explainable Deep\n  Learning Applications", "comments": "39 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The presumed data owners' right to explanations brought about by the General\nData Protection Regulation in Europe has shed light on the social challenges of\nexplainable artificial intelligence (XAI). In this paper, we present a case\nstudy with Deep Learning (DL) experts from a research and development\nlaboratory focused on the delivery of industrial-strength AI technologies. Our\naim was to investigate the social meaning (i.e. meaning to others) that DL\nexperts assign to what they do, given a richly contextualized and familiar\ndomain of application. Using qualitative research techniques to collect and\nanalyze empirical data, our study has shown that participating DL experts did\nnot spontaneously engage into considerations about the social meaning of\nmachine learning models that they build. Moreover, when explicitly stimulated\nto do so, these experts expressed expectations that, with real-world DL\napplication, there will be available mediators to bridge the gap between\ntechnical meanings that drive DL work, and social meanings that AI technology\nusers assign to it. We concluded that current research incentives and values\nguiding the participants' scientific interests and conduct are at odds with\nthose required to face some of the scientific challenges involved in advancing\nXAI, and thus responding to the alleged data owners' right to explanations or\nsimilar societal demands emerging from current debates. As a concrete\ncontribution to mitigate what seems to be a more general problem, we propose\nthree preliminary XAI Mediation Challenges with the potential to bring together\ntechnical and social meanings of DL applications, as well as to foster much\nneeded interdisciplinary collaboration among AI and the Social Sciences\nresearchers.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jul 2019 17:59:34 GMT"}], "update_date": "2019-07-17", "authors_parsed": [["Brand\u00e3o", "Rafael", ""], ["Carbonera", "Joel", ""], ["de Souza", "Clarisse", ""], ["Ferreira", "Juliana", ""], ["Gon\u00e7alves", "Bernardo", ""], ["Leit\u00e3o", "Carla", ""]]}, {"id": "1907.07181", "submitter": "Radha Nagarajan", "authors": "Radhakrishnan Nagarajan", "title": "Deciphering Dynamical Nonlinearities in Short Time Series Using\n  Recurrent Neural Networks", "comments": "18 pages, 7 Figures, 1 Table", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Surrogate testing techniques have been used widely to investigate the\npresence of dynamical nonlinearities, an essential ingredient of deterministic\nchaotic processes. Traditional surrogate testing subscribes to statistical\nhypothesis testing and investigates potential differences in discriminant\nstatistics between the given empirical sample and its surrogate counterparts.\nThe choice and estimation of the discriminant statistics can be challenging\nacross short time series. Also, conclusion based on a single empirical sample\nis an inherent limitation. The present study proposes a recurrent neural\nnetwork classification framework that uses the raw time series obviating the\nneed for discriminant statistic while accommodating multiple time series\nrealizations for enhanced generalizability of the findings. The results are\ndemonstrated on short time series with lengths (L = 32, 64, 128) from\ncontinuous and discrete dynamical systems in chaotic regimes, nonlinear\ntransform of linearly correlated noise and experimental data. Accuracy of the\nclassifier is shown to be markedly higher than >> 50% for the processes in\nchaotic regimes whereas those of nonlinearly correlated noise were around ~50%\nsimilar to that of random guess from a one-sample binomial test. These results\nare promising and elucidate the usefulness of the proposed framework in\nidentifying potential dynamical nonlinearities from short experimental time\nseries.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jul 2019 20:08:20 GMT"}], "update_date": "2019-07-18", "authors_parsed": [["Nagarajan", "Radhakrishnan", ""]]}, {"id": "1907.07207", "submitter": "Victor G. Turrisi Costa", "authors": "Victor G. Turrisi da Costa, Saulo Martiello Mastelini, Andr\\'e C.\n  Ponce de Leon Ferreira de Carvalho, Sylvio Barbon Jr", "title": "Online Local Boosting: improving performance in online decision trees", "comments": "To appear on the 8th Brazilian Conference on Intelligent Systems\n  (BRACIS)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As more data are produced each day, and faster, data stream mining is growing\nin importance, making clear the need for algorithms able to fast process these\ndata. Data stream mining algorithms are meant to be solutions to extract\nknowledge online, specially tailored from continuous data problem. Many of the\ncurrent algorithms for data stream mining have high processing and memory\ncosts. Often, the higher the predictive performance, the higher these costs. To\nincrease predictive performance without largely increasing memory and time\ncosts, this paper introduces a novel algorithm, named Online Local Boosting\n(OLBoost), which can be combined into online decision tree algorithms to\nimprove their predictive performance without modifying the structure of the\ninduced decision trees. For such, OLBoost applies a boosting to small separate\nregions of the instances space. Experimental results presented in this paper\nshow that by using OLBoost the online learning decision tree algorithms can\nsignificantly improve their predictive performance. Additionally, it can make\nsmaller trees perform as good or better than larger trees.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jul 2019 18:26:45 GMT"}], "update_date": "2019-07-18", "authors_parsed": [["da Costa", "Victor G. Turrisi", ""], ["Mastelini", "Saulo Martiello", ""], ["de Carvalho", "Andr\u00e9 C. Ponce de Leon Ferreira", ""], ["Barbon", "Sylvio", "Jr"]]}, {"id": "1907.07212", "submitter": "Wenting Zheng", "authors": "Wenting Zheng, Raluca Ada Popa, Joseph E. Gonzalez, Ion Stoica", "title": "Helen: Maliciously Secure Coopetitive Learning for Linear Models", "comments": null, "journal-ref": "IEEE S&P 2019", "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many organizations wish to collaboratively train machine learning models on\ntheir combined datasets for a common benefit (e.g., better medical research, or\nfraud detection). However, they often cannot share their plaintext datasets due\nto privacy concerns and/or business competition. In this paper, we design and\nbuild Helen, a system that allows multiple parties to train a linear model\nwithout revealing their data, a setting we call coopetitive learning. Compared\nto prior secure training systems, Helen protects against a much stronger\nadversary who is malicious and can compromise m-1 out of m parties. Our\nevaluation shows that Helen can achieve up to five orders of magnitude of\nperformance improvement when compared to training using an existing\nstate-of-the-art secure multi-party computation framework.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jul 2019 18:45:27 GMT"}, {"version": "v2", "created": "Tue, 3 Sep 2019 17:40:31 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Zheng", "Wenting", ""], ["Popa", "Raluca Ada", ""], ["Gonzalez", "Joseph E.", ""], ["Stoica", "Ion", ""]]}, {"id": "1907.07220", "submitter": "Fabian Timm", "authors": "Lukas Enderich and Fabian Timm and Lars Rosenbaum and Wolfram Burgard", "title": "Learning Multimodal Fixed-Point Weights using Gradient Descent", "comments": "presented at ESANN 2019 (European Symposium on Artificial Neural\n  Networks, Computational Intelligence and Machine Learning)", "journal-ref": "https://www.elen.ucl.ac.be/esann/proceedings/papers.php?ann=2019", "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to their high computational complexity, deep neural networks are still\nlimited to powerful processing units. To promote a reduced model complexity by\ndint of low-bit fixed-point quantization, we propose a gradient-based\noptimization strategy to generate a symmetric mixture of Gaussian modes (SGM)\nwhere each mode belongs to a particular quantization stage. We achieve 2-bit\nstate-of-the-art performance and illustrate the model's ability for\nself-dependent weight adaptation during training.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jul 2019 19:11:01 GMT"}], "update_date": "2019-07-18", "authors_parsed": [["Enderich", "Lukas", ""], ["Timm", "Fabian", ""], ["Rosenbaum", "Lars", ""], ["Burgard", "Wolfram", ""]]}, {"id": "1907.07223", "submitter": "Vasileios Iosifidis", "authors": "Vasileios Iosifidis, Thi Ngoc Han Tran, Eirini Ntoutsi", "title": "Fairness-enhancing interventions in stream classification", "comments": "15 pages, 7 figures. To appear in the proceedings of 30th\n  International Conference on Database and Expert Systems Applications, Linz,\n  Austria August 26 - 29, 2019", "journal-ref": null, "doi": "10.1007/978-3-030-27615-7_20", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The wide spread usage of automated data-driven decision support systems has\nraised a lot of concerns regarding accountability and fairness of the employed\nmodels in the absence of human supervision. Existing fairness-aware approaches\ntackle fairness as a batch learning problem and aim at learning a fair model\nwhich can then be applied to future instances of the problem. In many\napplications, however, the data comes sequentially and its characteristics\nmight evolve with time. In such a setting, it is counter-intuitive to \"fix\" a\n(fair) model over the data stream as changes in the data might incur changes in\nthe underlying model therefore, affecting its fairness. In this work, we\npropose fairness-enhancing interventions that modify the input data so that the\noutcome of any stream classifier applied to that data will be fair. Experiments\non real and synthetic data show that our approach achieves good predictive\nperformance and low discrimination scores over the course of the stream.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jul 2019 19:27:19 GMT"}], "update_date": "2020-01-24", "authors_parsed": [["Iosifidis", "Vasileios", ""], ["Tran", "Thi Ngoc Han", ""], ["Ntoutsi", "Eirini", ""]]}, {"id": "1907.07225", "submitter": "Keegan Hines E", "authors": "C. Bayan Bruss, Anish Khazane, Jonathan Rider, Richard Serpe, Antonia\n  Gogoglou, Keegan E. Hines", "title": "DeepTrax: Embedding Graphs of Financial Transactions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Financial transactions can be considered edges in a heterogeneous graph\nbetween entities sending money and entities receiving money. For financial\ninstitutions, such a graph is likely large (with millions or billions of edges)\nwhile also sparsely connected. It becomes challenging to apply machine learning\nto such large and sparse graphs. Graph representation learning seeks to embed\nthe nodes of a graph into a Euclidean vector space such that graph topological\nproperties are preserved after the transformation. In this paper, we present a\nnovel application of representation learning to bipartite graphs of credit card\ntransactions in order to learn embeddings of account and merchant entities. Our\nframework is inspired by popular approaches in graph embeddings and is trained\non two internal transaction datasets. This approach yields highly effective\nembeddings, as quantified by link prediction AUC and F1 score. Further, the\nresulting entity vectors retain intuitive semantic similarity that is explored\nthrough visualizations and other qualitative analyses. Finally, we show how\nthese embeddings can be used as features in downstream machine learning\nbusiness applications such as fraud detection.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jul 2019 19:32:57 GMT"}], "update_date": "2019-07-18", "authors_parsed": [["Bruss", "C. Bayan", ""], ["Khazane", "Anish", ""], ["Rider", "Jonathan", ""], ["Serpe", "Richard", ""], ["Gogoglou", "Antonia", ""], ["Hines", "Keegan E.", ""]]}, {"id": "1907.07228", "submitter": "Rahul Pandey", "authors": "Rahul Pandey, Carlos Castillo, and Hemant Purohit", "title": "Modeling Human Annotation Errors to Design Bias-Aware Systems for Social\n  Stream Processing", "comments": "To appear in International Conference on Advances in Social Networks\n  Analysis and Mining (ASONAM '19), Vancouver, BC, Canada", "journal-ref": null, "doi": "10.1145/3341161.3342931", "report-no": null, "categories": "cs.SI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  High-quality human annotations are necessary to create effective machine\nlearning systems for social media. Low-quality human annotations indirectly\ncontribute to the creation of inaccurate or biased learning systems. We show\nthat human annotation quality is dependent on the ordering of instances shown\nto annotators (referred as 'annotation schedule'), and can be improved by local\nchanges in the instance ordering provided to the annotators, yielding a more\naccurate annotation of the data stream for efficient real-time social media\nanalytics. We propose an error-mitigating active learning algorithm that is\nrobust with respect to some cases of human errors when deciding an annotation\nschedule. We validate the human error model and evaluate the proposed algorithm\nagainst strong baselines by experimenting on classification tasks of relevant\nsocial media posts during crises. According to these experiments, considering\nthe order in which data instances are presented to human annotators leads to\nboth an increase in accuracy for machine learning and awareness toward some\npotential biases in human learning that may affect the automated classifier.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jul 2019 19:38:46 GMT"}], "update_date": "2019-07-18", "authors_parsed": [["Pandey", "Rahul", ""], ["Castillo", "Carlos", ""], ["Purohit", "Hemant", ""]]}, {"id": "1907.07229", "submitter": "Vojtech Mrazek", "authors": "Vojtech Mrazek and Zdenek Vasicek and Lukas Sekanina and Muhammad\n  Abdullah Hanif and Muhammad Shafique", "title": "ALWANN: Automatic Layer-Wise Approximation of Deep Neural Network\n  Accelerators without Retraining", "comments": "Accepted for 2019 IEEE/ACM International Conference On Computer-Aided\n  Design (ICCAD'19)", "journal-ref": null, "doi": "10.1109/ICCAD45719.2019.8942068", "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The state-of-the-art approaches employ approximate computing to reduce the\nenergy consumption of DNN hardware. Approximate DNNs then require extensive\nretraining afterwards to recover from the accuracy loss caused by the use of\napproximate operations. However, retraining of complex DNNs does not scale\nwell. In this paper, we demonstrate that efficient approximations can be\nintroduced into the computational path of DNN accelerators while retraining can\ncompletely be avoided. ALWANN provides highly optimized implementations of DNNs\nfor custom low-power accelerators in which the number of computing units is\nlower than the number of DNN layers. First, a fully trained DNN is converted to\noperate with 8-bit weights and 8-bit multipliers in convolutional layers. A\nsuitable approximate multiplier is then selected for each computing element\nfrom a library of approximate multipliers in such a way that (i) one\napproximate multiplier serves several layers, and (ii) the overall\nclassification error and energy consumption are minimized. The optimizations\nincluding the multiplier selection problem are solved by means of a\nmultiobjective optimization NSGA-II algorithm. In order to completely avoid the\ncomputationally expensive retraining of DNN, which is usually employed to\nimprove the classification accuracy, we propose a simple weight updating scheme\nthat compensates the inaccuracy introduced by employing approximate\nmultipliers. The proposed approach is evaluated for two architectures of DNN\naccelerators with approximate multipliers from the open-source \"EvoApprox\"\nlibrary. We report that the proposed approach saves 30% of energy needed for\nmultiplication in convolutional layers of ResNet-50 while the accuracy is\ndegraded by only 0.6%. The proposed technique and approximate layers are\navailable as an open-source extension of TensorFlow at\nhttps://github.com/ehw-fit/tf-approximate.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jun 2019 10:36:55 GMT"}, {"version": "v2", "created": "Thu, 25 Jul 2019 08:01:30 GMT"}], "update_date": "2020-01-31", "authors_parsed": [["Mrazek", "Vojtech", ""], ["Vasicek", "Zdenek", ""], ["Sekanina", "Lukas", ""], ["Hanif", "Muhammad Abdullah", ""], ["Shafique", "Muhammad", ""]]}, {"id": "1907.07237", "submitter": "Wenbin Zhang", "authors": "Wenbin Zhang and Eirini Ntoutsi", "title": "FAHT: An Adaptive Fairness-aware Decision Tree Classifier", "comments": "Accepted to IJCAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automated data-driven decision-making systems are ubiquitous across a wide\nspread of online as well as offline services. These systems, depend on\nsophisticated learning algorithms and available data, to optimize the service\nfunction for decision support assistance. However, there is a growing concern\nabout the accountability and fairness of the employed models by the fact that\noften the available historic data is intrinsically discriminatory, i.e., the\nproportion of members sharing one or more sensitive attributes is higher than\nthe proportion in the population as a whole when receiving positive\nclassification, which leads to a lack of fairness in decision support system. A\nnumber of fairness-aware learning methods have been proposed to handle this\nconcern. However, these methods tackle fairness as a static problem and do not\ntake the evolution of the underlying stream population into consideration. In\nthis paper, we introduce a learning mechanism to design a fair classifier for\nonline stream based decision-making. Our learning model, FAHT (Fairness-Aware\nHoeffding Tree), is an extension of the well-known Hoeffding Tree algorithm for\ndecision tree induction over streams, that also accounts for fairness. Our\nexperiments show that our algorithm is able to deal with discrimination in\nstreaming environments, while maintaining a moderate predictive performance\nover the stream.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jul 2019 20:00:41 GMT"}], "update_date": "2019-07-18", "authors_parsed": [["Zhang", "Wenbin", ""], ["Ntoutsi", "Eirini", ""]]}, {"id": "1907.07238", "submitter": "Mohak Bhardwaj", "authors": "Mohak Bhardwaj, Sanjiban Choudhury, Byron Boots, Siddhartha Srinivasa", "title": "Leveraging Experience in Lazy Search", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Lazy graph search algorithms are efficient at solving motion planning\nproblems where edge evaluation is the computational bottleneck. These\nalgorithms work by lazily computing the shortest potentially feasible path,\nevaluating edges along that path, and repeating until a feasible path is found.\nThe order in which edges are selected is critical to minimizing the total\nnumber of edge evaluations: a good edge selector chooses edges that are not\nonly likely to be invalid, but also eliminates future paths from consideration.\nWe wish to learn such a selector by leveraging prior experience. We formulate\nthis problem as a Markov Decision Process (MDP) on the state of the search\nproblem. While solving this large MDP is generally intractable, we show that we\ncan compute oracular selectors that can solve the MDP during training. With\naccess to such oracles, we use imitation learning to find effective policies.\nIf new search problems are sufficiently similar to problems solved during\ntraining, the learned policy will choose a good edge evaluation ordering and\nsolve the motion planning problem quickly. We evaluate our algorithms on a wide\nrange of 2D and 7D problems and show that the learned selector outperforms\nbaseline commonly used heuristics.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jul 2019 20:03:57 GMT"}], "update_date": "2019-07-18", "authors_parsed": [["Bhardwaj", "Mohak", ""], ["Choudhury", "Sanjiban", ""], ["Boots", "Byron", ""], ["Srinivasa", "Siddhartha", ""]]}, {"id": "1907.07255", "submitter": "Aras Dargazany", "authors": "Aras R. Dargazany", "title": "Iterative temporal differencing with random synaptic feedback weights\n  support error backpropagation for deep learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work shows that a differentiable activation function is not necessary\nany more for error backpropagation. The derivative of the activation function\ncan be replaced by an iterative temporal differencing using fixed random\nfeedback alignment. Using fixed random synaptic feedback alignment with an\niterative temporal differencing is transforming the traditional error\nbackpropagation into a more biologically plausible approach for learning deep\nneural network architectures. This can be a big step toward the integration of\nSTDP-based error backpropagation in deep learning.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jul 2019 06:00:41 GMT"}], "update_date": "2019-07-18", "authors_parsed": [["Dargazany", "Aras R.", ""]]}, {"id": "1907.07263", "submitter": "Yantong Wang", "authors": "Yantong Wang, Vasilis Friderikos", "title": "Caching as an Image Characterization Problem using Deep Convolutional\n  Neural Networks", "comments": "7 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Caching of popular content closer to the mobile user can significantly\nincrease overall user experience as well as network efficiency by decongesting\nbackbone network segments in the case of congestion episodes. In order to find\nthe optimal caching locations, many conventional approaches rely on solving a\ncomplex optimization problem that suffers from the curse of dimensionality,\nwhich may fail to support online decision making. In this paper we propose a\nframework to amalgamate model based optimization with data driven techniques by\ntransforming an optimization problem to a grayscale image and train a\nconvolutional neural network (CNN) to predict optimal caching location\npolicies. The rationale for the proposed modelling comes from CNN's superiority\nto capture features in grayscale images reaching human level performance in\nimage recognition problems. The CNN is trained with optimal solutions and\nnumerical investigations reveal that the performance can increase by more than\n400% compared to powerful randomized greedy algorithms. To this end, the\nproposed technique seems as a promising way forward to the holy grail aspect in\nresource orchestration which is providing high quality decision making in real\ntime.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jul 2019 21:18:14 GMT"}, {"version": "v2", "created": "Wed, 1 Apr 2020 23:39:08 GMT"}], "update_date": "2020-04-03", "authors_parsed": [["Wang", "Yantong", ""], ["Friderikos", "Vasilis", ""]]}, {"id": "1907.07273", "submitter": "Zikang Xiong", "authors": "He Zhu, Zikang Xiong, Stephen Magill, Suresh Jagannathan", "title": "An Inductive Synthesis Framework for Verifiable Reinforcement Learning", "comments": "Published on PLDI 2019", "journal-ref": null, "doi": "10.1145/3314221.3314638", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the tremendous advances that have been made in the last decade on\ndeveloping useful machine-learning applications, their wider adoption has been\nhindered by the lack of strong assurance guarantees that can be made about\ntheir behavior. In this paper, we consider how formal verification techniques\ndeveloped for traditional software systems can be repurposed for verification\nof reinforcement learning-enabled ones, a particularly important class of\nmachine learning systems. Rather than enforcing safety by examining and\naltering the structure of a complex neural network implementation, our\ntechnique uses blackbox methods to synthesizes deterministic programs, simpler,\nmore interpretable, approximations of the network that can nonetheless\nguarantee desired safety properties are preserved, even when the network is\ndeployed in unanticipated or previously unobserved environments. Our\nmethodology frames the problem of neural network verification in terms of a\ncounterexample and syntax-guided inductive synthesis procedure over these\nprograms. The synthesis procedure searches for both a deterministic program and\nan inductive invariant over an infinite state transition system that represents\na specification of an application's control logic. Additional specifications\ndefining environment-based constraints can also be provided to further refine\nthe search space. Synthesized programs deployed in conjunction with a neural\nnetwork implementation dynamically enforce safety conditions by monitoring and\npreventing potentially unsafe actions proposed by neural policies. Experimental\nresults over a wide range of cyber-physical applications demonstrate that\nsoftware-inspired formal verification techniques can be used to realize\ntrustworthy reinforcement learning systems with low overhead.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jul 2019 21:57:17 GMT"}], "update_date": "2019-07-18", "authors_parsed": [["Zhu", "He", ""], ["Xiong", "Zikang", ""], ["Magill", "Stephen", ""], ["Jagannathan", "Suresh", ""]]}, {"id": "1907.07287", "submitter": "Simon Guiroy", "authors": "Simon Guiroy, Vikas Verma, Christopher Pal", "title": "Towards Understanding Generalization in Gradient-Based Meta-Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we study generalization of neural networks in gradient-based\nmeta-learning by analyzing various properties of the objective landscapes. We\nexperimentally demonstrate that as meta-training progresses, the meta-test\nsolutions, obtained after adapting the meta-train solution of the model, to new\ntasks via few steps of gradient-based fine-tuning, become flatter, lower in\nloss, and further away from the meta-train solution. We also show that those\nmeta-test solutions become flatter even as generalization starts to degrade,\nthus providing an experimental evidence against the correlation between\ngeneralization and flat minima in the paradigm of gradient-based meta-leaning.\nFurthermore, we provide empirical evidence that generalization to new tasks is\ncorrelated with the coherence between their adaptation trajectories in\nparameter space, measured by the average cosine similarity between\ntask-specific trajectory directions, starting from a same meta-train solution.\nWe also show that coherence of meta-test gradients, measured by the average\ninner product between the task-specific gradient vectors evaluated at\nmeta-train solution, is also correlated with generalization. Based on these\nobservations, we propose a novel regularizer for MAML and provide experimental\nevidence for its effectiveness.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jul 2019 23:22:14 GMT"}], "update_date": "2019-07-18", "authors_parsed": [["Guiroy", "Simon", ""], ["Verma", "Vikas", ""], ["Pal", "Christopher", ""]]}, {"id": "1907.07291", "submitter": "Arif Siddiqi", "authors": "Arif Siddiqi", "title": "Adversarial Security Attacks and Perturbations on Machine Learning and\n  Deep Learning Methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The ever-growing big data and emerging artificial intelligence (AI) demand\nthe use of machine learning (ML) and deep learning (DL) methods. Cybersecurity\nalso benefits from ML and DL methods for various types of applications. These\nmethods however are susceptible to security attacks. The adversaries can\nexploit the training and testing data of the learning models or can explore the\nworkings of those models for launching advanced future attacks. The topic of\nadversarial security attacks and perturbations within the ML and DL domains is\na recent exploration and a great interest is expressed by the security\nresearchers and practitioners. The literature covers different adversarial\nsecurity attacks and perturbations on ML and DL methods and those have their\nown presentation styles and merits. A need to review and consolidate knowledge\nthat is comprehending of this increasingly focused and growing topic of\nresearch; however, is the current demand of the research communities. In this\nreview paper, we specifically aim to target new researchers in the\ncybersecurity domain who may seek to acquire some basic knowledge on the\nmachine learning and deep learning models and algorithms, as well as some of\nthe relevant adversarial security attacks and perturbations.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jul 2019 00:00:07 GMT"}], "update_date": "2019-07-18", "authors_parsed": [["Siddiqi", "Arif", ""]]}, {"id": "1907.07296", "submitter": "Ross Maciejewski", "authors": "Yuxin Ma, Tiankai Xie, Jundong Li, Ross Maciejewski", "title": "Explaining Vulnerabilities to Adversarial Machine Learning through\n  Visual Analytics", "comments": "IEEE VAST (Transactions on Visualization and Computer Graphics), 2019", "journal-ref": null, "doi": "10.1109/TVCG.2019.2934631", "report-no": null, "categories": "cs.HC cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning models are currently being deployed in a variety of\nreal-world applications where model predictions are used to make decisions\nabout healthcare, bank loans, and numerous other critical tasks. As the\ndeployment of artificial intelligence technologies becomes ubiquitous, it is\nunsurprising that adversaries have begun developing methods to manipulate\nmachine learning models to their advantage. While the visual analytics\ncommunity has developed methods for opening the black box of machine learning\nmodels, little work has focused on helping the user understand their model\nvulnerabilities in the context of adversarial attacks. In this paper, we\npresent a visual analytics framework for explaining and exploring model\nvulnerabilities to adversarial attacks. Our framework employs a multi-faceted\nvisualization scheme designed to support the analysis of data poisoning attacks\nfrom the perspective of models, data instances, features, and local structures.\nWe demonstrate our framework through two case studies on binary classifiers and\nillustrate model vulnerabilities with respect to varying attack strategies.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jul 2019 00:50:37 GMT"}, {"version": "v2", "created": "Sat, 20 Jul 2019 01:12:30 GMT"}, {"version": "v3", "created": "Tue, 1 Oct 2019 20:34:56 GMT"}, {"version": "v4", "created": "Thu, 3 Oct 2019 19:38:48 GMT"}], "update_date": "2019-10-07", "authors_parsed": [["Ma", "Yuxin", ""], ["Xie", "Tiankai", ""], ["Li", "Jundong", ""], ["Maciejewski", "Ross", ""]]}, {"id": "1907.07307", "submitter": "Bradley Sturt", "authors": "Dimitris Bertsimas, Christopher McCord, Bradley Sturt", "title": "Dynamic optimization with side information", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a tractable and flexible approach for incorporating side\ninformation into dynamic optimization under uncertainty. The proposed framework\nuses predictive machine learning methods (such as $k$-nearest neighbors, kernel\nregression, and random forests) to weight the relative importance of various\ndata-driven uncertainty sets in a robust optimization formulation. Through a\nnovel measure concentration result for a class of machine learning methods, we\nprove that the proposed approach is asymptotically optimal for multi-period\nstochastic programming with side information. We also describe a\ngeneral-purpose approximation for these optimization problems, based on\noverlapping linear decision rules, which is computationally tractable and\nproduces high-quality solutions for dynamic problems with many stages. Across a\nvariety of examples in inventory management, finance, and shipment planning,\nour method achieves improvements of up to 15\\% over alternatives and requires\nless than one minute of computation time on problems with twelve stages.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jul 2019 02:38:37 GMT"}, {"version": "v2", "created": "Tue, 21 Jul 2020 22:54:55 GMT"}], "update_date": "2020-07-23", "authors_parsed": [["Bertsimas", "Dimitris", ""], ["McCord", "Christopher", ""], ["Sturt", "Bradley", ""]]}, {"id": "1907.07312", "submitter": "Shaofu Xu", "authors": "Shaofu Xu, Rui Wang, Jianping Chen, Lei Yu, and Weiwen Zou", "title": "Deep learning scheme for recovery of broadband microwave photonic\n  receiving systems in transceivers without expert knowledge and system priors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In regular microwave photonic (MWP) receiving systems, broadband signals are\nprocessed in the analog domain before they are transformed to the digital\ndomain for further processing and storage. However, the quality of the signals\nmay be degraded by defective photonic analog links, especially in a complicated\nMWP system. Here, we show a unified deep learning scheme that recovers the\ndistorted broadband signals as they are transformed to the digital domain. The\nneural network could automatically learn the end-to-end inverse responses of\nthe distortion effects of actual photonic analog links from data without expert\nknowledge and system priors. Hence, by shifting or augmenting the datasets, the\nneural network is potential to be generalized to various MWP receiving systems.\nWe conduct experiments by nontrivial MWP systems with complicated waveforms.\nResults validate the effectiveness, general applicability and the\nnoise-robustness of the proposed scheme, showing its superior performance in\npractical MWP systems. Therefore, the proposed deep learning scheme facilitates\nthe low-cost performance improvement of MWP receiving systems, as well as the\nnext-generation broadband transceivers, including radars, communications, and\nmicrowave imaging.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jul 2019 03:05:42 GMT"}, {"version": "v2", "created": "Fri, 25 Oct 2019 08:00:31 GMT"}], "update_date": "2019-10-28", "authors_parsed": [["Xu", "Shaofu", ""], ["Wang", "Rui", ""], ["Chen", "Jianping", ""], ["Yu", "Lei", ""], ["Zou", "Weiwen", ""]]}, {"id": "1907.07315", "submitter": "Chengyuan Zhang", "authors": "Chengyuan Zhang, Jiacheng Zhu, Wenshuo Wang, Ding Zhao", "title": "A General Framework of Learning Multi-Vehicle Interaction Patterns from\n  Videos", "comments": "2019 IEEE Intelligent Transportation Systems Conference (ITSC)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semantic learning and understanding of multi-vehicle interaction patterns in\na cluttered driving environment are essential but challenging for autonomous\nvehicles to make proper decisions. This paper presents a general framework to\ngain insights into intricate multi-vehicle interaction patterns from bird's-eye\nview traffic videos. We adopt a Gaussian velocity field to describe the\ntime-varying multi-vehicle interaction behaviors and then use deep autoencoders\nto learn associated latent representations for each temporal frame. Then, we\nutilize a hidden semi-Markov model with a hierarchical Dirichlet process as a\nprior to segment these sequential representations into granular components,\nalso called traffic primitives, corresponding to interaction patterns.\nExperimental results demonstrate that our proposed framework can extract\ntraffic primitives from videos, thus providing a semantic way to analyze\nmulti-vehicle interaction patterns, even for cluttered driving scenarios that\nare far messier than human beings can cope with.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jul 2019 03:41:51 GMT"}], "update_date": "2019-07-18", "authors_parsed": [["Zhang", "Chengyuan", ""], ["Zhu", "Jiacheng", ""], ["Wang", "Wenshuo", ""], ["Zhao", "Ding", ""]]}, {"id": "1907.07321", "submitter": "Ziyu Ye", "authors": "Ziyu Ye, Andrew Gilman, Qihang Peng, Kelly Levick, Pamela Cosman,\n  Larry Milstein", "title": "Comparison of Neural Network Architectures for Spectrum Sensing", "comments": "6 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Different neural network (NN) architectures have different advantages.\nConvolutional neural networks (CNNs) achieved enormous success in computer\nvision, while recurrent neural networks (RNNs) gained popularity in speech\nrecognition. It is not known which type of NN architecture is the best fit for\nclassification of communication signals. In this work, we compare the behavior\nof fully-connected NN (FC), CNN, RNN, and bi-directional RNN (BiRNN) in a\nspectrum sensing task. The four NN architectures are compared on their\ndetection performance, requirement of training data, computational complexity,\nand memory requirement. Given abundant training data and computational and\nmemory resources, CNN, RNN, and BiRNN are shown to achieve similar performance.\nThe performance of FC is worse than that of the other three types, except in\nthe case where computational complexity is stringently limited.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jul 2019 21:24:31 GMT"}], "update_date": "2019-07-18", "authors_parsed": [["Ye", "Ziyu", ""], ["Gilman", "Andrew", ""], ["Peng", "Qihang", ""], ["Levick", "Kelly", ""], ["Cosman", "Pamela", ""], ["Milstein", "Larry", ""]]}, {"id": "1907.07322", "submitter": "Thomas Searle", "authors": "Thomas Searle, Zeljko Kraljevic, Rebecca Bendayan, Daniel Bean,\n  Richard Dobson", "title": "MedCATTrainer: A Biomedical Free Text Annotation Interface with Active\n  Learning and Research Use Case Specific Customisation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present MedCATTrainer an interface for building, improving and customising\na given Named Entity Recognition and Linking (NER+L) model for biomedical\ndomain text. NER+L is often used as a first step in deriving value from\nclinical text. Collecting labelled data for training models is difficult due to\nthe need for specialist domain knowledge. MedCATTrainer offers an interactive\nweb-interface to inspect and improve recognised entities from an underlying\nNER+L model via active learning. Secondary use of data for clinical research\noften has task and context specific criteria. MedCATTrainer provides a further\ninterface to define and collect supervised learning training data for\nresearcher specific use cases. Initial results suggest our approach allows for\nefficient and accurate collection of research use case specific training data.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jul 2019 15:32:04 GMT"}], "update_date": "2019-07-18", "authors_parsed": [["Searle", "Thomas", ""], ["Kraljevic", "Zeljko", ""], ["Bendayan", "Rebecca", ""], ["Bean", "Daniel", ""], ["Dobson", "Richard", ""]]}, {"id": "1907.07323", "submitter": "L\\'eo Bouscarrat", "authors": "L\\'eo Bouscarrat, Antoine Bonnefoy, Thomas Peel, C\\'ecile Pereira", "title": "STRASS: A Light and Effective Method for Extractive Summarization Based\n  on Sentence Embeddings", "comments": "To appear in 2019 ACL Student Research Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces STRASS: Summarization by TRAnsformation Selection and\nScoring. It is an extractive text summarization method which leverages the\nsemantic information in existing sentence embedding spaces. Our method creates\nan extractive summary by selecting the sentences with the closest embeddings to\nthe document embedding. The model learns a transformation of the document\nembedding to minimize the similarity between the extractive summary and the\nground truth summary. As the transformation is only composed of a dense layer,\nthe training can be done on CPU, therefore, inexpensive. Moreover, inference\ntime is short and linear according to the number of sentences. As a second\ncontribution, we introduce the French CASS dataset, composed of judgments from\nthe French Court of cassation and their corresponding summaries. On this\ndataset, our results show that our method performs similarly to the state of\nthe art extractive methods with effective training and inferring time.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jul 2019 16:14:09 GMT"}], "update_date": "2019-07-18", "authors_parsed": [["Bouscarrat", "L\u00e9o", ""], ["Bonnefoy", "Antoine", ""], ["Peel", "Thomas", ""], ["Pereira", "C\u00e9cile", ""]]}, {"id": "1907.07324", "submitter": "Andr\\'e Goo{\\ss}en", "authors": "Andr\\'e Goo{\\ss}en, Hrishikesh Deshpande, Tim Harder, Evan Schwab, Ivo\n  Baltruschat, Thusitha Mabotuwana, Nathan Cross, Axel Saalbach", "title": "Deep Learning for Pneumothorax Detection and Localization in Chest\n  Radiographs", "comments": "MIDL 2019 [arXiv:1907.08612]", "journal-ref": null, "doi": null, "report-no": "MIDL/2019/ExtendedAbstract/SkxvPEqIwV", "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pneumothorax is a critical condition that requires timely communication and\nimmediate action. In order to prevent significant morbidity or patient death,\nearly detection is crucial. For the task of pneumothorax detection, we study\nthe characteristics of three different deep learning techniques: (i)\nconvolutional neural networks, (ii) multiple-instance learning, and (iii) fully\nconvolutional networks. We perform a five-fold cross-validation on a dataset\nconsisting of 1003 chest X-ray images. ROC analysis yields AUCs of 0.96, 0.93,\nand 0.92 for the three methods, respectively. We review the classification and\nlocalization performance of these approaches as well as an ensemble of the\nthree aforementioned techniques.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jul 2019 11:06:48 GMT"}], "update_date": "2019-07-29", "authors_parsed": [["Goo\u00dfen", "Andr\u00e9", ""], ["Deshpande", "Hrishikesh", ""], ["Harder", "Tim", ""], ["Schwab", "Evan", ""], ["Baltruschat", "Ivo", ""], ["Mabotuwana", "Thusitha", ""], ["Cross", "Nathan", ""], ["Saalbach", "Axel", ""]]}, {"id": "1907.07326", "submitter": "Ziyu Ye", "authors": "Ziyu Ye, Qihang Peng, Kelly Levick, Hui Rong, Andrew Gilman, Pamela\n  Cosman, Larry Milstein", "title": "A Neural Network Detector for Spectrum Sensing under Uncertainties", "comments": "6 pages, 4 figures, submitted to ICNC2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.IT cs.LG math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spectrum sensing is of critical importance in any cognitive radio system.\nWhen the primary user's signal has uncertain parameters, the likelihood ratio\ntest, which is the theoretically optimal detector, generally has no closed-form\nexpression. As a result, spectrum sensing under parameter uncertainty remains\nan open question, though many detectors exploiting specific features of a\nprimary signal have been proposed and have achieved reasonably good\nperformance. In this paper, a neural network is trained as a detector for\nmodulated signals. The result shows by training on an appropriate dataset, the\nneural network gains robustness under uncertainties in system parameters\nincluding the carrier frequency offset, carrier phase offset, and symbol time\noffset. The result displays the neural network's potential in exploiting\nimplicit and incomplete knowledge about the signal's structure.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jul 2019 21:13:19 GMT"}, {"version": "v2", "created": "Tue, 6 Aug 2019 04:29:52 GMT"}], "update_date": "2019-08-07", "authors_parsed": [["Ye", "Ziyu", ""], ["Peng", "Qihang", ""], ["Levick", "Kelly", ""], ["Rong", "Hui", ""], ["Gilman", "Andrew", ""], ["Cosman", "Pamela", ""], ["Milstein", "Larry", ""]]}, {"id": "1907.07327", "submitter": "Ross Harper", "authors": "Ross Harper and Joshua Southern", "title": "End-To-End Prediction of Emotion From Heartbeat Data Collected by a\n  Consumer Fitness Tracker", "comments": "7 pages, 5 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic detection of emotion has the potential to revolutionize mental\nhealth and wellbeing. Recent work has been successful in predicting affect from\nunimodal electrocardiogram (ECG) data. However, to be immediately relevant for\nreal-world applications, physiology-based emotion detection must make use of\nubiquitous photoplethysmogram (PPG) data collected by affordable consumer\nfitness trackers. Additionally, applications of emotion detection in healthcare\nsettings will require some measure of uncertainty over model predictions. We\npresent here a Bayesian deep learning model for end-to-end classification of\nemotional valence, using only the unimodal heartbeat time series collected by a\nconsumer fitness tracker (Garmin V\\'ivosmart 3). We collected a new dataset for\nthis task, and report a peak F1 score of 0.7. This demonstrates a practical\nrelevance of physiology-based emotion detection `in the wild' today.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jul 2019 09:24:23 GMT"}], "update_date": "2019-07-18", "authors_parsed": [["Harper", "Ross", ""], ["Southern", "Joshua", ""]]}, {"id": "1907.07330", "submitter": "Jessica Finocchiaro", "authors": "Jessie Finocchiaro, Rafael Frongillo, Bo Waggoner", "title": "An Embedding Framework for Consistent Polyhedral Surrogates", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We formalize and study the natural approach of designing convex surrogate\nloss functions via embeddings for problems such as classification or ranking.\nIn this approach, one embeds each of the finitely many predictions (e.g.\nclasses) as a point in R^d, assigns the original loss values to these points,\nand convexifies the loss in between to obtain a surrogate. We prove that this\napproach is equivalent, in a strong sense, to working with polyhedral\n(piecewise linear convex) losses. Moreover, given any polyhedral loss $L$, we\ngive a construction of a link function through which $L$ is a consistent\nsurrogate for the loss it embeds. We go on to illustrate the power of this\nembedding framework with succinct proofs of consistency or inconsistency of\nvarious polyhedral surrogates in the literature.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jul 2019 04:43:36 GMT"}], "update_date": "2019-07-18", "authors_parsed": [["Finocchiaro", "Jessie", ""], ["Frongillo", "Rafael", ""], ["Waggoner", "Bo", ""]]}, {"id": "1907.07331", "submitter": "Tailin Wu", "authors": "Tailin Wu, Ian Fischer, Isaac L. Chuang, Max Tegmark", "title": "Learnability for the Information Bottleneck", "comments": "Accepted at UAI 2019", "journal-ref": null, "doi": "10.3390/e21100924", "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Information Bottleneck (IB) method (\\cite{tishby2000information})\nprovides an insightful and principled approach for balancing compression and\nprediction for representation learning. The IB objective $I(X;Z)-\\beta I(Y;Z)$\nemploys a Lagrange multiplier $\\beta$ to tune this trade-off. However, in\npractice, not only is $\\beta$ chosen empirically without theoretical guidance,\nthere is also a lack of theoretical understanding between $\\beta$,\nlearnability, the intrinsic nature of the dataset and model capacity. In this\npaper, we show that if $\\beta$ is improperly chosen, learning cannot happen --\nthe trivial representation $P(Z|X)=P(Z)$ becomes the global minimum of the IB\nobjective. We show how this can be avoided, by identifying a sharp phase\ntransition between the unlearnable and the learnable which arises as $\\beta$ is\nvaried. This phase transition defines the concept of IB-Learnability. We prove\nseveral sufficient conditions for IB-Learnability, which provides theoretical\nguidance for choosing a good $\\beta$. We further show that IB-learnability is\ndetermined by the largest confident, typical, and imbalanced subset of the\nexamples (the conspicuous subset), and discuss its relation with model\ncapacity. We give practical algorithms to estimate the minimum $\\beta$ for a\ngiven dataset. We also empirically demonstrate our theoretical conditions with\nanalyses of synthetic datasets, MNIST, and CIFAR10.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jul 2019 04:48:01 GMT"}], "update_date": "2019-10-23", "authors_parsed": [["Wu", "Tailin", ""], ["Fischer", "Ian", ""], ["Chuang", "Isaac L.", ""], ["Tegmark", "Max", ""]]}, {"id": "1907.07346", "submitter": "Hanlin Tang", "authors": "Hanlin Tang, Xiangru Lian, Shuang Qiu, Lei Yuan, Ce Zhang, Tong Zhang,\n  Ji Liu", "title": "$\\texttt{DeepSqueeze}$: Decentralization Meets Error-Compensated\n  Compression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Communication is a key bottleneck in distributed training. Recently, an\n\\emph{error-compensated} compression technology was particularly designed for\nthe \\emph{centralized} learning and receives huge successes, by showing\nsignificant advantages over state-of-the-art compression based methods in\nsaving the communication cost. Since the \\emph{decentralized} training has been\nwitnessed to be superior to the traditional \\emph{centralized} training in the\ncommunication restricted scenario, therefore a natural question to ask is \"how\nto apply the error-compensated technology to the decentralized learning to\nfurther reduce the communication cost.\" However, a trivial extension of\ncompression based centralized training algorithms does not exist for the\ndecentralized scenario. key difference between centralized and decentralized\ntraining makes this extension extremely non-trivial. In this paper, we propose\nan elegant algorithmic design to employ error-compensated stochastic gradient\ndescent for the decentralized scenario, named $\\texttt{DeepSqueeze}$. Both the\ntheoretical analysis and the empirical study are provided to show the proposed\n$\\texttt{DeepSqueeze}$ algorithm outperforms the existing compression based\ndecentralized learning algorithms. To the best of our knowledge, this is the\nfirst time to apply the error-compensated compression to the decentralized\nlearning.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jul 2019 05:59:31 GMT"}, {"version": "v2", "created": "Sat, 3 Aug 2019 15:20:38 GMT"}], "update_date": "2019-08-06", "authors_parsed": [["Tang", "Hanlin", ""], ["Lian", "Xiangru", ""], ["Qiu", "Shuang", ""], ["Yuan", "Lei", ""], ["Zhang", "Ce", ""], ["Zhang", "Tong", ""], ["Liu", "Ji", ""]]}, {"id": "1907.07352", "submitter": "Zhaoqi Zhang", "authors": "Zhaoqi Zhang, Panpan Qi, Wei Wang", "title": "Dynamic Malware Analysis with Feature Engineering and Feature Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dynamic malware analysis executes the program in an isolated environment and\nmonitors its run-time behaviour (e.g. system API calls) for malware detection.\nThis technique has been proven to be effective against various code obfuscation\ntechniques and newly released (\"zero-day\") malware. However, existing works\ntypically only consider the API name while ignoring the arguments, or require\ncomplex feature engineering operations and expert knowledge to process the\narguments. In this paper, we propose a novel and low-cost feature extraction\napproach, and an effective deep neural network architecture for accurate and\nfast malware detection. Specifically, the feature representation approach\nutilizes a feature hashing trick to encode the API call arguments associated\nwith the API name. The deep neural network architecture applies multiple\nGated-CNNs (convolutional neural networks) to transform the extracted features\nof each API call. The outputs are further processed through bidirectional LSTM\n(long-short term memory networks) to learn the sequential correlation among API\ncalls. Experiments show that our solution outperforms baselines significantly\non a large real dataset. Valuable insights about feature engineering and\narchitecture design are derived from the ablation study.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jul 2019 06:15:13 GMT"}, {"version": "v2", "created": "Sun, 21 Jul 2019 00:30:03 GMT"}, {"version": "v3", "created": "Mon, 9 Sep 2019 08:08:37 GMT"}, {"version": "v4", "created": "Wed, 18 Dec 2019 10:20:02 GMT"}, {"version": "v5", "created": "Fri, 24 Jan 2020 02:36:00 GMT"}], "update_date": "2020-01-27", "authors_parsed": [["Zhang", "Zhaoqi", ""], ["Qi", "Panpan", ""], ["Wang", "Wei", ""]]}, {"id": "1907.07374", "submitter": "Erico Tjoa", "authors": "Erico Tjoa, Cuntai Guan", "title": "A Survey on Explainable Artificial Intelligence (XAI): Towards Medical\n  XAI", "comments": null, "journal-ref": null, "doi": "10.1109/TNNLS.2020.3027314", "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, artificial intelligence and machine learning in general have\ndemonstrated remarkable performances in many tasks, from image processing to\nnatural language processing, especially with the advent of deep learning. Along\nwith research progress, they have encroached upon many different fields and\ndisciplines. Some of them require high level of accountability and thus\ntransparency, for example the medical sector. Explanations for machine\ndecisions and predictions are thus needed to justify their reliability. This\nrequires greater interpretability, which often means we need to understand the\nmechanism underlying the algorithms. Unfortunately, the blackbox nature of the\ndeep learning is still unresolved, and many machine decisions are still poorly\nunderstood. We provide a review on interpretabilities suggested by different\nresearch works and categorize them. The different categories show different\ndimensions in interpretability research, from approaches that provide\n\"obviously\" interpretable information to the studies of complex patterns. By\napplying the same categorization to interpretability in medical research, it is\nhoped that (1) clinicians and practitioners can subsequently approach these\nmethods with caution, (2) insights into interpretability will be born with more\nconsiderations for medical practices, and (3) initiatives to push forward\ndata-based, mathematically- and technically-grounded medical education are\nencouraged.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jul 2019 08:00:37 GMT"}, {"version": "v2", "created": "Wed, 31 Jul 2019 02:43:20 GMT"}, {"version": "v3", "created": "Tue, 15 Oct 2019 16:08:53 GMT"}, {"version": "v4", "created": "Sun, 7 Jun 2020 12:58:21 GMT"}, {"version": "v5", "created": "Tue, 11 Aug 2020 02:28:13 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Tjoa", "Erico", ""], ["Guan", "Cuntai", ""]]}, {"id": "1907.07381", "submitter": "Won-Yong Shin", "authors": "Cong Tran, Won-Yong Shin, Andreas Spitz, Michael Gertz", "title": "DeepNC: Deep Generative Network Completion", "comments": "16 pages, 10 figures, 5 tables; to appear in the IEEE Transactions on\n  Pattern Analysis and Machine Intelligence (Please cite our journal version\n  that will appear in an upcoming issue.)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most network data are collected from partially observable networks with both\nmissing nodes and missing edges, for example, due to limited resources and\nprivacy settings specified by users on social media. Thus, it stands to reason\nthat inferring the missing parts of the networks by performing network\ncompletion should precede downstream applications. However, despite this need,\nthe recovery of missing nodes and edges in such incomplete networks is an\ninsufficiently explored problem due to the modeling difficulty, which is much\nmore challenging than link prediction that only infers missing edges. In this\npaper, we present DeepNC, a novel method for inferring the missing parts of a\nnetwork based on a deep generative model of graphs. Specifically, our method\nfirst learns a likelihood over edges via an autoregressive generative model,\nand then identifies the graph that maximizes the learned likelihood conditioned\non the observable graph topology. Moreover, we propose a computationally\nefficient DeepNC algorithm that consecutively finds individual nodes that\nmaximize the probability in each node generation step, as well as an enhanced\nversion using the expectation-maximization algorithm. The runtime complexities\nof both algorithms are shown to be almost linear in the number of nodes in the\nnetwork. We empirically demonstrate the superiority of DeepNC over\nstate-of-the-art network completion approaches.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jul 2019 08:25:20 GMT"}, {"version": "v2", "created": "Thu, 25 Jun 2020 07:18:09 GMT"}, {"version": "v3", "created": "Fri, 16 Oct 2020 01:26:05 GMT"}, {"version": "v4", "created": "Mon, 19 Oct 2020 02:26:49 GMT"}, {"version": "v5", "created": "Tue, 20 Oct 2020 08:58:24 GMT"}], "update_date": "2020-10-21", "authors_parsed": [["Tran", "Cong", ""], ["Shin", "Won-Yong", ""], ["Spitz", "Andreas", ""], ["Gertz", "Michael", ""]]}, {"id": "1907.07384", "submitter": "Mario Beraha", "authors": "Mario Beraha, Alberto Maria Metelli, Matteo Papini, Andrea Tirinzoni\n  and Marcello Restelli", "title": "Feature Selection via Mutual Information: New Theoretical Insights", "comments": "Accepted for presentation at the International Joint Conference on\n  Neural Networks (IJCNN) 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mutual information has been successfully adopted in filter feature-selection\nmethods to assess both the relevancy of a subset of features in predicting the\ntarget variable and the redundancy with respect to other variables. However,\nexisting algorithms are mostly heuristic and do not offer any guarantee on the\nproposed solution. In this paper, we provide novel theoretical results showing\nthat conditional mutual information naturally arises when bounding the ideal\nregression/classification errors achieved by different subsets of features.\nLeveraging on these insights, we propose a novel stopping condition for\nbackward and forward greedy methods which ensures that the ideal prediction\nerror using the selected feature subset remains bounded by a user-specified\nthreshold. We provide numerical simulations to support our theoretical claims\nand compare to common heuristic methods.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jul 2019 08:36:27 GMT"}], "update_date": "2019-07-18", "authors_parsed": [["Beraha", "Mario", ""], ["Metelli", "Alberto Maria", ""], ["Papini", "Matteo", ""], ["Tirinzoni", "Andrea", ""], ["Restelli", "Marcello", ""]]}, {"id": "1907.07410", "submitter": "P B Mr", "authors": "Prasad Bhavana, Vikas Kumar, Vineet Padmanabhan", "title": "Block based Singular Value Decomposition approach to matrix\n  factorization for recommender systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the abundance of data in recent years, interesting challenges are posed\nin the area of recommender systems. Producing high quality recommendations with\nscalability and performance is the need of the hour. Singular Value\nDecomposition(SVD) based recommendation algorithms have been leveraged to\nproduce better results. In this paper, we extend the SVD technique further for\nscalability and performance in the context of 1) multi-threading 2) multiple\ncomputational units (with the use of Graphical Processing Units) and 3)\ndistributed computation. We propose block based matrix factorization (BMF)\npaired with SVD. This enabled us to take advantage of SVD over basic matrix\nfactorization(MF) while taking advantage of parallelism and scalability through\nBMF. We used Compute Unified Device Architecture (CUDA) platform and related\nhardware for leveraging Graphical Processing Unit (GPU) along with block based\nSVD to demonstrate the advantages in terms of performance and memory.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jul 2019 09:35:56 GMT"}], "update_date": "2019-07-19", "authors_parsed": [["Bhavana", "Prasad", ""], ["Kumar", "Vikas", ""], ["Padmanabhan", "Vineet", ""]]}, {"id": "1907.07421", "submitter": "Hwaran Lee", "authors": "Hwaran Lee, Jinsik Lee, Tae-Yoon Kim", "title": "SUMBT: Slot-Utterance Matching for Universal and Scalable Belief\n  Tracking", "comments": "6 pages, 2 figures, The 57th Annual Meeting of the Association for\n  Computational Linguistics (ACL)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In goal-oriented dialog systems, belief trackers estimate the probability\ndistribution of slot-values at every dialog turn. Previous neural approaches\nhave modeled domain- and slot-dependent belief trackers, and have difficulty in\nadding new slot-values, resulting in lack of flexibility of domain ontology\nconfigurations. In this paper, we propose a new approach to universal and\nscalable belief tracker, called slot-utterance matching belief tracker (SUMBT).\nThe model learns the relations between domain-slot-types and slot-values\nappearing in utterances through attention mechanisms based on contextual\nsemantic vectors. Furthermore, the model predicts slot-value labels in a\nnon-parametric way. From our experiments on two dialog corpora, WOZ 2.0 and\nMultiWOZ, the proposed model showed performance improvement in comparison with\nslot-dependent methods and achieved the state-of-the-art joint accuracy.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jul 2019 10:03:38 GMT"}], "update_date": "2019-07-18", "authors_parsed": [["Lee", "Hwaran", ""], ["Lee", "Jinsik", ""], ["Kim", "Tae-Yoon", ""]]}, {"id": "1907.07442", "submitter": "Yiming Li", "authors": "Yiming Li, Yang Zhang, Qingtao Tang, Weipeng Huang, Yong Jiang,\n  Shu-Tao Xia", "title": "$t$-$k$-means: A Robust and Stable $k$-means Variant", "comments": "Accepted by the ICASSP 2021. The first two authors contributed\n  equally to this work", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  $k$-means algorithm is one of the most classical clustering methods, which\nhas been widely and successfully used in signal processing. However, due to the\nthin-tailed property of the Gaussian distribution, $k$-means algorithm suffers\nfrom relatively poor performance on the dataset containing heavy-tailed data or\noutliers. Besides, standard $k$-means algorithm also has relatively weak\nstability, $i.e.$ its results have a large variance, which reduces its\ncredibility. In this paper, we propose a robust and stable $k$-means variant,\ndubbed the $t$-$k$-means, as well as its fast version to alleviate those\nproblems. Theoretically, we derive the $t$-$k$-means and analyze its robustness\nand stability from the aspect of the loss function and the expression of the\nclustering center, respectively. Extensive experiments are also conducted,\nwhich verify the effectiveness and efficiency of the proposed method. The code\nfor reproducing main results is available at\n\\url{https://github.com/THUYimingLi/t-k-means}.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jul 2019 11:19:00 GMT"}, {"version": "v2", "created": "Tue, 14 Jan 2020 04:32:48 GMT"}, {"version": "v3", "created": "Thu, 24 Sep 2020 16:05:12 GMT"}, {"version": "v4", "created": "Sun, 31 Jan 2021 15:00:58 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Li", "Yiming", ""], ["Zhang", "Yang", ""], ["Tang", "Qingtao", ""], ["Huang", "Weipeng", ""], ["Jiang", "Yong", ""], ["Xia", "Shu-Tao", ""]]}, {"id": "1907.07464", "submitter": "Moritz Kulessa", "authors": "Moritz Kulessa, Eneldo Loza Menc\\'ia, Johannes F\\\"urnkranz", "title": "Improving Outbreak Detection with Stacking of Statistical Surveillance\n  Methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Epidemiologists use a variety of statistical algorithms for the early\ndetection of outbreaks. The practical usefulness of such methods highly depends\non the trade-off between the detection rate of outbreaks and the chances of\nraising a false alarm. Recent research has shown that the use of machine\nlearning for the fusion of multiple statistical algorithms improves outbreak\ndetection. Instead of relying only on the binary output (alarm or no alarm) of\nthe statistical algorithms, we propose to make use of their p-values for\ntraining a fusion classifier. In addition, we also show that adding additional\nfeatures and adapting the labeling of an epidemic period may further improve\nperformance. For comparison and evaluation, a new measure is introduced which\ncaptures the performance of an outbreak detection method with respect to a low\nrate of false alarms more precisely than previous works. Our results on\nsynthetic data show that it is challenging to improve the performance with a\ntrainable fusion method based on machine learning. In particular, the use of a\nfusion classifier that is only based on binary outputs of the statistical\nsurveillance methods can make the overall performance worse than directly using\nthe underlying algorithms. However, the use of p-values and additional\ninformation for the learning is promising, enabling to identify more valuable\npatterns to detect outbreaks.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jul 2019 12:04:46 GMT"}], "update_date": "2019-07-18", "authors_parsed": [["Kulessa", "Moritz", ""], ["Menc\u00eda", "Eneldo Loza", ""], ["F\u00fcrnkranz", "Johannes", ""]]}, {"id": "1907.07480", "submitter": "Paulo Roberto de Oliveira da Costa", "authors": "Paulo R. de O. da Costa, Alp Akcay, Yingqian Zhang, Uzay Kaymak", "title": "Remaining Useful Lifetime Prediction via Deep Domain Adaptation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In Prognostics and Health Management (PHM) sufficient prior observed\ndegradation data is usually critical for Remaining Useful Lifetime (RUL)\nprediction. Most previous data-driven prediction methods assume that training\n(source) and testing (target) condition monitoring data have similar\ndistributions. However, due to different operating conditions, fault modes,\nnoise and equipment updates distribution shift exists across different data\ndomains. This shift reduces the performance of predictive models previously\nbuilt to specific conditions when no observed run-to-failure data is available\nfor retraining. To address this issue, this paper proposes a new data-driven\napproach for domain adaptation in prognostics using Long Short-Term Neural\nNetworks (LSTM). We use a time window approach to extract temporal information\nfrom time-series data in a source domain with observed RUL values and a target\ndomain containing only sensor information. We propose a Domain Adversarial\nNeural Network (DANN) approach to learn domain-invariant features that can be\nused to predict the RUL in the target domain. The experimental results show\nthat the proposed method can provide more reliable RUL predictions under\ndatasets with different operating conditions and fault modes. These results\nsuggest that the proposed method offers a promising approach to performing\ndomain adaptation in practical PHM applications.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jul 2019 12:44:04 GMT"}], "update_date": "2019-07-18", "authors_parsed": [["da Costa", "Paulo R. de O.", ""], ["Akcay", "Alp", ""], ["Zhang", "Yingqian", ""], ["Kaymak", "Uzay", ""]]}, {"id": "1907.07484", "submitter": "Robert Geirhos", "authors": "Claudio Michaelis, Benjamin Mitzkus, Robert Geirhos, Evgenia Rusak,\n  Oliver Bringmann, Alexander S. Ecker, Matthias Bethge, Wieland Brendel", "title": "Benchmarking Robustness in Object Detection: Autonomous Driving when\n  Winter is Coming", "comments": "21 pages, 10 figures, 1 dragon", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability to detect objects regardless of image distortions or weather\nconditions is crucial for real-world applications of deep learning like\nautonomous driving. We here provide an easy-to-use benchmark to assess how\nobject detection models perform when image quality degrades. The three\nresulting benchmark datasets, termed Pascal-C, Coco-C and Cityscapes-C, contain\na large variety of image corruptions. We show that a range of standard object\ndetection models suffer a severe performance loss on corrupted images (down to\n30--60\\% of the original performance). However, a simple data augmentation\ntrick---stylizing the training images---leads to a substantial increase in\nrobustness across corruption type, severity and dataset. We envision our\ncomprehensive benchmark to track future progress towards building robust object\ndetection models. Benchmark, code and data are publicly available.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jul 2019 12:51:10 GMT"}, {"version": "v2", "created": "Tue, 31 Mar 2020 08:42:46 GMT"}], "update_date": "2020-04-01", "authors_parsed": [["Michaelis", "Claudio", ""], ["Mitzkus", "Benjamin", ""], ["Geirhos", "Robert", ""], ["Rusak", "Evgenia", ""], ["Bringmann", "Oliver", ""], ["Ecker", "Alexander S.", ""], ["Bethge", "Matthias", ""], ["Brendel", "Wieland", ""]]}, {"id": "1907.07487", "submitter": "Alessandro Erba", "authors": "Alessandro Erba, Riccardo Taormina, Stefano Galelli, Marcello\n  Pogliani, Michele Carminati, Stefano Zanero, Nils Ole Tippenhauer", "title": "Constrained Concealment Attacks against Reconstruction-based Anomaly\n  Detectors in Industrial Control Systems", "comments": "Proceedings of the Annual Computer Security Applications Conference\n  (ACSAC) 2020", "journal-ref": null, "doi": "10.1145/3427228.3427660", "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, reconstruction-based anomaly detection was proposed as an effective\ntechnique to detect attacks in dynamic industrial control networks. Unlike\nclassical network anomaly detectors that observe the network traffic,\nreconstruction-based detectors operate on the measured sensor data, leveraging\nphysical process models learned a priori.\n  In this work, we investigate different approaches to evade prior-work\nreconstruction-based anomaly detectors by manipulating sensor data so that the\nattack is concealed. We find that replay attacks (commonly assumed to be very\nstrong) show bad performance (i.e., increasing the number of alarms) if the\nattacker is constrained to manipulate less than 95% of all features in the\nsystem, as hidden correlations between the features are not replicated well. To\naddress this, we propose two novel attacks that manipulate a subset of the\nsensor readings, leveraging learned physical constraints of the system. Our\nattacks feature two different attacker models: A white box attacker, which uses\nan optimization approach with a detection oracle, and a black box attacker,\nwhich uses an autoencoder to translate anomalous data into normal data. We\nevaluate our implementation on two different datasets from the water\ndistribution domain, showing that the detector's Recall drops from 0.68 to 0.12\nby manipulating 4 sensors out of 82 in WADI dataset. In addition, we show that\nour black box attacks are transferable to different detectors: They work\nagainst autoencoder-, LSTM-, and CNN-based detectors. Finally, we implement and\ndemonstrate our attacks on a real industrial testbed to demonstrate their\nfeasibility in real-time.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jul 2019 12:54:48 GMT"}, {"version": "v2", "created": "Tue, 8 Oct 2019 12:29:27 GMT"}, {"version": "v3", "created": "Mon, 12 Oct 2020 13:27:47 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Erba", "Alessandro", ""], ["Taormina", "Riccardo", ""], ["Galelli", "Stefano", ""], ["Pogliani", "Marcello", ""], ["Carminati", "Michele", ""], ["Zanero", "Stefano", ""], ["Tippenhauer", "Nils Ole", ""]]}, {"id": "1907.07496", "submitter": "Martin Maritsch", "authors": "Martin Maritsch, Caterina B\\'erub\\'e, Mathias Kraus, Vera Lehmann,\n  Thomas Z\\\"uger, Stefan Feuerriegel, Tobias Kowatsch, Felix Wortmann", "title": "Improving Heart Rate Variability Measurements from Consumer Smartwatches\n  with Machine Learning", "comments": "Adjunct Proceedings of the 2019 ACM International Joint Conference on\n  Pervasive and Ubiquitous Computing and the 2019 International Symposium on\n  Wearable Computers", "journal-ref": null, "doi": "10.1145/3341162.3346276", "report-no": null, "categories": "cs.LG cs.HC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The reactions of the human body to physical exercise, psychophysiological\nstress and heart diseases are reflected in heart rate variability (HRV). Thus,\ncontinuous monitoring of HRV can contribute to determining and predicting\nissues in well-being and mental health. HRV can be measured in everyday life by\nconsumer wearable devices such as smartwatches which are easily accessible and\naffordable. However, they are arguably accurate due to the stability of the\nsensor. We hypothesize a systematic error which is related to the wearer\nmovement. Our evidence builds upon explanatory and predictive modeling: we find\na statistically significant correlation between error in HRV measurements and\nthe wearer movement. We show that this error can be minimized by bringing into\ncontext additional available sensor information, such as accelerometer data.\nThis work demonstrates our research-in-progress on how neural learning can\nminimize the error of such smartwatch HRV measurements.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jul 2019 13:16:57 GMT"}], "update_date": "2019-07-18", "authors_parsed": [["Maritsch", "Martin", ""], ["B\u00e9rub\u00e9", "Caterina", ""], ["Kraus", "Mathias", ""], ["Lehmann", "Vera", ""], ["Z\u00fcger", "Thomas", ""], ["Feuerriegel", "Stefan", ""], ["Kowatsch", "Tobias", ""], ["Wortmann", "Felix", ""]]}, {"id": "1907.07500", "submitter": "Miroslav Bogdanovic", "authors": "Miroslav Bogdanovic, Majid Khadiv, Ludovic Righetti", "title": "Learning Variable Impedance Control for Contact Sensitive Tasks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning algorithms have shown great success in solving\ndifferent problems ranging from playing video games to robotics. However, they\nstruggle to solve delicate robotic problems, especially those involving contact\ninteractions. Though in principle a policy directly outputting joint torques\nshould be able to learn to perform these tasks, in practice we see that it has\ndifficulty to robustly solve the problem without any given structure in the\naction space. In this paper, we investigate how the choice of action space can\ngive robust performance in presence of contact uncertainties. We propose\nlearning a policy giving as output impedance and desired position in joint\nspace and compare the performance of that approach to torque and position\ncontrol under different contact uncertainties. Furthermore, we propose an\nadditional reward term designed to regularize these variable impedance control\npolicies, giving them interpretability and facilitating their transfer to real\nsystems. We present extensive experiments in simulation of both floating and\nfixed-base systems in tasks involving contact uncertainties, as well as results\nfor running the learned policies on a real system.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jul 2019 13:20:15 GMT"}, {"version": "v2", "created": "Tue, 14 Jul 2020 16:03:07 GMT"}], "update_date": "2020-07-15", "authors_parsed": [["Bogdanovic", "Miroslav", ""], ["Khadiv", "Majid", ""], ["Righetti", "Ludovic", ""]]}, {"id": "1907.07502", "submitter": "Cynthia Rush", "authors": "Zhiqi Bu, Jason Klusowski, Cynthia Rush, Weijie Su", "title": "Algorithmic Analysis and Statistical Estimation of SLOPE via Approximate\n  Message Passing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG eess.SP math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  SLOPE is a relatively new convex optimization procedure for high-dimensional\nlinear regression via the sorted l1 penalty: the larger the rank of the fitted\ncoefficient, the larger the penalty. This non-separable penalty renders many\nexisting techniques invalid or inconclusive in analyzing the SLOPE solution. In\nthis paper, we develop an asymptotically exact characterization of the SLOPE\nsolution under Gaussian random designs through solving the SLOPE problem using\napproximate message passing (AMP). This algorithmic approach allows us to\napproximate the SLOPE solution via the much more amenable AMP iterates.\nExplicitly, we characterize the asymptotic dynamics of the AMP iterates relying\non a recently developed state evolution analysis for non-separable penalties,\nthereby overcoming the difficulty caused by the sorted l1 penalty. Moreover, we\nprove that the AMP iterates converge to the SLOPE solution in an asymptotic\nsense, and numerical simulations show that the convergence is surprisingly\nfast. Our proof rests on a novel technique that specifically leverages the\nSLOPE problem. In contrast to prior literature, our work not only yields an\nasymptotically sharp analysis but also offers an algorithmic, flexible, and\nconstructive approach to understanding the SLOPE problem.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jul 2019 13:21:51 GMT"}], "update_date": "2019-07-18", "authors_parsed": [["Bu", "Zhiqi", ""], ["Klusowski", "Jason", ""], ["Rush", "Cynthia", ""], ["Su", "Weijie", ""]]}, {"id": "1907.07503", "submitter": "Fulvio Flamini", "authors": "Fulvio Flamini, Arne Hamann, Sofi\\`ene Jerbi, Lea M. Trenkwalder,\n  Hendrik Poulsen Nautrup, Hans J. Briegel", "title": "Photonic architecture for reinforcement learning", "comments": "14 pages, 8 figures", "journal-ref": null, "doi": "10.1088/1367-2630/ab783c", "report-no": null, "categories": "quant-ph cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The last decade has seen an unprecedented growth in artificial intelligence\nand photonic technologies, both of which drive the limits of modern-day\ncomputing devices. In line with these recent developments, this work brings\ntogether the state of the art of both fields within the framework of\nreinforcement learning. We present the blueprint for a photonic implementation\nof an active learning machine incorporating contemporary algorithms such as\nSARSA, Q-learning, and projective simulation. We numerically investigate its\nperformance within typical reinforcement learning environments, showing that\nrealistic levels of experimental noise can be tolerated or even be beneficial\nfor the learning process. Remarkably, the architecture itself enables\nmechanisms of abstraction and generalization, two features which are often\nconsidered key ingredients for artificial intelligence. The proposed\narchitecture, based on single-photon evolution on a mesh of tunable\nbeamsplitters, is simple, scalable, and a first integration in portable systems\nappears to be within the reach of near-term technology.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jul 2019 13:23:58 GMT"}], "update_date": "2020-06-24", "authors_parsed": [["Flamini", "Fulvio", ""], ["Hamann", "Arne", ""], ["Jerbi", "Sofi\u00e8ne", ""], ["Trenkwalder", "Lea M.", ""], ["Nautrup", "Hendrik Poulsen", ""], ["Briegel", "Hans J.", ""]]}, {"id": "1907.07504", "submitter": "Andrew Wilson", "authors": "Pavel Izmailov, Wesley J. Maddox, Polina Kirichenko, Timur Garipov,\n  Dmitry Vetrov, Andrew Gordon Wilson", "title": "Subspace Inference for Bayesian Deep Learning", "comments": "Published at UAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian inference was once a gold standard for learning with neural\nnetworks, providing accurate full predictive distributions and well calibrated\nuncertainty. However, scaling Bayesian inference techniques to deep neural\nnetworks is challenging due to the high dimensionality of the parameter space.\nIn this paper, we construct low-dimensional subspaces of parameter space, such\nas the first principal components of the stochastic gradient descent (SGD)\ntrajectory, which contain diverse sets of high performing models. In these\nsubspaces, we are able to apply elliptical slice sampling and variational\ninference, which struggle in the full parameter space. We show that Bayesian\nmodel averaging over the induced posterior in these subspaces produces accurate\npredictions and well calibrated predictive uncertainty for both regression and\nimage classification.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jul 2019 13:26:07 GMT"}], "update_date": "2019-07-18", "authors_parsed": [["Izmailov", "Pavel", ""], ["Maddox", "Wesley J.", ""], ["Kirichenko", "Polina", ""], ["Garipov", "Timur", ""], ["Vetrov", "Dmitry", ""], ["Wilson", "Andrew Gordon", ""]]}, {"id": "1907.07543", "submitter": "Peter Usherwood", "authors": "Peter Usherwood and Steven Smit", "title": "Low-Shot Classification: A Comparison of Classical and Deep Transfer\n  Machine Learning Approaches", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the recent success of deep transfer learning approaches in NLP, there\nis a lack of quantitative studies demonstrating the gains these models offer in\nlow-shot text classification tasks over existing paradigms. Deep transfer\nlearning approaches such as BERT and ULMFiT demonstrate that they can beat\nstate-of-the-art results on larger datasets, however when one has only 100-1000\nlabelled examples per class, the choice of approach is less clear, with\nclassical machine learning and deep transfer learning representing valid\noptions. This paper compares the current best transfer learning approach with\ntop classical machine learning approaches on a trinary sentiment classification\ntask to assess the best paradigm. We find that BERT, representing the best of\ndeep transfer learning, is the best performing approach, outperforming top\nclassical machine learning algorithms by 9.7% on average when trained with 100\nexamples per class, narrowing to 1.8% at 1000 labels per class. We also show\nthe robustness of deep transfer learning in moving across domains, where the\nmaximum loss in accuracy is only 0.7% in similar domain tasks and 3.2% cross\ndomain, compared to classical machine learning which loses up to 20.6%.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jul 2019 14:23:15 GMT"}], "update_date": "2019-07-18", "authors_parsed": [["Usherwood", "Peter", ""], ["Smit", "Steven", ""]]}, {"id": "1907.07552", "submitter": "Themistoklis Sapsis", "authors": "Themistoklis P. Sapsis", "title": "Output-weighted optimal sampling for Bayesian regression and rare event\n  statistics using few samples", "comments": "34 pages; 13 figures", "journal-ref": null, "doi": "10.1098/rspa.2019.0834", "report-no": null, "categories": "stat.ML cs.LG stat.AP stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For many important problems the quantity of interest is an unknown function\nof the parameters, which is a random vector with known statistics. Since the\ndependence of the output on this random vector is unknown, the challenge is to\nidentify its statistics, using the minimum number of function evaluations. This\nproblem can been seen in the context of active learning or optimal experimental\ndesign. We employ Bayesian regression to represent the derived model\nuncertainty due to finite and small number of input-output pairs. In this\ncontext we evaluate existing methods for optimal sample selection, such as\nmodel error minimization and mutual information maximization. We show that for\nthe case of known output variance, the commonly employed criteria in the\nliterature do not take into account the output values of the existing\ninput-output pairs, while for the case of unknown output variance this\ndependence can be very weak. We introduce a criterion that takes into account\nthe values of the output for the existing samples and adaptively selects inputs\nfrom regions of the parameter space which have important contribution to the\noutput. The new method allows for application to high-dimensional inputs,\npaving the way for optimal experimental design in high-dimensions.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jul 2019 14:51:11 GMT"}, {"version": "v2", "created": "Sat, 30 Nov 2019 16:14:43 GMT"}], "update_date": "2021-04-28", "authors_parsed": [["Sapsis", "Themistoklis P.", ""]]}, {"id": "1907.07561", "submitter": "Qiang Zhang", "authors": "Qiang Zhang, Aldo Lipani, Omer Kirnap, Emine Yilmaz", "title": "Self-Attentive Hawkes Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Asynchronous events on the continuous time domain, e.g., social media actions\nand stock transactions, occur frequently in the world. The ability to recognize\noccurrence patterns of event sequences is crucial to predict which typeof\nevents will happen next and when. A de facto standard mathematical framework to\ndo this is the Hawkes process. In order to enhance expressivity of multivariate\nHawkes processes, conventional statistical methods and deep recurrent networks\nhave been employed to modify its intensity function. The former is highly\ninterpretable and requires small size of training data but relies on correct\nmodel design while the latter has less dependency on prior knowledge and is\nmore powerful in capturing complicated patterns. We leverage pros and cons of\nthese models and propose a self-attentive Hawkes process(SAHP). The proposed\nmethod adapts self-attention to fit the intensity function of Hawkes processes.\nThis design has two benefits:(1) compared with conventional statistical\nmethods, the SAHP is more powerful to identify complicated dependency\nrelationships between temporal events; (2)compared with deep recurrent\nnetworks, the self-attention mechanism is able to capture longer historical\ninformation, and is more interpretable because the learnt attention weight\ntensor shows contributions of each historical event. Experiments on four\nreal-world datasets demonstrate the effectiveness of the proposed method.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jul 2019 15:02:15 GMT"}, {"version": "v2", "created": "Fri, 14 Feb 2020 17:36:25 GMT"}], "update_date": "2020-02-17", "authors_parsed": [["Zhang", "Qiang", ""], ["Lipani", "Aldo", ""], ["Kirnap", "Omer", ""], ["Yilmaz", "Emine", ""]]}, {"id": "1907.07564", "submitter": "Nishchay Sharma", "authors": "Madan Gopal Jhawar, Vipindeep Vangala, Nishchay Sharma, Ankur\n  Hayatnagarkar, Mansi Saxena, Swati Valecha", "title": "Conversational Help for Task Completion and Feature Discovery in\n  Personal Assistants", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CL cs.LG cs.SD eess.AS stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Intelligent Personal Assistants (IPAs) have become widely popular in recent\ntimes. Most of the commercial IPAs today support a wide range of skills\nincluding Alarms, Reminders, Weather Updates, Music, News, Factual\nQuestioning-Answering, etc. The list grows every day, making it difficult to\nremember the command structures needed to execute various tasks. An IPA must\nhave the ability to communicate information about supported skills and direct\nusers towards the right commands needed to execute them. Users interact with\npersonal assistants in natural language. A query is defined to be a Help Query\nif it seeks information about a personal assistant's capabilities, or asks for\ninstructions to execute a task. In this paper, we propose an interactive system\nwhich identifies help queries and retrieves appropriate responses. Our system\ncomprises of a C-BiLSTM based classifier, which is a fusion of Convolutional\nNeural Networks (CNN) and Bidirectional LSTM (BiLSTM) architectures, to detect\nhelp queries and a semantic Approximate Nearest Neighbours (ANN) module to map\nthe query to an appropriate predefined response. Evaluation of our system on\nreal-world queries from a commercial IPA and a detailed comparison with popular\ntraditional machine learning and deep learning based models reveal that our\nsystem outperforms other approaches and returns relevant responses for help\nqueries.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jul 2019 09:25:13 GMT"}], "update_date": "2019-07-18", "authors_parsed": [["Jhawar", "Madan Gopal", ""], ["Vangala", "Vipindeep", ""], ["Sharma", "Nishchay", ""], ["Hayatnagarkar", "Ankur", ""], ["Saxena", "Mansi", ""], ["Valecha", "Swati", ""]]}, {"id": "1907.07568", "submitter": "Paulo Roberto de Oliveira da Costa", "authors": "Dylan Rijnen, Jason Rhuggenaath, Paulo R. de O. da Costa and Yingqian\n  Zhang", "title": "Machine Learning based Simulation Optimisation for Trailer Management", "comments": "Submitted to IEEE SMC 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many situations, simulation models are developed to handle complex\nreal-world business optimisation problems. For example, a discrete-event\nsimulation model is used to simulate the trailer management process in a big\nFast-Moving Consumer Goods company. To address the problem of finding suitable\ninputs to this simulator for optimising fleet configuration, we propose a\nsimulation optimisation approach in this paper. The simulation optimisation\nmodel combines a metaheuristic search (genetic algorithm), with an\napproximation model filter (feed-forward neural network) to optimise the\nparameter configuration of the simulation model. We introduce an ensure\nprobability that overrules the rejection of potential solutions by the\napproximation model and we demonstrate its effectiveness. In addition, we\nevaluate the impact of the parameters of the optimisation model on its\neffectiveness and show the parameters such as population size, filter\nthreshold, and mutation probability can have a significant impact on the\noverall optimisation performance. Moreover, we compare the proposed method with\na single global approximation model approach and a random-based approach. The\nresults show the effectiveness of our method in terms of computation time and\nsolution quality.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jul 2019 15:09:02 GMT"}], "update_date": "2019-07-18", "authors_parsed": [["Rijnen", "Dylan", ""], ["Rhuggenaath", "Jason", ""], ["da Costa", "Paulo R. de O.", ""], ["Zhang", "Yingqian", ""]]}, {"id": "1907.07573", "submitter": "Ankit Gupta", "authors": "Ankit Gupta, Elliott Ruebush", "title": "AquaSight: Automatic Water Impurity Detection Utilizing Convolutional\n  Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  According to the United Nations World Water Assessment Programme, every day,\n2 million tons of sewage and industrial and agricultural waste are discharged\ninto the worlds water. In order to address this pervasive issue of increasing\nwater pollution, while ensuring that the global population has an efficient,\naccurate, and low cost method to assess whether the water they drink is\ncontaminated, we propose AquaSight, a novel mobile application that utilizes\ndeep learning methods, specifically Convolutional Neural Networks, for\nautomated water impurity detection. After comprehensive training with a dataset\nof 105 images representing varying magnitudes of contamination, the deep\nlearning algorithm achieved a 96 percent accuracy and loss of 0.108.\nFurthermore, the machine learning model uses efficient analysis of the\nturbidity and transparency levels of water to estimate a particular sample of\nwaters level of contamination. When deployed, the AquaSight system will provide\nan efficient way for individuals to secure an estimation of water quality,\nalerting local and national government to take action and potentially saving\nmillions of lives worldwide.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jul 2019 15:17:21 GMT"}], "update_date": "2019-07-18", "authors_parsed": [["Gupta", "Ankit", ""], ["Ruebush", "Elliott", ""]]}, {"id": "1907.07578", "submitter": "Enrico Maria Malatesta", "authors": "Carlo Baldassi, Enrico M. Malatesta, Riccardo Zecchina", "title": "Properties of the geometry of solutions and capacity of multi-layer\n  neural networks with Rectified Linear Units activations", "comments": "11 pages, 3 figures", "journal-ref": "Phys. Rev. Lett. 123, 170602 (2019)", "doi": "10.1103/PhysRevLett.123.170602", "report-no": null, "categories": "cond-mat.dis-nn cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rectified Linear Units (ReLU) have become the main model for the neural units\nin current deep learning systems. This choice has been originally suggested as\na way to compensate for the so called vanishing gradient problem which can\nundercut stochastic gradient descent (SGD) learning in networks composed of\nmultiple layers. Here we provide analytical results on the effects of ReLUs on\nthe capacity and on the geometrical landscape of the solution space in\ntwo-layer neural networks with either binary or real-valued weights. We study\nthe problem of storing an extensive number of random patterns and find that,\nquite unexpectedly, the capacity of the network remains finite as the number of\nneurons in the hidden layer increases, at odds with the case of threshold units\nin which the capacity diverges. Possibly more important, a large deviation\napproach allows us to find that the geometrical landscape of the solution space\nhas a peculiar structure: while the majority of solutions are close in distance\nbut still isolated, there exist rare regions of solutions which are much more\ndense than the similar ones in the case of threshold units. These solutions are\nrobust to perturbations of the weights and can tolerate large perturbations of\nthe inputs. The analytical results are corroborated by numerical findings.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jul 2019 15:23:17 GMT"}, {"version": "v2", "created": "Thu, 19 Sep 2019 00:20:26 GMT"}, {"version": "v3", "created": "Sat, 21 Sep 2019 15:45:35 GMT"}, {"version": "v4", "created": "Wed, 23 Oct 2019 16:10:41 GMT"}, {"version": "v5", "created": "Thu, 30 Jul 2020 10:52:05 GMT"}], "update_date": "2020-07-31", "authors_parsed": [["Baldassi", "Carlo", ""], ["Malatesta", "Enrico M.", ""], ["Zecchina", "Riccardo", ""]]}, {"id": "1907.07585", "submitter": "O\\u{g}ul Can", "authors": "O\\u{g}ul Can, Yeti Ziya G\\\"urb\\\"uz and A. Ayd{\\i}n Alatan", "title": "Deep Metric Learning with Alternating Projections onto Feasible Sets", "comments": "10 pages, 3 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  During the training of networks for distance metric learning, minimizers of\nthe typical loss functions can be considered as \"feasible points\" satisfying a\nset of constraints imposed by the training data. To this end, we reformulate\ndistance metric learning problem as finding a feasible point of a constraint\nset where the embedding vectors of the training data satisfy desired\nintra-class and inter-class proximity. The feasible set induced by the\nconstraint set is expressed as the intersection of the relaxed feasible sets\nwhich enforce the proximity constraints only for particular samples (a sample\nfrom each class) of the training data. Then, the feasible point problem is to\nbe approximately solved by performing alternating projections onto those\nfeasible sets. Such an approach introduces a regularization term and results in\nminimizing a typical loss function with a systematic batch set construction\nwhere these batches are constrained to contain the same sample from each class\nfor a certain number of iterations. Moreover, these particular samples can be\nconsidered as the class representatives, allowing efficient utilization of hard\nclass mining during batch construction. The proposed technique is applied with\nthe well-accepted losses and evaluated on Stanford Online Products, CAR196 and\nCUB200-2011 datasets for image retrieval and clustering. Outperforming\nstate-of-the-art, the proposed approach consistently improves the performance\nof the integrated loss functions with no additional computational cost and\nboosts the performance further by hard negative class mining.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jul 2019 15:29:19 GMT"}, {"version": "v2", "created": "Wed, 27 Nov 2019 13:42:00 GMT"}], "update_date": "2019-11-28", "authors_parsed": [["Can", "O\u011ful", ""], ["G\u00fcrb\u00fcz", "Yeti Ziya", ""], ["Alatan", "A. Ayd\u0131n", ""]]}, {"id": "1907.07587", "submitter": "Michael Innes", "authors": "Mike Innes, Alan Edelman, Keno Fischer, Chris Rackauckas, Elliot Saba,\n  Viral B Shah, Will Tebbutt", "title": "A Differentiable Programming System to Bridge Machine Learning and\n  Scientific Computing", "comments": "Submitted to NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Scientific computing is increasingly incorporating the advancements in\nmachine learning and the ability to work with large amounts of data. At the\nsame time, machine learning models are becoming increasingly sophisticated and\nexhibit many features often seen in scientific computing, stressing the\ncapabilities of machine learning frameworks. Just as the disciplines of\nscientific computing and machine learning have shared common underlying\ninfrastructure in the form of numerical linear algebra, we now have the\nopportunity to further share new computational infrastructure, and thus ideas,\nin the form of Differentiable Programming. We describe Zygote, a Differentiable\nProgramming system that is able to take gradients of general program\nstructures. We implement this system in the Julia programming language. Our\nsystem supports almost all language constructs (control flow, recursion,\nmutation, etc.) and compiles high-performance code without requiring any user\nintervention or refactoring to stage computations. This enables an expressive\nprogramming model for deep learning, but more importantly, it enables us to\nincorporate a large ecosystem of libraries in our models in a straightforward\nway. We discuss our approach to automatic differentiation, including its\nsupport for advanced techniques such as mixed-mode, complex and checkpointed\ndifferentiation, and present several examples of differentiating programs.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jul 2019 15:35:04 GMT"}, {"version": "v2", "created": "Thu, 18 Jul 2019 12:56:11 GMT"}], "update_date": "2019-07-19", "authors_parsed": [["Innes", "Mike", ""], ["Edelman", "Alan", ""], ["Fischer", "Keno", ""], ["Rackauckas", "Chris", ""], ["Saba", "Elliot", ""], ["Shah", "Viral B", ""], ["Tebbutt", "Will", ""]]}, {"id": "1907.07590", "submitter": "Xuchao Zhang", "authors": "Xuchao Zhang, Fanglan Chen, Chang-Tien Lu, Naren Ramakrishnan", "title": "Mitigating Uncertainty in Document Classification", "comments": "Accepted by NAACL19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The uncertainty measurement of classifiers' predictions is especially\nimportant in applications such as medical diagnoses that need to ensure limited\nhuman resources can focus on the most uncertain predictions returned by machine\nlearning models. However, few existing uncertainty models attempt to improve\noverall prediction accuracy where human resources are involved in the text\nclassification task. In this paper, we propose a novel neural-network-based\nmodel that applies a new dropout-entropy method for uncertainty measurement. We\nalso design a metric learning method on feature representations, which can\nboost the performance of dropout-based uncertainty methods with smaller\nprediction variance in accurate prediction trials. Extensive experiments on\nreal-world data sets demonstrate that our method can achieve a considerable\nimprovement in overall prediction accuracy compared to existing approaches. In\nparticular, our model improved the accuracy from 0.78 to 0.92 when 30\\% of the\nmost uncertain predictions were handed over to human experts in \"20NewsGroup\"\ndata.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jul 2019 15:38:13 GMT"}], "update_date": "2019-07-18", "authors_parsed": [["Zhang", "Xuchao", ""], ["Chen", "Fanglan", ""], ["Lu", "Chang-Tien", ""], ["Ramakrishnan", "Naren", ""]]}, {"id": "1907.07603", "submitter": "Renjie Chen", "authors": "Renjie Chen, Jingyue Zhang, Nalini Ravishanker, Karthik Konduri", "title": "Clustering Activity-Travel Behavior Time Series using Topological Data\n  Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Over the last few years, traffic data has been exploding and the\ntransportation discipline has entered the era of big data. It brings out new\nopportunities for doing data-driven analysis, but it also challenges\ntraditional analytic methods. This paper proposes a new Divide and Combine\nbased approach to do K means clustering on activity-travel behavior time series\nusing features that are derived using tools in Time Series Analysis and\nTopological Data Analysis. Clustering data from five waves of the National\nHousehold Travel Survey ranging from 1990 to 2017 suggests that activity-travel\npatterns of individuals over the last three decades can be grouped into three\nclusters. Results also provide evidence in support of recent claims about\ndifferences in activity-travel patterns of different survey cohorts. The\nproposed method is generally applicable and is not limited only to\nactivity-travel behavior analysis in transportation studies. Driving behavior,\ntravel mode choice, household vehicle ownership, when being characterized as\ncategorical time series, can all be analyzed using the proposed method.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jul 2019 16:05:37 GMT"}], "update_date": "2019-07-18", "authors_parsed": [["Chen", "Renjie", ""], ["Zhang", "Jingyue", ""], ["Ravishanker", "Nalini", ""], ["Konduri", "Karthik", ""]]}, {"id": "1907.07629", "submitter": "Gabriel de Souza Pereira Moreira", "authors": "Gabriel de Souza P. Moreira, Dietmar Jannach, Adilson Marques da Cunha", "title": "On the Importance of News Content Representation in Hybrid Neural\n  Session-based Recommender Systems", "comments": "Short paper. In 7th International Workshop on News Recommendation and\n  Analytics (INRA 2019), in conjunction with RecSys 2019, September 19, 2019,\n  Copenhagen, Denmark. arXiv admin note: text overlap with arXiv:1904.10367", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  News recommender systems are designed to surface relevant information for\nonline readers by personalizing their user experiences. A particular problem in\nthat context is that online readers are often anonymous, which means that this\npersonalization can only be based on the last few recorded interactions with\nthe user, a setting named session-based recommendation. Another particularity\nof the news domain is that constantly fresh articles are published, which\nshould be immediately considered for recommendation. To deal with this item\ncold-start problem, it is important to consider the actual content of items\nwhen recommending. Hybrid approaches are therefore often considered as the\nmethod of choice in such settings. In this work, we analyze the importance of\nconsidering content information in a hybrid neural news recommender system. We\ncontrast content-aware and content-agnostic techniques and also explore the\neffects of using different content encodings. Experiments on two public\ndatasets confirm the importance of adopting a hybrid approach. Furthermore, we\nshow that the choice of the content encoding can have an impact on the\nresulting performance.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jul 2019 15:27:53 GMT"}, {"version": "v2", "created": "Mon, 19 Aug 2019 13:26:53 GMT"}, {"version": "v3", "created": "Fri, 6 Sep 2019 11:29:18 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Moreira", "Gabriel de Souza P.", ""], ["Jannach", "Dietmar", ""], ["da Cunha", "Adilson Marques", ""]]}, {"id": "1907.07640", "submitter": "Emin Orhan", "authors": "A. Emin Orhan", "title": "Robustness properties of Facebook's ResNeXt WSL models", "comments": "10 pages, 4 figures, 4 tables; v5 corrects the ImageNet-A results and\n  revises the discussion accordingly", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the robustness properties of ResNeXt class image recognition\nmodels trained with billion scale weakly supervised data (ResNeXt WSL models).\nThese models, recently made public by Facebook AI, were trained with ~1B images\nfrom Instagram and fine-tuned on ImageNet. We show that these models display an\nunprecedented degree of robustness against common image corruptions and\nperturbations, as measured by the ImageNet-C and ImageNet-P benchmarks. They\nalso achieve substantially improved accuracies on the recently introduced\n\"natural adversarial examples\" benchmark (ImageNet-A). The largest of the\nreleased models, in particular, achieves state-of-the-art results on\nImageNet-C, ImageNet-P, and ImageNet-A by a large margin. The gains on\nImageNet-C, ImageNet-P, and ImageNet-A far outpace the gains on ImageNet\nvalidation accuracy, suggesting the former as more useful benchmarks to measure\nfurther progress in image recognition. Remarkably, the ResNeXt WSL models even\nachieve a limited degree of adversarial robustness against state-of-the-art\nwhite-box attacks (10-step PGD attacks). However, in contrast to adversarially\ntrained models, the robustness of the ResNeXt WSL models rapidly declines with\nthe number of PGD steps, suggesting that these models do not achieve genuine\nadversarial robustness. Visualization of the learned features also confirms\nthis conclusion. Finally, we show that although the ResNeXt WSL models are more\nshape-biased than comparable ImageNet-trained models in a shape-texture cue\nconflict experiment, they still remain much more texture-biased than humans,\nsuggesting that they share some of the underlying characteristics of\nImageNet-trained models that make this benchmark challenging.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jul 2019 17:03:52 GMT"}, {"version": "v2", "created": "Wed, 24 Jul 2019 17:59:19 GMT"}, {"version": "v3", "created": "Thu, 25 Jul 2019 15:52:53 GMT"}, {"version": "v4", "created": "Fri, 2 Aug 2019 16:30:13 GMT"}, {"version": "v5", "created": "Mon, 9 Dec 2019 16:28:47 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["Orhan", "A. Emin", ""]]}, {"id": "1907.07653", "submitter": "Prabod Rathnayaka", "authors": "Prabod Rathnayaka, Supun Abeysinghe, Chamod Samarajeewa, Isura\n  Manchanayake, Malaka J.Walpola, Rashmika Nawaratne, Tharindu Bandaragoda and\n  Damminda Alahakoon", "title": "Gated Recurrent Neural Network Approach for Multilabel Emotion Detection\n  in Microblogs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  People express their opinions and emotions freely in social media posts and\nonline reviews that contain valuable feedback for multiple stakeholders such as\nbusinesses and political campaigns. Manually extracting opinions and emotions\nfrom large volumes of such posts is an impossible task. Therefore, automated\nprocessing of these posts to extract opinions and emotions is an important\nresearch problem. However, human emotion detection is a challenging task due to\nthe complexity and nuanced nature. To overcome these barriers, researchers have\nextensively used techniques such as deep learning, distant supervision, and\ntransfer learning. In this paper, we propose a novel Pyramid Attention Network\n(PAN) based model for emotion detection in microblogs. The main advantage of\nour approach is that PAN has the capability to evaluate sentences in different\nperspectives to capture multiple emotions existing in a single text. The\nproposed model was evaluated on a recently released dataset and the results\nachieved the state-of-the-art accuracy of 58.9%.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jul 2019 17:33:13 GMT"}], "update_date": "2019-07-18", "authors_parsed": [["Rathnayaka", "Prabod", ""], ["Abeysinghe", "Supun", ""], ["Samarajeewa", "Chamod", ""], ["Manchanayake", "Isura", ""], ["Walpola", "Malaka J.", ""], ["Nawaratne", "Rashmika", ""], ["Bandaragoda", "Tharindu", ""], ["Alahakoon", "Damminda", ""]]}, {"id": "1907.07671", "submitter": "Syed Anwar", "authors": "Sanay Muhammad Umar Saeed, Syed Muhammad Anwar, Humaira Khalid,\n  Muhammad Majid, Ulas Bagci", "title": "Electroencephalography based Classification of Long-term Stress using\n  Psychological Labeling", "comments": "Submitted to IEEE JBHI", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stress research is a rapidly emerging area in thefield of\nelectroencephalography (EEG) based signal processing.The use of EEG as an\nobjective measure for cost effective andpersonalized stress management becomes\nimportant in particularsituations such as the non-availability of mental health\nfacilities.In this study, long-term stress is classified using baseline\nEEGsignal recordings. The labelling for the stress and control groupsis\nperformed using two methods (i) the perceived stress scalescore and (ii) expert\nevaluation. The frequency domain featuresare extracted from five-channel EEG\nrecordings in addition tothe frontal and temporal alpha and beta asymmetries.\nThe alphaasymmetry is computed from four channels and used as a feature.Feature\nselection is also performed using a t-test to identifystatistically significant\nfeatures for both stress and control groups.We found that support vector\nmachine is best suited to classifylong-term human stress when used with alpha\nasymmetry asa feature. It is observed that expert evaluation based\nlabellingmethod has improved the classification accuracy up to 85.20%.Based on\nthese results, it is concluded that alpha asymmetry maybe used as a potential\nbio-marker for stress classification, when labels are assigned using expert\nevaluation.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jul 2019 01:49:04 GMT"}], "update_date": "2019-07-19", "authors_parsed": [["Saeed", "Sanay Muhammad Umar", ""], ["Anwar", "Syed Muhammad", ""], ["Khalid", "Humaira", ""], ["Majid", "Muhammad", ""], ["Bagci", "Ulas", ""]]}, {"id": "1907.07672", "submitter": "Shahin Atakishiyev", "authors": "Shahin Atakishiyev, Marek Z. Reformat", "title": "Analysis of Word Embeddings Using Fuzzy Clustering", "comments": "6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In data dominated systems and applications, a concept of representing words\nin a numerical format has gained a lot of attention. There are a few approaches\nused to generate such a representation. An interesting issue that should be\nconsidered is the ability of such representations - called embeddings - to\nimitate human-based semantic similarity between words. In this study, we\nperform a fuzzy-based analysis of vector representations of words, i.e., word\nembeddings. We use two popular fuzzy clustering algorithms on count-based word\nembeddings, known as GloVe, of different dimensionality. Words from\nWordSim-353, called the gold standard, are represented as vectors and\nclustered. The results indicate that fuzzy clustering algorithms are very\nsensitive to high-dimensional data, and parameter tuning can dramatically\nchange their performance. We show that by adjusting the value of the fuzzifier\nparameter, fuzzy clustering can be successfully applied to vectors of high - up\nto one hundred - dimensions. Additionally, we illustrate that fuzzy clustering\nallows to provide interesting results regarding membership of words to\ndifferent clusters.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jul 2019 23:40:46 GMT"}, {"version": "v2", "created": "Sat, 20 Jul 2019 07:48:52 GMT"}, {"version": "v3", "created": "Mon, 7 Dec 2020 07:56:30 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Atakishiyev", "Shahin", ""], ["Reformat", "Marek Z.", ""]]}, {"id": "1907.07673", "submitter": "Deepak Pahwa", "authors": "Deepak Pahwa, Binil Starly", "title": "Network Based Pricing for 3D Printing Services in Two-Sided\n  Manufacturing-as-a-Service Marketplace", "comments": "Manuscript accepted July 4th, 2019; Rapid Prototyping Journal", "journal-ref": null, "doi": "10.1108/RPJ-01-2019-0018", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This paper presents approaches to determine a network based pricing for 3D\nprinting services in the context of a two-sided manufacturing-as-a-service\nmarketplace. The intent is to provide cost analytics to enable service bureaus\nto better compete in the market by moving away from setting ad-hoc and\nsubjective prices. A data mining approach with machine learning methods is used\nto estimate a price range based on the profile characteristics of 3D printing\nservice suppliers. The model considers factors such as supplier experience,\nsupplier capabilities, customer reviews and ratings from past orders, and scale\nof operations among others to estimate a price range for suppliers' services.\nData was gathered from existing marketplace websites, which was then used to\ntrain and test the model. The model demonstrates an accuracy of 65% for US\nbased suppliers and 59% for Europe based suppliers to classify a supplier's 3D\nPrinter listing in one of the seven price categories. The improvement over\nbaseline accuracy of 25% demonstrates that machine learning based methods are\npromising for network based pricing in manufacturing marketplaces. Conventional\nmethodologies for pricing services through activity based costing are\ninefficient in strategically pricing 3D printing service offering in a\nconnected marketplace. As opposed to arbitrarily determining prices, this work\nproposes an approach to determine prices through data mining methods to\nestimate competitive prices. Such tools can be built into online marketplaces\nto help independent service bureaus to determine service price rates.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jul 2019 19:14:55 GMT"}], "update_date": "2019-07-19", "authors_parsed": [["Pahwa", "Deepak", ""], ["Starly", "Binil", ""]]}, {"id": "1907.07676", "submitter": "Guy Engelhard", "authors": "Evi Kopelowitz, Guy Engelhard", "title": "Lung Nodules Detection and Segmentation Using 3D Mask-RCNN", "comments": "MIDL 2019 [arXiv:1907.08612]", "journal-ref": null, "doi": null, "report-no": "MIDL/2019/ExtendedAbstract/Hkxqw5ilcV", "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurate assessment of Lung nodules is a time consuming and error prone\ningredient of the radiologist interpretation work. Automating 3D volume\ndetection and segmentation can improve workflow as well as patient care.\nPrevious works have focused either on detecting lung nodules from a full CT\nscan or on segmenting them from a small ROI. We adapt the state of the art\narchitecture for 2D object detection and segmentation, MaskRCNN, to handle 3D\nimages and employ it to detect and segment lung nodules from CT scans. We\nreport on competitive results for the lung nodule detection on LUNA16 data set.\nThe added value of our method is that in addition to lung nodule detection, our\nframework produces 3D segmentations of the detected nodules.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jul 2019 09:51:11 GMT"}], "update_date": "2019-07-29", "authors_parsed": [["Kopelowitz", "Evi", ""], ["Engelhard", "Guy", ""]]}, {"id": "1907.07677", "submitter": "Fanhua Shang", "authors": "Hongying Liu, Xiongjie Shen, Fanhua Shang, Fei Wang", "title": "CU-Net: Cascaded U-Net with Loss Weighted Sampling for Brain Tumor\n  Segmentation", "comments": "9 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a novel cascaded U-Net for brain tumor segmentation.\nInspired by the distinct hierarchical structure of brain tumor, we design a\ncascaded deep network framework, in which the whole tumor is segmented firstly\nand then the tumor internal substructures are further segmented. Considering\nthat the increase of the network depth brought by cascade structures leads to a\nloss of accurate localization information in deeper layers, we construct many\nskip connections to link features at the same resolution and transmit detailed\ninformation from shallow layers to the deeper layers. Then we present a loss\nweighted sampling (LWS) scheme to eliminate the issue of imbalanced data during\ntraining the network. Experimental results on BraTS 2017 data show that our\narchitecture framework outperforms the state-of-the-art segmentation\nalgorithms, especially in terms of segmentation sensitivity.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jul 2019 10:16:04 GMT"}], "update_date": "2019-07-19", "authors_parsed": [["Liu", "Hongying", ""], ["Shen", "Xiongjie", ""], ["Shang", "Fanhua", ""], ["Wang", "Fei", ""]]}, {"id": "1907.07713", "submitter": "Xin Hunt", "authors": "Xin J. Hunt, Ralph Abbey, Ricky Tharrington, Joost Huiskens, Nina\n  Wesdorp", "title": "An AI-Augmented Lesion Detection Framework For Liver Metastases With\n  Model Interpretability", "comments": "4 pages, 2 figures, 2019 KDD Workshop on Applied Data Science for\n  Healthcare", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Colorectal cancer (CRC) is the third most common cancer and the second\nleading cause of cancer-related deaths worldwide. Most CRC deaths are the\nresult of progression of metastases. The assessment of metastases is done using\nthe RECIST criterion, which is time consuming and subjective, as clinicians\nneed to manually measure anatomical tumor sizes. AI has many successes in image\nobject detection, but often suffers because the models used are not\ninterpretable, leading to issues in trust and implementation in the clinical\nsetting. We propose a framework for an AI-augmented system in which an\ninteractive AI system assists clinicians in the metastasis assessment. We\ninclude model interpretability to give explanations of the reasoning of the\nunderlying models.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jul 2019 18:35:25 GMT"}], "update_date": "2019-07-19", "authors_parsed": [["Hunt", "Xin J.", ""], ["Abbey", "Ralph", ""], ["Tharrington", "Ricky", ""], ["Huiskens", "Joost", ""], ["Wesdorp", "Nina", ""]]}, {"id": "1907.07723", "submitter": "Adrian Rivera Cardoso", "authors": "Adrian Rivera Cardoso and Jacob Abernethy and He Wang and Huan Xu", "title": "Competing Against Equilibria in Zero-Sum Games with Evolving Payoffs", "comments": "arXiv admin note: text overlap with arXiv:1806.08301", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of repeated play in a zero-sum game in which the payoff\nmatrix may change, in a possibly adversarial fashion, on each round; we call\nthese Online Matrix Games. Finding the Nash Equilibrium (NE) of a two player\nzero-sum game is core to many problems in statistics, optimization, and\neconomics, and for a fixed game matrix this can be easily reduced to solving a\nlinear program. But when the payoff matrix evolves over time our goal is to\nfind a sequential algorithm that can compete with, in a certain sense, the NE\nof the long-term-averaged payoff matrix. We design an algorithm with small NE\nregret--that is, we ensure that the long-term payoff of both players is close\nto minimax optimum in hindsight. Our algorithm achieves near-optimal dependence\nwith respect to the number of rounds and depends poly-logarithmically on the\nnumber of available actions of the players. Additionally, we show that the\nnaive reduction, where each player simply minimizes its own regret, fails to\nachieve the stated objective regardless of which algorithm is used. We also\nconsider the so-called bandit setting, where the feedback is significantly\nlimited, and we provide an algorithm with small NE regret using one-point\nestimates of each payoff matrix.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jul 2019 18:57:55 GMT"}], "update_date": "2020-04-06", "authors_parsed": [["Cardoso", "Adrian Rivera", ""], ["Abernethy", "Jacob", ""], ["Wang", "He", ""], ["Xu", "Huan", ""]]}, {"id": "1907.07732", "submitter": "Arash Rahnama", "authors": "Arash Rahnama, Andre T. Nguyen and Edward Raff", "title": "Connecting Lyapunov Control Theory to Adversarial Attacks", "comments": "8 pages, 3 figures, AdvML'19: Workshop on Adversarial Learning\n  Methods for Machine Learning and Data Mining at KDD", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Significant work is being done to develop the math and tools necessary to\nbuild provable defenses, or at least bounds, against adversarial attacks of\nneural networks. In this work, we argue that tools from control theory could be\nleveraged to aid in defending against such attacks. We do this by example,\nbuilding a provable defense against a weaker adversary. This is done so we can\nfocus on the mechanisms of control theory, and illuminate its intrinsic value.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jul 2019 19:32:47 GMT"}], "update_date": "2019-07-19", "authors_parsed": [["Rahnama", "Arash", ""], ["Nguyen", "Andre T.", ""], ["Raff", "Edward", ""]]}, {"id": "1907.07735", "submitter": "Yaochen Hu", "authors": "Yaochen Hu, Peng Liu, Linglong Kong, Di Niu", "title": "Learning Privately over Distributed Features: An ADMM Sharing Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributed machine learning has been widely studied in order to handle\nexploding amount of data. In this paper, we study an important yet less visited\ndistributed learning problem where features are inherently distributed or\nvertically partitioned among multiple parties, and sharing of raw data or model\nparameters among parties is prohibited due to privacy concerns. We propose an\nADMM sharing framework to approach risk minimization over distributed features,\nwhere each party only needs to share a single value for each sample in the\ntraining process, thus minimizing the data leakage risk. We establish\nconvergence and iteration complexity results for the proposed parallel ADMM\nalgorithm under non-convex loss. We further introduce a novel differentially\nprivate ADMM sharing algorithm and bound the privacy guarantee with carefully\ndesigned noise perturbation. The experiments based on a prototype system shows\nthat the proposed ADMM algorithms converge efficiently in a robust fashion,\ndemonstrating advantage over gradient based methods especially for data set\nwith high dimensional feature spaces.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jul 2019 20:02:05 GMT"}], "update_date": "2019-07-19", "authors_parsed": [["Hu", "Yaochen", ""], ["Liu", "Peng", ""], ["Kong", "Linglong", ""], ["Niu", "Di", ""]]}, {"id": "1907.07739", "submitter": "Heather Couture", "authors": "Heather D. Couture, Roland Kwitt, J.S. Marron, Melissa Troester,\n  Charles M. Perou, Marc Niethammer", "title": "Deep Multi-View Learning via Task-Optimal CCA", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Canonical Correlation Analysis (CCA) is widely used for multimodal data\nanalysis and, more recently, for discriminative tasks such as multi-view\nlearning; however, it makes no use of class labels. Recent CCA methods have\nstarted to address this weakness but are limited in that they do not\nsimultaneously optimize the CCA projection for discrimination and the CCA\nprojection itself, or they are linear only. We address these deficiencies by\nsimultaneously optimizing a CCA-based and a task objective in an end-to-end\nmanner. Together, these two objectives learn a non-linear CCA projection to a\nshared latent space that is highly correlated and discriminative. Our method\nshows a significant improvement over previous state-of-the-art (including deep\nsupervised approaches) for cross-view classification, regularization with a\nsecond view, and semi-supervised learning on real data.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jul 2019 20:06:47 GMT"}], "update_date": "2019-07-19", "authors_parsed": [["Couture", "Heather D.", ""], ["Kwitt", "Roland", ""], ["Marron", "J. S.", ""], ["Troester", "Melissa", ""], ["Perou", "Charles M.", ""], ["Niethammer", "Marc", ""]]}, {"id": "1907.07746", "submitter": "Robin Tibor Schirrmeister", "authors": "Robin Tibor Schirrmeister, Tonio Ball", "title": "Deep Invertible Networks for EEG-based brain-signal decoding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this manuscript, we investigate deep invertible networks for EEG-based\nbrain signal decoding and find them to generate realistic EEG signals as well\nas classify novel signals above chance. Further ideas for their regularization\ntowards better decoding accuracies are discussed.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jul 2019 20:26:21 GMT"}], "update_date": "2019-07-19", "authors_parsed": [["Schirrmeister", "Robin Tibor", ""], ["Ball", "Tonio", ""]]}, {"id": "1907.07751", "submitter": "Andrew Jacobsen", "authors": "Andrew Jacobsen, Matthew Schlegel, Cameron Linke, Thomas Degris, Adam\n  White, Martha White", "title": "Meta-descent for Online, Continual Prediction", "comments": "AAAI Conference on Artificial Intelligence 2019. v2: Correction to\n  Baird's counterexample. A bug in the code lead to results being reported for\n  AMSGrad in this experiment, when they were actually results for Adam", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates different vector step-size adaptation approaches for\nnon-stationary online, continual prediction problems. Vanilla stochastic\ngradient descent can be considerably improved by scaling the update with a\nvector of appropriately chosen step-sizes. Many methods, including AdaGrad,\nRMSProp, and AMSGrad, keep statistics about the learning process to approximate\na second order update---a vector approximation of the inverse Hessian. Another\nfamily of approaches use meta-gradient descent to adapt the step-size\nparameters to minimize prediction error. These meta-descent strategies are\npromising for non-stationary problems, but have not been as extensively\nexplored as quasi-second order methods. We first derive a general, incremental\nmeta-descent algorithm, called AdaGain, designed to be applicable to a much\nbroader range of algorithms, including those with semi-gradient updates or even\nthose with accelerations, such as RMSProp. We provide an empirical comparison\nof methods from both families. We conclude that methods from both families can\nperform well, but in non-stationary prediction problems the meta-descent\nmethods exhibit advantages. Our method is particularly robust across several\nprediction problems, and is competitive with the state-of-the-art method on a\nlarge-scale, time-series prediction problem on real data from a mobile robot.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jul 2019 20:51:58 GMT"}, {"version": "v2", "created": "Fri, 13 Dec 2019 05:43:15 GMT"}], "update_date": "2019-12-16", "authors_parsed": [["Jacobsen", "Andrew", ""], ["Schlegel", "Matthew", ""], ["Linke", "Cameron", ""], ["Degris", "Thomas", ""], ["White", "Adam", ""], ["White", "Martha", ""]]}, {"id": "1907.07755", "submitter": "Shweta Singh", "authors": "Renganathan Subramanian and Shweta Singh", "title": "Can Machine Learning Identify Governing Laws For Dynamics in Complex\n  Engineered Systems ? : A Study in Chemical Engineering", "comments": "8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.LG cs.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning recently has been used to identify the governing equations\nfor dynamics in physical systems. The promising results from applications on\nsystems such as fluid dynamics and chemical kinetics inspire further\ninvestigation of these methods on complex engineered systems. Dynamics of these\nsystems play a crucial role in design and operations. Hence, it would be\nadvantageous to learn about the mechanisms that may be driving the complex\ndynamics of systems. In this work, our research question was aimed at\naddressing this open question about applicability and usefulness of novel\nmachine learning approach in identifying the governing dynamical equations for\nengineered systems. We focused on distillation column which is an ubiquitous\nunit operation in chemical engineering and demonstrates complex dynamics i.e.\nit's dynamics is a combination of heuristics and fundamental physical laws. We\ntested the method of Sparse Identification of Non-Linear Dynamics (SINDy)\nbecause of it's ability to produce white-box models with terms that can be used\nfor physical interpretation of dynamics. Time series data for dynamics was\ngenerated from simulation of distillation column using ASPEN Dynamics. One\npromising result was reduction of number of equations for dynamic simulation\nfrom 1000s in ASPEN to only 13 - one for each state variable. Prediction\naccuracy was high on the test data from system within the perturbation range,\nhowever outside perturbation range equations did not perform well. In terms of\nphysical law extraction, some terms were interpretable as related to Fick's law\nof diffusion (with concentration terms) and Henry's law (with ratio of\nconcentration and pressure terms). While some terms were interpretable, we\nconclude that more research is needed on combining engineering systems with\nmachine learning approach to improve understanding of governing laws for\nunknown dynamics.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jul 2019 11:31:12 GMT"}], "update_date": "2019-07-19", "authors_parsed": [["Subramanian", "Renganathan", ""], ["Singh", "Shweta", ""]]}, {"id": "1907.07757", "submitter": "Fan Yang", "authors": "Fan Yang, Shiva K. Pentyala, Sina Mohseni, Mengnan Du, Hao Yuan, Rhema\n  Linder, Eric D. Ragan, Shuiwang Ji, Xia Hu", "title": "XFake: Explainable Fake News Detector with Visualizations", "comments": "4 pages, WebConf'2019 Demo", "journal-ref": null, "doi": "10.1145/3308558.3314119", "report-no": null, "categories": "cs.CY cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this demo paper, we present the XFake system, an explainable fake news\ndetector that assists end-users to identify news credibility. To effectively\ndetect and interpret the fakeness of news items, we jointly consider both\nattributes (e.g., speaker) and statements. Specifically, MIMIC, ATTN and PERT\nframeworks are designed, where MIMIC is built for attribute analysis, ATTN is\nfor statement semantic analysis and PERT is for statement linguistic analysis.\nBeyond the explanations extracted from the designed frameworks, relevant\nsupporting examples as well as visualization are further provided to facilitate\nthe interpretation. Our implemented system is demonstrated on a real-world\ndataset crawled from PolitiFact, where thousands of verified political news\nhave been collected.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jul 2019 18:29:58 GMT"}], "update_date": "2019-07-19", "authors_parsed": [["Yang", "Fan", ""], ["Pentyala", "Shiva K.", ""], ["Mohseni", "Sina", ""], ["Du", "Mengnan", ""], ["Yuan", "Hao", ""], ["Linder", "Rhema", ""], ["Ragan", "Eric D.", ""], ["Ji", "Shuiwang", ""], ["Hu", "Xia", ""]]}, {"id": "1907.07766", "submitter": "Masoud Mansoury", "authors": "Masoud Mansoury, Robin Burke, Bamshad Mobasher", "title": "Flatter is better: Percentile Transformations for Recommender Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is well known that explicit user ratings in recommender systems are biased\ntowards high ratings, and that users differ significantly in their usage of the\nrating scale. Implementers usually compensate for these issues through rating\nnormalization or the inclusion of a user bias term in factorization models.\nHowever, these methods adjust only for the central tendency of users'\ndistributions. In this work, we demonstrate that lack of \\textit{flatness} in\nrating distributions is negatively correlated with recommendation performance.\nWe propose a rating transformation model that compensates for skew in the\nrating distribution as well as its central tendency by converting ratings into\npercentile values as a pre-processing step before recommendation generation.\nThis transformation flattens the rating distribution, better compensates for\ndifferences in rating distributions, and improves recommendation performance.\nWe also show a smoothed version of this transformation designed to yield more\nintuitive results for users with very narrow rating distributions. A\ncomprehensive set of experiments show improved ranking performance for these\npercentile transformations with state-of-the-art recommendation algorithms in\nfour real-world data sets.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jul 2019 21:12:18 GMT"}], "update_date": "2019-07-19", "authors_parsed": [["Mansoury", "Masoud", ""], ["Burke", "Robin", ""], ["Mobasher", "Bamshad", ""]]}, {"id": "1907.07768", "submitter": "Avishek Bose", "authors": "Avishek Bose, Vahid Behzadan, Carlos Aguirre, William H. Hsu", "title": "A Novel Approach for Detection and Ranking of Trendy and Emerging Cyber\n  Threat Events in Twitter Streams", "comments": "9 pages, 3 figures, and 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CR cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new machine learning and text information extraction approach to\ndetection of cyber threat events in Twitter that are novel (previously\nnon-extant) and developing (marked by significance with respect to similarity\nwith a previously detected event). While some existing approaches to event\ndetection measure novelty and trendiness, typically as independent criteria and\noccasionally as a holistic measure, this work focuses on detecting both novel\nand developing events using an unsupervised machine learning approach.\nFurthermore, our proposed approach enables the ranking of cyber threat events\nbased on an importance score by extracting the tweet terms that are\ncharacterized as named entities, keywords, or both. We also impute influence to\nusers in order to assign a weighted score to noun phrases in proportion to user\ninfluence and the corresponding event scores for named entities and keywords.\nTo evaluate the performance of our proposed approach, we measure the efficiency\nand detection error rate for events over a specified time interval, relative to\nhuman annotator ground truth.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jul 2019 22:17:17 GMT"}], "update_date": "2019-07-19", "authors_parsed": [["Bose", "Avishek", ""], ["Behzadan", "Vahid", ""], ["Aguirre", "Carlos", ""], ["Hsu", "William H.", ""]]}, {"id": "1907.07769", "submitter": "Praveen Narayanan", "authors": "Praveen Narayanan, Punarjay Chakravarty, Francois Charette, Gint\n  Puskorius", "title": "Hierarchical Sequence to Sequence Voice Conversion with Limited Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a voice conversion solution using recurrent sequence to sequence\nmodeling for DNNs. Our solution takes advantage of recent advances in attention\nbased modeling in the fields of Neural Machine Translation (NMT),\nText-to-Speech (TTS) and Automatic Speech Recognition (ASR). The problem\nconsists of converting between voices in a parallel setting when {\\it\n$<$source,target$>$} audio pairs are available. Our seq2seq architecture makes\nuse of a hierarchical encoder to summarize input audio frames. On the decoder\nside, we use an attention based architecture used in recent TTS works. Since\nthere is a dearth of large multispeaker voice conversion databases needed for\ntraining DNNs, we resort to training the network with a large single speaker\ndataset as an autoencoder. This is then adapted for the smaller multispeaker\nvoice conversion datasets available for voice conversion. In contrast with\nother voice conversion works that use $F_0$, duration and linguistic features,\nour system uses mel spectrograms as the audio representation. Output mel frames\nare converted back to audio using a wavenet vocoder.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jul 2019 07:54:46 GMT"}], "update_date": "2019-07-19", "authors_parsed": [["Narayanan", "Praveen", ""], ["Chakravarty", "Punarjay", ""], ["Charette", "Francois", ""], ["Puskorius", "Gint", ""]]}, {"id": "1907.07772", "submitter": "Patrick Gikunda Mr.", "authors": "Patrick Kinyua Gikunda", "title": "Modern CNNs for IoT Based Farms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent introduction of ICT in agriculture has brought a number of changes in\nthe way farming is done. This means use of Internet of Things(IoT), Cloud\nComputing(CC), Big Data (BD) and automation to gain better control over the\nprocess of farming. As the use of these technologies in farms has grown\nexponentially with massive data production, there is need to develop and use\nstate-of-the-art tools in order to gain more insight from the data within\nreasonable time. In this paper, we present an initial understanding of\nConvolutional Neural Network (CNN), the recent architectures of\nstate-of-the-art CNN and their underlying complexities. Then we propose a\nclassification taxonomy tailored for agricultural application of CNN. Finally,\nwe present a comprehensive review of research dedicated to applications of\nstate-of-the-art CNNs in agricultural production systems. Our contribution is\nin two-fold. First, for end users of agricultural deep learning tools, our\nbenchmarking finding can serve as a guide to selecting appropriate architecture\nto use. Second, for agricultural software developers of deep learning tools,\nour in-depth analysis explains the state-of-the-art CNN complexities and points\nout possible future directions to further optimize the running performance.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jul 2019 19:28:46 GMT"}], "update_date": "2019-07-19", "authors_parsed": [["Gikunda", "Patrick Kinyua", ""]]}, {"id": "1907.07776", "submitter": "Eduardo Olmedo Sanchez", "authors": "Eduardo Olmedo Sanchez, Xian-He Sun", "title": "CADS: Core-Aware Dynamic Scheduler for Multicore Memory Controllers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Memory controller scheduling is crucial in multicore processors, where DRAM\nbandwidth is shared. Since increased number of requests from multiple cores of\nprocessors becomes a source of bottleneck, scheduling the requests efficiently\nis necessary to utilize all the computing power these processors offer.\nHowever, current multicore processors are using traditional memory controllers,\nwhich are designed for single-core processors. They are unable to adapt to\nchanging characteristics of memory workloads that run simultaneously on\nmultiple cores. Existing schedulers may disrupt locality and bank parallelism\namong data requests coming from different cores. Hence, novel memory\ncontrollers that consider and adapt to the memory access characteristics, and\nshare memory resources efficiently and fairly are necessary. We introduce\nCore-Aware Dynamic Scheduler (CADS) for multicore memory controller. CADS uses\nReinforcement Learning (RL) to alter its scheduling strategy dynamically at\nruntime. Our scheduler utilizes locality among data requests from multiple\ncores and exploits parallelism in accessing multiple banks of DRAM. CADS is\nalso able to share the DRAM while guaranteeing fairness to all cores accessing\nmemory. Using CADS policy, we achieve 20% better cycles per instruction (CPI)\nin running memory intensive and compute intensive PARSEC parallel benchmarks\nsimultaneously, and 16% better CPI with SPEC 2006 benchmarks.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jul 2019 21:14:24 GMT"}], "update_date": "2019-07-19", "authors_parsed": [["Sanchez", "Eduardo Olmedo", ""], ["Sun", "Xian-He", ""]]}, {"id": "1907.07783", "submitter": "Bernhard Egger", "authors": "Bernhard Egger, Markus D. Schirmer, Florian Dubost, Marco J. Nardin,\n  Natalia S. Rost, Polina Golland", "title": "Patient-specific Conditional Joint Models of Shape, Image Features and\n  Clinical Indicators", "comments": "Supplementary material: https://www.youtube.com/watch?v=gPoHP_iFQIA", "journal-ref": "MICCAI 2019, the 22nd International Conference on Medical Image\n  Computing and Computer Assisted Intervention, in Shenzhen, China", "doi": null, "report-no": null, "categories": "eess.IV cs.CG cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We propose and demonstrate a joint model of anatomical shapes, image features\nand clinical indicators for statistical shape modeling and medical image\nanalysis. The key idea is to employ a copula model to separate the joint\ndependency structure from the marginal distributions of variables of interest.\nThis separation provides flexibility on the assumptions made during the\nmodeling process. The proposed method can handle binary, discrete, ordinal and\ncontinuous variables. We demonstrate a simple and efficient way to include\nbinary, discrete and ordinal variables into the modeling. We build Bayesian\nconditional models based on observed partial clinical indicators, features or\nshape based on Gaussian processes capturing the dependency structure. We apply\nthe proposed method on a stroke dataset to jointly model the shape of the\nlateral ventricles, the spatial distribution of the white matter hyperintensity\nassociated with periventricular white matter disease, and clinical indicators.\nThe proposed method yields interpretable joint models for data exploration and\npatient-specific statistical shape models for medical image analysis.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jul 2019 21:49:29 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Egger", "Bernhard", ""], ["Schirmer", "Markus D.", ""], ["Dubost", "Florian", ""], ["Nardin", "Marco J.", ""], ["Rost", "Natalia S.", ""], ["Golland", "Polina", ""]]}, {"id": "1907.07786", "submitter": "Alex Burnap", "authors": "Alex Burnap, John R. Hauser, Artem Timoshenko", "title": "Design and Evaluation of Product Aesthetics: A Human-Machine Hybrid\n  Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV econ.EM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Aesthetics are critically important to market acceptance in many product\ncategories. In the automotive industry in particular, an improved aesthetic\ndesign can boost sales by 30% or more. Firms invest heavily in designing and\ntesting new product aesthetics. A single automotive \"theme clinic\" costs\nbetween \\$100,000 and \\$1,000,000, and hundreds are conducted annually. We use\nmachine learning to augment human judgment when designing and testing new\nproduct aesthetics. The model combines a probabilistic variational autoencoder\n(VAE) and adversarial components from generative adversarial networks (GAN),\nalong with modeling assumptions that address managerial requirements for firm\nadoption. We train our model with data from an automotive partner-7,000 images\nevaluated by targeted consumers and 180,000 high-quality unrated images. Our\nmodel predicts well the appeal of new aesthetic designs-38% improvement\nrelative to a baseline and substantial improvement over both conventional\nmachine learning models and pretrained deep learning models. New automotive\ndesigns are generated in a controllable manner for the design team to consider,\nwhich we also empirically verify are appealing to consumers. These results,\ncombining human and machine inputs for practical managerial usage, suggest that\nmachine learning offers significant opportunity to augment aesthetic design.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jul 2019 21:56:55 GMT"}], "update_date": "2019-07-19", "authors_parsed": [["Burnap", "Alex", ""], ["Hauser", "John R.", ""], ["Timoshenko", "Artem", ""]]}, {"id": "1907.07788", "submitter": "Sheng Zhang", "authors": "Sheng Zhang, Guang Lin", "title": "SubTSBR to tackle high noise and outliers for data-driven discovery of\n  differential equations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data-driven discovery of differential equations has been an emerging research\ntopic. We propose a novel algorithm subsampling-based threshold sparse Bayesian\nregression (SubTSBR) to tackle high noise and outliers. The subsampling\ntechnique is used for improving the accuracy of the Bayesian learning\nalgorithm. It has two parameters: subsampling size and the number of\nsubsamples. When the subsampling size increases with fixed total sample size,\nthe accuracy of our algorithm goes up and then down. When the number of\nsubsamples increases, the accuracy of our algorithm keeps going up. We\ndemonstrate how to use our algorithm step by step and compare our algorithm\nwith threshold sparse Bayesian regression (TSBR) for the discovery of\ndifferential equations. We show that our algorithm produces better results. We\nalso discuss the merits of discovering differential equations from data and\ndemonstrate how to discover models with random initial and boundary condition\nas well as models with bifurcations. The numerical examples are: (1)\npredator-prey model with noise, (2) shallow water equations with outliers, (3)\nheat diffusion with random initial and boundary condition, and (4)\nfish-harvesting problem with bifurcations.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jul 2019 22:00:48 GMT"}, {"version": "v2", "created": "Tue, 23 Jul 2019 00:40:37 GMT"}, {"version": "v3", "created": "Mon, 11 May 2020 01:52:33 GMT"}, {"version": "v4", "created": "Tue, 27 Oct 2020 16:35:16 GMT"}], "update_date": "2020-10-28", "authors_parsed": [["Zhang", "Sheng", ""], ["Lin", "Guang", ""]]}, {"id": "1907.07802", "submitter": "Garrett Wilson", "authors": "Garrett Wilson and Diane J. Cook", "title": "Multi-Purposing Domain Adaptation Discriminators for Pseudo Labeling\n  Confidence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Often domain adaptation is performed using a discriminator (domain\nclassifier) to learn domain-invariant feature representations so that a\nclassifier trained on labeled source data will generalize well to unlabeled\ntarget data. A line of research stemming from semi-supervised learning uses\npseudo labeling to directly generate \"pseudo labels\" for the unlabeled target\ndata and trains a classifier on the now-labeled target data, where the samples\nare selected or weighted based on some measure of confidence. In this paper, we\npropose multi-purposing the discriminator to not only aid in producing\ndomain-invariant representations but also to provide pseudo labeling\nconfidence.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jul 2019 22:51:33 GMT"}], "update_date": "2019-07-19", "authors_parsed": [["Wilson", "Garrett", ""], ["Cook", "Diane J.", ""]]}, {"id": "1907.07804", "submitter": "Subhojeet Pramanik", "authors": "Subhojeet Pramanik, Priyanka Agrawal, Aman Hussain", "title": "OmniNet: A unified architecture for multi-modal multi-task learning", "comments": "Source code available at: https://github.com/subho406/OmniNet", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transformer is a popularly used neural network architecture, especially for\nlanguage understanding. We introduce an extended and unified architecture that\ncan be used for tasks involving a variety of modalities like image, text,\nvideos, etc. We propose a spatio-temporal cache mechanism that enables learning\nspatial dimension of the input in addition to the hidden states corresponding\nto the temporal input sequence. The proposed architecture further enables a\nsingle model to support tasks with multiple input modalities as well as\nasynchronous multi-task learning, thus we refer to it as OmniNet. For example,\na single instance of OmniNet can concurrently learn to perform the tasks of\npart-of-speech tagging, image captioning, visual question answering and video\nactivity recognition. We demonstrate that training these four tasks together\nresults in about three times compressed model while retaining the performance\nin comparison to training them individually. We also show that using this\nneural network pre-trained on some modalities assists in learning unseen tasks\nsuch as video captioning and video question answering. This illustrates the\ngeneralization capacity of the self-attention mechanism on the spatio-temporal\ncache present in OmniNet.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jul 2019 22:59:56 GMT"}, {"version": "v2", "created": "Fri, 3 Jul 2020 09:59:06 GMT"}], "update_date": "2020-07-06", "authors_parsed": [["Pramanik", "Subhojeet", ""], ["Agrawal", "Priyanka", ""], ["Hussain", "Aman", ""]]}, {"id": "1907.07807", "submitter": "Usman Roshan", "authors": "Yunzhe Xue, Meiyan Xie, Fadi G. Farhat, Olga Boukrina, A. M. Barrett,\n  Jeffrey R. Binder, Usman W. Roshan, William W. Graves", "title": "A fully 3D multi-path convolutional neural network with feature fusion\n  and feature weighting for automatic lesion identification in brain MRI images", "comments": "Machine Learning for Health (ML4H) at NeurIPS 2019 - Extended\n  Abstract", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a fully 3D multi-path convolutional network to predict stroke\nlesions from 3D brain MRI images. Our multi-path model has independent encoders\nfor different modalities containing residual convolutional blocks, weighted\nmulti-path feature fusion from different modalities, and weighted fusion\nmodules to combine encoder and decoder features. Compared to existing 3D CNNs\nlike DeepMedic, 3D U-Net, and AnatomyNet, our networks achieves the highest\nstatistically significant cross-validation accuracy of 60.5% on the large ATLAS\nbenchmark of 220 patients. We also test our model on multi-modal images from\nthe Kessler Foundation and Medical College Wisconsin and achieve a\nstatistically significant cross-validation accuracy of 65%, significantly\noutperforming the multi-modal 3D U-Net and DeepMedic. Overall our model offers\na principled, extensible multi-path approach that outperforms multi-channel\nalternatives and achieves high Dice accuracies on existing benchmarks.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jul 2019 23:21:42 GMT"}, {"version": "v2", "created": "Sat, 16 Nov 2019 18:30:20 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Xue", "Yunzhe", ""], ["Xie", "Meiyan", ""], ["Farhat", "Fadi G.", ""], ["Boukrina", "Olga", ""], ["Barrett", "A. M.", ""], ["Binder", "Jeffrey R.", ""], ["Roshan", "Usman W.", ""], ["Graves", "William W.", ""]]}, {"id": "1907.07810", "submitter": "Suryanarayana Maddu", "authors": "Suryanarayana Maddu, Bevan L. Cheeseman, Ivo F. Sbalzarini, Christian\n  L. M\\\"uller", "title": "Stability selection enables robust learning of partial differential\n  equations from limited noisy data", "comments": "20 pages, 10 figures and supplementary material included", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.LG cs.NA physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a statistical learning framework for robust identification of\npartial differential equations from noisy spatiotemporal data. Extending\nprevious sparse regression approaches for inferring PDE models from simulated\ndata, we address key issues that have thus far limited the application of these\nmethods to noisy experimental data, namely their robustness against noise and\nthe need for manual parameter tuning. We address both points by proposing a\nstability-based model selection scheme to determine the level of regularization\nrequired for reproducible recovery of the underlying PDE. This avoids manual\nparameter tuning and provides a principled way to improve the method's\nrobustness against noise in the data. Our stability selection approach, termed\nPDE-STRIDE, can be combined with any sparsity-promoting penalized regression\nmodel and provides an interpretable criterion for model component importance.\nWe show that in particular the combination of stability selection with the\niterative hard-thresholding algorithm from compressed sensing provides a fast,\nparameter-free, and robust computational framework for PDE inference that\noutperforms previous algorithmic approaches with respect to recovery accuracy,\namount of data required, and robustness to noise. We illustrate the performance\nof our approach on a wide range of noise-corrupted simulated benchmark\nproblems, including 1D Burgers, 2D vorticity-transport, and 3D\nreaction-diffusion problems. We demonstrate the practical applicability of our\nmethod on real-world data by considering a purely data-driven re-evaluation of\nthe advective triggering hypothesis for an embryonic polarization system in\nC.~elegans. Using fluorescence microscopy images of C.~elegans zygotes as input\ndata, our framework is able to recover the PDE model for the regulatory\nreaction-diffusion-flow network of the associated proteins.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jul 2019 23:35:05 GMT"}], "update_date": "2019-07-19", "authors_parsed": [["Maddu", "Suryanarayana", ""], ["Cheeseman", "Bevan L.", ""], ["Sbalzarini", "Ivo F.", ""], ["M\u00fcller", "Christian L.", ""]]}, {"id": "1907.07826", "submitter": "Md. Ataur Rahman", "authors": "Md. Ataur Rahman and Md. Hanif Seddiqui", "title": "Comparison of Classical Machine Learning Approaches on Bangla Textual\n  Emotion Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Detecting emotions from text is an extension of simple sentiment polarity\ndetection. Instead of considering only positive or negative sentiments,\nemotions are conveyed using more tangible manner; thus, they can be expressed\nas many shades of gray. This paper manifests the results of our experimentation\nfor fine-grained emotion analysis on Bangla text. We gathered and annotated a\ntext corpus consisting of user comments from several Facebook groups regarding\nsocio-economic and political issues, and we made efforts to extract the basic\nemotions (sadness, happiness, disgust, surprise, fear, anger) conveyed through\nthese comments. Finally, we compared the results of the five most popular\nclassical machine learning techniques namely Naive Bayes, Decision Tree,\nk-Nearest Neighbor (k-NN), Support Vector Machine (SVM) and K-Means Clustering\nwith several combinations of features. Our best model (SVM with a non-linear\nradial-basis function (RBF) kernel) achieved an overall average accuracy score\nof 52.98% and an F1 score (macro) of 0.3324\n", "versions": [{"version": "v1", "created": "Thu, 18 Jul 2019 01:00:42 GMT"}], "update_date": "2019-07-19", "authors_parsed": [["Rahman", "Md. Ataur", ""], ["Seddiqui", "Md. Hanif", ""]]}, {"id": "1907.07835", "submitter": "Peixiang Zhong", "authors": "Peixiang Zhong, Di Wang, and Chunyan Miao", "title": "EEG-Based Emotion Recognition Using Regularized Graph Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Electroencephalography (EEG) measures the neuronal activities in different\nbrain regions via electrodes. Many existing studies on EEG-based emotion\nrecognition do not fully exploit the topology of EEG channels. In this paper,\nwe propose a regularized graph neural network (RGNN) for EEG-based emotion\nrecognition. RGNN considers the biological topology among different brain\nregions to capture both local and global relations among different EEG\nchannels. Specifically, we model the inter-channel relations in EEG signals via\nan adjacency matrix in a graph neural network where the connection and\nsparseness of the adjacency matrix are inspired by neuroscience theories of\nhuman brain organization. In addition, we propose two regularizers, namely\nnode-wise domain adversarial training (NodeDAT) and emotion-aware distribution\nlearning (EmotionDL), to better handle cross-subject EEG variations and noisy\nlabels, respectively. Extensive experiments on two public datasets, SEED and\nSEED-IV, demonstrate the superior performance of our model than\nstate-of-the-art models in most experimental settings. Moreover, ablation\nstudies show that the proposed adjacency matrix and two regularizers contribute\nconsistent and significant gain to the performance of our RGNN model. Finally,\ninvestigations on the neuronal activities reveal important brain regions and\ninter-channel relations for EEG-based emotion recognition.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jul 2019 01:44:44 GMT"}, {"version": "v2", "created": "Mon, 26 Aug 2019 10:57:39 GMT"}, {"version": "v3", "created": "Sun, 12 Apr 2020 07:02:59 GMT"}, {"version": "v4", "created": "Wed, 13 May 2020 03:19:26 GMT"}], "update_date": "2020-05-14", "authors_parsed": [["Zhong", "Peixiang", ""], ["Wang", "Di", ""], ["Miao", "Chunyan", ""]]}, {"id": "1907.07836", "submitter": "Ming Dong", "authors": "Ming Dong, Jian Shi, QingXin Shi", "title": "Multi-year Long-term Load Forecast for Area Distribution Feeders based\n  on Selective Sequence Learning", "comments": "22 pages, 9 figures", "journal-ref": null, "doi": "10.1016/j.energy.2020.118209", "report-no": null, "categories": "eess.SY cs.LG cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Long-term load forecast (LTLF) for area distribution feeders is one of the\nmost critical tasks frequently performed in electric distribution utility\ncompanies. For a specific planning area, cost-effective system upgrades can\nonly be planned out based on accurate feeder LTLF results. In our previous\nresearch, we established a unique sequence prediction method which has the\ntremendous advantage of combining area top-down, feeder bottom-up and\nmulti-year historical data all together for forecast and achieved a superior\nperformance over various traditional methods by real-world tests. However, the\nprevious method only focused on the forecast of the next one-year. In our\ncurrent work, we significantly improved this method: the forecast can now be\nextended to a multi-year forecast window in the future; unsupervised learning\ntechniques are used to group feeders by their load composition features to\nimprove accuracy; we also propose a novel selective sequence learning mechanism\nwhich uses Gated Recurrent Unit network to not only learn how to predict\nsequence values but also learn to select the best-performing sequential\nconfiguration for each individual feeder. The proposed method was tested on an\nactual urban distribution system in West Canada. It was compared with\ntraditional methods and our previous sequence prediction method. It\ndemonstrates the best forecasting performance as well as the possibility of\nusing sequence prediction models for multi-year component-level load forecast.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jul 2019 01:47:55 GMT"}, {"version": "v2", "created": "Fri, 19 Jul 2019 03:17:37 GMT"}, {"version": "v3", "created": "Wed, 1 Jul 2020 04:38:45 GMT"}], "update_date": "2020-07-02", "authors_parsed": [["Dong", "Ming", ""], ["Shi", "Jian", ""], ["Shi", "QingXin", ""]]}, {"id": "1907.07843", "submitter": "Hui Ye", "authors": "Hui Ye, Xiaopeng Ma, Qingfeng Pan, Huaqiang Fang, Hang Xiang, Tongzhen\n  Shao", "title": "An Adaptive Approach for Anomaly Detector Selection and Fine-Tuning in\n  Time Series", "comments": "7 pages, 5 figures it has been accepted to DLP-KDD 2019 workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The anomaly detection of time series is a hotspot of time series data mining.\nThe own characteristics of different anomaly detectors determine the abnormal\ndata that they are good at. There is no detector can be optimizing in all types\nof anomalies. Moreover, it still has difficulties in industrial production due\nto problems such as a single detector can't be optimized at different time\nwindows of the same time series. This paper proposes an adaptive model based on\ntime series characteristics and selecting appropriate detector and run-time\nparameters for anomaly detection, which is called ATSDLN(Adaptive Time Series\nDetector Learning Network). We take the time series as the input of the model,\nand learn the time series representation through FCN. In order to realize the\nadaptive selection of detectors and run-time parameters according to the input\ntime series, the outputs of FCN are the inputs of two sub-networks: the\ndetector selection network and the run-time parameters selection network. In\naddition, the way that the variable layer width design of the parameter\nselection sub-network and the introduction of transfer learning make the model\nbe with more expandability. Through experiments, it is found that ATSDLN can\nselect appropriate anomaly detector and run-time parameters, and have strong\nexpandability, which can quickly transfer. We investigate the performance of\nATSDLN in public data sets, our methods outperform other methods in most cases\nwith higher effect and better adaptation. We also show experimental results on\npublic data sets to demonstrate how model structure and transfer learning\naffect the effectiveness.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jul 2019 02:19:20 GMT"}], "update_date": "2019-07-19", "authors_parsed": [["Ye", "Hui", ""], ["Ma", "Xiaopeng", ""], ["Pan", "Qingfeng", ""], ["Fang", "Huaqiang", ""], ["Xiang", "Hang", ""], ["Shao", "Tongzhen", ""]]}, {"id": "1907.07844", "submitter": "Yu-Xiong Wang", "authors": "Yu-Xiong Wang, Deva Ramanan, Martial Hebert", "title": "Growing a Brain: Fine-Tuning by Increasing Model Capacity", "comments": "CVPR", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  CNNs have made an undeniable impact on computer vision through the ability to\nlearn high-capacity models with large annotated training sets. One of their\nremarkable properties is the ability to transfer knowledge from a large source\ndataset to a (typically smaller) target dataset. This is usually accomplished\nthrough fine-tuning a fixed-size network on new target data. Indeed, virtually\nevery contemporary visual recognition system makes use of fine-tuning to\ntransfer knowledge from ImageNet. In this work, we analyze what components and\nparameters change during fine-tuning, and discover that increasing model\ncapacity allows for more natural model adaptation through fine-tuning. By\nmaking an analogy to developmental learning, we demonstrate that \"growing\" a\nCNN with additional units, either by widening existing layers or deepening the\noverall network, significantly outperforms classic fine-tuning approaches. But\nin order to properly grow a network, we show that newly-added units must be\nappropriately normalized to allow for a pace of learning that is consistent\nwith existing units. We empirically validate our approach on several benchmark\ndatasets, producing state-of-the-art results.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jul 2019 02:20:18 GMT"}], "update_date": "2019-07-19", "authors_parsed": [["Wang", "Yu-Xiong", ""], ["Ramanan", "Deva", ""], ["Hebert", "Martial", ""]]}, {"id": "1907.07847", "submitter": "Qisheng Wang", "authors": "Qisheng Wang and Qichao Wang", "title": "Prioritized Guidance for Efficient Multi-Agent Reinforcement Learning\n  Exploration", "comments": "Theequations (7)-(10) in the paper are incorrectly derived, and need\n  to be withdrawn and revised in many places", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Exploration efficiency is a challenging problem in multi-agent reinforcement\nlearning (MARL), as the policy learned by confederate MARL depends on the\ncollaborative approach among multiple agents. Another important problem is the\nless informative reward restricts the learning speed of MARL compared with the\ninformative label in supervised learning. In this work, we leverage on a novel\ncommunication method to guide MARL to accelerate exploration and propose a\npredictive network to forecast the reward of current state-action pair and use\nthe guidance learned by the predictive network to modify the reward function.\nAn improved prioritized experience replay is employed to better take advantage\nof the different knowledge learned by different agents which utilizes\nTime-difference (TD) error more effectively. Experimental results demonstrates\nthat the proposed algorithm outperforms existing methods in cooperative\nmulti-agent environments. We remark that this algorithm can be extended to\nsupervised learning to speed up its training.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jul 2019 02:27:55 GMT"}, {"version": "v2", "created": "Fri, 19 Jul 2019 07:34:39 GMT"}, {"version": "v3", "created": "Wed, 25 Dec 2019 07:05:14 GMT"}], "update_date": "2019-12-30", "authors_parsed": [["Wang", "Qisheng", ""], ["Wang", "Qichao", ""]]}, {"id": "1907.07863", "submitter": "Saeed Anwar", "authors": "Saeed Anwar, Chongyi Li", "title": "Diving Deeper into Underwater Image Enhancement: A Survey", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  The powerful representation capacity of deep learning has made it inevitable\nfor the underwater image enhancement community to employ its potential. The\nexploration of deep underwater image enhancement networks is increasing over\ntime, and hence; a comprehensive survey is the need of the hour. In this paper,\nour main aim is two-fold, 1): to provide a comprehensive and in-depth survey of\nthe deep learning-based underwater image enhancement, which covers various\nperspectives ranging from algorithms to open issues, and 2): to conduct a\nqualitative and quantitative comparison of the deep algorithms on diverse\ndatasets to serve as a benchmark, which has been barely explored before. To be\nspecific, we first introduce the underwater image formation models, which are\nthe base of training data synthesis and design of deep networks, and also\nhelpful for understanding the process of underwater image degradation. Then, we\nreview deep underwater image enhancement algorithms, and a glimpse of some of\nthe aspects of the current networks is presented including network\narchitecture, network parameters, training data, loss function, and training\nconfigurations. We also summarize the evaluation metrics and underwater image\ndatasets. Following that, a systematically experimental comparison is carried\nout to analyze the robustness and effectiveness of deep algorithms. Meanwhile,\nwe point out the shortcomings of current benchmark datasets and evaluation\nmetrics. Finally, we discuss several unsolved open issues and suggest possible\nresearch directions. We hope that all efforts done in this paper might serve as\na comprehensive reference for future research and call for the development of\ndeep learning-based underwater image enhancement.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jul 2019 06:45:25 GMT"}], "update_date": "2019-07-19", "authors_parsed": [["Anwar", "Saeed", ""], ["Li", "Chongyi", ""]]}, {"id": "1907.07872", "submitter": "Euntae Choi", "authors": "Euntae Choi, Kyungmi Lee, Kiyoung Choi", "title": "Autoencoder-Based Incremental Class Learning without Retraining on Old\n  Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Incremental class learning, a scenario in continual learning context where\nclasses and their training data are sequentially and disjointedly observed,\nchallenges a problem widely known as catastrophic forgetting. In this work, we\npropose a novel incremental class learning method that can significantly reduce\nmemory overhead compared to previous approaches. Apart from conventional\nclassification scheme using softmax, our model bases on an autoencoder to\nextract prototypes for given inputs so that no change in its output unit is\nrequired. It stores only the mean of prototypes per class to perform\nmetric-based classification, unlike rehearsal approaches which rely on large\nmemory or generative model. To mitigate catastrophic forgetting, regularization\nmethods are applied on our model when a new task is encountered. We evaluate\nour method by experimenting on CIFAR-100 and CUB-200-2011 and show that its\nperformance is comparable to the state-of-the-art method with much lower\nadditional memory cost.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jul 2019 04:51:25 GMT"}], "update_date": "2019-07-19", "authors_parsed": [["Choi", "Euntae", ""], ["Lee", "Kyungmi", ""], ["Choi", "Kiyoung", ""]]}, {"id": "1907.07890", "submitter": "Julia Schulte", "authors": "Julia Schulte, Daniel Staps, Alexander Lampe", "title": "A feasibility study of deep neural networks for the recognition of\n  banknotes regarding central bank requirements", "comments": "6 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper contains a feasibility study of deep neural networks for the\nclassification of Euro banknotes with respect to requirements of central banks\non the ATM and high speed sorting industry. Instead of concentrating on the\naccuracy for a large number of classes as in the famous ImageNet Challenge we\nfocus thus on conditions with few classes and the requirement of rejection of\nimages belonging clearly to neither of the trained classes (i.e. classification\nin a so-called 0-class). These special requirements are part of frameworks\ndefined by central banks as the European Central Bank and are met by current\nATMs and high speed sorting machines. We also consider training and\nclassification time on state of the art GPU hardware. The study concentrates on\nthe banknote recognition whereas banknote class dependent authenticity and\nfitness checks are a topic of its own which is not considered in this work.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jul 2019 06:29:31 GMT"}, {"version": "v2", "created": "Mon, 7 Oct 2019 08:21:15 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Schulte", "Julia", ""], ["Staps", "Daniel", ""], ["Lampe", "Alexander", ""]]}, {"id": "1907.07897", "submitter": "Karlis Freivalds", "authors": "K\\=arlis Freivalds, Em\\=ils Ozoli\\c{n}\\v{s}, Agris \\v{S}ostaks", "title": "Neural Shuffle-Exchange Networks -- Sequence Processing in O(n log n)\n  Time", "comments": "33rd Conference on Neural Information Processing Systems (NeurIPS\n  2019), Vancouver, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A key requirement in sequence to sequence processing is the modeling of long\nrange dependencies. To this end, a vast majority of the state-of-the-art models\nuse attention mechanism which is of O($n^2$) complexity that leads to slow\nexecution for long sequences. We introduce a new Shuffle-Exchange neural\nnetwork model for sequence to sequence tasks which have O(log n) depth and O(n\nlog n) total complexity. We show that this model is powerful enough to infer\nefficient algorithms for common algorithmic benchmarks including sorting,\naddition and multiplication. We evaluate our architecture on the challenging\nLAMBADA question answering dataset and compare it with the state-of-the-art\nmodels which use attention. Our model achieves competitive accuracy and scales\nto sequences with more than a hundred thousand of elements. We are confident\nthat the proposed model has the potential for building more efficient\narchitectures for processing large interrelated data in language modeling,\nmusic generation and other application domains.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jul 2019 06:47:48 GMT"}, {"version": "v2", "created": "Tue, 23 Jul 2019 10:38:03 GMT"}, {"version": "v3", "created": "Mon, 28 Oct 2019 10:02:27 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Freivalds", "K\u0101rlis", ""], ["Ozoli\u0146\u0161", "Em\u012bls", ""], ["\u0160ostaks", "Agris", ""]]}, {"id": "1907.07904", "submitter": "Giuseppe Marra", "authors": "Francesco Giannini and Giuseppe Marra and Michelangelo Diligenti and\n  Marco Maggini and Marco Gori", "title": "On the relation between Loss Functions and T-Norms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning has been shown to achieve impressive results in several domains\nlike computer vision and natural language processing. A key element of this\nsuccess has been the development of new loss functions, like the popular\ncross-entropy loss, which has been shown to provide faster convergence and to\nreduce the vanishing gradient problem in very deep structures. While the\ncross-entropy loss is usually justified from a probabilistic perspective, this\npaper shows an alternative and more direct interpretation of this loss in terms\nof t-norms and their associated generator functions, and derives a general\nrelation between loss functions and t-norms. In particular, the presented work\nshows intriguing results leading to the development of a novel class of loss\nfunctions. These losses can be exploited in any supervised learning task and\nwhich could lead to faster convergence rates that the commonly employed\ncross-entropy loss.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jul 2019 06:58:36 GMT"}], "update_date": "2019-07-19", "authors_parsed": [["Giannini", "Francesco", ""], ["Marra", "Giuseppe", ""], ["Diligenti", "Michelangelo", ""], ["Maggini", "Marco", ""], ["Gori", "Marco", ""]]}, {"id": "1907.07945", "submitter": "Yang Song", "authors": "Yang Song and Chenlin Meng and Stefano Ermon", "title": "MintNet: Building Invertible Neural Networks with Masked Convolutions", "comments": "NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new way of constructing invertible neural networks by combining\nsimple building blocks with a novel set of composition rules. This leads to a\nrich set of invertible architectures, including those similar to ResNets.\nInversion is achieved with a locally convergent iterative procedure that is\nparallelizable and very fast in practice. Additionally, the determinant of the\nJacobian can be computed analytically and efficiently, enabling their\ngenerative use as flow models. To demonstrate their flexibility, we show that\nour invertible neural networks are competitive with ResNets on MNIST and\nCIFAR-10 classification. When trained as generative models, our invertible\nnetworks achieve competitive likelihoods on MNIST, CIFAR-10 and ImageNet 32x32,\nwith bits per dimension of 0.98, 3.32 and 4.06 respectively.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jul 2019 09:24:55 GMT"}, {"version": "v2", "created": "Tue, 29 Oct 2019 07:20:45 GMT"}], "update_date": "2019-10-30", "authors_parsed": [["Song", "Yang", ""], ["Meng", "Chenlin", ""], ["Ermon", "Stefano", ""]]}, {"id": "1907.07951", "submitter": "Mohammad Eslami", "authors": "Mohammad Eslami, Christiane Neuschaefer-Rube, Antoine Serrurier", "title": "Automatic vocal tract landmark localization from midsagittal MRI data", "comments": null, "journal-ref": null, "doi": "10.1038/s41598-020-58103-6", "report-no": null, "categories": "eess.IV cs.CV cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The various speech sounds of a language are obtained by varying the shape and\nposition of the articulators surrounding the vocal tract. Analyzing their\nvariations is crucial for understanding speech production, diagnosing speech\ndisorders and planning therapy. Identifying key anatomical landmarks of these\nstructures on medical images is a pre-requisite for any quantitative analysis\nand the rising amount of data generated in the field calls for an automatic\nsolution. The challenge lies in the high inter- and intra-speaker variability,\nthe mutual interaction between the articulators and the moderate quality of the\nimages. This study addresses this issue for the first time and tackles it by\nmeans by means of Deep Learning. It proposes a dedicated network architecture\nnamed Flat-net and its performance are evaluated and compared with eleven\nstate-of-the-art methods from the literature. The dataset contains midsagittal\nanatomical Magnetic Resonance Images for 9 speakers sustaining 62 articulations\nwith 21 annotated anatomical landmarks per image. Results show that the\nFlat-net approach outperforms the former methods, leading to an overall Root\nMean Square Error of 3.6 pixels/0.36 cm obtained in a leave-one-out procedure\nover the speakers. The implementation codes are also shared publicly on GitHub.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jul 2019 09:38:09 GMT"}, {"version": "v2", "created": "Thu, 9 Jan 2020 16:37:46 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Eslami", "Mohammad", ""], ["Neuschaefer-Rube", "Christiane", ""], ["Serrurier", "Antoine", ""]]}, {"id": "1907.07972", "submitter": "Zulfat Miftahutdinov", "authors": "Zulfat Miftahutdinov and Elena Tutubalina", "title": "Deep Neural Models for Medical Concept Normalization in User-Generated\n  Texts", "comments": "This is preprint of the paper \"Deep Neural Models for Medical Concept\n  Normalization in User-Generated Texts\" to be published at ACL 2019 - 57th\n  Annual Meeting of the Association for Computational Linguistics, Proceedings\n  of the Student Research Workshop", "journal-ref": null, "doi": "10.18653/v1/P19-2055", "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we consider the medical concept normalization problem, i.e.,\nthe problem of mapping a health-related entity mention in a free-form text to a\nconcept in a controlled vocabulary, usually to the standard thesaurus in the\nUnified Medical Language System (UMLS). This is a challenging task since\nmedical terminology is very different when coming from health care\nprofessionals or from the general public in the form of social media texts. We\napproach it as a sequence learning problem with powerful neural networks such\nas recurrent neural networks and contextualized word representation models\ntrained to obtain semantic representations of social media expressions. Our\nexperimental evaluation over three different benchmarks shows that neural\narchitectures leverage the semantic meaning of the entity mention and\nsignificantly outperform an existing state of the art models.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jul 2019 10:36:03 GMT"}], "update_date": "2019-12-17", "authors_parsed": [["Miftahutdinov", "Zulfat", ""], ["Tutubalina", "Elena", ""]]}, {"id": "1907.08006", "submitter": "Hristo Inouzhe Valdes", "authors": "Eustasio del Barrio and Hristo Inouzhe and Jean-Michel Loubes and\n  Carlos Matr\\'an and Agust\\'in Mayo-\\'Iscar", "title": "optimalFlow: Optimal-transport approach to flow cytometry gating and\n  population matching", "comments": "26 pages, 6 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data obtained from Flow Cytometry present pronounced variability due to\nbiological and technical reasons. Biological variability is a well-known\nphenomenon produced by measurements on different individuals, with different\ncharacteristics such as illness, age, sex, etc. The use of different settings\nfor measurement, the variation of the conditions during experiments and the\ndifferent types of flow cytometers are some of the technical causes of\nvariability. This mixture of sources of variability makes the use of supervised\nmachine learning for identification of cell populations difficult. The present\nwork is conceived as a combination of strategies to facilitate the task of\nsupervised gating.\n  We propose $optimalFlowTemplates$, based on a similarity distance and\n$\\text{Wasserstein barycenters}$, which clusters cytometries and produces\nprototype cytometries for the different groups. We show that supervised\nlearning, restricted to the new groups, performs better than the same\ntechniques applied to the whole collection. We also present\n$optimalFlowClassification$, which uses a database of gated cytometries and\noptimalFlowTemplates to assign cell types to a new cytometry. We show that this\nprocedure can outperform state of the art techniques in the proposed datasets.\nOur code is freely available as $optimalFlow$ a Bioconductor R package at\nhttps://bioconductor.org/packages/optimalFlow.\n  optimalFlowTemplates+optimalFlowClassification addresses the problem of using\nsupervised learning while accounting for biological and technical variability.\nOur methodology provides a robust automated gating workflow that handles the\nintrinsic variability of flow cytometry data well. Our main innovation is the\nmethodology itself and the optimal-transport techniques that we apply to flow\ncytometry analysis.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jul 2019 11:54:47 GMT"}, {"version": "v2", "created": "Wed, 29 Apr 2020 11:28:03 GMT"}], "update_date": "2020-04-30", "authors_parsed": [["del Barrio", "Eustasio", ""], ["Inouzhe", "Hristo", ""], ["Loubes", "Jean-Michel", ""], ["Matr\u00e1n", "Carlos", ""], ["Mayo-\u00cdscar", "Agust\u00edn", ""]]}, {"id": "1907.08009", "submitter": "Neslihan Kose Cihangir", "authors": "Neslihan Kose, Okan Kopuklu, Alexander Unnervik, Gerhard Rigoll", "title": "Real-Time Driver State Monitoring Using a CNN Based Spatio-Temporal\n  Approach", "comments": "Accepted for publication by the IEEE Intelligent Transportation\n  Systems Conference (ITSC 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many road accidents occur due to distracted drivers. Today, driver monitoring\nis essential even for the latest autonomous vehicles to alert distracted\ndrivers in order to take over control of the vehicle in case of emergency. In\nthis paper, a spatio-temporal approach is applied to classify drivers'\ndistraction level and movement decisions using convolutional neural networks\n(CNNs). We approach this problem as action recognition to benefit from temporal\ninformation in addition to spatial information. Our approach relies on features\nextracted from sparsely selected frames of an action using a pre-trained\nBN-Inception network. Experiments show that our approach outperforms the\nstate-of-the art results on the Distracted Driver Dataset (96.31%), with an\naccuracy of 99.10% for 10-class classification while providing real-time\nperformance. We also analyzed the impact of fusion using RGB and optical flow\nmodalities with a very recent data level fusion strategy. The results on the\nDistracted Driver and Brain4Cars datasets show that fusion of these modalities\nfurther increases the accuracy.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jul 2019 12:03:12 GMT"}], "update_date": "2019-07-19", "authors_parsed": [["Kose", "Neslihan", ""], ["Kopuklu", "Okan", ""], ["Unnervik", "Alexander", ""], ["Rigoll", "Gerhard", ""]]}, {"id": "1907.08020", "submitter": "Aleksei Tiulpin", "authors": "Aleksei Tiulpin and Simo Saarakkala", "title": "Automatic Grading of Individual Knee Osteoarthritis Features in Plain\n  Radiographs using Deep Convolutional Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knee osteoarthritis (OA) is the most common musculoskeletal disease in the\nworld. In primary healthcare, knee OA is diagnosed using clinical examination\nand radiographic assessment. Osteoarthritis Research Society International\n(OARSI) atlas of OA radiographic features allows to perform independent\nassessment of knee osteophytes, joint space narrowing and other knee features.\nThis provides a fine-grained OA severity assessment of the knee, compared to\nthe gold standard and most commonly used Kellgren-Lawrence (KL) composite\nscore. However, both OARSI and KL grading systems suffer from moderate\ninter-rater agreement, and therefore, the use of computer-aided methods could\nhelp to improve the reliability of the process. In this study, we developed a\nrobust, automatic method to simultaneously predict KL and OARSI grades in knee\nradiographs. Our method is based on Deep Learning and leverages an ensemble of\ndeep residual networks with 50 layers, squeeze-excitation and ResNeXt blocks.\nHere, we used transfer learning from ImageNet with a fine-tuning on the whole\nOsteoarthritis Initiative (OAI) dataset. An independent testing of our model\nwas performed on the whole Multicenter Osteoarthritis Study (MOST) dataset. Our\nmulti-task method yielded Cohen's kappa coefficients of 0.82 for KL-grade and\n0.79, 0.84, 0.94, 0.83, 0.84, 0.90 for femoral osteophytes, tibial osteophytes\nand joint space narrowing for lateral and medial compartments respectively.\nFurthermore, our method yielded area under the ROC curve of 0.98 and average\nprecision of 0.98 for detecting the presence of radiographic OA (KL $\\geq 2$),\nwhich is better than the current state-of-the-art.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jul 2019 12:52:32 GMT"}], "update_date": "2019-07-19", "authors_parsed": [["Tiulpin", "Aleksei", ""], ["Saarakkala", "Simo", ""]]}, {"id": "1907.08027", "submitter": "Johan Ferret", "authors": "Johan Ferret, Rapha\\\"el Marinier, Matthieu Geist and Olivier Pietquin", "title": "Self-Attentional Credit Assignment for Transfer in Reinforcement\n  Learning", "comments": "21 pages, 10 figures, 3 tables (accepted as an oral presentation at\n  the Learning Transferable Skills workshop, NeurIPS 2019)", "journal-ref": "International Joint Conference on Artificial Intelligence. 29\n  (2020) 2655-2661", "doi": "10.24963/ijcai.2020/368", "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The ability to transfer knowledge to novel environments and tasks is a\nsensible desiderata for general learning agents. Despite the apparent promises,\ntransfer in RL is still an open and little exploited research area. In this\npaper, we take a brand-new perspective about transfer: we suggest that the\nability to assign credit unveils structural invariants in the tasks that can be\ntransferred to make RL more sample-efficient. Our main contribution is SECRET,\na novel approach to transfer learning for RL that uses a backward-view credit\nassignment mechanism based on a self-attentive architecture. Two aspects are\nkey to its generality: it learns to assign credit as a separate offline\nsupervised process and exclusively modifies the reward function. Consequently,\nit can be supplemented by transfer methods that do not modify the reward\nfunction and it can be plugged on top of any RL algorithm.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jul 2019 13:02:16 GMT"}, {"version": "v2", "created": "Fri, 22 Nov 2019 14:22:44 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Ferret", "Johan", ""], ["Marinier", "Rapha\u00ebl", ""], ["Geist", "Matthieu", ""], ["Pietquin", "Olivier", ""]]}, {"id": "1907.08040", "submitter": "Hanten Chang", "authors": "Hanten Chang and Katsuya Futagami", "title": "Convolutional Reservoir Computing for World Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, reinforcement learning models have achieved great success,\ncompleting complex tasks such as mastering Go and other games with higher\nscores than human players. Many of these models collect considerable data on\nthe tasks and improve accuracy by extracting visual and time-series features\nusing convolutional neural networks (CNNs) and recurrent neural networks,\nrespectively. However, these networks have very high computational costs\nbecause they need to be trained by repeatedly using a large volume of past\nplaying data. In this study, we propose a novel practical approach called\nreinforcement learning with convolutional reservoir computing (RCRC) model. The\nRCRC model has several desirable features: 1. it can extract visual and\ntime-series features very fast because it uses random fixed-weight CNN and the\nreservoir computing model; 2. it does not require the training data to be\nstored because it extracts features without training and decides action with\nevolution strategy. Furthermore, the model achieves state of the art score in\nthe popular reinforcement learning task. Incredibly, we find the random\nweight-fixed simple networks like only one dense layer network can also reach\nhigh score in the RL task.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jul 2019 13:16:39 GMT"}], "update_date": "2019-07-19", "authors_parsed": [["Chang", "Hanten", ""], ["Futagami", "Katsuya", ""]]}, {"id": "1907.08059", "submitter": "Andreas Grammenos", "authors": "Andreas Grammenos, Rodrigo Mendoza-Smith, Jon Crowcroft, Cecilia\n  Mascolo", "title": "Federated Principal Component Analysis", "comments": "36 pages, 13 figures, 1 table. Accepted for publication at Neural\n  Information Processing Systems (NeurIPS 2020), Vancouver, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a federated, asynchronous, and $(\\varepsilon,\n\\delta)$-differentially private algorithm for PCA in the memory-limited\nsetting. Our algorithm incrementally computes local model updates using a\nstreaming procedure and adaptively estimates its $r$ leading principal\ncomponents when only $\\mathcal{O}(dr)$ memory is available with $d$ being the\ndimensionality of the data. We guarantee differential privacy via an\ninput-perturbation scheme in which the covariance matrix of a dataset\n$\\mathbf{X} \\in \\mathbb{R}^{d \\times n}$ is perturbed with a non-symmetric\nrandom Gaussian matrix with variance in\n$\\mathcal{O}\\left(\\left(\\frac{d}{n}\\right)^2 \\log d \\right)$, thus improving\nupon the state-of-the-art. Furthermore, contrary to previous federated or\ndistributed algorithms for PCA, our algorithm is also invariant to permutations\nin the incoming data, which provides robustness against straggler or failed\nnodes. Numerical simulations show that, while using limited-memory, our\nalgorithm exhibits performance that closely matches or outperforms traditional\nnon-federated algorithms, and in the absence of communication latency, it\nexhibits attractive horizontal scalability.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jul 2019 14:05:51 GMT"}, {"version": "v2", "created": "Mon, 15 Jun 2020 02:57:19 GMT"}, {"version": "v3", "created": "Thu, 22 Oct 2020 19:10:41 GMT"}], "update_date": "2020-10-26", "authors_parsed": [["Grammenos", "Andreas", ""], ["Mendoza-Smith", "Rodrigo", ""], ["Crowcroft", "Jon", ""], ["Mascolo", "Cecilia", ""]]}, {"id": "1907.08082", "submitter": "Adam Golinski", "authors": "Adam Goli\\'nski, Frank Wood, Tom Rainforth", "title": "Amortized Monte Carlo Integration", "comments": "Awarded Best Paper Honourable Mention at International Conference on\n  Machine Learning (ICML) 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current approaches to amortizing Bayesian inference focus solely on\napproximating the posterior distribution. Typically, this approximation is, in\nturn, used to calculate expectations for one or more target functions - a\ncomputational pipeline which is inefficient when the target function(s) are\nknown upfront. In this paper, we address this inefficiency by introducing AMCI,\na method for amortizing Monte Carlo integration directly. AMCI operates\nsimilarly to amortized inference but produces three distinct amortized\nproposals, each tailored to a different component of the overall expectation\ncalculation. At runtime, samples are produced separately from each amortized\nproposal, before being combined to an overall estimate of the expectation. We\nshow that while existing approaches are fundamentally limited in the level of\naccuracy they can achieve, AMCI can theoretically produce arbitrarily small\nerrors for any integrable target function using only a single sample from each\nproposal at runtime. We further show that it is able to empirically outperform\nthe theoretically optimal self-normalized importance sampler on a number of\nexample problems. Furthermore, AMCI allows not only for amortizing over\ndatasets but also amortizing over target functions.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jul 2019 14:36:48 GMT"}], "update_date": "2019-07-19", "authors_parsed": [["Goli\u0144ski", "Adam", ""], ["Wood", "Frank", ""], ["Rainforth", "Tom", ""]]}, {"id": "1907.08087", "submitter": "Jesse Read", "authors": "Jesse Read and Luca Martino", "title": "Probabilistic Regressor Chains with Monte Carlo Methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A large number and diversity of techniques have been offered in the\nliterature in recent years for solving multi-label classification tasks,\nincluding classifier chains where predictions are cascaded to other models as\nadditional features. The idea of extending this chaining methodology to\nmulti-output regression has already been suggested and trialed: regressor\nchains. However, this has so-far been limited to greedy inference and has\nprovided relatively poor results compared to individual models, and of limited\napplicability. In this paper we identify and discuss the main limitations,\nincluding an analysis of different base models, loss functions, explainability,\nand other desiderata of real-world applications. To overcome the identified\nlimitations we study and develop methods for regressor chains. In particular we\npresent a sequential Monte Carlo scheme in the framework of a probabilistic\nregressor chain, and we show it can be effective, flexible and useful in\nseveral types of data. We place regressor chains in context in general terms of\nmulti-output learning with continuous outputs, and in doing this shed\nadditional light on classifier chains.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jul 2019 14:41:25 GMT"}], "update_date": "2019-07-19", "authors_parsed": [["Read", "Jesse", ""], ["Martino", "Luca", ""]]}, {"id": "1907.08100", "submitter": "Yoshihiro Hirose", "authors": "Yoshihiro Hirose", "title": "Least Angle Regression in Tangent Space and LASSO for Generalized Linear\n  Models", "comments": "PDFLaTeX, 17 pages with 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This study proposes sparse estimation methods for the generalized linear\nmodels, which run one of least angle regression (LARS) and least absolute\nshrinkage and selection operator (LASSO) in the tangent space of the manifold\nof the statistical model. This study approximates the statistical model and\nsubsequently uses exact calculations. LARS was proposed as an efficient\nalgorithm for parameter estimation and variable selection for the normal linear\nmodel. The LARS algorithm is described in terms of Euclidean geometry regarding\nthe correlation as the metric of the parameter space. Since the LARS algorithm\nonly works in Euclidean space, we transform a manifold of the statistical model\ninto the tangent space at the origin. In the generalized linear regression,\nthis transformation allows us to run the original LARS algorithm for the\ngeneralized linear models. The proposed methods are efficient and perform well.\nReal-data analysis indicates that the proposed methods output similar results\nto that of the $l_1$-regularized maximum likelihood estimation for the\naforementioned models. Numerical experiments reveal that our methods work well\nand they may be better than the $l_1$-regularization in generalization,\nparameter estimation, and model selection.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jul 2019 14:58:18 GMT"}, {"version": "v2", "created": "Wed, 4 Mar 2020 03:03:52 GMT"}, {"version": "v3", "created": "Fri, 17 Jul 2020 08:33:29 GMT"}], "update_date": "2020-07-20", "authors_parsed": [["Hirose", "Yoshihiro", ""]]}, {"id": "1907.08120", "submitter": "Francesco Ventura", "authors": "Tania Cerquitelli, Stefano Proto, Francesco Ventura, Daniele Apiletti,\n  Elena Baralis", "title": "Automating concept-drift detection by self-evaluating predictive model\n  degradation", "comments": "5 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  A key aspect of automating predictive machine learning entails the capability\nof properly triggering the update of the trained model. To this aim, suitable\nautomatic solutions to self-assess the prediction quality and the data\ndistribution drift between the original training set and the new data have to\nbe devised. In this paper, we propose a novel methodology to automatically\ndetect prediction-quality degradation of machine learning models due to\nclass-based concept drift, i.e., when new data contains samples that do not fit\nthe set of class labels known by the currently-trained predictive model.\nExperiments on synthetic and real-world public datasets show the effectiveness\nof the proposed methodology in automatically detecting and describing concept\ndrift caused by changes in the class-label data distributions.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jul 2019 15:50:37 GMT"}], "update_date": "2019-07-19", "authors_parsed": [["Cerquitelli", "Tania", ""], ["Proto", "Stefano", ""], ["Ventura", "Francesco", ""], ["Apiletti", "Daniele", ""], ["Baralis", "Elena", ""]]}, {"id": "1907.08127", "submitter": "Yishai Shimoni", "authors": "Ehud Karavani, Peter Bak, Yishai Shimoni", "title": "A discriminative approach for finding and characterizing positivity\n  violations using decision trees", "comments": "10 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The assumption of positivity in causal inference (also known as common\nsupport and co-variate overlap) is necessary to obtain valid causal estimates.\nTherefore, confirming it holds in a given dataset is an important first step of\nany causal analysis. Most common methods to date are insufficient for\ndiscovering non-positivity, as they do not scale for modern high-dimensional\ncovariate spaces, or they cannot pinpoint the subpopulation violating\npositivity. To overcome these issues, we suggest to harness decision trees for\ndetecting violations. By dividing the covariate space into mutually exclusive\nregions, each with maximized homogeneity of treatment groups, decision trees\ncan be used to automatically detect subspaces violating positivity. By\naugmenting the method with an additional random forest model, we can quantify\nthe robustness of the violation within each subspace. This solution is scalable\nand provides an interpretable characterization of the subspaces in which\nviolations occur. We provide a visualization of the stratification rules that\ndefine each subpopulation, combined with the severity of positivity violation\nwithin it. We also provide an interactive version of the visualization that\nallows a deeper dive into the properties of each subspace.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jul 2019 16:06:30 GMT"}], "update_date": "2019-07-19", "authors_parsed": [["Karavani", "Ehud", ""], ["Bak", "Peter", ""], ["Shimoni", "Yishai", ""]]}, {"id": "1907.08138", "submitter": "Lisa Ehrlinger", "authors": "Lisa Ehrlinger, Elisa Rusz, Wolfram W\\\"o{\\ss}", "title": "A Survey of Data Quality Measurement and Monitoring Tools", "comments": "35 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  High-quality data is key to interpretable and trustworthy data analytics and\nthe basis for meaningful data-driven decisions. In practical scenarios, data\nquality is typically associated with data preprocessing, profiling, and\ncleansing for subsequent tasks like data integration or data analytics.\nHowever, from a scientific perspective, a lot of research has been published\nabout the measurement (i.e., the detection) of data quality issues and\ndifferent generally applicable data quality dimensions and metrics have been\ndiscussed. In this work, we close the gap between research into data quality\nmeasurement and practical implementations by investigating the functional scope\nof current data quality tools. With a systematic search, we identified 667\nsoftware tools dedicated to \"data quality\", from which we evaluated 13 tools\nwith respect to three functionality areas: (1) data profiling, (2) data quality\nmeasurement in terms of metrics, and (3) continuous data quality monitoring. We\nselected the evaluated tools with regard to pre-defined exclusion criteria to\nensure that they are domain-independent, provide the investigated functions,\nand are evaluable freely or as trial. This survey aims at a comprehensive\noverview on state-of-the-art data quality tools and reveals potential for their\nfunctional enhancement. Additionally, the results allow a critical discussion\non concepts, which are widely accepted in research, but hardly implemented in\nany tool observed, for example, generally applicable data quality metrics.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jul 2019 16:19:52 GMT"}], "update_date": "2019-07-19", "authors_parsed": [["Ehrlinger", "Lisa", ""], ["Rusz", "Elisa", ""], ["W\u00f6\u00df", "Wolfram", ""]]}, {"id": "1907.08175", "submitter": "Terrance DeVries", "authors": "Terrance DeVries, Adriana Romero, Luis Pineda, Graham W. Taylor,\n  Michal Drozdzal", "title": "On the Evaluation of Conditional GANs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conditional Generative Adversarial Networks (cGANs) are finding increasingly\nwidespread use in many application domains. Despite outstanding progress,\nquantitative evaluation of such models often involves multiple distinct metrics\nto assess different desirable properties, such as image quality, conditional\nconsistency, and intra-conditioning diversity. In this setting, model\nbenchmarking becomes a challenge, as each metric may indicate a different\n\"best\" model. In this paper, we propose the Frechet Joint Distance (FJD), which\nis defined as the Frechet distance between joint distributions of images and\nconditioning, allowing it to implicitly capture the aforementioned properties\nin a single metric. We conduct proof-of-concept experiments on a controllable\nsynthetic dataset, which consistently highlight the benefits of FJD when\ncompared to currently established metrics. Moreover, we use the newly\nintroduced metric to compare existing cGAN-based models for a variety of\nconditioning modalities (e.g. class labels, object masks, bounding boxes,\nimages, and text captions). We show that FJD can be used as a promising single\nmetric for cGAN benchmarking and model selection. Code can be found at\nhttps://github.com/facebookresearch/fjd.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jul 2019 17:41:57 GMT"}, {"version": "v2", "created": "Fri, 27 Sep 2019 21:02:23 GMT"}, {"version": "v3", "created": "Tue, 24 Dec 2019 02:53:54 GMT"}], "update_date": "2019-12-25", "authors_parsed": [["DeVries", "Terrance", ""], ["Romero", "Adriana", ""], ["Pineda", "Luis", ""], ["Taylor", "Graham W.", ""], ["Drozdzal", "Michal", ""]]}, {"id": "1907.08196", "submitter": "Tanya Schmah", "authors": "Kevin Raina, Uladzimir Yahorau, Tanya Schmah", "title": "Exploiting bilateral symmetry in brain lesion segmentation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Brain lesions, including stroke and tumours, have a high degree of\nvariability in terms of location, size, intensity and form, making automatic\nsegmentation difficult. We propose an improvement to existing segmentation\nmethods by exploiting the bilateral quasi-symmetry of healthy brains, which\nbreaks down when lesions are present. Specifically, we use nonlinear\nregistration of a neuroimage to a reflected version of itself (\"reflective\nregistration\") to determine for each voxel its homologous (corresponding) voxel\nin the other hemisphere. A patch around the homologous voxel is added as a set\nof new features to the segmentation algorithm. To evaluate this method, we\nimplemented two different CNN-based multimodal MRI stroke lesion segmentation\nalgorithms, and then augmented them by adding extra symmetry features using the\nreflective registration method described above. For each architecture, we\ncompared the performance with and without symmetry augmentation, on the SISS\nTraining dataset of the Ischemic Stroke Lesion Segmentation Challenge (ISLES)\n2015 challenge. Using affine reflective registration improves performance over\nbaseline, but nonlinear reflective registration gives significantly better\nresults: an improvement in Dice coefficient of 13 percentage points over\nbaseline for one architecture and 9 points for the other. We argue for the\nbroad applicability of adding symmetric features to existing segmentation\nalgorithms, specifically using nonlinear, template-free methods.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jul 2019 13:42:22 GMT"}], "update_date": "2019-07-22", "authors_parsed": [["Raina", "Kevin", ""], ["Yahorau", "Uladzimir", ""], ["Schmah", "Tanya", ""]]}, {"id": "1907.08199", "submitter": "Daniel Angelov", "authors": "Daniel Angelov, Yordan Hristov, Michael Burke, Subramanian Ramamoorthy", "title": "Composing Diverse Policies for Temporally Extended Tasks", "comments": "arXiv admin note: substantial text overlap with arXiv:1906.10099", "journal-ref": null, "doi": "10.1109/LRA.2020.2972794", "report-no": null, "categories": "cs.RO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robot control policies for temporally extended and sequenced tasks are often\ncharacterized by discontinuous switches between different local dynamics. These\nchange-points are often exploited in hierarchical motion planning to build\napproximate models and to facilitate the design of local, region-specific\ncontrollers. However, it becomes combinatorially challenging to implement such\na pipeline for complex temporally extended tasks, especially when the\nsub-controllers work on different information streams, time scales and action\nspaces. In this paper, we introduce a method that can compose diverse policies\ncomprising motion planning trajectories, dynamic motion primitives and neural\nnetwork controllers. We introduce a global goal scoring estimator that uses\nlocal, per-motion primitive dynamics models and corresponding activation\nstate-space sets to sequence diverse policies in a locally optimal fashion. We\nuse expert demonstrations to convert what is typically viewed as a\ngradient-based learning process into a planning process without explicitly\nspecifying pre- and post-conditions. We first illustrate the proposed framework\nusing an MDP benchmark to showcase robustness to action and model dynamics\nmismatch, and then with a particularly complex physical gear assembly task,\nsolved on a PR2 robot. We show that the proposed approach successfully\ndiscovers the optimal sequence of controllers and solves both tasks\nefficiently.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jul 2019 14:28:46 GMT"}, {"version": "v2", "created": "Tue, 1 Oct 2019 15:31:18 GMT"}, {"version": "v3", "created": "Mon, 17 Feb 2020 16:54:08 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Angelov", "Daniel", ""], ["Hristov", "Yordan", ""], ["Burke", "Michael", ""], ["Ramamoorthy", "Subramanian", ""]]}, {"id": "1907.08220", "submitter": "Mojtaba Moattari", "authors": "Mojtaba Moattari, Mohammad Hassan Moradi, Reza Boostani", "title": "Modified swarm-based metaheuristics enhance Gradient Descent\n  initialization performance: Application for EEG spatial filtering", "comments": "10 tables, 32 references, 11 formulas. arXiv admin note: text overlap\n  with arXiv:1209.4115 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gradient Descent (GD) approximators often fail in the solution space with\nmultiple scales of convexities, i.e., in subspace learning and neural network\nscenarios. To handle that, one solution is to run GD multiple times from\ndifferent randomized initial states and select the best solution over all\nexperiments. However, this idea is proved impractical in plenty of cases. Even\nSwarm-based optimizers like Particle Swarm Optimization (PSO) or Imperialistic\nCompetitive Algorithm (ICA), as commonly used GD initializers, have failed to\nfind optimal solutions in some applications. In this paper, Swarm-based\noptimizers like ICA and PSO are modified by a new optimization framework to\nimprove GD optimization performance. This improvement is for applications with\nhigh number of convex localities in multiple scales. Performance of the\nproposed method is analyzed in a nonlinear subspace filtering objective\nfunction over EEG data. The proposed metaheuristic outperforms commonly used\nbaseline optimizers as GD initializers in both the EEG classification accuracy\nand EEG loss function fitness. The optimizers have been also compared to each\nother in some of CEC 2014 benchmark functions, where again our method\noutperforms other algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 13 Jun 2019 07:50:16 GMT"}, {"version": "v2", "created": "Wed, 6 May 2020 16:44:02 GMT"}], "update_date": "2020-05-07", "authors_parsed": [["Moattari", "Mojtaba", ""], ["Moradi", "Mohammad Hassan", ""], ["Boostani", "Reza", ""]]}, {"id": "1907.08225", "submitter": "Kristian Hartikainen", "authors": "Kristian Hartikainen, Xinyang Geng, Tuomas Haarnoja, Sergey Levine", "title": "Dynamical Distance Learning for Semi-Supervised and Unsupervised Skill\n  Discovery", "comments": "11+6 pages, 6+2 figures, last two authors (Tuomas Haarnoja, Sergey\n  Levine) advised equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning requires manual specification of a reward function to\nlearn a task. While in principle this reward function only needs to specify the\ntask goal, in practice reinforcement learning can be very time-consuming or\neven infeasible unless the reward function is shaped so as to provide a smooth\ngradient towards a successful outcome. This shaping is difficult to specify by\nhand, particularly when the task is learned from raw observations, such as\nimages. In this paper, we study how we can automatically learn dynamical\ndistances: a measure of the expected number of time steps to reach a given goal\nstate from any other state. These dynamical distances can be used to provide\nwell-shaped reward functions for reaching new goals, making it possible to\nlearn complex tasks efficiently. We show that dynamical distances can be used\nin a semi-supervised regime, where unsupervised interaction with the\nenvironment is used to learn the dynamical distances, while a small amount of\npreference supervision is used to determine the task goal, without any manually\nengineered reward function or goal examples. We evaluate our method both on a\nreal-world robot and in simulation. We show that our method can learn to turn a\nvalve with a real-world 9-DoF hand, using raw image observations and just ten\npreference labels, without any other supervision. Videos of the learned skills\ncan be found on the project website:\nhttps://sites.google.com/view/dynamical-distance-learning.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jul 2019 18:07:47 GMT"}, {"version": "v2", "created": "Wed, 25 Sep 2019 18:25:04 GMT"}, {"version": "v3", "created": "Sat, 16 Nov 2019 14:15:46 GMT"}, {"version": "v4", "created": "Fri, 14 Feb 2020 10:16:54 GMT"}], "update_date": "2020-02-17", "authors_parsed": [["Hartikainen", "Kristian", ""], ["Geng", "Xinyang", ""], ["Haarnoja", "Tuomas", ""], ["Levine", "Sergey", ""]]}, {"id": "1907.08226", "submitter": "Stefano Sarao Mannelli", "authors": "Stefano Sarao Mannelli, Giulio Biroli, Chiara Cammarota, Florent\n  Krzakala, and Lenka Zdeborov\\'a", "title": "Who is Afraid of Big Bad Minima? Analysis of Gradient-Flow in a Spiked\n  Matrix-Tensor Model", "comments": "9 pages, 4 figures + appendix. Appears in Proceedings of the Advances\n  in Neural Information Processing Systems 2019 (NeurIPS 2019)", "journal-ref": "Advances in Neural Information Processing Systems, pp. 8676-8686.\n  2019", "doi": null, "report-no": null, "categories": "cs.LG cond-mat.dis-nn math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gradient-based algorithms are effective for many machine learning tasks, but\ndespite ample recent effort and some progress, it often remains unclear why\nthey work in practice in optimising high-dimensional non-convex functions and\nwhy they find good minima instead of being trapped in spurious ones.\n  Here we present a quantitative theory explaining this behaviour in a spiked\nmatrix-tensor model.\n  Our framework is based on the Kac-Rice analysis of stationary points and a\nclosed-form analysis of gradient-flow originating from statistical physics. We\nshow that there is a well defined region of parameters where the gradient-flow\nalgorithm finds a good global minimum despite the presence of exponentially\nmany spurious local minima.\n  We show that this is achieved by surfing on saddles that have strong negative\ndirection towards the global minima, a phenomenon that is connected to a\nBBP-type threshold in the Hessian describing the critical points of the\nlandscapes.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jul 2019 18:11:24 GMT"}, {"version": "v2", "created": "Mon, 22 Jul 2019 13:43:09 GMT"}, {"version": "v3", "created": "Mon, 20 Jan 2020 15:08:26 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Mannelli", "Stefano Sarao", ""], ["Biroli", "Giulio", ""], ["Cammarota", "Chiara", ""], ["Krzakala", "Florent", ""], ["Zdeborov\u00e1", "Lenka", ""]]}, {"id": "1907.08259", "submitter": "Mukul Bhutani", "authors": "Prakhar Gupta, Vinayshekhar Bannihatti Kumar, Mukul Bhutani, Alan W\n  Black", "title": "WriterForcing: Generating more interesting story endings", "comments": "Accepted in ACL workshop on Storytelling 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of generating interesting endings for stories. Neural\ngenerative models have shown promising results for various text generation\nproblems. Sequence to Sequence (Seq2Seq) models are typically trained to\ngenerate a single output sequence for a given input sequence. However, in the\ncontext of a story, multiple endings are possible. Seq2Seq models tend to\nignore the context and generate generic and dull responses. Very few works have\nstudied generating diverse and interesting story endings for a given story\ncontext. In this paper, we propose models which generate more diverse and\ninteresting outputs by 1) training models to focus attention on important\nkeyphrases of the story, and 2) promoting generation of non-generic words. We\nshow that the combination of the two leads to more diverse and interesting\nendings.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jul 2019 19:29:29 GMT"}], "update_date": "2019-07-22", "authors_parsed": [["Gupta", "Prakhar", ""], ["Kumar", "Vinayshekhar Bannihatti", ""], ["Bhutani", "Mukul", ""], ["Black", "Alan W", ""]]}, {"id": "1907.08268", "submitter": "Ari Seff", "authors": "Ari Seff, Wenda Zhou, Farhan Damani, Abigail Doyle, Ryan P. Adams", "title": "Discrete Object Generation with Reversible Inductive Construction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The success of generative modeling in continuous domains has led to a surge\nof interest in generating discrete data such as molecules, source code, and\ngraphs. However, construction histories for these discrete objects are\ntypically not unique and so generative models must reason about intractably\nlarge spaces in order to learn. Additionally, structured discrete domains are\noften characterized by strict constraints on what constitutes a valid object\nand generative models must respect these requirements in order to produce\nuseful novel samples. Here, we present a generative model for discrete objects\nemploying a Markov chain where transitions are restricted to a set of local\noperations that preserve validity. Building off of generative interpretations\nof denoising autoencoders, the Markov chain alternates between producing 1) a\nsequence of corrupted objects that are valid but not from the data\ndistribution, and 2) a learned reconstruction distribution that attempts to fix\nthe corruptions while also preserving validity. This approach constrains the\ngenerative model to only produce valid objects, requires the learner to only\ndiscover local modifications to the objects, and avoids marginalization over an\nunknown and potentially large space of construction histories. We evaluate the\nproposed approach on two highly structured discrete domains, molecules and\nLaman graphs, and find that it compares favorably to alternative methods at\ncapturing distributional statistics for a host of semantically relevant\nmetrics.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jul 2019 20:17:27 GMT"}, {"version": "v2", "created": "Thu, 31 Oct 2019 17:51:12 GMT"}], "update_date": "2019-11-01", "authors_parsed": [["Seff", "Ari", ""], ["Zhou", "Wenda", ""], ["Damani", "Farhan", ""], ["Doyle", "Abigail", ""], ["Adams", "Ryan P.", ""]]}, {"id": "1907.08288", "submitter": "Canyi Lu", "authors": "Canyi Lu and Pan Zhou", "title": "Exact Recovery of Tensor Robust Principal Component Analysis under\n  Linear Transforms", "comments": "arXiv admin note: text overlap with arXiv:1804.03728; text overlap\n  with arXiv:1311.6182 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work studies the Tensor Robust Principal Component Analysis (TRPCA)\nproblem, which aims to exactly recover the low-rank and sparse components from\ntheir sum. Our model is motivated by the recently proposed linear transforms\nbased tensor-tensor product and tensor SVD. We define a new transforms depended\ntensor rank and the corresponding tensor nuclear norm. Then we solve the TRPCA\nproblem by convex optimization whose objective is a weighted combination of the\nnew tensor nuclear norm and the $\\ell_1$-norm. In theory, we show that under\ncertain incoherence conditions, the convex program exactly recovers the\nunderlying low-rank and sparse components. It is of great interest that our new\nTRPCA model generalizes existing works. In particular, if the studied tensor\nreduces to a matrix, our TRPCA model reduces to the known matrix RPCA. Our new\nTRPCA which is allowed to use general linear transforms can be regarded as an\nextension of our former TRPCA work which uses the discrete Fourier transform.\nBut their proof of the recovery guarantee is different. Numerical experiments\nverify our results and the application on image recovery demonstrates the\nsuperiority of our method.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jul 2019 19:05:15 GMT"}], "update_date": "2019-07-22", "authors_parsed": [["Lu", "Canyi", ""], ["Zhou", "Pan", ""]]}, {"id": "1907.08292", "submitter": "Bruno Gavranovi\\'c", "authors": "Bruno Gavranovi\\'c", "title": "Compositional Deep Learning", "comments": "56 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.CT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks have become an increasingly popular tool for solving many\nreal-world problems. They are a general framework for differentiable\noptimization which includes many other machine learning approaches as special\ncases. In this thesis we build a category-theoretic formalism around a class of\nneural networks exemplified by CycleGAN. CycleGAN is a collection of neural\nnetworks, closed under composition, whose inductive bias is increased by\nenforcing composition invariants, i.e. cycle-consistencies. Inspired by\nFunctorial Data Migration, we specify the interconnection of these networks\nusing a categorical schema, and network instances as set-valued functors on\nthis schema. We also frame neural network architectures, datasets, models, and\na number of other concepts in a categorical setting and thus show a special\nclass of functors, rather than functions, can be learned using gradient\ndescent. We use the category-theoretic framework to conceive a novel neural\nnetwork architecture whose goal is to learn the task of object insertion and\nobject deletion in images with unpaired data. We test the architecture on three\ndifferent datasets and obtain promising results.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jul 2019 10:21:15 GMT"}], "update_date": "2019-07-22", "authors_parsed": [["Gavranovi\u0107", "Bruno", ""]]}, {"id": "1907.08294", "submitter": "Yuki Saito", "authors": "Yuki Saito, Shinnosuke Takamichi, Hiroshi Saruwatari", "title": "DNN-based Speaker Embedding Using Subjective Inter-speaker Similarity\n  for Multi-speaker Modeling in Speech Synthesis", "comments": "6 pages, 7 figures, accepted for The 10th ISCA Speech Synthesis\n  Workshop (SSW10)", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes novel algorithms for speaker embedding using subjective\ninter-speaker similarity based on deep neural networks (DNNs). Although\nconventional DNN-based speaker embedding such as a $d$-vector can be applied to\nmulti-speaker modeling in speech synthesis, it does not correlate with the\nsubjective inter-speaker similarity and is not necessarily appropriate speaker\nrepresentation for open speakers whose speech utterances are not included in\nthe training data. We propose two training algorithms for DNN-based speaker\nembedding model using an inter-speaker similarity matrix obtained by\nlarge-scale subjective scoring. One is based on similarity vector embedding and\ntrains the model to predict a vector of the similarity matrix as speaker\nrepresentation. The other is based on similarity matrix embedding and trains\nthe model to minimize the squared Frobenius norm between the similarity matrix\nand the Gram matrix of $d$-vectors, i.e., the inter-speaker similarity derived\nfrom the $d$-vectors. We crowdsourced the inter-speaker similarity scores of\n153 Japanese female speakers, and the experimental results demonstrate that our\nalgorithms learn speaker embedding that is highly correlated with the\nsubjective similarity. We also apply the proposed speaker embedding to\nmulti-speaker modeling in DNN-based speech synthesis and reveal that the\nproposed similarity vector embedding improves synthetic speech quality for open\nspeakers whose speech utterances are unseen during the training.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jul 2019 09:11:35 GMT"}], "update_date": "2019-07-22", "authors_parsed": [["Saito", "Yuki", ""], ["Takamichi", "Shinnosuke", ""], ["Saruwatari", "Hiroshi", ""]]}, {"id": "1907.08307", "submitter": "Martin Wistuba", "authors": "Martin Wistuba", "title": "XferNAS: Transfer Neural Architecture Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The term Neural Architecture Search (NAS) refers to the automatic\noptimization of network architectures for a new, previously unknown task. Since\ntesting an architecture is computationally very expensive, many optimizers need\ndays or even weeks to find suitable architectures. However, this search time\ncan be significantly reduced if knowledge from previous searches on different\ntasks is reused. In this work, we propose a generally applicable framework that\nintroduces only minor changes to existing optimizers to leverage this feature.\nAs an example, we select an existing optimizer and demonstrate the complexity\nof the integration of the framework as well as its impact. In experiments on\nCIFAR-10 and CIFAR-100, we observe a reduction in the search time from 200 to\nonly 6 GPU days, a speed up by a factor of 33. In addition, we observe new\nrecords of 1.99 and 14.06 for NAS optimizers on the CIFAR benchmarks,\nrespectively. In a separate study, we analyze the impact of the amount of\nsource and target data. Empirically, we demonstrate that the proposed framework\ngenerally gives better results and, in the worst case, is just as good as the\nunmodified optimizer.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jul 2019 22:05:49 GMT"}], "update_date": "2019-07-22", "authors_parsed": [["Wistuba", "Martin", ""]]}, {"id": "1907.08313", "submitter": "Angelo Oddi", "authors": "Angelo Oddi, Riccardo Rasconi, Emilio Cartoni, Gabriele Sartor,\n  Gianluca Baldassarre, Vieri Giuliano Santucci", "title": "Learning High-Level Planning Symbols from Intrinsically Motivated\n  Experience", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In symbolic planning systems, the knowledge on the domain is commonly\nprovided by an expert. Recently, an automatic abstraction procedure has been\nproposed in the literature to create a Planning Domain Definition Language\n(PDDL) representation, which is the most widely used input format for most\noff-the-shelf automated planners, starting from `options', a data structure\nused to represent actions within the hierarchical reinforcement learning\nframework. We propose an architecture that potentially removes the need for\nhuman intervention. In particular, the architecture first acquires options in a\nfully autonomous fashion on the basis of open-ended learning, then builds a\nPDDL domain based on symbols and operators that can be used to accomplish\nuser-defined goals through a standard PDDL planner.\n  We start from an implementation of the above mentioned procedure tested on a\nset of benchmark domains in which a humanoid robot can change the state of some\nobjects through direct interaction with the environment. We then investigate\nsome critical aspects of the information abstraction process that have been\nobserved, and propose an extension that mitigates such criticalities, in\nparticular by analysing the type of classifiers that allow a suitable grounding\nof symbols.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jul 2019 22:42:35 GMT"}], "update_date": "2019-07-22", "authors_parsed": [["Oddi", "Angelo", ""], ["Rasconi", "Riccardo", ""], ["Cartoni", "Emilio", ""], ["Sartor", "Gabriele", ""], ["Baldassarre", "Gianluca", ""], ["Santucci", "Vieri Giuliano", ""]]}, {"id": "1907.08320", "submitter": "Bruna Maciel-Pearson", "authors": "Bruna G. Maciel-Pearson, Samet Akcay, Amir Atapour-Abarghouei,\n  Christopher Holder and Toby P. Breckon", "title": "Multi-Task Regression-based Learning for Autonomous Unmanned Aerial\n  Vehicle Flight Control within Unstructured Outdoor Environments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.CV cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Increased growth in the global Unmanned Aerial Vehicles (UAV) (drone)\nindustry has expanded possibilities for fully autonomous UAV applications. A\nparticular application which has in part motivated this research is the use of\nUAV in wide area search and surveillance operations in unstructured outdoor\nenvironments. The critical issue with such environments is the lack of\nstructured features that could aid in autonomous flight, such as road lines or\npaths. In this paper, we propose an End-to-End Multi-Task Regression-based\nLearning approach capable of defining flight commands for navigation and\nexploration under the forest canopy, regardless of the presence of trails or\nadditional sensors (i.e. GPS). Training and testing are performed using a\nsoftware in the loop pipeline which allows for a detailed evaluation against\nstate-of-the-art pose estimation techniques. Our extensive experiments\ndemonstrate that our approach excels in performing dense exploration within the\nrequired search perimeter, is capable of covering wider search regions,\ngeneralises to previously unseen and unexplored environments and outperforms\ncontemporary state-of-the-art techniques.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jul 2019 23:45:05 GMT"}], "update_date": "2019-07-22", "authors_parsed": [["Maciel-Pearson", "Bruna G.", ""], ["Akcay", "Samet", ""], ["Atapour-Abarghouei", "Amir", ""], ["Holder", "Christopher", ""], ["Breckon", "Toby P.", ""]]}, {"id": "1907.08321", "submitter": "Isaac Kamlish", "authors": "Isaac Kamlish, Isaac Bentata Chocron, Nicholas McCarthy", "title": "SentiMATE: Learning to play Chess through Natural Language Processing", "comments": "Accepted for Oral at the AIIDE-19 Workshop on Artificial Intelligence\n  for Strategy Games", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present SentiMATE, a novel end-to-end Deep Learning model for Chess,\nemploying Natural Language Processing that aims to learn an effective\nevaluation function assessing move quality. This function is pre-trained on the\nsentiment of commentary associated with the training moves and is used to guide\nand optimize the agent's game-playing decision making. The contributions of\nthis research are three-fold: we build and put forward both a classifier which\nextracts commentary describing the quality of Chess moves in vast commentary\ndatasets, and a Sentiment Analysis model trained on Chess commentary to\naccurately predict the quality of said moves, to then use those predictions to\nevaluate the optimal next move of a Chess agent. Both classifiers achieve over\n90 % classification accuracy. Lastly, we present a Chess engine, SentiMATE,\nwhich evaluates Chess moves based on a pre-trained sentiment evaluation\nfunction. Our results exhibit strong evidence to support our initial hypothesis\n- \"Can Natural Language Processing be used to train a novel and sample\nefficient evaluation function in Chess Engines?\" - as we integrate our\nevaluation function into modern Chess engines and play against agents with\ntraditional Chess move evaluation functions, beating both random agents and a\nDeepChess implementation at a level-one search depth - representing the number\nof moves a traditional Chess agent (employing the alpha-beta search algorithm)\nlooks ahead in order to evaluate a given chess state.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jul 2019 23:48:21 GMT"}, {"version": "v2", "created": "Mon, 22 Jul 2019 09:08:47 GMT"}, {"version": "v3", "created": "Wed, 25 Sep 2019 18:57:47 GMT"}], "update_date": "2019-09-27", "authors_parsed": [["Kamlish", "Isaac", ""], ["Chocron", "Isaac Bentata", ""], ["McCarthy", "Nicholas", ""]]}, {"id": "1907.08322", "submitter": "Xuling Wang", "authors": "Shirly Wang, Matthew B. A. McDermott, Geeticka Chauhan, Michael C.\n  Hughes, Tristan Naumann, Marzyeh Ghassemi", "title": "MIMIC-Extract: A Data Extraction, Preprocessing, and Representation\n  Pipeline for MIMIC-III", "comments": null, "journal-ref": null, "doi": "10.1145/3368555.3384469", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robust machine learning relies on access to data that can be used with\nstandardized frameworks in important tasks and the ability to develop models\nwhose performance can be reasonably reproduced. In machine learning for\nhealthcare, the community faces reproducibility challenges due to a lack of\npublicly accessible data and a lack of standardized data processing frameworks.\nWe present MIMIC-Extract, an open-source pipeline for transforming raw\nelectronic health record (EHR) data for critical care patients contained in the\npublicly-available MIMIC-III database into dataframes that are directly usable\nin common machine learning pipelines. MIMIC-Extract addresses three primary\nchallenges in making complex health records data accessible to the broader\nmachine learning community. First, it provides standardized data processing\nfunctions, including unit conversion, outlier detection, and aggregating\nsemantically equivalent features, thus accounting for duplication and reducing\nmissingness. Second, it preserves the time series nature of clinical data and\ncan be easily integrated into clinically actionable prediction tasks in machine\nlearning for health. Finally, it is highly extensible so that other researchers\nwith related questions can easily use the same pipeline. We demonstrate the\nutility of this pipeline by showcasing several benchmark tasks and baseline\nresults.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jul 2019 00:13:52 GMT"}, {"version": "v2", "created": "Wed, 19 Aug 2020 17:38:36 GMT"}], "update_date": "2020-08-20", "authors_parsed": [["Wang", "Shirly", ""], ["McDermott", "Matthew B. A.", ""], ["Chauhan", "Geeticka", ""], ["Hughes", "Michael C.", ""], ["Naumann", "Tristan", ""], ["Ghassemi", "Marzyeh", ""]]}, {"id": "1907.08325", "submitter": "Shusen Liu", "authors": "Shusen Liu, Di Wang, Dan Maljovec, Rushil Anirudh, Jayaraman J.\n  Thiagarajan, Sam Ade Jacobs, Brian C. Van Essen, David Hysom, Jae-Seung Yeom,\n  Jim Gaffney, Luc Peterson, Peter B. Robinson, Harsh Bhatia, Valerio Pascucci,\n  Brian K. Spears and Peer-Timo Bremer", "title": "Scalable Topological Data Analysis and Visualization for Evaluating\n  Data-Driven Models in Scientific Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.HC cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the rapid adoption of machine learning techniques for large-scale\napplications in science and engineering comes the convergence of two grand\nchallenges in visualization. First, the utilization of black box models (e.g.,\ndeep neural networks) calls for advanced techniques in exploring and\ninterpreting model behaviors. Second, the rapid growth in computing has\nproduced enormous datasets that require techniques that can handle millions or\nmore samples. Although some solutions to these interpretability challenges have\nbeen proposed, they typically do not scale beyond thousands of samples, nor do\nthey provide the high-level intuition scientists are looking for. Here, we\npresent the first scalable solution to explore and analyze high-dimensional\nfunctions often encountered in the scientific data analysis pipeline. By\ncombining a new streaming neighborhood graph construction, the corresponding\ntopology computation, and a novel data aggregation scheme, namely topology\naware datacubes, we enable interactive exploration of both the topological and\nthe geometric aspect of high-dimensional data. Following two use cases from\nhigh-energy-density (HED) physics and computational biology, we demonstrate how\nthese capabilities have led to crucial new insights in both applications.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jul 2019 00:37:39 GMT"}], "update_date": "2019-07-22", "authors_parsed": [["Liu", "Shusen", ""], ["Wang", "Di", ""], ["Maljovec", "Dan", ""], ["Anirudh", "Rushil", ""], ["Thiagarajan", "Jayaraman J.", ""], ["Jacobs", "Sam Ade", ""], ["Van Essen", "Brian C.", ""], ["Hysom", "David", ""], ["Yeom", "Jae-Seung", ""], ["Gaffney", "Jim", ""], ["Peterson", "Luc", ""], ["Robinson", "Peter B.", ""], ["Bhatia", "Harsh", ""], ["Pascucci", "Valerio", ""], ["Spears", "Brian K.", ""], ["Bremer", "Peer-Timo", ""]]}, {"id": "1907.08333", "submitter": "Abdul Karim", "authors": "Abdul Karim, Jaspreet Singh, Avinash Mishra, Abdollah Dehzangi, M. A.\n  Hakim Newton, and Abdul Sattar", "title": "Toxicity Prediction by Multimodal Deep Learning", "comments": "Preprint Version", "journal-ref": "2019 Pacific Rim Knowledge Acquisition Workshop", "doi": null, "report-no": null, "categories": "cs.LG physics.chem-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Prediction of toxicity levels of chemical compounds is an important issue in\nQuantitative Structure-Activity Relationship (QSAR) modeling. Although toxicity\nprediction has achieved significant progress in recent times through deep\nlearning, prediction accuracy levels obtained by even very recent methods are\nnot yet very high. We propose a multimodal deep learning method using multiple\nheterogeneous neural network types and data representations. We represent\nchemical compounds by strings, images, and numerical features. We train fully\nconnected, convolutional, and recurrent neural networks and their ensembles.\nEach data representation or neural network type has its own strengths and\nweaknesses. Our motivation is to obtain a collective performance that could go\nbeyond individual performance of each data representation or each neural\nnetwork type. On a standard toxicity benchmark, our proposed method obtains\nsignificantly better accuracy levels than that by the state-of-the-art toxicity\nprediction methods.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jul 2019 01:32:02 GMT"}], "update_date": "2019-07-22", "authors_parsed": [["Karim", "Abdul", ""], ["Singh", "Jaspreet", ""], ["Mishra", "Avinash", ""], ["Dehzangi", "Abdollah", ""], ["Newton", "M. A. Hakim", ""], ["Sattar", "Abdul", ""]]}, {"id": "1907.08334", "submitter": "Harrison Nguyen", "authors": "Eddie Anderson, Harrison Nguyen", "title": "When can we improve on sample average approximation for stochastic\n  optimization?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore the performance of sample average approximation in comparison with\nseveral other methods for stochastic optimization when there is information\navailable on the underlying true probability distribution. The methods we\nevaluate are (a) bagging; (b) kernel smoothing; (c) maximum likelihood\nestimation (MLE); and (d) a Bayesian approach. We use two test sets, the first\nhas a quadratic objective function allowing for very different types of\ninteraction between the random component and the univariate decision variable.\nHere the sample average approximation is remarkably effective and only\nconsistently outperformed by a Bayesian approach. The second test set is a\nportfolio optimization problem in which we use different covariance structures\nfor a set of 5 stocks. Here bagging, MLE and a Bayesian approach all do well.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jul 2019 01:33:11 GMT"}], "update_date": "2019-07-22", "authors_parsed": [["Anderson", "Eddie", ""], ["Nguyen", "Harrison", ""]]}, {"id": "1907.08338", "submitter": "Yuma Koizumi", "authors": "Yuma Koizumi, Shoichiro Saito, Masataka Yamaguchi, Shin Murata and\n  Noboru Harada", "title": "Batch Uniformization for Minimizing Maximum Anomaly Score of DNN-based\n  Anomaly Detection in Sounds", "comments": "5 pages, to appear in IEEE WASPAA 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Use of an autoencoder (AE) as a normal model is a state-of-the-art technique\nfor unsupervised-anomaly detection in sounds (ADS). The AE is trained to\nminimize the sample mean of the anomaly score of normal sounds in a mini-batch.\nOne problem with this approach is that the anomaly score of rare-normal sounds\nbecomes higher than that of frequent-normal sounds, because the sample mean is\nstrongly affected by frequent-normal samples, resulting in preferentially\ndecreasing the anomaly score of frequent-normal samples. To decrease anomaly\nscores for both frequent- and rare-normal sounds, we propose batch\nuniformization, a training method for unsupervised-ADS for minimizing a\nweighted average of the anomaly score on each sample in a mini-batch. We used\nthe reciprocal of the probabilistic density of each sample as the weight, more\nintuitively, a large weight is given for rare-normal sounds. Such a weight\nworks to give a constant anomaly score for both frequent- and rare-normal\nsounds. Since the probabilistic density is unknown, we estimate it by using the\nkernel density estimation on each training mini-batch. Verification- and\nobjective-experiments show that the proposed batch uniformization improves the\nperformance of unsupervised-ADS.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jul 2019 01:58:20 GMT"}], "update_date": "2019-07-22", "authors_parsed": [["Koizumi", "Yuma", ""], ["Saito", "Shoichiro", ""], ["Yamaguchi", "Masataka", ""], ["Murata", "Shin", ""], ["Harada", "Noboru", ""]]}, {"id": "1907.08340", "submitter": "Shengxin Zha", "authors": "Laura Sevilla-Lara, Shengxin Zha, Zhicheng Yan, Vedanuj Goswami, Matt\n  Feiszli, Lorenzo Torresani", "title": "Only Time Can Tell: Discovering Temporal Data for Temporal Modeling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding temporal information and how the visual world changes over time\nis a fundamental ability of intelligent systems. In video understanding,\ntemporal information is at the core of many current challenges, including\ncompression, efficient inference, motion estimation or summarization. However,\nin current video datasets it has been observed that action classes can often be\nrecognized without any temporal information from a single frame of video. As a\nresult, both benchmarking and training in these datasets may give an\nunintentional advantage to models with strong image understanding capabilities,\nas opposed to those with strong temporal understanding. In this paper we\naddress this problem head on by identifying action classes where temporal\ninformation is actually necessary to recognize them and call these \"temporal\nclasses\". Selecting temporal classes using a computational method would bias\nthe process. Instead, we propose a methodology based on a simple and effective\nhuman annotation experiment. We remove just the temporal information by\nshuffling frames in time and measure if the action can still be recognized.\nClasses that cannot be recognized when frames are not in order are included in\nthe temporal Dataset. We observe that this set is statistically different from\nother static classes, and that performance in it correlates with a network's\nability to capture temporal information. Thus we use it as a benchmark on\ncurrent popular networks, which reveals a series of interesting facts. We also\nexplore the effect of training on the temporal dataset, and observe that this\nleads to better generalization in unseen classes, demonstrating the need for\nmore temporal data. We hope that the proposed dataset of temporal categories\nwill help guide future research in temporal modeling for better video\nunderstanding.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jul 2019 02:00:23 GMT"}, {"version": "v2", "created": "Tue, 29 Oct 2019 19:20:18 GMT"}], "update_date": "2019-10-31", "authors_parsed": [["Sevilla-Lara", "Laura", ""], ["Zha", "Shengxin", ""], ["Yan", "Zhicheng", ""], ["Goswami", "Vedanuj", ""], ["Feiszli", "Matt", ""], ["Torresani", "Lorenzo", ""]]}, {"id": "1907.08349", "submitter": "Yiwen Han", "authors": "Xiaofei Wang and Yiwen Han and Victor C.M. Leung and Dusit Niyato and\n  Xueqiang Yan and Xu Chen", "title": "Convergence of Edge Computing and Deep Learning: A Comprehensive Survey", "comments": "To be published in IEEE Communications Surveys and Tutorials", "journal-ref": "IEEE Communications Surveys & Tutorials, vol. 22, no. 2, pp.\n  869-904, Secondquarter 2020", "doi": "10.1109/COMST.2020.2970550", "report-no": null, "categories": "cs.NI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ubiquitous sensors and smart devices from factories and communities are\ngenerating massive amounts of data, and ever-increasing computing power is\ndriving the core of computation and services from the cloud to the edge of the\nnetwork. As an important enabler broadly changing people's lives, from face\nrecognition to ambitious smart factories and cities, developments of artificial\nintelligence (especially deep learning, DL) based applications and services are\nthriving. However, due to efficiency and latency issues, the current cloud\ncomputing service architecture hinders the vision of \"providing artificial\nintelligence for every person and every organization at everywhere\". Thus,\nunleashing DL services using resources at the network edge near the data\nsources has emerged as a desirable solution. Therefore, edge intelligence,\naiming to facilitate the deployment of DL services by edge computing, has\nreceived significant attention. In addition, DL, as the representative\ntechnique of artificial intelligence, can be integrated into edge computing\nframeworks to build intelligent edge for dynamic, adaptive edge maintenance and\nmanagement. With regard to mutually beneficial edge intelligence and\nintelligent edge, this paper introduces and discusses: 1) the application\nscenarios of both; 2) the practical implementation methods and enabling\ntechnologies, namely DL training and inference in the customized edge computing\nframework; 3) challenges and future trends of more pervasive and fine-grained\nintelligence. We believe that by consolidating information scattered across the\ncommunication, networking, and DL areas, this survey can help readers to\nunderstand the connections between enabling technologies while promoting\nfurther discussions on the fusion of edge intelligence and intelligent edge,\ni.e., Edge DL.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jul 2019 02:36:52 GMT"}, {"version": "v2", "created": "Thu, 26 Dec 2019 14:10:31 GMT"}, {"version": "v3", "created": "Tue, 28 Jan 2020 14:37:43 GMT"}], "update_date": "2020-06-02", "authors_parsed": [["Wang", "Xiaofei", ""], ["Han", "Yiwen", ""], ["Leung", "Victor C. M.", ""], ["Niyato", "Dusit", ""], ["Yan", "Xueqiang", ""], ["Chen", "Xu", ""]]}, {"id": "1907.08350", "submitter": "Yusuke Tanaka", "authors": "Yusuke Tanaka, Toshiyuki Tanaka, Tomoharu Iwata, Takeshi Kurashima,\n  Maya Okawa, Yasunori Akagi, Hiroyuki Toda", "title": "Spatially Aggregated Gaussian Processes with Multivariate Areal Outputs", "comments": "Accepted at NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a probabilistic model for inferring the multivariate function from\nmultiple areal data sets with various granularities. Here, the areal data are\nobserved not at location points but at regions. Existing regression-based\nmodels can only utilize the sufficiently fine-grained auxiliary data sets on\nthe same domain (e.g., a city). With the proposed model, the functions for\nrespective areal data sets are assumed to be a multivariate dependent Gaussian\nprocess (GP) that is modeled as a linear mixing of independent latent GPs.\nSharing of latent GPs across multiple areal data sets allows us to effectively\nestimate the spatial correlation for each areal data set; moreover it can\neasily be extended to transfer learning across multiple domains. To handle the\nmultivariate areal data, we design an observation model with a spatial\naggregation process for each areal data set, which is an integral of the mixed\nGP over the corresponding region. By deriving the posterior GP, we can predict\nthe data value at any location point by considering the spatial correlations\nand the dependences between areal data sets, simultaneously. Our experiments on\nreal-world data sets demonstrate that our model can 1) accurately refine\ncoarse-grained areal data, and 2) offer performance improvements by using the\nareal data sets from multiple domains.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jul 2019 02:45:50 GMT"}, {"version": "v2", "created": "Tue, 7 Jan 2020 11:08:57 GMT"}], "update_date": "2020-01-08", "authors_parsed": [["Tanaka", "Yusuke", ""], ["Tanaka", "Toshiyuki", ""], ["Iwata", "Tomoharu", ""], ["Kurashima", "Takeshi", ""], ["Okawa", "Maya", ""], ["Akagi", "Yasunori", ""], ["Toda", "Hiroyuki", ""]]}, {"id": "1907.08356", "submitter": "Kaiwen Shen", "authors": "Shuqiang Lu, Lingyun Ying, Wenjie Lin, Yu Wang, Meining Nie, Kaiwen\n  Shen, Lu Liu, Haixin Duan", "title": "New Era of Deeplearning-Based Malware Intrusion Detection: The Malware\n  Detection and Prediction Based On Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the development of artificial intelligence algorithms like deep learning\nmodels and the successful applications in many different fields, further\nsimilar trails of deep learning technology have been made in cyber security\narea. It shows the preferable performance not only in academic security\nresearch but also in industry practices when dealing with part of cyber\nsecurity issues by deep learning methods compared to those conventional rules.\nEspecially for the malware detection and classification tasks, it saves\ngenerous time cost and promotes the accuracy for a total pipeline of malware\ndetection system. In this paper, we construct special deep neural network, ie,\nMalDeepNet (TB-Malnet and IB-Malnet) for malware dynamic behavior\nclassification tasks. Then we build the family clustering algorithm based on\ndeep learning and fulfil related testing. Except that, we also design a novel\nmalware prediction model which could detect the malware coming in future\nthrough the Mal Generative Adversarial Network (Mal-GAN) implementation. All\nthose algorithms present fairly considerable value in related datasets\nafterwards.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jul 2019 03:04:50 GMT"}], "update_date": "2019-07-22", "authors_parsed": [["Lu", "Shuqiang", ""], ["Ying", "Lingyun", ""], ["Lin", "Wenjie", ""], ["Wang", "Yu", ""], ["Nie", "Meining", ""], ["Shen", "Kaiwen", ""], ["Liu", "Lu", ""], ["Duan", "Haixin", ""]]}, {"id": "1907.08375", "submitter": "Feng Liu", "authors": "Zhen Fang, Jie Lu, Feng Liu, Junyu Xuan, Guangquan Zhang", "title": "Open Set Domain Adaptation: Theoretical Bound and Algorithm", "comments": "This paper has been accepted by IEEE-TNNLS", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The aim of unsupervised domain adaptation is to leverage the knowledge in a\nlabeled (source) domain to improve a model's learning performance with an\nunlabeled (target) domain -- the basic strategy being to mitigate the effects\nof discrepancies between the two distributions. Most existing algorithms can\nonly handle unsupervised closed set domain adaptation (UCSDA), i.e., where the\nsource and target domains are assumed to share the same label set. In this\npaper, we target a more challenging but realistic setting: unsupervised open\nset domain adaptation (UOSDA), where the target domain has unknown classes that\nare not found in the source domain. This is the first study to provide a\nlearning bound for open set domain adaptation, which we do by theoretically\ninvestigating the risk of the target classifier on unknown classes. The\nproposed learning bound has a special term, namely open set difference, which\nreflects the risk of the target classifier on unknown classes. Further, we\npresent a novel and theoretically guided unsupervised algorithm for open set\ndomain adaptation, called distribution alignment with ppen difference (DAOD),\nwhich is based on regularizing this open set difference bound. The experiments\non several benchmark datasets show the superior performance of the proposed\nUOSDA method compared with the state-of-the-art methods in the literature.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jul 2019 05:39:32 GMT"}, {"version": "v2", "created": "Thu, 8 Oct 2020 01:22:17 GMT"}], "update_date": "2020-10-09", "authors_parsed": [["Fang", "Zhen", ""], ["Lu", "Jie", ""], ["Liu", "Feng", ""], ["Xuan", "Junyu", ""], ["Zhang", "Guangquan", ""]]}, {"id": "1907.08377", "submitter": "Surat Teerapittayanon", "authors": "Surat Teerapittayanon, H. T. Kung", "title": "DaiMoN: A Decentralized Artificial Intelligence Model Network", "comments": "2019 IEEE International Conference on Blockchain", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce DaiMoN, a decentralized artificial intelligence model network,\nwhich incentivizes peer collaboration in improving the accuracy of machine\nlearning models for a given classification problem. It is an autonomous network\nwhere peers may submit models with improved accuracy and other peers may verify\nthe accuracy improvement. The system maintains an append-only decentralized\nledger to keep the log of critical information, including who has trained the\nmodel and improved its accuracy, when it has been improved, by how much it has\nimproved, and where to find the newly updated model. DaiMoN rewards these\ncontributing peers with cryptographic tokens. A main feature of DaiMoN is that\nit allows peers to verify the accuracy improvement of submitted models without\nknowing the test labels. This is an essential component in order to mitigate\nintentional model overfitting by model-improving peers. To enable this model\naccuracy evaluation with hidden test labels, DaiMoN uses a novel learnable\nDistance Embedding for Labels (DEL) function proposed in this paper. Specific\nto each test dataset, DEL scrambles the test label vector by embedding it in a\nlow-dimension space while approximately preserving the distance between the\ndataset's test label vector and a label vector inferred by the classifier. It\ntherefore allows proof-of-improvement (PoI) by peers without providing them\naccess to true test labels. We provide analysis and empirical evidence that\nunder DEL, peers can accurately assess model accuracy. We also argue that it is\nhard to invert the embedding function and thus, DEL is resilient against\nattacks aiming to recover test labels in order to cheat. Our prototype\nimplementation of DaiMoN is available at https://github.com/steerapi/daimon.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jul 2019 06:02:41 GMT"}], "update_date": "2019-07-22", "authors_parsed": [["Teerapittayanon", "Surat", ""], ["Kung", "H. T.", ""]]}, {"id": "1907.08392", "submitter": "Thilo Stadelmann", "authors": "Lukas Tuggener, Mohammadreza Amirian, Katharina Rombach, Stefan\n  L\\\"orwald, Anastasia Varlet, Christian Westermann, Thilo Stadelmann", "title": "Automated Machine Learning in Practice: State of the Art and Recent\n  Results", "comments": "Accepted full paper at SDS2019, the 6th Swiss Conference on Data\n  Science", "journal-ref": null, "doi": "10.1109/SDS.2019.00-11", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A main driver behind the digitization of industry and society is the belief\nthat data-driven model building and decision making can contribute to higher\ndegrees of automation and more informed decisions. Building such models from\ndata often involves the application of some form of machine learning. Thus,\nthere is an ever growing demand in work force with the necessary skill set to\ndo so. This demand has given rise to a new research topic concerned with\nfitting machine learning models fully automatically - AutoML. This paper gives\nan overview of the state of the art in AutoML with a focus on practical\napplicability in a business context, and provides recent benchmark results on\nthe most important AutoML algorithms.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jul 2019 07:19:07 GMT"}], "update_date": "2019-07-22", "authors_parsed": [["Tuggener", "Lukas", ""], ["Amirian", "Mohammadreza", ""], ["Rombach", "Katharina", ""], ["L\u00f6rwald", "Stefan", ""], ["Varlet", "Anastasia", ""], ["Westermann", "Christian", ""], ["Stadelmann", "Thilo", ""]]}, {"id": "1907.08400", "submitter": "Matteo Manica", "authors": "Matteo Manica, Christoph Auer, Valery Weber, Federico Zipoli, Michele\n  Dolfi, Peter Staar, Teodoro Laino, Costas Bekas, Akihiro Fujita, Hiroki Toda,\n  Shuichi Hirose, Yasumitsu Orii", "title": "An Information Extraction and Knowledge Graph Platform for Accelerating\n  Biochemical Discoveries", "comments": "4 pages, 1 figure, Workshop on Applied Data Science for Healthcare at\n  KDD, Anchorage, AK, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Information extraction and data mining in biochemical literature is a\ndaunting task that demands resource-intensive computation and appropriate means\nto scale knowledge ingestion. Being able to leverage this immense source of\ntechnical information helps to drastically reduce costs and time to solution in\nmultiple application fields from food safety to pharmaceutics. We present a\nscalable document ingestion system that integrates data from databases and\npublications (in PDF format) in a biochemistry knowledge graph (BCKG). The BCKG\nis a comprehensive source of knowledge that can be queried to retrieve known\nbiochemical facts and to generate novel insights. After describing the\nknowledge ingestion framework, we showcase an application of our system in the\nfield of carbohydrate enzymes. The BCKG represents a way to scale knowledge\ningestion and automatically exploit prior knowledge to accelerate discovery in\nbiochemical sciences.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jul 2019 08:17:30 GMT"}], "update_date": "2019-07-22", "authors_parsed": [["Manica", "Matteo", ""], ["Auer", "Christoph", ""], ["Weber", "Valery", ""], ["Zipoli", "Federico", ""], ["Dolfi", "Michele", ""], ["Staar", "Peter", ""], ["Laino", "Teodoro", ""], ["Bekas", "Costas", ""], ["Fujita", "Akihiro", ""], ["Toda", "Hiroki", ""], ["Hirose", "Shuichi", ""], ["Orii", "Yasumitsu", ""]]}, {"id": "1907.08410", "submitter": "Rajiv Khanna", "authors": "Rajiv Khanna, Michael W. Mahoney", "title": "On Linear Convergence of Weighted Kernel Herding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide a novel convergence analysis of two popular sampling algorithms,\nWeighted Kernel Herding and Sequential Bayesian Quadrature, that are used to\napproximate the expectation of a function under a distribution. Existing\ntheoretical analysis was insufficient to explain the empirical successes of\nthese algorithms. We improve upon existing convergence rates to show that,\nunder mild assumptions, these algorithms converge linearly. To this end, we\nalso suggest a simplifying assumption that is true for most cases in finite\ndimensions, and that acts as a sufficient condition for linear convergence to\nhold in the much harder case of infinite dimensions. When this condition is not\nsatisfied, we provide a weaker convergence guarantee. Our analysis also yields\na new distributed algorithm for large-scale computation that we prove converges\nlinearly under the same assumptions. Finally, we provide an empirical\nevaluation to test the proposed algorithm for a real world application.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jul 2019 08:49:12 GMT"}, {"version": "v2", "created": "Mon, 2 Mar 2020 02:18:12 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Khanna", "Rajiv", ""], ["Mahoney", "Michael W.", ""]]}, {"id": "1907.08440", "submitter": "Vijaikumar M", "authors": "Vijaikumar M and Shirish Shevade and M N Murty", "title": "Neural Cross-Domain Collaborative Filtering with Shared Entities", "comments": "10 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cross-Domain Collaborative Filtering (CDCF) provides a way to alleviate data\nsparsity and cold-start problems present in recommendation systems by\nexploiting the knowledge from related domains. Existing CDCF models are either\nbased on matrix factorization or deep neural networks. Either of the techniques\nin isolation may result in suboptimal performance for the prediction task.\nAlso, most of the existing models face challenges particularly in handling\ndiversity between domains and learning complex non-linear relationships that\nexist amongst entities (users/items) within and across domains. In this work,\nwe propose an end-to-end neural network model -- NeuCDCF, to address these\nchallenges in a cross-domain setting. More importantly, NeuCDCF follows a wide\nand deep framework and it learns the representations combinedly from both\nmatrix factorization and deep neural networks. We perform experiments on four\nreal-world datasets and demonstrate that our model performs better than\nstate-of-the-art CDCF models.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jul 2019 10:04:28 GMT"}], "update_date": "2019-07-22", "authors_parsed": [["M", "Vijaikumar", ""], ["Shevade", "Shirish", ""], ["Murty", "M N", ""]]}, {"id": "1907.08448", "submitter": "Diego Valsesia", "authors": "Diego Valsesia, Giulia Fracastoro, Enrico Magli", "title": "Deep Graph-Convolutional Image Denoising", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Non-local self-similarity is well-known to be an effective prior for the\nimage denoising problem. However, little work has been done to incorporate it\nin convolutional neural networks, which surpass non-local model-based methods\ndespite only exploiting local information. In this paper, we propose a novel\nend-to-end trainable neural network architecture employing layers based on\ngraph convolution operations, thereby creating neurons with non-local receptive\nfields. The graph convolution operation generalizes the classic convolution to\narbitrary graphs. In this work, the graph is dynamically computed from\nsimilarities among the hidden features of the network, so that the powerful\nrepresentation learning capabilities of the network are exploited to uncover\nself-similar patterns. We introduce a lightweight Edge-Conditioned Convolution\nwhich addresses vanishing gradient and over-parameterization issues of this\nparticular graph convolution. Extensive experiments show state-of-the-art\nperformance with improved qualitative and quantitative results on both\nsynthetic Gaussian noise and real noise.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jul 2019 10:27:41 GMT"}], "update_date": "2019-07-22", "authors_parsed": [["Valsesia", "Diego", ""], ["Fracastoro", "Giulia", ""], ["Magli", "Enrico", ""]]}, {"id": "1907.08456", "submitter": "Frederik Kratzert", "authors": "Frederik Kratzert, Daniel Klotz, Guy Shalev, G\\\"unter Klambauer, Sepp\n  Hochreiter, Grey Nearing", "title": "Towards Learning Universal, Regional, and Local Hydrological Behaviors\n  via Machine-Learning Applied to Large-Sample Datasets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Regional rainfall-runoff modeling is an old but still mostly out-standing\nproblem in Hydrological Sciences. The problem currently is that traditional\nhydrological models degrade significantly in performance when calibrated for\nmultiple basins together instead of for a single basin alone. In this paper, we\npropose a novel, data-driven approach using Long Short-Term Memory networks\n(LSTMs), and demonstrate that under a 'big data' paradigm, this is not\nnecessarily the case. By training a single LSTM model on 531 basins from the\nCAMELS data set using meteorological time series data and static catchment\nattributes, we were able to significantly improve performance compared to a set\nof several different hydrological benchmark models. Our proposed approach not\nonly significantly outperforms hydrological models that were calibrated\nregionally but also achieves better performance than hydrological models that\nwere calibrated for each basin individually. Furthermore, we propose an\nadaption to the standard LSTM architecture, which we call an Entity-Aware-LSTM\n(EA-LSTM), that allows for learning, and embedding as a feature layer in a deep\nlearning model, catchment similarities. We show that this learned catchment\nsimilarity corresponds well with what we would expect from prior hydrological\nunderstanding.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jul 2019 10:52:12 GMT"}, {"version": "v2", "created": "Sun, 10 Nov 2019 15:03:52 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Kratzert", "Frederik", ""], ["Klotz", "Daniel", ""], ["Shalev", "Guy", ""], ["Klambauer", "G\u00fcnter", ""], ["Hochreiter", "Sepp", ""], ["Nearing", "Grey", ""]]}, {"id": "1907.08461", "submitter": "Vanessa Kosoy", "authors": "Vanessa Kosoy", "title": "Delegative Reinforcement Learning: learning to avoid traps with a little\n  help", "comments": "22 pages", "journal-ref": "SafeML ICLR 2019 Workshop", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most known regret bounds for reinforcement learning are either episodic or\nassume an environment without traps. We derive a regret bound without making\neither assumption, by allowing the algorithm to occasionally delegate an action\nto an external advisor. We thus arrive at a setting of active one-shot\nmodel-based reinforcement learning that we call DRL (delegative reinforcement\nlearning.) The algorithm we construct in order to demonstrate the regret bound\nis a variant of Posterior Sampling Reinforcement Learning supplemented by a\nsubroutine that decides which actions should be delegated. The algorithm is not\nanytime, since the parameters must be adjusted according to the target time\ndiscount. Currently, our analysis is limited to Markov decision processes with\nfinite numbers of hypotheses, states and actions.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jul 2019 11:19:03 GMT"}], "update_date": "2019-07-22", "authors_parsed": [["Kosoy", "Vanessa", ""]]}, {"id": "1907.08467", "submitter": "Iuri Frosio", "authors": "Steven Dalton and Iuri Frosio and Michael Garland", "title": "Accelerating Reinforcement Learning through GPU Atari Emulation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce CuLE (CUDA Learning Environment), a CUDA port of the Atari\nLearning Environment (ALE) which is used for the development of deep\nreinforcement algorithms. CuLE overcomes many limitations of existing CPU-based\nemulators and scales naturally to multiple GPUs. It leverages GPU\nparallelization to run thousands of games simultaneously and it renders frames\ndirectly on the GPU, to avoid the bottleneck arising from the limited CPU-GPU\ncommunication bandwidth. CuLE generates up to 155M frames per hour on a single\nGPU, a finding previously achieved only through a cluster of CPUs. Beyond\nhighlighting the differences between CPU and GPU emulators in the context of\nreinforcement learning, we show how to leverage the high throughput of CuLE by\neffective batching of the training data, and show accelerated convergence for\nA2C+V-trace. CuLE is available at https://github.com/NVLabs/cule .\n", "versions": [{"version": "v1", "created": "Fri, 19 Jul 2019 11:36:10 GMT"}, {"version": "v2", "created": "Mon, 5 Oct 2020 18:49:48 GMT"}], "update_date": "2020-10-07", "authors_parsed": [["Dalton", "Steven", ""], ["Frosio", "Iuri", ""], ["Garland", "Michael", ""]]}, {"id": "1907.08475", "submitter": "Bernhard Bermeitinger", "authors": "Bernhard Bermeitinger, Tomas Hrycej, Siegfried Handschuh", "title": "Representational Capacity of Deep Neural Networks -- A Computing Study", "comments": null, "journal-ref": "2019 11th International Conference on Knowledge Discovery and\n  Information Retrieval (KDIR)", "doi": "10.5220/0008364305320538", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is some theoretical evidence that deep neural networks with multiple\nhidden layers have a potential for more efficient representation of\nmultidimensional mappings than shallow networks with a single hidden layer. The\nquestion is whether it is possible to exploit this theoretical advantage for\nfinding such representations with help of numerical training methods. Tests\nusing prototypical problems with a known mean square minimum did not confirm\nthis hypothesis. Minima found with the help of deep networks have always been\nworse than those found using shallow networks. This does not directly\ncontradict the theoretical findings---it is possible that the superior\nrepresentational capacity of deep networks is genuine while finding the mean\nsquare minimum of such deep networks is a substantially harder problem than\nwith shallow ones.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jul 2019 11:56:09 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Bermeitinger", "Bernhard", ""], ["Hrycej", "Tomas", ""], ["Handschuh", "Siegfried", ""]]}, {"id": "1907.08487", "submitter": "Shen Yifei", "authors": "Yifei Shen, Yuanming Shi, Jun Zhang, Khaled B. Letaief", "title": "A Graph Neural Network Approach for Scalable Wireless Power Control", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG eess.SP math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks have recently emerged as a disruptive technology to\nsolve NP-hard wireless resource allocation problems in a real-time manner.\nHowever, the adopted neural network structures, e.g., multi-layer perceptron\n(MLP) and convolutional neural network (CNN), are inherited from deep learning\nfor image processing tasks, and thus are not tailored to problems in wireless\nnetworks. In particular, the performance of these methods deteriorates\ndramatically when the wireless network size becomes large. In this paper, we\npropose to utilize graph neural networks (GNNs) to develop scalable methods for\nsolving the power control problem in $K$-user interference channels.\nSpecifically, a $K$-user interference channel is first modeled as a complete\ngraph, where the quantitative information of wireless channels is incorporated\nas the features of the graph. We then propose an interference graph\nconvolutional neural network (IGCNet) to learn the optimal power control in an\nunsupervised manner. It is shown that one-layer IGCNet is a universal\napproximator to continuous set functions, which well matches the permutation\ninvariance property of interference channels and it is robust to imperfect\nchannel state information (CSI). Extensive simulations will show that the\nproposed IGCNet outperforms existing methods and achieves significant speedup\nover the classic algorithm for power control, namely, WMMSE. The code is\navailable on https://github.com/yshenaw/Globecom2019.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jul 2019 12:38:20 GMT"}], "update_date": "2019-07-22", "authors_parsed": [["Shen", "Yifei", ""], ["Shi", "Yuanming", ""], ["Zhang", "Jun", ""], ["Letaief", "Khaled B.", ""]]}, {"id": "1907.08488", "submitter": "Thomas Pock", "authors": "Alexander Effland, Erich Kobler, Karl Kunisch, Thomas Pock", "title": "An Optimal Control Approach to Early Stopping Variational Methods for\n  Image Restoration", "comments": "14 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate a well-known phenomenon of variational approaches in image\nprocessing, where typically the best image quality is achieved when the\ngradient flow process is stopped before converging to a stationary point. This\nparadox originates from a tradeoff between optimization and modelling errors of\nthe underlying variational model and holds true even if deep learning methods\nare used to learn highly expressive regularizers from data. In this paper, we\ntake advantage of this paradox and introduce an optimal stopping time into the\ngradient flow process, which in turn is learned from data by means of an\noptimal control approach. As a result, we obtain highly efficient numerical\nschemes that achieve competitive results for image denoising and image\ndeblurring. A nonlinear spectral analysis of the gradient of the learned\nregularizer gives enlightening insights about the different regularization\nproperties.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jul 2019 12:38:36 GMT"}], "update_date": "2019-07-23", "authors_parsed": [["Effland", "Alexander", ""], ["Kobler", "Erich", ""], ["Kunisch", "Karl", ""], ["Pock", "Thomas", ""]]}, {"id": "1907.08489", "submitter": "Ning Wu", "authors": "Jingyuan Wang, Ning Wu, Wayne Xin Zhao, Fanzhang Peng and Xin Lin", "title": "Empowering A* Search Algorithms with Neural Networks for Personalized\n  Route Recommendation", "comments": "9 pages, 25TH ACM SIGKDD Conference On Knowledge Discovery And Data\n  Mining", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Personalized Route Recommendation (PRR) aims to generate user-specific route\nsuggestions in response to users' route queries. Early studies cast the PRR\ntask as a pathfinding problem on graphs, and adopt adapted search algorithms by\nintegrating heuristic strategies. Although these methods are effective to some\nextent, they require setting the cost functions with heuristics. In addition,\nit is difficult to utilize useful context information in the search procedure.\nTo address these issues, we propose using neural networks to automatically\nlearn the cost functions of a classic heuristic algorithm, namely A* algorithm,\nfor the PRR task. Our model consists of two components. First, we employ\nattention-based Recurrent Neural Networks (RNN) to model the cost from the\nsource to the candidate location by incorporating useful context information.\nInstead of learning a single cost value, the RNN component is able to learn a\ntime-varying vectorized representation for the moving state of a user. Second,\nwe propose to use a value network for estimating the cost from a candidate\nlocation to the destination. For capturing structural characteristics, the\nvalue network is built on top of improved graph attention networks by\nincorporating the moving state of a user and other context information. The two\ncomponents are integrated in a principled way for deriving a more accurate cost\nof a candidate location. Extensive experiment results on three real-world\ndatasets have shown the effectiveness and robustness of the proposed model.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jul 2019 12:47:00 GMT"}], "update_date": "2019-07-22", "authors_parsed": [["Wang", "Jingyuan", ""], ["Wu", "Ning", ""], ["Zhao", "Wayne Xin", ""], ["Peng", "Fanzhang", ""], ["Lin", "Xin", ""]]}, {"id": "1907.08506", "submitter": "Konstantinos Drossos", "authors": "Konstantinos Drossos and Shayan Gharib and Paul Magron and Tuomas\n  Virtanen", "title": "Language Modelling for Sound Event Detection with Teacher Forcing and\n  Scheduled Sampling", "comments": "Fixed the display of URLs at footnote, updated the results", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A sound event detection (SED) method typically takes as an input a sequence\nof audio frames and predicts the activities of sound events in each frame. In\nreal-life recordings, the sound events exhibit some temporal structure: for\ninstance, a \"car horn\" will likely be followed by a \"car passing by\". While\nthis temporal structure is widely exploited in sequence prediction tasks (e.g.,\nin machine translation), where language models (LM) are exploited, it is not\nsatisfactorily modeled in SED. In this work we propose a method which allows a\nrecurrent neural network (RNN) to learn an LM for the SED task. The method\nconditions the input of the RNN with the activities of classes at the previous\ntime step. We evaluate our method using F1 score and error rate (ER) over three\ndifferent and publicly available datasets; the TUT-SED Synthetic 2016 and the\nTUT Sound Events 2016 and 2017 datasets. The obtained results show an increase\nof 9% and 2% at the F1 (higher is better) and a decrease of 7% and 2% at ER\n(lower is better) for the TUT Sound Events 2016 and 2017 datasets,\nrespectively, when using our method. On the contrary, with our method there is\na decrease of 4% at F1 score and an increase of 7% at ER for the TUT-SED\nSynthetic 2016 dataset.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jul 2019 13:26:03 GMT"}, {"version": "v2", "created": "Mon, 22 Jul 2019 05:45:13 GMT"}, {"version": "v3", "created": "Wed, 6 Nov 2019 11:49:21 GMT"}], "update_date": "2019-11-07", "authors_parsed": [["Drossos", "Konstantinos", ""], ["Gharib", "Shayan", ""], ["Magron", "Paul", ""], ["Virtanen", "Tuomas", ""]]}, {"id": "1907.08526", "submitter": "Saeed Soori", "authors": "Saeed Soori, Bugra Can, Mert Gurbuzbalaba, Maryam Mehri Dehnavi", "title": "ASYNC: A Cloud Engine with Asynchrony and History for Distributed\n  Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  ASYNC is a framework that supports the implementation of asynchrony and\nhistory for optimization methods on distributed computing platforms. The\npopularity of asynchronous optimization methods has increased in distributed\nmachine learning. However, their applicability and practical experimentation on\ndistributed systems are limited because current bulk-processing cloud engines\ndo not provide a robust support for asynchrony and history. With introducing\nthree main modules and bookkeeping system-specific and application parameters,\nASYNC provides practitioners with a framework to implement asynchronous machine\nlearning methods. To demonstrate ease-of-implementation in ASYNC, the\nsynchronous and asynchronous variants of two well-known optimization methods,\nstochastic gradient descent and SAGA, are demonstrated in ASYNC.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jul 2019 14:26:56 GMT"}, {"version": "v2", "created": "Sat, 27 Jul 2019 18:14:10 GMT"}, {"version": "v3", "created": "Tue, 15 Oct 2019 15:36:53 GMT"}, {"version": "v4", "created": "Fri, 21 Feb 2020 03:19:14 GMT"}], "update_date": "2020-02-24", "authors_parsed": [["Soori", "Saeed", ""], ["Can", "Bugra", ""], ["Gurbuzbalaba", "Mert", ""], ["Dehnavi", "Maryam Mehri", ""]]}, {"id": "1907.08532", "submitter": "Zhiguo Wang", "authors": "Zhiguo Wang, Yue Zhang, Mo Yu, Wei Zhang, Lin Pan, Linfeng Song, Kun\n  Xu, Yousef El-Kurdi", "title": "Multi-Granular Text Encoding for Self-Explaining Categorization", "comments": "Accepted by BlackboxNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Self-explaining text categorization requires a classifier to make a\nprediction along with supporting evidence. A popular type of evidence is\nsub-sequences extracted from the input text which are sufficient for the\nclassifier to make the prediction. In this work, we define multi-granular\nngrams as basic units for explanation, and organize all ngrams into a\nhierarchical structure, so that shorter ngrams can be reused while computing\nlonger ngrams. We leverage a tree-structured LSTM to learn a\ncontext-independent representation for each unit via parameter sharing.\nExperiments on medical disease classification show that our model is more\naccurate, efficient and compact than BiLSTM and CNN baselines. More\nimportantly, our model can extract intuitive multi-granular evidence to support\nits predictions.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jul 2019 14:43:51 GMT"}], "update_date": "2019-07-22", "authors_parsed": [["Wang", "Zhiguo", ""], ["Zhang", "Yue", ""], ["Yu", "Mo", ""], ["Zhang", "Wei", ""], ["Pan", "Lin", ""], ["Song", "Linfeng", ""], ["Xu", "Kun", ""], ["El-Kurdi", "Yousef", ""]]}, {"id": "1907.08544", "submitter": "Enzo Tartaglione", "authors": "Enzo Tartaglione, Daniele Perlo and Marco Grangetto", "title": "Post-synaptic potential regularization has potential", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Improving generalization is one of the main challenges for training deep\nneural networks on classification tasks. In particular, a number of techniques\nhave been proposed, aiming to boost the performance on unseen data: from\nstandard data augmentation techniques to the $\\ell_2$ regularization, dropout,\nbatch normalization, entropy-driven SGD and many more.\\\\ In this work we\npropose an elegant, simple and principled approach: post-synaptic potential\nregularization (PSP). We tested this regularization on a number of different\nstate-of-the-art scenarios. Empirical results show that PSP achieves a\nclassification error comparable to more sophisticated learning strategies in\nthe MNIST scenario, while improves the generalization compared to $\\ell_2$\nregularization in deep architectures trained on CIFAR-10.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jul 2019 15:25:21 GMT"}], "update_date": "2019-07-22", "authors_parsed": [["Tartaglione", "Enzo", ""], ["Perlo", "Daniele", ""], ["Grangetto", "Marco", ""]]}, {"id": "1907.08556", "submitter": "Divya Saxena", "authors": "Divya Saxena, Jiannong Cao", "title": "D-GAN: Deep Generative Adversarial Nets for Spatio-Temporal Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spatio-temporal (ST) data for urban applications, such as taxi demand,\ntraffic flow, regional rainfall is inherently stochastic and unpredictable.\nRecently, deep learning based ST prediction models are proposed to learn the ST\ncharacteristics of data. However, it is still very challenging (1) to\nadequately learn the complex and non-linear ST relationships; (2) to model the\nhigh variations in the ST data volumes as it is inherently dynamic, changing\nover time (i.e., irregular) and highly influenced by many external factors,\nsuch as adverse weather, accidents, traffic control, PoI, etc.; and (3) as\nthere can be many complicated external factors that can affect the accuracy and\nit is impossible to list them explicitly. To handle the aforementioned issues,\nin this paper, we propose a novel deep generative adversarial network based\nmodel (named, D-GAN) for more accurate ST prediction by implicitly learning ST\nfeature representations in an unsupervised manner. D-GAN adopts a GAN-based\nstructure and jointly learns generation and variational inference of data. More\nspecifically, D-GAN consists of two major parts: (1) a deep ST feature learning\nnetwork to model the ST correlations and semantic variations, and underlying\nfactors of variations and irregularity in the data through the implicit\ndistribution modelling; (2) a fusion module to incorporate external factors for\nreaching a better inference. To the best our knowledge, no prior work studies\nST prediction problem via deep implicit generative model and in an unsupervised\nmanner. Extensive experiments performed on two real-world datasets show that\nD-GAN achieves more accurate results than traditional as well as deep learning\nbased ST prediction methods.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jul 2019 15:54:54 GMT"}, {"version": "v2", "created": "Mon, 22 Jul 2019 08:56:50 GMT"}, {"version": "v3", "created": "Sat, 29 May 2021 10:17:13 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Saxena", "Divya", ""], ["Cao", "Jiannong", ""]]}, {"id": "1907.08577", "submitter": "Abdelaali Hassaine", "authors": "Abdelaali Hassaine, Dexter Canoy, Jose Roberto Ayala Solares, Yajie\n  Zhu, Shishir Rao, Yikuan Li, Mariagrazia Zottoli, Kazem Rahimi, Gholamreza\n  Salimi-Khorshidi", "title": "Learning Multimorbidity Patterns from Electronic Health Records Using\n  Non-negative Matrix Factorisation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multimorbidity, or the presence of several medical conditions in the same\nindividual, has been increasing in the population, both in absolute and\nrelative terms. However, multimorbidity remains poorly understood, and the\nevidence from existing research to describe its burden, determinants and\nconsequences has been limited. Previous studies attempting to understand\nmultimorbidity patterns are often cross-sectional and do not explicitly account\nfor multimorbidity patterns' evolution over time; some of them are based on\nsmall datasets and/or use arbitrary and narrow age ranges; and those that\nemployed advanced models, usually lack appropriate benchmarking and\nvalidations. In this study, we (1) introduce a novel approach for using\nNon-negative Matrix Factorisation (NMF) for temporal phenotyping (i.e.,\nsimultaneously mining disease clusters and their trajectories); (2) provide\nquantitative metrics for the evaluation of disease clusters from such studies;\nand (3) demonstrate how the temporal characteristics of the disease clusters\nthat result from our model can help mine multimorbidity networks and generate\nnew hypotheses for the emergence of various multimorbidity patterns over time.\nWe trained and evaluated our models on one of the world's largest electronic\nhealth records (EHR), with 7 million patients, from which over 2 million where\nrelevant to this study.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jul 2019 17:03:44 GMT"}, {"version": "v2", "created": "Mon, 18 Nov 2019 10:33:55 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Hassaine", "Abdelaali", ""], ["Canoy", "Dexter", ""], ["Solares", "Jose Roberto Ayala", ""], ["Zhu", "Yajie", ""], ["Rao", "Shishir", ""], ["Li", "Yikuan", ""], ["Zottoli", "Mariagrazia", ""], ["Rahimi", "Kazem", ""], ["Salimi-Khorshidi", "Gholamreza", ""]]}, {"id": "1907.08589", "submitter": "Justin Shenk", "authors": "Justin Shenk, Mats L. Richter, Anders Arpteg, Mikael Huss", "title": "Spectral Analysis of Latent Representations", "comments": "13 pages, 16 figures, code: https://github.com/delve-team/delve", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a metric, Layer Saturation, defined as the proportion of the\nnumber of eigenvalues needed to explain 99% of the variance of the latent\nrepresentations, for analyzing the learned representations of neural network\nlayers. Saturation is based on spectral analysis and can be computed\nefficiently, making live analysis of the representations practical during\ntraining. We provide an outlook for future applications of this metric by\noutlining the behaviour of layer saturation in different neural architectures\nand problems. We further show that saturation is related to the generalization\nand predictive performance of neural networks.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jul 2019 17:41:28 GMT"}], "update_date": "2019-07-22", "authors_parsed": [["Shenk", "Justin", ""], ["Richter", "Mats L.", ""], ["Arpteg", "Anders", ""], ["Huss", "Mikael", ""]]}, {"id": "1907.08591", "submitter": "Michele Buzzicotti", "authors": "Luca Biferale, Fabio Bonaccorso, Michele Buzzicotti, Patricio Clark Di\n  Leoni and Kristian Gustavsson", "title": "Zermelo's problem: Optimal point-to-point navigation in 2D turbulent\n  flows using Reinforcement Learning", "comments": null, "journal-ref": null, "doi": "10.1063/1.5120370", "report-no": null, "categories": "nlin.CD cs.AI cs.LG cs.SY eess.SY physics.flu-dyn", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To find the path that minimizes the time to navigate between two given points\nin a fluid flow is known as Zermelo's problem. Here, we investigate it by using\na Reinforcement Learning (RL) approach for the case of a vessel which has a\nslip velocity with fixed intensity, Vs , but variable direction and navigating\nin a 2D turbulent sea. We show that an Actor-Critic RL algorithm is able to\nfind quasi-optimal solutions for both time-independent and chaotically evolving\nflow configurations. For the frozen case, we also compared the results with\nstrategies obtained analytically from continuous Optimal Navigation (ON)\nprotocols. We show that for our application, ON solutions are unstable for the\ntypical duration of the navigation process, and are therefore not useful in\npractice. On the other hand, RL solutions are much more robust with respect to\nsmall changes in the initial conditions and to external noise, even when V s is\nmuch smaller than the maximum flow velocity. Furthermore, we show how the RL\napproach is able to take advantage of the flow properties in order to reach the\ntarget, especially when the steering speed is small.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jul 2019 15:12:52 GMT"}, {"version": "v2", "created": "Thu, 26 Sep 2019 10:51:15 GMT"}], "update_date": "2020-01-08", "authors_parsed": [["Biferale", "Luca", ""], ["Bonaccorso", "Fabio", ""], ["Buzzicotti", "Michele", ""], ["Di Leoni", "Patricio Clark", ""], ["Gustavsson", "Kristian", ""]]}, {"id": "1907.08592", "submitter": "Houman Owhadi", "authors": "Houman Owhadi and Clint Scovel and Gene Ryan Yoo", "title": "Kernel Mode Decomposition and programmable/interpretable regression\n  networks", "comments": "102 pages, 39 figures. Python source codes available at\n  https://github.com/kernel-enthusiasts/Kernel-Mode-Decomposition-1D", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mode decomposition is a prototypical pattern recognition problem that can be\naddressed from the (a priori distinct) perspectives of numerical approximation,\nstatistical inference and deep learning. Could its analysis through these\ncombined perspectives be used as a Rosetta stone for deciphering mechanisms at\nplay in deep learning? Motivated by this question we introduce programmable and\ninterpretable regression networks for pattern recognition and address mode\ndecomposition as a prototypical problem. The programming of these networks is\nachieved by assembling elementary modules decomposing and recomposing kernels\nand data. These elementary steps are repeated across levels of abstraction and\ninterpreted from the equivalent perspectives of optimal recovery, game theory\nand Gaussian process regression (GPR). The prototypical mode/kernel\ndecomposition module produces an optimal approximation $(w_1,w_2,\\cdots,w_m)$\nof an element $(v_1,v_2,\\ldots,v_m)$ of a product of Hilbert subspaces of a\ncommon Hilbert space from the observation of the sum $v:=v_1+\\cdots+v_m$. The\nprototypical mode/kernel recomposition module performs partial sums of the\nrecovered modes $w_i$ based on the alignment between each recovered mode $w_i$\nand the data $v$. We illustrate the proposed framework by programming\nregression networks approximating the modes $v_i=\na_i(t)y_i\\big(\\theta_i(t)\\big)$ of a (possibly noisy) signal $\\sum_i v_i$ when\nthe amplitudes $a_i$, instantaneous phases $\\theta_i$ and periodic waveforms\n$y_i$ may all be unknown and show near machine precision recovery under\nregularity and separation assumptions on the instantaneous amplitudes $a_i$ and\nfrequencies $\\dot{\\theta}_i$. The structure of some of these networks share\nintriguing similarities with convolutional neural networks while being\ninterpretable, programmable and amenable to theoretical analysis.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jul 2019 17:42:27 GMT"}, {"version": "v2", "created": "Wed, 5 Aug 2020 19:07:36 GMT"}], "update_date": "2020-08-07", "authors_parsed": [["Owhadi", "Houman", ""], ["Scovel", "Clint", ""], ["Yoo", "Gene Ryan", ""]]}, {"id": "1907.08600", "submitter": "Luca Manneschi", "authors": "Luca Manneschi, Andrew C. Lin, Eleni Vasilaki", "title": "Learning sparsity in reservoir computing through a novel bio-inspired\n  algorithm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The mushroom body is the key network for the representation of learned\nolfactory stimuli in Drosophila and insects. The sparse activity of Kenyon\ncells, the principal neurons in the mushroom body, plays a key role in the\nlearned classification of different odours. In the specific case of the fruit\nfly, the sparseness of the network is enforced by an inhibitory feedback neuron\ncalled APL, and by an intrinsic high firing threshold of the Kenyon cells. In\nthis work we took inspiration from the fruit fly brain to formulate a novel\nmachine learning algorithm that is able to optimize the sparsity level of a\nreservoir by changing the firing thresholds of the nodes. The sparsity is only\napplied on the readout layer so as not to change the timescales of the\nreservoir and to allow the derivation of a one-layer update rule for the firing\nthresholds. The proposed algorithm is a combination of learning a\nneuron-specific sparsity threshold via gradient descent and a global sparsity\nthreshold via a Markov chain Monte Carlo method. The proposed model outperforms\nthe standard gradient descent, which is limited to the readout weights of the\nreservoir, on two example tasks. It demonstrates how the learnt sparse\nrepresentation can lead to better classification performance, memorization\nability and convergence time.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jul 2019 17:53:29 GMT"}], "update_date": "2019-07-22", "authors_parsed": [["Manneschi", "Luca", ""], ["Lin", "Andrew C.", ""], ["Vasilaki", "Eleni", ""]]}, {"id": "1907.08610", "submitter": "Michael Zhang", "authors": "Michael R. Zhang, James Lucas, Geoffrey Hinton, Jimmy Ba", "title": "Lookahead Optimizer: k steps forward, 1 step back", "comments": "Accepted to Neural Information Processing Systems 2019. Code\n  available at: https://github.com/michaelrzhang/lookahead", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The vast majority of successful deep neural networks are trained using\nvariants of stochastic gradient descent (SGD) algorithms. Recent attempts to\nimprove SGD can be broadly categorized into two approaches: (1) adaptive\nlearning rate schemes, such as AdaGrad and Adam, and (2) accelerated schemes,\nsuch as heavy-ball and Nesterov momentum. In this paper, we propose a new\noptimization algorithm, Lookahead, that is orthogonal to these previous\napproaches and iteratively updates two sets of weights. Intuitively, the\nalgorithm chooses a search direction by looking ahead at the sequence of fast\nweights generated by another optimizer. We show that Lookahead improves the\nlearning stability and lowers the variance of its inner optimizer with\nnegligible computation and memory cost. We empirically demonstrate Lookahead\ncan significantly improve the performance of SGD and Adam, even with their\ndefault hyperparameter settings on ImageNet, CIFAR-10/100, neural machine\ntranslation, and Penn Treebank.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jul 2019 17:59:50 GMT"}, {"version": "v2", "created": "Tue, 3 Dec 2019 15:55:38 GMT"}], "update_date": "2019-12-04", "authors_parsed": [["Zhang", "Michael R.", ""], ["Lucas", "James", ""], ["Hinton", "Geoffrey", ""], ["Ba", "Jimmy", ""]]}, {"id": "1907.08612", "submitter": "Tom Vercauteren", "authors": "M. Jorge Cardoso, Aasa Feragen, Ben Glocker, Ender Konukoglu, Ipek\n  Oguz, Gozde Unal, Tom Vercauteren", "title": "Medical Imaging with Deep Learning: MIDL 2019 -- Extended Abstract Track", "comments": "Accepted extended abstracts can also be found at\n  https://openreview.net/group?id=MIDL.io/2019/Conference#abstract-accept-papers", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This compendium gathers all the accepted extended abstracts from the Second\nInternational Conference on Medical Imaging with Deep Learning (MIDL 2019),\nheld in London, UK, 8-10 July 2019. Note that only accepted extended abstracts\nare listed here, the Proceedings of the MIDL 2019 Full Paper Track are\npublished as Volume 102 of the Proceedings of Machine Learning Research (PMLR)\nhttp://proceedings.mlr.press/v102/.\n", "versions": [{"version": "v1", "created": "Tue, 21 May 2019 16:27:29 GMT"}, {"version": "v2", "created": "Mon, 22 Jul 2019 13:14:56 GMT"}], "update_date": "2019-07-23", "authors_parsed": [["Cardoso", "M. Jorge", ""], ["Feragen", "Aasa", ""], ["Glocker", "Ben", ""], ["Konukoglu", "Ender", ""], ["Oguz", "Ipek", ""], ["Unal", "Gozde", ""], ["Vercauteren", "Tom", ""]]}, {"id": "1907.08615", "submitter": "Ben Gelman", "authors": "Jacob Dormuth, Ben Gelman, Jessica Moore, and David Slater", "title": "Logical Segmentation of Source Code", "comments": "SEKE2019 Conference Full Paper", "journal-ref": null, "doi": "10.18293/SEKE2019-026", "report-no": null, "categories": "cs.SE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many software analysis methods have come to rely on machine learning\napproaches. Code segmentation - the process of decomposing source code into\nmeaningful blocks - can augment these methods by featurizing code, reducing\nnoise, and limiting the problem space. Traditionally, code segmentation has\nbeen done using syntactic cues; current approaches do not intentionally capture\nlogical content. We develop a novel deep learning approach to generate logical\ncode segments regardless of the language or syntactic correctness of the code.\nDue to the lack of logically segmented source code, we introduce a unique data\nset construction technique to approximate ground truth for logically segmented\ncode. Logical code segmentation can improve tasks such as automatically\ncommenting code, detecting software vulnerabilities, repairing bugs, labeling\ncode functionality, and synthesizing new code.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jul 2019 18:23:26 GMT"}], "update_date": "2019-07-23", "authors_parsed": [["Dormuth", "Jacob", ""], ["Gelman", "Ben", ""], ["Moore", "Jessica", ""], ["Slater", "David", ""]]}, {"id": "1907.08646", "submitter": "John Lafferty", "authors": "Dana Yang, John Lafferty, David Pollard", "title": "Fair quantile regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantile regression is a tool for learning conditional distributions. In this\npaper we study quantile regression in the setting where a protected attribute\nis unavailable when fitting the model. This can lead to \"unfair'' quantile\nestimators for which the effective quantiles are very different for the\nsubpopulations defined by the protected attribute. We propose a procedure for\nadjusting the estimator on a heldout sample where the protected attribute is\navailable. The main result of the paper is an empirical process analysis\nshowing that the adjustment leads to a fair estimator for which the target\nquantiles are brought into balance, in a statistical sense that we call\n$\\sqrt{n}$-fairness. We illustrate the ideas and adjustment procedure on a\ndataset of 200,000 live births, where the objective is to characterize the\ndependence of the birth weights of the babies on demographic attributes of the\nbirth mother; the protected attribute is the mother's race.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jul 2019 18:52:35 GMT"}], "update_date": "2019-07-23", "authors_parsed": [["Yang", "Dana", ""], ["Lafferty", "John", ""], ["Pollard", "David", ""]]}, {"id": "1907.08650", "submitter": "Sutanay Choudhury", "authors": "Khushbu Agarwal, Tome Eftimov, Raghavendra Addanki, Sutanay Choudhury,\n  Suzanne Tamang, and Robert Rallo", "title": "Snomed2Vec: Random Walk and Poincar\\'e Embeddings of a Clinical\n  Knowledge Base for Healthcare Analytics", "comments": "2019 KDD Workshop on Applied Data Science for Healthcare (DSHealth\n  '19). https://gitlab.com/agarwal.khushbu/Snomed2Vec", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Representation learning methods that transform encoded data (e.g., diagnosis\nand drug codes) into continuous vector spaces (i.e., vector embeddings) are\ncritical for the application of deep learning in healthcare. Initial work in\nthis area explored the use of variants of the word2vec algorithm to learn\nembeddings for medical concepts from electronic health records or medical\nclaims datasets. We propose learning embeddings for medical concepts by using\ngraph-based representation learning methods on SNOMED-CT, a widely popular\nknowledge graph in the healthcare domain with numerous operational and research\napplications. Current work presents an empirical analysis of various embedding\nmethods, including the evaluation of their performance on multiple tasks of\nbiomedical relevance (node classification, link prediction, and patient state\nprediction). Our results show that concept embeddings derived from the\nSNOMED-CT knowledge graph significantly outperform state-of-the-art embeddings,\nshowing 5-6x improvement in ``concept similarity\" and 6-20\\% improvement in\npatient diagnosis.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jul 2019 19:11:39 GMT"}], "update_date": "2019-07-23", "authors_parsed": [["Agarwal", "Khushbu", ""], ["Eftimov", "Tome", ""], ["Addanki", "Raghavendra", ""], ["Choudhury", "Sutanay", ""], ["Tamang", "Suzanne", ""], ["Rallo", "Robert", ""]]}, {"id": "1907.08651", "submitter": "Daniel Karapetyan Dr", "authors": "Dobromir Marinov and Daniel Karapetyan", "title": "Hyperparameter Optimisation with Early Termination of Poor Performers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is typical for a machine learning system to have numerous hyperparameters\nthat affect its learning rate and prediction quality. Finding a good\ncombination of the hyperparameters is, however, a challenging job. This is\nmainly because evaluation of each combination is extremely expensive\ncomputationally; indeed, training a machine learning system on real data with\njust a single combination of hyperparameters usually takes hours or even days.\nIn this paper, we address this challenge by trying to predict the performance\nof the machine learning system with a given combination of hyperparameters\nwithout completing the expensive learning process. Instead, we terminate the\ntraining process at an early stage, collect the model performance data and use\nit to predict which of the combinations of hyperparameters is most promising.\nOur preliminary experiments show that such a prediction improves the\nperformance of the commonly used random search approach.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jul 2019 19:14:18 GMT"}, {"version": "v2", "created": "Tue, 6 Aug 2019 19:29:13 GMT"}], "update_date": "2019-08-08", "authors_parsed": [["Marinov", "Dobromir", ""], ["Karapetyan", "Daniel", ""]]}, {"id": "1907.08653", "submitter": "John Lafferty", "authors": "Ganlin Song, Zhou Fan, John Lafferty", "title": "Surfing: Iterative optimization over incrementally trained deep networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate a sequential optimization procedure to minimize the empirical\nrisk functional $f_{\\hat\\theta}(x) = \\frac{1}{2}\\|G_{\\hat\\theta}(x) - y\\|^2$\nfor certain families of deep networks $G_{\\theta}(x)$. The approach is to\noptimize a sequence of objective functions that use network parameters obtained\nduring different stages of the training process. When initialized with random\nparameters $\\theta_0$, we show that the objective $f_{\\theta_0}(x)$ is \"nice''\nand easy to optimize with gradient descent. As learning is carried out, we\nobtain a sequence of generative networks $x \\mapsto G_{\\theta_t}(x)$ and\nassociated risk functions $f_{\\theta_t}(x)$, where $t$ indicates a stage of\nstochastic gradient descent during training. Since the parameters of the\nnetwork do not change by very much in each step, the surface evolves slowly and\ncan be incrementally optimized. The algorithm is formalized and analyzed for a\nfamily of expansive networks. We call the procedure {\\it surfing} since it\nrides along the peak of the evolving (negative) empirical risk function,\nstarting from a smooth surface at the beginning of learning and ending with a\nwavy nonconvex surface after learning is complete. Experiments show how surfing\ncan be used to find the global optimum and for compressed sensing even when\ndirect gradient descent on the final learned network fails.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jul 2019 19:16:04 GMT"}], "update_date": "2019-07-23", "authors_parsed": [["Song", "Ganlin", ""], ["Fan", "Zhou", ""], ["Lafferty", "John", ""]]}, {"id": "1907.08657", "submitter": "Dany Haddad", "authors": "Dany Haddad and Joydeep Ghosh", "title": "Learning More From Less: Towards Strengthening Weak Supervision for\n  Ad-Hoc Retrieval", "comments": "SIGIR 2019", "journal-ref": null, "doi": "10.1145/3331184.3331272", "report-no": null, "categories": "cs.IR cs.LG", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  The limited availability of ground truth relevance labels has been a major\nimpediment to the application of supervised methods to ad-hoc retrieval. As a\nresult, unsupervised scoring methods, such as BM25, remain strong competitors\nto deep learning techniques which have brought on dramatic improvements in\nother domains, such as computer vision and natural language processing. Recent\nworks have shown that it is possible to take advantage of the performance of\nthese unsupervised methods to generate training data for learning-to-rank\nmodels. The key limitation to this line of work is the size of the training set\nrequired to surpass the performance of the original unsupervised method, which\ncan be as large as $10^{13}$ training examples. Building on these insights, we\npropose two methods to reduce the amount of training data required. The first\nmethod takes inspiration from crowdsourcing, and leverages multiple\nunsupervised rankers to generate soft, or noise-aware, training labels. The\nsecond identifies harmful, or mislabeled, training examples and removes them\nfrom the training set. We show that our methods allow us to surpass the\nperformance of the unsupervised baseline with far fewer training examples than\nprevious works.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jul 2019 19:27:14 GMT"}], "update_date": "2019-07-23", "authors_parsed": [["Haddad", "Dany", ""], ["Ghosh", "Joydeep", ""]]}, {"id": "1907.08674", "submitter": "Kiran Rama", "authors": "Kiran Rama, Pradeep Kumar, Bharat Bhasker", "title": "Deep Learning to Address Candidate Generation and Cold Start Challenges\n  in Recommender Systems: A Research Survey", "comments": "22 pages, Submitted and Presented at PAN IIM Conference in IIM\n  Bangalore", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Among the machine learning applications to business, recommender systems\nwould take one of the top places when it comes to success and adoption. They\nhelp the user in accelerating the process of search while helping businesses\nmaximize sales. Post phenomenal success in computer vision and speech\nrecognition, deep learning methods are beginning to get applied to recommender\nsystems. Current survey papers on deep learning in recommender systems provide\na historical overview and taxonomy of recommender systems based on type. Our\npaper addresses the gaps of providing a taxonomy of deep learning approaches to\naddress recommender systems problems in the areas of cold start and candidate\ngeneration in recommender systems. We outline different challenges in\nrecommender systems into those related to the recommendations themselves\n(include relevance, speed, accuracy and scalability), those related to the\nnature of the data (cold start problem, imbalance and sparsity) and candidate\ngeneration. We then provide a taxonomy of deep learning techniques to address\nthese challenges. Deep learning techniques are mapped to the different\nchallenges in recommender systems providing an overview of how deep learning\ntechniques can be used to address them. We contribute a taxonomy of deep\nlearning techniques to address the cold start and candidate generation problems\nin recommender systems. Cold Start is addressed through additional features\n(for audio, images, text) and by learning hidden user and item representations.\nCandidate generation has been addressed by separate networks, RNNs,\nautoencoders and hybrid methods. We also summarize the advantages and\nlimitations of these techniques while outlining areas for future research.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jul 2019 06:22:38 GMT"}], "update_date": "2019-07-23", "authors_parsed": [["Rama", "Kiran", ""], ["Kumar", "Pradeep", ""], ["Bhasker", "Bharat", ""]]}, {"id": "1907.08679", "submitter": "Zitao Liu", "authors": "Tianqiao Liu, Zhiwei Wang, Jiliang Tang, Songfan Yang, Gale Yan Huang,\n  Zitao Liu", "title": "Recommender Systems with Heterogeneous Side Information", "comments": null, "journal-ref": "Proceedings of the 2019 World Wide Web Conference", "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In modern recommender systems, both users and items are associated with rich\nside information, which can help understand users and items. Such information\nis typically heterogeneous and can be roughly categorized into flat and\nhierarchical side information. While side information has been proved to be\nvaluable, the majority of existing systems have exploited either only flat side\ninformation or only hierarchical side information due to the challenges brought\nby the heterogeneity. In this paper, we investigate the problem of exploiting\nheterogeneous side information for recommendations. Specifically, we propose a\nnovel framework jointly captures flat and hierarchical side information with\nmathematical coherence. We demonstrate the effectiveness of the proposed\nframework via extensive experiments on various real-world datasets. Empirical\nresults show that our approach is able to lead a significant performance gain\nover the state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jul 2019 03:20:21 GMT"}], "update_date": "2019-07-23", "authors_parsed": [["Liu", "Tianqiao", ""], ["Wang", "Zhiwei", ""], ["Tang", "Jiliang", ""], ["Yang", "Songfan", ""], ["Huang", "Gale Yan", ""], ["Liu", "Zitao", ""]]}, {"id": "1907.08686", "submitter": "Zhipeng Li", "authors": "Zhipeng Li, Jianwei Wu, Lin Sun, Tao Rong", "title": "Combinatorial Keyword Recommendations for Sponsored Search with Deep\n  Reinforcement Learning", "comments": "6 pages, adKDD 2019", "journal-ref": "In Proceedings of 2019 AdKDD, Anchorage, Alaska, USA, August,\n  2019, 6 pages", "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In sponsored search, keyword recommendations help advertisers to achieve much\nbetter performance within limited budget. Many works have been done to mine\nnumerous candidate keywords from search logs or landing pages. However, the\nstrategy to select from given candidates remains to be improved. The existing\nrelevance-based, popularity-based and regular combinatorial strategies fail to\ntake the internal or external competitions among keywords into consideration.\nIn this paper, we regard keyword recommendations as a combinatorial\noptimization problem and solve it with a modified pointer network structure.\nThe model is trained on an actor-critic based deep reinforcement learning\nframework. A pre-clustering method called Equal Size K-Means is proposed to\naccelerate the training and testing procedure on the framework by reducing the\naction space. The performance of framework is evaluated both in offline and\nonline environments, and remarkable improvements can be observed.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jul 2019 13:29:04 GMT"}], "update_date": "2019-07-23", "authors_parsed": [["Li", "Zhipeng", ""], ["Wu", "Jianwei", ""], ["Sun", "Lin", ""], ["Rong", "Tao", ""]]}, {"id": "1907.08687", "submitter": "Douglas Turnbull", "authors": "Daniel Akimchuk and Timothy Clerico and Douglas Turnbull", "title": "Evaluating Recommender System Algorithms for Generating Local Music\n  Playlists", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We explore the task of local music recommendation: provide listeners with\npersonalized playlists of relevant tracks by artists who play most of their\nlive events within a small geographic area. Most local artists tend to be\nobscure, long-tail artists and generally have little or no available user\npreference data associated with them. This creates a cold-start problem for\ncollaborative filtering-based recommendation algorithms that depend on large\namounts of such information to make accurate recommendations. In this paper, we\ncompare the performance of three standard recommender system algorithms\n(Item-Item Neighborhood (IIN), Alternating Least Squares for Implicit Feedback\n(ALS), and Bayesian Personalized Ranking (BPR)) on the task of local music\nrecommendation using the Million Playlist Dataset. To do this, we modify the\nstandard evaluation procedure such that the algorithms only rank tracks by\nlocal artists for each of the eight different cities. Despite the fact that\ntechniques based on matrix factorization (ALS, BPR) typically perform best on\nlarge recommendation tasks, we find that the neighborhood-based approach (IIN)\nperforms best for long-tail local music recommendation.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jul 2019 17:20:33 GMT"}], "update_date": "2019-07-23", "authors_parsed": [["Akimchuk", "Daniel", ""], ["Clerico", "Timothy", ""], ["Turnbull", "Douglas", ""]]}, {"id": "1907.08696", "submitter": "Zhongkai Sun", "authors": "Zhongkai Sun, Prathusha K Sarma, William Sethares, Erik P. Bucy", "title": "Multi-modal Sentiment Analysis using Deep Canonical Correlation Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper learns multi-modal embeddings from text, audio, and video\nviews/modes of data in order to improve upon down-stream sentiment\nclassification. The experimental framework also allows investigation of the\nrelative contributions of the individual views in the final multi-modal\nembedding. Individual features derived from the three views are combined into a\nmulti-modal embedding using Deep Canonical Correlation Analysis (DCCA) in two\nways i) One-Step DCCA and ii) Two-Step DCCA. This paper learns text embeddings\nusing BERT, the current state-of-the-art in text encoders. We posit that this\nhighly optimized algorithm dominates over the contribution of other views,\nthough each view does contribute to the final result. Classification tasks are\ncarried out on two benchmark datasets and on a new Debate Emotion data set, and\ntogether these demonstrate that the one-Step DCCA outperforms the current\nstate-of-the-art in learning multi-modal embeddings.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jul 2019 21:48:28 GMT"}], "update_date": "2019-07-23", "authors_parsed": [["Sun", "Zhongkai", ""], ["Sarma", "Prathusha K", ""], ["Sethares", "William", ""], ["Bucy", "Erik P.", ""]]}, {"id": "1907.08697", "submitter": "Cristian Rusu", "authors": "Cristian Rusu and Lorenzo Rosasco", "title": "Fast approximation of orthogonal matrices and application to PCA", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.LG cs.NA eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of approximating orthogonal matrices so that their\napplication is numerically fast and yet accurate. We find an approximation by\nsolving an optimization problem over a set of structured matrices, that we call\nextended orthogonal Givens transformations, including Givens rotations as a\nspecial case. We propose an efficient greedy algorithm to solve such a problem\nand show that it strikes a balance between approximation accuracy and speed of\ncomputation. The approach is relevant to spectral methods and we illustrate its\napplication to PCA.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jul 2019 09:33:11 GMT"}, {"version": "v2", "created": "Wed, 23 Oct 2019 12:34:33 GMT"}, {"version": "v3", "created": "Fri, 20 Mar 2020 19:23:34 GMT"}, {"version": "v4", "created": "Fri, 8 May 2020 15:31:51 GMT"}, {"version": "v5", "created": "Tue, 23 Mar 2021 16:30:44 GMT"}], "update_date": "2021-03-24", "authors_parsed": [["Rusu", "Cristian", ""], ["Rosasco", "Lorenzo", ""]]}, {"id": "1907.08698", "submitter": "Romain Hennequin", "authors": "Elena V. Epure, Anis Khlif, Romain Hennequin", "title": "Leveraging Knowledge Bases And Parallel Annotations For Music Genre\n  Translation", "comments": "Published in ISMIR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.IR cs.LG eess.AS stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Prevalent efforts have been put in automatically inferring genres of musical\nitems. Yet, the propose solutions often rely on simplifications and fail to\naddress the diversity and subjectivity of music genres. Accounting for these\nhas, though, many benefits for aligning knowledge sources, integrating data and\nenriching musical items with tags. Here, we choose a new angle for the genre\nstudy by seeking to predict what would be the genres of musical items in a\ntarget tag system, knowing the genres assigned to them within source tag\nsystems. We call this a translation task and identify three cases: 1) no common\nannotated corpus between source and target tag systems exists, 2) such a large\ncorpus exists, 3) only few common annotations exist. We propose the related\nsolutions: a knowledge-based translation modeled as taxonomy mapping, a\nstatistical translation modeled with maximum likelihood logistic regression; a\nhybrid translation modeled with maximum a posteriori logistic regression with\npriors given by the knowledge-based translation. During evaluation, the\nsolutions fit well the identified cases and the hybrid translation is\nsystematically the most effective w.r.t. multilabel classification metrics.\nThis is a first attempt to unify genre tag systems by leveraging both\nrepresentation and interpretation diversity.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jul 2019 15:23:15 GMT"}, {"version": "v2", "created": "Sat, 27 Jul 2019 20:31:33 GMT"}], "update_date": "2019-07-30", "authors_parsed": [["Epure", "Elena V.", ""], ["Khlif", "Anis", ""], ["Hennequin", "Romain", ""]]}, {"id": "1907.08731", "submitter": "Alexander Ponomarenko", "authors": "Alexander Ponomarenko, Leonidas Pitsoulis, Marat Shamshetdinov", "title": "Overlapping community detection in networks based on link partitioning\n  and partitioning around medoids", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.DM cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we present a new method for detecting overlapping communities\nin networks with a predefined number of clusters called LPAM (Link Partitioning\nAround Medoids). The overlapping communities in the graph are obtained by\ndetecting the disjoint communities in the associated line graph employing link\npartitioning and partitioning around medoids which are done through the use of\na distance function defined on the set of nodes. We consider both the commute\ndistance and amplified commute distance as distance functions. The performance\nof the LPAM method is evaluated with computational experiments on real life\ninstances, as well as synthetic network benchmarks. For small and medium-size\nnetworks, the exact solution was found, while for large networks we found\nsolutions with a heuristic version of the LPAM method.\n", "versions": [{"version": "v1", "created": "Sat, 20 Jul 2019 00:56:01 GMT"}, {"version": "v2", "created": "Sat, 24 Apr 2021 14:59:55 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Ponomarenko", "Alexander", ""], ["Pitsoulis", "Leonidas", ""], ["Shamshetdinov", "Marat", ""]]}, {"id": "1907.08736", "submitter": "Haohan Bo", "authors": "Haohan Bo, Steven H. H. Ding, Benjamin C. M. Fung, Farkhund Iqbal", "title": "ER-AE: Differentially Private Text Generation for Authorship\n  Anonymization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most of privacy protection studies for textual data focus on removing\nexplicit sensitive identifiers. However, personal writing style, as a strong\nindicator of the authorship, is often neglected. Recent studies, such as SynTF,\nhave shown promising results on privacy-preserving text mining. However, their\nanonymization algorithm can only output numeric term vectors which are\ndifficult for the recipients to interpret. We propose a novel text generation\nmodel with a two-set exponential mechanism for authorship anonymization. By\naugmenting the semantic information through a REINFORCE training reward\nfunction, the model can generate differentially private text that has a close\nsemantic and similar grammatical structure to the original text while removing\npersonal traits of the writing style. It does not assume any conditioned labels\nor paralleled text data for training. We evaluate the performance of the\nproposed model on the real-life peer reviews dataset and the Yelp review\ndataset. The result suggests that our model outperforms the state-of-the-art on\nsemantic preservation, authorship obfuscation, and stylometric transformation.\n", "versions": [{"version": "v1", "created": "Sat, 20 Jul 2019 02:07:02 GMT"}, {"version": "v2", "created": "Tue, 10 Sep 2019 14:45:01 GMT"}, {"version": "v3", "created": "Wed, 11 Sep 2019 17:48:09 GMT"}, {"version": "v4", "created": "Thu, 13 May 2021 07:55:27 GMT"}], "update_date": "2021-05-14", "authors_parsed": [["Bo", "Haohan", ""], ["Ding", "Steven H. H.", ""], ["Fung", "Benjamin C. M.", ""], ["Iqbal", "Farkhund", ""]]}, {"id": "1907.08738", "submitter": "Taehee Lee", "authors": "Taehee Lee, Lorraine E. Lisiecki, Devin Rand, Geoffrey Gebbie, Charles\n  E. Lawrence", "title": "Bayesian Inference Gaussian Process Multiproxy Alignment of Continuous\n  Signals (BIGMACS): Applications for Paleoceanography", "comments": "This article has been submitted to \"Bayesian Analysis\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We first introduce a novel profile-based alignment algorithm, the multiple\ncontinuous Signal Alignment algorithm with Gaussian Process Regression profiles\n(SA-GPR). SA-GPR addresses the limitations of currently available signal\nalignment methods by adopting a hybrid of the particle smoothing and\nMarkov-chain Monte Carlo (MCMC) algorithms to align signals, and by applying\nthe Gaussian process regression to construct profiles to be aligned\ncontinuously. SA-GPR shares all the strengths of the existing alignment\nalgorithms that depend on profiles but is more exact in the sense that profiles\ndo not need to be discretized as sequential bins. The uncertainty of\nperformance over the resolution of such bins is thereby eliminated. This\nmethodology produces alignments that are consistent, that regularize extreme\ncases, and that properly reflect the inherent uncertainty.\n  Then we extend SA-GPR to a specific problem in the field of paleoceanography\nwith a method called Bayesian Inference Gaussian Process Multiproxy Alignment\nof Continuous Signals (BIGMACS). The goal of BIGMACS is to infer continuous\nages for ocean sediment cores using two classes of age proxies: proxies that\nexplicitly return calendar ages (e.g., radiocarbon) and those used to\nsynchronize ages in multiple marine records (e.g., an oxygen isotope based\nmarine proxy known as benthic ${\\delta}^{18}{\\rm O}$). BIGMACS integrates these\ntwo proxies by iteratively performing two steps: profile construction from\nbenthic ${\\delta}^{18}{\\rm O}$ age models and alignment of each core to the\nprofile also reflecting radiocarbon dates. We use BIGMACS to construct a new\nDeep Northeastern Atlantic stack (i.e., a profile from a particular benthic\n${\\delta}^{18}{\\rm O}$ records) of five ocean sediment cores. We conclude by\nconstructing multiproxy age models for two additional cores from the same\nregion by aligning them to the stack.\n", "versions": [{"version": "v1", "created": "Sat, 20 Jul 2019 02:44:00 GMT"}, {"version": "v2", "created": "Tue, 24 Dec 2019 05:25:07 GMT"}, {"version": "v3", "created": "Fri, 27 Dec 2019 05:56:21 GMT"}, {"version": "v4", "created": "Sun, 13 Jun 2021 09:11:58 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Lee", "Taehee", ""], ["Lisiecki", "Lorraine E.", ""], ["Rand", "Devin", ""], ["Gebbie", "Geoffrey", ""], ["Lawrence", "Charles E.", ""]]}, {"id": "1907.08743", "submitter": "Cl\\'ement Canonne", "authors": "Jayadev Acharya, Cl\\'ement L. Canonne, Yanjun Han, Ziteng Sun, and\n  Himanshu Tyagi", "title": "Domain Compression and its Application to Randomness-Optimal Distributed\n  Goodness-of-Fit", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM cs.IT cs.LG math.IT math.ST stat.TH", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We study goodness-of-fit of discrete distributions in the distributed\nsetting, where samples are divided between multiple users who can only release\na limited amount of information about their samples due to various information\nconstraints. Recently, a subset of the authors showed that having access to a\ncommon random seed (i.e., shared randomness) leads to a significant reduction\nin the sample complexity of this problem. In this work, we provide a complete\nunderstanding of the interplay between the amount of shared randomness\navailable, the stringency of information constraints, and the sample complexity\nof the testing problem by characterizing a tight trade-off between these three\nparameters. We provide a general distributed goodness-of-fit protocol that as a\nfunction of the amount of shared randomness interpolates smoothly between the\nprivate- and public-coin sample complexities. We complement our upper bound\nwith a general framework to prove lower bounds on the sample complexity of this\ntesting problems under limited shared randomness. Finally, we instantiate our\nbounds for the two archetypal information constraints of communication and\nlocal privacy, and show that our sample complexity bounds are optimal as a\nfunction of all the parameters of the problem, including the amount of shared\nrandomness.\n  A key component of our upper bounds is a new primitive of domain compression,\na tool that allows us to map distributions to a much smaller domain size while\npreserving their pairwise distances, using a limited amount of randomness.\n", "versions": [{"version": "v1", "created": "Sat, 20 Jul 2019 03:03:56 GMT"}], "update_date": "2019-07-23", "authors_parsed": [["Acharya", "Jayadev", ""], ["Canonne", "Cl\u00e9ment L.", ""], ["Han", "Yanjun", ""], ["Sun", "Ziteng", ""], ["Tyagi", "Himanshu", ""]]}, {"id": "1907.08744", "submitter": "Henry M. Kim", "authors": "Hjalmar Turesson, Henry M. Kim, Marek Laskowski, Alexandra Roatis", "title": "Proof-of-Useful-Work as Dual-Purpose Mechanism for Blockchain and AI:\n  Blockchain Consensus that Enables Privacy Preserving Data Mining", "comments": "I would like to withdraw the paper as there is an internal dispute\n  about who the authors of the paper are. In previous versions, it is fair to\n  say that the names and order of the authors are representative of\n  contribution but the same cannot be said for this version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Blockchains rely on a consensus among participants to achieve\ndecentralization and security. However, reaching consensus in an online,\ndigital world where identities are not tied to physical users is a challenging\nproblem. Proof-of-work provides a solution by linking representation to a\nvaluable, physical resource. While this has worked well, it uses a tremendous\namount of specialized hardware and energy, with no utility beyond blockchain\nsecurity. Here, we propose an alternative consensus scheme that directs the\ncomputational resources to the optimization of machine learning (ML) models, a\ntask with more general utility. This is achieved by a hybrid consensus scheme\nrelying on three parties: data providers, miners, and a committee. The data\nprovider makes data available and provides payment in return for the best\nmodel, miners compete about the payment and access to the committee by\nproducing ML optimized models, and the committee controls the ML competition.\n", "versions": [{"version": "v1", "created": "Sat, 20 Jul 2019 03:22:56 GMT"}, {"version": "v2", "created": "Sat, 14 Sep 2019 12:12:17 GMT"}, {"version": "v3", "created": "Fri, 23 Oct 2020 06:28:33 GMT"}, {"version": "v4", "created": "Thu, 12 Nov 2020 20:49:35 GMT"}], "update_date": "2020-11-16", "authors_parsed": [["Turesson", "Hjalmar", ""], ["Kim", "Henry M.", ""], ["Laskowski", "Marek", ""], ["Roatis", "Alexandra", ""]]}, {"id": "1907.08793", "submitter": "Pedro Almagro-Blanco", "authors": "Pedro Almagro-Blanco, Fernando Sancho-Caparrini", "title": "Improving Skip-Gram based Graph Embeddings via Centrality-Weighted\n  Sampling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network embedding techniques inspired by word2vec represent an effective\nunsupervised relational learning model. Commonly, by means of a Skip-Gram\nprocedure, these techniques learn low dimensional vector representations of the\nnodes in a graph by sampling node-context examples. Although many ways of\nsampling the context of a node have been proposed, the effects of the way a\nnode is chosen have not been analyzed in depth. To fill this gap, we have\nre-implemented the main four word2vec inspired graph embedding techniques under\nthe same framework and analyzed how different sampling distributions affects\nembeddings performance when tested in node classification problems. We present\na set of experiments on different well known real data sets that show how the\nuse of popular centrality distributions in sampling leads to improvements,\nobtaining speeds of up to 2 times in learning times and increasing accuracy in\nall cases.\n", "versions": [{"version": "v1", "created": "Sat, 20 Jul 2019 10:46:03 GMT"}], "update_date": "2019-07-23", "authors_parsed": [["Almagro-Blanco", "Pedro", ""], ["Sancho-Caparrini", "Fernando", ""]]}, {"id": "1907.08823", "submitter": "Bhaskar Ramasubramanian", "authors": "Baicen Xiao, Bhaskar Ramasubramanian, Andrew Clark, Hannaneh\n  Hajishirzi, Linda Bushnell, Radha Poovendran", "title": "Potential-Based Advice for Stochastic Policy Learning", "comments": "Accepted to the IEEE Conference on Decision and Control, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper augments the reward received by a reinforcement learning agent\nwith potential functions in order to help the agent learn (possibly stochastic)\noptimal policies. We show that a potential-based reward shaping scheme is able\nto preserve optimality of stochastic policies, and demonstrate that the ability\nof an agent to learn an optimal policy is not affected when this scheme is\naugmented to soft Q-learning. We propose a method to impart potential based\nadvice schemes to policy gradient algorithms. An algorithm that considers an\nadvantage actor-critic architecture augmented with this scheme is proposed, and\nwe give guarantees on its convergence. Finally, we evaluate our approach on a\npuddle-jump grid world with indistinguishable states, and the continuous state\nand action mountain car environment from classical control. Our results\nindicate that these schemes allow the agent to learn a stochastic optimal\npolicy faster and obtain a higher average reward.\n", "versions": [{"version": "v1", "created": "Sat, 20 Jul 2019 15:21:11 GMT"}], "update_date": "2019-07-23", "authors_parsed": [["Xiao", "Baicen", ""], ["Ramasubramanian", "Bhaskar", ""], ["Clark", "Andrew", ""], ["Hajishirzi", "Hannaneh", ""], ["Bushnell", "Linda", ""], ["Poovendran", "Radha", ""]]}, {"id": "1907.08827", "submitter": "Wonyeol Lee", "authors": "Wonyeol Lee, Hangyeol Yu, Xavier Rival, Hongseok Yang", "title": "Towards Verified Stochastic Variational Inference for Probabilistic\n  Programs", "comments": "To appear at Principles of Programming Languages (POPL) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Probabilistic programming is the idea of writing models from statistics and\nmachine learning using program notations and reasoning about these models using\ngeneric inference engines. Recently its combination with deep learning has been\nexplored intensely, leading to the development of deep probabilistic\nprogramming languages such as Pyro. At the core of this development lie\ninference engines based on stochastic variational inference algorithms. When\nasked to find information about the posterior distribution of a model written\nin such a language, these algorithms convert this posterior-inference query\ninto an optimisation problem and solve it approximately by gradient ascent. In\nthis paper, we analyse one of the most fundamental and versatile variational\ninference algorithms, called score estimator, using tools from denotational\nsemantics and program analysis. We formally express what this algorithm does on\nmodels denoted by programs, and expose implicit assumptions made by the\nalgorithm. The violation of these assumptions may lead to an undefined\noptimisation objective or the loss of convergence guarantee of the optimisation\nprocess. We then describe rules for proving these assumptions, which can be\nautomated by static program analyses. Some of our rules use nontrivial facts\nfrom continuous mathematics, and let us replace requirements about integrals in\nthe assumptions, by conditions involving differentiation or boundedness, which\nare much easier to prove automatically. Following our general methodology, we\nhave developed a static program analysis for Pyro that aims at discharging the\nassumption about what we call model-guide support match. Applied to the eight\nrepresentative model-guide pairs from the Pyro webpage, our analysis finds a\nbug in one of these cases, reveals a non-standard use of an inference engine in\nanother, and shows the assumptions are met in the remaining cases.\n", "versions": [{"version": "v1", "created": "Sat, 20 Jul 2019 15:33:40 GMT"}, {"version": "v2", "created": "Thu, 25 Jul 2019 19:04:47 GMT"}, {"version": "v3", "created": "Sat, 26 Oct 2019 11:36:57 GMT"}, {"version": "v4", "created": "Mon, 18 Nov 2019 05:37:42 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Lee", "Wonyeol", ""], ["Yu", "Hangyeol", ""], ["Rival", "Xavier", ""], ["Yang", "Hongseok", ""]]}, {"id": "1907.08831", "submitter": "Markus Roland Ernst", "authors": "Markus Roland Ernst, Jochen Triesch, Thomas Burwick", "title": "Recurrent Connections Aid Occluded Object Recognition by Discounting\n  Occluders", "comments": "13 pages, 5 figures, accepted at the 28th International Conference on\n  Artificial Neural Networks, published in Springer Lecture Notes in Computer\n  Science vol 11729", "journal-ref": "In: Tetko, I. V. et al. (eds.) ICANN 2019. LNCS, vol 11729.\n  Springer, Cham, pp 294-305", "doi": "10.1007/978-3-030-30508-6_24", "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent connections in the visual cortex are thought to aid object\nrecognition when part of the stimulus is occluded. Here we investigate if and\nhow recurrent connections in artificial neural networks similarly aid object\nrecognition. We systematically test and compare architectures comprised of\nbottom-up (B), lateral (L) and top-down (T) connections. Performance is\nevaluated on a novel stereoscopic occluded object recognition dataset. The task\nconsists of recognizing one target digit occluded by multiple occluder digits\nin a pseudo-3D environment. We find that recurrent models perform significantly\nbetter than their feedforward counterparts, which were matched in parametric\ncomplexity. Furthermore, we analyze how the network's representation of the\nstimuli evolves over time due to recurrent connections. We show that the\nrecurrent connections tend to move the network's representation of an occluded\ndigit towards its un-occluded version. Our results suggest that both the brain\nand artificial neural networks can exploit recurrent connectivity to aid\noccluded object recognition.\n", "versions": [{"version": "v1", "created": "Sat, 20 Jul 2019 16:10:04 GMT"}, {"version": "v2", "created": "Wed, 11 Sep 2019 09:36:29 GMT"}], "update_date": "2019-09-12", "authors_parsed": [["Ernst", "Markus Roland", ""], ["Triesch", "Jochen", ""], ["Burwick", "Thomas", ""]]}, {"id": "1907.08834", "submitter": "James Cheney", "authors": "S\\'andor Bartha and James Cheney", "title": "Towards meta-interpretive learning of programming language semantics", "comments": "ILP 2019, to appear", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LG cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new application for inductive logic programming: learning the\nsemantics of programming languages from example evaluations. In this short\npaper, we explored a simplified task in this domain using the Metagol\nmeta-interpretive learning system. We highlighted the challenging aspects of\nthis scenario, including abstracting over function symbols, nonterminating\nexamples, and learning non-observed predicates, and proposed extensions to\nMetagol helpful for overcoming these challenges, which may prove useful in\nother domains.\n", "versions": [{"version": "v1", "created": "Sat, 20 Jul 2019 16:39:06 GMT"}], "update_date": "2019-07-23", "authors_parsed": [["Bartha", "S\u00e1ndor", ""], ["Cheney", "James", ""]]}, {"id": "1907.08880", "submitter": "Jiaming Xu", "authors": "Zhou Fan, Cheng Mao, Yihong Wu, and Jiaming Xu", "title": "Spectral Graph Matching and Regularized Quadratic Relaxations I: The\n  Gaussian Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.PR math.SP math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph matching aims at finding the vertex correspondence between two\nunlabeled graphs that maximizes the total edge weight correlation. This amounts\nto solving a computationally intractable quadratic assignment problem. In this\npaper we propose a new spectral method, GRAph Matching by Pairwise\neigen-Alignments (GRAMPA). Departing from prior spectral approaches that only\ncompare top eigenvectors, or eigenvectors of the same order, GRAMPA first\nconstructs a similarity matrix as a weighted sum of outer products between all\npairs of eigenvectors of the two graphs, with weights given by a Cauchy kernel\napplied to the separation of the corresponding eigenvalues, then outputs a\nmatching by a simple rounding procedure. The similarity matrix can also be\ninterpreted as the solution to a regularized quadratic programming relaxation\nof the quadratic assignment problem.\n  For the Gaussian Wigner model in which two complete graphs on $n$ vertices\nhave Gaussian edge weights with correlation coefficient $1-\\sigma^2$, we show\nthat GRAMPA exactly recovers the correct vertex correspondence with high\nprobability when $\\sigma = O(\\frac{1}{\\log n})$. This matches the state of the\nart of polynomial-time algorithms, and significantly improves over existing\nspectral methods which require $\\sigma$ to be polynomially small in $n$. The\nsuperiority of GRAMPA is also demonstrated on a variety of synthetic and real\ndatasets, in terms of both statistical accuracy and computational efficiency.\nUniversality results, including similar guarantees for dense and sparse\nErd\\H{o}s-R\\'{e}nyi graphs, are deferred to the companion paper.\n", "versions": [{"version": "v1", "created": "Sat, 20 Jul 2019 23:36:41 GMT"}], "update_date": "2019-07-23", "authors_parsed": [["Fan", "Zhou", ""], ["Mao", "Cheng", ""], ["Wu", "Yihong", ""], ["Xu", "Jiaming", ""]]}, {"id": "1907.08883", "submitter": "Jiaming Xu", "authors": "Zhou Fan, Cheng Mao, Yihong Wu, and Jiaming Xu", "title": "Spectral Graph Matching and Regularized Quadratic Relaxations II:\n  Erd\\H{o}s-R\\'enyi Graphs and Universality", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR cs.LG math.SP math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyze a new spectral graph matching algorithm, GRAph Matching by\nPairwise eigen-Alignments (GRAMPA), for recovering the latent vertex\ncorrespondence between two unlabeled, edge-correlated weighted graphs.\nExtending the exact recovery guarantees established in the companion paper for\nGaussian weights, in this work, we prove the universality of these guarantees\nfor a general correlated Wigner model. In particular, for two Erd\\H{o}s-R\\'enyi\ngraphs with edge correlation coefficient $1-\\sigma^2$ and average degree at\nleast $\\operatorname{polylog}(n)$, we show that GRAMPA exactly recovers the\nlatent vertex correspondence with high probability when $\\sigma \\lesssim\n1/\\operatorname{polylog}(n)$. Moreover, we establish a similar guarantee for a\nvariant of GRAMPA, corresponding to a tighter quadratic programming relaxation\nof the quadratic assignment problem. Our analysis exploits a resolvent\nrepresentation of the GRAMPA similarity matrix and local laws for the\nresolvents of sparse Wigner matrices.\n", "versions": [{"version": "v1", "created": "Sat, 20 Jul 2019 23:50:02 GMT"}], "update_date": "2019-07-23", "authors_parsed": [["Fan", "Zhou", ""], ["Mao", "Cheng", ""], ["Wu", "Yihong", ""], ["Xu", "Jiaming", ""]]}, {"id": "1907.08892", "submitter": "Jan Strappa Figueroa", "authors": "Jan Strappa and Facundo Bromberg", "title": "Efficient comparison of independence structures of log-linear models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Log-linear models are a family of probability distributions which capture\nrelationships between variables, including context-specific independencies.\nMany approaches exist for automatic learning of their independence structures\nfrom data, although the only known methods for evaluating these approaches are\nindirect measures of their complete density. This requires additional learning\nof numerical parameters, and introduces distortions when used for comparing\nstructures. This work addresses this issue by presenting a measure for the\ndirect and efficient comparison of independence structures of log-linear\nmodels. We present proof that the measure is a metric, and a method for its\ncomputation that is efficient in the number of variables of the domain.\nEfficiency in the number of features in the models is not guaranteed and will\nbe the subject of future work.\n", "versions": [{"version": "v1", "created": "Sun, 21 Jul 2019 01:52:28 GMT"}, {"version": "v2", "created": "Thu, 11 Feb 2021 14:10:35 GMT"}, {"version": "v3", "created": "Thu, 13 May 2021 21:18:32 GMT"}], "update_date": "2021-05-17", "authors_parsed": [["Strappa", "Jan", ""], ["Bromberg", "Facundo", ""]]}, {"id": "1907.08908", "submitter": "Yi-Wei Chen", "authors": "Yi-Wei Chen, Qingquan Song, Xia Hu", "title": "Techniques for Automated Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automated machine learning (AutoML) aims to find optimal machine learning\nsolutions automatically given a machine learning problem. It could release the\nburden of data scientists from the multifarious manual tuning process and\nenable the access of domain experts to the off-the-shelf machine learning\nsolutions without extensive experience. In this paper, we review the current\ndevelopments of AutoML in terms of three categories, automated feature\nengineering (AutoFE), automated model and hyperparameter learning (AutoMHL),\nand automated deep learning (AutoDL). State-of-the-art techniques adopted in\nthe three categories are presented, including Bayesian optimization,\nreinforcement learning, evolutionary algorithm, and gradient-based approaches.\nWe summarize popular AutoML frameworks and conclude with current open\nchallenges of AutoML.\n", "versions": [{"version": "v1", "created": "Sun, 21 Jul 2019 04:03:36 GMT"}], "update_date": "2019-07-23", "authors_parsed": [["Chen", "Yi-Wei", ""], ["Song", "Qingquan", ""], ["Hu", "Xia", ""]]}, {"id": "1907.08922", "submitter": "Melvin Wevers", "authors": "Melvin Wevers", "title": "Using Word Embeddings to Examine Gender Bias in Dutch Newspapers,\n  1950-1990", "comments": "6 pages with appendix. Published in Proceedings of the 1st\n  International Workshop on Computational Approaches to Historical Language\n  Change 2019 co-organized with ACL2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Contemporary debates on filter bubbles and polarization in public and social\nmedia raise the question to what extent news media of the past exhibited\nbiases. This paper specifically examines bias related to gender in six Dutch\nnational newspapers between 1950 and 1990. We measure bias related to gender by\ncomparing local changes in word embedding models trained on newspapers with\ndivergent ideological backgrounds. We demonstrate clear differences in gender\nbias and changes within and between newspapers over time. In relation to themes\nsuch as sexuality and leisure, we see the bias moving toward women, whereas,\ngenerally, the bias shifts in the direction of men, despite growing female\nemployment number and feminist movements. Even though Dutch society became less\nstratified ideologically (depillarization), we found an increasing divergence\nin gender bias between religious and social-democratic on the one hand and\nliberal newspapers on the other. Methodologically, this paper illustrates how\nword embeddings can be used to examine historical language change. Future work\nwill investigate how fine-tuning deep contextualized embedding models, such as\nELMO, might be used for similar tasks with greater contextual information.\n", "versions": [{"version": "v1", "created": "Sun, 21 Jul 2019 06:58:22 GMT"}], "update_date": "2019-07-23", "authors_parsed": [["Wevers", "Melvin", ""]]}, {"id": "1907.08931", "submitter": "Kensuke Nakamura", "authors": "Kensuke Nakamura, Byung-Woo Hong", "title": "Adaptive Weight Decay for Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Regularization in the optimization of deep neural networks is often critical\nto avoid undesirable over-fitting leading to better generalization of model.\nOne of the most popular regularization algorithms is to impose L-2 penalty on\nthe model parameters resulting in the decay of parameters, called weight-decay,\nand the decay rate is generally constant to all the model parameters in the\ncourse of optimization. In contrast to the previous approach based on the\nconstant rate of weight-decay, we propose to consider the residual that\nmeasures dissimilarity between the current state of model and observations in\nthe determination of the weight-decay for each parameter in an adaptive way,\ncalled adaptive weight-decay (AdaDecay) where the gradient norms are normalized\nwithin each layer and the degree of regularization for each parameter is\ndetermined in proportional to the magnitude of its gradient using the sigmoid\nfunction. We empirically demonstrate the effectiveness of AdaDecay in\ncomparison to the state-of-the-art optimization algorithms using popular\nbenchmark datasets: MNIST, Fashion-MNIST, and CIFAR-10 with conventional neural\nnetwork models ranging from shallow to deep. The quantitative evaluation of our\nproposed algorithm indicates that AdaDecay improves generalization leading to\nbetter accuracy across all the datasets and models.\n", "versions": [{"version": "v1", "created": "Sun, 21 Jul 2019 08:04:29 GMT"}, {"version": "v2", "created": "Wed, 7 Aug 2019 20:27:52 GMT"}], "update_date": "2019-08-09", "authors_parsed": [["Nakamura", "Kensuke", ""], ["Hong", "Byung-Woo", ""]]}, {"id": "1907.08937", "submitter": "Hao Zhu", "authors": "Weize Chen, Hao Zhu, Xu Han, Zhiyuan Liu, Maosong Sun", "title": "Quantifying Similarity between Relations with Fact Distribution", "comments": "ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  We introduce a conceptually simple and effective method to quantify the\nsimilarity between relations in knowledge bases. Specifically, our approach is\nbased on the divergence between the conditional probability distributions over\nentity pairs. In this paper, these distributions are parameterized by a very\nsimple neural network. Although computing the exact similarity is in-tractable,\nwe provide a sampling-based method to get a good approximation. We empirically\nshow the outputs of our approach significantly correlate with human judgments.\nBy applying our method to various tasks, we also find that (1) our approach\ncould effectively detect redundant relations extracted by open information\nextraction (Open IE) models, that (2) even the most competitive models for\nrelational classification still make mistakes among very similar relations, and\nthat (3) our approach could be incorporated into negative sampling and softmax\nclassification to alleviate these mistakes. The source code and experiment\ndetails of this paper can be obtained from\nhttps://github.com/thunlp/relation-similarity.\n", "versions": [{"version": "v1", "created": "Sun, 21 Jul 2019 09:22:50 GMT"}], "update_date": "2019-07-23", "authors_parsed": [["Chen", "Weize", ""], ["Zhu", "Hao", ""], ["Han", "Xu", ""], ["Liu", "Zhiyuan", ""], ["Sun", "Maosong", ""]]}, {"id": "1907.08953", "submitter": "Miao Zhang", "authors": "Miao Zhang, Huiqi Li, Steven Su", "title": "High Dimensional Bayesian Optimization via Supervised Dimension\n  Reduction", "comments": "7 pages, 3 figures, IJCAI 2019 accepted paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian optimization (BO) has been broadly applied to computational\nexpensive problems, but it is still challenging to extend BO to high\ndimensions. Existing works are usually under strict assumption of an additive\nor a linear embedding structure for objective functions. This paper directly\nintroduces a supervised dimension reduction method, Sliced Inverse Regression\n(SIR), to high dimensional Bayesian optimization, which could effectively learn\nthe intrinsic sub-structure of objective function during the optimization.\nFurthermore, a kernel trick is developed to reduce computational complexity and\nlearn nonlinear subset of the unknowing function when applying SIR to extremely\nhigh dimensional BO. We present several computational benefits and derive\ntheoretical regret bounds of our algorithm. Extensive experiments on synthetic\nexamples and two real applications demonstrate the superiority of our\nalgorithms for high dimensional Bayesian optimization.\n", "versions": [{"version": "v1", "created": "Sun, 21 Jul 2019 10:31:23 GMT"}], "update_date": "2019-07-23", "authors_parsed": [["Zhang", "Miao", ""], ["Li", "Huiqi", ""], ["Su", "Steven", ""]]}, {"id": "1907.08956", "submitter": "Stephen Odaibo", "authors": "Stephen Odaibo", "title": "Tutorial: Deriving the Standard Variational Autoencoder (VAE) Loss\n  Function", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In Bayesian machine learning, the posterior distribution is typically\ncomputationally intractable, hence variational inference is often required. In\nthis approach, an evidence lower bound on the log likelihood of data is\nmaximized during training. Variational Autoencoders (VAE) are one important\nexample where variational inference is utilized. In this tutorial, we derive\nthe variational lower bound loss function of the standard variational\nautoencoder. We do so in the instance of a gaussian latent prior and gaussian\napproximate posterior, under which assumptions the Kullback-Leibler term in the\nvariational lower bound has a closed form solution. We derive essentially\neverything we use along the way; everything from Bayes' theorem to the\nKullback-Leibler divergence.\n", "versions": [{"version": "v1", "created": "Sun, 21 Jul 2019 11:09:42 GMT"}], "update_date": "2019-07-23", "authors_parsed": [["Odaibo", "Stephen", ""]]}, {"id": "1907.08962", "submitter": "Petr Prokofjev", "authors": "Elena V. Djukova, Gleb O. Masliakov, Petr A. Prokofyev", "title": "Logical Classification of Partially Ordered Data", "comments": "11 pages, 1 figure, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Issues concerning intelligent data analysis occurring in machine learning are\ninvestigated. A scheme for synthesizing correct supervised classification\nprocedures is proposed. These procedures are focused on specifying partial\norder relations on sets of feature values; they are based on a generalization\nof the classical concepts of logical classification. It is shown that learning\nthe correct logical classifier requires an intractable discrete problem to be\nsolved. This is the dualization problem over products of partially ordered\nsets. The matrix formulation of this problem is given. The effectiveness of the\nproposed approach to the supervised classification problem is illustrated on\nmodel and real-life data.\n", "versions": [{"version": "v1", "created": "Sun, 21 Jul 2019 12:18:54 GMT"}], "update_date": "2019-07-23", "authors_parsed": [["Djukova", "Elena V.", ""], ["Masliakov", "Gleb O.", ""], ["Prokofyev", "Petr A.", ""]]}, {"id": "1907.08967", "submitter": "Vikas Dwivedi", "authors": "Vikas Dwivedi, Nishant Parashar, Balaji Srinivasan", "title": "Distributed physics informed neural network for data-efficient solution\n  to partial differential equations", "comments": "16 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG physics.comp-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The physics informed neural network (PINN) is evolving as a viable method to\nsolve partial differential equations. In the recent past PINNs have been\nsuccessfully tested and validated to find solutions to both linear and\nnon-linear partial differential equations (PDEs). However, the literature lacks\ndetailed investigation of PINNs in terms of their representation capability. In\nthis work, we first test the original PINN method in terms of its capability to\nrepresent a complicated function. Further, to address the shortcomings of the\nPINN architecture, we propose a novel distributed PINN, named DPINN. We first\nperform a direct comparison of the proposed DPINN approach against PINN to\nsolve a non-linear PDE (Burgers' equation). We show that DPINN not only yields\na more accurate solution to the Burgers' equation, but it is found to be more\ndata-efficient as well. At last, we employ our novel DPINN to two-dimensional\nsteady-state Navier-Stokes equation, which is a system of non-linear PDEs. To\nthe best of the authors' knowledge, this is the first such attempt to directly\nsolve the Navier-Stokes equation using a physics informed neural network.\n", "versions": [{"version": "v1", "created": "Sun, 21 Jul 2019 12:45:18 GMT"}], "update_date": "2019-07-23", "authors_parsed": [["Dwivedi", "Vikas", ""], ["Parashar", "Nishant", ""], ["Srinivasan", "Balaji", ""]]}, {"id": "1907.08968", "submitter": "Antonia Saravanou", "authors": "Antonia Saravanou, Clemens Noelke, Nicholas Huntington, Dolores\n  Acevedo-Garcia, Dimitrios Gunopulos", "title": "Infant Mortality Prediction using Birth Certificate Data", "comments": "DSHealth Workshop, Health Day, SIGKDD 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Infant Mortality Rate (IMR) is the number of infants per 1000 that do not\nsurvive until their first birthday. It is an important metric providing\ninformation about infant health but it also measures the society's general\nhealth status. Despite the high level of prosperity in the U.S.A., the\ncountry's IMR is higher than that of many other developed countries.\nAdditionally, the U.S.A. exhibits persistent inequalities in the IMR across\ndifferent racial and ethnic groups. In this paper, we study the infant\nmortality prediction using features extracted from birth certificates. We are\ninterested in training classification models to decide whether an infant will\nsurvive or not. We focus on exploring and understanding the importance of\nfeatures in subsets of the population; we compare models trained for individual\nraces to general models. Our evaluation shows that our methodology outperforms\nstandard classification methods used by epidemiology researchers.\n", "versions": [{"version": "v1", "created": "Sun, 21 Jul 2019 12:45:59 GMT"}, {"version": "v2", "created": "Thu, 25 Jul 2019 09:14:54 GMT"}], "update_date": "2019-07-26", "authors_parsed": [["Saravanou", "Antonia", ""], ["Noelke", "Clemens", ""], ["Huntington", "Nicholas", ""], ["Acevedo-Garcia", "Dolores", ""], ["Gunopulos", "Dimitrios", ""]]}, {"id": "1907.08971", "submitter": "Eyal Shnarch", "authors": "Martin Gleize, Eyal Shnarch, Leshem Choshen, Lena Dankin, Guy\n  Moshkowich, Ranit Aharonov, Noam Slonim", "title": "Are You Convinced? Choosing the More Convincing Evidence with a Siamese\n  Network", "comments": "accepted to ACL 2019 - long paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  With the advancement in argument detection, we suggest to pay more attention\nto the challenging task of identifying the more convincing arguments. Machines\ncapable of responding and interacting with humans in helpful ways have become\nubiquitous. We now expect them to discuss with us the more delicate questions\nin our world, and they should do so armed with effective arguments. But what\nmakes an argument more persuasive? What will convince you? In this paper, we\npresent a new data set, IBM-EviConv, of pairs of evidence labeled for\nconvincingness, designed to be more challenging than existing alternatives. We\nalso propose a Siamese neural network architecture shown to outperform several\nbaselines on both a prior convincingness data set and our own. Finally, we\nprovide insights into our experimental results and the various kinds of\nargumentative value our method is capable of detecting.\n", "versions": [{"version": "v1", "created": "Sun, 21 Jul 2019 13:05:45 GMT"}, {"version": "v2", "created": "Tue, 23 Jul 2019 09:14:32 GMT"}], "update_date": "2019-07-24", "authors_parsed": [["Gleize", "Martin", ""], ["Shnarch", "Eyal", ""], ["Choshen", "Leshem", ""], ["Dankin", "Lena", ""], ["Moshkowich", "Guy", ""], ["Aharonov", "Ranit", ""], ["Slonim", "Noam", ""]]}, {"id": "1907.08981", "submitter": "Zhanzhan Zhao", "authors": "Zhanzhan Zhao, Haoran Sun", "title": "Alice's Adventures in the Markovian World", "comments": "9 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.LG cs.RO cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes an algorithm Alice having no access to the physics law of\nthe environment, which is actually linear with stochastic noise, and learns to\nmake decisions directly online without a training phase or a stable policy as\ninitial input. Neither estimating the system parameters nor the value functions\nonline, the proposed algorithm generalizes one of the most fundamental online\nlearning algorithms Follow-the-Leader into a linear Gauss-Markov process\nsetting, with a regularization term similar to the momentum method in the\ngradient descent algorithm, and a feasible online constraint inspired by\nLyapunov's Second Theorem. The proposed algorithm is considered as a mirror\noptimization to the model predictive control. Only knowing the state-action\nalignment relationship, with the ability to observe every state exactly, a\nno-regret proof of the algorithm without state noise is given. The analysis of\nthe general linear system with stochastic noise is shown with a sufficient\ncondition for the no-regret proof. The simulations compare the performance of\nAlice with another recent work and verify the great flexibility of Alice.\n", "versions": [{"version": "v1", "created": "Sun, 21 Jul 2019 14:16:57 GMT"}], "update_date": "2019-07-23", "authors_parsed": [["Zhao", "Zhanzhan", ""], ["Sun", "Haoran", ""]]}, {"id": "1907.08982", "submitter": "Jonas Rothfuss", "authors": "Jonas Rothfuss, Fabio Ferreira, Simon Boehm, Simon Walther, Maxim\n  Ulrich, Tamim Asfour, Andreas Krause", "title": "Noise Regularization for Conditional Density Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Modelling statistical relationships beyond the conditional mean is crucial in\nmany settings. Conditional density estimation (CDE) aims to learn the full\nconditional probability density from data. Though highly expressive, neural\nnetwork based CDE models can suffer from severe over-fitting when trained with\nthe maximum likelihood objective. Due to the inherent structure of such models,\nclassical regularization approaches in the parameter space are rendered\nineffective. To address this issue, we develop a model-agnostic noise\nregularization method for CDE that adds random perturbations to the data during\ntraining. We demonstrate that the proposed approach corresponds to a smoothness\nregularization and prove its asymptotic consistency. In our experiments, noise\nregularization significantly and consistently outperforms other regularization\nmethods across seven data sets and three CDE models. The effectiveness of noise\nregularization makes neural network based CDE the preferable method over\nprevious non- and semi-parametric approaches, even when training data is\nscarce.\n", "versions": [{"version": "v1", "created": "Sun, 21 Jul 2019 14:17:28 GMT"}, {"version": "v2", "created": "Fri, 14 Feb 2020 09:37:59 GMT"}], "update_date": "2020-02-17", "authors_parsed": [["Rothfuss", "Jonas", ""], ["Ferreira", "Fabio", ""], ["Boehm", "Simon", ""], ["Walther", "Simon", ""], ["Ulrich", "Maxim", ""], ["Asfour", "Tamim", ""], ["Krause", "Andreas", ""]]}, {"id": "1907.08990", "submitter": "Yi Ma", "authors": "Yi Ma, Jianye Hao, Yaodong Yang, Han Li, Junqi Jin, Guangyong Chen", "title": "Spectral-based Graph Convolutional Network for Directed Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph convolutional networks(GCNs) have become the most popular approaches\nfor graph data in these days because of their powerful ability to extract\nfeatures from graph. GCNs approaches are divided into two categories,\nspectral-based and spatial-based. As the earliest convolutional networks for\ngraph data, spectral-based GCNs have achieved impressive results in many graph\nrelated analytics tasks. However, spectral-based models cannot directly work on\ndirected graphs. In this paper, we propose an improved spectral-based GCN for\nthe directed graph by leveraging redefined Laplacians to improve its\npropagation model. Our approach can work directly on directed graph data in\nsemi-supervised nodes classification tasks. Experiments on a number of directed\ngraph datasets demonstrate that our approach outperforms the state-of-the-art\nmethods.\n", "versions": [{"version": "v1", "created": "Sun, 21 Jul 2019 15:35:16 GMT"}], "update_date": "2019-07-23", "authors_parsed": [["Ma", "Yi", ""], ["Hao", "Jianye", ""], ["Yang", "Yaodong", ""], ["Li", "Han", ""], ["Jin", "Junqi", ""], ["Chen", "Guangyong", ""]]}, {"id": "1907.08996", "submitter": "Mazharul Islam", "authors": "Mazharul Islam, Shuangrong Liu, Lin Wang, Xiaojing Zhang", "title": "Improving Neural Network Classifier using Gradient-based Floating\n  Centroid Method", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Floating centroid method (FCM) offers an efficient way to solve a\nfixed-centroid problem for the neural network classifiers. However,\nevolutionary computation as its optimization method restrains the FCM to\nachieve satisfactory performance for different neural network structures,\nbecause of the high computational complexity and inefficiency. Traditional\ngradient-based methods have been extensively adopted to optimize the neural\nnetwork classifiers. In this study, a gradient-based floating centroid (GDFC)\nmethod is introduced to address the fixed centroid problem for the neural\nnetwork classifiers optimized by gradient-based methods. Furthermore, a new\nloss function for optimizing GDFC is introduced. The experimental results\ndisplay that GDFC obtains promising classification performance than the\ncomparison methods on the benchmark datasets.\n", "versions": [{"version": "v1", "created": "Sun, 21 Jul 2019 16:09:16 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Islam", "Mazharul", ""], ["Liu", "Shuangrong", ""], ["Wang", "Lin", ""], ["Zhang", "Xiaojing", ""]]}, {"id": "1907.09000", "submitter": "Boris Knyazev", "authors": "Boris Knyazev, Xiao Lin, Mohamed R. Amer, Graham W. Taylor", "title": "Image Classification with Hierarchical Multigraph Networks", "comments": "13 pages, BMVC 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph Convolutional Networks (GCNs) are a class of general models that can\nlearn from graph structured data. Despite being general, GCNs are admittedly\ninferior to convolutional neural networks (CNNs) when applied to vision tasks,\nmainly due to the lack of domain knowledge that is hardcoded into CNNs, such as\nspatially oriented translation invariant filters. However, a great advantage of\nGCNs is the ability to work on irregular inputs, such as superpixels of images.\nThis could significantly reduce the computational cost of image reasoning\ntasks. Another key advantage inherent to GCNs is the natural ability to model\nmultirelational data. Building upon these two promising properties, in this\nwork, we show best practices for designing GCNs for image classification; in\nsome cases even outperforming CNNs on the MNIST, CIFAR-10 and PASCAL image\ndatasets.\n", "versions": [{"version": "v1", "created": "Sun, 21 Jul 2019 16:30:32 GMT"}], "update_date": "2019-07-23", "authors_parsed": [["Knyazev", "Boris", ""], ["Lin", "Xiao", ""], ["Amer", "Mohamed R.", ""], ["Taylor", "Graham W.", ""]]}, {"id": "1907.09008", "submitter": "Fanhua Shang", "authors": "Dong Wang, Yicheng Liu, Wenwo Tang, Fanhua Shang, Hongying Liu, Qigong\n  Sun, Licheng Jiao", "title": "signADAM: Learning Confidences for Deep Neural Networks", "comments": "11 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a new first-order gradient-based algorithm to train\ndeep neural networks. We first introduce the sign operation of stochastic\ngradients (as in sign-based methods, e.g., SIGN-SGD) into ADAM, which is called\nas signADAM. Moreover, in order to make the rate of fitting each feature\ncloser, we define a confidence function to distinguish different components of\ngradients and apply it to our algorithm. It can generate more sparse gradients\nthan existing algorithms do. We call this new algorithm signADAM++. In\nparticular, both our algorithms are easy to implement and can speed up training\nof various deep neural networks. The motivation of signADAM++ is preferably\nlearning features from the most different samples by updating large and useful\ngradients regardless of useless information in stochastic gradients. We also\nestablish theoretical convergence guarantees for our algorithms. Empirical\nresults on various datasets and models show that our algorithms yield much\nbetter performance than many state-of-the-art algorithms including SIGN-SGD,\nSIGNUM and ADAM. We also analyze the performance from multiple perspectives\nincluding the loss landscape and develop an adaptive method to further improve\ngeneralization. The source code is available at\nhttps://github.com/DongWanginxdu/signADAM-Learn-by-Confidence.\n", "versions": [{"version": "v1", "created": "Sun, 21 Jul 2019 17:08:50 GMT"}], "update_date": "2019-07-23", "authors_parsed": [["Wang", "Dong", ""], ["Liu", "Yicheng", ""], ["Tang", "Wenwo", ""], ["Shang", "Fanhua", ""], ["Liu", "Hongying", ""], ["Sun", "Qigong", ""], ["Jiao", "Licheng", ""]]}, {"id": "1907.09013", "submitter": "Tom LaGatta", "authors": "Brian d'Alessandro, Cathy O'Neil, Tom LaGatta", "title": "Conscientious Classification: A Data Scientist's Guide to\n  Discrimination-Aware Classification", "comments": "30 pages, 3 figures", "journal-ref": "Big Data, 5(2), 120-134 (2017)", "doi": "10.1089/big.2016.0048", "report-no": null, "categories": "stat.ML cs.LG stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent research has helped to cultivate growing awareness that machine\nlearning systems fueled by big data can create or exacerbate troubling\ndisparities in society. Much of this research comes from outside of the\npracticing data science community, leaving its members with little concrete\nguidance to proactively address these concerns. This article introduces issues\nof discrimination to the data science community on its own terms. In it, we\ntour the familiar data mining process while providing a taxonomy of common\npractices that have the potential to produce unintended discrimination. We also\nsurvey how discrimination is commonly measured, and suggest how familiar\ndevelopment processes can be augmented to mitigate systems' discriminatory\npotential. We advocate that data scientists should be intentional about\nmodeling and reducing discriminatory outcomes. Without doing so, their efforts\nwill result in perpetuating any systemic discrimination that may exist, but\nunder a misleading veil of data-driven objectivity.\n", "versions": [{"version": "v1", "created": "Sun, 21 Jul 2019 17:57:45 GMT"}], "update_date": "2019-07-23", "authors_parsed": [["d'Alessandro", "Brian", ""], ["O'Neil", "Cathy", ""], ["LaGatta", "Tom", ""]]}, {"id": "1907.09019", "submitter": "Eric Sun", "authors": "Eric D. Sun and Ron Dekel", "title": "ImageNet-trained deep neural network exhibits illusion-like response to\n  the Scintillating Grid", "comments": "Supplementary material at end of document", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural network (DNN) models for computer vision are now capable of\nhuman-level object recognition. Consequently, similarities in the performance\nand vulnerabilities of DNN and human vision are of great interest. Here we\ncharacterize the response of the VGG-19 DNN to images of the Scintillating Grid\nvisual illusion, in which white dots are perceived to be partially black. We\nobserved a significant deviation from the expected monotonic relation between\nVGG-19 representational dissimilarity and dot whiteness in the Scintillating\nGrid. That is, a linear increase in dot whiteness leads to a non-linear\nincrease and then, remarkably, a decrease (non-monotonicity) in\nrepresentational dissimilarity. In control images, mostly monotonic relations\nbetween representational dissimilarity and dot whiteness were observed.\nFurthermore, the dot whiteness level corresponding to the maximal\nrepresentational dissimilarity (i.e. onset of non-monotonic dissimilarity)\nmatched closely with that corresponding to the onset of illusion perception in\nhuman observers. As such, the non-monotonic response in the DNN is a potential\nmodel correlate for human illusion perception.\n", "versions": [{"version": "v1", "created": "Sun, 21 Jul 2019 19:14:47 GMT"}, {"version": "v2", "created": "Mon, 5 Aug 2019 02:13:38 GMT"}], "update_date": "2019-08-06", "authors_parsed": [["Sun", "Eric D.", ""], ["Dekel", "Ron", ""]]}, {"id": "1907.09038", "submitter": "Stein{\\th}\\'or Steingr\\'imsson", "authors": "Stein{\\th}\\'or Steingr\\'imsson and \\\"Orvar K\\'arason and Hrafn\n  Loftsson", "title": "Augmenting a BiLSTM tagger with a Morphological Lexicon and a Lexical\n  Category Identification Step", "comments": "Accepted by RANLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Previous work on using BiLSTM models for PoS tagging has primarily focused on\nsmall tagsets. We evaluate BiLSTM models for tagging Icelandic, a\nmorphologically rich language, using a relatively large tagset. Our baseline\nBiLSTM model achieves higher accuracy than any previously published tagger not\ntaking advantage of a morphological lexicon. When we extend the model by\nincorporating such data, we outperform previous state-of-the-art results by a\nsignificant margin. We also report on work in progress that attempts to address\nthe problem of data sparsity inherent in morphologically detailed, fine-grained\ntagsets. We experiment with training a separate model on only the lexical\ncategory and using the coarse-grained output tag as an input for the main\nmodel. This method further increases the accuracy and reduces the tagging\nerrors by 21.3% compared to previous state-of-the-art results. Finally, we\ntrain and test our tagger on a new gold standard for Icelandic.\n", "versions": [{"version": "v1", "created": "Sun, 21 Jul 2019 21:27:44 GMT"}], "update_date": "2019-07-23", "authors_parsed": [["Steingr\u00edmsson", "Stein\u00fe\u00f3r", ""], ["K\u00e1rason", "\u00d6rvar", ""], ["Loftsson", "Hrafn", ""]]}, {"id": "1907.09050", "submitter": "Richard Jiang", "authors": "Richard Jiang and Danny Crookes", "title": "Shallow Unorganized Neural Networks using Smart Neuron Model for Visual\n  Perception", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.NE eess.IV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The recent success of Deep Neural Networks (DNNs) has revealed the\nsignificant capability of neural computing in many challenging applications.\nAlthough DNNs are derived from emulating biological neurons, there still exist\ndoubts over whether or not DNNs are the final and best model to emulate the\nmechanism of human intelligence. In particular, there are two discrepancies\nbetween computational DNN models and the observed facts of biological neurons.\nFirst, human neurons are interconnected randomly, while DNNs need\ncarefully-designed architectures to work properly. Second, human neurons\nusually have a long spiking latency (~100ms) which implies that not many layers\ncan be involved in making a decision, while DNNs could have hundreds of layers\nto guarantee high accuracy. In this paper, we propose a new computational\nmodel, namely shallow unorganized neural networks (SUNNs), in contrast to\nANNs/DNNs. The proposed SUNNs differ from standard ANNs or DNNs in three\nfundamental aspects: 1) SUNNs are based on an adaptive neuron cell model, Smart\nNeurons, that allows each artificial neuron cell to adaptively respond to its\ninputs rather than carrying out a fixed weighted-sum operation like the classic\nneuron model in ANNs/DNNs; 2) SUNNs can cope with computational tasks with very\nshallow architectures; 3) SUNNs have a natural topology with random\ninterconnections, as the human brain does, and as proposed by Turing's B-type\nunorganized machines. We implemented the proposed SUNN architecture and tested\nit on a number of unsupervised early stage visual perception tasks.\nSurprisingly, such simple shallow architectures achieved very good results in\nour experiments. The success of our new computational model makes it the first\nworkable example of Turing's B-Type unorganized machine that can achieve\ncomparable or better performance against the state-of-the-art algorithms.\n", "versions": [{"version": "v1", "created": "Sun, 21 Jul 2019 23:09:35 GMT"}, {"version": "v2", "created": "Wed, 30 Oct 2019 23:50:49 GMT"}], "update_date": "2019-11-01", "authors_parsed": [["Jiang", "Richard", ""], ["Crookes", "Danny", ""]]}, {"id": "1907.09053", "submitter": "Evan Rosenman", "authors": "Evan Rosenman", "title": "Some New Results for Poisson Binomial Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a problem of ecological inference, in which individual-level\ncovariates are known, but labeled data is available only at the aggregate\nlevel. The intended application is modeling voter preferences in elections. In\nRosenman and Viswanathan (2018), we proposed modeling individual voter\nprobabilities via a logistic regression, and posing the problem as a maximum\nlikelihood estimation for the parameter vector beta. The likelihood is a\nPoisson binomial, the distribution of the sum of independent but not\nidentically distributed Bernoulli variables, though we approximate it with a\nheteroscedastic Gaussian for computational efficiency. Here, we extend the\nprior work by proving results about the existence of the MLE and the curvature\nof this likelihood, which is not log-concave in general. We further demonstrate\nthe utility of our method on a real data example. Using data on voters in\nMorris County, NJ, we demonstrate that our approach outperforms other\necological inference methods in predicting a related, but known outcome:\nwhether an individual votes.\n", "versions": [{"version": "v1", "created": "Sun, 21 Jul 2019 23:42:07 GMT"}], "update_date": "2019-07-23", "authors_parsed": [["Rosenman", "Evan", ""]]}, {"id": "1907.09059", "submitter": "Lei Lei", "authors": "Lei Lei, Yue Tan, Kan Zheng, Shiwen Liu, Kuan Zhang, Xuemin (Sherman)\n  Shen", "title": "Deep Reinforcement Learning for Autonomous Internet of Things: Model,\n  Applications and Challenges", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Internet of Things (IoT) extends the Internet connectivity into billions\nof IoT devices around the world, where the IoT devices collect and share\ninformation to reflect status of the physical world. The Autonomous Control\nSystem (ACS), on the other hand, performs control functions on the physical\nsystems without external intervention over an extended period of time. The\nintegration of IoT and ACS results in a new concept - autonomous IoT (AIoT).\nThe sensors collect information on the system status, based on which the\nintelligent agents in the IoT devices as well as the Edge/Fog/Cloud servers\nmake control decisions for the actuators to react. In order to achieve\nautonomy, a promising method is for the intelligent agents to leverage the\ntechniques in the field of artificial intelligence, especially reinforcement\nlearning (RL) and deep reinforcement learning (DRL) for decision making. In\nthis paper, we first provide a tutorial of DRL, and then propose a general\nmodel for the applications of RL/DRL in AIoT. Next, a comprehensive survey of\nthe state-of-art research on DRL for AIoT is presented, where the existing\nworks are classified and summarized under the umbrella of the proposed general\nDRL model. Finally, the challenges and open issues for future research are\nidentified.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jul 2019 00:06:49 GMT"}, {"version": "v2", "created": "Wed, 8 Jan 2020 15:10:04 GMT"}, {"version": "v3", "created": "Mon, 13 Apr 2020 16:08:11 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Lei", "Lei", "", "Sherman"], ["Tan", "Yue", "", "Sherman"], ["Zheng", "Kan", "", "Sherman"], ["Liu", "Shiwen", "", "Sherman"], ["Zhang", "Kuan", "", "Sherman"], ["Xuemin", "", "", "Sherman"], ["Shen", "", ""]]}, {"id": "1907.09061", "submitter": "Dian Ang Yap", "authors": "Vinay Uday Prabhu, Dian Ang Yap, Joyce Xu, John Whaley", "title": "Understanding Adversarial Robustness Through Loss Landscape Geometries", "comments": "Presented at the ICML 2019 Workshop on Uncertainty and Robustness in\n  Deep Learning, and CVPR 2019 Workshop on The Bright and Dark Sides of\n  Computer Vision: Challenges and Opportunities for Privacy and Security\n  (CV-COPS)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The pursuit of explaining and improving generalization in deep learning has\nelicited efforts both in regularization techniques as well as visualization\ntechniques of the loss surface geometry. The latter is related to the intuition\nprevalent in the community that flatter local optima leads to lower\ngeneralization error. In this paper, we harness the state-of-the-art \"filter\nnormalization\" technique of loss-surface visualization to qualitatively\nunderstand the consequences of using adversarial training data augmentation as\nthe explicit regularization technique of choice. Much to our surprise, we\ndiscover that this oft deployed adversarial augmentation technique does not\nactually result in \"flatter\" loss-landscapes, which requires rethinking\nadversarial training generalization, and the relationship between\ngeneralization and loss landscapes geometries.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jul 2019 00:24:29 GMT"}], "update_date": "2019-07-23", "authors_parsed": [["Prabhu", "Vinay Uday", ""], ["Yap", "Dian Ang", ""], ["Xu", "Joyce", ""], ["Whaley", "John", ""]]}, {"id": "1907.09063", "submitter": "Andrew Song", "authors": "Andrew H. Song, Francisco J. Flores, Demba Ba", "title": "Fast Convolutional Dictionary Learning off the Grid", "comments": null, "journal-ref": "IEEE Transactions on Signal Processing 2020", "doi": "10.1109/TSP.2020.2986897", "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a continuous-time signal that can be modeled as the superposition of\nlocalized, time-shifted events from multiple sources, the goal of Convolutional\nDictionary Learning (CDL) is to identify the location of the events--by\nConvolutional Sparse Coding (CSC)--and learn the template for each source--by\nConvolutional Dictionary Update (CDU). In practice, because we observe samples\nof the continuous-time signal on a uniformly-sampled grid in discrete time,\nclassical CSC methods can only produce estimates of the times when the events\noccur on this grid, which degrades the performance of the CDU. We introduce a\nCDL framework that significantly reduces the errors arising from performing the\nestimation in discrete time. Specifically, we construct an expanded dictionary\nthat comprises, not only discrete-time shifts of the templates, but also\ninterpolated variants, obtained by bandlimited interpolation, that account for\ncontinuous-time shifts. For CSC, we develop a novel computationally efficient\nCSC algorithm, termed Convolutional Orthogonal Matching Pursuit with\ninterpolated dictionary (COMP-INTERP). We benchmarked COMP-INTERP to\nContiunuous Basis Pursuit (CBP), the state-of-the-art CSC algorithm for\nestimating off-the-grid events, and demonstrate, on simulated data, that 1)\nCOMP-INTERP achieves a similar level of accuracy, and 2) is two orders of\nmagnitude faster. For CDU, we derive a novel procedure to update the templates\ngiven sparse codes that can occur both on and off the discrete-time grid. We\nalso show that 3) dictionary update with the overcomplete dictionary yields\nmore accurate templates. Finally, we apply the algorithms to the spike sorting\nproblem on electrophysiology recording and show their competitive performance.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jul 2019 00:35:20 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Song", "Andrew H.", ""], ["Flores", "Francisco J.", ""], ["Ba", "Demba", ""]]}, {"id": "1907.09064", "submitter": "Abolfazl Hashemi", "authors": "Abolfazl Hashemi, Haris Vikalo, Gustavo de Veciana", "title": "Progressive Stochastic Greedy Sparse Reconstruction and Support\n  Selection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sparse reconstruction and sparse support selection, i.e., the tasks of\ninferring an arbitrary $m$-dimensional sparse vector $\\mathbf{x}$ having $k$\nnonzero entries from $n$ measurements of linear combinations of its components,\nare often encountered in machine learning, computer vision, and signal\nprocessing. Existing greedy-based algorithms achieve optimal $n =\n\\mathcal{O}(k\\log\\frac{m}{k})$ sampling complexity with computational\ncomplexity that is linear in the size of the data $m$ and cardinality\nconstraint $k$. However, the ${\\mathcal{O}}(mk)$ computational complexity is\nstill prohibitive for large-scale datasets. In this paper, we present the first\nsparse support selection algorithm for arbitrary sparse vectors that achieves\nexact identification of the optimal subset from $n =\n\\mathcal{O}(k\\log\\frac{m}{k})$ measurements with $\\tilde{\\mathcal{O}}(m)$\ncomputational complexity. The proposed scheme utilizes the idea of randomly\nrestricting search space of the greedy method in a progressive manner to reduce\nthe computational cost while maintaining the same order of sampling complexity\nas the existing greedy schemes. Simulation results including an application of\nthe algorithm to the task of column subset selection demonstrate efficacy of\nthe proposed algorithm.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jul 2019 00:41:49 GMT"}, {"version": "v2", "created": "Sun, 9 Feb 2020 21:56:43 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Hashemi", "Abolfazl", ""], ["Vikalo", "Haris", ""], ["de Veciana", "Gustavo", ""]]}, {"id": "1907.09065", "submitter": "Cheng Li", "authors": "Cheng Li, Santu Rana, Sunil Gupta, Vu Nguyen, Svetha Venkatesh,\n  Alessandra Sutti, David Rubin, Teo Slezak, Murray Height, Mazher Mohammed,\n  Ian Gibson", "title": "Accelerating Experimental Design by Incorporating Experimenter Hunches", "comments": "IEEE International Conference on Data Mining (ICDM) 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Experimental design is a process of obtaining a product with target property\nvia experimentation. Bayesian optimization offers a sample-efficient tool for\nexperimental design when experiments are expensive. Often, expert experimenters\nhave 'hunches' about the behavior of the experimental system, offering\npotentials to further improve the efficiency. In this paper, we consider\nper-variable monotonic trend in the underlying property that results in a\nunimodal trend in those variables for a target value optimization. For example,\nsweetness of a candy is monotonic to the sugar content. However, to obtain a\ntarget sweetness, the utility of the sugar content becomes a unimodal function,\nwhich peaks at the value giving the target sweetness and falls off both ways.\nIn this paper, we propose a novel method to solve such problems that achieves\ntwo main objectives: a) the monotonicity information is used to the fullest\nextent possible, whilst ensuring that b) the convergence guarantee remains\nintact. This is achieved by a two-stage Gaussian process modeling, where the\nfirst stage uses the monotonicity trend to model the underlying property, and\nthe second stage uses `virtual' samples, sampled from the first, to model the\ntarget value optimization function. The process is made theoretically\nconsistent by adding appropriate adjustment factor in the posterior\ncomputation, necessitated because of using the `virtual' samples. The proposed\nmethod is evaluated through both simulations and real world experimental design\nproblems of a) new short polymer fiber with the target length, and b) designing\nof a new three dimensional porous scaffolding with a target porosity. In all\nscenarios our method demonstrates faster convergence than the basic Bayesian\noptimization approach not using such `hunches'.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jul 2019 00:48:24 GMT"}], "update_date": "2019-07-23", "authors_parsed": [["Li", "Cheng", ""], ["Rana", "Santu", ""], ["Gupta", "Sunil", ""], ["Nguyen", "Vu", ""], ["Venkatesh", "Svetha", ""], ["Sutti", "Alessandra", ""], ["Rubin", "David", ""], ["Slezak", "Teo", ""], ["Height", "Murray", ""], ["Mohammed", "Mazher", ""], ["Gibson", "Ian", ""]]}, {"id": "1907.09077", "submitter": "Ruizhe Cai", "authors": "Ruizhe Cai, Ao Ren, Olivia Chen, Ning Liu, Caiwen Ding, Xuehai Qian,\n  Jie Han, Wenhui Luo, Nobuyuki Yoshikawa, Yanzhi Wang", "title": "A Stochastic-Computing based Deep Learning Framework using Adiabatic\n  Quantum-Flux-Parametron SuperconductingTechnology", "comments": null, "journal-ref": null, "doi": "10.1145/3307650.3322270", "report-no": null, "categories": "cs.NE cs.ET cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Adiabatic Quantum-Flux-Parametron (AQFP) superconducting technology has\nbeen recently developed, which achieves the highest energy efficiency among\nsuperconducting logic families, potentially huge gain compared with\nstate-of-the-art CMOS. In 2016, the successful fabrication and testing of\nAQFP-based circuits with the scale of 83,000 JJs have demonstrated the\nscalability and potential of implementing large-scale systems using AQFP. As a\nresult, it will be promising for AQFP in high-performance computing and deep\nspace applications, with Deep Neural Network (DNN) inference acceleration as an\nimportant example. Besides ultra-high energy efficiency, AQFP exhibits two\nunique characteristics: the deep pipelining nature since each AQFP logic gate\nis connected with an AC clock signal, which increases the difficulty to avoid\nRAW hazards; the second is the unique opportunity of true random number\ngeneration (RNG) using a single AQFP buffer, far more efficient than RNG in\nCMOS. We point out that these two characteristics make AQFP especially\ncompatible with the \\emph{stochastic computing} (SC) technique, which uses a\ntime-independent bit sequence for value representation, and is compatible with\nthe deep pipelining nature. Further, the application of SC has been\ninvestigated in DNNs in prior work, and the suitability has been illustrated as\nSC is more compatible with approximate computations. This work is the first to\ndevelop an SC-based DNN acceleration framework using AQFP technology.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jul 2019 01:44:49 GMT"}], "update_date": "2019-07-23", "authors_parsed": [["Cai", "Ruizhe", ""], ["Ren", "Ao", ""], ["Chen", "Olivia", ""], ["Liu", "Ning", ""], ["Ding", "Caiwen", ""], ["Qian", "Xuehai", ""], ["Han", "Jie", ""], ["Luo", "Wenhui", ""], ["Yoshikawa", "Nobuyuki", ""], ["Wang", "Yanzhi", ""]]}, {"id": "1907.09083", "submitter": "Zhen Li", "authors": "Zhen Li and Eric Laber", "title": "Convergence Rates of Posterior Distributions in Markov Decision Process", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG math.OC stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we show the convergence rates of posterior distributions of\nthe model dynamics in a MDP for both episodic and continuous tasks. The\ntheoretical results hold for general state and action space and the parameter\nspace of the dynamics can be infinite dimensional. Moreover, we show the\nconvergence rates of posterior distributions of the mean accumulative reward\nunder a fixed or the optimal policy and of the regret bound. A variant of\nThompson sampling algorithm is proposed which provides both posterior\nconvergence rates for the dynamics and the regret-type bound. Then the previous\nresults are extended to Markov games. Finally, we show numerical results with\nthree simulation scenarios and conclude with discussions.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jul 2019 02:08:47 GMT"}], "update_date": "2019-07-23", "authors_parsed": [["Li", "Zhen", ""], ["Laber", "Eric", ""]]}, {"id": "1907.09109", "submitter": "Miao Zhang", "authors": "Miao Zhang, Huiqi Li, Shirui Pan, Taoping Liu, Steven Su", "title": "Efficient Novelty-Driven Neural Architecture Search", "comments": "10 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One-Shot Neural architecture search (NAS) attracts broad attention recently\ndue to its capacity to reduce the computational hours through weight sharing.\nHowever, extensive experiments on several recent works show that there is no\npositive correlation between the validation accuracy with inherited weights\nfrom the supernet and the test accuracy after re-training for One-Shot NAS.\nDifferent from devising a controller to find the best performing architecture\nwith inherited weights, this paper focuses on how to sample architectures to\ntrain the supernet to make it more predictive. A single-path supernet is\nadopted, where only a small part of weights are optimized in each step, to\nreduce the memory demand greatly. Furthermore, we abandon devising complicated\nreward based architecture sampling controller, and sample architectures to\ntrain supernet based on novelty search. An efficient novelty search method for\nNAS is devised in this paper, and extensive experiments demonstrate the\neffectiveness and efficiency of our novelty search based architecture sampling\nmethod. The best architecture obtained by our algorithm with the same search\nspace achieves the state-of-the-art test error rate of 2.51\\% on CIFAR-10 with\nonly 7.5 hours search time in a single GPU, and a validation perplexity of\n60.02 and a test perplexity of 57.36 on PTB. We also transfer these search cell\nstructures to larger datasets ImageNet and WikiText-2, respectively.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jul 2019 03:17:13 GMT"}], "update_date": "2019-07-23", "authors_parsed": [["Zhang", "Miao", ""], ["Li", "Huiqi", ""], ["Pan", "Shirui", ""], ["Liu", "Taoping", ""], ["Su", "Steven", ""]]}, {"id": "1907.09117", "submitter": "Yourui Huangfu", "authors": "Yourui Huangfu, Jian Wang, Chen Xu, Rong Li, Yiqun Ge, Xianbin Wang,\n  Huazi Zhang, Jun Wang", "title": "Realistic Channel Models Pre-training", "comments": "6 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a neural-network-based realistic channel model with\nboth the similar accuracy as deterministic channel models and uniformity as\nstochastic channel models. To facilitate this realistic channel modeling, a\nmulti-domain channel embedding method combined with self-attention mechanism is\nproposed to extract channel features from multiple domains simultaneously. This\n'one model to fit them all' solution employs available wireless channel data as\nthe only data set for self-supervised pre-training. With the permission of\nusers, network operators or other organizations can make use of some available\nuser specific data to fine-tune this pre-trained realistic channel model for\napplications on channel-related downstream tasks. Moreover, even without\nfine-tuning, we show that the pre-trained realistic channel model itself is a\ngreat tool with its understanding of wireless channel.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jul 2019 03:26:06 GMT"}], "update_date": "2019-07-23", "authors_parsed": [["Huangfu", "Yourui", ""], ["Wang", "Jian", ""], ["Xu", "Chen", ""], ["Li", "Rong", ""], ["Ge", "Yiqun", ""], ["Wang", "Xianbin", ""], ["Zhang", "Huazi", ""], ["Wang", "Jun", ""]]}, {"id": "1907.09133", "submitter": "Fahira Afzal Maken", "authors": "Fahira Afzal Maken, Fabio Ramos, Lionel Ott", "title": "Speeding Up Iterative Closest Point Using Stochastic Gradient Descent", "comments": "7 Pages, 4 Figures, Submitted to ICRA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sensors producing 3D point clouds such as 3D laser scanners and RGB-D cameras\nare widely used in robotics, be it for autonomous driving or manipulation.\nAligning point clouds produced by these sensors is a vital component in such\napplications to perform tasks such as model registration, pose estimation, and\nSLAM. Iterative closest point (ICP) is the most widely used method for this\ntask, due to its simplicity and efficiency. In this paper we propose a novel\nmethod which solves the optimisation problem posed by ICP using stochastic\ngradient descent (SGD). Using SGD allows us to improve the convergence speed of\nICP without sacrificing solution quality. Experiments using Kinect as well as\nVelodyne data show that, our proposed method is faster than existing methods,\nwhile obtaining solutions comparable to standard ICP. An additional benefit is\nrobustness to parameters when processing data from different sensors.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jul 2019 04:50:22 GMT"}], "update_date": "2019-07-23", "authors_parsed": [["Maken", "Fahira Afzal", ""], ["Ramos", "Fabio", ""], ["Ott", "Lionel", ""]]}, {"id": "1907.09137", "submitter": "Dravyansh Sharma", "authors": "Maria-Florina Balcan, Travis Dick, Dravyansh Sharma", "title": "Learning piecewise Lipschitz functions in changing environments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optimization in the presence of sharp (non-Lipschitz), unpredictable (w.r.t.\ntime and amount) changes is a challenging and largely unexplored problem of\ngreat significance. We consider the class of piecewise Lipschitz functions,\nwhich is the most general online setting considered in the literature for the\nproblem, and arises naturally in various combinatorial algorithm selection\nproblems where utility functions can have sharp discontinuities. The usual\nperformance metric of $\\mathit{static}$ regret minimizes the gap between the\npayoff accumulated and that of the best fixed point for the entire duration,\nand thus fails to capture changing environments. Shifting regret is a useful\nalternative, which allows for up to $s$ environment shifts. In this work we\nprovide an $O(\\sqrt{sdT\\log T}+sT^{1-\\beta})$ regret bound for\n$\\beta$-dispersed functions, where $\\beta$ roughly quantifies the rate at which\ndiscontinuities appear in the utility functions in expectation (typically\n$\\beta\\ge1/2$ in problems of practical interest). We also present a lower bound\ntight up to sub-logarithmic factors. We further obtain improved bounds when\nselecting from a small pool of experts. We empirically demonstrate a key\napplication of our algorithms to online clustering problems on popular\nbenchmarks.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jul 2019 04:57:59 GMT"}, {"version": "v2", "created": "Tue, 17 Dec 2019 21:32:58 GMT"}, {"version": "v3", "created": "Wed, 18 Mar 2020 19:44:12 GMT"}, {"version": "v4", "created": "Fri, 7 Aug 2020 01:03:37 GMT"}], "update_date": "2020-08-10", "authors_parsed": [["Balcan", "Maria-Florina", ""], ["Dick", "Travis", ""], ["Sharma", "Dravyansh", ""]]}, {"id": "1907.09138", "submitter": "Xiang Gao", "authors": "Wei Hu, Xiang Gao, Gene Cheung, Zongming Guo", "title": "Feature Graph Learning for 3D Point Cloud Denoising", "comments": null, "journal-ref": null, "doi": "10.1109/TSP.2020.2978617", "report-no": null, "categories": "cs.CV cs.LG eess.IV eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Identifying an appropriate underlying graph kernel that reflects pairwise\nsimilarities is critical in many recent graph spectral signal restoration\nschemes, including image denoising, dequantization, and contrast enhancement.\nExisting graph learning algorithms compute the most likely entries of a\nproperly defined graph Laplacian matrix $\\mathbf{L}$, but require a large\nnumber of signal observations $\\mathbf{z}$'s for a stable estimate. In this\nwork, we assume instead the availability of a relevant feature vector\n$\\mathbf{f}_i$ per node $i$, from which we compute an optimal feature graph via\noptimization of a feature metric. Specifically, we alternately optimize the\ndiagonal and off-diagonal entries of a Mahalanobis distance matrix $\\mathbf{M}$\nby minimizing the graph Laplacian regularizer (GLR) $\\mathbf{z}^{\\top}\n\\mathbf{L} \\mathbf{z}$, where edge weight is $w_{i,j} = \\exp\\{-(\\mathbf{f}_i -\n\\mathbf{f}_j)^{\\top} \\mathbf{M} (\\mathbf{f}_i - \\mathbf{f}_j) \\}$, given a\nsingle observation $\\mathbf{z}$. We optimize diagonal entries via proximal\ngradient (PG), where we constrain $\\mathbf{M}$ to be positive definite (PD) via\nlinear inequalities derived from the Gershgorin circle theorem. To optimize\noff-diagonal entries, we design a block descent algorithm that iteratively\noptimizes one row and column of $\\mathbf{M}$. To keep $\\mathbf{M}$ PD, we\nconstrain the Schur complement of sub-matrix $\\mathbf{M}_{2,2}$ of $\\mathbf{M}$\nto be PD when optimizing via PG. Our algorithm mitigates full\neigen-decomposition of $\\mathbf{M}$, thus ensuring fast computation speed even\nwhen feature vector $\\mathbf{f}_i$ has high dimension. To validate its\nusefulness, we apply our feature graph learning algorithm to the problem of 3D\npoint cloud denoising, resulting in state-of-the-art performance compared to\ncompeting schemes in extensive experiments.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jul 2019 05:02:12 GMT"}, {"version": "v2", "created": "Wed, 15 Jan 2020 02:11:27 GMT"}], "update_date": "2020-06-24", "authors_parsed": [["Hu", "Wei", ""], ["Gao", "Xiang", ""], ["Cheung", "Gene", ""], ["Guo", "Zongming", ""]]}, {"id": "1907.09150", "submitter": "Jianshu Chen", "authors": "Adithya M. Devraj and Jianshu Chen", "title": "Stochastic Variance Reduced Primal Dual Algorithms for Empirical\n  Composition Optimization", "comments": "42 pages; Published at Thirty-third Conference on Neural Information\n  Processing Systems (NeurIPS 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a generic empirical composition optimization problem, where there\nare empirical averages present both outside and inside nonlinear loss\nfunctions. Such a problem is of interest in various machine learning\napplications, and cannot be directly solved by standard methods such as\nstochastic gradient descent. We take a novel approach to solving this problem\nby reformulating the original minimization objective into an equivalent min-max\nobjective, which brings out all the empirical averages that are originally\ninside the nonlinear loss functions. We exploit the rich structures of the\nreformulated problem and develop a stochastic primal-dual algorithm, SVRPDA-I,\nto solve the problem efficiently. We carry out extensive theoretical analysis\nof the proposed algorithm, obtaining the convergence rate, the computation\ncomplexity and the storage complexity. In particular, the algorithm is shown to\nconverge at a linear rate when the problem is strongly convex. Moreover, we\nalso develop an approximate version of the algorithm, named SVRPDA-II, which\nfurther reduces the memory requirement. Finally, we evaluate our proposed\nalgorithms on several real-world benchmarks, and experimental results show that\nthe proposed algorithms significantly outperform existing techniques.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jul 2019 06:29:41 GMT"}, {"version": "v2", "created": "Thu, 31 Oct 2019 20:47:08 GMT"}], "update_date": "2019-11-04", "authors_parsed": [["Devraj", "Adithya M.", ""], ["Chen", "Jianshu", ""]]}, {"id": "1907.09158", "submitter": "Andreas Metzger", "authors": "Andreas Metzger, Cl\\'ement Quinton, Zolt\\'an \\'Ad\\'am Mann, Luciano\n  Baresi, Klaus Pohl", "title": "Feature-Model-Guided Online Learning for Self-Adaptive Systems", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-030-65310-1_20", "report-no": null, "categories": "cs.SE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A self-adaptive system can modify its own structure and behavior at runtime\nbased on its perception of the environment, of itself and of its requirements.\nTo develop a self-adaptive system, software developers codify knowledge about\nthe system and its environment, as well as how adaptation actions impact on the\nsystem. However, the codified knowledge may be insufficient due to design time\nuncertainty, and thus a self-adaptive system may execute adaptation actions\nthat do not have the desired effect. Online learning is an emerging approach to\naddress design time uncertainty by employing machine learning at runtime.\nOnline learning accumulates knowledge at runtime by, for instance, exploring\nnot-yet executed adaptation actions. We address two specific problems with\nrespect to online learning for self-adaptive systems. First, the number of\npossible adaptation actions can be very large. Existing online learning\ntechniques randomly explore the possible adaptation actions, but this can lead\nto slow convergence of the learning process. Second, the possible adaptation\nactions can change as a result of system evolution. Existing online learning\ntechniques are unaware of these changes and thus do not explore new adaptation\nactions, but explore adaptation actions that are no longer valid. We propose\nusing feature models to give structure to the set of adaptation actions and\nthereby guide the exploration process during online learning. Experimental\nresults involving four real-world systems suggest that considering the\nhierarchical structure of feature models may speed up convergence by 7.2% on\naverage. Considering the differences between feature models before and after an\nevolution step may speed up convergence by 64.6% on average. [...]\n", "versions": [{"version": "v1", "created": "Mon, 22 Jul 2019 07:04:11 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Metzger", "Andreas", ""], ["Quinton", "Cl\u00e9ment", ""], ["Mann", "Zolt\u00e1n \u00c1d\u00e1m", ""], ["Baresi", "Luciano", ""], ["Pohl", "Klaus", ""]]}, {"id": "1907.09169", "submitter": "Syrielle Montariol", "authors": "Syrielle Montariol, Alexandre Allauzen", "title": "Learning dynamic word embeddings with drift regularisation", "comments": "Published at TALN 2019. in French", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Word usage, meaning and connotation change throughout time. Diachronic word\nembeddings are used to grasp these changes in an unsupervised way. In this\npaper, we use variants of the Dynamic Bernoulli Embeddings model to learn\ndynamic word embeddings, in order to identify notable properties of the model.\nThe comparison is made on the New York Times Annotated Corpus in English and a\nset of articles from the French newspaper Le Monde covering the same period.\nThis allows us to define a pipeline to analyse the evolution of words use\nacross two languages.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jul 2019 07:44:09 GMT"}], "update_date": "2019-07-23", "authors_parsed": [["Montariol", "Syrielle", ""], ["Allauzen", "Alexandre", ""]]}, {"id": "1907.09173", "submitter": "Jindong Wang", "authors": "Yiqiang Chen, Jindong Wang, Chaohui Yu, Wen Gao, Xin Qin", "title": "FedHealth: A Federated Transfer Learning Framework for Wearable\n  Healthcare", "comments": "IJCAI-19 Workshop on Federated Machine Learning for User Privacy and\n  Data Confidentiality (IJCAI (FML)) 2019; fix typos; journal version:\n  https://ieeexplore.ieee.org/document/9076082", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  With the rapid development of computing technology, wearable devices such as\nsmart phones and wristbands make it easy to get access to people's health\ninformation including activities, sleep, sports, etc. Smart healthcare achieves\ngreat success by training machine learning models on a large quantity of user\ndata. However, there are two critical challenges. Firstly, user data often\nexists in the form of isolated islands, making it difficult to perform\naggregation without compromising privacy security. Secondly, the models trained\non the cloud fail on personalization. In this paper, we propose FedHealth, the\nfirst federated transfer learning framework for wearable healthcare to tackle\nthese challenges. FedHealth performs data aggregation through federated\nlearning, and then builds personalized models by transfer learning. It is able\nto achieve accurate and personalized healthcare without compromising privacy\nand security. Experiments demonstrate that FedHealth produces higher accuracy\n(5.3% improvement) for wearable activity recognition when compared to\ntraditional methods. FedHealth is general and extensible and has the potential\nto be used in many healthcare applications.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jul 2019 07:56:33 GMT"}, {"version": "v2", "created": "Tue, 11 May 2021 10:22:03 GMT"}], "update_date": "2021-05-12", "authors_parsed": [["Chen", "Yiqiang", ""], ["Wang", "Jindong", ""], ["Yu", "Chaohui", ""], ["Gao", "Wen", ""], ["Qin", "Xin", ""]]}, {"id": "1907.09177", "submitter": "Fuming Fang", "authors": "David Ifeoluwa Adelani, Haotian Mai, Fuming Fang, Huy H. Nguyen,\n  Junichi Yamagishi, Isao Echizen", "title": "Generating Sentiment-Preserving Fake Online Reviews Using Neural\n  Language Models and Their Human- and Machine-based Detection", "comments": "The 34-th International Conference on Advanced Information Networking\n  and Applications (AINA-2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CR cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Advanced neural language models (NLMs) are widely used in sequence generation\ntasks because they are able to produce fluent and meaningful sentences. They\ncan also be used to generate fake reviews, which can then be used to attack\nonline review systems and influence the buying decisions of online shoppers. To\nperform such attacks, it is necessary for experts to train a tailored LM for a\nspecific topic. In this work, we show that a low-skilled threat model can be\nbuilt just by combining publicly available LMs and show that the produced fake\nreviews can fool both humans and machines. In particular, we use the GPT-2 NLM\nto generate a large number of high-quality reviews based on a review with the\ndesired sentiment and then using a BERT based text classifier (with accuracy of\n96%) to filter out reviews with undesired sentiments. Because none of the words\nin the review are modified, fluent samples like the training data can be\ngenerated from the learned distribution. A subjective evaluation with 80\nparticipants demonstrated that this simple method can produce reviews that are\nas fluent as those written by people. It also showed that the participants\ntended to distinguish fake reviews randomly. Three countermeasures, Grover,\nGLTR, and OpenAI GPT-2 detector, were found to be difficult to accurately\ndetect fake review.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jul 2019 08:22:08 GMT"}, {"version": "v2", "created": "Tue, 3 Dec 2019 07:46:44 GMT"}], "update_date": "2019-12-04", "authors_parsed": [["Adelani", "David Ifeoluwa", ""], ["Mai", "Haotian", ""], ["Fang", "Fuming", ""], ["Nguyen", "Huy H.", ""], ["Yamagishi", "Junichi", ""], ["Echizen", "Isao", ""]]}, {"id": "1907.09180", "submitter": "Hemin Ali Qadir", "authors": "Hemin Ali Qadir, Younghak Shin, Johannes Solhusvik, Jacob Bergsland,\n  Lars Aabakken, Ilangko Balasingham", "title": "Polyp Detection and Segmentation using Mask R-CNN: Does a Deeper Feature\n  Extractor CNN Always Perform Better?", "comments": "6", "journal-ref": "2019 13th International Symposium on Medical Information and\n  Communication Technology (ISMICT)", "doi": "10.1109/ISMICT.2019.8743694", "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic polyp detection and segmentation are highly desirable for colon\nscreening due to polyp miss rate by physicians during colonoscopy, which is\nabout 25%. However, this computerization is still an unsolved problem due to\nvarious polyp-like structures in the colon and high interclass polyp variations\nin terms of size, color, shape, and texture. In this paper, we adapt Mask R-CNN\nand evaluate its performance with different modern convolutional neural\nnetworks (CNN) as its feature extractor for polyp detection and segmentation.\nWe investigate the performance improvement of each feature extractor by adding\nextra polyp images to the training dataset to answer whether we need deeper and\nmore complex CNNs or better dataset for training in automatic polyp detection\nand segmentation. Finally, we propose an ensemble method for further\nperformance improvement. We evaluate the performance on the 2015 MICCAI polyp\ndetection dataset. The best results achieved are 72.59% recall, 80% precision,\n70.42% dice, and 61.24% Jaccard. The model achieved state-of-the-art\nsegmentation performance.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jul 2019 08:34:47 GMT"}], "update_date": "2019-07-23", "authors_parsed": [["Qadir", "Hemin Ali", ""], ["Shin", "Younghak", ""], ["Solhusvik", "Johannes", ""], ["Bergsland", "Jacob", ""], ["Aabakken", "Lars", ""], ["Balasingham", "Ilangko", ""]]}, {"id": "1907.09200", "submitter": "Ben Glocker", "authors": "Matthew C.H. Lee, Ozan Oktay, Andreas Schuh, Michiel Schaap, Ben\n  Glocker", "title": "Image-and-Spatial Transformer Networks for Structure-Guided Image\n  Registration", "comments": "Accepted at MICCAI 2019. Code available on\n  https://github.com/biomedia-mira/istn", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Image registration with deep neural networks has become an active field of\nresearch and exciting avenue for a long standing problem in medical imaging.\nThe goal is to learn a complex function that maps the appearance of input image\npairs to parameters of a spatial transformation in order to align corresponding\nanatomical structures. We argue and show that the current direct, non-iterative\napproaches are sub-optimal, in particular if we seek accurate alignment of\nStructures-of-Interest (SoI). Information about SoI is often available at\ntraining time, for example, in form of segmentations or landmarks. We introduce\na novel, generic framework, Image-and-Spatial Transformer Networks (ISTNs), to\nleverage SoI information allowing us to learn new image representations that\nare optimised for the downstream registration task. Thanks to these\nrepresentations we can employ a test-specific, iterative refinement over the\ntransformation parameters which yields highly accurate registration even with\nvery limited training data. Performance is demonstrated on pairwise 3D brain\nregistration and illustrative synthetic data.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jul 2019 09:39:53 GMT"}], "update_date": "2019-07-23", "authors_parsed": [["Lee", "Matthew C. H.", ""], ["Oktay", "Ozan", ""], ["Schuh", "Andreas", ""], ["Schaap", "Michiel", ""], ["Glocker", "Ben", ""]]}, {"id": "1907.09204", "submitter": "Gabriel Michau Dr.", "authors": "Gabriel Michau and Olga Fink", "title": "Domain Adaptation for One-Class Classification: Monitoring the Health of\n  Critical Systems Under Limited Information", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The failure of a complex and safety critical industrial asset can have\nextremely high consequences. Close monitoring for early detection of abnormal\nsystem conditions is therefore required. Data-driven solutions to this problem\nhave been limited for two reasons: First, safety critical assets are designed\nand maintained to be highly reliable and faults are rare. Fault detection can\nthus not be solved with supervised learning. Second, complex industrial systems\nusually have long lifetime during which they face very different operating\nconditions. In the early life of the system, the collected data is probably not\nrepresentative of future operating conditions, making it challenging to train a\nrobust model.\n  In this paper, we propose a methodology to monitor the systems in their early\nlife. To do so, we enhance the training dataset with other units from a fleet,\nfor which longer observations are available. Since each unit has its own\nspecificity, we propose to extract features made independent of their origin by\nthree unsupervised feature alignment techniques. First, using a variational\nencoder, we impose a shared probabilistic encoder/decoder for both units.\nSecond, we introduce a new loss designed to conserve inter-point spacial\nrelationships between the input and the learned features. Last, we propose to\ntrain in an adversarial manner a discriminator on the origin of the features.\nOnce aligned, the features are fed to a one-class classifier to monitor the\nhealth of the system. By exploring the different combinations of the proposed\nalignment strategies, and by testing them on a real case study, a fleet\ncomposed of 112 power plants operated in different geographical locations and\nunder very different operating regimes, we demonstrate that this alignment is\nnecessary and beneficial.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jul 2019 09:49:50 GMT"}, {"version": "v2", "created": "Mon, 30 Sep 2019 07:24:00 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Michau", "Gabriel", ""], ["Fink", "Olga", ""]]}, {"id": "1907.09207", "submitter": "Alberto Gasparin Mr", "authors": "Alberto Gasparin, Slobodan Lukovic, Cesare Alippi", "title": "Deep Learning for Time Series Forecasting: The Electric Load Case", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Management and efficient operations in critical infrastructure such as Smart\nGrids take huge advantage of accurate power load forecasting which, due to its\nnonlinear nature, remains a challenging task. Recently, deep learning has\nemerged in the machine learning field achieving impressive performance in a\nvast range of tasks, from image classification to machine translation.\nApplications of deep learning models to the electric load forecasting problem\nare gaining interest among researchers as well as the industry, but a\ncomprehensive and sound comparison among different architectures is not yet\navailable in the literature. This work aims at filling the gap by reviewing and\nexperimentally evaluating on two real-world datasets the most recent trends in\nelectric load forecasting, by contrasting deep learning architectures on short\nterm forecast (one day ahead prediction). Specifically, we focus on feedforward\nand recurrent neural networks, sequence to sequence models and temporal\nconvolutional neural networks along with architectural variants, which are\nknown in the signal processing community but are novel to the load forecasting\none.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jul 2019 10:03:17 GMT"}], "update_date": "2019-07-23", "authors_parsed": [["Gasparin", "Alberto", ""], ["Lukovic", "Slobodan", ""], ["Alippi", "Cesare", ""]]}, {"id": "1907.09236", "submitter": "Isaac Ronald Ward", "authors": "Isaac Ronald Ward, Hamid Laga, Mohammed Bennamoun", "title": "RGB-D image-based Object Detection: from Traditional Methods to Deep\n  Learning Techniques", "comments": "Chapter in the book 'RGB-D Image Analysis and Processing' (Paul\n  Rosin)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Object detection from RGB images is a long-standing problem in image\nprocessing and computer vision. It has applications in various domains\nincluding robotics, surveillance, human-computer interaction, and medical\ndiagnosis. With the availability of low cost 3D scanners, a large number of\nRGB-D object detection approaches have been proposed in the past years. This\nchapter provides a comprehensive survey of the recent developments in this\nfield. We structure the chapter into two parts; the focus of the first part is\non techniques that are based on hand-crafted features combined with machine\nlearning algorithms. The focus of the second part is on the more recent work,\nwhich is based on deep learning. Deep learning techniques, coupled with the\navailability of large training datasets, have now revolutionized the field of\ncomputer vision, including RGB-D object detection, achieving an unprecedented\nlevel of performance. We survey the key contributions, summarize the most\ncommonly used pipelines, discuss their benefits and limitations, and highlight\nsome important directions for future research.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jul 2019 11:18:01 GMT"}], "update_date": "2019-07-23", "authors_parsed": [["Ward", "Isaac Ronald", ""], ["Laga", "Hamid", ""], ["Bennamoun", "Mohammed", ""]]}, {"id": "1907.09239", "submitter": "Tom Hanika", "authors": "Maximilian Stubbemann and Tom Hanika and Gerd Stumme", "title": "Orometric Methods in Bounded Metric Data", "comments": "8 Pages, 1 figure", "journal-ref": null, "doi": "10.1007/978-3-030-44584-3_39", "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A large amount of data accommodated in knowledge graphs (KG) is actually\nmetric. For example, the Wikidata KG contains a plenitude of metric facts about\ngeographic entities like cities, chemical compounds or celestial objects. In\nthis paper, we propose a novel approach that transfers orometric (topographic)\nmeasures to bounded metric spaces. While these methods were originally designed\nto identify relevant mountain peaks on the surface of the earth, we demonstrate\na notion to use them for metric data sets in general. Notably, metric sets of\nitems inclosed in knowledge graphs. Based on this we present a method for\nidentifying outstanding items using the transferred valuations functions\n'isolation' and 'prominence'. Building up on this we imagine an item\nrecommendation process. To demonstrate the relevance of the novel valuations\nfor such processes we use item sets from the Wikidata knowledge graph. We then\nevaluate the usefulness of 'isolation' and 'prominence' empirically in a\nsupervised machine learning setting. In particular, we find structurally\nrelevant items in the geographic population distributions of Germany and\nFrance.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jul 2019 11:30:06 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Stubbemann", "Maximilian", ""], ["Hanika", "Tom", ""], ["Stumme", "Gerd", ""]]}, {"id": "1907.09282", "submitter": "Martin Monperrus", "authors": "Zhongxing Yu, Matias Martinez, Tegawend\\'e F. Bissyand\\'e, Martin\n  Monperrus", "title": "Learning the Relation between Code Features and Code Transforms with\n  Structured Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.LG cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present in this paper the first approach for structurally predicting code\ntransforms at the level of AST nodes using conditional random fields. Our\napproach first learns offline a probabilistic model that captures how certain\ncode transforms are applied to certain AST nodes, and then uses the learned\nmodel to predict transforms for new, unseen code snippets. We implement our\napproach in the context of repair transform prediction for Java programs. Our\nimplementation contains a set of carefully designed code features, deals with\nthe training data imbalance issue, and comprises transform constraints that are\nspecific to code. We conduct a large-scale experimental evaluation based on a\ndataset of 4,590,679 bug fixing commits from real-world Java projects. The\nexperimental results show that our approach predicts the code transforms with a\nsuccess rate varying from 37.1% to 61.1% depending on the transforms.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jul 2019 12:42:32 GMT"}], "update_date": "2019-07-23", "authors_parsed": [["Yu", "Zhongxing", ""], ["Martinez", "Matias", ""], ["Bissyand\u00e9", "Tegawend\u00e9 F.", ""], ["Monperrus", "Martin", ""]]}, {"id": "1907.09285", "submitter": "Clement Leroy", "authors": "Clement Leroy, Eric Anquetil, Nathalie Girard", "title": "ParaFIS:A new online fuzzy inference system based on parallel drift\n  anticipation", "comments": null, "journal-ref": "FUZZ-IEEE, Jun 2019, New Orleans, United States", "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a new architecture of incremen-tal fuzzy inference system\n(also called Evolving Fuzzy System-EFS). In the context of classifying data\nstream in non stationary environment, concept drifts problems must be\naddressed. Several studies have shown that EFS can deal with such environment\nthanks to their high structural flexibility. These EFS perform well with smooth\ndrift (or incremental drift). The new architecture we propose is focused on\nimproving the processing of brutal changes in the data distribution (often\ncalled brutal concept drift). More precisely, a generalized EFS is paired with\na module of anticipation to improve the adaptation of new rules after a brutal\ndrift. The proposed architecture is evaluated on three datasets from UCI\nrepository where artificial brutal drifts have been applied. A fit model is\nalso proposed to get a \"reactivity time\" needed to converge to the steady-state\nand the score at end. Both characteristics are compared between the same system\nwith and without anticipation and with a similar EFS from state-of-the-art. The\nexperiments demonstrates improvements in both cases.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jul 2019 08:30:59 GMT"}], "update_date": "2019-07-23", "authors_parsed": [["Leroy", "Clement", ""], ["Anquetil", "Eric", ""], ["Girard", "Nathalie", ""]]}, {"id": "1907.09286", "submitter": "Besher Alhalabi", "authors": "Besher Alhalabi, Mohamed Medhat Gaber, Shadi Basurra", "title": "EnSyth: A Pruning Approach to Synthesis of Deep Learning Ensembles", "comments": "accepted in SMC2019", "journal-ref": null, "doi": "10.1109/SMC.2019.8913944", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks have achieved state-of-art performance in many domains\nincluding computer vision, natural language processing and self-driving cars.\nHowever, they are very computationally expensive and memory intensive which\nraises significant challenges when it comes to deploy or train them on strict\nlatency applications or resource-limited environments. As a result, many\nattempts have been introduced to accelerate and compress deep learning models,\nhowever the majority were not able to maintain the same accuracy of the\nbaseline models. In this paper, we describe EnSyth, a deep learning ensemble\napproach to enhance the predictability of compact neural network's models.\nFirst, we generate a set of diverse compressed deep learning models using\ndifferent hyperparameters for a pruning method, after that we utilise ensemble\nlearning to synthesise the outputs of the compressed models to compose a new\npool of classifiers. Finally, we apply backward elimination on the generated\npool to explore the best performing combinations of models. On CIFAR-10,\nCIFAR-5 data-sets with LeNet-5, EnSyth outperforms the predictability of the\nbaseline model.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jul 2019 12:44:46 GMT"}], "update_date": "2020-04-13", "authors_parsed": [["Alhalabi", "Besher", ""], ["Gaber", "Mohamed Medhat", ""], ["Basurra", "Shadi", ""]]}, {"id": "1907.09294", "submitter": "Thibault Laugel", "authors": "Thibault Laugel, Marie-Jeanne Lesot, Christophe Marsala, Xavier\n  Renard, Marcin Detyniecki", "title": "The Dangers of Post-hoc Interpretability: Unjustified Counterfactual\n  Explanations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Post-hoc interpretability approaches have been proven to be powerful tools to\ngenerate explanations for the predictions made by a trained black-box model.\nHowever, they create the risk of having explanations that are a result of some\nartifacts learned by the model instead of actual knowledge from the data. This\npaper focuses on the case of counterfactual explanations and asks whether the\ngenerated instances can be justified, i.e. continuously connected to some\nground-truth data. We evaluate the risk of generating unjustified\ncounterfactual examples by investigating the local neighborhoods of instances\nwhose predictions are to be explained and show that this risk is quite high for\nseveral datasets. Furthermore, we show that most state of the art approaches do\nnot differentiate justified from unjustified counterfactual examples, leading\nto less useful explanations.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jul 2019 13:10:24 GMT"}], "update_date": "2021-04-14", "authors_parsed": [["Laugel", "Thibault", ""], ["Lesot", "Marie-Jeanne", ""], ["Marsala", "Christophe", ""], ["Renard", "Xavier", ""], ["Detyniecki", "Marcin", ""]]}, {"id": "1907.09314", "submitter": "Prashanth B", "authors": "B.U.V Prashanth, Mohammed Riyaz Ahmed", "title": "Artificial Neural Network Algorithm based Skyrmion Material Design of\n  Chiral Crystals", "comments": "8 Pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.comp-ph cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The model presented in this research predicts ideal chiral crystal and\npropose a new direction of designing chiral crystals. Skyrmions are\ntopologically protected and structurally assymetric materials with an exotic\nspin composition. This work presents deep learning method for skyrmion material\ndesign of chiral crystals. This paper presents an approach to construct a\nprobabilistic classifier and an Artificial Neural Network(ANN) from a true or\nfalse chirality dataset consisting of chiral and achiral compounds with 'A' and\n'B' type elements. A quantitative predictor for accuracy of forming the chiral\ncrystals is illustrated. The feasibility of ANN method is tested in a\ncomprehensive manner by comparing with probalistic classifier method.\nThroughout this manuscript we present deep learnig algorithm design with\nmodelling and simulations of materials. This research work elucidated paves a\nway to develop sophisticated software tool to make an indicator of crystal\ndesign.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jul 2019 09:07:09 GMT"}], "update_date": "2019-07-23", "authors_parsed": [["Prashanth", "B. U. V", ""], ["Ahmed", "Mohammed Riyaz", ""]]}, {"id": "1907.09319", "submitter": "Taylan \\c{S}ahin", "authors": "Taylan \\c{S}ahin, Ramin Khalili, Mate Boban, Adam Wolisz", "title": "VRLS: A Unified Reinforcement Learning Scheduler for Vehicle-to-Vehicle\n  Communications", "comments": "Article accepted to IEEE CAVS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.AI cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Vehicle-to-vehicle (V2V) communications have distinct challenges that need to\nbe taken into account when scheduling the radio resources. Although centralized\nschedulers (e.g., located on base stations) could be utilized to deliver high\nscheduling performance, they cannot be employed in case of coverage gaps. To\naddress the issue of reliable scheduling of V2V transmissions out of coverage,\nwe propose Vehicular Reinforcement Learning Scheduler (VRLS), a centralized\nscheduler that predictively assigns the resources for V2V communication while\nthe vehicle is still in cellular network coverage. VRLS is a unified\nreinforcement learning (RL) solution, wherein the learning agent, the state\nrepresentation, and the reward provided to the agent are applicable to\ndifferent vehicular environments of interest (in terms of vehicular density,\nresource configuration, and wireless channel conditions). Such a unified\nsolution eliminates the necessity of redesigning the RL components for a\ndifferent environment, and facilitates transfer learning from one to another\nsimilar environment. We evaluate the performance of VRLS and show its ability\nto avoid collisions and half-duplex errors, and to reuse the resources better\nthan the state of the art scheduling algorithms. We also show that pre-trained\nVRLS agent can adapt to different V2V environments with limited retraining,\nthus enabling real-world deployment in different scenarios.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jul 2019 13:42:51 GMT"}], "update_date": "2019-07-23", "authors_parsed": [["\u015eahin", "Taylan", ""], ["Khalili", "Ramin", ""], ["Boban", "Mate", ""], ["Wolisz", "Adam", ""]]}, {"id": "1907.09340", "submitter": "Pranava Madhyastha", "authors": "Pranava Madhyastha, Josiah Wang, Lucia Specia", "title": "VIFIDEL: Evaluating the Visual Fidelity of Image Descriptions", "comments": "Accepted for publication at ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We address the task of evaluating image description generation systems. We\npropose a novel image-aware metric for this task: VIFIDEL. It estimates the\nfaithfulness of a generated caption with respect to the content of the actual\nimage, based on the semantic similarity between labels of objects depicted in\nimages and words in the description. The metric is also able to take into\naccount the relative importance of objects mentioned in human reference\ndescriptions during evaluation. Even if these human reference descriptions are\nnot available, VIFIDEL can still reliably evaluate system descriptions. The\nmetric achieves high correlation with human judgments on two well-known\ndatasets and is competitive with metrics that depend on human references\n", "versions": [{"version": "v1", "created": "Mon, 22 Jul 2019 14:33:43 GMT"}], "update_date": "2019-07-23", "authors_parsed": [["Madhyastha", "Pranava", ""], ["Wang", "Josiah", ""], ["Specia", "Lucia", ""]]}, {"id": "1907.09350", "submitter": "Tiancheng Yu", "authors": "Tiancheng Yu, Suvrit Sra", "title": "Efficient Policy Learning for Non-Stationary MDPs under Adversarial\n  Manipulation", "comments": "There is a problem in the Theorem 1. We will try to fix it and update\n  a new version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A Markov Decision Process (MDP) is a popular model for reinforcement\nlearning. However, its commonly used assumption of stationary dynamics and\nrewards is too stringent and fails to hold in adversarial, nonstationary, or\nmulti-agent problems. We study an episodic setting where the parameters of an\nMDP can differ across episodes. We learn a reliable policy of this potentially\nadversarial MDP by developing an Adversarial Reinforcement Learning (ARL)\nalgorithm that reduces our MDP to a sequence of \\emph{adversarial} bandit\nproblems. ARL achieves $O(\\sqrt{SATH^3})$ regret, which is optimal with respect\nto $S$, $A$, and $T$, and its dependence on $H$ is the best (even for the usual\nstationary MDP) among existing model-free methods.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jul 2019 14:48:49 GMT"}, {"version": "v2", "created": "Wed, 21 Aug 2019 14:36:57 GMT"}], "update_date": "2019-08-22", "authors_parsed": [["Yu", "Tiancheng", ""], ["Sra", "Suvrit", ""]]}, {"id": "1907.09356", "submitter": "Anastasiia Koloskova", "authors": "Anastasia Koloskova, Tao Lin, Sebastian U. Stich, Martin Jaggi", "title": "Decentralized Deep Learning with Arbitrary Communication Compression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC cs.DS math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decentralized training of deep learning models is a key element for enabling\ndata privacy and on-device learning over networks, as well as for efficient\nscaling to large compute clusters. As current approaches suffer from limited\nbandwidth of the network, we propose the use of communication compression in\nthe decentralized training context. We show that Choco-SGD $-$ recently\nintroduced and analyzed for strongly-convex objectives only $-$ converges under\narbitrary high compression ratio on general non-convex functions at the rate\n$O\\bigl(1/\\sqrt{nT}\\bigr)$ where $T$ denotes the number of iterations and $n$\nthe number of workers. The algorithm achieves linear speedup in the number of\nworkers and supports higher compression than previous state-of-the art methods.\nWe demonstrate the practical performance of the algorithm in two key scenarios:\nthe training of deep learning models (i) over distributed user devices,\nconnected by a social network and (ii) in a datacenter (outperforming\nall-reduce time-wise).\n", "versions": [{"version": "v1", "created": "Mon, 22 Jul 2019 14:53:02 GMT"}, {"version": "v2", "created": "Wed, 18 Mar 2020 11:06:08 GMT"}, {"version": "v3", "created": "Wed, 11 Nov 2020 17:24:35 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Koloskova", "Anastasia", ""], ["Lin", "Tao", ""], ["Stich", "Sebastian U.", ""], ["Jaggi", "Martin", ""]]}, {"id": "1907.09358", "submitter": "Aditya Mogadala", "authors": "Aditya Mogadala and Marimuthu Kalimuthu and Dietrich Klakow", "title": "Trends in Integration of Vision and Language Research: A Survey of\n  Tasks, Datasets, and Methods", "comments": "Accepted at Journal of Artificial Intelligence Research (JAIR)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The interest in Artificial Intelligence (AI) and its applications has seen\nunprecedented growth in the last few years. This success can be partly\nattributed to the advancements made in the sub-fields of AI such as Machine\nLearning (ML), Computer Vision (CV), and Natural Language Processing (NLP). The\nlargest of the growths in these fields has been made possible with deep\nlearning, a sub-area of machine learning, which uses the principles of\nartificial neural networks. This has created significant interest in the\nintegration of vision and language. The tasks are designed such that they\nperfectly embrace the ideas of deep learning. In this survey, we focus on ten\nprominent tasks that integrate language and vision by discussing their problem\nformulations, methods, existing datasets, evaluation measures, and compare the\nresults obtained with corresponding state-of-the-art methods. Our efforts go\nbeyond earlier surveys which are either task-specific or concentrate only on\none type of visual content, i.e., image or video. Furthermore, we also provide\nsome potential future directions in this field of research with an anticipation\nthat this survey brings in innovative thoughts and ideas to address the\nexisting challenges and build new applications.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jul 2019 14:53:48 GMT"}, {"version": "v2", "created": "Sat, 12 Sep 2020 13:26:29 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Mogadala", "Aditya", ""], ["Kalimuthu", "Marimuthu", ""], ["Klakow", "Dietrich", ""]]}, {"id": "1907.09361", "submitter": "Nilesh Chakraborty", "authors": "Nilesh Chakraborty, Denis Lukovnikov, Gaurav Maheshwari, Priyansh\n  Trivedi, Jens Lehmann, Asja Fischer", "title": "Introduction to Neural Network based Approaches for Question Answering\n  over Knowledge Graphs", "comments": "Preprint, under review. The first four authors contributed equally to\n  this paper, and should be regarded as co-first authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Question answering has emerged as an intuitive way of querying structured\ndata sources, and has attracted significant advancements over the years. In\nthis article, we provide an overview over these recent advancements, focusing\non neural network based question answering systems over knowledge graphs. We\nintroduce readers to the challenges in the tasks, current paradigms of\napproaches, discuss notable advancements, and outline the emerging trends in\nthe field. Through this article, we aim to provide newcomers to the field with\na suitable entry point, and ease their process of making informed decisions\nwhile creating their own QA system.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jul 2019 14:57:13 GMT"}], "update_date": "2019-07-23", "authors_parsed": [["Chakraborty", "Nilesh", ""], ["Lukovnikov", "Denis", ""], ["Maheshwari", "Gaurav", ""], ["Trivedi", "Priyansh", ""], ["Lehmann", "Jens", ""], ["Fischer", "Asja", ""]]}, {"id": "1907.09369", "submitter": "Armin Seyeditabari", "authors": "Armin Seyeditabari, Narges Tabari, Shafie Gholizadeh, Wlodek Zadrozny", "title": "Emotion Detection in Text: Focusing on Latent Representation", "comments": "6 pages, 7 tables, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, emotion detection in text has become more popular due to its\nvast potential applications in marketing, political science, psychology,\nhuman-computer interaction, artificial intelligence, etc. In this work, we\nargue that current methods which are based on conventional machine learning\nmodels cannot grasp the intricacy of emotional language by ignoring the\nsequential nature of the text, and the context. These methods, therefore, are\nnot sufficient to create an applicable and generalizable emotion detection\nmethodology. Understanding these limitations, we present a new network based on\na bidirectional GRU model to show that capturing more meaningful information\nfrom text can significantly improve the performance of these models. The\nresults show significant improvement with an average of 26.8 point increase in\nF-measure on our test data and 38.6 increase on the totally new dataset.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jul 2019 15:33:53 GMT"}], "update_date": "2019-07-23", "authors_parsed": [["Seyeditabari", "Armin", ""], ["Tabari", "Narges", ""], ["Gholizadeh", "Shafie", ""], ["Zadrozny", "Wlodek", ""]]}, {"id": "1907.09380", "submitter": "Shervin Minaee", "authors": "Shervin Minaee, Amirali Abdolrashidi", "title": "DeepIris: Iris Recognition Using A Deep Learning Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Iris recognition has been an active research area during last few decades,\nbecause of its wide applications in security, from airports to homeland\nsecurity border control. Different features and algorithms have been proposed\nfor iris recognition in the past. In this paper, we propose an end-to-end deep\nlearning framework for iris recognition based on residual convolutional neural\nnetwork (CNN), which can jointly learn the feature representation and perform\nrecognition. We train our model on a well-known iris recognition dataset using\nonly a few training images from each class, and show promising results and\nimprovements over previous approaches. We also present a visualization\ntechnique which is able to detect the important areas in iris images which can\nmostly impact the recognition results. We believe this framework can be widely\nused for other biometrics recognition tasks, helping to have a more scalable\nand accurate systems.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jul 2019 15:48:48 GMT"}], "update_date": "2019-07-23", "authors_parsed": [["Minaee", "Shervin", ""], ["Abdolrashidi", "Amirali", ""]]}, {"id": "1907.09395", "submitter": "Nazim Choudhury", "authors": "Nazim Choudhury, Fahim Faisal, Matloob Khushi", "title": "Mining Temporal Evolution of Knowledge Graph and Genealogical Features\n  for Literature-based Discovery Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Literature-based knowledge discovery process identifies the important but\nimplicit relations among information embedded in published literature. Existing\ntechniques from Information Retrieval and Natural Language Processing attempt\nto identify the hidden or unpublished connections between information concepts\nwithin published literature, however, these techniques undermine the concept of\npredicting the future and emerging relations among scientific knowledge\ncomponents encapsulated within the literature. Keyword Co-occurrence Network\n(KCN), built upon author selected keywords (i.e., knowledge entities), is\nconsidered as a knowledge graph that focuses both on these knowledge components\nand knowledge structure of a scientific domain by examining the relationships\nbetween knowledge entities. Using data from two multidisciplinary research\ndomains other than the medical domain, capitalizing on bibliometrics, the\ndynamicity of temporal KCNs, and a Long Short Term Memory recurrent neural\nnetwork, this study proposed a framework to successfully predict the future\nliterature-based discoveries - the emerging connections among knowledge units.\nFraming the problem as a dynamic supervised link prediction task, the proposed\nframework integrates some novel node and edge-level features. Temporal\nimportance of keywords computed from both bipartite and unipartite networks,\ncommunities of keywords, built upon genealogical relations, and relative\nimportance of temporal citation counts used in the feature construction\nprocess. Both node and edge-level features were input into an LSTM network to\nforecast the feature values for positive and negatively labeled non-connected\nkeyword pairs and classify them accurately. High classification performance\nrates suggest that these features are supportive both in predicting the\nemerging connections between scientific knowledge units and emerging trend\nanalysis.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jul 2019 16:10:37 GMT"}, {"version": "v2", "created": "Mon, 11 Nov 2019 02:40:35 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Choudhury", "Nazim", ""], ["Faisal", "Fahim", ""], ["Khushi", "Matloob", ""]]}, {"id": "1907.09404", "submitter": "Alessandro Lameiras Koerich", "authors": "Kelly Lais Wiggers, Alceu de Souza Britto Junior, Alessandro Lameiras\n  Koerich, Laurent Heutte, Luiz Eduardo Soares de Oliveira", "title": "Deep Learning Approaches for Image Retrieval and Pattern Spotting in\n  Ancient Documents", "comments": "The paper is under consideration at Pattern Recognition Letters", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes two approaches for content-based image retrieval and\npattern spotting in document images using deep learning. The first approach\nuses a pre-trained CNN model to cope with the lack of training data, which is\nfine-tuned to achieve a compact yet discriminant representation of queries and\nimage candidates. The second approach uses a Siamese Convolution Neural Network\ntrained on a previously prepared subset of image pairs from the ImageNet\ndataset to provide the similarity-based feature maps. In both methods, the\nlearned representation scheme considers feature maps of different sizes which\nare evaluated in terms of retrieval performance. A robust experimental protocol\nusing two public datasets (Tobacoo-800 and DocExplore) has shown that the\nproposed methods compare favorably against state-of-the-art document image\nretrieval and pattern spotting methods.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jul 2019 16:27:19 GMT"}], "update_date": "2019-07-25", "authors_parsed": [["Wiggers", "Kelly Lais", ""], ["Junior", "Alceu de Souza Britto", ""], ["Koerich", "Alessandro Lameiras", ""], ["Heutte", "Laurent", ""], ["de Oliveira", "Luiz Eduardo Soares", ""]]}, {"id": "1907.09423", "submitter": "Eleonora Bernasconi", "authors": "Eleonora Bernasconi, Francesco Pugliese, Diego Zardetto, Monica\n  Scannapieco", "title": "Satellite-Net: Automatic Extraction of Land Cover Indicators from\n  Satellite Imagery by Deep Learning", "comments": "New Techniques and Technologies for Statistics 2019, Brussels", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper we address the challenge of land cover classification for\nsatellite images via Deep Learning (DL). Land Cover aims to detect the physical\ncharacteristics of the territory and estimate the percentage of land occupied\nby a certain category of entities: vegetation, residential buildings,\nindustrial areas, forest areas, rivers, lakes, etc. DL is a new paradigm for\nBig Data analytics and in particular for Computer Vision. The application of DL\nin images classification for land cover purposes has a great potential owing to\nthe high degree of automation and computing performance. In particular, the\ninvention of Convolution Neural Networks (CNNs) was a fundament for the\nadvancements in this field. In [1], the Satellite Task Team of the UN Global\nWorking Group describes the results achieved so far with respect to the use of\nearth observation for Official Statistics. However, in that study, CNNs have\nnot yet been explored for automatic classification of imagery. This work\ninvestigates the usage of CNNs for the estimation of land cover indicators,\nproviding evidence of the first promising results. In particular, the paper\nproposes a customized model, called Satellite-Net, able to reach an accuracy\nlevel up to 98% on test sets.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jul 2019 16:50:35 GMT"}], "update_date": "2019-07-23", "authors_parsed": [["Bernasconi", "Eleonora", ""], ["Pugliese", "Francesco", ""], ["Zardetto", "Diego", ""], ["Scannapieco", "Monica", ""]]}, {"id": "1907.09427", "submitter": "Salman Sherin", "authors": "Salman Sherin, Muhammad Uzair khan, Muhammad Zohaib Iqbal", "title": "A Systematic Mapping Study on Testing of Machine Learning Programs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We aim to conduct a systematic mapping in the area of testing ML programs. We\nidentify, analyze and classify the existing literature to provide an overview\nof the area. We followed well-established guidelines of systematic mapping to\ndevelop a systematic protocol to identify and review the existing literature.\nWe formulate three sets of research questions, define inclusion and exclusion\ncriteria and systematically identify themes for the classification of existing\ntechniques. We also report the quality of the published works using established\nassessment criteria. we finally selected 37 papers out of 1654 based on our\nselection criteria up to January 2019. We analyze trends such as contribution\nfacet, research facet, test approach, type of ML and the kind of testing with\nseveral other attributes. We also discuss the empirical evidence and reporting\nquality of selected papers. The data from the study is made publicly available\nfor other researchers and practitioners. We present an overview of the area by\nanswering several research questions. The area is growing rapidly, however,\nthere is lack of enough empirical evidence to compare and assess the\neffectiveness of the techniques. More publicly available tools are required for\nuse of practitioners and researchers. Further attention is needed on\nnon-functional testing and testing of ML programs using reinforcement learning.\nWe believe that this study can help researchers and practitioners to obtain an\noverview of the area and identify several sub-areas where more research is\nrequired\n", "versions": [{"version": "v1", "created": "Thu, 11 Jul 2019 17:32:52 GMT"}], "update_date": "2019-07-23", "authors_parsed": [["Sherin", "Salman", ""], ["khan", "Muhammad Uzair", ""], ["Iqbal", "Muhammad Zohaib", ""]]}, {"id": "1907.09439", "submitter": "Hengtao He", "authors": "Hengtao He, Chao-Kai Wen, Shi Jin, and Geoffrey Ye Li", "title": "Model-Driven Deep Learning for MIMO Detection", "comments": "This paper has been published on the IEEE Trans. Signal Process. The\n  code is available at https://github.com/hehengtao/OAMP-Net", "journal-ref": null, "doi": "10.1109/TSP.2020.2976585", "report-no": null, "categories": "cs.IT cs.LG eess.SP math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we investigate the model-driven deep learning (DL) for MIMO\ndetection. In particular, the MIMO detector is specially designed by unfolding\nan iterative algorithm and adding some trainable parameters. Since the number\nof trainable parameters is much fewer than the data-driven DL based signal\ndetector, the model-driven DL based MIMO detector can be rapidly trained with a\nmuch smaller data set. The proposed MIMO detector can be extended to soft-input\nsoft-output detection easily. Furthermore, we investigate joint MIMO channel\nestimation and signal detection (JCESD), where the detector takes channel\nestimation error and channel statistics into consideration while channel\nestimation is refined by detected data and considers the detection error. Based\non numerical results, the model-driven DL based MIMO detector significantly\nimproves the performance of corresponding traditional iterative detector,\noutperforms other DL-based MIMO detectors and exhibits superior robustness to\nvarious mismatches.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jul 2019 17:22:50 GMT"}, {"version": "v2", "created": "Fri, 19 Mar 2021 07:50:29 GMT"}], "update_date": "2021-03-24", "authors_parsed": [["He", "Hengtao", ""], ["Wen", "Chao-Kai", ""], ["Jin", "Shi", ""], ["Li", "Geoffrey Ye", ""]]}, {"id": "1907.09452", "submitter": "Adamantios Ntakaris Mr", "authors": "Adamantios Ntakaris, Juho Kanniainen, Moncef Gabbouj, Alexandros\n  Iosifidis", "title": "Mid-price Prediction Based on Machine Learning Methods with Technical\n  and Quantitative Indicators", "comments": null, "journal-ref": null, "doi": "10.1371/journal.pone.0234107", "report-no": null, "categories": "q-fin.ST cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stock price prediction is a challenging task, but machine learning methods\nhave recently been used successfully for this purpose. In this paper, we\nextract over 270 hand-crafted features (factors) inspired by technical and\nquantitative analysis and tested their validity on short-term mid-price\nmovement prediction. We focus on a wrapper feature selection method using\nentropy, least-mean squares, and linear discriminant analysis. We also build a\nnew quantitative feature based on adaptive logistic regression for online\nlearning, which is constantly selected first among the majority of the proposed\nfeature selection methods. This study examines the best combination of features\nusing high frequency limit order book data from Nasdaq Nordic. Our results\nsuggest that sorting methods and classifiers can be used in such a way that one\ncan reach the best performance with a combination of only very few advanced\nhand-crafted features.\n", "versions": [{"version": "v1", "created": "Sat, 13 Jul 2019 13:26:47 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["Ntakaris", "Adamantios", ""], ["Kanniainen", "Juho", ""], ["Gabbouj", "Moncef", ""], ["Iosifidis", "Alexandros", ""]]}, {"id": "1907.09453", "submitter": "Simone Gelmini", "authors": "Simone Gelmini, Giulio Panzani, Sergio Savaresi", "title": "Analysis and development of an automatic eCall for motorcycles: a\n  one-class cepstrum approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The automatic dial of an emergency call - eCall - in response to a road\naccident is a feature that is gaining interest in the intelligent vehicle\ncommunity. It indirectly increases the driving safety of road vehicles, but\npresents the technical challenge of developing an algorithm which triggers the\nemergency call only when needed, a non-trivial task for two-wheeled vehicles\ndue to their complex dynamics. In the present work, we propose an eCall\nalgorithm that detects these anomalies in the data time series, thanks to the\ncepstral analysis. The main advantage of the proposed approach is the direct\nfocus on the data dynamics, solving the limits of approaches based on the\nanalysis of the instantaneous value of some signals combination. The algorithm\nis calibrated and tested against real driving data of ten different drivers,\nincluding seven real crash events, and performance are compared with known\nmethods.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jul 2019 14:55:09 GMT"}], "update_date": "2019-07-23", "authors_parsed": [["Gelmini", "Simone", ""], ["Panzani", "Giulio", ""], ["Savaresi", "Sergio", ""]]}, {"id": "1907.09455", "submitter": "Abdallah Chehade", "authors": "Abdallah A. Chehade, Ala A. Hussein", "title": "Latent Function Decomposition for Forecasting Li-ion Battery Cells\n  Capacity: A Multi-Output Convolved Gaussian Process Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A latent function decomposition method is proposed for forecasting the\ncapacity of lithium-ion battery cells. The method uses the Multi-Output\nGaussian Process, a generative machine learning framework for multi-task and\ntransfer learning. The MCGP decomposes the available capacity trends from\nmultiple battery cells into latent functions. The latent functions are then\nconvolved over kernel smoothers to reconstruct and/or forecast capacity trends\nof the battery cells. Besides the high prediction accuracy the proposed method\npossesses, it provides uncertainty information for the predictions and captures\nnontrivial cross-correlations between capacity trends of different battery\ncells. These two merits make the proposed MCGP a very reliable and practical\nsolution for applications that use battery cell packs. The MCGP is derived and\ncompared to benchmark methods on an experimental lithium-ion battery cells\ndata. The results show the effectiveness of the proposed method.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jul 2019 15:48:22 GMT"}], "update_date": "2019-07-23", "authors_parsed": [["Chehade", "Abdallah A.", ""], ["Hussein", "Ala A.", ""]]}, {"id": "1907.09466", "submitter": "Elaheh Barati", "authors": "Elaheh Barati and Xuewen Chen", "title": "An Actor-Critic-Attention Mechanism for Deep Reinforcement Learning in\n  Multi-view Environments", "comments": "The 28th International Joint Conference on Artificial Intelligence\n  (IJCAI'19). arXiv admin note: text overlap with arXiv:1905.03985", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In reinforcement learning algorithms, leveraging multiple views of the\nenvironment can improve the learning of complicated policies. In multi-view\nenvironments, due to the fact that the views may frequently suffer from partial\nobservability, their level of importance are often different. In this paper, we\npropose a deep reinforcement learning method and an attention mechanism in a\nmulti-view environment. Each view can provide various representative\ninformation about the environment. Through our attention mechanism, our method\ngenerates a single feature representation of environment given its multiple\nviews. It learns a policy to dynamically attend to each view based on its\nimportance in the decision-making process. Through experiments, we show that\nour method outperforms its state-of-the-art baselines on TORCS racing car\nsimulator and three other complex 3D environments with obstacles. We also\nprovide experimental results to evaluate the performance of our method on noisy\nconditions and partial observation settings.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jul 2019 19:38:02 GMT"}], "update_date": "2019-07-24", "authors_parsed": [["Barati", "Elaheh", ""], ["Chen", "Xuewen", ""]]}, {"id": "1907.09467", "submitter": "Qing Wang", "authors": "Qing Wang, Jiechao Xiong, Lei Han, Meng Fang, Xinghai Sun, Zhuobin\n  Zheng, Peng Sun, Zhengyou Zhang", "title": "Arena: a toolkit for Multi-Agent Reinforcement Learning", "comments": "21 pages, 14 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce Arena, a toolkit for multi-agent reinforcement learning (MARL)\nresearch. In MARL, it usually requires customizing observations, rewards and\nactions for each agent, changing cooperative-competitive agent-interaction, and\nplaying with/against a third-party agent, etc. We provide a novel modular\ndesign, called Interface, for manipulating such routines in essentially two\nways: 1) Different interfaces can be concatenated and combined, which extends\nthe OpenAI Gym Wrappers concept to MARL scenarios. 2) During MARL training or\ntesting, interfaces can be embedded in either wrapped OpenAI Gym compatible\nEnvironments or raw environment compatible Agents. We offer off-the-shelf\ninterfaces for several popular MARL platforms, including StarCraft II,\nPommerman, ViZDoom, Soccer, etc. The interfaces effectively support self-play\nRL and cooperative-competitive hybrid MARL. Also, Arena can be conveniently\nextended to your own favorite MARL platform.\n", "versions": [{"version": "v1", "created": "Sat, 20 Jul 2019 05:13:53 GMT"}], "update_date": "2019-07-24", "authors_parsed": [["Wang", "Qing", ""], ["Xiong", "Jiechao", ""], ["Han", "Lei", ""], ["Fang", "Meng", ""], ["Sun", "Xinghai", ""], ["Zheng", "Zhuobin", ""], ["Sun", "Peng", ""], ["Zhang", "Zhengyou", ""]]}, {"id": "1907.09470", "submitter": "Xinlei Pan", "authors": "Chaowei Xiao, Xinlei Pan, Warren He, Jian Peng, Mingjie Sun, Jinfeng\n  Yi, Mingyan Liu, Bo Li, Dawn Song", "title": "Characterizing Attacks on Deep Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning (DRL) has achieved great success in various\napplications. However, recent studies show that machine learning models are\nvulnerable to adversarial attacks. DRL models have been attacked by adding\nperturbations to observations. While such observation based attack is only one\naspect of potential attacks on DRL, other forms of attacks which are more\npractical require further analysis, such as manipulating environment dynamics.\nTherefore, we propose to understand the vulnerabilities of DRL from various\nperspectives and provide a thorough taxonomy of potential attacks. We conduct\nthe first set of experiments on the unexplored parts within the taxonomy. In\naddition to current observation based attacks against DRL, we propose the first\ntargeted attacks based on action space and environment dynamics. We also\nintroduce the online sequential attacks based on temporal consistency\ninformation among frames. To better estimate gradient in black-box setting, we\npropose a sampling strategy and theoretically prove its efficiency and\nestimation error bound. We conduct extensive experiments to compare the\neffectiveness of different attacks with several baselines in various\nenvironments, including game playing, robotics control, and autonomous driving.\n", "versions": [{"version": "v1", "created": "Sun, 21 Jul 2019 22:00:24 GMT"}, {"version": "v2", "created": "Wed, 24 Jul 2019 07:46:39 GMT"}], "update_date": "2019-07-25", "authors_parsed": [["Xiao", "Chaowei", ""], ["Pan", "Xinlei", ""], ["He", "Warren", ""], ["Peng", "Jian", ""], ["Sun", "Mingjie", ""], ["Yi", "Jinfeng", ""], ["Liu", "Mingyan", ""], ["Li", "Bo", ""], ["Song", "Dawn", ""]]}, {"id": "1907.09471", "submitter": "Shalin Shah", "authors": "Jianfeng Gao, Qiang Wu, Chris Burges, Krysta Svore, Yi Su, Nazan Khan,\n  Shalin Shah, Hongyan Zhou", "title": "Model Adaptation via Model Interpolation and Boosting for Web Search\n  Ranking", "comments": null, "journal-ref": null, "doi": "10.3115/1699571.1699578", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper explores two classes of model adaptation methods for Web search\nranking: Model Interpolation and error-driven learning approaches based on a\nboosting algorithm. The results show that model interpolation, though simple,\nachieves the best results on all the open test sets where the test data is very\ndifferent from the training data. The tree-based boosting algorithm achieves\nthe best performance on most of the closed test sets where the test data and\nthe training data are similar, but its performance drops significantly on the\nopen test sets due to the instability of trees. Several methods are explored to\nimprove the robustness of the algorithm, with limited success.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jul 2019 03:03:15 GMT"}], "update_date": "2019-07-24", "authors_parsed": [["Gao", "Jianfeng", ""], ["Wu", "Qiang", ""], ["Burges", "Chris", ""], ["Svore", "Krysta", ""], ["Su", "Yi", ""], ["Khan", "Nazan", ""], ["Shah", "Shalin", ""], ["Zhou", "Hongyan", ""]]}, {"id": "1907.09474", "submitter": "Vicent Blanes-Selva", "authors": "Vicent Blanes-Selva, Vicente Ruiz-Garc\\'ia, Salvador Tortajada,\n  Jos\\'e-Miguel Bened\\'i, Bernardo Valdivieso, Juan M. Garc\\'ia-G\\'omez", "title": "Design of one-year mortality forecast at hospital admission based: a\n  machine learning approach", "comments": null, "journal-ref": null, "doi": "10.1177/1460458220987580", "report-no": null, "categories": "cs.LG stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Background: Palliative care is referred to a set of programs for patients\nthat suffer life-limiting illnesses. These programs aim to guarantee a minimum\nlevel of quality of life (QoL) for the last stage of life. They are currently\nbased on clinical evaluation of risk of one-year mortality.\n  Objectives: The main objective of this work is to develop and validate\nmachine-learning based models to predict the exitus of a patient within the\nnext year using data gathered at hospital admission.\n  Methods: Five machine learning techniques were applied in our study to\ndevelop machine-learning predictive models: Support Vector Machines,\nK-neighbors Classifier, Gradient Boosting Classifier, Random Forest and\nMultilayer Perceptron. All models were trained and evaluated using the\nretrospective dataset. The evaluation was performed with five metrics computed\nby a resampling strategy: Accuracy, the area under the ROC curve, Specificity,\nSensitivity, and the Balanced Error Rate.\n  Results: All models for forecasting one-year mortality achieved an AUC ROC\nfrom 0.858 to 0.911. Specifically, Gradient Boosting Classifier was the best\nmodel, producing an AUC ROC of 0.911 (CI 95%, 0.911 to 0.912), a sensitivity of\n0.858 (CI 95%, 0.856 to 0.86) and a specificity of 0.807 (CI 95%, 0.806 to\n0808) and a BER of 0.168 (CI 95%, 0.167 to 0.169).\n  Conclusions: The analysis of common information at hospital admission\ncombined with machine learning techniques produced models with competitive\ndiscriminative power. Our models reach the best results reported in state of\nthe art. These results demonstrate that they can be used as an accurate\ndata-driven palliative care criteria inclusion.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jul 2019 14:18:04 GMT"}], "update_date": "2021-01-14", "authors_parsed": [["Blanes-Selva", "Vicent", ""], ["Ruiz-Garc\u00eda", "Vicente", ""], ["Tortajada", "Salvador", ""], ["Bened\u00ed", "Jos\u00e9-Miguel", ""], ["Valdivieso", "Bernardo", ""], ["Garc\u00eda-G\u00f3mez", "Juan M.", ""]]}, {"id": "1907.09475", "submitter": "Siqi Liu", "authors": "Siqi Liu, Kee Yuan Ngiam, Mengling Feng", "title": "Deep Reinforcement Learning for Clinical Decision Support: A Brief\n  Survey", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Owe to the recent advancements in Artificial Intelligence especially deep\nlearning, many data-driven decision support systems have been implemented to\nfacilitate medical doctors in delivering personalized care. We focus on the\ndeep reinforcement learning (DRL) models in this paper. DRL models have\ndemonstrated human-level or even superior performance in the tasks of computer\nvision and game playings, such as Go and Atari game. However, the adoption of\ndeep reinforcement learning techniques in clinical decision optimization is\nstill rare. We present the first survey that summarizes reinforcement learning\nalgorithms with Deep Neural Networks (DNN) on clinical decision support. We\nalso discuss some case studies, where different DRL algorithms were applied to\naddress various clinical challenges. We further compare and contrast the\nadvantages and limitations of various DRL algorithms and present a preliminary\nguide on how to choose the appropriate DRL algorithm for particular clinical\napplications.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jul 2019 14:44:25 GMT"}], "update_date": "2019-07-24", "authors_parsed": [["Liu", "Siqi", ""], ["Ngiam", "Kee Yuan", ""], ["Feng", "Mengling", ""]]}, {"id": "1907.09478", "submitter": "Muhammad Shaban", "authors": "Muhammad Shaban, Ruqayya Awan, Muhammad Moazam Fraz, Ayesha Azam,\n  David Snead, Nasir M. Rajpoot", "title": "Context-Aware Convolutional Neural Network for Grading of Colorectal\n  Cancer Histology Images", "comments": "10 pages, 4 figures, Supplementary Document", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Digital histology images are amenable to the application of convolutional\nneural network (CNN) for analysis due to the sheer size of pixel data present\nin them. CNNs are generally used for representation learning from small image\npatches (e.g. 224x224) extracted from digital histology images due to\ncomputational and memory constraints. However, this approach does not\nincorporate high-resolution contextual information in histology images. We\npropose a novel way to incorporate larger context by a context-aware neural\nnetwork based on images with a dimension of 1,792x1,792 pixels. The proposed\nframework first encodes the local representation of a histology image into high\ndimensional features then aggregates the features by considering their spatial\norganization to make a final prediction. The proposed method is evaluated for\ncolorectal cancer grading and breast cancer classification. A comprehensive\nanalysis of some variants of the proposed method is presented. Our method\noutperformed the traditional patch-based approaches, problem-specific methods,\nand existing context-based methods quantitatively by a margin of 3.61%. Code\nand dataset related information is available at this link:\nhttps://tia-lab.github.io/Context-Aware-CNN\n", "versions": [{"version": "v1", "created": "Mon, 22 Jul 2019 16:37:36 GMT"}], "update_date": "2019-07-24", "authors_parsed": [["Shaban", "Muhammad", ""], ["Awan", "Ruqayya", ""], ["Fraz", "Muhammad Moazam", ""], ["Azam", "Ayesha", ""], ["Snead", "David", ""], ["Rajpoot", "Nasir M.", ""]]}, {"id": "1907.09495", "submitter": "Lin Meng", "authors": "Lin Meng and Jiawei Zhang", "title": "IsoNN: Isomorphic Neural Network for Graph Representation Learning and\n  Classification", "comments": "14 pages, 6 figures, submitted to ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning models have achieved huge success in numerous fields, such as\ncomputer vision and natural language processing. However, unlike such fields,\nit is hard to apply traditional deep learning models on the graph data due to\nthe 'node-orderless' property. Normally, adjacency matrices will cast an\nartificial and random node-order on the graphs, which renders the performance\nof deep models on graph classification tasks extremely erratic, and the\nrepresentations learned by such models lack clear interpretability. To\neliminate the unnecessary node-order constraint, we propose a novel model named\nIsomorphic Neural Network (IsoNN), which learns the graph representation by\nextracting its isomorphic features via the graph matching between input graph\nand templates. IsoNN has two main components: graph isomorphic feature\nextraction component and classification component. The graph isomorphic feature\nextraction component utilizes a set of subgraph templates as the kernel\nvariables to learn the possible subgraph patterns existing in the input graph\nand then computes the isomorphic features. A set of permutation matrices is\nused in the component to break the node-order brought by the matrix\nrepresentation. Three fully-connected layers are used as the classification\ncomponent in IsoNN. Extensive experiments are conducted on benchmark datasets,\nthe experimental results can demonstrate the effectiveness of ISONN, especially\ncompared with both classic and state-of-the-art graph classification methods.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jul 2019 18:01:04 GMT"}, {"version": "v2", "created": "Sat, 28 Sep 2019 03:55:50 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Meng", "Lin", ""], ["Zhang", "Jiawei", ""]]}, {"id": "1907.09504", "submitter": "Fatemeh Hadaeghi", "authors": "Fatemeh Hadaeghi", "title": "Reservoir Computing Models for Patient-Adaptable ECG Monitoring in\n  Wearable Devices", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The reservoir computing paradigm is employed to classify heartbeat anomalies\nonline based on electrocardiogram signals. Inspired by the principles of\ninformation processing in the brain, reservoir computing provides a framework\nto design, train, and analyze recurrent neural networks (RNNs) for processing\ntime-dependent information. Due to its computational efficiency and the fact\nthat training amounts to a simple linear regression, this supervised learning\nalgorithm has been variously considered as a strategy to implement useful\ncomputations not only on digital computers but also on emerging unconventional\nhardware platforms such as neuromorphic microchips. Here, this\nbiological-inspired learning framework is exploited to devise an accurate\npatient-adaptive model that has the potential to be integrated into wearable\ncardiac events monitoring devices. The proposed patient-customized model was\ntrained and tested on ECG recordings selected from the MIT-BIH arrhythmia\ndatabase. Restrictive inclusion criteria were used to conduct the study only on\nECGs including, at least, two classes of heartbeats with highly unequal number\nof instances. The results of extensive simulations showed this model not only\nprovides accurate, cheap and fast patient-customized heartbeat classifier but\nalso circumvents the problem of \"imbalanced classes\" when the readout weights\nare trained using weighted ridge-regression.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jul 2019 18:11:21 GMT"}], "update_date": "2019-07-24", "authors_parsed": [["Hadaeghi", "Fatemeh", ""]]}, {"id": "1907.09527", "submitter": "Vrindavan Harrison", "authors": "Vrindavan Harrison, Lena Reed, Shereen Oraby, Marilyn Walker", "title": "Maximizing Stylistic Control and Semantic Accuracy in NLG: Personality\n  Variation and Discourse Contrast", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural generation methods for task-oriented dialogue typically generate from\na meaning representation that is populated using a database of domain\ninformation, such as a table of data describing a restaurant. While earlier\nwork focused solely on the semantic fidelity of outputs, recent work has\nstarted to explore methods for controlling the style of the generated text\nwhile simultaneously achieving semantic accuracy. Here we experiment with two\nstylistic benchmark tasks, generating language that exhibits variation in\npersonality, and generating discourse contrast. We report a huge performance\nimprovement in both stylistic control and semantic accuracy over the state of\nthe art on both of these benchmarks. We test several different models and show\nthat putting stylistic conditioning in the decoder and eliminating the semantic\nre-ranker used in earlier models results in more than 15 points higher BLEU for\nPersonality, with a reduction of semantic error to near zero. We also report an\nimprovement from .75 to .81 in controlling contrast and a reduction in semantic\nerror from 16% to 2%.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jul 2019 18:57:14 GMT"}], "update_date": "2019-07-24", "authors_parsed": [["Harrison", "Vrindavan", ""], ["Reed", "Lena", ""], ["Oraby", "Shereen", ""], ["Walker", "Marilyn", ""]]}, {"id": "1907.09538", "submitter": "Shishir Rao", "authors": "Yikuan Li, Shishir Rao, Jose Roberto Ayala Solares, Abdelaali\n  Hassaine, Dexter Canoy, Yajie Zhu, Kazem Rahimi, Gholamreza Salimi-Khorshidi", "title": "BEHRT: Transformer for Electronic Health Records", "comments": "Shishir Rao and Yikuan Li have equally contributed to this work as\n  first authors. Shishir Rao is Corresponding Author for this work", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Today, despite decades of developments in medicine and the growing interest\nin precision healthcare, vast majority of diagnoses happen once patients begin\nto show noticeable signs of illness. Early indication and detection of\ndiseases, however, can provide patients and carers with the chance of early\nintervention, better disease management, and efficient allocation of healthcare\nresources. The latest developments in machine learning (more specifically, deep\nlearning) provides a great opportunity to address this unmet need. In this\nstudy, we introduce BEHRT: A deep neural sequence transduction model for EHR\n(electronic health records), capable of multitask prediction and disease\ntrajectory mapping. When trained and evaluated on the data from nearly 1.6\nmillion individuals, BEHRT shows a striking absolute improvement of 8.0-10.8%,\nin terms of Average Precision Score, compared to the existing state-of-the-art\ndeep EHR models (in terms of average precision, when predicting for the onset\nof 301 conditions). In addition to its superior prediction power, BEHRT\nprovides a personalised view of disease trajectories through its attention\nmechanism; its flexible architecture enables it to incorporate multiple\nheterogeneous concepts (e.g., diagnosis, medication, measurements, and more) to\nimprove the accuracy of its predictions; and its (pre-)training results in\ndisease and patient representations that can help us get a step closer to\ninterpretable predictions.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jul 2019 19:22:06 GMT"}], "update_date": "2019-07-24", "authors_parsed": [["Li", "Yikuan", ""], ["Rao", "Shishir", ""], ["Solares", "Jose Roberto Ayala", ""], ["Hassaine", "Abdelaali", ""], ["Canoy", "Dexter", ""], ["Zhu", "Yajie", ""], ["Rahimi", "Kazem", ""], ["Salimi-Khorshidi", "Gholamreza", ""]]}, {"id": "1907.09539", "submitter": "Zhenwei Dai", "authors": "Zhenwei Dai and Reinhard Heckel", "title": "Channel Normalization in Convolutional Neural Network avoids Vanishing\n  Gradients", "comments": "13 pages, 5 figures", "journal-ref": "ICML 2019 Workshop Deep Phenomena", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Normalization layers are widely used in deep neural networks to stabilize\ntraining. In this paper, we consider the training of convolutional neural\nnetworks with gradient descent on a single training example. This optimization\nproblem arises in recent approaches for solving inverse problems such as the\ndeep image prior or the deep decoder. We show that for this setup, channel\nnormalization, which centers and normalizes each channel individually, avoids\nvanishing gradients, whereas, without normalization, gradients vanish which\nprevents efficient optimization. This effect prevails in deep single-channel\nlinear convolutional networks, and we show that without channel normalization,\ngradient descent takes at least exponentially many steps to come close to an\noptimum. Contrary, with channel normalization, the gradients remain bounded,\nthus avoiding exploding gradients.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jul 2019 19:25:25 GMT"}], "update_date": "2019-07-24", "authors_parsed": [["Dai", "Zhenwei", ""], ["Heckel", "Reinhard", ""]]}, {"id": "1907.09540", "submitter": "Ozan Ozdenizci", "authors": "Ozan Ozdenizci, Barry Oken, Tab Memmott, Melanie Fried-Oken, Deniz\n  Erdogmus", "title": "Adversarial Feature Learning in Brain Interfacing: An Experimental Study\n  on Eliminating Drowsiness Effects", "comments": "8th Graz Brain-Computer Interface Conference 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Across- and within-recording variabilities in electroencephalographic (EEG)\nactivity is a major limitation in EEG-based brain-computer interfaces (BCIs).\nSpecifically, gradual changes in fatigue and vigilance levels during long EEG\nrecording durations and BCI system usage bring along significant fluctuations\nin BCI performances even when these systems are calibrated daily. We address\nthis in an experimental offline study from EEG-based BCI speller usage data\nacquired for one hour duration. As the main part of our methodological\napproach, we propose the concept of adversarial invariant feature learning for\nBCIs as a regularization approach on recently expanding EEG deep learning\narchitectures, to learn nuisance-invariant discriminative features. We\nempirically demonstrate the feasibility of adversarial feature learning on\neliminating drowsiness effects from event related EEG activity features, by\nusing temporal recording block ordering as the source of drowsiness\nvariability.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jul 2019 19:28:37 GMT"}], "update_date": "2019-07-24", "authors_parsed": [["Ozdenizci", "Ozan", ""], ["Oken", "Barry", ""], ["Memmott", "Tab", ""], ["Fried-Oken", "Melanie", ""], ["Erdogmus", "Deniz", ""]]}, {"id": "1907.09543", "submitter": "Adrian Albert", "authors": "Adrian Albert and Jasleen Kaur and Emanuele Strano and Marta Gonzalez", "title": "Spatial sensitivity analysis for urban land use prediction with\n  physics-constrained conditional generative adversarial networks", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurately forecasting urban development and its environmental and climate\nimpacts critically depends on realistic models of the spatial structure of the\nbuilt environment, and of its dependence on key factors such as population and\neconomic development. Scenario simulation and sensitivity analysis, i.e.,\npredicting how changes in underlying factors at a given location affect\nurbanization outcomes at other locations, is currently not achievable at a\nlarge scale with traditional urban growth models, which are either too\nsimplistic, or depend on detailed locally-collected socioeconomic data that is\nnot available in most places. Here we develop a framework to estimate, purely\nfrom globally-available remote-sensing data and without parametric assumptions,\nthe spatial sensitivity of the (\\textit{static}) rate of change of urban sprawl\nto key macroeconomic development indicators. We formulate this spatial\nregression problem as an image-to-image translation task using conditional\ngenerative adversarial networks (GANs), where the gradients necessary for\ncomparative static analysis are provided by the backpropagation algorithm used\nto train the model. This framework allows to naturally incorporate physical\nconstraints, e.g., the inability to build over water bodies. To validate the\nspatial structure of model-generated built environment distributions, we use\nspatial statistics commonly used in urban form analysis. We apply our method to\na novel dataset comprising of layers on the built environment, nightlighs\nmeasurements (a proxy for economic development and energy use), and population\ndensity for the world's most populous 15,000 cities.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jul 2019 19:32:43 GMT"}], "update_date": "2019-07-24", "authors_parsed": [["Albert", "Adrian", ""], ["Kaur", "Jasleen", ""], ["Strano", "Emanuele", ""], ["Gonzalez", "Marta", ""]]}, {"id": "1907.09547", "submitter": "Damek Davis", "authors": "Damek Davis, Dmitriy Drusvyatskiy, Vasileios Charisopoulos", "title": "Stochastic algorithms with geometric step decay converge linearly on\n  sharp functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic (sub)gradient methods require step size schedule tuning to perform\nwell in practice. Classical tuning strategies decay the step size polynomially\nand lead to optimal sublinear rates on (strongly) convex problems. An\nalternative schedule, popular in nonconvex optimization, is called\n\\emph{geometric step decay} and proceeds by halving the step size after every\nfew epochs. In recent work, geometric step decay was shown to improve\nexponentially upon classical sublinear rates for the class of \\emph{sharp}\nconvex functions. In this work, we ask whether geometric step decay similarly\nimproves stochastic algorithms for the class of sharp nonconvex problems. Such\nlosses feature in modern statistical recovery problems and lead to a new\nchallenge not present in the convex setting: the region of convergence is\nlocal, so one must bound the probability of escape. Our main result shows that\nfor a large class of stochastic, sharp, nonsmooth, and nonconvex problems a\ngeometric step decay schedule endows well-known algorithms with a local linear\nrate of convergence to global minimizers. This guarantee applies to the\nstochastic projected subgradient, proximal point, and prox-linear algorithms.\nAs an application of our main result, we analyze two statistical recovery\ntasks---phase retrieval and blind deconvolution---and match the best known\nguarantees under Gaussian measurement models and establish new guarantees under\nheavy-tailed distributions.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jul 2019 19:52:11 GMT"}], "update_date": "2019-07-24", "authors_parsed": [["Davis", "Damek", ""], ["Drusvyatskiy", "Dmitriy", ""], ["Charisopoulos", "Vasileios", ""]]}, {"id": "1907.09554", "submitter": "Ankita Shukla", "authors": "Ankita Shukla, Sarthak Bhagat, Shagun Uppal, Saket Anand, Pavan Turaga", "title": "Product of Orthogonal Spheres Parameterization for Disentangled\n  Representation Learning", "comments": "Accepted at British Machine Vision Conference (BMVC) 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning representations that can disentangle explanatory attributes\nunderlying the data improves interpretabilty as well as provides control on\ndata generation. Various learning frameworks such as VAEs, GANs and\nauto-encoders have been used in the literature to learn such representations.\nMost often, the latent space is constrained to a partitioned representation or\nstructured by a prior to impose disentangling. In this work, we advance the use\nof a latent representation based on a product space of Orthogonal Spheres\nPrOSe. The PrOSe model is motivated by the reasoning that latent-variables\nrelated to the physics of image-formation can under certain relaxed assumptions\nlead to spherical-spaces. Orthogonality between the spheres is motivated via\nphysical independence models. Imposing the orthogonal-sphere constraint is much\nsimpler than other complicated physical models, is fairly general and flexible,\nand extensible beyond the factors used to motivate its development. Under\nfurther relaxed assumptions of equal-sized latent blocks per factor, the\nconstraint can be written down in closed form as an ortho-normality term in the\nloss function. We show that our approach improves the quality of\ndisentanglement significantly. We find consistent improvement in\ndisentanglement compared to several state-of-the-art approaches, across several\nbenchmarks and metrics.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jul 2019 20:20:00 GMT"}], "update_date": "2019-07-24", "authors_parsed": [["Shukla", "Ankita", ""], ["Bhagat", "Sarthak", ""], ["Uppal", "Shagun", ""], ["Anand", "Saket", ""], ["Turaga", "Pavan", ""]]}, {"id": "1907.09557", "submitter": "Xiahan Shi", "authors": "Xiahan Shi, Leonard Salewski, Martin Schiegg, Zeynep Akata, Max\n  Welling", "title": "Relational Generalized Few-Shot Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transferring learned models to novel tasks is a challenging problem,\nparticularly if only very few labeled examples are available. Although this\nfew-shot learning setup has received a lot of attention recently, most proposed\nmethods focus on discriminating novel classes only. Instead, we consider the\nextended setup of generalized few-shot learning (GFSL), where the model is\nrequired to perform classification on the joint label space consisting of both\npreviously seen and novel classes. We propose a graph-based framework that\nexplicitly models relationships between all seen and novel classes in the joint\nlabel space. Our model Graph-convolutional Global Prototypical Networks (GcGPN)\nincorporates these inter-class relations using graph-convolution in order to\nembed novel class representations into the existing space of previously seen\nclasses in a globally consistent manner. Our approach ensures both fast\nadaptation and global discrimination, which is the major challenge in GFSL. We\ndemonstrate the benefits of our model on two challenging benchmark datasets.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jul 2019 20:23:27 GMT"}, {"version": "v2", "created": "Tue, 15 Sep 2020 09:23:48 GMT"}], "update_date": "2020-09-16", "authors_parsed": [["Shi", "Xiahan", ""], ["Salewski", "Leonard", ""], ["Schiegg", "Martin", ""], ["Akata", "Zeynep", ""], ["Welling", "Max", ""]]}, {"id": "1907.09562", "submitter": "Samira Sheikhi", "authors": "Samira Sheikhi", "title": "Practical Newton-Type Distributed Learning using Gradient Based\n  Approximations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study distributed algorithms for expected loss minimization where the\ndatasets are large and have to be stored on different machines. Often we deal\nwith minimizing the average of a set of convex functions where each function is\nthe empirical risk of the corresponding part of the data. In the distributed\nsetting where the individual data instances can be accessed only on the local\nmachines, there would be a series of rounds of local computations followed by\nsome communication among the machines. Since the cost of the communication is\nusually higher than the local machine computations, it is important to reduce\nit as much as possible. However, we should not allow this to make the\ncomputation too expensive to become a burden in practice. Using second-order\nmethods could make the algorithms converge faster and decrease the amount of\ncommunication needed. There are some successful attempts in developing\ndistributed second-order methods. Although these methods have shown fast\nconvergence, their local computation is expensive and could enjoy more\nimprovement for practical uses. In this study we modify an existing approach,\nDANE (Distributed Approximate NEwton), in order to improve the computational\ncost while maintaining the accuracy. We tackle this problem by using iterative\nmethods for solving the local subproblems approximately instead of providing\nexact solutions for each round of communication. We study how using different\niterative methods affect the behavior of the algorithm and try to provide an\nappropriate tradeoff between the amount of local computation and the required\namount of communication. We demonstrate the practicality of our algorithm and\ncompare it to the existing distributed gradient based methods such as SGD.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jul 2019 20:36:23 GMT"}], "update_date": "2019-07-24", "authors_parsed": [["Sheikhi", "Samira", ""]]}, {"id": "1907.09569", "submitter": "Peiye Liu", "authors": "Peiye Liu, Bo Wu, Huadong Ma, Mingoo Seok", "title": "MemNet: Memory-Efficiency Guided Neural Architecture Search with\n  Augment-Trim learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent studies on automatic neural architectures search have demonstrated\nsignificant performance, competitive to or even better than hand-crafted neural\narchitectures. However, most of the existing network architecture tend to use\nresidual, parallel structures and concatenation block between shallow and deep\nfeatures to construct a large network. This requires large amounts of memory\nfor storing both weights and feature maps. This is challenging for mobile and\nembedded devices since they may not have enough memory to perform inference\nwith the designed large network model. To close this gap, we propose MemNet, an\naugment-trim learning-based neural network search framework that optimizes not\nonly performance but also memory requirement. Specifically, it employs memory\nconsumption based ranking score which forces an upper bound on memory\nconsumption for navigating the search process. Experiment results show that, as\ncompared to the state-of-the-art efficient designing methods, MemNet can find\nan architecture which can achieve competitive accuracy and save an average of\n24.17% on the total memory needed.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jul 2019 20:49:53 GMT"}, {"version": "v2", "created": "Wed, 10 Jun 2020 20:12:57 GMT"}], "update_date": "2020-06-12", "authors_parsed": [["Liu", "Peiye", ""], ["Wu", "Bo", ""], ["Ma", "Huadong", ""], ["Seok", "Mingoo", ""]]}, {"id": "1907.09578", "submitter": "Andrey Zhmoginov", "authors": "Andrey Zhmoginov, Ian Fischer, Mark Sandler", "title": "Information-Bottleneck Approach to Salient Region Discovery", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new method for learning image attention masks in a\nsemi-supervised setting based on the Information Bottleneck principle. Provided\nwith a set of labeled images, the mask generation model is minimizing mutual\ninformation between the input and the masked image while maximizing the mutual\ninformation between the same masked image and the image label. In contrast with\nother approaches, our attention model produces a Boolean rather than a\ncontinuous mask, entirely concealing the information in masked-out pixels.\nUsing a set of synthetic datasets based on MNIST and CIFAR10 and the SVHN\ndatasets, we demonstrate that our method can successfully attend to features\nknown to define the image class.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jul 2019 21:13:30 GMT"}, {"version": "v2", "created": "Fri, 14 Feb 2020 22:14:54 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Zhmoginov", "Andrey", ""], ["Fischer", "Ian", ""], ["Sandler", "Mark", ""]]}, {"id": "1907.09588", "submitter": "Wenkai Xu", "authors": "Wenkai Xu, Gang Niu, Aapo Hyv\\\"arinen, Masashi Sugiyama", "title": "Direction Matters: On Influence-Preserving Graph Summarization and\n  Max-cut Principle for Directed Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Summarizing large-scaled directed graphs into small-scale representations is\na useful but less studied problem setting. Conventional clustering approaches,\nwhich based on \"Min-Cut\"-style criteria, compress both the vertices and edges\nof the graph into the communities, that lead to a loss of directed edge\ninformation. On the other hand, compressing the vertices while preserving the\ndirected edge information provides a way to learn the small-scale\nrepresentation of a directed graph. The reconstruction error, which measures\nthe edge information preserved by the summarized graph, can be used to learn\nsuch representation. Compared to the original graphs, the summarized graphs are\neasier to analyze and are capable of extracting group-level features which is\nuseful for efficient interventions of population behavior. In this paper, we\npresent a model, based on minimizing reconstruction error with non-negative\nconstraints, which relates to a \"Max-Cut\" criterion that simultaneously\nidentifies the compressed nodes and the directed compressed relations between\nthese nodes. A multiplicative update algorithm with column-wise normalization\nis proposed. We further provide theoretical results on the identifiability of\nthe model and on the convergence of the proposed algorithms. Experiments are\nconducted to demonstrate the accuracy and robustness of the proposed method.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jul 2019 21:34:47 GMT"}], "update_date": "2019-07-24", "authors_parsed": [["Xu", "Wenkai", ""], ["Niu", "Gang", ""], ["Hyv\u00e4rinen", "Aapo", ""], ["Sugiyama", "Masashi", ""]]}, {"id": "1907.09595", "submitter": "Mingxing Tan", "authors": "Mingxing Tan, Quoc V. Le", "title": "MixConv: Mixed Depthwise Convolutional Kernels", "comments": "BMVC 2019", "journal-ref": "BMVC 2019", "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Depthwise convolution is becoming increasingly popular in modern efficient\nConvNets, but its kernel size is often overlooked. In this paper, we\nsystematically study the impact of different kernel sizes, and observe that\ncombining the benefits of multiple kernel sizes can lead to better accuracy and\nefficiency. Based on this observation, we propose a new mixed depthwise\nconvolution (MixConv), which naturally mixes up multiple kernel sizes in a\nsingle convolution. As a simple drop-in replacement of vanilla depthwise\nconvolution, our MixConv improves the accuracy and efficiency for existing\nMobileNets on both ImageNet classification and COCO object detection. To\ndemonstrate the effectiveness of MixConv, we integrate it into AutoML search\nspace and develop a new family of models, named as MixNets, which outperform\nprevious mobile models including MobileNetV2 [20] (ImageNet top-1 accuracy\n+4.2%), ShuffleNetV2 [16] (+3.5%), MnasNet [26] (+1.3%), ProxylessNAS [2]\n(+2.2%), and FBNet [27] (+2.0%). In particular, our MixNet-L achieves a new\nstate-of-the-art 78.9% ImageNet top-1 accuracy under typical mobile settings\n(<600M FLOPS). Code is at https://github.com/\ntensorflow/tpu/tree/master/models/official/mnasnet/mixnet\n", "versions": [{"version": "v1", "created": "Mon, 22 Jul 2019 21:49:25 GMT"}, {"version": "v2", "created": "Thu, 1 Aug 2019 01:43:48 GMT"}, {"version": "v3", "created": "Sun, 1 Dec 2019 06:29:57 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Tan", "Mingxing", ""], ["Le", "Quoc V.", ""]]}, {"id": "1907.09597", "submitter": "Pablo Hernandez-Leal", "authors": "Pablo Hernandez-Leal, Bilal Kartal and Matthew E. Taylor", "title": "Agent Modeling as Auxiliary Task for Deep Reinforcement Learning", "comments": "AAAI Conference on Artificial Intelligence and Interactive Digital\n  Entertainment (AIIDE'19)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we explore how actor-critic methods in deep reinforcement\nlearning, in particular Asynchronous Advantage Actor-Critic (A3C), can be\nextended with agent modeling. Inspired by recent works on representation\nlearning and multiagent deep reinforcement learning, we propose two\narchitectures to perform agent modeling: the first one based on parameter\nsharing, and the second one based on agent policy features. Both architectures\naim to learn other agents' policies as auxiliary tasks, besides the standard\nactor (policy) and critic (values). We performed experiments in both\ncooperative and competitive domains. The former is a problem of coordinated\nmultiagent object transportation and the latter is a two-player mini version of\nthe Pommerman game. Our results show that the proposed architectures stabilize\nlearning and outperform the standard A3C architecture when learning a best\nresponse in terms of expected rewards.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jul 2019 21:54:44 GMT"}], "update_date": "2019-07-24", "authors_parsed": [["Hernandez-Leal", "Pablo", ""], ["Kartal", "Bilal", ""], ["Taylor", "Matthew E.", ""]]}, {"id": "1907.09600", "submitter": "Lorenzo A. Rossi", "authors": "Lorenzo A. Rossi, Chad Shawber, Janet Munu and Finly Zachariah", "title": "Evaluation of Embeddings of Laboratory Test Codes for Patients at a\n  Cancer Center", "comments": "2019 KDD Workshop on Applied Data Science for Healthcare (DSHealth,\n  August 2019, Anchorage, AK). Make sure you have downloaded the latest version\n  with the link to the DSHealth2019_loinc_embeddings GitHub repository:\n  https://github.com/elleros/DSHealth2019_loinc_embeddings", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.CY stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Laboratory test results are an important and generally high dimensional\ncomponent of a patient's Electronic Health Record (EHR). We train embedding\nrepresentations (via Word2Vec and GloVe) for LOINC codes of laboratory tests\nfrom the EHRs of about 80,000 patients at a cancer center. To include\ninformation about lab test outcomes, we also train embeddings on the\nconcatenation of a LOINC code with a symbol indicating normality or abnormality\nof the result. We observe several clinically meaningful similarities among\nLOINC embeddings trained over our data. For the embeddings of the concatenation\nof LOINCs with abnormality codes, we evaluate the performance for mortality\nprediction tasks and the ability to preserve ordinality properties: i.e. a lab\ntest with normal outcome should be more similar to an abnormal one than to the\na very abnormal one.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jul 2019 21:58:40 GMT"}, {"version": "v2", "created": "Thu, 1 Aug 2019 15:29:44 GMT"}], "update_date": "2019-08-02", "authors_parsed": [["Rossi", "Lorenzo A.", ""], ["Shawber", "Chad", ""], ["Munu", "Janet", ""], ["Zachariah", "Finly", ""]]}, {"id": "1907.09605", "submitter": "Harbir Antil", "authors": "Harbir Antil, Zichao Di, Ratna Khatri", "title": "Bilevel Optimization, Deep Learning and Fractional Laplacian\n  Regularization with Applications in Tomography", "comments": null, "journal-ref": null, "doi": "10.1088/1361-6420/ab80d7", "report-no": null, "categories": "eess.IV cs.LG cs.NA math.NA math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we consider a generalized bilevel optimization framework for\nsolving inverse problems. We introduce fractional Laplacian as a regularizer to\nimprove the reconstruction quality, and compare it with the total variation\nregularization. We emphasize that the key advantage of using fractional\nLaplacian as a regularizer is that it leads to a linear operator, as opposed to\nthe total variation regularization which results in a nonlinear degenerate\noperator. Inspired by residual neural networks, to learn the optimal strength\nof regularization and the exponent of fractional Laplacian, we develop a\ndedicated bilevel optimization neural network with a variable depth for a\ngeneral regularized inverse problem. We also draw some parallels between an\nactivation function in a neural network and regularization. We illustrate how\nto incorporate various regularizer choices into our proposed network. As an\nexample, we consider tomographic reconstruction as a model problem and show an\nimprovement in reconstruction quality, especially for limited data, via\nfractional Laplacian regularization. We successfully learn the regularization\nstrength and the fractional exponent via our proposed bilevel optimization\nneural network. We observe that the fractional Laplacian regularization\noutperforms total variation regularization. This is specially encouraging, and\nimportant, in the case of limited and noisy data.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jul 2019 22:08:40 GMT"}], "update_date": "2020-06-24", "authors_parsed": [["Antil", "Harbir", ""], ["Di", "Zichao", ""], ["Khatri", "Ratna", ""]]}, {"id": "1907.09607", "submitter": "Prashnna Gyawali", "authors": "Prashnna Kumar Gyawali, Zhiyuan Li, Sandesh Ghimire and Linwei Wang", "title": "Semi-Supervised Learning by Disentangling and Self-Ensembling Over\n  Stochastic Latent Space", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The success of deep learning in medical imaging is mostly achieved at the\ncost of a large labeled data set. Semi-supervised learning (SSL) provides a\npromising solution by leveraging the structure of unlabeled data to improve\nlearning from a small set of labeled data. Self-ensembling is a simple approach\nused in SSL to encourage consensus among ensemble predictions of unknown\nlabels, improving generalization of the model by making it more insensitive to\nthe latent space. Currently, such an ensemble is obtained by randomization such\nas dropout regularization and random data augmentation. In this work, we\nhypothesize -- from the generalization perspective -- that self-ensembling can\nbe improved by exploiting the stochasticity of a disentangled latent space. To\nthis end, we present a stacked SSL model that utilizes unsupervised\ndisentangled representation learning as the stochastic embedding for\nself-ensembling. We evaluate the presented model for multi-label classification\nusing chest X-ray images, demonstrating its improved performance over related\nSSL models as well as the interpretability of its disentangled representations.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jul 2019 22:19:04 GMT"}], "update_date": "2019-07-24", "authors_parsed": [["Gyawali", "Prashnna Kumar", ""], ["Li", "Zhiyuan", ""], ["Ghimire", "Sandesh", ""], ["Wang", "Linwei", ""]]}, {"id": "1907.09613", "submitter": "Alessandro Lameiras Koerich", "authors": "Alexandre Reeberg de Mello and Marcelo Ricardo Stemmer and Alessandro\n  Lameiras Koerich", "title": "Incremental and Decremental Fuzzy Bounded Twin Support Vector Machine", "comments": "23 pages", "journal-ref": "Information Sciences, 2020", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present an incremental variant of the Twin Support Vector\nMachine (TWSVM) called Fuzzy Bounded Twin Support Vector Machine (FBTWSVM) to\ndeal with large datasets and learning from data streams. We combine the TWSVM\nwith a fuzzy membership function, so that each input has a different\ncontribution to each hyperplane in a binary classifier. To solve the pair of\nquadratic programming problems (QPPs) we use a dual coordinate descent\nalgorithm with a shrinking strategy, and to obtain a robust classification with\na fast training we propose the use of a Fourier Gaussian approximation function\nwith our linear FBTWSVM. Inspired by the shrinking technique, the incremental\nalgorithm re-utilizes part of the training method with some heuristics, while\nthe decremental procedure is based on a scored window. The FBTWSVM is also\nextended for multi-class problems by combining binary classifiers using a\nDirected Acyclic Graph (DAG) approach. Moreover, we analyzed the theoretical\nfoundations properties of the proposed approach and its extension, and the\nexperimental results on benchmark datasets indicate that the FBTWSVM has a fast\ntraining and retraining process while maintaining a robust classification\nperformance.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jul 2019 22:32:36 GMT"}, {"version": "v2", "created": "Mon, 23 Mar 2020 11:28:19 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["de Mello", "Alexandre Reeberg", ""], ["Stemmer", "Marcelo Ricardo", ""], ["Koerich", "Alessandro Lameiras", ""]]}, {"id": "1907.09615", "submitter": "Shalmali Joshi", "authors": "Shalmali Joshi, Oluwasanmi Koyejo, Warut Vijitbenjaronk, Been Kim,\n  Joydeep Ghosh", "title": "Towards Realistic Individual Recourse and Actionable Explanations in\n  Black-Box Decision Making Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning based decision making systems are increasingly affecting\nhumans. An individual can suffer an undesirable outcome under such decision\nmaking systems (e.g. denied credit) irrespective of whether the decision is\nfair or accurate. Individual recourse pertains to the problem of providing an\nactionable set of changes a person can undertake in order to improve their\noutcome. We propose a recourse algorithm that models the underlying data\ndistribution or manifold. We then provide a mechanism to generate the smallest\nset of changes that will improve an individual's outcome. This mechanism can be\neasily used to provide recourse for any differentiable machine learning based\ndecision making system. Further, the resulting algorithm is shown to be\napplicable to both supervised classification and causal decision making\nsystems. Our work attempts to fill gaps in existing fairness literature that\nhave primarily focused on discovering and/or algorithmically enforcing fairness\nconstraints on decision making systems. This work also provides an alternative\napproach to generating counterfactual explanations.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jul 2019 22:35:51 GMT"}], "update_date": "2019-07-24", "authors_parsed": [["Joshi", "Shalmali", ""], ["Koyejo", "Oluwasanmi", ""], ["Vijitbenjaronk", "Warut", ""], ["Kim", "Been", ""], ["Ghosh", "Joydeep", ""]]}, {"id": "1907.09620", "submitter": "Kelsey Allen", "authors": "Kelsey R. Allen, Kevin A. Smith, Joshua B. Tenenbaum", "title": "Rapid trial-and-error learning with simulation supports flexible tool\n  use and physical reasoning", "comments": "This manuscript is in press at PNAS. It is an extended version of a\n  paper \"Rapid Trial-and-Error Learning in Physical Problem Solving\" accepted\n  for oral presentation at the 41st Annual Meeting of the Cognitive Science\n  Society (2019). It represents ongoing work on the part of the authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many animals, and an increasing number of artificial agents, display\nsophisticated capabilities to perceive and manipulate objects. But human beings\nremain distinctive in their capacity for flexible, creative tool use -- using\nobjects in new ways to act on the world, achieve a goal, or solve a problem. To\nstudy this type of general physical problem solving, we introduce the Virtual\nTools game. In this game, people solve a large range of challenging physical\npuzzles in just a handful of attempts. We propose that the flexibility of human\nphysical problem solving rests on an ability to imagine the effects of\nhypothesized actions, while the efficiency of human search arises from rich\naction priors which are updated via observations of the world. We instantiate\nthese components in the \"Sample, Simulate, Update\" (SSUP) model and show that\nit captures human performance across 30 levels of the Virtual Tools game. More\nbroadly, this model provides a mechanism for explaining how people condense\ngeneral physical knowledge into actionable, task-specific plans to achieve\nflexible and efficient physical problem-solving.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jul 2019 22:49:27 GMT"}, {"version": "v2", "created": "Thu, 25 Jul 2019 18:15:30 GMT"}, {"version": "v3", "created": "Mon, 29 Jun 2020 17:05:56 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Allen", "Kelsey R.", ""], ["Smith", "Kevin A.", ""], ["Tenenbaum", "Joshua B.", ""]]}, {"id": "1907.09623", "submitter": "Yi Su", "authors": "Yi Su, Maria Dimakopoulou, Akshay Krishnamurthy, Miroslav Dud\\'ik", "title": "Doubly robust off-policy evaluation with shrinkage", "comments": null, "journal-ref": "International Conference on Machine Learning (2020)", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new framework for designing estimators for off-policy evaluation\nin contextual bandits. Our approach is based on the asymptotically optimal\ndoubly robust estimator, but we shrink the importance weights to minimize a\nbound on the mean squared error, which results in a better bias-variance\ntradeoff in finite samples. We use this optimization-based framework to obtain\nthree estimators: (a) a weight-clipping estimator, (b) a new weight-shrinkage\nestimator, and (c) the first shrinkage-based estimator for combinatorial action\nsets. Extensive experiments in both standard and combinatorial bandit benchmark\nproblems show that our estimators are highly adaptive and typically outperform\nstate-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jul 2019 22:55:31 GMT"}, {"version": "v2", "created": "Fri, 18 Sep 2020 20:53:19 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Su", "Yi", ""], ["Dimakopoulou", "Maria", ""], ["Krishnamurthy", "Akshay", ""], ["Dud\u00edk", "Miroslav", ""]]}, {"id": "1907.09643", "submitter": "Oceangroup Ouc", "authors": "Haoran Zhao, Xin Sun, Junyu Dong, Changrui Chen and Zihe Dong", "title": "Highlight Every Step: Knowledge Distillation via Collaborative Teaching", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  High storage and computational costs obstruct deep neural networks to be\ndeployed on resource-constrained devices. Knowledge distillation aims to train\na compact student network by transferring knowledge from a larger pre-trained\nteacher model. However, most existing methods on knowledge distillation ignore\nthe valuable information among training process associated with training\nresults. In this paper, we provide a new Collaborative Teaching Knowledge\nDistillation (CTKD) strategy which employs two special teachers. Specifically,\none teacher trained from scratch (i.e., scratch teacher) assists the student\nstep by step using its temporary outputs. It forces the student to approach the\noptimal path towards the final logits with high accuracy. The other pre-trained\nteacher (i.e., expert teacher) guides the student to focus on a critical region\nwhich is more useful for the task. The combination of the knowledge from two\nspecial teachers can significantly improve the performance of the student\nnetwork in knowledge distillation. The results of experiments on CIFAR-10,\nCIFAR-100, SVHN and Tiny ImageNet datasets verify that the proposed knowledge\ndistillation method is efficient and achieves state-of-the-art performance.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jul 2019 01:02:39 GMT"}], "update_date": "2019-07-24", "authors_parsed": [["Zhao", "Haoran", ""], ["Sun", "Xin", ""], ["Dong", "Junyu", ""], ["Chen", "Changrui", ""], ["Dong", "Zihe", ""]]}, {"id": "1907.09648", "submitter": "Usman Khan", "authors": "Ran Xin and Soummya Kar and Usman A. Khan", "title": "An introduction to decentralized stochastic optimization with gradient\n  tracking", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SY math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decentralized solutions to finite-sum minimization are of significant\nimportance in many signal processing, control, and machine learning\napplications. In such settings, the data is distributed over a network of\narbitrarily-connected nodes and raw data sharing is prohibitive often due to\ncommunication or privacy constraints. In this article, we review decentralized\nstochastic first-order optimization methods and illustrate some recent\nimprovements based on gradient tracking and variance reduction, focusing\nparticularly on smooth and strongly-convex objective functions. We provide\nintuitive illustrations of the main technical ideas as well as applications of\nthe algorithms in the context of decentralized training of machine learning\nmodels.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jul 2019 01:36:41 GMT"}, {"version": "v2", "created": "Tue, 12 Nov 2019 22:15:02 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["Xin", "Ran", ""], ["Kar", "Soummya", ""], ["Khan", "Usman A.", ""]]}, {"id": "1907.09652", "submitter": "Li He", "authors": "Li He, Long Xia, Wei Zeng, Zhi-Ming Ma, Yihong Zhao, and Dawei Yin", "title": "Off-policy Learning for Multiple Loggers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is well known that the historical logs are used for evaluating and\nlearning policies in interactive systems, e.g. recommendation, search, and\nonline advertising. Since direct online policy learning usually harms user\nexperiences, it is more crucial to apply off-policy learning in real-world\napplications instead. Though there have been some existing works, most are\nfocusing on learning with one single historical policy. However, in practice,\nusually a number of parallel experiments, e.g. multiple AB tests, are performed\nsimultaneously. To make full use of such historical data, learning policies\nfrom multiple loggers becomes necessary. Motivated by this, in this paper, we\ninvestigate off-policy learning when the training data coming from multiple\nhistorical policies. Specifically, policies, e.g. neural networks, can be\nlearned directly from multi-logger data, with counterfactual estimators. In\norder to understand the generalization ability of such estimator better, we\nconduct generalization error analysis for the empirical risk minimization\nproblem. We then introduce the generalization error bound as the new risk\nfunction, which can be reduced to a constrained optimization problem. Finally,\nwe give the corresponding learning algorithm for the new constrained problem,\nwhere we can appeal to the minimax problems to control the constraints.\nExtensive experiments on benchmark datasets demonstrate that the proposed\nmethods achieve better performances than the state-of-the-arts.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jul 2019 01:52:34 GMT"}, {"version": "v2", "created": "Mon, 5 Aug 2019 08:47:53 GMT"}], "update_date": "2019-08-06", "authors_parsed": [["He", "Li", ""], ["Xia", "Long", ""], ["Zeng", "Wei", ""], ["Ma", "Zhi-Ming", ""], ["Zhao", "Yihong", ""], ["Yin", "Dawei", ""]]}, {"id": "1907.09671", "submitter": "David Gaddy", "authors": "David Gaddy and Dan Klein", "title": "Pre-Learning Environment Representations for Data-Efficient Neural\n  Instruction Following", "comments": "ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of learning to map from natural language instructions\nto state transitions (actions) in a data-efficient manner. Our method takes\ninspiration from the idea that it should be easier to ground language to\nconcepts that have already been formed through pre-linguistic observation. We\naugment a baseline instruction-following learner with an initial\nenvironment-learning phase that uses observations of language-free state\ntransitions to induce a suitable latent representation of actions before\nprocessing the instruction-following training data. We show that mapping to\npre-learned representations substantially improves performance over systems\nwhose representations are learned from limited instructional data alone.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jul 2019 03:11:07 GMT"}], "update_date": "2019-07-24", "authors_parsed": [["Gaddy", "David", ""], ["Klein", "Dan", ""]]}, {"id": "1907.09692", "submitter": "Boyuan Pan", "authors": "Boyuan Pan, Yazheng Yang, Zhou Zhao, Yueting Zhuang, Deng Cai, Xiaofei\n  He", "title": "Discourse Marker Augmented Network with Reinforcement Learning for\n  Natural Language Inference", "comments": "Accepted in ACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Natural Language Inference (NLI), also known as Recognizing Textual\nEntailment (RTE), is one of the most important problems in natural language\nprocessing. It requires to infer the logical relationship between two given\nsentences. While current approaches mostly focus on the interaction\narchitectures of the sentences, in this paper, we propose to transfer knowledge\nfrom some important discourse markers to augment the quality of the NLI model.\nWe observe that people usually use some discourse markers such as \"so\" or \"but\"\nto represent the logical relationship between two sentences. These words\npotentially have deep connections with the meanings of the sentences, thus can\nbe utilized to help improve the representations of them. Moreover, we use\nreinforcement learning to optimize a new objective function with a reward\ndefined by the property of the NLI datasets to make full use of the labels\ninformation. Experiments show that our method achieves the state-of-the-art\nperformance on several large-scale datasets.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jul 2019 04:27:57 GMT"}], "update_date": "2019-07-24", "authors_parsed": [["Pan", "Boyuan", ""], ["Yang", "Yazheng", ""], ["Zhao", "Zhou", ""], ["Zhuang", "Yueting", ""], ["Cai", "Deng", ""], ["He", "Xiaofei", ""]]}, {"id": "1907.09693", "submitter": "Qinbin Li", "authors": "Qinbin Li, Zeyi Wen, Zhaomin Wu, Sixu Hu, Naibo Wang, Yuan Li, Xu Liu,\n  Bingsheng He", "title": "A Survey on Federated Learning Systems: Vision, Hype and Reality for\n  Data Privacy and Protection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.DB stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning has been a hot research topic in enabling the\ncollaborative training of machine learning models among different organizations\nunder the privacy restrictions. As researchers try to support more machine\nlearning models with different privacy-preserving approaches, there is a\nrequirement in developing systems and infrastructures to ease the development\nof various federated learning algorithms. Similar to deep learning systems such\nas PyTorch and TensorFlow that boost the development of deep learning,\nfederated learning systems (FLSs) are equivalently important, and face\nchallenges from various aspects such as effectiveness, efficiency, and privacy.\nIn this survey, we conduct a comprehensive review on federated learning\nsystems. To achieve smooth flow and guide future research, we introduce the\ndefinition of federated learning systems and analyze the system components.\nMoreover, we provide a thorough categorization for federated learning systems\naccording to six different aspects, including data distribution, machine\nlearning model, privacy mechanism, communication architecture, scale of\nfederation and motivation of federation. The categorization can help the design\nof federated learning systems as shown in our case studies. By systematically\nsummarizing the existing federated learning systems, we present the design\nfactors, case studies, and future research opportunities.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jul 2019 04:30:50 GMT"}, {"version": "v2", "created": "Mon, 14 Oct 2019 08:06:54 GMT"}, {"version": "v3", "created": "Tue, 3 Dec 2019 13:34:19 GMT"}, {"version": "v4", "created": "Wed, 1 Apr 2020 13:33:21 GMT"}, {"version": "v5", "created": "Wed, 13 Jan 2021 11:30:07 GMT"}, {"version": "v6", "created": "Thu, 1 Jul 2021 04:04:38 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Li", "Qinbin", ""], ["Wen", "Zeyi", ""], ["Wu", "Zhaomin", ""], ["Hu", "Sixu", ""], ["Wang", "Naibo", ""], ["Li", "Yuan", ""], ["Liu", "Xu", ""], ["He", "Bingsheng", ""]]}, {"id": "1907.09696", "submitter": "Yeonjong Shin", "authors": "Yeonjong Shin, George Em Karniadakis", "title": "Trainability of ReLU networks and Data-dependent Initialization", "comments": null, "journal-ref": null, "doi": "10.1615/.2020034126", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In this paper, we study the trainability of rectified linear unit (ReLU)\nnetworks. A ReLU neuron is said to be dead if it only outputs a constant for\nany input. Two death states of neurons are introduced; tentative and permanent\ndeath. A network is then said to be trainable if the number of permanently dead\nneurons is sufficiently small for a learning task. We refer to the probability\nof a network being trainable as trainability. We show that a network being\ntrainable is a necessary condition for successful training and the trainability\nserves as an upper bound of successful training rates. In order to quantify the\ntrainability, we study the probability distribution of the number of active\nneurons at the initialization. In many applications, over-specified or\nover-parameterized neural networks are successfully employed and shown to be\ntrained effectively. With the notion of trainability, we show that\nover-parameterization is both a necessary and a sufficient condition for\nminimizing the training loss. Furthermore, we propose a data-dependent\ninitialization method in the over-parameterized setting. Numerical examples are\nprovided to demonstrate the effectiveness of the method and our theoretical\nfindings.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jul 2019 05:11:32 GMT"}, {"version": "v2", "created": "Tue, 31 Mar 2020 04:25:31 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Shin", "Yeonjong", ""], ["Karniadakis", "George Em", ""]]}, {"id": "1907.09697", "submitter": "Tao Sun", "authors": "Tao Sun, Dongsheng Li, Zhe Quan, Hao Jiang, Shengguo Li, Yong Dou", "title": "Heavy-ball Algorithms Always Escape Saddle Points", "comments": "IJCAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nonconvex optimization algorithms with random initialization have attracted\nincreasing attention recently. It has been showed that many first-order methods\nalways avoid saddle points with random starting points. In this paper, we\nanswer a question: can the nonconvex heavy-ball algorithms with random\ninitialization avoid saddle points? The answer is yes! Direct using the\nexisting proof technique for the heavy-ball algorithms is hard due to that each\niteration of the heavy-ball algorithm consists of current and last points. It\nis impossible to formulate the algorithms as iteration like xk+1= g(xk) under\nsome mapping g. To this end, we design a new mapping on a new space. With some\ntransfers, the heavy-ball algorithm can be interpreted as iterations after this\nmapping. Theoretically, we prove that heavy-ball gradient descent enjoys larger\nstepsize than the gradient descent to escape saddle points to escape the saddle\npoint. And the heavy-ball proximal point algorithm is also considered; we also\nproved that the algorithm can always escape the saddle point.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jul 2019 05:15:55 GMT"}], "update_date": "2019-07-24", "authors_parsed": [["Sun", "Tao", ""], ["Li", "Dongsheng", ""], ["Quan", "Zhe", ""], ["Jiang", "Hao", ""], ["Li", "Shengguo", ""], ["Dou", "Yong", ""]]}, {"id": "1907.09701", "submitter": "Mengjiao Yang", "authors": "Mengjiao Yang, Been Kim", "title": "Benchmarking Attribution Methods with Relative Feature Importance", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interpretability is an important area of research for safe deployment of\nmachine learning systems. One particular type of interpretability method\nattributes model decisions to input features. Despite active development,\nquantitative evaluation of feature attribution methods remains difficult due to\nthe lack of ground truth: we do not know which input features are in fact\nimportant to a model. In this work, we propose a framework for Benchmarking\nAttribution Methods (BAM) with a priori knowledge of relative feature\nimportance. BAM includes 1) a carefully crafted dataset and models trained with\nknown relative feature importance and 2) three complementary metrics to\nquantitatively evaluate attribution methods by comparing feature attributions\nbetween pairs of models and pairs of inputs. Our evaluation on several\nwidely-used attribution methods suggests that certain methods are more likely\nto produce false positive explanations---features that are incorrectly\nattributed as more important to model prediction. We open source our dataset,\nmodels, and metrics.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jul 2019 05:50:14 GMT"}, {"version": "v2", "created": "Mon, 4 Nov 2019 20:50:25 GMT"}], "update_date": "2019-11-06", "authors_parsed": [["Yang", "Mengjiao", ""], ["Kim", "Been", ""]]}, {"id": "1907.09705", "submitter": "Zhaoyi Wan", "authors": "Zhaoyi Wan, Fengming Xie, Yibo Liu, Xiang Bai, Cong Yao", "title": "2D-CTC for Scene Text Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Scene text recognition has been an important, active research topic in\ncomputer vision for years. Previous approaches mainly consider text as 1D\nsignals and cast scene text recognition as a sequence prediction problem, by\nfeat of CTC or attention based encoder-decoder framework, which is originally\ndesigned for speech recognition. However, different from speech voices, which\nare 1D signals, text instances are essentially distributed in 2D image spaces.\nTo adhere to and make use of the 2D nature of text for higher recognition\naccuracy, we extend the vanilla CTC model to a second dimension, thus creating\n2D-CTC. 2D-CTC can adaptively concentrate on most relevant features while\nexcluding the impact from clutters and noises in the background; It can also\nnaturally handle text instances with various forms (horizontal, oriented and\ncurved) while giving more interpretable intermediate predictions. The\nexperiments on standard benchmarks for scene text recognition, such as IIIT-5K,\nICDAR 2015, SVP-Perspective, and CUTE80, demonstrate that the proposed 2D-CTC\nmodel outperforms state-of-the-art methods on the text of both regular and\nirregular shapes. Moreover, 2D-CTC exhibits its superiority over prior art on\ntraining and testing speed. Our implementation and models of 2D-CTC will be\nmade publicly available soon later.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jul 2019 05:55:28 GMT"}], "update_date": "2019-07-24", "authors_parsed": [["Wan", "Zhaoyi", ""], ["Xie", "Fengming", ""], ["Liu", "Yibo", ""], ["Bai", "Xiang", ""], ["Yao", "Cong", ""]]}, {"id": "1907.09706", "submitter": "Heon Lee", "authors": "Samuel Yu, Heon Lee, John Kim", "title": "LYTNet: A Convolutional Neural Network for Real-Time Pedestrian Traffic\n  Lights and Zebra Crossing Recognition for the Visually Impaired", "comments": "12 pages, 5 figures, 6 tables, International Conference on Computer\n  Analysis of Images and Patterns (CAIP)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Currently, the visually impaired rely on either a sighted human, guide dog,\nor white cane to safely navigate. However, the training of guide dogs is\nextremely expensive, and canes cannot provide essential information regarding\nthe color of traffic lights and direction of crosswalks. In this paper, we\npropose a deep learning based solution that provides information regarding the\ntraffic light mode and the position of the zebra crossing. Previous solutions\nthat utilize machine learning only provide one piece of information and are\nmostly binary: only detecting red or green lights. The proposed convolutional\nneural network, LYTNet, is designed for comprehensiveness, accuracy, and\ncomputational efficiency. LYTNet delivers both of the two most important pieces\nof information for the visually impaired to cross the road. We provide five\nclasses of pedestrian traffic lights rather than the commonly seen three or\nfour, and a direction vector representing the midline of the zebra crossing\nthat is converted from the 2D image plane to real-world positions. We created\nour own dataset of pedestrian traffic lights containing over 5000 photos taken\nat hundreds of intersections in Shanghai. The experiments carried out achieve a\nclassification accuracy of 94%, average angle error of 6.35 degrees, with a\nframe rate of 20 frames per second when testing the network on an iPhone 7 with\nadditional post-processing steps.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jul 2019 05:56:43 GMT"}], "update_date": "2019-07-25", "authors_parsed": [["Yu", "Samuel", ""], ["Lee", "Heon", ""], ["Kim", "John", ""]]}, {"id": "1907.09708", "submitter": "Huangjie Zheng", "authors": "Xu Chen, Siheng Chen, Huangjie Zheng, Jiangchao Yao, Kenan Cui, Ya\n  Zhang, Ivor W. Tsang", "title": "Node Attribute Generation on Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph structured data provide two-fold information: graph structures and node\nattributes. Numerous graph-based algorithms rely on both information to achieve\nsuccess in supervised tasks, such as node classification and link prediction.\nHowever, node attributes could be missing or incomplete, which significantly\ndeteriorates the performance. The task of node attribute generation aims to\ngenerate attributes for those nodes whose attributes are completely unobserved.\nThis task benefits many real-world problems like profiling, node classification\nand graph data augmentation. To tackle this task, we propose a deep adversarial\nlearning based method to generate node attributes; called node attribute neural\ngenerator (NANG). NANG learns a unifying latent representation which is shared\nby both node attributes and graph structures and can be translated to different\nmodalities. We thus use this latent representation as a bridge to convert\ninformation from one modality to another. We further introduce practical\napplications to quantify the performance of node attribute generation.\nExtensive experiments are conducted on four real-world datasets and the\nempirical results show that node attributes generated by the proposed method\nare high-qualitative and beneficial to other applications. The datasets and\ncodes are available online.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jul 2019 06:02:45 GMT"}], "update_date": "2019-07-24", "authors_parsed": [["Chen", "Xu", ""], ["Chen", "Siheng", ""], ["Zheng", "Huangjie", ""], ["Yao", "Jiangchao", ""], ["Cui", "Kenan", ""], ["Zhang", "Ya", ""], ["Tsang", "Ivor W.", ""]]}, {"id": "1907.09720", "submitter": "Tsendsuren Munkhdalai", "authors": "Tsendsuren Munkhdalai, Alessandro Sordoni, Tong Wang and Adam\n  Trischler", "title": "Metalearned Neural Memory", "comments": "NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We augment recurrent neural networks with an external memory mechanism that\nbuilds upon recent progress in metalearning. We conceptualize this memory as a\nrapidly adaptable function that we parameterize as a deep neural network.\nReading from the neural memory function amounts to pushing an input (the key\nvector) through the function to produce an output (the value vector). Writing\nto memory means changing the function; specifically, updating the parameters of\nthe neural network to encode desired information. We leverage training and\nalgorithmic techniques from metalearning to update the neural memory function\nin one shot. The proposed memory-augmented model achieves strong performance on\na variety of learning problems, from supervised question answering to\nreinforcement learning.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jul 2019 07:04:07 GMT"}, {"version": "v2", "created": "Tue, 3 Dec 2019 14:16:23 GMT"}], "update_date": "2019-12-04", "authors_parsed": [["Munkhdalai", "Tsendsuren", ""], ["Sordoni", "Alessandro", ""], ["Wang", "Tong", ""], ["Trischler", "Adam", ""]]}, {"id": "1907.09725", "submitter": "Takeshi Ise", "authors": "Takeshi Ise and Yurika Oba", "title": "VARENN: Graphical representation of spatiotemporal data and application\n  to climate studies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG physics.ao-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Analyzing and utilizing spatiotemporal big data are essential for studies\nconcerning climate change. However, such data are not fully integrated into\nclimate models owing to limitations in statistical frameworks. Herein, we\nemploy VARENN (visually augmented representation of environment for neural\nnetworks) to efficiently summarize monthly observations of climate data for\n1901-2016 into 2-dimensional graphical images. Using red, green, and blue\nchannels of color images, three different variables are simultaneously\nrepresented in a single image. For global datasets, models were trained via\nconvolutional neural networks. These models successfully classified rises and\nfalls in temperature and precipitation. Moreover, similarities between the\ninput and target variables were observed to have a significant effect on model\naccuracy. The input variables had both seasonal and interannual variations,\nwhose importance was quantified for model efficacy. VARENN is thus an effective\nmethod to summarize spatiotemporal data objectively and accurately.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jul 2019 07:23:01 GMT"}], "update_date": "2019-07-24", "authors_parsed": [["Ise", "Takeshi", ""], ["Oba", "Yurika", ""]]}, {"id": "1907.09728", "submitter": "Yao Ming", "authors": "Yao Ming and Panpan Xu and Huamin Qu and Liu Ren", "title": "Interpretable and Steerable Sequence Learning via Prototypes", "comments": "Accepted as a full paper at KDD 2019 on May 8, 2019", "journal-ref": "Proceedings of the 25th ACM SIGKDD International Conference on\n  Knowledge Discovery & Data Mining, KDD 2019", "doi": "10.1145/3292500.3330908", "report-no": null, "categories": "cs.LG cs.HC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the major challenges in machine learning nowadays is to provide\npredictions with not only high accuracy but also user-friendly explanations.\nAlthough in recent years we have witnessed increasingly popular use of deep\nneural networks for sequence modeling, it is still challenging to explain the\nrationales behind the model outputs, which is essential for building trust and\nsupporting the domain experts to validate, critique and refine the model. We\npropose ProSeNet, an interpretable and steerable deep sequence model with\nnatural explanations derived from case-based reasoning. The prediction is\nobtained by comparing the inputs to a few prototypes, which are exemplar cases\nin the problem domain. For better interpretability, we define several criteria\nfor constructing the prototypes, including simplicity, diversity, and sparsity\nand propose the learning objective and the optimization procedure. ProSeNet\nalso provides a user-friendly approach to model steering: domain experts\nwithout any knowledge on the underlying model or parameters can easily\nincorporate their intuition and experience by manually refining the prototypes.\nWe conduct experiments on a wide range of real-world applications, including\npredictive diagnostics for automobiles, ECG, and protein sequence\nclassification and sentiment analysis on texts. The result shows that ProSeNet\ncan achieve accuracy on par with state-of-the-art deep learning models. We also\nevaluate the interpretability of the results with concrete case studies.\nFinally, through user study on Amazon Mechanical Turk (MTurk), we demonstrate\nthat the model selects high-quality prototypes which align well with human\nknowledge and can be interactively refined for better interpretability without\nloss of performance.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jul 2019 07:28:28 GMT"}], "update_date": "2019-07-24", "authors_parsed": [["Ming", "Yao", ""], ["Xu", "Panpan", ""], ["Qu", "Huamin", ""], ["Ren", "Liu", ""]]}, {"id": "1907.09748", "submitter": "Yaxiong Wang", "authors": "Yaxiong Wang, Hao Yang, Xueming Qian, Lin Ma, Jing Lu, Biao Li and Xin\n  Fan", "title": "Position Focused Attention Network for Image-Text Matching", "comments": "Accepted by IJCAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Image-text matching tasks have recently attracted a lot of attention in the\ncomputer vision field. The key point of this cross-domain problem is how to\naccurately measure the similarity between the visual and the textual contents,\nwhich demands a fine understanding of both modalities. In this paper, we\npropose a novel position focused attention network (PFAN) to investigate the\nrelation between the visual and the textual views. In this work, we integrate\nthe object position clue to enhance the visual-text joint-embedding learning.\nWe first split the images into blocks, by which we infer the relative position\nof region in the image. Then, an attention mechanism is proposed to model the\nrelations between the image region and blocks and generate the valuable\nposition feature, which will be further utilized to enhance the region\nexpression and model a more reliable relationship between the visual image and\nthe textual sentence. Experiments on the popular datasets Flickr30K and MS-COCO\nshow the effectiveness of the proposed method. Besides the public datasets, we\nalso conduct experiments on our collected practical large-scale news dataset\n(Tencent-News) to validate the practical application value of proposed method.\nAs far as we know, this is the first attempt to test the performance on the\npractical application. Our method achieves the state-of-art performance on all\nof these three datasets.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jul 2019 08:23:42 GMT"}], "update_date": "2019-07-24", "authors_parsed": [["Wang", "Yaxiong", ""], ["Yang", "Hao", ""], ["Qian", "Xueming", ""], ["Ma", "Lin", ""], ["Lu", "Jing", ""], ["Li", "Biao", ""], ["Fan", "Xin", ""]]}, {"id": "1907.09750", "submitter": "Junghee Cho", "authors": "Junghee Cho, Junseok Kwon, Byung-Woo Hong", "title": "Adaptive Regularization via Residual Smoothing in Deep Learning\n  Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an adaptive regularization algorithm that can be effectively\napplied to the optimization problem in deep learning framework. Our\nregularization algorithm aims to take into account the fitness of data to the\ncurrent state of model in the determination of regularity to achieve better\ngeneralization. The degree of regularization at each element in the target\nspace of the neural network architecture is determined based on the residual at\neach optimization iteration in an adaptive way. Our adaptive regularization\nalgorithm is designed to apply a diffusion process driven by the heat equation\nwith spatially varying diffusivity depending on the probability density\nfunction following a certain distribution of residual. Our data-driven\nregularity is imposed by adaptively smoothing a simplified objective function\nin which the explicit regularization term is omitted in an alternating manner\nbetween the evaluation of residual and the determination of the degree of its\nregularity. The effectiveness of our algorithm is empirically demonstrated by\nthe numerical experiments in the application of image classification problems,\nindicating that our algorithm outperforms other commonly used optimization\nalgorithms in terms of generalization using popular deep learning models and\nbenchmark datasets.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jul 2019 08:28:09 GMT"}, {"version": "v2", "created": "Fri, 30 Aug 2019 14:27:37 GMT"}], "update_date": "2019-09-02", "authors_parsed": [["Cho", "Junghee", ""], ["Kwon", "Junseok", ""], ["Hong", "Byung-Woo", ""]]}, {"id": "1907.09764", "submitter": "Nishchal Dwivedi", "authors": "Nishchal R. Dwivedi", "title": "Trees and Islands -- Machine learning approach to nuclear physics", "comments": "8 Figures, 2 Tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "nucl-th cs.LG nucl-ex stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We implement machine learning algorithms to nuclear data. These algorithms\nare purely data driven and generate models that are capable to capture\nintricate trends. Gradient boosted trees algorithm is employed to generate a\ntrained model from existing nuclear data, which is used for prediction for data\nof damping parameter, shell correction energies, quadrupole deformation,\npairing gaps, level densities and giant dipole resonance for large number of\nnuclei. We, in particular, predict level density parameter for superheavy\nelements which is of great current interest. The predictions made by the\nmachine learning algorithm is found to have standard deviation from 0.00035 to\n0.73.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jul 2019 08:54:01 GMT"}], "update_date": "2019-07-24", "authors_parsed": [["Dwivedi", "Nishchal R.", ""]]}, {"id": "1907.09765", "submitter": "Eric Benhamou", "authors": "Eric Benhamou", "title": "Variance Reduction in Actor Critic Methods (ACM)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  After presenting Actor Critic Methods (ACM), we show ACM are control variate\nestimators. Using the projection theorem, we prove that the Q and Advantage\nActor Critic (A2C) methods are optimal in the sense of the $L^2$ norm for the\ncontrol variate estimators spanned by functions conditioned by the current\nstate and action. This straightforward application of Pythagoras theorem\nprovides a theoretical justification of the strong performance of QAC and AAC\nmost often referred to as A2C methods in deep policy gradient methods. This\nenables us to derive a new formulation for Advantage Actor Critic methods that\nhas lower variance and improves the traditional A2C method.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jul 2019 08:56:08 GMT"}], "update_date": "2019-07-24", "authors_parsed": [["Benhamou", "Eric", ""]]}, {"id": "1907.09769", "submitter": "Mohammad Mohammadi Amiri Dr.", "authors": "Mohammad Mohammadi Amiri and Deniz Gunduz", "title": "Federated Learning over Wireless Fading Channels", "comments": "to appear, IEEE Transactions on Wireless Communications", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.DC cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study federated machine learning at the wireless network edge, where\nlimited power wireless devices, each with its own dataset, build a joint model\nwith the help of a remote parameter server (PS). We consider a\nbandwidth-limited fading multiple access channel (MAC) from the wireless\ndevices to the PS, and propose various techniques to implement distributed\nstochastic gradient descent (DSGD). We first propose a digital DSGD (D-DSGD)\nscheme, in which one device is selected opportunistically for transmission at\neach iteration based on the channel conditions; the scheduled device quantizes\nits gradient estimate to a finite number of bits imposed by the channel\ncondition, and transmits these bits to the PS in a reliable manner. Next,\nmotivated by the additive nature of the wireless MAC, we propose a novel analog\ncommunication scheme, referred to as the compressed analog DSGD (CA-DSGD),\nwhere the devices first sparsify their gradient estimates while accumulating\nerror, and project the resultant sparse vector into a low-dimensional vector\nfor bandwidth reduction. Numerical results show that D-DSGD outperforms other\ndigital approaches in the literature; however, in general the proposed CA-DSGD\nalgorithm converges faster than the D-DSGD scheme and other schemes in the\nliterature, and reaches a higher level of accuracy. We have observed that the\ngap between the analog and digital schemes increases when the datasets of\ndevices are not independent and identically distributed (i.i.d.). Furthermore,\nthe performance of the CA-DSGD scheme is shown to be robust against imperfect\nchannel state information (CSI) at the devices. Overall these results show\nclear advantages for the proposed analog over-the-air DSGD scheme, which\nsuggests that learning and communication algorithms should be designed jointly\nto achieve the best end-to-end performance in machine learning applications at\nthe wireless edge.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jul 2019 09:00:42 GMT"}, {"version": "v2", "created": "Tue, 11 Feb 2020 04:18:25 GMT"}], "update_date": "2020-02-12", "authors_parsed": [["Amiri", "Mohammad Mohammadi", ""], ["Gunduz", "Deniz", ""]]}, {"id": "1907.09844", "submitter": "Abdul-Saboor Sheikh", "authors": "Abdul-Saboor Sheikh, Romain Guigoures, Evgenii Koriagin, Yuen King Ho,\n  Reza Shirvany, Roland Vollgraf, Urs Bergmann", "title": "A Deep Learning System for Predicting Size and Fit in Fashion E-Commerce", "comments": "Published at the Thirteenth ACM Conference on Recommender Systems\n  (RecSys '19), September 16--20, 2019, Copenhagen, Denmark", "journal-ref": null, "doi": "10.1145/3298689.3347006", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Personalized size and fit recommendations bear crucial significance for any\nfashion e-commerce platform. Predicting the correct fit drives customer\nsatisfaction and benefits the business by reducing costs incurred due to\nsize-related returns. Traditional collaborative filtering algorithms seek to\nmodel customer preferences based on their previous orders. A typical challenge\nfor such methods stems from extreme sparsity of customer-article orders. To\nalleviate this problem, we propose a deep learning based content-collaborative\nmethodology for personalized size and fit recommendation. Our proposed method\ncan ingest arbitrary customer and article data and can model multiple\nindividuals or intents behind a single account. The method optimizes a global\nset of parameters to learn population-level abstractions of size and fit\nrelevant information from observed customer-article interactions. It further\nemploys customer and article specific embedding variables to learn their\nproperties. Together with learned entity embeddings, the method maps additional\ncustomer and article attributes into a latent space to derive personalized\nrecommendations. Application of our method to two publicly available datasets\ndemonstrate an improvement over the state-of-the-art published results. On two\nproprietary datasets, one containing fit feedback from fashion experts and the\nother involving customer purchases, we further outperform comparable\nmethodologies, including a recent Bayesian approach for size recommendation.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jul 2019 12:47:53 GMT"}], "update_date": "2019-07-24", "authors_parsed": [["Sheikh", "Abdul-Saboor", ""], ["Guigoures", "Romain", ""], ["Koriagin", "Evgenii", ""], ["Ho", "Yuen King", ""], ["Shirvany", "Reza", ""], ["Vollgraf", "Roland", ""], ["Bergmann", "Urs", ""]]}, {"id": "1907.09881", "submitter": "Javier Zazo", "authors": "Javier Zazo, Bahareh Tolooshams, Demba Ba", "title": "Convolutional Dictionary Learning in Hierarchical Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Filter banks are a popular tool for the analysis of piecewise smooth signals\nsuch as natural images. Motivated by the empirically observed properties of\nscale and detail coefficients of images in the wavelet domain, we propose a\nhierarchical deep generative model of piecewise smooth signals that is a\nrecursion across scales: the low pass scale coefficients at one layer are\nobtained by filtering the scale coefficients at the next layer, and adding a\nhigh pass detail innovation obtained by filtering a sparse vector. This\nrecursion describes a linear dynamic system that is a non-Gaussian Markov\nprocess across scales and is closely related to multilayer-convolutional sparse\ncoding (ML-CSC) generative model for deep networks, except that our model\nallows for deeper architectures, and combines sparse and non-sparse signal\nrepresentations. We propose an alternating minimization algorithm for learning\nthe filters in this hierarchical model given observations at layer zero, e.g.,\nnatural images. The algorithm alternates between a coefficient-estimation step\nand a filter update step. The coefficient update step performs sparse (detail)\nand smooth (scale) coding and, when unfolded, leads to a deep neural network.\nWe use MNIST to demonstrate the representation capabilities of the model, and\nits derived features (coefficients) for classification.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jul 2019 13:57:03 GMT"}], "update_date": "2019-07-24", "authors_parsed": [["Zazo", "Javier", ""], ["Tolooshams", "Bahareh", ""], ["Ba", "Demba", ""]]}, {"id": "1907.09884", "submitter": "Cunhang Fan", "authors": "Cunhang Fan, Bin Liu, Jianhua Tao, Jiangyan Yi, Zhengqi Wen", "title": "Discriminative Learning for Monaural Speech Separation Using Deep\n  Embedding Features", "comments": "5 pages, 1 figure, accepted by INTERSPEECH 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep clustering (DC) and utterance-level permutation invariant training\n(uPIT) have been demonstrated promising for speaker-independent speech\nseparation. DC is usually formulated as two-step processes: embedding learning\nand embedding clustering, which results in complex separation pipelines and a\nhuge obstacle in directly optimizing the actual separation objectives. As for\nuPIT, it only minimizes the chosen permutation with the lowest mean square\nerror, doesn't discriminate it with other permutations. In this paper, we\npropose a discriminative learning method for speaker-independent speech\nseparation using deep embedding features. Firstly, a DC network is trained to\nextract deep embedding features, which contain each source's information and\nhave an advantage in discriminating each target speakers. Then these features\nare used as the input for uPIT to directly separate the different sources.\nFinally, uPIT and DC are jointly trained, which directly optimizes the actual\nseparation objectives. Moreover, in order to maximize the distance of each\npermutation, the discriminative learning is applied to fine tuning the whole\nmodel. Our experiments are conducted on WSJ0-2mix dataset. Experimental results\nshow that the proposed models achieve better performances than DC and uPIT for\nspeaker-independent speech separation.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jul 2019 14:00:06 GMT"}], "update_date": "2019-07-24", "authors_parsed": [["Fan", "Cunhang", ""], ["Liu", "Bin", ""], ["Tao", "Jianhua", ""], ["Yi", "Jiangyan", ""], ["Wen", "Zhengqi", ""]]}, {"id": "1907.09915", "submitter": "Huajun Liu", "authors": "Huajun Liu, Hui Zhang, Christoph Mertz", "title": "DeepDA: LSTM-based Deep Data Association Network for Multi-Targets\n  Tracking in Clutter", "comments": "8 pages, 12 figures. arXiv admin note: text overlap with\n  arXiv:1802.06897, arXiv:1604.03635 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Long Short-Term Memory (LSTM) neural network based data association\nalgorithm named as DeepDA for multi-target tracking in clutters is proposed to\ndeal with the NP-hard combinatorial optimization problem in this paper.\nDifferent from the classical data association methods involving complex models\nand accurate prior knowledge on clutter density, filter covariance or\nassociated gating etc, data-driven deep learning methods have been extensively\nresearched for this topic. Firstly, data association mathematical problem for\nmultitarget tracking on unknown target number, missed detection and clutter,\nwhich is beyond one-to-one mapping between observations and targets is\nredefined formally. Subsequently, an LSTM network is designed to learn the\nmeasurement-to-track association probability from radar noisy measurements and\nexist tracks. Moreover, an LSTM-based data-driven deep neural network after a\nsupervised training through the BPTT and RMSprop optimization method can get\nthe association probability directly. Experimental results on simulated data\nshow a significant performance on association ratio, target ID switching and\ntime-consuming for tracking multiple targets even they are crossing each other\nin the complicated clutter environment.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jul 2019 23:00:42 GMT"}], "update_date": "2019-07-29", "authors_parsed": [["Liu", "Huajun", ""], ["Zhang", "Hui", ""], ["Mertz", "Christoph", ""]]}, {"id": "1907.09916", "submitter": "Shuo-An Huang", "authors": "Shuo-An Huang and Chia-Hsiang Yang", "title": "A Hardware-Efficient ADMM-Based SVM Training Algorithm for Edge\n  Computing", "comments": "10 pages, 1 table, and 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work demonstrates a hardware-efficient support vector machine (SVM)\ntraining algorithm via the alternative direction method of multipliers (ADMM)\noptimizer. Low-rank approximation is exploited to reduce the dimension of the\nkernel matrix by employing the Nystr\\\"{o}m method. Verified in four datasets,\nthe proposed ADMM-based training algorithm with rank approximation reduces\n32$\\times$ of matrix dimension with only 2% drop in inference accuracy.\nCompared to the conventional sequential minimal optimization (SMO) algorithm,\nthe ADMM-based training algorithm is able to achieve a 9.8$\\times$10$^7$\nshorter latency for training 2048 samples. Hardware design techniques,\nincluding pre-computation and memory sharing, are proposed to reduce the\ncomputational complexity by 62% and the memory usage by 60%. As a proof of\nconcept, an epileptic seizure detector chip is designed to demonstrate the\neffectiveness of the proposed hardware-efficient training algorithm. The chip\nachieves a 153,310$\\times$ higher energy efficiency and a 364$\\times$ higher\nthroughput-to-area ratio for SVM training than a high-end CPU. This work\nprovides a promising solution for edge devices which require low-power and\nreal-time training.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jul 2019 14:40:53 GMT"}], "update_date": "2019-07-24", "authors_parsed": [["Huang", "Shuo-An", ""], ["Yang", "Chia-Hsiang", ""]]}, {"id": "1907.09929", "submitter": "Daniel Lopez-Martinez", "authors": "Daniel Lopez-Martinez and Neska El-Haouij and Rosalind Picard", "title": "Detection of Real-world Driving-induced Affective State Using\n  Physiological Signals and Multi-view Multi-task Machine Learning", "comments": "Affective Computing and Intelligent Interaction Conference 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Affective states have a critical role in driving performance and safety. They\ncan degrade driver situation awareness and negatively impact cognitive\nprocesses, severely diminishing road safety. Therefore, detecting and assessing\ndrivers' affective states is crucial in order to help improve the driving\nexperience, and increase safety, comfort and well-being. Recent advances in\naffective computing have enabled the detection of such states. This may lead to\nempathic automotive user interfaces that account for the driver's emotional\nstate and influence the driver in order to improve safety. In this work, we\npropose a multiview multi-task machine learning method for the detection of\ndriver's affective states using physiological signals. The proposed approach is\nable to account for inter-drive variability in physiological responses while\nenabling interpretability of the learned models, a factor that is especially\nimportant in systems deployed in the real world. We evaluate the models on\nthree different datasets containing real-world driving experiences. Our results\nindicate that accounting for drive-specific differences significantly improves\nmodel performance.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jul 2019 19:16:00 GMT"}], "update_date": "2019-07-24", "authors_parsed": [["Lopez-Martinez", "Daniel", ""], ["El-Haouij", "Neska", ""], ["Picard", "Rosalind", ""]]}, {"id": "1907.09949", "submitter": "Peng Cheng", "authors": "Rui Zhang, Peng Cheng, Zhuo Chen, Yonghui Li, Branka Vucetic", "title": "A Learning-Based Two-Stage Spectrum Sharing Strategy with Multiple\n  Primary Transmit Power Levels", "comments": "46 pages, 10 figures, accepted by IEEE Transactions on Signal\n  Processing 2019", "journal-ref": null, "doi": "10.1109/TSP.2019.2932866", "report-no": null, "categories": "eess.SP cs.IT cs.LG math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-parameter cognition in a cognitive radio network (CRN) provides a more\nthorough understanding of the radio environments, and could potentially lead to\nfar more intelligent and efficient spectrum usage for a secondary user. In this\npaper, we investigate the multi-parameter cognition problem for a CRN where the\nprimary transmitter (PT) radiates multiple transmit power levels, and propose a\nlearning-based two-stage spectrum sharing strategy. We first propose a\ndata-driven/machine learning based multi-level spectrum sensing scheme,\nincluding the spectrum learning (Stage I) and prediction (the first part in\nStage II). This fully blind sensing scheme does not require any prior knowledge\nof the PT power characteristics. Then, based on a novel normalized power level\nalignment metric, we propose two prediction-transmission structures, namely\nperiodic and non-periodic, for spectrum access (the second part in Stage II),\nwhich enable the secondary transmitter (ST) to closely follow the PT power\nlevel variation. The periodic structure features a fixed prediction interval,\nwhile the non-periodic one dynamically determines the interval with a proposed\nreinforcement learning algorithm to further improve the alignment metric.\nFinally, we extend the prediction-transmission structure to an online scenario,\nwhere the number of PT power levels might change as a consequence of PT\nadapting to the environment fluctuation or quality of service variation. The\nsimulation results demonstrate the effectiveness of the proposed strategy in\nvarious scenarios.\n", "versions": [{"version": "v1", "created": "Sun, 21 Jul 2019 10:54:21 GMT"}], "update_date": "2019-10-02", "authors_parsed": [["Zhang", "Rui", ""], ["Cheng", "Peng", ""], ["Chen", "Zhuo", ""], ["Li", "Yonghui", ""], ["Vucetic", "Branka", ""]]}, {"id": "1907.09951", "submitter": "Hongming Shan", "authors": "Hongming Shan, Christopher Wiedeman, Ge Wang, Yang Yang", "title": "Simultaneous reconstruction of the initial pressure and sound speed in\n  photoacoustic tomography using a deep-learning approach", "comments": null, "journal-ref": null, "doi": "10.1117/12.2529984", "report-no": null, "categories": "eess.IV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Photoacoustic tomography seeks to reconstruct an acoustic initial pressure\ndistribution from the measurement of the ultrasound waveforms. Conventional\nmethods assume a-prior knowledge of the sound speed distribution, which\npractically is unknown. One way to circumvent the issue is to simultaneously\nreconstruct both the acoustic initial pressure and speed. In this article, we\ndevelop a novel data-driven method that integrates an advanced deep neural\nnetwork through model-based iteration. The image of the initial pressure is\nsignificantly improved in our numerical simulation.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jul 2019 15:16:06 GMT"}, {"version": "v2", "created": "Fri, 13 Sep 2019 13:56:52 GMT"}], "update_date": "2019-09-16", "authors_parsed": [["Shan", "Hongming", ""], ["Wiedeman", "Christopher", ""], ["Wang", "Ge", ""], ["Yang", "Yang", ""]]}, {"id": "1907.09974", "submitter": "Lydia Neary-Zajiczek", "authors": "Lydia Neary-Zajiczek, Clara Essmann, Neil Clancy, Aiman Haider, Elena\n  Miranda, Michael Shaw, Amir Gander, Brian Davidson, Delmiro Fernandez-Reyes,\n  Vijay Pawar and Danail Stoyanov", "title": "Whole-Sample Mapping of Cancerous and Benign Tissue Properties", "comments": "Accepted at MICCAI2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Structural and mechanical differences between cancerous and healthy tissue\ngive rise to variations in macroscopic properties such as visual appearance and\nelastic modulus that show promise as signatures for early cancer detection.\nAtomic force microscopy (AFM) has been used to measure significant differences\nin stiffness between cancerous and healthy cells owing to its high force\nsensitivity and spatial resolution, however due to absorption and scattering of\nlight, it is often challenging to accurately locate where AFM measurements have\nbeen made on a bulk tissue sample. In this paper we describe an image\nregistration method that localizes AFM elastic stiffness measurements with\nhigh-resolution images of haematoxylin and eosin (H\\&E)-stained tissue to\nwithin 1.5 microns. Color RGB images are segmented into three structure types\n(lumen, cells and stroma) by a neural network classifier trained on\nground-truth pixel data obtained through k-means clustering in HSV color space.\nUsing the localized stiffness maps and corresponding structural information, a\nwhole-sample stiffness map is generated with a region matching and\ninterpolation algorithm that associates similar structures with measured\nstiffness values. We present results showing significant differences in\nstiffness between healthy and cancerous liver tissue and discuss potential\napplications of this technique.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jul 2019 16:00:52 GMT"}], "update_date": "2019-07-24", "authors_parsed": [["Neary-Zajiczek", "Lydia", ""], ["Essmann", "Clara", ""], ["Clancy", "Neil", ""], ["Haider", "Aiman", ""], ["Miranda", "Elena", ""], ["Shaw", "Michael", ""], ["Gander", "Amir", ""], ["Davidson", "Brian", ""], ["Fernandez-Reyes", "Delmiro", ""], ["Pawar", "Vijay", ""], ["Stoyanov", "Danail", ""]]}, {"id": "1907.09983", "submitter": "Chen Chen", "authors": "Chen Chen, Carlo Biffi, Giacomo Tarroni, Steffen Petersen, Wenjia Bai,\n  Daniel Rueckert", "title": "Learning Shape Priors for Robust Cardiac MR Segmentation from Multi-view\n  Images", "comments": "11 pages, 5 figures, accepted at MICCAI 2019, Camera-ready version", "journal-ref": null, "doi": "10.1007/978-3-030-32245-8_58", "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Cardiac MR image segmentation is essential for the morphological and\nfunctional analysis of the heart. Inspired by how experienced clinicians assess\nthe cardiac morphology and function across multiple standard views (i.e. long-\nand short-axis views), we propose a novel approach which learns anatomical\nshape priors across different 2D standard views and leverages these priors to\nsegment the left ventricular (LV) myocardium from short-axis MR image stacks.\nThe proposed segmentation method has the advantage of being a 2D network but at\nthe same time incorporates spatial context from multiple, complementary views\nthat span a 3D space. Our method achieves accurate and robust segmentation of\nthe myocardium across different short-axis slices (from apex to base),\noutperforming baseline models (e.g. 2D U-Net, 3D U-Net) while achieving higher\ndata efficiency. Compared to the 2D U-Net, the proposed method reduces the mean\nHausdorff distance (mm) from 3.24 to 2.49 on the apical slices, from 2.34 to\n2.09 on the middle slices and from 3.62 to 2.76 on the basal slices on the test\nset, when only 10% of the training data was used.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jul 2019 16:22:43 GMT"}, {"version": "v2", "created": "Tue, 17 Dec 2019 17:06:11 GMT"}], "update_date": "2019-12-18", "authors_parsed": [["Chen", "Chen", ""], ["Biffi", "Carlo", ""], ["Tarroni", "Giacomo", ""], ["Petersen", "Steffen", ""], ["Bai", "Wenjia", ""], ["Rueckert", "Daniel", ""]]}, {"id": "1907.09987", "submitter": "Assad Oberai", "authors": "Dhruv Patel and Assad A Oberai", "title": "Bayesian Inference with Generative Adversarial Network Priors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG eess.IV physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian inference is used extensively to infer and to quantify the\nuncertainty in a field of interest from a measurement of a related field when\nthe two are linked by a physical model. Despite its many applications, Bayesian\ninference faces challenges when inferring fields that have discrete\nrepresentations of large dimension, and/or have prior distributions that are\ndifficult to represent mathematically. In this manuscript we consider the use\nof Generative Adversarial Networks (GANs) in addressing these challenges. A GAN\nis a type of deep neural network equipped with the ability to learn the\ndistribution implied by multiple samples of a given field. Once trained on\nthese samples, the generator component of a GAN maps the iid components of a\nlow-dimensional latent vector to an approximation of the distribution of the\nfield of interest. In this work we demonstrate how this approximate\ndistribution may be used as a prior in a Bayesian update, and how it addresses\nthe challenges associated with characterizing complex prior distributions and\nthe large dimension of the inferred field. We demonstrate the efficacy of this\napproach by applying it to the problem of inferring and quantifying uncertainty\nin the initial temperature field in a heat conduction problem from a noisy\nmeasurement of the temperature at later time.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jul 2019 05:08:20 GMT"}], "update_date": "2019-07-24", "authors_parsed": [["Patel", "Dhruv", ""], ["Oberai", "Assad A", ""]]}, {"id": "1907.10016", "submitter": "Shikib Mehri", "authors": "Shikib Mehri, Tejas Srinivasan and Maxine Eskenazi", "title": "Structured Fusion Networks for Dialog", "comments": "Accepted to SIGDial 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural dialog models have exhibited strong performance, however their\nend-to-end nature lacks a representation of the explicit structure of dialog.\nThis results in a loss of generalizability, controllability and a data-hungry\nnature. Conversely, more traditional dialog systems do have strong models of\nexplicit structure. This paper introduces several approaches for explicitly\nincorporating structure into neural models of dialog. Structured Fusion\nNetworks first learn neural dialog modules corresponding to the structured\ncomponents of traditional dialog systems and then incorporate these modules in\na higher-level generative model. Structured Fusion Networks obtain strong\nresults on the MultiWOZ dataset, both with and without reinforcement learning.\nStructured Fusion Networks are shown to have several valuable properties,\nincluding better domain generalizability, improved performance in reduced data\nscenarios and robustness to divergence during reinforcement learning.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jul 2019 17:20:13 GMT"}], "update_date": "2019-07-24", "authors_parsed": [["Mehri", "Shikib", ""], ["Srinivasan", "Tejas", ""], ["Eskenazi", "Maxine", ""]]}, {"id": "1907.10085", "submitter": "Angelica I. Aviles-Rivero", "authors": "Angelica I. Aviles-Rivero, Nicolas Papadakis, Ruoteng Li, Philip\n  Sellars, Qingnan Fan, Robby T. Tan, Carola-Bibiane Sch\\\"onlieb", "title": "GraphX$^{NET}-$ Chest X-Ray Classification Under Extreme Minimal\n  Supervision", "comments": "MICCAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The task of classifying X-ray data is a problem of both theoretical and\nclinical interest. Whilst supervised deep learning methods rely upon huge\namounts of labelled data, the critical problem of achieving a good\nclassification accuracy when an extremely small amount of labelled data is\navailable has yet to be tackled. In this work, we introduce a novel\nsemi-supervised framework for X-ray classification which is based on a\ngraph-based optimisation model. To the best of our knowledge, this is the first\nmethod that exploits graph-based semi-supervised learning for X-ray data\nclassification. Furthermore, we introduce a new multi-class classification\nfunctional with carefully selected class priors which allows for a smooth\nsolution that strengthens the synergy between the limited number of labels and\nthe huge amount of unlabelled data. We demonstrate, through a set of numerical\nand visual experiments, that our method produces highly competitive results on\nthe ChestX-ray14 data set whilst drastically reducing the need for annotated\ndata.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jul 2019 18:10:32 GMT"}, {"version": "v2", "created": "Thu, 25 Jul 2019 12:39:10 GMT"}, {"version": "v3", "created": "Fri, 3 Jul 2020 21:42:19 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["Aviles-Rivero", "Angelica I.", ""], ["Papadakis", "Nicolas", ""], ["Li", "Ruoteng", ""], ["Sellars", "Philip", ""], ["Fan", "Qingnan", ""], ["Tan", "Robby T.", ""], ["Sch\u00f6nlieb", "Carola-Bibiane", ""]]}, {"id": "1907.10132", "submitter": "Sebastian Niehaus", "authors": "Marie Kloenne, Sebastian Niehaus, Leonie Lampe, Alberto Merola, Janis\n  Reinelt, Ingo Roeder, Nico Scherf", "title": "Domain specific cues improve robustness of deep learning based\n  segmentation of ct volumes", "comments": null, "journal-ref": "Scientific Reports 10, 10712 (2020)", "doi": "10.1038/s41598-020-67544-y", "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine Learning has considerably improved medical image analysis in the past\nyears. Although data-driven approaches are intrinsically adaptive and thus,\ngeneric, they often do not perform the same way on data from different imaging\nmodalities. In particular Computed tomography (CT) data poses many challenges\nto medical image segmentation based on convolutional neural networks (CNNs),\nmostly due to the broad dynamic range of intensities and the varying number of\nrecorded slices of CT volumes. In this paper, we address these issues with a\nframework that combines domain-specific data preprocessing and augmentation\nwith state-of-the-art CNN architectures. The focus is not limited to optimise\nthe score, but also to stabilise the prediction performance since this is a\nmandatory requirement for use in automated and semi-automated workflows in the\nclinical environment.\n  The framework is validated with an architecture comparison to show CNN\narchitecture-independent effects of our framework functionality. We compare a\nmodified U-Net and a modified Mixed-Scale Dense Network (MS-D Net) to compare\ndilated convolutions for parallel multi-scale processing to the U-Net approach\nbased on traditional scaling operations. Finally, we propose an ensemble model\ncombining the strengths of different individual methods. The framework performs\nwell on a range of tasks such as liver and kidney segmentation, without\nsignificant differences in prediction performance on strongly differing volume\nsizes and varying slice thickness. Thus our framework is an essential step\ntowards performing robust segmentation of unknown real-world samples.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jul 2019 21:11:22 GMT"}, {"version": "v2", "created": "Fri, 27 Sep 2019 14:37:34 GMT"}, {"version": "v3", "created": "Thu, 30 Jan 2020 09:26:58 GMT"}], "update_date": "2020-07-02", "authors_parsed": [["Kloenne", "Marie", ""], ["Niehaus", "Sebastian", ""], ["Lampe", "Leonie", ""], ["Merola", "Alberto", ""], ["Reinelt", "Janis", ""], ["Roeder", "Ingo", ""], ["Scherf", "Nico", ""]]}, {"id": "1907.10134", "submitter": "Shang Wang", "authors": "Shang Wang and Yifan Bai and Gennady Pekhimenko", "title": "BPPSA: Scaling Back-propagation by Parallel Scan Algorithm", "comments": "In Proceedings of MLSys 2020:\n  https://mlsys.org/Conferences/2020/Schedule?showEvent=1407", "journal-ref": "Proceedings of Machine Learning and Systems 2020 (2020) 451-469", "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In an era when the performance of a single compute device plateaus, software\nmust be designed to scale on massively parallel systems for better runtime\nperformance. However, in the context of training deep learning models, the\npopular back-propagation (BP) algorithm imposes a strong sequential dependency\nin the process of gradient computation. Under model parallelism, BP takes\n$\\Theta (n)$ steps to complete which hinders its scalability on parallel\nsystems ($n$ represents the number of compute devices into which a model is\npartitioned).\n  In this work, in order to improve the scalability of BP, we reformulate BP\ninto a scan operation which is a primitive that performs an in-order\naggregation on a sequence of values and returns the partial result at each\nstep. We can then scale such reformulation of BP on parallel systems by our\nmodified version of the Blelloch scan algorithm which theoretically takes\n$\\Theta (\\log n)$ steps. We evaluate our approach on a vanilla Recurrent Neural\nNetwork (RNN) training with synthetic datasets and a RNN with Gated Recurrent\nUnits (GRU) training with the IRMAS dataset, and demonstrate up to $2.75\\times$\nspeedup on the overall training time and $108\\times$ speedup on the backward\npass. We also demonstrate that the retraining of pruned networks can be a\npractical use case of our method.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jul 2019 21:14:56 GMT"}, {"version": "v2", "created": "Tue, 10 Sep 2019 21:46:59 GMT"}, {"version": "v3", "created": "Sat, 7 Mar 2020 05:45:50 GMT"}], "update_date": "2020-03-10", "authors_parsed": [["Wang", "Shang", ""], ["Bai", "Yifan", ""], ["Pekhimenko", "Gennady", ""]]}, {"id": "1907.10147", "submitter": "Mineto Tsukada", "authors": "Mineto Tsukada, Masaaki Kondo, Hiroki Matsutani", "title": "A Neural Network-Based On-device Learning Anomaly Detector for Edge\n  Devices", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semi-supervised anomaly detection is an approach to identify anomalies by\nlearning the distribution of normal data. Backpropagation neural networks\n(i.e., BP-NNs) based approaches have recently drawn attention because of their\ngood generalization capability. In a typical situation, BP-NN-based models are\niteratively optimized in server machines with input data gathered from edge\ndevices. However, (1) the iterative optimization often requires significant\nefforts to follow changes in the distribution of normal data (i.e., concept\ndrift), and (2) data transfers between edge and server impose additional\nlatency and energy consumption. To address these issues, we propose ONLAD and\nits IP core, named ONLAD Core. ONLAD is highly optimized to perform fast\nsequential learning to follow concept drift in less than one millisecond. ONLAD\nCore realizes on-device learning for edge devices at low power consumption,\nwhich realizes standalone execution where data transfers between edge and\nserver are not required. Experiments show that ONLAD has favorable anomaly\ndetection capability in an environment that simulates concept drift.\nEvaluations of ONLAD Core confirm that the training latency is 1.95x~6.58x\nfaster than the other software implementations. Also, the runtime power\nconsumption of ONLAD Core implemented on PYNQ-Z1 board, a small FPGA/CPU SoC\nplatform, is 5.0x~25.4x lower than them.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jul 2019 21:40:46 GMT"}, {"version": "v2", "created": "Tue, 27 Aug 2019 12:23:16 GMT"}, {"version": "v3", "created": "Wed, 28 Aug 2019 17:25:50 GMT"}, {"version": "v4", "created": "Wed, 2 Oct 2019 15:42:33 GMT"}, {"version": "v5", "created": "Sun, 2 Feb 2020 18:58:01 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Tsukada", "Mineto", ""], ["Kondo", "Masaaki", ""], ["Matsutani", "Hiroki", ""]]}, {"id": "1907.10148", "submitter": "Hamid Hekmatian", "authors": "Hamid Hekmatian, Jingfu Jin and Samir Al-Stouhi", "title": "Conf-Net: Toward High-Confidence Dense 3D Point-Cloud with Error-Map\n  Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work proposes a method for depth completion of sparse LiDAR data using a\nconvolutional neural network which can be used to generate semi-dense depth\nmaps and \"almost\" full 3D point-clouds with significantly lower root mean\nsquared error (RMSE) over state-of-the-art methods. We add an \"Error\nPrediction\" unit to our network and present a novel and simple end-to-end\nmethod that learns to predict an error-map of depth regression task. An\n\"almost\" dense high-confidence/low-variance point-cloud is more valuable for\nsafety-critical applications specifically real-world autonomous driving than a\nfull point-cloud with high error rate and high error variance. Using our\npredicted error-map, we demonstrate that by up-filling a LiDAR point cloud from\n18,000 points to 285,000 points, versus 300,000 points for full depth, we can\nreduce the RMSE error from 1004 to 399. This error is approximately 60% less\nthan the state-of-the-art and 50% less than the state-of-the-art with RGB\nguidance (we did not use RGB guidance in our algorithm). In addition to\nanalyzing our results on Kitti depth completion dataset, we also demonstrate\nthe ability of our proposed method to extend to new tasks by deploying our\n\"Error Prediction\" unit to improve upon the state-of-the-art for monocular\ndepth estimation. Codes and demo videos are available at\nhttp://github.com/hekmak/Conf-net.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jul 2019 21:41:54 GMT"}, {"version": "v2", "created": "Mon, 29 Jul 2019 15:11:43 GMT"}, {"version": "v3", "created": "Thu, 19 Sep 2019 18:52:58 GMT"}], "update_date": "2019-09-23", "authors_parsed": [["Hekmatian", "Hamid", ""], ["Jin", "Jingfu", ""], ["Al-Stouhi", "Samir", ""]]}, {"id": "1907.10154", "submitter": "Matthew Faw", "authors": "Matthew Faw, Rajat Sen, Karthikeyan Shanmugam, Constantine Caramanis,\n  Sanjay Shakkottai", "title": "Mix and Match: An Optimistic Tree-Search Approach for Learning Models\n  from Mixture Distributions", "comments": "New from previous version: Adds Acknowledgements section", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a covariate shift problem where one has access to several\ndifferent training datasets for the same learning problem and a small\nvalidation set which possibly differs from all the individual training\ndistributions. This covariate shift is caused, in part, due to unobserved\nfeatures in the datasets. The objective, then, is to find the best mixture\ndistribution over the training datasets (with only observed features) such that\ntraining a learning algorithm using this mixture has the best validation\nperformance. Our proposed algorithm, ${\\sf Mix\\&Match}$, combines stochastic\ngradient descent (SGD) with optimistic tree search and model re-use (evolving\npartially trained models with samples from different mixture distributions)\nover the space of mixtures, for this task. We prove simple regret guarantees\nfor our algorithm with respect to recovering the optimal mixture, given a total\nbudget of SGD evaluations. Finally, we validate our algorithm on two real-world\ndatasets.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jul 2019 22:02:52 GMT"}, {"version": "v2", "created": "Fri, 23 Aug 2019 03:51:12 GMT"}, {"version": "v3", "created": "Wed, 9 Oct 2019 03:42:33 GMT"}, {"version": "v4", "created": "Sat, 8 Feb 2020 01:40:03 GMT"}, {"version": "v5", "created": "Tue, 14 Jul 2020 19:43:16 GMT"}], "update_date": "2020-07-16", "authors_parsed": [["Faw", "Matthew", ""], ["Sen", "Rajat", ""], ["Shanmugam", "Karthikeyan", ""], ["Caramanis", "Constantine", ""], ["Shakkottai", "Sanjay", ""]]}, {"id": "1907.10159", "submitter": "Saeid Tizpaz-Niari", "authors": "Saeid Tizpaz-Niari, Pavol Cerny, Sriram Sankaranarayanan, and Ashutosh\n  Trivedi", "title": "Efficient Detection and Quantification of Timing Leaks with Neural\n  Networks", "comments": "To Appear in RV'19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Detection and quantification of information leaks through timing side\nchannels are important to guarantee confidentiality. Although static analysis\nremains the prevalent approach for detecting timing side channels, it is\ncomputationally challenging for real-world applications. In addition, the\ndetection techniques are usually restricted to 'yes' or 'no' answers. In\npractice, real-world applications may need to leak information about the\nsecret. Therefore, quantification techniques are necessary to evaluate the\nresulting threats of information leaks. Since both problems are very difficult\nor impossible for static analysis techniques, we propose a dynamic analysis\nmethod. Our novel approach is to split the problem into two tasks. First, we\nlearn a timing model of the program as a neural network. Second, we analyze the\nneural network to quantify information leaks. As demonstrated in our\nexperiments, both of these tasks are feasible in practice --- making the\napproach a significant improvement over the state-of-the-art side channel\ndetectors and quantifiers. Our key technical contributions are (a) a neural\nnetwork architecture that enables side channel discovery and (b) an MILP-based\nalgorithm to estimate the side-channel strength. On a set of micro-benchmarks\nand real-world applications, we show that neural network models learn timing\nbehaviors of programs with thousands of methods. We also show that neural\nnetworks with thousands of neurons can be efficiently analyzed to detect and\nquantify information leaks through timing side channels.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jul 2019 22:24:20 GMT"}], "update_date": "2019-07-25", "authors_parsed": [["Tizpaz-Niari", "Saeid", ""], ["Cerny", "Pavol", ""], ["Sankaranarayanan", "Sriram", ""], ["Trivedi", "Ashutosh", ""]]}, {"id": "1907.10165", "submitter": "Derek Tam", "authors": "Derek Tam, Nicholas Monath, Ari Kobren, Aaron Traylor, Rajarshi Das,\n  Andrew McCallum", "title": "Optimal Transport-based Alignment of Learned Character Representations\n  for String Similarity", "comments": "ACL Long Paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  String similarity models are vital for record linkage, entity resolution, and\nsearch. In this work, we present STANCE --a learned model for computing the\nsimilarity of two strings. Our approach encodes the characters of each string,\naligns the encodings using Sinkhorn Iteration (alignment is posed as an\ninstance of optimal transport) and scores the alignment with a convolutional\nneural network. We evaluate STANCE's ability to detect whether two strings can\nrefer to the same entity--a task we term alias detection. We construct five new\nalias detection datasets (and make them publicly available). We show that\nSTANCE or one of its variants outperforms both state-of-the-art and classic,\nparameter-free similarity models on four of the five datasets. We also\ndemonstrate STANCE's ability to improve downstream tasks by applying it to an\ninstance of cross-document coreference and show that it leads to a 2.8 point\nimprovement in B^3 F1 over the previous state-of-the-art approach.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jul 2019 22:41:22 GMT"}], "update_date": "2019-07-25", "authors_parsed": [["Tam", "Derek", ""], ["Monath", "Nicholas", ""], ["Kobren", "Ari", ""], ["Traylor", "Aaron", ""], ["Das", "Rajarshi", ""], ["McCallum", "Andrew", ""]]}, {"id": "1907.10170", "submitter": "Yeping Hu", "authors": "Yeping Hu, Liting Sun, Masayoshi Tomizuka", "title": "Generic Prediction Architecture Considering both Rational and Irrational\n  Driving Behaviors", "comments": "Accepted by 2019 IEEE Intelligent Transportation Systems Conference\n  (ITSC)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurately predicting future behaviors of surrounding vehicles is an\nessential capability for autonomous vehicles in order to plan safe and feasible\ntrajectories. The behaviors of others, however, are full of uncertainties. Both\nrational and irrational behaviors exist, and the autonomous vehicles need to be\naware of this in their prediction module. The prediction module is also\nexpected to generate reasonable results in the presence of unseen and corner\nscenarios. Two types of prediction models are typically used to solve the\nprediction problem: learning-based model and planning-based model.\nLearning-based model utilizes real driving data to model the human behaviors.\nDepending on the structure of the data, learning-based models can predict both\nrational and irrational behaviors. But the balance between them cannot be\ncustomized, which creates challenges in generalizing the prediction results.\nPlanning-based model, on the other hand, usually assumes human as a rational\nagent, i.e., it anticipates only rational behavior of human drivers. In this\npaper, a generic prediction architecture is proposed to address various\nrationalities in human behavior. We leverage the advantages from both\nlearning-based and planning-based prediction models. The proposed approach is\nable to predict continuous trajectories that well-reflect possible future\nsituations of other drivers. Moreover, the prediction performance remains\nstable under various unseen driving scenarios. A case study under a real-world\nroundabout scenario is provided to demonstrate the performance and capability\nof the proposed prediction architecture.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jul 2019 23:07:22 GMT"}], "update_date": "2019-07-25", "authors_parsed": [["Hu", "Yeping", ""], ["Sun", "Liting", ""], ["Tomizuka", "Masayoshi", ""]]}, {"id": "1907.10178", "submitter": "Luca Anthony Thiede", "authors": "Luca Anthony Thiede and Pratik Prabhanjan Brahma", "title": "Analyzing the Variety Loss in the Context of Probabilistic Trajectory\n  Prediction", "comments": "Accepted for publication at ICCV 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Trajectory or behavior prediction of traffic agents is an important component\nof autonomous driving and robot planning in general. It can be framed as a\nprobabilistic future sequence generation problem and recent literature has\nstudied the applicability of generative models in this context. The variety or\nMinimum over N (MoN) loss, which tries to minimize the error between the ground\ntruth and the closest of N output predictions, has been used in these recent\nlearning models to improve the diversity of predictions. In this work, we\npresent a proof to show that the MoN loss does not lead to the ground truth\nprobability density function, but approximately to its square root instead. We\nvalidate this finding with extensive experiments on both simulated toy as well\nas real world datasets. We also propose multiple solutions to compensate for\nthe dilation to show improvement of log likelihood of the ground truth samples\nin the corrected probability density function.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jul 2019 23:56:02 GMT"}], "update_date": "2019-07-25", "authors_parsed": [["Thiede", "Luca Anthony", ""], ["Brahma", "Pratik Prabhanjan", ""]]}, {"id": "1907.10203", "submitter": "Saurabh Jha", "authors": "Saurabh Jha, Shengkun Cui, Tianyin Xu, Jeremy Enos, Mike Showerman,\n  Mark Dalton, Zbigniew T. Kalbarczyk, William T. Kramer, Ravishankar K. Iyer", "title": "Live Forensics for Distributed Storage Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present Kaleidoscope an innovative system that supports live forensics for\napplication performance problems caused by either individual component failures\nor resource contention issues in large-scale distributed storage systems. The\ndesign of Kaleidoscope is driven by our study of I/O failures observed in a\npeta-scale storage system anonymized as PetaStore. Kaleidoscope is built on\nthree key features: 1) using temporal and spatial differential observability\nfor end-to-end performance monitoring of I/O requests, 2) modeling the health\nof storage components as a stochastic process using domain-guided functions\nthat accounts for path redundancy and uncertainty in measurements, and, 3)\nobserving differences in reliability and performance metrics between similar\ntypes of healthy and unhealthy components to attribute the most likely root\ncauses. We deployed Kaleidoscope on PetaStore and our evaluation shows that\nKaleidoscope can run live forensics at 5-minute intervals and pinpoint the root\ncauses of 95.8% of real-world performance issues, with negligible monitoring\noverhead.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jul 2019 01:52:38 GMT"}], "update_date": "2019-07-25", "authors_parsed": [["Jha", "Saurabh", ""], ["Cui", "Shengkun", ""], ["Xu", "Tianyin", ""], ["Enos", "Jeremy", ""], ["Showerman", "Mike", ""], ["Dalton", "Mark", ""], ["Kalbarczyk", "Zbigniew T.", ""], ["Kramer", "William T.", ""], ["Iyer", "Ravishankar K.", ""]]}, {"id": "1907.10211", "submitter": "Yi Zhu", "authors": "Yi Zhu and Shawn Newsam", "title": "Motion-Aware Feature for Improved Video Anomaly Detection", "comments": "BMVC 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by our observation that motion information is the key to good\nanomaly detection performance in video, we propose a temporal augmented network\nto learn a motion-aware feature. This feature alone can achieve competitive\nperformance with previous state-of-the-art methods, and when combined with\nthem, can achieve significant performance improvements. Furthermore, we\nincorporate temporal context into the Multiple Instance Learning (MIL) ranking\nmodel by using an attention block. The learned attention weights can help to\ndifferentiate between anomalous and normal video segments better. With the\nproposed motion-aware feature and the temporal MIL ranking model, we outperform\nprevious approaches by a large margin on both anomaly detection and anomalous\naction recognition tasks in the UCF Crime dataset.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jul 2019 02:36:28 GMT"}], "update_date": "2019-07-25", "authors_parsed": [["Zhu", "Yi", ""], ["Newsam", "Shawn", ""]]}, {"id": "1907.10225", "submitter": "Zhenghang Cui", "authors": "Zhenghang Cui, Nontawat Charoenphakdee, Issei Sato, Masashi Sugiyama", "title": "Classification from Triplet Comparison Data", "comments": "Code: https://github.com/zchenry/triplet_classification", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning from triplet comparison data has been extensively studied in the\ncontext of metric learning, where we want to learn a distance metric between\ntwo instances, and ordinal embedding, where we want to learn an embedding in an\nEuclidean space of the given instances that preserves the comparison order as\nwell as possible. Unlike fully-labeled data, triplet comparison data can be\ncollected in a more accurate and human-friendly way. Although learning from\ntriplet comparison data has been considered in many applications, an important\nfundamental question of whether we can learn a classifier only from triplet\ncomparison data has remained unanswered. In this paper, we give a positive\nanswer to this important question by proposing an unbiased estimator for the\nclassification risk under the empirical risk minimization framework. Since the\nproposed method is based on the empirical risk minimization framework, it\ninherently has the advantage that any surrogate loss function and any model,\nincluding neural networks, can be easily applied. Furthermore, we theoretically\nestablish an estimation error bound for the proposed empirical risk minimizer.\nFinally, we provide experimental results to show that our method empirically\nworks well and outperforms various baseline methods.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jul 2019 03:49:16 GMT"}, {"version": "v2", "created": "Mon, 5 Aug 2019 05:09:32 GMT"}, {"version": "v3", "created": "Sat, 18 Apr 2020 05:17:47 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Cui", "Zhenghang", ""], ["Charoenphakdee", "Nontawat", ""], ["Sato", "Issei", ""], ["Sugiyama", "Masashi", ""]]}, {"id": "1907.10235", "submitter": "Junwei Pan", "authors": "Junwei Pan, Yizhi Mao, Alfonso Lobos Ruiz, Yu Sun, Aaron Flores", "title": "Predicting Different Types of Conversions with Multi-Task Learning in\n  Online Advertising", "comments": "SIGKDD", "journal-ref": "SIGKDD 2019", "doi": "10.1145/3292500.3330783", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conversion prediction plays an important role in online advertising since\nCost-Per-Action (CPA) has become one of the primary campaign performance\nobjectives in the industry. Unlike click prediction, conversions have different\ntypes in nature, and each type may be associated with different decisive\nfactors. In this paper, we formulate conversion prediction as a multi-task\nlearning problem, so that the prediction models for different types of\nconversions can be learned together. These models share feature\nrepresentations, but have their specific parameters, providing the benefit of\ninformation-sharing across all tasks. We then propose Multi-Task Field-weighted\nFactorization Machine (MT-FwFM) to solve these tasks jointly. Our experiment\nresults show that, compared with two state-of-the-art models, MT-FwFM improve\nthe AUC by 0.74% and 0.84% on two conversion types, and the weighted AUC across\nall conversion types is also improved by 0.50%.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jul 2019 04:47:05 GMT"}, {"version": "v2", "created": "Sun, 8 Mar 2020 23:46:52 GMT"}], "update_date": "2020-03-10", "authors_parsed": [["Pan", "Junwei", ""], ["Mao", "Yizhi", ""], ["Ruiz", "Alfonso Lobos", ""], ["Sun", "Yu", ""], ["Flores", "Aaron", ""]]}, {"id": "1907.10247", "submitter": "Yijie Guo", "authors": "Yijie Guo, Jongwook Choi, Marcin Moczulski, Shengyu Feng, Samy Bengio,\n  Mohammad Norouzi, Honglak Lee", "title": "Memory Based Trajectory-conditioned Policies for Learning from Sparse\n  Rewards", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning with sparse rewards is challenging because an agent\ncan rarely obtain non-zero rewards and hence, gradient-based optimization of\nparameterized policies can be incremental and slow. Recent work demonstrated\nthat using a memory buffer of previous successful trajectories can result in\nmore effective policies. However, existing methods may overly exploit past\nsuccessful experiences, which can encourage the agent to adopt sub-optimal and\nmyopic behaviors. In this work, instead of focusing on good experiences with\nlimited diversity, we propose to learn a trajectory-conditioned policy to\nfollow and expand diverse past trajectories from a memory buffer. Our method\nallows the agent to reach diverse regions in the state space and improve upon\nthe past trajectories to reach new states. We empirically show that our\napproach significantly outperforms count-based exploration methods (parametric\napproach) and self-imitation learning (parametric approach with non-parametric\nmemory) on various complex tasks with local optima. In particular, without\nusing expert demonstrations or resetting to arbitrary states, we achieve the\nstate-of-the-art scores under five billion number of frames, on challenging\nAtari games such as Montezuma's Revenge and Pitfall.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jul 2019 05:46:27 GMT"}, {"version": "v2", "created": "Wed, 20 Nov 2019 00:41:38 GMT"}, {"version": "v3", "created": "Mon, 15 Feb 2021 03:53:20 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Guo", "Yijie", ""], ["Choi", "Jongwook", ""], ["Moczulski", "Marcin", ""], ["Feng", "Shengyu", ""], ["Bengio", "Samy", ""], ["Norouzi", "Mohammad", ""], ["Lee", "Honglak", ""]]}, {"id": "1907.10250", "submitter": "Nitin Agarwal", "authors": "Nitin Agarwal, Sung-eui Yoon, M Gopi", "title": "Learning Embedding of 3D models with Quadric Loss", "comments": "Accepted to BMVC 2019 for Oral Presentation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CG cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sharp features such as edges and corners play an important role in the\nperception of 3D models. In order to capture them better, we propose quadric\nloss, a point-surface loss function, which minimizes the quadric error between\nthe reconstructed points and the input surface. Computation of Quadric loss is\neasy, efficient since the quadric matrices can be computed apriori, and is\nfully differentiable, making quadric loss suitable for training point and mesh\nbased architectures. Through extensive experiments we show the merits and\ndemerits of quadric loss. When combined with Chamfer loss, quadric loss\nachieves better reconstruction results as compared to any one of them or other\npoint-surface loss functions.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jul 2019 05:57:27 GMT"}], "update_date": "2019-07-25", "authors_parsed": [["Agarwal", "Nitin", ""], ["Yoon", "Sung-eui", ""], ["Gopi", "M", ""]]}, {"id": "1907.10257", "submitter": "Jong Chul Ye", "authors": "Shujaat Khan, Jaeyoung Huh, Jong Chul Ye", "title": "Adaptive and Compressive Beamforming Using Deep Learning for Medical\n  Ultrasound", "comments": "This is a significantly extended version of the original paper in\n  arXiv:1901.01706. This paper is accepted for IEEE Transactions on\n  Ultrasonics, Ferroelectrics, and Frequency Control", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In ultrasound (US) imaging, various types of adaptive beamforming techniques\nhave been investigated to improve the resolution and contrast-to-noise ratio of\nthe delay and sum (DAS) beamformers. Unfortunately, the performance of these\nadaptive beamforming approaches degrade when the underlying model is not\nsufficiently accurate and the number of channels decreases. To address this\nproblem, here we propose a deep learning-based beamformer to generate\nsignificantly improved images over widely varying measurement conditions and\nchannel subsampling patterns. In particular, our deep neural network is\ndesigned to directly process full or sub-sampled radio-frequency (RF) data\nacquired at various subsampling rates and detector configurations so that it\ncan generate high quality ultrasound images using a single beamformer. The\norigin of such input-dependent adaptivity is also theoretically analyzed.\nExperimental results using B-mode focused ultrasound confirm the efficacy of\nthe proposed methods.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jul 2019 06:30:30 GMT"}, {"version": "v2", "created": "Wed, 18 Dec 2019 10:54:20 GMT"}, {"version": "v3", "created": "Sun, 23 Feb 2020 16:15:20 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Khan", "Shujaat", ""], ["Huh", "Jaeyoung", ""], ["Ye", "Jong Chul", ""]]}, {"id": "1907.10265", "submitter": "Sara Mohammadinejad", "authors": "Sara Mohammadinejad, Jyotirmoy V. Deshmukh, Aniruddh G. Puranic,\n  Marcell Vazquez-Chanlatte, Alexandre Donz\\'e", "title": "Interpretable Classification of Time-Series Data using Efficient\n  Enumerative Techniques", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cyber-physical system applications such as autonomous vehicles, wearable\ndevices, and avionic systems generate a large volume of time-series data.\nDesigners often look for tools to help classify and categorize the data.\nTraditional machine learning techniques for time-series data offer several\nsolutions to solve these problems; however, the artifacts trained by these\nalgorithms often lack interpretability. On the other hand, temporal logics,\nsuch as Signal Temporal Logic (STL) have been successfully used in the formal\nmethods community as specifications of time-series behaviors. In this work, we\npropose a new technique to automatically learn temporal logic formulae that are\nable to cluster and classify real-valued time-series data. Previous work on\nlearning STL formulas from data either assumes a formula-template to be given\nby the user, or assumes some special fragment of STL that enables exploring the\nformula structure in a systematic fashion. In our technique, we relax these\nassumptions, and provide a way to systematically explore the space of all STL\nformulas. As the space of all STL formulas is very large, and contains many\nsemantically equivalent formulas, we suggest a technique to heuristically prune\nthe space of formulas considered. Finally, we illustrate our technique on\nvarious case studies from the automotive, transportation and healthcare domain.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jul 2019 06:54:04 GMT"}], "update_date": "2019-07-25", "authors_parsed": [["Mohammadinejad", "Sara", ""], ["Deshmukh", "Jyotirmoy V.", ""], ["Puranic", "Aniruddh G.", ""], ["Vazquez-Chanlatte", "Marcell", ""], ["Donz\u00e9", "Alexandre", ""]]}, {"id": "1907.10267", "submitter": "Jun Chen", "authors": "Jun Chen, Heye Zhang, Yanping Zhang, Shu Zhao, Raad Mohiaddin, Tom\n  Wong, David Firmin, Guang Yang, Jennifer Keegan", "title": "Discriminative Consistent Domain Generation for Semi-supervised Learning", "comments": "MICCAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning based task systems normally rely on a large amount of manually\nlabeled training data, which is expensive to obtain and subject to operator\nvariations. Moreover, it does not always hold that the manually labeled data\nand the unlabeled data are sitting in the same distribution. In this paper, we\nalleviate these problems by proposing a discriminative consistent domain\ngeneration (DCDG) approach to achieve a semi-supervised learning. The\ndiscriminative consistent domain is achieved by a double-sided domain\nadaptation. The double-sided domain adaptation aims to make a fusion of the\nfeature spaces of labeled data and unlabeled data. In this way, we can fit the\ndifferences of various distributions between labeled data and unlabeled data.\nIn order to keep the discriminativeness of generated consistent domain for the\ntask learning, we apply an indirect learning for the double-sided domain\nadaptation. Based on the generated discriminative consistent domain, we can use\nthe unlabeled data to learn the task model along with the labeled data via a\nconsistent image generation. We demonstrate the performance of our proposed\nDCDG on the late gadolinium enhancement cardiac MRI (LGE-CMRI) images acquired\nfrom patients with atrial fibrillation in two clinical centers for the\nsegmentation of the left atrium anatomy (LA) and proximal pulmonary veins\n(PVs). The experiments show that our semi-supervised approach achieves\ncompelling segmentation results, which can prove the robustness of DCDG for the\nsemi-supervised learning using the unlabeled data along with labeled data\nacquired from a single center or multicenter studies.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jul 2019 06:59:23 GMT"}], "update_date": "2019-07-25", "authors_parsed": [["Chen", "Jun", ""], ["Zhang", "Heye", ""], ["Zhang", "Yanping", ""], ["Zhao", "Shu", ""], ["Mohiaddin", "Raad", ""], ["Wong", "Tom", ""], ["Firmin", "David", ""], ["Yang", "Guang", ""], ["Keegan", "Jennifer", ""]]}, {"id": "1907.10282", "submitter": "Dibyasundar Das", "authors": "Dibyasundar Das, Deepak Ranjan Nayak, Ratnakar Dash, Banshidhar Majhi", "title": "Backward-Forward Algorithm: An Improvement towards Extreme Learning\n  Machine", "comments": "12 Pages, 11 figures, to be submitted to journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The extreme learning machine needs a large number of hidden nodes to\ngeneralize a single hidden layer neural network for a given training data-set.\nThe need for more number of hidden nodes suggests that the neural-network is\nmemorizing rather than generalizing the model. Hence, a supervised learning\nmethod is described here that uses Moore-Penrose approximation to determine\nboth input-weight and output-weight in two epochs, namely, backward-pass and\nforward-pass. The proposed technique has an advantage over the back-propagation\nmethod in terms of iterations required and is superior to the extreme learning\nmachine in terms of the number of hidden units necessary for generalization.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jul 2019 07:52:57 GMT"}, {"version": "v2", "created": "Fri, 26 Jul 2019 08:37:30 GMT"}, {"version": "v3", "created": "Mon, 29 Jul 2019 12:48:12 GMT"}, {"version": "v4", "created": "Mon, 7 Oct 2019 08:37:20 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Das", "Dibyasundar", ""], ["Nayak", "Deepak Ranjan", ""], ["Dash", "Ratnakar", ""], ["Majhi", "Banshidhar", ""]]}, {"id": "1907.10290", "submitter": "Shi-Ju Ran", "authors": "Shi-Ju Ran, Zheng-Zhi Sun, Shao-Ming Fei, Gang Su, and Maciej\n  Lewenstein", "title": "Quantum Compressed Sensing with Unsupervised Tensor-Network Machine\n  Learning", "comments": "5+6 pages, 3+6 figures. Essential changes and new data were added to\n  this new version", "journal-ref": "Phys. Rev. Research 2, 033293 (2020)", "doi": "10.1103/PhysRevResearch.2.033293", "report-no": null, "categories": "stat.ML cond-mat.str-el cs.LG quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose tensor-network compressed sensing (TNCS) by combining the ideas of\ncompressed sensing, tensor network (TN), and machine learning, which permits\nnovel and efficient quantum communications of realistic data. The strategy is\nto use the unsupervised TN machine learning algorithm to obtain the entangled\nstate $|\\Psi \\rangle$ that describes the probability distribution of a huge\namount of classical information considered to be communicated. To transfer a\nspecific piece of information with $|\\Psi \\rangle$, our proposal is to encode\nsuch information in the separable state with the minimal distance to the\nmeasured state $|\\Phi \\rangle$ that is obtained by partially measuring on\n$|\\Psi \\rangle$ in a designed way. To this end, a measuring protocol analogous\nto the compressed sensing with neural-network machine learning is suggested,\nwhere the measurements are designed to minimize uncertainty of information from\nthe probability distribution given by $|\\Phi \\rangle$. In this way, those who\nhave $|\\Phi \\rangle$ can reliably access the information by simply measuring on\n$|\\Phi \\rangle$. We propose q-sparsity to characterize the sparsity of quantum\nstates and the efficiency of the quantum communications by TNCS. The high\nq-sparsity is essentially due to the fact that the TN states describing nicely\nthe probability distribution obey the area law of entanglement entropy. Testing\non realistic datasets (hand-written digits and fashion images), TNCS is shown\nto possess high efficiency and accuracy, where the security of communications\nis guaranteed by the fundamental quantum principles.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jul 2019 08:09:03 GMT"}, {"version": "v2", "created": "Sun, 13 Oct 2019 12:25:58 GMT"}], "update_date": "2020-09-02", "authors_parsed": [["Ran", "Shi-Ju", ""], ["Sun", "Zheng-Zhi", ""], ["Fei", "Shao-Ming", ""], ["Su", "Gang", ""], ["Lewenstein", "Maciej", ""]]}, {"id": "1907.10310", "submitter": "Haichao Zhang", "authors": "Haichao Zhang, Jianyu Wang", "title": "Towards Adversarially Robust Object Detection", "comments": "ICCV 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Object detection is an important vision task and has emerged as an\nindispensable component in many vision system, rendering its robustness as an\nincreasingly important performance factor for practical applications. While\nobject detection models have been demonstrated to be vulnerable against\nadversarial attacks by many recent works, very few efforts have been devoted to\nimproving their robustness. In this work, we take an initial attempt towards\nthis direction. We first revisit and systematically analyze object detectors\nand many recently developed attacks from the perspective of model robustness.\nWe then present a multi-task learning perspective of object detection and\nidentify an asymmetric role of task losses. We further develop an adversarial\ntraining approach which can leverage the multiple sources of attacks for\nimproving the robustness of detection models. Extensive experiments on\nPASCAL-VOC and MS-COCO verified the effectiveness of the proposed approach.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jul 2019 09:04:23 GMT"}], "update_date": "2019-07-25", "authors_parsed": [["Zhang", "Haichao", ""], ["Wang", "Jianyu", ""]]}, {"id": "1907.10323", "submitter": "Paul Weng", "authors": "Paul Weng", "title": "Fairness in Reinforcement Learning", "comments": "Presented at the AI for Social Good Workshop at IJCAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decision support systems (e.g., for ecological conservation) and autonomous\nsystems (e.g., adaptive controllers in smart cities) start to be deployed in\nreal applications. Although their operations often impact many users or\nstakeholders, no fairness consideration is generally taken into account in\ntheir design, which could lead to completely unfair outcomes for some users or\nstakeholders. To tackle this issue, we advocate for the use of social welfare\nfunctions that encode fairness and present this general novel problem in the\ncontext of (deep) reinforcement learning, although it could possibly be\nextended to other machine learning tasks.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jul 2019 09:27:11 GMT"}], "update_date": "2019-07-25", "authors_parsed": [["Weng", "Paul", ""]]}, {"id": "1907.10327", "submitter": "Yusuke Kawamoto", "authors": "Yusuke Kawamoto", "title": "Towards Logical Specification of Statistical Machine Learning", "comments": "SEFM'19 conference paper (full version with errors corrected)", "journal-ref": null, "doi": "10.1007/978-3-030-30446-1_16", "report-no": null, "categories": "cs.LO cs.AI cs.CR cs.LG cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a logical approach to formalizing statistical properties of\nmachine learning. Specifically, we propose a formal model for statistical\nclassification based on a Kripke model, and formalize various notions of\nclassification performance, robustness, and fairness of classifiers by using\nepistemic logic. Then we show some relationships among properties of\nclassifiers and those between classification performance and robustness, which\nsuggests robustness-related properties that have not been formalized in the\nliterature as far as we know. To formalize fairness properties, we define a\nnotion of counterfactual knowledge and show techniques to formalize conditional\nindistinguishability by using counterfactual epistemic operators. As far as we\nknow, this is the first work that uses logical formulas to express statistical\nproperties of machine learning, and that provides epistemic (resp.\ncounterfactually epistemic) views on robustness (resp. fairness) of\nclassifiers.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jul 2019 09:33:07 GMT"}, {"version": "v2", "created": "Sat, 28 Mar 2020 14:30:40 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Kawamoto", "Yusuke", ""]]}, {"id": "1907.10348", "submitter": "Vlad Niculae", "authors": "Andr\\'e F.T. Martins, Vlad Niculae", "title": "Notes on Latent Structure Models and SPIGOT", "comments": "7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  These notes aim to shed light on the recently proposed structured projected\nintermediate gradient optimization technique (SPIGOT, Peng et al., 2018).\nSPIGOT is a variant of the straight-through estimator (Bengio et al., 2013)\nwhich bypasses gradients of the argmax function by back-propagating a surrogate\n\"gradient.\" We provide a new interpretation to the proposed gradient and put\nthis technique into perspective, linking it to other methods for training\nneural networks with discrete latent variables. As a by-product, we suggest\nalternate variants of SPIGOT which will be further explored in future work.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jul 2019 10:26:45 GMT"}], "update_date": "2019-07-25", "authors_parsed": [["Martins", "Andr\u00e9 F. T.", ""], ["Niculae", "Vlad", ""]]}, {"id": "1907.10370", "submitter": "Vishal Srivastava Dr", "authors": "Kavita Dubey, Anant Agarwal, Astitwa Sarthak Lathe, Ranjeet Kumar and\n  Vishal Srivastava", "title": "Self-attention based BiLSTM-CNN classifier for the prediction of\n  ischemic and non-ischemic cardiomyopathy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Heart Failure is a major component of healthcare expenditure and a leading\ncause of mortality worldwide. Despite higher inter-rater variability,\nendomyocardial biopsy (EMB) is still regarded as the standard technique, used\nto identify the cause (e.g. ischemic or non-ischemic cardiomyopathy, coronary\nartery disease, myocardial infarction etc.) of unexplained heart failure. In\nthis paper, we focus on identifying cardiomyopathy as ischemic or non-ischemic.\nFor this, we propose and implement a new unified architecture comprising CNN\n(inception-V3 model) and bidirectional LSTM (BiLSTM) with self-attention\nmechanism to predict the ischemic or non-ischemic to classify cardiomyopathy\nusing histopathological images. The proposed model is based on self-attention\nthat implicitly focuses on the information outputted from the hidden layers of\nBiLSTM. Through our results we demonstrate that this framework carries a high\nlearning capacity and is able to improve the classification performance.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jul 2019 11:34:44 GMT"}, {"version": "v2", "created": "Thu, 25 Jul 2019 11:39:52 GMT"}, {"version": "v3", "created": "Mon, 29 Jul 2019 06:46:33 GMT"}], "update_date": "2019-07-30", "authors_parsed": [["Dubey", "Kavita", ""], ["Agarwal", "Anant", ""], ["Lathe", "Astitwa Sarthak", ""], ["Kumar", "Ranjeet", ""], ["Srivastava", "Vishal", ""]]}, {"id": "1907.10380", "submitter": "Th\\'eis Bazin", "authors": "Th\\'eis Bazin and Ga\\\"etan Hadjeres", "title": "NONOTO: A Model-agnostic Web Interface for Interactive Music Composition\n  by Inpainting", "comments": "3 pages, 1 figure. Published as a conference paper at the 10th\n  International Conference on Computational Creativity (ICCC 2019), UNC\n  Charlotte, North Carolina", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inpainting-based generative modeling allows for stimulating human-machine\ninteractions by letting users perform stylistically coherent local editions to\nan object using a statistical model. We present NONOTO, a new interface for\ninteractive music generation based on inpainting models. It is aimed both at\nresearchers, by offering a simple and flexible API allowing them to connect\ntheir own models with the interface, and at musicians by providing\nindustry-standard features such as audio playback, real-time MIDI output and\nstraightforward synchronization with DAWs using Ableton Link.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jul 2019 13:47:46 GMT"}], "update_date": "2019-07-25", "authors_parsed": [["Bazin", "Th\u00e9is", ""], ["Hadjeres", "Ga\u00ebtan", ""]]}, {"id": "1907.10383", "submitter": "Alonso Marco", "authors": "Alonso Marco, Dominik Baumann, Philipp Hennig, Sebastian Trimpe", "title": "Classified Regression for Bayesian Optimization: Robot Learning with\n  Unknown Penalties", "comments": "This paper was submitted to JMLR in 2018 and rejected. Currently, it\n  is not published, nor under review in any conference or journal venue", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning robot controllers by minimizing a black-box objective cost using\nBayesian optimization (BO) can be time-consuming and challenging. It is very\noften the case that some roll-outs result in failure behaviors, causing\npremature experiment detention. In such cases, the designer is forced to decide\non heuristic cost penalties because the acquired data is often scarce, or not\ncomparable with that of the stable policies. To overcome this, we propose a\nBayesian model that captures exactly what we know about the cost of unstable\ncontrollers prior to data collection: Nothing, except that it should be a\nsomewhat large number. The resulting Bayesian model, approximated with a\nGaussian process, predicts high cost values in regions where failures are\nlikely to occur. In this way, the model guides the BO exploration toward\nregions of stability. We demonstrate the benefits of the proposed model in\nseveral illustrative and statistical synthetic benchmarks, and also in\nexperiments on a real robotic platform. In addition, we propose and\nexperimentally validate a new BO method to account for unknown constraints.\nSuch method is an extension of Max-Value Entropy Search, a recent\ninformation-theoretic method, to solve unconstrained global optimization\nproblems.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jul 2019 12:25:37 GMT"}, {"version": "v2", "created": "Mon, 9 Nov 2020 19:22:36 GMT"}], "update_date": "2020-11-11", "authors_parsed": [["Marco", "Alonso", ""], ["Baumann", "Dominik", ""], ["Hennig", "Philipp", ""], ["Trimpe", "Sebastian", ""]]}, {"id": "1907.10388", "submitter": "Eric Mitchell", "authors": "Eric Mitchell, Selim Engin, Volkan Isler, Daniel D Lee", "title": "Higher-Order Function Networks for Learning Composable 3D Object\n  Representations", "comments": "To be published in International Conference on Learning\n  Representations (ICLR 2020) [https://openreview.net/forum?id=HJgfDREKDB]; 19\n  pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new approach to 3D object representation where a neural network\nencodes the geometry of an object directly into the weights and biases of a\nsecond 'mapping' network. This mapping network can be used to reconstruct an\nobject by applying its encoded transformation to points randomly sampled from a\nsimple geometric space, such as the unit sphere. We study the effectiveness of\nour method through various experiments on subsets of the ShapeNet dataset. We\nfind that the proposed approach can reconstruct encoded objects with accuracy\nequal to or exceeding state-of-the-art methods with orders of magnitude fewer\nparameters. Our smallest mapping network has only about 7000 parameters and\nshows reconstruction quality on par with state-of-the-art object decoder\narchitectures with millions of parameters. Further experiments on feature\nmixing through the composition of learned functions show that the encoding\ncaptures a meaningful subspace of objects.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jul 2019 12:31:16 GMT"}, {"version": "v2", "created": "Mon, 6 Apr 2020 05:18:09 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Mitchell", "Eric", ""], ["Engin", "Selim", ""], ["Isler", "Volkan", ""], ["Lee", "Daniel D", ""]]}, {"id": "1907.10393", "submitter": "Qingjian Lin", "authors": "Qingjian Lin, Ruiqing Yin, Ming Li, Herv\\'e Bredin, Claude Barras", "title": "LSTM based Similarity Measurement with Spectral Clustering for Speaker\n  Diarization", "comments": "Accepted for INTERSPEECH 2019", "journal-ref": null, "doi": "10.21437/Interspeech.2019-1388", "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  More and more neural network approaches have achieved considerable\nimprovement upon submodules of speaker diarization system, including speaker\nchange detection and segment-wise speaker embedding extraction. Still, in the\nclustering stage, traditional algorithms like probabilistic linear discriminant\nanalysis (PLDA) are widely used for scoring the similarity between two speech\nsegments. In this paper, we propose a supervised method to measure the\nsimilarity matrix between all segments of an audio recording with sequential\nbidirectional long short-term memory networks (Bi-LSTM). Spectral clustering is\napplied on top of the similarity matrix to further improve the performance.\nExperimental results show that our system significantly outperforms the\nstate-of-the-art methods and achieves a diarization error rate of 6.63% on the\nNIST SRE 2000 CALLHOME database.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jul 2019 04:17:58 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Lin", "Qingjian", ""], ["Yin", "Ruiqing", ""], ["Li", "Ming", ""], ["Bredin", "Herv\u00e9", ""], ["Barras", "Claude", ""]]}, {"id": "1907.10401", "submitter": "Camille Roth", "authors": "Camille Roth (CAMS, CMB)", "title": "Algorithmic Distortion of Informational Landscapes", "comments": null, "journal-ref": "Intellectica, In press", "doi": null, "report-no": null, "categories": "cs.CY cs.IR cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The possible impact of algorithmic recommendation on the autonomy and free\nchoice of Internet users is being increasingly discussed, especially in terms\nof the rendering of information and the structuring of interactions. This paper\naims at reviewing and framing this issue along a double dichotomy. The first\none addresses the discrepancy between users' intentions and actions (1) under\nsome algorithmic influence and (2) without it. The second one distinguishes\nalgorithmic biases on (1) prior information rearrangement and (2) posterior\ninformation arrangement. In all cases, we focus on and differentiate situations\nwhere algorithms empirically appear to expand the cognitive and social horizon\nof users, from those where they seem to limit that horizon. We additionally\nsuggest that these biases may not be properly appraised without taking into\naccount the underlying social processes which algorithms are building upon.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jul 2019 08:13:18 GMT"}], "update_date": "2019-07-25", "authors_parsed": [["Roth", "Camille", "", "CAMS, CMB"]]}, {"id": "1907.10406", "submitter": "Qi Xuan", "authors": "Yun Xiang, Zhuangzhi Chen, Zuohui Chen, Zebin Fang, Haiyang Hao,\n  Jinyin Chen, Yi Liu, Zhefu Wu, Qi Xuan and Xiaoniu Yang", "title": "Open DNN Box by Power Side-Channel Attack", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks are becoming popular and important assets of many AI\ncompanies. However, recent studies indicate that they are also vulnerable to\nadversarial attacks. Adversarial attacks can be either white-box or black-box.\nThe white-box attacks assume full knowledge of the models while the black-box\nones assume none. In general, revealing more internal information can enable\nmuch more powerful and efficient attacks. However, in most real-world\napplications, the internal information of embedded AI devices is unavailable,\ni.e., they are black-box. Therefore, in this work, we propose a side-channel\ninformation based technique to reveal the internal information of black-box\nmodels. Specifically, we have made the following contributions: (1) we are the\nfirst to use side-channel information to reveal internal network architecture\nin embedded devices; (2) we are the first to construct models for internal\nparameter estimation; and (3) we validate our methods on real-world devices and\napplications. The experimental results show that our method can achieve 96.50\\%\naccuracy on average. Such results suggest that we should pay strong attention\nto the security problem of many AI applications, and further propose\ncorresponding defensive strategies in the future.\n", "versions": [{"version": "v1", "created": "Sun, 21 Jul 2019 11:52:36 GMT"}], "update_date": "2019-07-25", "authors_parsed": [["Xiang", "Yun", ""], ["Chen", "Zhuangzhi", ""], ["Chen", "Zuohui", ""], ["Fang", "Zebin", ""], ["Hao", "Haiyang", ""], ["Chen", "Jinyin", ""], ["Liu", "Yi", ""], ["Wu", "Zhefu", ""], ["Xuan", "Qi", ""], ["Yang", "Xiaoniu", ""]]}, {"id": "1907.10409", "submitter": "Muhammad Umer Anwaar", "authors": "Muhammad Umer Anwaar, Dmytro Rybalko, Martin Kleinsteuber", "title": "Mend The Learning Approach, Not the Data: Insights for Ranking\n  E-Commerce Products", "comments": "Accepted for ECML-PKDD 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Improved search quality enhances users' satisfaction, which directly impacts\nsales growth of an E-Commerce (E-Com) platform. Traditional Learning to Rank\n(LTR) algorithms require relevance judgments on products. In E-Com, getting\nsuch judgments poses an immense challenge. In the literature, it is proposed to\nemploy user feedback (such as clicks, add-to-basket (AtB) clicks and orders) to\ngenerate relevance judgments. It is done in two steps: first, query-product\npair data are aggregated from the logs and then order rate etc are calculated\nfor each pair in the logs. In this paper, we advocate counterfactual risk\nminimization (CRM) approach which circumvents the need of relevance judgements,\ndata aggregation and is better suited for learning from logged data, i.e.\ncontextual bandit feedback. Due to unavailability of public E-Com LTR dataset,\nwe provide \\textit{Mercateo dataset} from our platform. It contains more than\n10 million AtB click logs and 1 million order logs from a catalogue of about\n3.5 million products associated with 3060 queries. To the best of our\nknowledge, this is the first work which examines effectiveness of CRM approach\nin learning ranking model from real-world logged data. Our empirical evaluation\nshows that our CRM approach learns effectively from logged data and beats a\nstrong baseline ranker ($\\lambda$-MART) by a huge margin. Our method\noutperforms full-information loss (e.g. cross-entropy) on various deep neural\nnetwork models. These findings demonstrate that by adopting CRM approach, E-Com\nplatforms can get better product search quality compared to full-information\napproach. The code and dataset can be accessed at:\nhttps://github.com/ecom-research/CRM-LTR.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jul 2019 12:53:15 GMT"}, {"version": "v2", "created": "Tue, 10 Dec 2019 22:34:06 GMT"}, {"version": "v3", "created": "Thu, 16 Jan 2020 14:39:05 GMT"}, {"version": "v4", "created": "Tue, 21 Jan 2020 15:42:29 GMT"}, {"version": "v5", "created": "Sun, 29 Mar 2020 21:16:39 GMT"}, {"version": "v6", "created": "Thu, 30 Apr 2020 10:55:32 GMT"}, {"version": "v7", "created": "Fri, 19 Jun 2020 11:31:51 GMT"}, {"version": "v8", "created": "Thu, 9 Jul 2020 07:35:56 GMT"}], "update_date": "2020-07-10", "authors_parsed": [["Anwaar", "Muhammad Umer", ""], ["Rybalko", "Dmytro", ""], ["Kleinsteuber", "Martin", ""]]}, {"id": "1907.10410", "submitter": "Adel Bibi", "authors": "Adel Bibi, Baoyuan Wu and Bernard Ghanem", "title": "Constrained K-means with General Pairwise and Cardinality Constraints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we study constrained clustering, where constraints are utilized\nto guide the clustering process. In existing works, two categories of\nconstraints have been widely explored, namely pairwise and cardinality\nconstraints. Pairwise constraints enforce the cluster labels of two instances\nto be the same (must-link constraints) or different (cannot-link constraints).\nCardinality constraints encourage cluster sizes to satisfy a user-specified\ndistribution. However, most existing constrained clustering models can only\nutilize one category of constraints at a time. In this paper, we enforce the\nabove two categories into a unified clustering model starting with the integer\nprogram formulation of the standard K-means. As these two categories provide\nuseful information at different levels, utilizing both of them is expected to\nallow for better clustering performance. However, the optimization is difficult\ndue to the binary and quadratic constraints in the proposed unified\nformulation. To alleviate this difficulty, we utilize two techniques:\nequivalently replacing the binary constraints by the intersection of two\ncontinuous constraints; the other is transforming the quadratic constraints\ninto bi-linear constraints by introducing extra variables. Then we derive an\nequivalent continuous reformulation with simple constraints, which can be\nefficiently solved by Alternating Direction Method of Multipliers (ADMM)\nalgorithm. Extensive experiments on both synthetic and real data demonstrate:\n(1) when utilizing a single category of constraint, the proposed model is\nsuperior to or competitive with state-of-the-art constrained clustering models,\nand (2) when utilizing both categories of constraints jointly, the proposed\nmodel shows better performance than the case of the single category.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jul 2019 12:53:19 GMT"}], "update_date": "2019-07-25", "authors_parsed": [["Bibi", "Adel", ""], ["Wu", "Baoyuan", ""], ["Ghanem", "Bernard", ""]]}, {"id": "1907.10413", "submitter": "Antoine Blanchard", "authors": "Antoine Blanchard and Themistoklis P. Sapsis", "title": "Learning the Tangent Space of Dynamical Instabilities from Data", "comments": null, "journal-ref": null, "doi": "10.1063/1.5120830", "report-no": null, "categories": "physics.comp-ph cs.LG math.DS nlin.CD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For a large class of dynamical systems, the optimally time-dependent (OTD)\nmodes, a set of deformable orthonormal tangent vectors that track directions of\ninstabilities along any trajectory, are known to depend \"pointwise\" on the\nstate of the system on the attractor, and not on the history of the trajectory.\nWe leverage the power of neural networks to learn this \"pointwise\" mapping from\nphase space to OTD space directly from data. The result of the learning process\nis a cartography of directions associated with strongest instabilities in phase\nspace. Implications for data-driven prediction and control of dynamical\ninstabilities are discussed.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jul 2019 14:18:53 GMT"}, {"version": "v2", "created": "Fri, 8 Nov 2019 21:09:46 GMT"}], "update_date": "2020-01-08", "authors_parsed": [["Blanchard", "Antoine", ""], ["Sapsis", "Themistoklis P.", ""]]}, {"id": "1907.10416", "submitter": "Georgios Katsimpras", "authors": "Georgios Katsimpras, Georgios Paliouras", "title": "Semi-Supervised Tensor Factorization for Node Classification in Complex\n  Social Networks", "comments": "Presented at the Joint International Workshop on Social Influence\n  Analysis and Mining Actionable Insights from Social Networks 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a method to guide tensor factorization, using class\nlabels. Furthermore, it shows the advantages of using the proposed method in\nidentifying nodes that play a special role in multi-relational networks, e.g.\nspammers. Most complex systems involve multiple types of relationships and\ninteractions among entities. Combining information from different relationships\nmay be crucial for various prediction tasks. Instead of creating distinct\nprediction models for each type of relationship, in this paper we present a\ntensor factorization approach based on RESCAL, which collectively exploits all\nexisting relations. We extend RESCAL to produce a semi-supervised factorization\nmethod that combines a classification error term with the standard factor\noptimization process. The coupled optimization approach, models the tensorial\ndata assimilating observed information from all the relations, while also\ntaking into account classification performance. Our evaluation on real-world\nsocial network data shows that incorporating supervision, when available, leads\nto models that are more accurate.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jul 2019 13:00:57 GMT"}], "update_date": "2019-07-25", "authors_parsed": [["Katsimpras", "Georgios", ""], ["Paliouras", "Georgios", ""]]}, {"id": "1907.10418", "submitter": "Mahdy Rahman Chowdhury Mahdy", "authors": "Aimon Rahman, Hasib Zunair, M Sohel Rahman, Jesia Quader Yuki,\n  Sabyasachi Biswas, Md Ashraful Alam, Nabila Binte Alam, M.R.C. Mahdy", "title": "Improving Malaria Parasite Detection from Red Blood Cell using Deep\n  Convolutional Neural Networks", "comments": "Application of deep learning in biological science for the early\n  detection of disease", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Malaria is a female anopheles mosquito-bite inflicted life-threatening\ndisease which is considered endemic in many parts of the world. This article\nfocuses on improving malaria detection from patches segmented from microscopic\nimages of red blood cell smears by introducing a deep convolutional neural\nnetwork. Compared to the traditional methods that use tedious hand engineering\nfeature extraction, the proposed method uses deep learning in an end-to-end\narrangement that performs both feature extraction and classification directly\nfrom the raw segmented patches of the red blood smears. The dataset used in\nthis study was taken from National Institute of Health named NIH Malaria\nDataset. The evaluation metric accuracy and loss along with 5-fold cross\nvalidation was used to compare and select the best performing architecture. To\nmaximize the performance, existing standard pre-processing techniques from the\nliterature has also been experimented. In addition, several other complex\narchitectures have been implemented and tested to pick the best performing\nmodel. A holdout test has also been conducted to verify how well the proposed\nmodel generalizes on unseen data. Our best model achieves an accuracy of almost\n97.77%.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jul 2019 04:30:12 GMT"}], "update_date": "2019-07-25", "authors_parsed": [["Rahman", "Aimon", ""], ["Zunair", "Hasib", ""], ["Rahman", "M Sohel", ""], ["Yuki", "Jesia Quader", ""], ["Biswas", "Sabyasachi", ""], ["Alam", "Md Ashraful", ""], ["Alam", "Nabila Binte", ""], ["Mahdy", "M. R. C.", ""]]}, {"id": "1907.10419", "submitter": "Po-Yu Kao", "authors": "Po-Yu Kao, Jefferson W. Chen, B.S. Manjunath", "title": "Predicting Clinical Outcome of Stroke Patients with Tractographic\n  Feature", "comments": "12 pages, 4 figures, 3 tables. Accepted by MICCAI-BrainLesion 2019 as\n  an oral presentation", "journal-ref": null, "doi": "10.1007/978-3-030-46640-4_4", "report-no": null, "categories": "eess.IV cs.LG q-bio.QM stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The volume of stroke lesion is the gold standard for predicting the clinical\noutcome of stroke patients. However, the presence of stroke lesion may cause\nneural disruptions to other brain regions, and these potentially damaged\nregions may affect the clinical outcome of stroke patients. In this paper, we\nintroduce the tractographic feature to capture these potentially damaged\nregions and predict the modified Rankin Scale (mRS), which is a widely used\noutcome measure in stroke clinical trials. The tractographic feature is built\nfrom the stroke lesion and average connectome information from a group of\nnormal subjects. The tractographic feature takes into account different\nfunctional regions that may be affected by the stroke, thus complementing the\ncommonly used stroke volume features. The proposed tractographic feature is\ntested on a public stroke benchmark Ischemic Stroke Lesion Segmentation 2017\nand achieves higher accuracy than the stroke volume and the state-of-the-art\nfeature on predicting the mRS grades of stroke patients. In addition, the\ntractographic feature also yields a lower average absolute error than the\ncommonly used stroke volume feature.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jul 2019 23:27:54 GMT"}, {"version": "v2", "created": "Tue, 3 Sep 2019 23:15:17 GMT"}, {"version": "v3", "created": "Thu, 19 Sep 2019 23:12:58 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["Kao", "Po-Yu", ""], ["Chen", "Jefferson W.", ""], ["Manjunath", "B. S.", ""]]}, {"id": "1907.10420", "submitter": "Amirhossein Hajavi", "authors": "Amirhossein Hajavi and Ali Etemad", "title": "A Deep Neural Network for Short-Segment Speaker Recognition", "comments": "Accepted in Interspeech 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Todays interactive devices such as smart-phone assistants and smart speakers\noften deal with short-duration speech segments. As a result, speaker\nrecognition systems integrated into such devices will be much better suited\nwith models capable of performing the recognition task with short-duration\nutterances. In this paper, a new deep neural network, UtterIdNet, capable of\nperforming speaker recognition with short speech segments is proposed. Our\nproposed model utilizes a novel architecture that makes it suitable for\nshort-segment speaker recognition through an efficiently increased use of\ninformation in short speech segments. UtterIdNet has been trained and tested on\nthe VoxCeleb datasets, the latest benchmarks in speaker recognition.\nEvaluations for different segment durations show consistent and stable\nperformance for short segments, with significant improvement over the previous\nmodels for segments of 2 seconds, 1 second, and especially sub-second durations\n(250 ms and 500 ms).\n", "versions": [{"version": "v1", "created": "Mon, 22 Jul 2019 23:43:20 GMT"}], "update_date": "2019-07-25", "authors_parsed": [["Hajavi", "Amirhossein", ""], ["Etemad", "Ali", ""]]}, {"id": "1907.10421", "submitter": "Sumedh Yadav", "authors": "Sumedh Yadav and Mathis Bode", "title": "A graphical heuristic for reduction and partitioning of large datasets\n  for scalable supervised training", "comments": "30 pages, 25 figures, undergoing revision for publication in the\n  Journal of Big Data", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A scalable graphical method is presented for selecting, and partitioning\ndatasets for the training phase of a classification task. For the heuristic, a\nclustering algorithm is required to get its computation cost in a reasonable\nproportion to the task itself. This step is proceeded by construction of an\ninformation graph of the underlying classification patterns using approximate\nnearest neighbor methods. The presented method constitutes of two approaches,\none for reducing a given training set, and another for partitioning the\nselected/reduced set. The heuristic targets large datasets, since the primary\ngoal is significant reduction in training computation run-time without\ncompromising prediction accuracy. Test results show that both approaches\nsignificantly speed-up the training task when compared against that of\nstate-of-the-art shrinking heuristic available in LIBSVM. Furthermore, the\napproaches closely follow or even outperform in prediction accuracy. A network\ndesign is also presented for the partitioning based distributed training\nformulation. Added speed-up in training run-time is observed when compared to\nthat of serial implementation of the approaches.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jul 2019 13:05:15 GMT"}], "update_date": "2019-07-25", "authors_parsed": [["Yadav", "Sumedh", ""], ["Bode", "Mathis", ""]]}, {"id": "1907.10428", "submitter": "Zixing Zhang", "authors": "Jing Han, Zixing Zhang, Zhao Ren, Bj\\\"orn Schuller", "title": "EmoBed: Strengthening Monomodal Emotion Recognition via Training with\n  Crossmodal Emotion Embeddings", "comments": null, "journal-ref": null, "doi": "10.1109/TAFFC.2019.2928297", "report-no": null, "categories": "cs.LG cs.HC cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite remarkable advances in emotion recognition, they are severely\nrestrained from either the essentially limited property of the employed single\nmodality, or the synchronous presence of all involved multiple modalities.\nMotivated by this, we propose a novel crossmodal emotion embedding framework\ncalled EmoBed, which aims to leverage the knowledge from other auxiliary\nmodalities to improve the performance of an emotion recognition system at hand.\nThe framework generally includes two main learning components, i. e., joint\nmultimodal training and crossmodal training. Both of them tend to explore the\nunderlying semantic emotion information but with a shared recognition network\nor with a shared emotion embedding space, respectively. In doing this, the\nenhanced system trained with this approach can efficiently make use of the\ncomplementary information from other modalities. Nevertheless, the presence of\nthese auxiliary modalities is not demanded during inference. To empirically\ninvestigate the effectiveness and robustness of the proposed framework, we\nperform extensive experiments on the two benchmark databases RECOLA and\nOMG-Emotion for the tasks of dimensional emotion regression and categorical\nemotion classification, respectively. The obtained results show that the\nproposed framework significantly outperforms related baselines in monomodal\ninference, and are also competitive or superior to the recently reported\nsystems, which emphasises the importance of the proposed crossmodal learning\nfor emotion recognition.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jul 2019 07:55:29 GMT"}], "update_date": "2019-07-25", "authors_parsed": [["Han", "Jing", ""], ["Zhang", "Zixing", ""], ["Ren", "Zhao", ""], ["Schuller", "Bj\u00f6rn", ""]]}, {"id": "1907.10430", "submitter": "Octavian-Eugen Ganea", "authors": "Octavian-Eugen Ganea, Yashas Annadani, Gary B\\'ecigneul", "title": "Noise Contrastive Variational Autoencoders", "comments": "There is a mistake common to all the main proofs. In summary, what we\n  find are saddle points or global maxima of the respective loss functions and\n  not the global minima. We apologize for this", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We take steps towards understanding the \"posterior collapse (PC)\" difficulty\nin variational autoencoders (VAEs),~i.e. a degenerate optimum in which the\nlatent codes become independent of their corresponding inputs. We rely on\ncalculus of variations and theoretically explore a few popular VAE models,\nshowing that PC always occurs for non-parametric encoders and decoders.\nInspired by the popular noise contrastive estimation algorithm, we propose\nNC-VAE where the encoder discriminates between the latent codes of real data\nand of some artificially generated noise, in addition to encouraging good data\nreconstruction abilities. Theoretically, we prove that our model cannot reach\nPC and provide novel lower bounds. Our method is straightforward to implement\nand has the same run-time as vanilla VAE. Empirically, we showcase its benefits\non popular image and text datasets.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jul 2019 15:06:23 GMT"}, {"version": "v2", "created": "Wed, 31 Jul 2019 13:47:43 GMT"}], "update_date": "2019-08-01", "authors_parsed": [["Ganea", "Octavian-Eugen", ""], ["Annadani", "Yashas", ""], ["B\u00e9cigneul", "Gary", ""]]}, {"id": "1907.10442", "submitter": "Ankit Gupta", "authors": "Ayush Hariharan, Ankit Gupta, Trisha Pal", "title": "CAMLPAD: Cybersecurity Autonomous Machine Learning Platform for Anomaly\n  Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As machine learning and cybersecurity continue to explode in the context of\nthe digital ecosystem, the complexity of cybersecurity data combined with\ncomplicated and evasive machine learning algorithms leads to vast difficulties\nin designing an end to end system for intelligent, automatic anomaly\nclassification. On the other hand, traditional systems use elementary\nstatistics techniques and are often inaccurate, leading to weak centralized\ndata analysis platforms. In this paper, we propose a novel system that\naddresses these two problems, titled CAMLPAD, for Cybersecurity Autonomous\nMachine Learning Platform for Anomaly Detection. The CAMLPAD systems\nstreamlined, holistic approach begins with retrieving a multitude of different\nspecies of cybersecurity data in real time using elasticsearch, then running\nseveral machine learning algorithms, namely Isolation Forest, Histogram Based\nOutlier Score (HBOS), Cluster Based Local Outlier Factor (CBLOF), and K Means\nClustering, to process the data. Next, the calculated anomalies are visualized\nusing Kibana and are assigned an outlier score, which serves as an indicator\nfor whether an alert should be sent to the system administrator that there are\npotential anomalies in the network. After comprehensive testing of our platform\nin a simulated environment, the CAMLPAD system achieved an adjusted rand score\nof 95 percent, exhibiting the reliable accuracy and precision of the system.\nAll in all, the CAMLPAD system provides an accurate, streamlined approach to\nreal time cybersecurity anomaly detection, delivering a novel solution that has\nthe potential to revolutionize the cybersecurity sector.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jul 2019 17:50:43 GMT"}], "update_date": "2019-07-25", "authors_parsed": [["Hariharan", "Ayush", ""], ["Gupta", "Ankit", ""], ["Pal", "Trisha", ""]]}, {"id": "1907.10456", "submitter": "Yuhao Niu", "authors": "Xingjun Ma, Yuhao Niu, Lin Gu, Yisen Wang, Yitian Zhao, James Bailey,\n  Feng Lu", "title": "Understanding Adversarial Attacks on Deep Learning Based Medical Image\n  Analysis Systems", "comments": "15 pages, 11 figures, to appear in Pattern Recognition", "journal-ref": null, "doi": "10.1016/j.patcog.2020.107332", "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) have become popular for medical image analysis\ntasks like cancer diagnosis and lesion detection. However, a recent study\ndemonstrates that medical deep learning systems can be compromised by\ncarefully-engineered adversarial examples/attacks with small imperceptible\nperturbations. This raises safety concerns about the deployment of these\nsystems in clinical settings. In this paper, we provide a deeper understanding\nof adversarial examples in the context of medical images. We find that medical\nDNN models can be more vulnerable to adversarial attacks compared to models for\nnatural images, according to two different viewpoints. Surprisingly, we also\nfind that medical adversarial attacks can be easily detected, i.e., simple\ndetectors can achieve over 98% detection AUC against state-of-the-art attacks,\ndue to fundamental feature differences compared to normal examples. We believe\nthese findings may be a useful basis to approach the design of more explainable\nand secure medical deep learning systems.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jul 2019 14:04:13 GMT"}, {"version": "v2", "created": "Fri, 13 Mar 2020 15:57:31 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Ma", "Xingjun", ""], ["Niu", "Yuhao", ""], ["Gu", "Lin", ""], ["Wang", "Yisen", ""], ["Zhao", "Yitian", ""], ["Bailey", "James", ""], ["Lu", "Feng", ""]]}, {"id": "1907.10473", "submitter": "Ruimao Zhang", "authors": "Ping Luo, Ruimao Zhang, Jiamin Ren, Zhanglin Peng, Jingyu Li", "title": "Switchable Normalization for Learning-to-Normalize Deep Representation", "comments": "IEEE Transactions on Pattern Analysis and Machine Intelligence, 18\n  pages, 15 figures, 11 tables. arXiv admin note: substantial text overlap with\n  arXiv:1806.10779", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address a learning-to-normalize problem by proposing Switchable\nNormalization (SN), which learns to select different normalizers for different\nnormalization layers of a deep neural network. SN employs three distinct scopes\nto compute statistics (means and variances) including a channel, a layer, and a\nminibatch. SN switches between them by learning their importance weights in an\nend-to-end manner. It has several good properties. First, it adapts to various\nnetwork architectures and tasks. Second, it is robust to a wide range of batch\nsizes, maintaining high performance even when small minibatch is presented\n(e.g. 2 images/GPU). Third, SN does not have sensitive hyper-parameter, unlike\ngroup normalization that searches the number of groups as a hyper-parameter.\nWithout bells and whistles, SN outperforms its counterparts on various\nchallenging benchmarks, such as ImageNet, COCO, CityScapes, ADE20K, MegaFace,\nand Kinetics. Analyses of SN are also presented to answer the following three\nquestions: (a) Is it useful to allow each normalization layer to select its own\nnormalizer? (b) What impacts the choices of normalizers? (c) Do different tasks\nand datasets prefer different normalizers? We hope SN will help ease the usage\nand understand the normalization techniques in deep learning. The code of SN\nhas been released at https://github.com/switchablenorms.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jul 2019 17:50:31 GMT"}], "update_date": "2019-07-25", "authors_parsed": [["Luo", "Ping", ""], ["Zhang", "Ruimao", ""], ["Ren", "Jiamin", ""], ["Peng", "Zhanglin", ""], ["Li", "Jingyu", ""]]}, {"id": "1907.10477", "submitter": "Axel Finke", "authors": "Axel Finke, Alexandre H. Thiery", "title": "On importance-weighted autoencoders", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The importance weighted autoencoder (IWAE) (Burda et al., 2016) is a popular\nvariational-inference method which achieves a tighter evidence bound (and hence\na lower bias) than standard variational autoencoders by optimising a\nmulti-sample objective, i.e. an objective that is expressible as an integral\nover $K > 1$ Monte Carlo samples. Unfortunately, IWAE crucially relies on the\navailability of reparametrisations and even if these exist, the multi-sample\nobjective leads to inference-network gradients which break down as $K$ is\nincreased (Rainforth et al., 2018). This breakdown can only be circumvented by\nremoving high-variance score-function terms, either by heuristically ignoring\nthem (which yields the 'sticking-the-landing' IWAE (IWAE-STL) gradient from\nRoeder et al. (2017)) or through an identity from Tucker et al. (2019) (which\nyields the 'doubly-reparametrised' IWAE (IWAE-DREG) gradient). In this work, we\nargue that directly optimising the proposal distribution in importance sampling\nas in the reweighted wake-sleep (RWS) algorithm from Bornschein & Bengio (2015)\nis preferable to optimising IWAE-type multi-sample objectives. To formalise\nthis argument, we introduce an adaptive-importance sampling framework termed\nadaptive importance sampling for learning (AISLE) which slightly generalises\nthe RWS algorithm. We then show that AISLE admits IWAE-STL and IWAE-DREG (i.e.\nthe IWAE-gradients which avoid breakdown) as special cases.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jul 2019 14:52:12 GMT"}, {"version": "v2", "created": "Thu, 19 Sep 2019 09:46:02 GMT"}], "update_date": "2019-09-20", "authors_parsed": [["Finke", "Axel", ""], ["Thiery", "Alexandre H.", ""]]}, {"id": "1907.10480", "submitter": "Evgeny Postnikov", "authors": "Evgeny Postnikov (1), Alexander Kryukov (1), Stanislav Polyakov (1),\n  Dmitry Zhurov (2 and 3) ((1) Lomonosov Moscow State University Skobeltsyn\n  Institute of Nuclear Physics (MSU SINP), Moscow, Russia, (2) Applied Physics\n  Institute of Irkutsk State University (API ISU), Irkutsk, Russia, (3) Irkutsk\n  National Research Technical University, Irkutsk, Russia)", "title": "Deep Learning for Energy Estimation and Particle Identification in\n  Gamma-ray Astronomy", "comments": "10 pages, 6 figures. arXiv admin note: text overlap with\n  arXiv:1812.01551", "journal-ref": "Proc. of the 3rd Int. Workshop DLC-2019, CEUR-WS Proceedings,\n  Vol-2406, pp.90-99", "doi": null, "report-no": null, "categories": "astro-ph.IM cs.DC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning techniques, namely convolutional neural networks (CNN), have\npreviously been adapted to select gamma-ray events in the TAIGA experiment,\nhaving achieved a good quality of selection as compared with the conventional\nHillas approach. Another important task for the TAIGA data analysis was also\nsolved with CNN: gamma-ray energy estimation showed some improvement in\ncomparison with the conventional method based on the Hillas analysis.\nFurthermore, our software was completely redeveloped for the graphics\nprocessing unit (GPU), which led to significantly faster calculations in both\nof these tasks. All the results have been obtained with the simulated data of\nTAIGA Monte Carlo software; their experimental confirmation is envisaged for\nthe near future.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jul 2019 11:27:56 GMT"}], "update_date": "2019-07-25", "authors_parsed": [["Postnikov", "Evgeny", "", "2 and 3"], ["Kryukov", "Alexander", "", "2 and 3"], ["Polyakov", "Stanislav", "", "2 and 3"], ["Zhurov", "Dmitry", "", "2 and 3"]]}, {"id": "1907.10493", "submitter": "Jonas H\\\"ochst", "authors": "Jonas H\\\"ochst, Artur Sterz, Alexander Fr\\\"ommgen, Denny Stohr, Ralf\n  Steinmetz, Bernd Freisleben", "title": "Learning Wi-Fi Connection Loss Predictions for Seamless Vertical\n  Handovers Using Multipath TCP", "comments": "LCN 2019 Cam Ready Version", "journal-ref": "2019 IEEE 44th Conference on Local Computer Networks (LCN)", "doi": "10.1109/LCN44214.2019.8990753", "report-no": null, "categories": "cs.NI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel data-driven approach to perform smooth Wi-Fi/cellular\nhandovers on smartphones. Our approach relies on data provided by multiple\nsmartphone sensors (e.g., Wi-Fi RSSI, acceleration, compass, step counter, air\npressure) to predict Wi-Fi connection loss and uses Multipath TCP to\ndynamically switch between different connectivity modes. We train a random\nforest classifier and an artificial neural network on real-world sensor data\ncollected by five smartphone users over a period of three months. The trained\nmodels are executed on smartphones to reliably predict Wi-Fi connection loss 15\nseconds ahead of time, with a precision of up to 0.97 and a recall of up to\n0.98. Furthermore, we present results for four DASH video streaming experiments\nthat run on a Nexus 5 smartphone using available Wi-Fi/cellular networks. The\nneural network predictions for Wi-Fi connection loss are used to establish\nMPTCP subflows on the cellular link. The experiments show that our approach\nprovides seamless wireless connectivity, improves quality of experience of DASH\nvideo streaming, and requires less cellular data compared to handover\napproaches without Wi-Fi connection loss predictions.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jul 2019 14:58:24 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["H\u00f6chst", "Jonas", ""], ["Sterz", "Artur", ""], ["Fr\u00f6mmgen", "Alexander", ""], ["Stohr", "Denny", ""], ["Steinmetz", "Ralf", ""], ["Freisleben", "Bernd", ""]]}, {"id": "1907.10500", "submitter": "Yen-Wei Chang", "authors": "Yen-Wei Chang and Wen-Hsiao Peng", "title": "Learning Goal-Oriented Visual Dialog Agents: Imitating and Surpassing\n  Analytic Experts", "comments": "ICME2019 Oral Paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper tackles the problem of learning a questioner in the goal-oriented\nvisual dialog task. Several previous works adopt model-free reinforcement\nlearning. Most pretrain the model from a finite set of human-generated data. We\nargue that using limited demonstrations to kick-start the questioner is\ninsufficient due to the large policy search space. Inspired by a recently\nproposed information theoretic approach, we develop two analytic experts to\nserve as a source of high-quality demonstrations for imitation learning. We\nthen take advantage of reinforcement learning to refine the model towards the\ngoal-oriented objective. Experimental results on the GuessWhat?! dataset show\nthat our method has the combined merits of imitation and reinforcement\nlearning, achieving the state-of-the-art performance.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jul 2019 15:08:38 GMT"}], "update_date": "2019-07-25", "authors_parsed": [["Chang", "Yen-Wei", ""], ["Peng", "Wen-Hsiao", ""]]}, {"id": "1907.10509", "submitter": "Anti Ingel", "authors": "Anti Ingel, Ilya Kuzovkin, Raul Vicente", "title": "Direct information transfer rate optimisation for SSVEP-based BCI", "comments": null, "journal-ref": "Journal of neural engineering, 16(1), 016016 (2018)", "doi": "10.1088/1741-2552/aae8c7", "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, a classification method for SSVEP-based BCI is proposed. The\nclassification method uses features extracted by traditional SSVEP-based BCI\nmethods and finds optimal discrimination thresholds for each feature to\nclassify the targets. Optimising the thresholds is formalised as a maximisation\ntask of a performance measure of BCIs called information transfer rate (ITR).\nHowever, instead of the standard method of calculating ITR, which makes certain\nassumptions about the data, a more general formula is derived to avoid\nincorrect ITR calculation when the standard assumptions are not met. This\nallows the optimal discrimination thresholds to be automatically calculated and\nthus eliminates the need for manual parameter selection or performing\ncomputationally expensive grid searches. The proposed method shows good\nperformance in classifying targets of a BCI, outperforming previously reported\nresults on the same dataset by a factor of 2 in terms of ITR. The highest\nachieved ITR on the used dataset was 62 bit/min. The proposed method also\nprovides a way to reduce false classifications, which is important in\nreal-world applications.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jul 2019 23:09:51 GMT"}], "update_date": "2019-07-25", "authors_parsed": [["Ingel", "Anti", ""], ["Kuzovkin", "Ilya", ""], ["Vicente", "Raul", ""]]}, {"id": "1907.10515", "submitter": "Kourosh Hakhamaneshi", "authors": "Kourosh Hakhamaneshi, Nick Werblun, Pieter Abbeel, Vladimir Stojanovic", "title": "BagNet: Berkeley Analog Generator with Layout Optimizer Boosted with\n  Deep Neural Networks", "comments": "Accepted on ICCAD 2019 Conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The discrepancy between post-layout and schematic simulation results\ncontinues to widen in analog design due in part to the domination of layout\nparasitics. This paradigm shift is forcing designers to adopt design\nmethodologies that seamlessly integrate layout effects into the standard design\nflow. Hence, any simulation-based optimization framework should take into\naccount time-consuming post-layout simulation results. This work presents a\nlearning framework that learns to reduce the number of simulations of\nevolutionary-based combinatorial optimizers, using a DNN that discriminates\nagainst generated samples, before running simulations. Using this approach, the\ndiscriminator achieves at least two orders of magnitude improvement on sample\nefficiency for several large circuit examples including an optical link\nreceiver layout.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jul 2019 05:02:51 GMT"}], "update_date": "2019-07-25", "authors_parsed": [["Hakhamaneshi", "Kourosh", ""], ["Werblun", "Nick", ""], ["Abbeel", "Pieter", ""], ["Stojanovic", "Vladimir", ""]]}, {"id": "1907.10516", "submitter": "Ganesh Ghalme", "authors": "Vishakha Patil, Ganesh Ghalme, Vineet Nair, Y. Narahari", "title": "Achieving Fairness in the Stochastic Multi-armed Bandit Problem", "comments": "arXiv admin note: substantial text overlap with arXiv:1905.11260", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study an interesting variant of the stochastic multi-armed bandit problem,\ncalled the Fair-SMAB problem, where each arm is required to be pulled for at\nleast a given fraction of the total available rounds. We investigate the\ninterplay between learning and fairness in terms of a pre-specified vector\ndenoting the fractions of guaranteed pulls. We define a fairness-aware regret,\ncalled $r$-Regret, that takes into account the above fairness constraints and\nnaturally extends the conventional notion of regret. Our primary contribution\nis characterizing a class of Fair-SMAB algorithms by two parameters: the\nunfairness tolerance and the learning algorithm used as a black-box. We provide\na fairness guarantee for this class that holds uniformly over time irrespective\nof the choice of the learning algorithm. In particular, when the learning\nalgorithm is UCB1, we show that our algorithm achieves $O(\\ln T)$ $r$-Regret.\nFinally, we evaluate the cost of fairness in terms of the conventional notion\nof regret.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jul 2019 04:02:56 GMT"}, {"version": "v2", "created": "Wed, 5 Feb 2020 11:13:33 GMT"}], "update_date": "2020-02-06", "authors_parsed": [["Patil", "Vishakha", ""], ["Ghalme", "Ganesh", ""], ["Nair", "Vineet", ""], ["Narahari", "Y.", ""]]}, {"id": "1907.10518", "submitter": "Damian Pascual", "authors": "Damian Pascual, Amir Aminifar, David Atienza, Philippe Ryvlin, Roger\n  Wattenhofer", "title": "Synthetic Epileptic Brain Activities Using Generative Adversarial\n  Networks", "comments": "Machine Learning for Health (ML4H) at NeurIPS 2019 - Extended\n  Abstract", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Epilepsy is a chronic neurological disorder affecting more than 65 million\npeople worldwide and manifested by recurrent unprovoked seizures. The\nunpredictability of seizures not only degrades the quality of life of the\npatients, but it can also be life-threatening. Modern systems monitoring\nelectroencephalography (EEG) signals are being currently developed with the\nview to detect epileptic seizures in order to alert caregivers and reduce the\nimpact of seizures on patients' quality of life. Such seizure detection systems\nemploy state-of-the-art machine learning algorithms that require a considerably\nlarge amount of labeled personal data for training. However, acquiring EEG\nsignals of epileptic seizures is a costly and time-consuming process for\nmedical experts and patients, currently requiring in-hospital recordings in\nspecialized units. In this work, we generate synthetic seizure-like brain\nelectrical activities, i.e., EEG signals, that can be used to train seizure\ndetection algorithms, alleviating the need for recorded data. First, we train a\nGenerative Adversarial Network (GAN) with data from 30 epilepsy patients. Then,\nwe generate synthetic personalized training sets for new, unseen patients,\nwhich overall yield higher detection performance than the real-data training\nsets. We demonstrate our results using the datasets from the EPILEPSIAE\nProject, one of the world's largest public databases for seizure detection.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jul 2019 18:05:55 GMT"}, {"version": "v2", "created": "Fri, 1 Nov 2019 10:09:01 GMT"}, {"version": "v3", "created": "Tue, 12 Nov 2019 13:35:19 GMT"}], "update_date": "2019-11-13", "authors_parsed": [["Pascual", "Damian", ""], ["Aminifar", "Amir", ""], ["Atienza", "David", ""], ["Ryvlin", "Philippe", ""], ["Wattenhofer", "Roger", ""]]}, {"id": "1907.10529", "submitter": "Mandar Joshi", "authors": "Mandar Joshi, Danqi Chen, Yinhan Liu, Daniel S. Weld, Luke\n  Zettlemoyer, Omer Levy", "title": "SpanBERT: Improving Pre-training by Representing and Predicting Spans", "comments": "Accepted at TACL", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present SpanBERT, a pre-training method that is designed to better\nrepresent and predict spans of text. Our approach extends BERT by (1) masking\ncontiguous random spans, rather than random tokens, and (2) training the span\nboundary representations to predict the entire content of the masked span,\nwithout relying on the individual token representations within it. SpanBERT\nconsistently outperforms BERT and our better-tuned baselines, with substantial\ngains on span selection tasks such as question answering and coreference\nresolution. In particular, with the same training data and model size as\nBERT-large, our single model obtains 94.6% and 88.7% F1 on SQuAD 1.1 and 2.0,\nrespectively. We also achieve a new state of the art on the OntoNotes\ncoreference resolution task (79.6\\% F1), strong performance on the TACRED\nrelation extraction benchmark, and even show gains on GLUE.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jul 2019 15:43:40 GMT"}, {"version": "v2", "created": "Wed, 31 Jul 2019 17:13:57 GMT"}, {"version": "v3", "created": "Sat, 18 Jan 2020 03:53:04 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Joshi", "Mandar", ""], ["Chen", "Danqi", ""], ["Liu", "Yinhan", ""], ["Weld", "Daniel S.", ""], ["Zettlemoyer", "Luke", ""], ["Levy", "Omer", ""]]}, {"id": "1907.10552", "submitter": "Tam\\'as Kriv\\'achy", "authors": "Tam\\'as Kriv\\'achy, Yu Cai, Daniel Cavalcanti, Arash Tavakoli, Nicolas\n  Gisin, Nicolas Brunner", "title": "A neural network oracle for quantum nonlocality problems in networks", "comments": "This is a pre-print of an article published in npj Quantum\n  Information. The final authenticated version is available online at:\n  https://doi.org/10.1038/s41534-020-00305-x Implementation can be found at:\n  https://github.com/tkrivachy/neural-network-for-nonlocality-in-networks", "journal-ref": "npj Quantum Inf 6, 70 (2020)", "doi": "10.1038/s41534-020-00305-x", "report-no": null, "categories": "quant-ph cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Characterizing quantum nonlocality in networks is a challenging, but\nimportant problem. Using quantum sources one can achieve distributions which\nare unattainable classically. A key point in investigations is to decide\nwhether an observed probability distribution can be reproduced using only\nclassical resources. This causal inference task is challenging even for simple\nnetworks, both analytically and using standard numerical techniques. We propose\nto use neural networks as numerical tools to overcome these challenges, by\nlearning the classical strategies required to reproduce a distribution. As\nsuch, the neural network acts as an oracle, demonstrating that a behavior is\nclassical if it can be learned. We apply our method to several examples in the\ntriangle configuration. After demonstrating that the method is consistent with\npreviously known results, we give solid evidence that the distribution\npresented in [N. Gisin, Entropy 21(3), 325 (2019)] is indeed nonlocal as\nconjectured. Finally we examine the genuinely nonlocal distribution presented\nin [M.-O. Renou et al., PRL 123, 140401 (2019)], and, guided by the findings of\nthe neural network, conjecture nonlocality in a new range of parameters in\nthese distributions. The method allows us to get an estimate on the noise\nrobustness of all examined distributions.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jul 2019 16:43:13 GMT"}, {"version": "v2", "created": "Thu, 14 Nov 2019 13:29:18 GMT"}, {"version": "v3", "created": "Mon, 7 Sep 2020 14:17:23 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Kriv\u00e1chy", "Tam\u00e1s", ""], ["Cai", "Yu", ""], ["Cavalcanti", "Daniel", ""], ["Tavakoli", "Arash", ""], ["Gisin", "Nicolas", ""], ["Brunner", "Nicolas", ""]]}, {"id": "1907.10580", "submitter": "Nirbhay Modhe", "authors": "Nirbhay Modhe, Prithvijit Chattopadhyay, Mohit Sharma, Abhishek Das,\n  Devi Parikh, Dhruv Batra, Ramakrishna Vedantam", "title": "IR-VIC: Unsupervised Discovery of Sub-goals for Transfer in RL", "comments": null, "journal-ref": null, "doi": "10.24963/ijcai.2020/280", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel framework to identify sub-goals useful for exploration in\nsequential decision making tasks under partial observability. We utilize the\nvariational intrinsic control framework (Gregor et.al., 2016) which maximizes\nempowerment -- the ability to reliably reach a diverse set of states and show\nhow to identify sub-goals as states with high necessary option information\nthrough an information theoretic regularizer. Despite being discovered without\nexplicit goal supervision, our sub-goals provide better exploration and sample\ncomplexity on challenging grid-world navigation tasks compared to supervised\ncounterparts in prior work.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jul 2019 17:30:39 GMT"}, {"version": "v2", "created": "Thu, 15 Aug 2019 15:17:00 GMT"}, {"version": "v3", "created": "Tue, 15 Oct 2019 15:59:01 GMT"}, {"version": "v4", "created": "Sat, 4 Jul 2020 20:47:39 GMT"}, {"version": "v5", "created": "Sun, 3 Jan 2021 17:37:08 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Modhe", "Nirbhay", ""], ["Chattopadhyay", "Prithvijit", ""], ["Sharma", "Mohit", ""], ["Das", "Abhishek", ""], ["Parikh", "Devi", ""], ["Batra", "Dhruv", ""], ["Vedantam", "Ramakrishna", ""]]}, {"id": "1907.10585", "submitter": "JinHong Lu", "authors": "JinHong Lu, Hiroshi Shimodaira", "title": "A neural network based post-filter for speech-driven head motion\n  synthesis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the fact that neural networks are widely used for speech-driven head\nmotion synthesis, it is well-known that the output of neural networks is noisy\nor discontinuous due to the limited capability of deep neural networks in\npredicting human motion. Thus, post-processing is required to obtain smooth\nhead motion trajectories for animation. It is common to apply a linear filter\nor consider keyframes as post-processing. However, neither approach is optimal\nas there is always a trade-off between smoothness and accuracy. We propose to\nemploy a neural network trained in a way that it is capable of reconstructing\nthe head motions, in order to overcome this limitation. In the objective\nevaluation, this filter is proved to be good at de-noising data involving types\nof noise (dropout or Gaussian noise). Objective metrics also demonstrate the\nimprovement of the joined head motion's smoothness after being processed by our\nproposed filter. A detailed analysis reveals that our proposed filter learns\nthe characteristic of head motions. The subjective evaluation shows that\nparticipants were unable to distinguish the synthesised head motions with our\nproposed filter from ground truth, which was preferred over the Gaussian filter\nand moving average.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jul 2019 17:38:37 GMT"}, {"version": "v2", "created": "Thu, 25 Jul 2019 00:54:33 GMT"}], "update_date": "2019-07-26", "authors_parsed": [["Lu", "JinHong", ""], ["Shimodaira", "Hiroshi", ""]]}, {"id": "1907.10592", "submitter": "Cathy Maugis-Rabusseau", "authors": "Yohann de Castro (ECL, ICJ), S\\'ebastien Gadat (TSE), Cl\\'ement\n  Marteau (ICJ), Cathy Maugis (IMT)", "title": "SuperMix: Sparse Regularization for Mixtures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates the statistical estimation of a discrete mixing\nmeasure $\\mu$0 involved in a kernel mixture model. Using some recent advances\nin l1-regularization over the space of measures, we introduce a \"data fitting\nand regularization\" convex program for estimating $\\mu$0 in a grid-less manner\nfrom a sample of mixture law, this method is referred to as Beurling-LASSO. Our\ncontribution is twofold: we derive a lower bound on the bandwidth of our data\nfitting term depending only on the support of $\\mu$0 and its so-called \"minimum\nseparation\" to ensure quantitative support localization error bounds; and under\na so-called \"non-degenerate source condition\" we derive a non-asymptotic\nsupport stability property. This latter shows that for a sufficiently large\nsample size n, our estimator has exactly as many weighted Dirac masses as the\ntarget $\\mu$0 , converging in amplitude and localization towards the true ones.\nFinally, we also introduce some tractable algorithms for solving this convex\nprogram based on \"Sliding Frank-Wolfe\" or \"Conic Particle Gradient Descent\".\nStatistical performances of this estimator are investigated designing a\nso-called \"dual certificate\", which is appropriate to our setting. Some\nclassical situations, as e.g. mixtures of super-smooth distributions (e.g.\nGaussian distributions) or ordinary-smooth distributions (e.g. Laplace\ndistributions), are discussed at the end of the paper.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jul 2019 08:45:57 GMT"}, {"version": "v2", "created": "Thu, 18 Jun 2020 19:07:32 GMT"}], "update_date": "2020-06-22", "authors_parsed": [["de Castro", "Yohann", "", "ECL, ICJ"], ["Gadat", "S\u00e9bastien", "", "TSE"], ["Marteau", "Cl\u00e9ment", "", "ICJ"], ["Maugis", "Cathy", "", "IMT"]]}, {"id": "1907.10595", "submitter": "Amirhossein Reisizadeh", "authors": "Amirhossein Reisizadeh, Hossein Taheri, Aryan Mokhtari, Hamed Hassani,\n  Ramtin Pedarsani", "title": "Robust and Communication-Efficient Collaborative Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a decentralized learning problem, where a set of computing nodes\naim at solving a non-convex optimization problem collaboratively. It is\nwell-known that decentralized optimization schemes face two major system\nbottlenecks: stragglers' delay and communication overhead. In this paper, we\ntackle these bottlenecks by proposing a novel decentralized and gradient-based\noptimization algorithm named as QuanTimed-DSGD. Our algorithm stands on two\nmain ideas: (i) we impose a deadline on the local gradient computations of each\nnode at each iteration of the algorithm, and (ii) the nodes exchange quantized\nversions of their local models. The first idea robustifies to straggling nodes\nand the second alleviates communication efficiency. The key technical\ncontribution of our work is to prove that with non-vanishing noises for\nquantization and stochastic gradients, the proposed method exactly converges to\nthe global optimal for convex loss functions, and finds a first-order\nstationary point in non-convex scenarios. Our numerical evaluations of the\nQuanTimed-DSGD on training benchmark datasets, MNIST and CIFAR-10, demonstrate\nspeedups of up to 3x in run-time, compared to state-of-the-art decentralized\noptimization methods.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jul 2019 17:55:44 GMT"}, {"version": "v2", "created": "Thu, 31 Oct 2019 21:53:56 GMT"}], "update_date": "2019-11-04", "authors_parsed": [["Reisizadeh", "Amirhossein", ""], ["Taheri", "Hossein", ""], ["Mokhtari", "Aryan", ""], ["Hassani", "Hamed", ""], ["Pedarsani", "Ramtin", ""]]}, {"id": "1907.10597", "submitter": "Roy Schwartz", "authors": "Roy Schwartz, Jesse Dodge, Noah A. Smith, Oren Etzioni", "title": "Green AI", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CL cs.CV cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The computations required for deep learning research have been doubling every\nfew months, resulting in an estimated 300,000x increase from 2012 to 2018 [2].\nThese computations have a surprisingly large carbon footprint [38]. Ironically,\ndeep learning was inspired by the human brain, which is remarkably energy\nefficient. Moreover, the financial cost of the computations can make it\ndifficult for academics, students, and researchers, in particular those from\nemerging economies, to engage in deep learning research.\n  This position paper advocates a practical solution by making efficiency an\nevaluation criterion for research alongside accuracy and related measures. In\naddition, we propose reporting the financial cost or \"price tag\" of developing,\ntraining, and running models to provide baselines for the investigation of\nincreasingly efficient methods. Our goal is to make AI both greener and more\ninclusive---enabling any inspired undergraduate with a laptop to write\nhigh-quality research papers. Green AI is an emerging focus at the Allen\nInstitute for AI.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jul 2019 19:36:18 GMT"}, {"version": "v2", "created": "Thu, 25 Jul 2019 02:54:44 GMT"}, {"version": "v3", "created": "Tue, 13 Aug 2019 20:09:57 GMT"}], "update_date": "2019-08-15", "authors_parsed": [["Schwartz", "Roy", ""], ["Dodge", "Jesse", ""], ["Smith", "Noah A.", ""], ["Etzioni", "Oren", ""]]}, {"id": "1907.10599", "submitter": "Greg Yang", "authors": "Greg Yang and Hadi Salman", "title": "A Fine-Grained Spectral Perspective on Neural Networks", "comments": "8 pages of main text, 19 figures, 51 pages including appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Are neural networks biased toward simple functions? Does depth always help\nlearn more complex features? Is training the last layer of a network as good as\ntraining all layers? How to set the range for learning rate tuning? These\nquestions seem unrelated at face value, but in this work we give all of them a\ncommon treatment from the spectral perspective. We will study the spectra of\nthe *Conjugate Kernel, CK,* (also called the *Neural Network-Gaussian Process\nKernel*), and the *Neural Tangent Kernel, NTK*. Roughly, the CK and the NTK\ntell us respectively \"what a network looks like at initialization\" and \"what a\nnetwork looks like during and after training.\" Their spectra then encode\nvaluable information about the initial distribution and the training and\ngeneralization properties of neural networks. By analyzing the eigenvalues, we\nlend novel insights into the questions put forth at the beginning, and we\nverify these insights by extensive experiments of neural networks. We derive\nfast algorithms for computing the spectra of CK and NTK when the data is\nuniformly distributed over the boolean cube, and show this spectra is the same\nin high dimensions when data is drawn from isotropic Gaussian or uniformly over\nthe sphere. Code replicating our results is available at\ngithub.com/thegregyang/NNspectra.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jul 2019 17:58:45 GMT"}, {"version": "v2", "created": "Sun, 22 Sep 2019 23:05:20 GMT"}, {"version": "v3", "created": "Sat, 4 Apr 2020 21:12:24 GMT"}, {"version": "v4", "created": "Thu, 9 Apr 2020 15:12:11 GMT"}], "update_date": "2020-04-10", "authors_parsed": [["Yang", "Greg", ""], ["Salman", "Hadi", ""]]}, {"id": "1907.10628", "submitter": "Vinod Kumar Kurmi", "authors": "Vinod Kumar Kurmi, Vipul Bajaj, Venkatesh K Subramanian, Vinay P\n  Namboodiri", "title": "Curriculum based Dropout Discriminator for Domain Adaptation", "comments": "BMVC 2019 Accepted, Project Page:\n  https://delta-lab-iitk.github.io/CD3A/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Domain adaptation is essential to enable wide usage of deep learning based\nnetworks trained using large labeled datasets. Adversarial learning based\ntechniques have shown their utility towards solving this problem using a\ndiscriminator that ensures source and target distributions are close. However,\nhere we suggest that rather than using a point estimate, it would be useful if\na distribution based discriminator could be used to bridge this gap. This could\nbe achieved using multiple classifiers or using traditional ensemble methods.\nIn contrast, we suggest that a Monte Carlo dropout based ensemble discriminator\ncould suffice to obtain the distribution based discriminator. Specifically, we\npropose a curriculum based dropout discriminator that gradually increases the\nvariance of the sample based distribution and the corresponding reverse\ngradients are used to align the source and target feature representations. The\ndetailed results and thorough ablation analysis show that our model outperforms\nstate-of-the-art results.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jul 2019 18:00:12 GMT"}, {"version": "v2", "created": "Sat, 19 Oct 2019 19:43:26 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Kurmi", "Vinod Kumar", ""], ["Bajaj", "Vipul", ""], ["Subramanian", "Venkatesh K", ""], ["Namboodiri", "Vinay P", ""]]}, {"id": "1907.10634", "submitter": "Andrea Palazzi", "authors": "Andrea Palazzi, Luca Bergamini, Simone Calderara, Rita Cucchiara", "title": "Warp and Learn: Novel Views Generation for Vehicles and Other Objects", "comments": "IEEE Transactions on Pattern Analysis and Machine Intelligence", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we introduce a new self-supervised, semi-parametric approach for\nsynthesizing novel views of a vehicle starting from a single monocular image.\nDifferently from parametric (i.e. entirely learning-based) methods, we show how\na-priori geometric knowledge about the object and the 3D world can be\nsuccessfully integrated into a deep learning based image generation framework.\nAs this geometric component is not learnt, we call our approach\nsemi-parametric. In particular, we exploit man-made object symmetry and\npiece-wise planarity to integrate rich a-priori visual information into the\nnovel viewpoint synthesis process. An Image Completion Network (ICN) is then\ntrained to generate a realistic image starting from this geometric guidance.\nThis careful blend between parametric and non-parametric components allows us\nto i) operate in a real-world scenario, ii) preserve high-frequency visual\ninformation such as textures, iii) handle truly arbitrary 3D roto-translations\nof the input and iv) perform shape transfer to completely different 3D models.\nEventually, we show that our approach can be easily complemented with synthetic\ndata and extended to other rigid objects with completely different topology,\neven in presence of concave structures and holes (e.g. chairs). A comprehensive\nexperimental analysis against state-of-the-art competitors shows the efficacy\nof our method both from a quantitative and a perceptive point of view.\nSupplementary material, animated results, code and data are available at:\nhttps://github.com/ndrplz/semiparametric\n", "versions": [{"version": "v1", "created": "Wed, 24 Jul 2019 18:01:51 GMT"}, {"version": "v2", "created": "Mon, 11 Nov 2019 12:44:51 GMT"}, {"version": "v3", "created": "Sat, 10 Oct 2020 15:21:58 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Palazzi", "Andrea", ""], ["Bergamini", "Luca", ""], ["Calderara", "Simone", ""], ["Cucchiara", "Rita", ""]]}, {"id": "1907.10662", "submitter": "Xuankang Lin", "authors": "Xuankang Lin, He Zhu, Roopsha Samanta, Suresh Jagannathan", "title": "ART: Abstraction Refinement-Guided Training for Provably Correct Neural\n  Networks", "comments": "FMCAD'20", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.PL cs.SC stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Artificial Neural Networks (ANNs) have demonstrated remarkable utility in\nvarious challenging machine learning applications. While formally verified\nproperties of their behaviors are highly desired, they have proven notoriously\ndifficult to derive and enforce. Existing approaches typically formulate this\nproblem as a post facto analysis process. In this paper, we present a novel\nlearning framework that ensures such formal guarantees are enforced by\nconstruction. Our technique enables training provably correct networks with\nrespect to a broad class of safety properties, a capability that goes\nwell-beyond existing approaches, without compromising much accuracy. Our key\ninsight is that we can integrate an optimization-based abstraction refinement\nloop into the learning process and operate over dynamically constructed\npartitions of the input space that considers accuracy and safety objectives\nsynergistically. The refinement procedure iteratively splits the input space\nfrom which training data is drawn, guided by the efficacy with which such\npartitions enable safety verification. We have implemented our approach in a\ntool (ART) and applied it to enforce general safety properties on unmanned\naviator collision avoidance system ACAS Xu dataset and the Collision Detection\ndataset. Importantly, we empirically demonstrate that realizing safety does not\ncome at the price of much accuracy. Our methodology demonstrates that an\nabstraction refinement methodology provides a meaningful pathway for building\nboth accurate and correct machine learning networks.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jul 2019 16:58:33 GMT"}, {"version": "v2", "created": "Fri, 26 Jul 2019 02:42:17 GMT"}, {"version": "v3", "created": "Thu, 1 Oct 2020 21:49:51 GMT"}], "update_date": "2020-10-05", "authors_parsed": [["Lin", "Xuankang", ""], ["Zhu", "He", ""], ["Samanta", "Roopsha", ""], ["Jagannathan", "Suresh", ""]]}, {"id": "1907.10697", "submitter": "Kari Torkkola", "authors": "Ruofeng Wen, Kari Torkkola", "title": "Deep Generative Quantile-Copula Models for Probabilistic Forecasting", "comments": "Published at the 36th International Conference on Machine Learning\n  (ICML2019), Time Series Workshop, Long Beach, California, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new category of multivariate conditional generative models and\ndemonstrate its performance and versatility in probabilistic time series\nforecasting and simulation. Specifically, the output of quantile regression\nnetworks is expanded from a set of fixed quantiles to the whole Quantile\nFunction by a univariate mapping from a latent uniform distribution to the\ntarget distribution. Then the multivariate case is solved by learning such\nquantile functions for each dimension's marginal distribution, followed by\nestimating a conditional Copula to associate these latent uniform random\nvariables. The quantile functions and copula, together defining the joint\npredictive distribution, can be parameterized by a single implicit generative\nDeep Neural Network.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jul 2019 20:11:41 GMT"}], "update_date": "2019-07-26", "authors_parsed": [["Wen", "Ruofeng", ""], ["Torkkola", "Kari", ""]]}, {"id": "1907.10701", "submitter": "Yu Emma Wang", "authors": "Yu Emma Wang, Gu-Yeon Wei, David Brooks", "title": "Benchmarking TPU, GPU, and CPU Platforms for Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.PF stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Training deep learning models is compute-intensive and there is an\nindustry-wide trend towards hardware specialization to improve performance. To\nsystematically benchmark deep learning platforms, we introduce ParaDnn, a\nparameterized benchmark suite for deep learning that generates end-to-end\nmodels for fully connected (FC), convolutional (CNN), and recurrent (RNN)\nneural networks. Along with six real-world models, we benchmark Google's Cloud\nTPU v2/v3, NVIDIA's V100 GPU, and an Intel Skylake CPU platform. We take a deep\ndive into TPU architecture, reveal its bottlenecks, and highlight valuable\nlessons learned for future specialized system design. We also provide a\nthorough comparison of the platforms and find that each has unique strengths\nfor some types of models. Finally, we quantify the rapid performance\nimprovements that specialized software stacks provide for the TPU and GPU\nplatforms.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jul 2019 20:18:28 GMT"}, {"version": "v2", "created": "Wed, 31 Jul 2019 20:27:59 GMT"}, {"version": "v3", "created": "Tue, 6 Aug 2019 21:30:47 GMT"}, {"version": "v4", "created": "Tue, 22 Oct 2019 06:07:55 GMT"}], "update_date": "2019-10-23", "authors_parsed": [["Wang", "Yu Emma", ""], ["Wei", "Gu-Yeon", ""], ["Brooks", "David", ""]]}, {"id": "1907.10709", "submitter": "Giulio Siracusano Dr.", "authors": "Giulio Siracusano, Aurelio La Corte, Riccardo Tomasello, Francesco\n  Lamonaca, Carmelo Scuro, Francesca Garesc\\`i, Mario Carpentieri and Giovanni\n  Finocchio", "title": "Automatic crack detection and classification by exploiting statistical\n  event descriptors for Deep Learning", "comments": "34 pages, 2 tables, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In modern building infrastructures, the chance to devise adaptive and\nunsupervised data-driven health monitoring systems is gaining in popularity due\nto the large availability of data from low-cost sensors with internetworking\ncapabilities. In particular, deep learning provides the tools for processing\nand analyzing this unprecedented amount of data efficiently. The main purpose\nof this paper is to combine the recent advances of Deep Learning (DL) and\nstatistical analysis on structural health monitoring (SHM) to develop an\naccurate classification tool able to discriminate among different acoustic\nemission events (cracks) by means of the identification of tensile, shear and\nmixed modes. The applications of DL in SHM systems is described by using the\nconcept of Bidirectional Long Short Term Memory. We investigated on effective\nevent descriptors to capture the unique characteristics from the different\ntypes of modes. Among them, Spectral Kurtosis and Spectral L2/L1 Norm exhibit\ndistinctive behavior and effectively contributed to the learning process. This\nclassification will contribute to unambiguously detect incipient damages, which\nis advantageous to realize predictive maintenance. Tests on experimental\nresults confirm that this method achieves accurate classification (92%)\ncapabilities of crack events and can impact on the design of future SHM\ntechnologies.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jul 2019 20:39:49 GMT"}], "update_date": "2019-07-26", "authors_parsed": [["Siracusano", "Giulio", ""], ["La Corte", "Aurelio", ""], ["Tomasello", "Riccardo", ""], ["Lamonaca", "Francesco", ""], ["Scuro", "Carmelo", ""], ["Garesc\u00ec", "Francesca", ""], ["Carpentieri", "Mario", ""], ["Finocchio", "Giovanni", ""]]}, {"id": "1907.10726", "submitter": "Suyoun Kim", "authors": "Suyoun Kim, Siddharth Dalmia, Florian Metze", "title": "Cross-Attention End-to-End ASR for Two-Party Conversations", "comments": "Interspeech 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an end-to-end speech recognition model that learns interaction\nbetween two speakers based on the turn-changing information. Unlike\nconventional speech recognition models, our model exploits two speakers'\nhistory of conversational-context information that spans across multiple turns\nwithin an end-to-end framework. Specifically, we propose a speaker-specific\ncross-attention mechanism that can look at the output of the other speaker side\nas well as the one of the current speaker for better at recognizing long\nconversations. We evaluated the models on the Switchboard conversational speech\ncorpus and show that our model outperforms standard end-to-end speech\nrecognition models.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jul 2019 21:18:39 GMT"}], "update_date": "2019-07-26", "authors_parsed": [["Kim", "Suyoun", ""], ["Dalmia", "Siddharth", ""], ["Metze", "Florian", ""]]}, {"id": "1907.10732", "submitter": "Xinyan Li", "authors": "Xinyan Li, Qilong Gu, Yingxue Zhou, Tiancong Chen, and Arindam\n  Banerjee", "title": "Hessian based analysis of SGD for Deep Nets: Dynamics and Generalization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While stochastic gradient descent (SGD) and variants have been surprisingly\nsuccessful for training deep nets, several aspects of the optimization dynamics\nand generalization are still not well understood. In this paper, we present new\nempirical observations and theoretical results on both the optimization\ndynamics and generalization behavior of SGD for deep nets based on the Hessian\nof the training loss and associated quantities. We consider three specific\nresearch questions: (1) what is the relationship between the Hessian of the\nloss and the second moment of stochastic gradients (SGs)? (2) how can we\ncharacterize the stochastic optimization dynamics of SGD with fixed and\nadaptive step sizes and diagonal pre-conditioning based on the first and second\nmoments of SGs? and (3) how can we characterize a scale-invariant\ngeneralization bound of deep nets based on the Hessian of the loss, which by\nitself is not scale invariant? We shed light on these three questions using\ntheoretical results supported by extensive empirical observations, with\nexperiments on synthetic data, MNIST, and CIFAR-10, with different batch sizes,\nand with different difficulty levels by synthetically adding random labels.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jul 2019 21:27:13 GMT"}], "update_date": "2019-07-26", "authors_parsed": [["Li", "Xinyan", ""], ["Gu", "Qilong", ""], ["Zhou", "Yingxue", ""], ["Chen", "Tiancong", ""], ["Banerjee", "Arindam", ""]]}, {"id": "1907.10737", "submitter": "Haichao Zhang", "authors": "Haichao Zhang, Jianyu Wang", "title": "Joint Adversarial Training: Incorporating both Spatial and Pixel Attacks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conventional adversarial training methods using attacks that manipulate the\npixel value directly and individually, leading to models that are less robust\nin face of spatial transformation-based attacks. In this paper, we propose a\njoint adversarial training method that incorporates both spatial\ntransformation-based and pixel-value based attacks for improving model\nrobustness. We introduce a spatial transformation-based attack with an explicit\nnotion of budget and develop an algorithm for spatial attack generation. We\nfurther integrate both pixel and spatial attacks into one generation model and\nshow how to leverage the complementary strengths of each other in training for\nimproving the overall model robustness. Extensive experimental results on\ndifferent benchmark datasets compared with state-of-the-art methods verified\nthe effectiveness of the proposed method.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jul 2019 21:36:27 GMT"}, {"version": "v2", "created": "Wed, 31 Jul 2019 05:28:27 GMT"}], "update_date": "2019-08-01", "authors_parsed": [["Zhang", "Haichao", ""], ["Wang", "Jianyu", ""]]}, {"id": "1907.10738", "submitter": "Pratyay Banerjee", "authors": "Pratyay Banerjee, Kuntal Kumar Pal, Arindam Mitra, Chitta Baral", "title": "Careful Selection of Knowledge to solve Open Book Question Answering", "comments": "Accepted to ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Open book question answering is a type of natural language based QA (NLQA)\nwhere questions are expected to be answered with respect to a given set of open\nbook facts, and common knowledge about a topic. Recently a challenge involving\nsuch QA, OpenBookQA, has been proposed. Unlike most other NLQA tasks that focus\non linguistic understanding, OpenBookQA requires deeper reasoning involving\nlinguistic understanding as well as reasoning with common knowledge. In this\npaper we address QA with respect to the OpenBookQA dataset and combine state of\nthe art language models with abductive information retrieval (IR), information\ngain based re-ranking, passage selection and weighted scoring to achieve 72.0%\naccuracy, an 11.6% improvement over the current state of the art.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jul 2019 21:37:16 GMT"}], "update_date": "2019-07-26", "authors_parsed": [["Banerjee", "Pratyay", ""], ["Pal", "Kuntal Kumar", ""], ["Mitra", "Arindam", ""], ["Baral", "Chitta", ""]]}, {"id": "1907.10739", "submitter": "Sebastian Gehrmann", "authors": "Sebastian Gehrmann, Hendrik Strobelt, Robert Kr\\\"uger, Hanspeter\n  Pfister, Alexander M. Rush", "title": "Visual Interaction with Deep Learning Models through Collaborative\n  Semantic Inference", "comments": "IEEE VIS 2019 (VAST)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automation of tasks can have critical consequences when humans lose agency\nover decision processes. Deep learning models are particularly susceptible\nsince current black-box approaches lack explainable reasoning. We argue that\nboth the visual interface and model structure of deep learning systems need to\ntake into account interaction design. We propose a framework of collaborative\nsemantic inference (CSI) for the co-design of interactions and models to enable\nvisual collaboration between humans and algorithms. The approach exposes the\nintermediate reasoning process of models which allows semantic interactions\nwith the visual metaphors of a problem, which means that a user can both\nunderstand and control parts of the model reasoning process. We demonstrate the\nfeasibility of CSI with a co-designed case study of a document summarization\nsystem.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jul 2019 21:37:29 GMT"}], "update_date": "2019-07-26", "authors_parsed": [["Gehrmann", "Sebastian", ""], ["Strobelt", "Hendrik", ""], ["Kr\u00fcger", "Robert", ""], ["Pfister", "Hanspeter", ""], ["Rush", "Alexander M.", ""]]}, {"id": "1907.10747", "submitter": "Ankit Singh Rawat", "authors": "Ankit Singh Rawat, Jiecao Chen, Felix Yu, Ananda Theertha Suresh,\n  Sanjiv Kumar", "title": "Sampled Softmax with Random Fourier Features", "comments": "In NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The computational cost of training with softmax cross entropy loss grows\nlinearly with the number of classes. For the settings where a large number of\nclasses are involved, a common method to speed up training is to sample a\nsubset of classes and utilize an estimate of the loss gradient based on these\nclasses, known as the sampled softmax method. However, the sampled softmax\nprovides a biased estimate of the gradient unless the samples are drawn from\nthe exact softmax distribution, which is again expensive to compute. Therefore,\na widely employed practical approach involves sampling from a simpler\ndistribution in the hope of approximating the exact softmax distribution. In\nthis paper, we develop the first theoretical understanding of the role that\ndifferent sampling distributions play in determining the quality of sampled\nsoftmax. Motivated by our analysis and the work on kernel-based sampling, we\npropose the Random Fourier Softmax (RF-softmax) method that utilizes the\npowerful Random Fourier Features to enable more efficient and accurate sampling\nfrom an approximate softmax distribution. We show that RF-softmax leads to low\nbias in estimation in terms of both the full softmax distribution and the full\nsoftmax gradient. Furthermore, the cost of RF-softmax scales only\nlogarithmically with the number of classes.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jul 2019 22:04:42 GMT"}, {"version": "v2", "created": "Tue, 31 Dec 2019 16:59:14 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Rawat", "Ankit Singh", ""], ["Chen", "Jiecao", ""], ["Yu", "Felix", ""], ["Suresh", "Ananda Theertha", ""], ["Kumar", "Sanjiv", ""]]}, {"id": "1907.10761", "submitter": "Mikel Artetxe", "authors": "Mikel Artetxe, Gorka Labaka, Eneko Agirre", "title": "Bilingual Lexicon Induction through Unsupervised Machine Translation", "comments": "ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A recent research line has obtained strong results on bilingual lexicon\ninduction by aligning independently trained word embeddings in two languages\nand using the resulting cross-lingual embeddings to induce word translation\npairs through nearest neighbor or related retrieval methods. In this paper, we\npropose an alternative approach to this problem that builds on the recent work\non unsupervised machine translation. This way, instead of directly inducing a\nbilingual lexicon from cross-lingual embeddings, we use them to build a\nphrase-table, combine it with a language model, and use the resulting machine\ntranslation system to generate a synthetic parallel corpus, from which we\nextract the bilingual lexicon using statistical word alignment techniques. As\nsuch, our method can work with any word embedding and cross-lingual mapping\ntechnique, and it does not require any additional resource besides the\nmonolingual corpus used to train the embeddings. When evaluated on the exact\nsame cross-lingual embeddings, our proposed method obtains an average\nimprovement of 6 accuracy points over nearest neighbor and 4 points over CSLS\nretrieval, establishing a new state-of-the-art in the standard MUSE dataset.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jul 2019 22:30:04 GMT"}], "update_date": "2019-07-26", "authors_parsed": [["Artetxe", "Mikel", ""], ["Labaka", "Gorka", ""], ["Agirre", "Eneko", ""]]}, {"id": "1907.10763", "submitter": "Xiao-Yun Zhou", "authors": "Xiao-Yun Zhou, Zhao-Yang Wang, Peichao Li, Jian-Qing Zheng,\n  Guang-Zhong Yang", "title": "One-stage Shape Instantiation from a Single 2D Image to 3D Point Cloud", "comments": "8.5 pages, 5 figures, MICCAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Shape instantiation which predicts the 3D shape of a dynamic target from one\nor more 2D images is important for real-time intra-operative navigation.\nPreviously, a general shape instantiation framework was proposed with manual\nimage segmentation to generate a 2D Statistical Shape Model (SSM) and with\nKernel Partial Least Square Regression (KPLSR) to learn the relationship\nbetween the 2D and 3D SSM for 3D shape prediction. In this paper, the two-stage\nshape instantiation is improved to be one-stage. PointOutNet with 19\nconvolutional layers and three fully-connected layers is used as the network\nstructure and Chamfer distance is used as the loss function to predict the 3D\ntarget point cloud from a single 2D image. With the proposed one-stage shape\ninstantiation algorithm, a spontaneous image-to-point cloud training and\ninference can be achieved. A dataset from 27 Right Ventricle (RV) subjects,\nindicating 609 experiments, were used to validate the proposed one-stage shape\ninstantiation algorithm. An average point cloud-to-point cloud (PC-to-PC) error\nof 1.72mm has been achieved, which is comparable to the PLSR-based (1.42mm) and\nKPLSR-based (1.31mm) two-stage shape instantiation algorithm.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jul 2019 22:41:46 GMT"}], "update_date": "2019-07-26", "authors_parsed": [["Zhou", "Xiao-Yun", ""], ["Wang", "Zhao-Yang", ""], ["Li", "Peichao", ""], ["Zheng", "Jian-Qing", ""], ["Yang", "Guang-Zhong", ""]]}, {"id": "1907.10764", "submitter": "Haichao Zhang", "authors": "Haichao Zhang, Jianyu Wang", "title": "Defense Against Adversarial Attacks Using Feature Scattering-based\n  Adversarial Training", "comments": "Published at NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a feature scattering-based adversarial training approach for\nimproving model robustness against adversarial attacks. Conventional\nadversarial training approaches leverage a supervised scheme (either targeted\nor non-targeted) in generating attacks for training, which typically suffer\nfrom issues such as label leaking as noted in recent works. Differently, the\nproposed approach generates adversarial images for training through feature\nscattering in the latent space, which is unsupervised in nature and avoids\nlabel leaking. More importantly, this new approach generates perturbed images\nin a collaborative fashion, taking the inter-sample relationships into\nconsideration. We conduct analysis on model robustness and demonstrate the\neffectiveness of the proposed approach through extensively experiments on\ndifferent datasets compared with state-of-the-art approaches.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jul 2019 22:43:55 GMT"}, {"version": "v2", "created": "Fri, 26 Jul 2019 07:20:14 GMT"}, {"version": "v3", "created": "Mon, 29 Jul 2019 00:45:19 GMT"}, {"version": "v4", "created": "Thu, 21 Nov 2019 21:51:21 GMT"}], "update_date": "2019-11-25", "authors_parsed": [["Zhang", "Haichao", ""], ["Wang", "Jianyu", ""]]}, {"id": "1907.10772", "submitter": "Jorge Gustavo Madrid Perez", "authors": "Jorge G. Madrid, Hugo Jair Escalante, Eduardo F. Morales, Wei-Wei Tu,\n  Yang Yu, Lisheng Sun-Hosoya, Isabelle Guyon, Michele Sebag", "title": "Towards AutoML in the presence of Drift: first results", "comments": "AutoML 2018 @ ICML/IJCAI-ECAI", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Research progress in AutoML has lead to state of the art solutions that can\ncope quite wellwith supervised learning task, e.g., classification with\nAutoSklearn. However, so far thesesystems do not take into account the changing\nnature of evolving data over time (i.e., theystill assume i.i.d. data); even\nwhen this sort of domains are increasingly available in realapplications (e.g.,\nspam filtering, user preferences, etc.). We describe a first attempt to\nde-velop an AutoML solution for scenarios in which data distribution changes\nrelatively slowlyover time and in which the problem is approached in a lifelong\nlearning setting. We extendAuto-Sklearn with sound and intuitive mechanisms\nthat allow it to cope with this sort ofproblems. The extended Auto-Sklearn is\ncombined with concept drift detection techniquesthat allow it to automatically\ndetermine when the initial models have to be adapted. Wereport experimental\nresults in benchmark data from AutoML competitions that adhere tothis scenario.\nResults demonstrate the effectiveness of the proposed methodology.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jul 2019 23:28:37 GMT"}], "update_date": "2019-07-26", "authors_parsed": [["Madrid", "Jorge G.", ""], ["Escalante", "Hugo Jair", ""], ["Morales", "Eduardo F.", ""], ["Tu", "Wei-Wei", ""], ["Yu", "Yang", ""], ["Sun-Hosoya", "Lisheng", ""], ["Guyon", "Isabelle", ""], ["Sebag", "Michele", ""]]}, {"id": "1907.10794", "submitter": "Byunghyun Ban", "authors": "Byunghyun Ban, Donghun Ryu, Minwoo Lee", "title": "Machine learning approach to remove ion interference effect in\n  agricultural nutrient solutions", "comments": "6 pages, 5 figures, 5 tables. Accepted to 2019 International\n  Conference on Information and Communication Technology Convergence (ICTC) -\n  ICTC2019", "journal-ref": "2019 International Conference on Information and Communication\n  Technology Convergence (ICTC)", "doi": "10.1109/ICTC46691.2019.8939812", "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  High concentration agricultural facilities such as vertical farms or plant\nfactories consider hydroponic techniques as optimal solutions. Although\nclosed-system dramatically reduces water consumption and pollution issues, it\nhas ion-ratio related problem. As the root absorbs individual ions with\ndifferent rate, ion rate in a nutrient solution should be adjusted\nperiodically. But traditional method only considers pH and electrical\nconductivity to adjust the nutrient solution, leading to ion imbalance and\naccumulation of excessive salts. To avoid those problems, some researchers have\nproposed ion-balancing methods which measure and control each ion\nconcentration. However, those approaches do not overcome the innate limitations\nof ISEs, especially ion interference effect. An anion sensor is affected by\nother anions, and the error grows larger in higher concentration solution. A\nmachine learning approach to modify ISE data distorted by ion interference\neffect is proposed in this paper. As measurement of TDS value is relatively\nrobust than any other signals, we applied TDS as key parameter to build a\nreadjustment function to remove the artifact. Once a readjustment model is\nestablished, application on ISE data can be done in real time. Readjusted data\nwith proposed model showed about 91.6 ~ 98.3% accuracies. This method will\nenable the fields to apply recent methods in feasible status.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jul 2019 01:50:29 GMT"}, {"version": "v2", "created": "Fri, 26 Jul 2019 02:57:41 GMT"}, {"version": "v3", "created": "Wed, 7 Aug 2019 05:51:17 GMT"}, {"version": "v4", "created": "Tue, 3 Sep 2019 00:36:21 GMT"}], "update_date": "2021-01-07", "authors_parsed": [["Ban", "Byunghyun", ""], ["Ryu", "Donghun", ""], ["Lee", "Minwoo", ""]]}, {"id": "1907.10804", "submitter": "Han Shu", "authors": "Han Shu, Yunhe Wang, Xu Jia, Kai Han, Hanting Chen, Chunjing Xu, Qi\n  Tian, Chang Xu", "title": "Co-Evolutionary Compression for Unpaired Image Translation", "comments": "Accepted by ICCV 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative adversarial networks (GANs) have been successfully used for\nconsiderable computer vision tasks, especially the image-to-image translation.\nHowever, generators in these networks are of complicated architectures with\nlarge number of parameters and huge computational complexities. Existing\nmethods are mainly designed for compressing and speeding-up deep neural\nnetworks in the classification task, and cannot be directly applied on GANs for\nimage translation, due to their different objectives and training procedures.\nTo this end, we develop a novel co-evolutionary approach for reducing their\nmemory usage and FLOPs simultaneously. In practice, generators for two image\ndomains are encoded as two populations and synergistically optimized for\ninvestigating the most important convolution filters iteratively. Fitness of\neach individual is calculated using the number of parameters, a\ndiscriminator-aware regularization, and the cycle consistency. Extensive\nexperiments conducted on benchmark datasets demonstrate the effectiveness of\nthe proposed method for obtaining compact and effective generators.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jul 2019 02:26:14 GMT"}], "update_date": "2019-07-26", "authors_parsed": [["Shu", "Han", ""], ["Wang", "Yunhe", ""], ["Jia", "Xu", ""], ["Han", "Kai", ""], ["Chen", "Hanting", ""], ["Xu", "Chunjing", ""], ["Tian", "Qi", ""], ["Xu", "Chang", ""]]}, {"id": "1907.10818", "submitter": "Ioannis Chatzigiannakis", "authors": "Na Zhu, Aris Anagnostopoulos and Ioannis Chatzigiannakis", "title": "On Mining IoT Data for Evaluating the Operation of Public Educational\n  Buildings", "comments": "13 pages, 7 figures. arXiv admin note: substantial text overlap with\n  arXiv:1805.09561", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Public educational systems operate thousands of buildings with vastly\ndifferent characteristics in terms of size, age, location, construction,\nthermal behavior and user communities. Their strategic planning and sustainable\noperation is an extremely complex and requires quantitative evidence on the\nperformance of buildings such as the interaction of indoor-outdoor environment.\nInternet of Things (IoT) deployments can provide the necessary data to\nevaluate, redesign and eventually improve the organizational and managerial\nmeasures. In this work a data mining approach is presented to analyze the\nsensor data collected over a period of 2 years from an IoT infrastructure\ndeployed over 18 school buildings spread in Greece, Italy and Sweden. The\nreal-world evaluation indicates that data mining on sensor data can provide\ncritical insights to building managers and custodial staff about ways to lower\na building's energy footprint through effectively managing building operations.\n", "versions": [{"version": "v1", "created": "Thu, 20 Jun 2019 19:17:08 GMT"}], "update_date": "2019-07-26", "authors_parsed": [["Zhu", "Na", ""], ["Anagnostopoulos", "Aris", ""], ["Chatzigiannakis", "Ioannis", ""]]}, {"id": "1907.10823", "submitter": "Qian Huang", "authors": "Qian Huang, Isay Katsman, Horace He, Zeqi Gu, Serge Belongie, Ser-Nam\n  Lim", "title": "Enhancing Adversarial Example Transferability with an Intermediate Level\n  Attack", "comments": "ICCV 2019 camera-ready. Imagenet results are updated after fixing the\n  normalization. arXiv admin note: text overlap with arXiv:1811.08458", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks are vulnerable to adversarial examples, malicious inputs\ncrafted to fool trained models. Adversarial examples often exhibit black-box\ntransfer, meaning that adversarial examples for one model can fool another\nmodel. However, adversarial examples are typically overfit to exploit the\nparticular architecture and feature representation of a source model, resulting\nin sub-optimal black-box transfer attacks to other target models. We introduce\nthe Intermediate Level Attack (ILA), which attempts to fine-tune an existing\nadversarial example for greater black-box transferability by increasing its\nperturbation on a pre-specified layer of the source model, improving upon\nstate-of-the-art methods. We show that we can select a layer of the source\nmodel to perturb without any knowledge of the target models while achieving\nhigh transferability. Additionally, we provide some explanatory insights\nregarding our method and the effect of optimizing for adversarial examples\nusing intermediate feature maps. Our code is available at\nhttps://github.com/CUVL/Intermediate-Level-Attack.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jul 2019 23:37:15 GMT"}, {"version": "v2", "created": "Sun, 6 Oct 2019 00:45:51 GMT"}, {"version": "v3", "created": "Thu, 27 Feb 2020 22:43:49 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Huang", "Qian", ""], ["Katsman", "Isay", ""], ["He", "Horace", ""], ["Gu", "Zeqi", ""], ["Belongie", "Serge", ""], ["Lim", "Ser-Nam", ""]]}, {"id": "1907.10827", "submitter": "Pablo Hernandez-Leal", "authors": "Bilal Kartal, Pablo Hernandez-Leal and Matthew E. Taylor", "title": "Terminal Prediction as an Auxiliary Task for Deep Reinforcement Learning", "comments": "AAAI Conference on Artificial Intelligence and Interactive Digital\n  Entertainment (AIIDE'19). arXiv admin note: text overlap with\n  arXiv:1812.00045", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning has achieved great successes in recent years, but\nthere are still open challenges, such as convergence to locally optimal\npolicies and sample inefficiency. In this paper, we contribute a novel\nself-supervised auxiliary task, i.e., Terminal Prediction (TP), estimating\ntemporal closeness to terminal states for episodic tasks. The intuition is to\nhelp representation learning by letting the agent predict how close it is to a\nterminal state, while learning its control policy. Although TP could be\nintegrated with multiple algorithms, this paper focuses on Asynchronous\nAdvantage Actor-Critic (A3C) and demonstrating the advantages of A3C-TP. Our\nextensive evaluation includes: a set of Atari games, the BipedalWalker domain,\nand a mini version of the recently proposed multi-agent Pommerman game. Our\nresults on Atari games and the BipedalWalker domain suggest that A3C-TP\noutperforms standard A3C in most of the tested domains and in others it has\nsimilar performance. In Pommerman, our proposed method provides significant\nimprovement both in learning efficiency and converging to better policies\nagainst different opponents.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jul 2019 16:26:21 GMT"}], "update_date": "2019-07-26", "authors_parsed": [["Kartal", "Bilal", ""], ["Hernandez-Leal", "Pablo", ""], ["Taylor", "Matthew E.", ""]]}, {"id": "1907.10834", "submitter": "Chang Min Hyun", "authors": "Chang Min Hyun, Kang Cheol Kim, Hyun Cheol Cho, Jae Kyu Choi and Jin\n  Keun Seo", "title": "Framelet Pooling Aided Deep Learning Network : The Method to Process\n  High Dimensional Medical Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA eess.IV math.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning-based analysis of medical images often faces several\nhurdles, such as the lack of training data, the curse of dimensionality\nproblem, and the generalization issues. One of the main difficulties is that\nthere exists computational cost problem in dealing with input data of large\nsize matrices which represent medical images. The purpose of this paper is to\nintroduce a framelet-pooling aided deep learning method for mitigating\ncomputational bundle, caused by large dimensionality. By transforming high\ndimensional data into low dimensional components by filter banks with\npreserving detailed information, the proposed method aims to reduce the\ncomplexity of the neural network and computational costs significantly during\nthe learning process. Various experiments show that our method is comparable to\nthe standard unreduced learning method, while reducing computational burdens by\ndecomposing large-sized learning tasks into several small-scale learning tasks.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jul 2019 04:40:16 GMT"}], "update_date": "2019-07-29", "authors_parsed": [["Hyun", "Chang Min", ""], ["Kim", "Kang Cheol", ""], ["Cho", "Hyun Cheol", ""], ["Choi", "Jae Kyu", ""], ["Seo", "Jin Keun", ""]]}, {"id": "1907.10837", "submitter": "Chunfei Ma", "authors": "Chunfei Ma, Joonhyang Choi, Byeongwon Lee, Seungji Yang", "title": "Submission to ActivityNet Challenge 2019: Task B Spatio-temporal Action\n  Localization", "comments": "4 pages, 2 fighures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This technical report present an overview of our system proposed for the\nspatio-temporal action localization(SAL) task in ActivityNet Challenge 2019.\nUnlike previous two-streams-based works, we focus on exploring the end-to-end\ntrainable architecture using only RGB sequential images. To this end, we employ\na previously proposed simple yet effective two-branches network called SlowFast\nNetworks which is capable of capturing both short- and long-term spatiotemporal\nfeatures. Moreover, to handle the severe class imbalance and overfitting\nproblems, we propose a correlation-preserving data augmentation method and a\nrandom label subsampling method which have been proven to be able to reduce\noverfitting and improve the performance.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jul 2019 04:48:10 GMT"}], "update_date": "2019-07-26", "authors_parsed": [["Ma", "Chunfei", ""], ["Choi", "Joonhyang", ""], ["Lee", "Byeongwon", ""], ["Yang", "Seungji", ""]]}, {"id": "1907.10839", "submitter": "Yun Ye", "authors": "Yun Ye, Yixin Li, Bo Wu, Wei Zhang, Lingyu Duan, Tao Mei", "title": "Hard-Aware Fashion Attribute Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fashion attribute classification is of great importance to many high-level\ntasks such as fashion item search, fashion trend analysis, fashion\nrecommendation, etc. The task is challenging due to the extremely imbalanced\ndata distribution, particularly the attributes with only a few positive\nsamples. In this paper, we introduce a hard-aware pipeline to make full use of\n\"hard\" samples/attributes. We first propose Hard-Aware BackPropagation (HABP)\nto efficiently and adaptively focus on training \"hard\" data. Then for the\nidentified hard labels, we propose to synthesize more complementary samples for\ntraining. To stabilize training, we extend semi-supervised GAN by directly\ndeactivating outputs for synthetic complementary samples (Deact). In general,\nour method is more effective in addressing \"hard\" cases. HABP weights more on\n\"hard\" samples. For \"hard\" attributes with insufficient training data, Deact\nbrings more stable synthetic samples for training and further improve the\nperformance. Our method is verified on large scale fashion dataset,\noutperforming other state-of-the-art without any additional supervisions.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jul 2019 05:02:02 GMT"}], "update_date": "2019-07-26", "authors_parsed": [["Ye", "Yun", ""], ["Li", "Yixin", ""], ["Wu", "Bo", ""], ["Zhang", "Wei", ""], ["Duan", "Lingyu", ""], ["Mei", "Tao", ""]]}, {"id": "1907.10843", "submitter": "Yu-Jhe Li", "authors": "Yun-Chun Chen, Yu-Jhe Li, Xiaofei Du, Yu-Chiang Frank Wang", "title": "Learning Resolution-Invariant Deep Representations for Person\n  Re-Identification", "comments": "Accepted to AAAI 2019 (Oral)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Person re-identification (re-ID) solves the task of matching images across\ncameras and is among the research topics in vision community. Since query\nimages in real-world scenarios might suffer from resolution loss, how to solve\nthe resolution mismatch problem during person re-ID becomes a practical\nproblem. Instead of applying separate image super-resolution models, we propose\na novel network architecture of Resolution Adaptation and re-Identification\nNetwork (RAIN) to solve cross-resolution person re-ID. Advancing the strategy\nof adversarial learning, we aim at extracting resolution-invariant\nrepresentations for re-ID, while the proposed model is learned in an end-to-end\ntraining fashion. Our experiments confirm that the use of our model can\nrecognize low-resolution query images, even if the resolution is not seen\nduring training. Moreover, the extension of our model for semi-supervised re-ID\nfurther confirms the scalability of our proposed method for real-world\nscenarios and applications.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jul 2019 05:24:05 GMT"}], "update_date": "2019-07-26", "authors_parsed": [["Chen", "Yun-Chun", ""], ["Li", "Yu-Jhe", ""], ["Du", "Xiaofei", ""], ["Wang", "Yu-Chiang Frank", ""]]}, {"id": "1907.10865", "submitter": "Giulio Siracusano Dr.", "authors": "Giulio Siracusano, Aurelio La Corte", "title": "Forecasting Mobile Traffic with Spatiotemporal correlation using Deep\n  Regression", "comments": "5 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The concept of mobility prediction represents one of the key enablers for an\nefficient management of future cellular networks, which tend to be\nprogressively more elaborate and dense due to the aggregation of multiple\ntechnologies. In this letter we aim to investigate the problem of cellular\ntraffic prediction over a metropolitan area and propose a deep regression (DR)\napproach to model its complex spatio-temporal dynamics. DR is instrumental in\ncapturing multi-scale and multi-domain dependences of mobile data by solving an\nimage-to-image regression problem. A parametric relationship between input and\nexpected output is defined and grid search is put in place to isolate and\noptimize performance. Experimental results confirm that the proposed method\nachieves a lower prediction error against stateof-the-art algorithms. We\nvalidate forecasting performance and stability by using a large public dataset\nof a European Provider.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jul 2019 07:12:53 GMT"}], "update_date": "2019-07-26", "authors_parsed": [["Siracusano", "Giulio", ""], ["La Corte", "Aurelio", ""]]}, {"id": "1907.10882", "submitter": "Max Losch", "authors": "Max Losch, Mario Fritz, Bernt Schiele", "title": "Interpretability Beyond Classification Output: Semantic Bottleneck\n  Networks", "comments": "Correct figures in appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Today's deep learning systems deliver high performance based on end-to-end\ntraining. While they deliver strong performance, these systems are hard to\ninterpret. To address this issue, we propose Semantic Bottleneck Networks\n(SBN): deep networks with semantically interpretable intermediate layers that\nall downstream results are based on. As a consequence, the analysis on what the\nfinal prediction is based on is transparent to the engineer and failure cases\nand modes can be analyzed and avoided by high-level reasoning. We present a\ncase study on street scene segmentation to demonstrate the feasibility and\npower of SBN. In particular, we start from a well performing classic deep\nnetwork which we adapt to house a SB-Layer containing task related semantic\nconcepts (such as object-parts and materials). Importantly, we can recover\nstate of the art performance despite a drastic dimensionality reduction from\n1000s (non-semantic feature) to 10s (semantic concept) channels. Additionally\nwe show how the activations of the SB-Layer can be used for both the\ninterpretation of failure cases of the network as well as for confidence\nprediction of the resulting output. For the first time, e.g., we show\ninterpretable segmentation results for most predictions at over 99% accuracy.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jul 2019 07:53:00 GMT"}, {"version": "v2", "created": "Sun, 28 Jul 2019 11:40:03 GMT"}], "update_date": "2019-07-30", "authors_parsed": [["Losch", "Max", ""], ["Fritz", "Mario", ""], ["Schiele", "Bernt", ""]]}, {"id": "1907.10885", "submitter": "Rui Li", "authors": "Rui Li, Kai Shuang, Mengyu Gu, Sen Su", "title": "Adaptive Noise Injection: A Structure-Expanding Regularization for RNN", "comments": "Recently, we find the theory \"extending model can play the role of\n  regularization\"doesn't hold on other NLP tasks' datasets. Now, we are looking\n  for a new theory to explain the effectiveness of ANI.We don't have an\n  alternative version yet, so we choose to withdraw it", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The vanilla LSTM has become one of the most potential architectures in\nword-level language modeling, like other recurrent neural networks, overfitting\nis always a key barrier for its effectiveness. The existing noise-injected\nregularizations introduce the random noises of fixation intensity, which\ninhibits the learning of the RNN throughout the training process. In this\npaper, we propose a new structure-expanding regularization method called\nAdjective Noise Injection (ANI), which considers the output of an extra RNN\nbranch as a kind of adaptive noises and injects it into the main-branch RNN\noutput. Due to the adaptive noises can be improved as the training processes,\nits negative effects can be weakened and even transformed into a positive\neffect to further improve the expressiveness of the main-branch RNN. As a\nresult, ANI can regularize the RNN in the early stage of training and further\npromoting its training performance in the later stage. We conduct experiments\non three widely-used corpora: PTB, WT2, and WT103, whose results verify both\nthe regularization and promoting the training performance functions of ANI.\nFurthermore, we design a series simulation experiments to explore the reasons\nthat may lead to the regularization effect of ANI, and we find that in training\nprocess, the robustness against the parameter update errors can be strengthened\nwhen the LSTM equipped with ANI.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jul 2019 07:58:08 GMT"}, {"version": "v2", "created": "Wed, 17 Mar 2021 14:05:26 GMT"}], "update_date": "2021-03-18", "authors_parsed": [["Li", "Rui", ""], ["Shuang", "Kai", ""], ["Gu", "Mengyu", ""], ["Su", "Sen", ""]]}, {"id": "1907.10892", "submitter": "Ahmed Nassar", "authors": "Ahmed Samy Nassar, Sebastien Lefevre, Jan D. Wegner", "title": "Simultaneous multi-view instance detection with learned geometric\n  soft-constraints", "comments": "Internationcal Conference on Computer Vision 2019 (ICCV 19)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose to jointly learn multi-view geometry and warping between views of\nthe same object instances for robust cross-view object detection. What makes\nmulti-view object instance detection difficult are strong changes in viewpoint,\nlighting conditions, high similarity of neighbouring objects, and strong\nvariability in scale. By turning object detection and instance\nre-identification in different views into a joint learning task, we are able to\nincorporate both image appearance and geometric soft constraints into a single,\nmulti-view detection process that is learnable end-to-end. We validate our\nmethod on a new, large data set of street-level panoramas of urban objects and\nshow superior performance compared to various baselines. Our contribution is\nthreefold: a large-scale, publicly available data set for multi-view instance\ndetection and re-identification; an annotation tool custom-tailored for\nmulti-view instance detection; and a novel, holistic multi-view instance\ndetection and re-identification method that jointly models geometry and\nappearance across views.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jul 2019 08:11:22 GMT"}], "update_date": "2019-07-26", "authors_parsed": [["Nassar", "Ahmed Samy", ""], ["Lefevre", "Sebastien", ""], ["Wegner", "Jan D.", ""]]}, {"id": "1907.10900", "submitter": "Yoshikazu Terada", "authors": "Yoshikazu Terada and Ryoma Hirose", "title": "Fast generalization error bound of deep learning without scale\n  invariance of activation functions", "comments": "32 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In theoretical analysis of deep learning, discovering which features of deep\nlearning lead to good performance is an important task. In this paper, using\nthe framework for analyzing the generalization error developed in Suzuki\n(2018), we derive a fast learning rate for deep neural networks with more\ngeneral activation functions. In Suzuki (2018), assuming the scale invariance\nof activation functions, the tight generalization error bound of deep learning\nwas derived. They mention that the scale invariance of the activation function\nis essential to derive tight error bounds. Whereas the rectified linear unit\n(ReLU; Nair and Hinton, 2010) satisfies the scale invariance, the other famous\nactivation functions including the sigmoid and the hyperbolic tangent\nfunctions, and the exponential linear unit (ELU; Clevert et al., 2016) does not\nsatisfy this condition. The existing analysis indicates a possibility that a\ndeep learning with the non scale invariant activations may have a slower\nconvergence rate of $O(1/\\sqrt{n})$ when one with the scale invariant\nactivations can reach a rate faster than $O(1/\\sqrt{n})$. In this paper,\nwithout the scale invariance of activation functions, we derive the tight\ngeneralization error bound which is essentially the same as that of Suzuki\n(2018). From this result, at least in the framework of Suzuki (2018), it is\nshown that the scale invariance of the activation functions is not essential to\nget the fast rate of convergence. Simultaneously, it is also shown that the\ntheoretical framework proposed by Suzuki (2018) can be widely applied for\nanalysis of deep learning with general activation functions.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jul 2019 08:41:39 GMT"}], "update_date": "2019-07-26", "authors_parsed": [["Terada", "Yoshikazu", ""], ["Hirose", "Ryoma", ""]]}, {"id": "1907.10901", "submitter": "Tom Viering", "authors": "Tom Viering, Ziqi Wang, Marco Loog, Elmar Eisemann", "title": "How to Manipulate CNNs to Make Them Lie: the GradCAM Case", "comments": "Presented at BMVC 2019: Workshop on Interpretable and Explainable\n  Machine Vision, Cardiff, UK. Updated to BMVC template", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently many methods have been introduced to explain CNN decisions. However,\nit has been shown that some methods can be sensitive to manipulation of the\ninput. We continue this line of work and investigate the explanation method\nGradCAM. Instead of manipulating the input, we consider an adversary that\nmanipulates the model itself to attack the explanation. By changing weights and\narchitecture, we demonstrate that it is possible to generate any desired\nexplanation, while leaving the model's accuracy essentially unchanged. This\nillustrates that GradCAM cannot explain the decision of every CNN and provides\na proof of concept showing that it is possible to obfuscate the inner workings\nof a CNN. Finally, we combine input and model manipulation. To this end we put\na backdoor in the network: the explanation is correct unless there is a\nspecific pattern present in the input, which triggers a malicious explanation.\nOur work raises new security concerns, especially in settings where\nexplanations of models may be used to make decisions, such as in the medical\ndomain.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jul 2019 08:51:08 GMT"}, {"version": "v2", "created": "Fri, 16 Aug 2019 14:12:21 GMT"}], "update_date": "2019-08-19", "authors_parsed": [["Viering", "Tom", ""], ["Wang", "Ziqi", ""], ["Loog", "Marco", ""], ["Eisemann", "Elmar", ""]]}, {"id": "1907.10902", "submitter": "Toshihiko Yanase", "authors": "Takuya Akiba, Shotaro Sano, Toshihiko Yanase, Takeru Ohta and Masanori\n  Koyama", "title": "Optuna: A Next-generation Hyperparameter Optimization Framework", "comments": "10 pages, Accepted at KDD 2019 Applied Data Science track", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The purpose of this study is to introduce new design-criteria for\nnext-generation hyperparameter optimization software. The criteria we propose\ninclude (1) define-by-run API that allows users to construct the parameter\nsearch space dynamically, (2) efficient implementation of both searching and\npruning strategies, and (3) easy-to-setup, versatile architecture that can be\ndeployed for various purposes, ranging from scalable distributed computing to\nlight-weight experiment conducted via interactive interface. In order to prove\nour point, we will introduce Optuna, an optimization software which is a\nculmination of our effort in the development of a next generation optimization\nsoftware. As an optimization software designed with define-by-run principle,\nOptuna is particularly the first of its kind. We will present the\ndesign-techniques that became necessary in the development of the software that\nmeets the above criteria, and demonstrate the power of our new design through\nexperimental results and real world applications. Our software is available\nunder the MIT license (https://github.com/pfnet/optuna/).\n", "versions": [{"version": "v1", "created": "Thu, 25 Jul 2019 08:55:22 GMT"}], "update_date": "2019-07-26", "authors_parsed": [["Akiba", "Takuya", ""], ["Sano", "Shotaro", ""], ["Yanase", "Toshihiko", ""], ["Ohta", "Takeru", ""], ["Koyama", "Masanori", ""]]}, {"id": "1907.10903", "submitter": "Wenbing Huang", "authors": "Yu Rong, Wenbing Huang, Tingyang Xu, Junzhou Huang", "title": "DropEdge: Towards Deep Graph Convolutional Networks on Node\n  Classification", "comments": "13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  \\emph{Over-fitting} and \\emph{over-smoothing} are two main obstacles of\ndeveloping deep Graph Convolutional Networks (GCNs) for node classification. In\nparticular, over-fitting weakens the generalization ability on small dataset,\nwhile over-smoothing impedes model training by isolating output representations\nfrom the input features with the increase in network depth. This paper proposes\nDropEdge, a novel and flexible technique to alleviate both issues. At its core,\nDropEdge randomly removes a certain number of edges from the input graph at\neach training epoch, acting like a data augmenter and also a message passing\nreducer. Furthermore, we theoretically demonstrate that DropEdge either reduces\nthe convergence speed of over-smoothing or relieves the information loss caused\nby it. More importantly, our DropEdge is a general skill that can be equipped\nwith many other backbone models (e.g. GCN, ResGCN, GraphSAGE, and JKNet) for\nenhanced performance. Extensive experiments on several benchmarks verify that\nDropEdge consistently improves the performance on a variety of both shallow and\ndeep GCNs. The effect of DropEdge on preventing over-smoothing is empirically\nvisualized and validated as well. Codes are released\non~\\url{https://github.com/DropEdge/DropEdge}.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jul 2019 08:57:45 GMT"}, {"version": "v2", "created": "Mon, 9 Sep 2019 09:08:42 GMT"}, {"version": "v3", "created": "Thu, 9 Jan 2020 14:02:35 GMT"}, {"version": "v4", "created": "Thu, 12 Mar 2020 08:04:36 GMT"}], "update_date": "2020-03-13", "authors_parsed": [["Rong", "Yu", ""], ["Huang", "Wenbing", ""], ["Xu", "Tingyang", ""], ["Huang", "Junzhou", ""]]}, {"id": "1907.10905", "submitter": "Shuxiao Chen", "authors": "Shuxiao Chen, Edgar Dobriban, Jane H Lee", "title": "A Group-Theoretic Framework for Data Augmentation", "comments": "To appear in Journal of Machine Learning Research", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data augmentation is a widely used trick when training deep neural networks:\nin addition to the original data, properly transformed data are also added to\nthe training set. However, to the best of our knowledge, a clear mathematical\nframework to explain the performance benefits of data augmentation is not\navailable. In this paper, we develop such a theoretical framework. We show data\naugmentation is equivalent to an averaging operation over the orbits of a\ncertain group that keeps the data distribution approximately invariant. We\nprove that it leads to variance reduction. We study empirical risk\nminimization, and the examples of exponential families, linear regression, and\ncertain two-layer neural networks. We also discuss how data augmentation could\nbe used in problems with symmetry where other approaches are prevalent, such as\nin cryo-electron microscopy (cryo-EM).\n", "versions": [{"version": "v1", "created": "Thu, 25 Jul 2019 08:58:59 GMT"}, {"version": "v2", "created": "Sat, 28 Dec 2019 19:29:42 GMT"}, {"version": "v3", "created": "Fri, 21 Feb 2020 20:50:50 GMT"}, {"version": "v4", "created": "Fri, 6 Nov 2020 19:48:43 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Chen", "Shuxiao", ""], ["Dobriban", "Edgar", ""], ["Lee", "Jane H", ""]]}, {"id": "1907.10906", "submitter": "Yuantao Gu", "authors": "Gen Li and Yuantao Gu", "title": "Theory of Spectral Method for Union of Subspaces-Based Random Geometry\n  Graph", "comments": "22 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spectral Method is a commonly used scheme to cluster data points lying close\nto Union of Subspaces by first constructing a Random Geometry Graph, called\nSubspace Clustering. This paper establishes a theory to analyze this method.\nBased on this theory, we demonstrate the efficiency of Subspace Clustering in\nfairly broad conditions. The insights and analysis techniques developed in this\npaper might also have implications for other random graph problems. Numerical\nexperiments demonstrate the effectiveness of our theoretical study.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jul 2019 09:02:10 GMT"}], "update_date": "2019-07-26", "authors_parsed": [["Li", "Gen", ""], ["Gu", "Yuantao", ""]]}, {"id": "1907.10915", "submitter": "Jiaolong Xu", "authors": "Jiaolong Xu and Liang Xiao and Antonio M. Lopez", "title": "Self-supervised Domain Adaptation for Computer Vision Tasks", "comments": "Accepted by IEEE Access", "journal-ref": "IEEE Access. 7 (2019) 156694-156706", "doi": "10.1109/ACCESS.2019.2949697", "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent progress of self-supervised visual representation learning has\nachieved remarkable success on many challenging computer vision benchmarks.\nHowever, whether these techniques can be used for domain adaptation has not\nbeen explored. In this work, we propose a generic method for self-supervised\ndomain adaptation, using object recognition and semantic segmentation of urban\nscenes as use cases. Focusing on simple pretext/auxiliary tasks (e.g. image\nrotation prediction), we assess different learning strategies to improve domain\nadaptation effectiveness by self-supervision. Additionally, we propose two\ncomplementary strategies to further boost the domain adaptation accuracy on\nsemantic segmentation within our method, consisting of prediction layer\nalignment and batch normalization calibration. The experimental results show\nadaptation levels comparable to most studied domain adaptation methods, thus,\nbringing self-supervision as a new alternative for reaching domain adaptation.\nThe code is available at https://github.com/Jiaolong/self-supervised-da.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jul 2019 09:20:29 GMT"}, {"version": "v2", "created": "Wed, 9 Oct 2019 05:17:19 GMT"}, {"version": "v3", "created": "Tue, 10 Dec 2019 23:55:34 GMT"}], "update_date": "2019-12-12", "authors_parsed": [["Xu", "Jiaolong", ""], ["Xiao", "Liang", ""], ["Lopez", "Antonio M.", ""]]}, {"id": "1907.10931", "submitter": "Mattias Heinrich", "authors": "Mattias P. Heinrich", "title": "Closing the Gap between Deep and Conventional Image Registration using\n  Probabilistic Dense Displacement Networks", "comments": "accepted for publication at MICCAI 2019, open source code available\n  at https://github.com/multimodallearning/pdd_net", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nonlinear image registration continues to be a fundamentally important tool\nin medical image analysis. Diagnostic tasks, image-guided surgery and\nradiotherapy as well as motion analysis all rely heavily on accurate\nintra-patient alignment. Furthermore, inter-patient registration enables\natlas-based segmentation or landmark localisation and shape analysis. When\nlabelled scans are scarce and anatomical differences large, conventional\nregistration has often remained superior to deep learning methods that have so\nfar mainly dealt with relatively small or low-complexity deformations. We\naddress this shortcoming by leveraging ideas from probabilistic dense\ndisplacement optimisation that has excelled in many registration tasks with\nlarge deformations. We propose to design a network with approximate\nmin-convolutions and mean field inference for differentiable displacement\nregularisation within a discrete weakly-supervised registration setting. By\nemploying these meaningful and theoretically proven constraints, our learnable\nregistration algorithm contains very few trainable weights (primarily for\nfeature extraction) and is easier to train with few labelled scans. It is very\nfast in training and inference and achieves state-of-the-art accuracies for the\nchallenging inter-patient registration of abdominal CT outperforming previous\ndeep learning approaches by 15% Dice overlap.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jul 2019 09:44:12 GMT"}], "update_date": "2019-07-26", "authors_parsed": [["Heinrich", "Mattias P.", ""]]}, {"id": "1907.10949", "submitter": "Massimiliano Patacchiola PhD", "authors": "Massimiliano Patacchiola and Patrick Fox-Roberts and Edward Rosten", "title": "Y-Autoencoders: disentangling latent representations via\n  sequential-encoding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the last few years there have been important advancements in generative\nmodels with the two dominant approaches being Generative Adversarial Networks\n(GANs) and Variational Autoencoders (VAEs). However, standard Autoencoders\n(AEs) and closely related structures have remained popular because they are\neasy to train and adapt to different tasks. An interesting question is if we\ncan achieve state-of-the-art performance with AEs while retaining their good\nproperties. We propose an answer to this question by introducing a new model\ncalled Y-Autoencoder (Y-AE). The structure and training procedure of a Y-AE\nenclose a representation into an implicit and an explicit part. The implicit\npart is similar to the output of an autoencoder and the explicit part is\nstrongly correlated with labels in the training set. The two parts are\nseparated in the latent space by splitting the output of the encoder into two\npaths (forming a Y shape) before decoding and re-encoding. We then impose a\nnumber of losses, such as reconstruction loss, and a loss on dependence between\nthe implicit and explicit parts. Additionally, the projection in the explicit\nmanifold is monitored by a predictor, that is embedded in the encoder and\ntrained end-to-end with no adversarial losses. We provide significant\nexperimental results on various domains, such as separation of style and\ncontent, image-to-image translation, and inverse graphics.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jul 2019 10:28:15 GMT"}], "update_date": "2019-07-26", "authors_parsed": [["Patacchiola", "Massimiliano", ""], ["Fox-Roberts", "Patrick", ""], ["Rosten", "Edward", ""]]}, {"id": "1907.10952", "submitter": "Andrew Cropper", "authors": "Andrew Cropper and Sophie Tourret", "title": "Logical reduction of metarules", "comments": "MLJ submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many forms of inductive logic programming (ILP) use \\emph{metarules},\nsecond-order Horn clauses, to define the structure of learnable programs and\nthus the hypothesis space. Deciding which metarules to use for a given learning\ntask is a major open problem and is a trade-off between efficiency and\nexpressivity: the hypothesis space grows given more metarules, so we wish to\nuse fewer metarules, but if we use too few metarules then we lose expressivity.\nIn this paper, we study whether fragments of metarules can be logically reduced\nto minimal finite subsets. We consider two traditional forms of logical\nreduction: subsumption and entailment. We also consider a new reduction\ntechnique called \\emph{derivation reduction}, which is based on SLD-resolution.\nWe compute reduced sets of metarules for fragments relevant to ILP and\ntheoretically show whether these reduced sets are reductions for more general\ninfinite fragments. We experimentally compare learning with reduced sets of\nmetarules on three domains: Michalski trains, string transformations, and game\nrules. In general, derivation reduced sets of metarules outperforms subsumption\nand entailment reduced sets, both in terms of predictive accuracies and\nlearning times.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jul 2019 10:31:34 GMT"}], "update_date": "2019-07-26", "authors_parsed": [["Cropper", "Andrew", ""], ["Tourret", "Sophie", ""]]}, {"id": "1907.10953", "submitter": "Andrew Cropper", "authors": "Andrew Cropper and Rolf Morel and Stephen H. Muggleton", "title": "Learning higher-order logic programs", "comments": "Submitted to the MLJ", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A key feature of inductive logic programming (ILP) is its ability to learn\nfirst-order programs, which are intrinsically more expressive than\npropositional programs. In this paper, we introduce techniques to learn\nhigher-order programs. Specifically, we extend meta-interpretive learning (MIL)\nto support learning higher-order programs by allowing for \\emph{higher-order\ndefinitions} to be used as background knowledge. Our theoretical results show\nthat learning higher-order programs, rather than first-order programs, can\nreduce the textual complexity required to express programs which in turn\nreduces the size of the hypothesis space and sample complexity. We implement\nour idea in two new MIL systems: the Prolog system \\namea{} and the ASP system\n\\nameb{}. Both systems support learning higher-order programs and higher-order\npredicate invention, such as inventing functions for \\tw{map/3} and conditions\nfor \\tw{filter/3}. We conduct experiments on four domains (robot strategies,\nchess playing, list transformations, and string decryption) that compare\nlearning first-order and higher-order programs. Our experimental results\nsupport our theoretical claims and show that, compared to learning first-order\nprograms, learning higher-order programs can significantly improve predictive\naccuracies and reduce learning times.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jul 2019 10:36:01 GMT"}], "update_date": "2019-07-26", "authors_parsed": [["Cropper", "Andrew", ""], ["Morel", "Rolf", ""], ["Muggleton", "Stephen H.", ""]]}, {"id": "1907.10982", "submitter": "Zeju Li", "authors": "Zeju Li and Konstantinos Kamnitsas and Ben Glocker", "title": "Overfitting of neural nets under class imbalance: Analysis and\n  improvements for segmentation", "comments": "Accepted at MICCAI 2019; typo corrected in Table 1", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Overfitting in deep learning has been the focus of a number of recent works,\nyet its exact impact on the behavior of neural networks is not well understood.\nThis study analyzes overfitting by examining how the distribution of logits\nalters in relation to how much the model overfits. Specifically, we find that\nwhen training with few data samples, the distribution of logit activations when\nprocessing unseen test samples of an under-represented class tends to shift\ntowards and even across the decision boundary, while the over-represented class\nseems unaffected. In image segmentation, foreground samples are often heavily\nunder-represented. We observe that sensitivity of the model drops as a result\nof overfitting, while precision remains mostly stable. Based on our analysis,\nwe derive asymmetric modifications of existing loss functions and regularizers\nincluding a large margin loss, focal loss, adversarial training and mixup,\nwhich specifically aim at reducing the shift observed when embedding unseen\nsamples of the under-represented class. We study the case of binary\nsegmentation of brain tumor core and show that our proposed simple\nmodifications lead to significantly improved segmentation performance over the\nsymmetric variants.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jul 2019 11:47:12 GMT"}, {"version": "v2", "created": "Tue, 1 Oct 2019 13:22:58 GMT"}], "update_date": "2019-10-02", "authors_parsed": [["Li", "Zeju", ""], ["Kamnitsas", "Konstantinos", ""], ["Glocker", "Ben", ""]]}, {"id": "1907.10994", "submitter": "Maria H\\\"ugle", "authors": "Maria H\\\"ugle, Gabriel Kalweit, Branka Mirchevska, Moritz Werling,\n  Joschka Boedecker", "title": "Dynamic Input for Deep Reinforcement Learning in Autonomous Driving", "comments": "Accepted at IROS 2019", "journal-ref": null, "doi": "10.1109/IROS40897.2019.8968560", "report-no": null, "categories": "cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many real-world decision making problems, reaching an optimal decision\nrequires taking into account a variable number of objects around the agent.\nAutonomous driving is a domain in which this is especially relevant, since the\nnumber of cars surrounding the agent varies considerably over time and affects\nthe optimal action to be taken. Classical methods that process object lists can\ndeal with this requirement. However, to take advantage of recent\nhigh-performing methods based on deep reinforcement learning in modular\npipelines, special architectures are necessary. For these, a number of options\nexist, but a thorough comparison of the different possibilities is missing. In\nthis paper, we elaborate limitations of fully-connected neural networks and\nother established approaches like convolutional and recurrent neural networks\nin the context of reinforcement learning problems that have to deal with\nvariable sized inputs. We employ the structure of Deep Sets in off-policy\nreinforcement learning for high-level decision making, highlight their\ncapabilities to alleviate these limitations, and show that Deep Sets not only\nyield the best overall performance but also offer better generalization to\nunseen situations than the other approaches.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jul 2019 12:08:28 GMT"}], "update_date": "2020-08-13", "authors_parsed": [["H\u00fcgle", "Maria", ""], ["Kalweit", "Gabriel", ""], ["Mirchevska", "Branka", ""], ["Werling", "Moritz", ""], ["Boedecker", "Joschka", ""]]}, {"id": "1907.11000", "submitter": "Ludovik Coba <", "authors": "Ludovik Coba, Panagiotis Symeonidis, Markus Zanker", "title": "Personalised novel and explainable matrix factorisation", "comments": null, "journal-ref": "Data & Knowledge Engineering Volume 122, July 2019, Pages 142-158\n  https://www.sciencedirect.com/science/article/pii/S0169023X1830332X", "doi": "10.1016/j.datak.2019.06.003", "report-no": null, "categories": "cs.IR cs.HC cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Recommendation systems personalise suggestions to individuals to help them in\ntheir decision making and exploration tasks. In the ideal case, these\nrecommendations, besides of being accurate, should also be novel and\nexplainable. However, up to now most platforms fail to provide both, novel\nrecommendations that advance users' exploration along with explanations to make\ntheir reasoning more transparent to them. For instance, a well-known\nrecommendation algorithm, such as matrix factorisation (MF), optimises only the\naccuracy criterion, while disregarding other quality criteria such as the\nexplainability or the novelty, of recommended items. In this paper, to the best\nof our knowledge, we propose a new model, denoted as NEMF, that allows to\ntrade-off the MF performance with respect to the criteria of novelty and\nexplainability, while only minimally compromising on accuracy. In addition, we\nrecommend a new explainability metric based on nDCG, which distinguishes a more\nexplainable item from a less explainable item. An initial user study indicates\nhow users perceive the different attributes of these \"user\" style explanations\nand our extensive experimental results demonstrate that we attain high accuracy\nby recommending also novel and explainable items.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jul 2019 12:21:19 GMT"}], "update_date": "2019-07-26", "authors_parsed": [["Coba", "Ludovik", ""], ["Symeonidis", "Panagiotis", ""], ["Zanker", "Markus", ""]]}, {"id": "1907.11004", "submitter": "Horia Porav", "authors": "Horia Porav, Tom Bruls and Paul Newman", "title": "Don't Worry About the Weather: Unsupervised Condition-Dependent Domain\n  Adaptation", "comments": "Presented at ITSC2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern models that perform system-critical tasks such as segmentation and\nlocalization exhibit good performance and robustness under ideal conditions\n(i.e. daytime, overcast) but performance degrades quickly and often\ncatastrophically when input conditions change. In this work, we present a\ndomain adaptation system that uses light-weight input adapters to pre-processes\ninput images, irrespective of their appearance, in a way that makes them\ncompatible with off-the-shelf computer vision tasks that are trained only on\ninputs with ideal conditions. No fine-tuning is performed on the off-the-shelf\nmodels, and the system is capable of incrementally training new input adapters\nin a self-supervised fashion, using the computer vision tasks as supervisors,\nwhen the input domain differs significantly from previously seen domains. We\nreport large improvements in semantic segmentation and topological localization\nperformance on two popular datasets, RobotCar and BDD.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jul 2019 12:28:35 GMT"}], "update_date": "2019-07-26", "authors_parsed": [["Porav", "Horia", ""], ["Bruls", "Tom", ""], ["Newman", "Paul", ""]]}, {"id": "1907.11025", "submitter": "Patrick Wenzel", "authors": "Qadeer Khan, Patrick Wenzel, Daniel Cremers, Laura Leal-Taix\\'e", "title": "Towards Generalizing Sensorimotor Control Across Weather Conditions", "comments": "Accepted for publication in 2019 IEEE/RSJ International Conference on\n  Intelligent Robots and Systems (IROS)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability of deep learning models to generalize well across different\nscenarios depends primarily on the quality and quantity of annotated data.\nLabeling large amounts of data for all possible scenarios that a model may\nencounter would not be feasible; if even possible. We propose a framework to\ndeal with limited labeled training data and demonstrate it on the application\nof vision-based vehicle control. We show how limited steering angle data\navailable for only one condition can be transferred to multiple different\nweather scenarios. This is done by leveraging unlabeled images in a\nteacher-student learning paradigm complemented with an image-to-image\ntranslation network. The translation network transfers the images to a new\ndomain, whereas the teacher provides soft supervised targets to train the\nstudent on this domain. Furthermore, we demonstrate how utilization of\nauxiliary networks can reduce the size of a model at inference time, without\naffecting the accuracy. The experiments show that our approach generalizes well\nacross multiple different weather conditions using only ground truth labels\nfrom one domain.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jul 2019 13:22:05 GMT"}], "update_date": "2019-07-26", "authors_parsed": [["Khan", "Qadeer", ""], ["Wenzel", "Patrick", ""], ["Cremers", "Daniel", ""], ["Leal-Taix\u00e9", "Laura", ""]]}, {"id": "1907.11039", "submitter": "Nathan Hurley", "authors": "Nathan C. Hurley, Adrian D. Haimovich, R. Andrew Taylor, Bobak J.\n  Mortazavi", "title": "Visualization of Emergency Department Clinical Data for Interpretable\n  Patient Phenotyping", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Visual summarization of clinical data collected on patients contained within\nthe electronic health record (EHR) may enable precise and rapid triage at the\ntime of patient presentation to an emergency department (ED). The triage\nprocess is critical in the appropriate allocation of resources and in\nanticipating eventual patient disposition, typically admission to the hospital\nor discharge home. EHR data are high-dimensional and complex, but offer the\nopportunity to discover and characterize underlying data-driven patient\nphenotypes. These phenotypes will enable improved, personalized therapeutic\ndecision making and prognostication. In this work, we focus on the challenge of\ntwo-dimensional patient projections. A low dimensional embedding offers visual\ninterpretability lost in higher dimensions. While linear dimensionality\nreduction techniques such as principal component analysis are often used\ntowards this aim, they are insufficient to describe the variance of patient\ndata. In this work, we employ the newly-described non-linear embedding\ntechnique called uniform manifold approximation and projection (UMAP). UMAP\nseeks to capture both local and global structures in high-dimensional data. We\nthen use Gaussian mixture models to identify clusters in the embedded data and\nuse the adjusted Rand index (ARI) to establish stability in the discovery of\nthese clusters. This technique is applied to five common clinical chief\ncomplaints from a real-world ED EHR dataset, describing the emergent properties\nof discovered clusters. We observe clinically-relevant cluster attributes,\nsuggesting that visual embeddings of EHR data using non-linear dimensionality\nreduction is a promising approach to reveal data-driven patient phenotypes. In\nthe five chief complaints, we find between 2 and 6 clusters, with the peak mean\npairwise ARI between subsequent training iterations to range from 0.35 to 0.74.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jul 2019 19:01:56 GMT"}], "update_date": "2019-07-26", "authors_parsed": [["Hurley", "Nathan C.", ""], ["Haimovich", "Adrian D.", ""], ["Taylor", "R. Andrew", ""], ["Mortazavi", "Bobak J.", ""]]}, {"id": "1907.11040", "submitter": "Yong Wang", "authors": "Yong Wang, Zhihua Jin, Qianwen Wang, Weiwei Cui, Tengfei Ma and Huamin\n  Qu", "title": "DeepDrawing: A Deep Learning Approach to Graph Drawing", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Node-link diagrams are widely used to facilitate network explorations.\nHowever, when using a graph drawing technique to visualize networks, users\noften need to tune different algorithm-specific parameters iteratively by\ncomparing the corresponding drawing results in order to achieve a desired\nvisual effect. This trial and error process is often tedious and\ntime-consuming, especially for non-expert users. Inspired by the powerful data\nmodelling and prediction capabilities of deep learning techniques, we explore\nthe possibility of applying deep learning techniques to graph drawing.\nSpecifically, we propose using a graph-LSTM-based approach to directly map\nnetwork structures to graph drawings. Given a set of layout examples as the\ntraining dataset, we train the proposed graph-LSTM-based model to capture their\nlayout characteristics. Then, the trained model is used to generate graph\ndrawings in a similar style for new networks. We evaluated the proposed\napproach on two special types of layouts (i.e., grid layouts and star layouts)\nand two general types of layouts (i.e., ForceAtlas2 and PivotMDS) in both\nqualitative and quantitative ways. The results provide support for the\neffectiveness of our approach. We also conducted a time cost assessment on the\ndrawings of small graphs with 20 to 50 nodes. We further report the lessons we\nlearned and discuss the limitations and future work.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jul 2019 15:34:44 GMT"}, {"version": "v2", "created": "Sat, 27 Jul 2019 15:14:02 GMT"}, {"version": "v3", "created": "Wed, 9 Oct 2019 16:50:22 GMT"}], "update_date": "2019-10-10", "authors_parsed": [["Wang", "Yong", ""], ["Jin", "Zhihua", ""], ["Wang", "Qianwen", ""], ["Cui", "Weiwei", ""], ["Ma", "Tengfei", ""], ["Qu", "Huamin", ""]]}, {"id": "1907.11075", "submitter": "Andrew Warrington", "authors": "Andrew Warrington, Arthur Spencer, Frank Wood", "title": "The Virtual Patch Clamp: Imputing C. elegans Membrane Potentials from\n  Calcium Imaging", "comments": "Includes Supplementary Materials", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a stochastic whole-brain and body simulator of the nematode\nroundworm Caenorhabditis elegans (C. elegans) and show that it is sufficiently\nregularizing to allow imputation of latent membrane potentials from partial\ncalcium fluorescence imaging observations. This is the first attempt we know of\nto \"complete the circle,\" where an anatomically grounded whole-connectome\nsimulator is used to impute a time-varying \"brain\" state at single-cell\nfidelity from covariates that are measurable in practice. The sequential Monte\nCarlo (SMC) method we employ not only enables imputation of said latent states\nbut also presents a strategy for learning simulator parameters via variational\noptimization of the noisy model evidence approximation provided by SMC. Our\nimputation and parameter estimation experiments were conducted on distributed\nsystems using novel implementations of the aforementioned techniques applied to\nsynthetic data of dimension and type representative of that which are measured\nin laboratories currently.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jul 2019 17:57:39 GMT"}], "update_date": "2019-07-26", "authors_parsed": [["Warrington", "Andrew", ""], ["Spencer", "Arthur", ""], ["Wood", "Frank", ""]]}, {"id": "1907.11086", "submitter": "Alan Chern", "authors": "Alan Chern, Phuong Hoang, Madhav Sigdel, Janani Balaji, and Mohammed\n  Korayem", "title": "Automated Discovery and Classification of Training Videos for Career\n  Progression", "comments": "5 pages, 4 figures, Proceedings of the Data Collection, Curation, and\n  Labeling for Mining and Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Job transitions and upskilling are common actions taken by many industry\nworking professionals throughout their career. With the current rapidly\nchanging job landscape where requirements are constantly changing and industry\nsectors are emerging, it is especially difficult to plan and navigate a\npredetermined career path. In this work, we implemented a system to automate\nthe collection and classification of training videos to help job seekers\nidentify and acquire the skills necessary to transition to the next step in\ntheir career. We extracted educational videos and built a machine learning\nclassifier to predict video relevancy. This system allows us to discover\nrelevant videos at a large scale for job title-skill pairs. Our experiments\nshow significant improvements in the model performance by incorporating\nembedding vectors associated with the video attributes. Additionally, we\nevaluated the optimal probability threshold to extract as many videos as\npossible with minimal false positive rate.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jul 2019 18:23:57 GMT"}], "update_date": "2019-07-26", "authors_parsed": [["Chern", "Alan", ""], ["Hoang", "Phuong", ""], ["Sigdel", "Madhav", ""], ["Balaji", "Janani", ""], ["Korayem", "Mohammed", ""]]}, {"id": "1907.11090", "submitter": "Heyang Gong", "authors": "Gong Heyang and Zhu Ke", "title": "Info Intervention", "comments": "See more information on Causal AI:\n  https://sites.google.com/view/minituring/home", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Causal diagrams based on do intervention are useful tools to formalize,\nprocess and understand causal relationship among variables. However, the do\nintervention has controversial interpretation of causal questions for\nnon-manipulable variables, and it also lacks the power to check the conditions\nrelated to counterfactual variables. This paper introduces a new info\nintervention to tackle these two problems, and provides causal diagrams for\ncommunication and theoretical focus based on this info intervention. Our info\nintervention intervenes the input/output information of causal mechanisms,\nwhile the do intervention intervenes the causal mechanisms. Consequently, the\ncausality is viewed as information transfer in the info intervention framework.\nAs an extension, the generalized info intervention is also proposed and studied\nin this paper.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jul 2019 07:31:14 GMT"}, {"version": "v2", "created": "Sun, 29 Dec 2019 02:59:06 GMT"}, {"version": "v3", "created": "Thu, 16 Apr 2020 15:33:59 GMT"}, {"version": "v4", "created": "Fri, 17 Apr 2020 03:22:07 GMT"}, {"version": "v5", "created": "Mon, 1 Jun 2020 08:11:52 GMT"}, {"version": "v6", "created": "Tue, 2 Jun 2020 03:25:10 GMT"}], "update_date": "2020-06-03", "authors_parsed": [["Heyang", "Gong", ""], ["Ke", "Zhu", ""]]}, {"id": "1907.11094", "submitter": "Guihong Wan", "authors": "Guihong Wan, Crystal Maung, Haim Schweitzer", "title": "Improving the Accuracy of Principal Component Analysis by the Maximum\n  Entropy Method", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classical Principal Component Analysis (PCA) approximates data in terms of\nprojections on a small number of orthogonal vectors. There are simple\nprocedures to efficiently compute various functions of the data from the PCA\napproximation. The most important function is arguably the Euclidean distance\nbetween data items, This can be used, for example, to solve the approximate\nnearest neighbor problem. We use random variables to model the inherent\nuncertainty in such approximations, and apply the Maximum Entropy Method to\ninfer the underlying probability distribution. We propose using the expected\nvalues of distances between these random variables as improved estimates of the\ndistance. We show by analysis and experimentally that in most cases results\nobtained by our method are more accurate than what is obtained by the classical\napproach. This improves the accuracy of a classical technique that have been\nused with little change for over 100 years.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jul 2019 03:24:33 GMT"}], "update_date": "2019-07-26", "authors_parsed": [["Wan", "Guihong", ""], ["Maung", "Crystal", ""], ["Schweitzer", "Haim", ""]]}, {"id": "1907.11105", "submitter": "Raoul Heese", "authors": "Raoul Heese and Micha{\\l} Walczak and Lukas Morand and Dirk Helm and\n  Michael Bortz", "title": "The Good, the Bad and the Ugly: Augmenting a black-box model with expert\n  knowledge", "comments": "International Conference on Artificial Neural Networks (ICANN) 2019", "journal-ref": "Artificial Neural Networks and Machine Learning - ICANN 2019:\n  Workshop and Special Sessions. ICANN 2019. Lecture Notes in Computer Science\n  11731 (2019) 391-395", "doi": "10.1007/978-3-030-30493-5_38", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address a non-unique parameter fitting problem in the context of material\nscience. In particular, we propose to resolve ambiguities in parameter space by\naugmenting a black-box artificial neural network (ANN) model with two different\nlevels of expert knowledge and benchmark them against a pure black-box model.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jul 2019 09:15:01 GMT"}, {"version": "v2", "created": "Mon, 11 May 2020 17:07:49 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Heese", "Raoul", ""], ["Walczak", "Micha\u0142", ""], ["Morand", "Lukas", ""], ["Helm", "Dirk", ""], ["Bortz", "Michael", ""]]}, {"id": "1907.11110", "submitter": "Seyed Mehdi Ayyoubzadeh", "authors": "Seyed Mehdi Ayyoubzadeh, Xiaolin Wu", "title": "Filter Bank Regularization of Convolutional Neural Networks", "comments": "11 pages, 19 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Regularization techniques are widely used to improve the generality,\nrobustness, and efficiency of deep convolutional neural networks (DCNNs). In\nthis paper, we propose a novel approach of regulating DCNN convolutional\nkernels by a structured filter bank. Comparing with the existing regularization\nmethods, such as $\\ell_1$ or $\\ell_2$ minimization of DCNN kernel weights and\nthe kernel orthogonality, which ignore sample correlations within a kernel, the\nuse of filter bank in regularization of DCNNs can mold the DCNN kernels to\ncommon spatial structures and features (e.g., edges or textures of various\norientations and frequencies) of natural images. On the other hand, unlike\ndirectly making DCNN kernels fixed filters, the filter bank regularization\nstill allows the freedom of optimizing DCNN weights via deep learning. This new\nDCNN design strategy aims to combine the best of two worlds: the inclusion of\nstructural image priors of traditional filter banks to improve the robustness\nand generality of DCNN solutions and the capability of modern deep learning to\nmodel complex non-linear functions hidden in training data. Experimental\nresults on object recognition tasks show that the proposed regularization\napproach guides DCNNs to faster convergence and better generalization than\nexisting regularization methods of weight decay and kernel orthogonality.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jul 2019 14:43:10 GMT"}, {"version": "v2", "created": "Tue, 12 Nov 2019 20:45:53 GMT"}, {"version": "v3", "created": "Tue, 26 Nov 2019 20:43:51 GMT"}], "update_date": "2019-11-28", "authors_parsed": [["Ayyoubzadeh", "Seyed Mehdi", ""], ["Wu", "Xiaolin", ""]]}, {"id": "1907.11114", "submitter": "Jiawei Zhang", "authors": "Yixin Chen, Lin Meng, and Jiawei Zhang", "title": "Graph Neural Lasso for Dynamic Network Regression", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The regression of multiple inter-connected sequence data is a problem in\nvarious disciplines. Formally, we name the regression problem of multiple\ninter-connected data entities as the \"dynamic network regression\" in this\npaper. Within the problem of stock forecasting or traffic speed prediction, we\nneed to consider both the trends of the entities and the relationships among\nthe entities. A majority of existing approaches can't capture that information\ntogether. Some of the approaches are proposed to deal with the sequence data,\nlike LSTM. The others use the prior knowledge in a network to get a fixed graph\nstructure and do prediction on some unknown entities, like GCN. To overcome the\nlimitations in those methods, we propose a novel graph neural network, namely\nGraph Neural Lasso (GNL), to deal with the dynamic network problem. GNL extends\nthe GDU (gated diffusive unit) as the base neuron to capture the information\nbehind the sequence. Rather than using a fixed graph structure, GNL can learn\nthe dynamic graph structure automatically. By adding the attention mechanism in\nGNL, we can learn the dynamic relations among entities within each network\nsnapshot. Combining these two parts, GNL is able to model the dynamic network\nproblem well. Experimental results provided on two networked sequence datasets,\ni.e., Nasdaq-100 and METR-LA, show that GNL can address the network regression\nproblem very well and is also very competitive among the existing approaches.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jul 2019 14:52:10 GMT"}, {"version": "v2", "created": "Fri, 16 Oct 2020 03:58:03 GMT"}], "update_date": "2020-10-19", "authors_parsed": [["Chen", "Yixin", ""], ["Meng", "Lin", ""], ["Zhang", "Jiawei", ""]]}, {"id": "1907.11129", "submitter": "Casey Kneale Ph.D", "authors": "Casey Kneale, Kolia Sadeghi", "title": "Semisupervised Adversarial Neural Networks for Cyber Security Transfer\n  Learning", "comments": "14 figures, 17 pages, Draft", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.NE stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  On the path to establishing a global cybersecurity framework where each\nenterprise shares information about malicious behavior, an important question\narises. How can a machine learning representation characterizing a cyber attack\non one network be used to detect similar attacks on other enterprise networks\nif each networks has wildly different distributions of benign and malicious\ntraffic? We address this issue by comparing the results of naively transferring\na model across network domains and using CORrelation ALignment, to our novel\nadversarial Siamese neural network. Our proposed model learns attack\nrepresentations that are more invariant to each network's particularities via\nan adversarial approach. It uses a simple ranking loss that prioritizes the\nlabeling of the most egregious malicious events correctly over average\naccuracy. This is appropriate for driving an alert triage workflow wherein an\nanalyst only has time to inspect the top few events ranked highest by the\nmodel. In terms of accuracy, the other approaches fail completely to detect any\nmalicious events when models were trained on one dataset are evaluated on\nanother for the first 100 events. While, the method presented here retrieves\nsizable proportions of malicious events, at the expense of some training\ninstabilities due in adversarial modeling. We evaluate these approaches using 2\npublicly available networking datasets, and suggest areas for future research.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jul 2019 15:14:38 GMT"}], "update_date": "2019-07-26", "authors_parsed": [["Kneale", "Casey", ""], ["Sadeghi", "Kolia", ""]]}, {"id": "1907.11142", "submitter": "Marzia Cremona", "authors": "Jacopo Di Iorio, Francesca Chiaromonte and Marzia A. Cremona", "title": "On the bias of H-scores for comparing biclusters, and how to correct it", "comments": "12 pages, 3 figures", "journal-ref": "Bioinformatics 2020, 36(1): 2955-2957", "doi": "10.1093/bioinformatics/btaa060", "report-no": null, "categories": "stat.ME cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the last two decades several biclustering methods have been developed as\nnew unsupervised learning techniques to simultaneously cluster rows and columns\nof a data matrix. These algorithms play a central role in contemporary machine\nlearning and in many applications, e.g. to computational biology and\nbioinformatics. The H-score is the evaluation score underlying the seminal\nbiclustering algorithm by Cheng and Church, as well as many other subsequent\nbiclustering methods. In this paper, we characterize a potentially troublesome\nbias in this score, that can distort biclustering results. We prove, both\nanalytically and by simulation, that the average H-score increases with the\nnumber of rows/columns in a bicluster. This makes the H-score, and hence all\nalgorithms based on it, biased towards small clusters. Based on our analytical\nproof, we are able to provide a straightforward way to correct this bias,\nallowing users to accurately compare biclusters.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jul 2019 15:24:27 GMT"}], "update_date": "2020-07-08", "authors_parsed": [["Di Iorio", "Jacopo", ""], ["Chiaromonte", "Francesca", ""], ["Cremona", "Marzia A.", ""]]}, {"id": "1907.11180", "submitter": "Anton Raichuk", "authors": "Karol Kurach, Anton Raichuk, Piotr Sta\\'nczyk, Micha{\\l} Zaj\\k{a}c,\n  Olivier Bachem, Lasse Espeholt, Carlos Riquelme, Damien Vincent, Marcin\n  Michalski, Olivier Bousquet, Sylvain Gelly", "title": "Google Research Football: A Novel Reinforcement Learning Environment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent progress in the field of reinforcement learning has been accelerated\nby virtual learning environments such as video games, where novel algorithms\nand ideas can be quickly tested in a safe and reproducible manner. We introduce\nthe Google Research Football Environment, a new reinforcement learning\nenvironment where agents are trained to play football in an advanced,\nphysics-based 3D simulator. The resulting environment is challenging, easy to\nuse and customize, and it is available under a permissive open-source license.\nIn addition, it provides support for multiplayer and multi-agent experiments.\nWe propose three full-game scenarios of varying difficulty with the Football\nBenchmarks and report baseline results for three commonly used reinforcement\nalgorithms (IMPALA, PPO, and Ape-X DQN). We also provide a diverse set of\nsimpler scenarios with the Football Academy and showcase several promising\nresearch directions.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jul 2019 16:39:27 GMT"}, {"version": "v2", "created": "Tue, 14 Apr 2020 18:11:24 GMT"}], "update_date": "2020-04-16", "authors_parsed": [["Kurach", "Karol", ""], ["Raichuk", "Anton", ""], ["Sta\u0144czyk", "Piotr", ""], ["Zaj\u0105c", "Micha\u0142", ""], ["Bachem", "Olivier", ""], ["Espeholt", "Lasse", ""], ["Riquelme", "Carlos", ""], ["Vincent", "Damien", ""], ["Michalski", "Marcin", ""], ["Bousquet", "Olivier", ""], ["Gelly", "Sylvain", ""]]}, {"id": "1907.11184", "submitter": "Prithviraj Sen", "authors": "Yiwei Yang, Eser Kandogan, Yunyao Li, Walter S. Lasecki, and\n  Prithviraj Sen", "title": "HEIDL: Learning Linguistic Expressions with Deep Learning and\n  Human-in-the-Loop", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While the role of humans is increasingly recognized in machine learning\ncommunity, representation of and interaction with models in current\nhuman-in-the-loop machine learning (HITL-ML) approaches are too low-level and\nfar-removed from human's conceptual models. We demonstrate HEIDL, a prototype\nHITL-ML system that exposes the machine-learned model through high-level,\nexplainable linguistic expressions formed of predicates representing semantic\nstructure of text. In HEIDL, human's role is elevated from simply evaluating\nmodel predictions to interpreting and even updating the model logic directly by\nenabling interaction with rule predicates themselves. Raising the currency of\ninteraction to such semantic levels calls for new interaction paradigms between\nhumans and machines that result in improved productivity for text analytics\nmodel development process. Moreover, by involving humans in the process, the\nhuman-machine co-created models generalize better to unseen data as domain\nexperts are able to instill their expertise by extrapolating from what has been\nlearned by automated algorithms from few labelled data.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jul 2019 16:45:06 GMT"}], "update_date": "2019-07-26", "authors_parsed": [["Yang", "Yiwei", ""], ["Kandogan", "Eser", ""], ["Li", "Yunyao", ""], ["Lasecki", "Walter S.", ""], ["Sen", "Prithviraj", ""]]}, {"id": "1907.11195", "submitter": "Xiao Wang", "authors": "Xiao Wang, Zhijie Wang, Yolande M. Pengetnze, Barry S. Lachman, Vikas\n  Chowdhry", "title": "Deep Learning Models to Predict Pediatric Asthma Emergency Department\n  Visits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pediatric asthma is the most prevalent chronic childhood illness, afflicting\nabout 6.2 million children in the United States. However, asthma could be\nbetter managed by identifying and avoiding triggers, educating about\nmedications and proper disease management strategies. This research utilizes\ndeep learning methodologies to predict asthma-related emergency department (ED)\nvisit within 3 months using Medicaid claims data. We compare prediction results\nagainst traditional statistical classification model - penalized Lasso logistic\nregression, which we trained and have deployed since 2015. The results have\nindicated that deep learning model Artificial Neural Networks (ANN) slightly\noutperforms (with AUC = 0.845) the Lasso logistic regression (with AUC =\n0.842). The reason may come from the nonlinear nature of ANN.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jul 2019 16:56:56 GMT"}], "update_date": "2019-07-26", "authors_parsed": [["Wang", "Xiao", ""], ["Wang", "Zhijie", ""], ["Pengetnze", "Yolande M.", ""], ["Lachman", "Barry S.", ""], ["Chowdhry", "Vikas", ""]]}, {"id": "1907.11202", "submitter": "Ligong Han", "authors": "Ligong Han, Yang Zou, Ruijiang Gao, Lezi Wang, Dimitris Metaxas", "title": "Unsupervised Domain Adaptation via Calibrating Uncertainties", "comments": "4 pages", "journal-ref": "The IEEE Conference on Computer Vision and Pattern Recognition\n  (CVPR) Workshops, 2019, pp. 99-102", "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Unsupervised domain adaptation (UDA) aims at inferring class labels for\nunlabeled target domain given a related labeled source dataset. Intuitively, a\nmodel trained on source domain normally produces higher uncertainties for\nunseen data. In this work, we build on this assumption and propose to adapt\nfrom source to target domain via calibrating their predictive uncertainties.\nThe uncertainty is quantified as the Renyi entropy, from which we propose a\ngeneral Renyi entropy regularization (RER) framework. We further employ\nvariational Bayes learning for reliable uncertainty estimation. In addition,\ncalibrating the sample variance of network parameters serves as a plug-in\nregularizer for training. We discuss the theoretical properties of the proposed\nmethod and demonstrate its effectiveness on three domain-adaptation tasks.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jul 2019 17:02:51 GMT"}], "update_date": "2019-07-26", "authors_parsed": [["Han", "Ligong", ""], ["Zou", "Yang", ""], ["Gao", "Ruijiang", ""], ["Wang", "Lezi", ""], ["Metaxas", "Dimitris", ""]]}, {"id": "1907.11208", "submitter": "David Augustin", "authors": "David Augustin, Marius Hofmann, Ulrich Konigorski", "title": "Prediction of Highway Lane Changes Based on Prototype Trajectories", "comments": "VDI AUTOREG 2019, 17 pages, 5 figures", "journal-ref": "VDI-Berichte Nr. 2349: 111-127, 2019, VDI Wissensforum GmbH, ISSN:\n  0083-5560, ISBN: 978-3-18-092349-9", "doi": null, "report-no": null, "categories": "cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The vision of automated driving is to increase both road safety and\nefficiency, while offering passengers a convenient travel experience. This\nrequires that autonomous systems correctly estimate the current traffic scene\nand its likely evolution. In highway scenarios early recognition of cut-in\nmaneuvers is essential for risk-aware maneuver planning. In this paper, a\nstatistical approach is proposed, which advantageously utilizes a set of\nprototypical lane change trajectories to realize both early maneuver detection\nand uncertainty-aware trajectory prediction for traffic participants.\nGeneration of prototype trajectories from real traffic data is accomplished by\nAgglomerative Hierarchical Clustering. During clustering, the alignment of the\ncluster prototypes to each other is optimized and the cohesion of the resulting\nprototype is limited when two clusters merge. In the prediction stage, the\nsimilarity of observed vehicle motion and typical lane change patterns in the\ndata base is evaluated to construct a set of significant features for maneuver\nclassification via Boosted Decision Trees. The future trajectory is predicted\ncombining typical lane change realizations in a mixture model. B-splines based\ntrajectory adaptations guarantee continuity during transition from actually\nobserved to predicted vehicle states. Quantitative evaluation results\ndemonstrate the proposed concept's improved performance for both maneuver and\ntrajectory prediction compared to a previously implemented reference approach.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jul 2019 17:18:53 GMT"}], "update_date": "2019-07-26", "authors_parsed": [["Augustin", "David", ""], ["Hofmann", "Marius", ""], ["Konigorski", "Ulrich", ""]]}, {"id": "1907.11210", "submitter": "Feng Shi", "authors": "Feng Shi, Ziheng Xu, Tao Yuan, Song-Chun Zhu", "title": "HUGE2: a Highly Untangled Generative-model Engine for Edge-computing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As a type of prominent studies in deep learning, generative models have been\nwidely investigated in research recently. Two research branches of the deep\nlearning models, the Generative Networks (GANs, VAE) and the Semantic\nSegmentation, rely highly on the upsampling operations, especially the\ntransposed convolution and the dilated convolution. However, these two types of\nconvolutions are intrinsically different from standard convolution regarding\nthe insertion of zeros in input feature maps or in kernels respectively. This\ndistinct nature severely degrades the performance of the existing deep learning\nengine or frameworks, such as Darknet, Tensorflow, and PyTorch, which are\nmainly developed for the standard convolution. Another trend in deep learning\nrealm is to deploy the model onto edge/ embedded devices, in which the memory\nresource is scarce. In this work, we propose a Highly Untangled\nGenerative-model Engine for Edge-computing or HUGE2 for accelerating these two\nspecial convolutions on the edge-computing platform by decomposing the kernels\nand untangling these smaller convolutions by performing basic matrix\nmultiplications. The methods we propose use much smaller memory footprint,\nhence much fewer memory accesses, and the data access patterns also\ndramatically increase the reusability of the data already fetched in caches,\nhence increasing the localities of caches. Our engine achieves a speedup of\nnearly 5x on embedded CPUs, and around 10x on embedded GPUs, and more than 50%\nreduction of memory access.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jul 2019 17:21:52 GMT"}, {"version": "v2", "created": "Sat, 8 May 2021 17:07:28 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Shi", "Feng", ""], ["Xu", "Ziheng", ""], ["Yuan", "Tao", ""], ["Zhu", "Song-Chun", ""]]}, {"id": "1907.11216", "submitter": "Shoubo Hu", "authors": "Shoubo Hu, Kun Zhang, Zhitang Chen, Laiwan Chan", "title": "Domain Generalization via Multidomain Discriminant Analysis", "comments": "UAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Domain generalization (DG) aims to incorporate knowledge from multiple source\ndomains into a single model that could generalize well on unseen target\ndomains. This problem is ubiquitous in practice since the distributions of the\ntarget data may rarely be identical to those of the source data. In this paper,\nwe propose Multidomain Discriminant Analysis (MDA) to address DG of\nclassification tasks in general situations. MDA learns a domain-invariant\nfeature transformation that aims to achieve appealing properties, including a\nminimal divergence among domains within each class, a maximal separability\namong classes, and overall maximal compactness of all classes. Furthermore, we\nprovide the bounds on excess risk and generalization error by learning theory\nanalysis. Comprehensive experiments on synthetic and real benchmark datasets\ndemonstrate the effectiveness of MDA.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jul 2019 17:39:44 GMT"}], "update_date": "2019-07-26", "authors_parsed": [["Hu", "Shoubo", ""], ["Zhang", "Kun", ""], ["Chen", "Zhitang", ""], ["Chan", "Laiwan", ""]]}, {"id": "1907.11223", "submitter": "Wengong Jin", "authors": "Wengong Jin, Regina Barzilay, Tommi Jaakkola", "title": "Hierarchical Graph-to-Graph Translation for Molecules", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.chem-ph cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of accelerating drug discovery relies heavily on automatic tools\nto optimize precursor molecules to afford them with better biochemical\nproperties. Our work in this paper substantially extends prior state-of-the-art\non graph-to-graph translation methods for molecular optimization. In\nparticular, we realize coherent multi-resolution representations by\ninterweaving the encoding of substructure components with the atom-level\nencoding of the original molecular graph. Moreover, our graph decoder is fully\nautoregressive, and interleaves each step of adding a new substructure with the\nprocess of resolving its attachment to the emerging molecule. We evaluate our\nmodel on multiple molecular optimization tasks and show that our model\nsignificantly outperforms previous state-of-the-art baselines.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jun 2019 21:50:42 GMT"}, {"version": "v2", "created": "Fri, 18 Oct 2019 19:52:58 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Jin", "Wengong", ""], ["Barzilay", "Regina", ""], ["Jaakkola", "Tommi", ""]]}, {"id": "1907.11229", "submitter": "Changtao Zhong", "authors": "Mateusz Fedoryszak, Brent Frederick, Vijay Rajaram, Changtao Zhong", "title": "Real-time Event Detection on Social Data Streams", "comments": "Accepted as a full paper at KDD 2019 on April 29, 2019", "journal-ref": null, "doi": "10.1145/3292500.3330689", "report-no": null, "categories": "cs.SI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Social networks are quickly becoming the primary medium for discussing what\nis happening around real-world events. The information that is generated on\nsocial platforms like Twitter can produce rich data streams for immediate\ninsights into ongoing matters and the conversations around them. To tackle the\nproblem of event detection, we model events as a list of clusters of trending\nentities over time. We describe a real-time system for discovering events that\nis modular in design and novel in scale and speed: it applies clustering on a\nlarge stream with millions of entities per minute and produces a dynamically\nupdated set of events. In order to assess clustering methodologies, we build an\nevaluation dataset derived from a snapshot of the full Twitter Firehose and\npropose novel metrics for measuring clustering quality. Through experiments and\nsystem profiling, we highlight key results from the offline and online\npipelines. Finally, we visualize a high profile event on Twitter to show the\nimportance of modeling the evolution of events, especially those detected from\nsocial data streams.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jul 2019 17:59:00 GMT"}], "update_date": "2019-07-26", "authors_parsed": [["Fedoryszak", "Mateusz", ""], ["Frederick", "Brent", ""], ["Rajaram", "Vijay", ""], ["Zhong", "Changtao", ""]]}, {"id": "1907.11235", "submitter": "Peichang Guo", "authors": "Pei-Chang Guo", "title": "A Frobenius norm regularization method for convolutional kernels to\n  avoid unstable gradient problem", "comments": "arXiv admin note: text overlap with arXiv:1906.04866", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional neural network is a very important model of deep learning. It\ncan help avoid the exploding/vanishing gradient problem and improve the\ngeneralizability of a neural network if the singular values of the Jacobian of\na layer are bounded around $1$ in the training process. We propose a new\npenalty function for a convolutional kernel to let the singular values of the\ncorresponding transformation matrix are bounded around $1$. We show how to\ncarry out the gradient type methods. The penalty is about the structured\ntransformation matrix corresponding to a convolutional kernel. This provides a\nnew regularization method about the weights of convolutional layers.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jul 2019 23:43:05 GMT"}], "update_date": "2019-07-29", "authors_parsed": [["Guo", "Pei-Chang", ""]]}, {"id": "1907.11238", "submitter": "Szymon Drgas", "authors": "Tomasz Grzywalski, Riccardo Belluzzo, Szymon Drgas, Agnieszka\n  Cwalinska, Honorata Hafke-Dys", "title": "Interactive Lungs Auscultation with Reinforcement Learning Agent", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.AI cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To perform a precise auscultation for the purposes of examination of\nrespiratory system normally requires the presence of an experienced doctor.\nWith most recent advances in machine learning and artificial intelligence,\nautomatic detection of pathological breath phenomena in sounds recorded with\nstethoscope becomes a reality. But to perform a full auscultation in home\nenvironment by layman is another matter, especially if the patient is a child.\nIn this paper we propose a unique application of Reinforcement Learning for\ntraining an agent that interactively guides the end user throughout the\nauscultation procedure. We show that \\textit{intelligent} selection of\nauscultation points by the agent reduces time of the examination fourfold\nwithout significant decrease in diagnosis accuracy compared to exhaustive\nauscultation.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jul 2019 11:04:08 GMT"}], "update_date": "2019-07-29", "authors_parsed": [["Grzywalski", "Tomasz", ""], ["Belluzzo", "Riccardo", ""], ["Drgas", "Szymon", ""], ["Cwalinska", "Agnieszka", ""], ["Hafke-Dys", "Honorata", ""]]}, {"id": "1907.11274", "submitter": "Aviv Ovadya", "authors": "Aviv Ovadya, Jess Whittlestone", "title": "Reducing malicious use of synthetic media research: Considerations and\n  potential release practices for machine learning", "comments": "11 pages. Language fixes and tweaks for clarity", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The aim of this paper is to facilitate nuanced discussion around research\nnorms and practices to mitigate the harmful impacts of advances in machine\nlearning (ML). We focus particularly on the use of ML to create \"synthetic\nmedia\" (e.g. to generate or manipulate audio, video, images, and text), and the\nquestion of what publication and release processes around such research might\nlook like, though many of the considerations discussed will apply to ML\nresearch more broadly. We are not arguing for any specific approach on when or\nhow research should be distributed, but instead try to lay out some useful\ntools, analogies, and options for thinking about these issues.\n  We begin with some background on the idea that ML research might be misused\nin harmful ways, and why advances in synthetic media, in particular, are\nraising concerns. We then outline in more detail some of the different paths to\nharm from ML research, before reviewing research risk mitigation strategies in\nother fields and identifying components that seem most worth emulating in the\nML and synthetic media research communities. Next, we outline some important\ndimensions of disagreement on these issues which risk polarizing conversations.\n  Finally, we conclude with recommendations, suggesting that the machine\nlearning community might benefit from: working with subject matter experts to\nincrease understanding of the risk landscape and possible mitigation\nstrategies; building a community and norms around understanding the impacts of\nML research, e.g. through regular workshops at major conferences; and\nestablishing institutions and systems to support release practices that would\notherwise be onerous and error-prone.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jul 2019 18:51:45 GMT"}, {"version": "v2", "created": "Mon, 29 Jul 2019 02:01:40 GMT"}], "update_date": "2019-07-30", "authors_parsed": [["Ovadya", "Aviv", ""], ["Whittlestone", "Jess", ""]]}, {"id": "1907.11277", "submitter": "Gabriel Aguiar", "authors": "Gabriel Jonas Aguiar, Everton Jos\\'e Santana, Saulo Martiello\n  Mastelini, Rafael Gomes Mantovani, Sylvio Barbon Jr", "title": "Towards meta-learning for multi-target regression problems", "comments": "To appear on the 8th Brazilian Conference on Intelligent Systems\n  (BRACIS)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Several multi-target regression methods were devel-oped in the last years\naiming at improving predictive performanceby exploring inter-target correlation\nwithin the problem. However, none of these methods outperforms the others for\nall problems. This motivates the development of automatic approachesto\nrecommend the most suitable multi-target regression method. In this paper, we\npropose a meta-learning system to recommend the best predictive method for a\ngiven multi-target regression problem. We performed experiments with a\nmeta-dataset generated by a total of 648 synthetic datasets. These datasets\nwere created to explore distinct inter-targets characteristics toward\nrecommending the most promising method. In experiments, we evaluated four\ndifferent algorithms with different biases as meta-learners. Our meta-dataset\nis composed of 58 meta-features, based on: statistical information, correlation\ncharacteristics, linear landmarking, from the distribution and smoothness of\nthe data, and has four different meta-labels. Results showed that induced\nmeta-models were able to recommend the best methodfor different base level\ndatasets with a balanced accuracy superior to 70% using a Random Forest\nmeta-model, which statistically outperformed the meta-learning baselines.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jul 2019 19:05:16 GMT"}], "update_date": "2019-07-29", "authors_parsed": [["Aguiar", "Gabriel Jonas", ""], ["Santana", "Everton Jos\u00e9", ""], ["Mastelini", "Saulo Martiello", ""], ["Mantovani", "Rafael Gomes", ""], ["Barbon", "Sylvio", "Jr"]]}, {"id": "1907.11281", "submitter": "G\\\"unther Waxenegger-Wilfing", "authors": "G\\\"unther Waxenegger-Wilfing, Kai Dresia, Jan Christian Deeken,\n  Michael Oschwald", "title": "Heat Transfer Prediction for Methane in Regenerative Cooling Channels\n  with Neural Networks", "comments": null, "journal-ref": null, "doi": "10.2514/1.T5865", "report-no": null, "categories": "cs.LG physics.app-ph physics.flu-dyn stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Methane is considered being a good choice as a propellant for future reusable\nlaunch systems. However, the heat transfer prediction for supercritical methane\nflowing in cooling channels of a regeneratively cooled combustion chamber is\nchallenging. Because accurate heat transfer predictions are essential to design\nreliable and efficient cooling systems, heat transfer modeling is a fundamental\nissue to address. Advanced computational fluid dynamics (CFD) calculations\nachieve sufficient accuracy, but the associated computational cost prevents an\nefficient integration in optimization loops. Surrogate models based on\nartificial neural networks (ANNs) offer a great speed advantage. It is shown\nthat an ANN, trained on data extracted from samples of CFD simulations, is able\nto predict the maximum wall temperature along straight rocket engine cooling\nchannels using methane with convincing precision. The combination of the ANN\nmodel with simple relations for pressure drop and enthalpy rise results in a\ncomplete reduced order model, which can be used for numerically efficient\ndesign space exploration and optimization.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jul 2019 16:49:09 GMT"}], "update_date": "2020-02-07", "authors_parsed": [["Waxenegger-Wilfing", "G\u00fcnther", ""], ["Dresia", "Kai", ""], ["Deeken", "Jan Christian", ""], ["Oschwald", "Michael", ""]]}, {"id": "1907.11294", "submitter": "Yun Liao", "authors": "Yun Liao, Nariman Farsad, Nir Shlezinger, Yonina C. Eldar, Andrea J.\n  Goldsmith", "title": "Deep Neural Network Symbol Detection for Millimeter Wave Communications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes to use a deep neural network (DNN)-based symbol detector\nfor mmWave systems such that CSI acquisition can be bypassed. In particular, we\nconsider a sliding bidirectional recurrent neural network (BRNN) architecture\nthat is suitable for the long memory length of typical mmWave channels. The\nperformance of the DNN detector is evaluated in comparison to that of the\nViterbi detector. The results show that the performance of the DNN detector is\nclose to that of the optimal Viterbi detector with perfect CSI, and that it\noutperforms the Viterbi algorithm with CSI estimation error. Further\nexperiments show that the DNN detector is robust to a wide range of noise\nlevels and varying channel conditions, and that a pretrained detector can be\nreliably applied to different mmWave channel realizations with minimal\noverhead.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jul 2019 20:06:32 GMT"}], "update_date": "2019-07-29", "authors_parsed": [["Liao", "Yun", ""], ["Farsad", "Nariman", ""], ["Shlezinger", "Nir", ""], ["Eldar", "Yonina C.", ""], ["Goldsmith", "Andrea J.", ""]]}, {"id": "1907.11307", "submitter": "Jiyang Bai", "authors": "Jiyang Bai, Yuxiang Ren and Jiawei Zhang", "title": "DEAM: Adaptive Momentum with Discriminative Weight for Stochastic\n  Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optimization algorithms with momentum, e.g., (ADAM), have been widely used\nfor building deep learning models due to the faster convergence rates compared\nwith stochastic gradient descent (SGD). Momentum helps accelerate SGD in the\nrelevant directions in parameter updating, which can minify the oscillations of\nparameters update route. However, there exist errors in some update steps in\noptimization algorithms with momentum like ADAM. The fixed momentum weight\n(e.g., \\beta_1 in ADAM) will propagate errors in momentum computing. In this\npaper, we introduce a novel optimization algorithm, namely Discriminative\nwEight on Adaptive Momentum (DEAM). Instead of assigning the momentum term\nweight with a fixed hyperparameter, DEAM proposes to compute the momentum\nweight automatically based on the discriminative angle. In this way, DEAM\ninvolves fewer hyperparameters. DEAM also contains a novel backtrack term,\nwhich restricts redundant updates when the correction of the last step is\nneeded. Extensive experiments demonstrate that DEAM can achieve a faster\nconvergence rate than the existing optimization algorithms in training the deep\nlearning models of both convex and non-convex situations.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jul 2019 20:55:54 GMT"}, {"version": "v2", "created": "Thu, 23 Jan 2020 04:36:41 GMT"}], "update_date": "2020-01-24", "authors_parsed": [["Bai", "Jiyang", ""], ["Ren", "Yuxiang", ""], ["Zhang", "Jiawei", ""]]}, {"id": "1907.11313", "submitter": "Piyush Pandita", "authors": "Piyush Pandita, Jesper Kristensen and Liping Wang", "title": "Towards Scalable Gaussian Process Modeling", "comments": "15 pages, 15 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Numerous engineering problems of interest to the industry are often\ncharacterized by expensive black-box objective experiments or computer\nsimulations. Obtaining insight into the problem or performing subsequent\noptimizations requires hundreds of thousands of evaluations of the objective\nfunction which is most often a practically unachievable task. Gaussian Process\n(GP) surrogate modeling replaces the expensive function with a\ncheap-to-evaluate data-driven probabilistic model. While the GP does not assume\na functional form of the problem, it is defined by a set of parameters, called\nhyperparameters. The hyperparameters define the characteristics of the\nobjective function, such as smoothness, magnitude, periodicity, etc. Accurately\nestimating these hyperparameters is a key ingredient in developing a reliable\nand generalizable surrogate model. Markov chain Monte Carlo (MCMC) is a\nubiquitously used Bayesian method to estimate these hyperparameters. At the GE\nGlobal Research Center, a customized industry-strength Bayesian hybrid modeling\nframework utilizing the GP, called GEBHM, has been employed and validated over\nmany years. GEBHM is very effective on problems of small and medium size,\ntypically less than 1000 training points. However, the GP does not scale well\nin time with a growing dataset and problem dimensionality which can be a major\nimpediment in such problems. In this work, we extend and implement in GEBHM an\nAdaptive Sequential Monte Carlo (ASMC) methodology for training the GP enabling\nthe modeling of large-scale industry problems. This implementation saves\ncomputational time (especially for large-scale problems) while not sacrificing\npredictability over the current MCMC implementation. We demonstrate the\neffectiveness and accuracy of GEBHM with ASMC on four mathematical problems and\non two challenging industry applications of varying complexity.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jul 2019 21:15:57 GMT"}], "update_date": "2019-07-29", "authors_parsed": [["Pandita", "Piyush", ""], ["Kristensen", "Jesper", ""], ["Wang", "Liping", ""]]}, {"id": "1907.11318", "submitter": "Jaak Simm", "authors": "Jaak Simm, Adam Arany, Edward De Brouwer, Yves Moreau", "title": "Expressive Graph Informer Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Applying machine learning to molecules is challenging because of their\nnatural representation as graphs rather than vectors.Several architectures have\nbeen recently proposed for deep learning from molecular graphs, but they suffer\nfrom informationbottlenecks because they only pass information from a graph\nnode to its direct neighbors. Here, we introduce a more expressiveroute-based\nmulti-attention mechanism that incorporates features from routes between node\npairs. We call the resulting methodGraph Informer. A single network layer can\ntherefore attend to nodes several steps away. We show empirically that the\nproposedmethod compares favorably against existing approaches in two prediction\ntasks: (1) 13C Nuclear Magnetic Resonance (NMR)spectra, improving the\nstate-of-the-art with an MAE of 1.35 ppm and (2) predicting drug bioactivity\nand toxicity. Additionally, wedevelop a variant called injective Graph Informer\nthat isprovablyas powerful as the Weisfeiler-Lehman test for graph\nisomorphism.Furthermore, we demonstrate that the route information allows the\nmethod to be informed about thenonlocal topologyof the graphand, thus, even go\nbeyond the capabilities of the Weisfeiler-Lehman test.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jul 2019 22:01:32 GMT"}, {"version": "v2", "created": "Mon, 14 Sep 2020 12:56:17 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Simm", "Jaak", ""], ["Arany", "Adam", ""], ["De Brouwer", "Edward", ""], ["Moreau", "Yves", ""]]}, {"id": "1907.11321", "submitter": "Mark-Oliver Stehr", "authors": "Mark-Oliver Stehr, Minyoung Kim, Carolyn L. Talcott, Merrill Knapp,\n  Akos Vertes", "title": "Probabilistic Approximate Logic and its Implementation in the Logical\n  Imagination Engine", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.LO q-bio.CB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In spite of the rapidly increasing number of applications of machine learning\nin various domains, a principled and systematic approach to the incorporation\nof domain knowledge in the engineering process is still lacking and ad hoc\nsolutions that are difficult to validate are still the norm in practice, which\nis of growing concern not only in mission-critical applications.\n  In this note, we introduce Probabilistic Approximate Logic (PALO) as a logic\nbased on the notion of mean approximate probability to overcome conceptual and\ncomputational difficulties inherent to strictly probabilistic logics. The logic\nis approximate in several dimensions. Logical independence assumptions are used\nto obtain approximate probabilities, but by averaging over many instances of\nformulas a useful estimate of mean probability with known confidence can\nusually be obtained. To enable efficient computational inference, the logic has\na continuous semantics that reflects only a subset of the structural properties\nof classical logic, but this imprecision can be partly compensated by richer\ntheories obtained by classical inference or other means. Computational\ninference, which refers to the construction of models and validation of logical\nproperties, is based on Stochastic Gradient Descent (SGD) and Markov Chain\nMonte Carlo (MCMC) techniques and hence another dimension where approximations\nare involved.\n  We also present the Logical Imagination Engine (LIME), a prototypical\nimplementation of PALO based on TensorFlow. Albeit not limited to the\nbiological domain, we illustrate its operation in a quite substantial\nbioinformatics machine learning application concerned with network synthesis\nand analysis in a recent DARPA project.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jul 2019 22:13:24 GMT"}], "update_date": "2019-07-29", "authors_parsed": [["Stehr", "Mark-Oliver", ""], ["Kim", "Minyoung", ""], ["Talcott", "Carolyn L.", ""], ["Knapp", "Merrill", ""], ["Vertes", "Akos", ""]]}, {"id": "1907.11341", "submitter": "Saem Park", "authors": "Saem Park, Nojun Kwak", "title": "Image Enhancement by Recurrently-trained Super-resolution Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new learning strategy for image enhancement by recurrently\ntraining the same simple superresolution (SR) network multiple times. After\ninitially training an SR network by using pairs of a corrupted low resolution\n(LR) image and an original image, the proposed method makes use of the trained\nSR network to generate new high resolution (HR) images with a doubled\nresolution from the original uncorrupted images. Then, the new HR images are\ndownscaled to the original resolution, which work as target images for the SR\nnetwork in the next stage. The newly generated HR images by the repeatedly\ntrained SR network show better image quality and this strategy of training LR\nto mimic new HR can lead to a more efficient SR network. Up to a certain point,\nby repeating this process multiple times, better and better images are\nobtained. This recurrent leaning strategy for SR can be a good solution for\ndownsizing convolution networks and making a more efficient SR network. To\nmeasure the enhanced image quality, for the first time in this area of\nsuper-resolution and image enhancement, we use VIQET MOS score which reflects\nhuman visual quality more accurately than the conventional MSE measure.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jul 2019 00:30:36 GMT"}], "update_date": "2019-07-29", "authors_parsed": [["Park", "Saem", ""], ["Kwak", "Nojun", ""]]}, {"id": "1907.11361", "submitter": "Alzahra Badi", "authors": "Alzahra Badi, Sangwook Park, David K. Han, Hanseok Ko", "title": "Correlation Distance Skip Connection Denoising Autoencoder (CDSK-DAE)\n  for Speech Feature Enhancement", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Performance of learning based Automatic Speech Recognition (ASR) is\nsusceptible to noise, especially when it is introduced in the testing data\nwhile not presented in the training data. This work focuses on a feature\nenhancement for noise robust end-to-end ASR system by introducing a novel\nvariant of denoising autoencoder (DAE). The proposed method uses skip\nconnections in both encoder and decoder sides by passing speech information of\nthe target frame from input to the model. It also uses a new objective function\nin training model that uses a correlation distance measure in penalty terms by\nmeasuring dependency of the latent target features and the model (latent\nfeatures and enhanced features obtained from the DAE). Performance of the\nproposed method was compared against a conventional model and a state of the\nart model under both seen and unseen noisy environments of 7 different types of\nbackground noise with different SNR levels (0, 5, 10 and 20 dB). The proposed\nmethod also is tested using linear and non-linear penalty terms as well, where,\nthey both show an improvement on the overall average WER under noisy conditions\nboth seen and unseen in comparison to the state-of-the-art model.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jul 2019 02:25:44 GMT"}], "update_date": "2019-07-29", "authors_parsed": [["Badi", "Alzahra", ""], ["Park", "Sangwook", ""], ["Han", "David K.", ""], ["Ko", "Hanseok", ""]]}, {"id": "1907.11362", "submitter": "Gi-Soo Kim", "authors": "Gi-Soo Kim and Myunghee Cho Paik", "title": "Doubly-Robust Lasso Bandit", "comments": "Corrections to previous version", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Contextual multi-armed bandit algorithms are widely used in sequential\ndecision tasks such as news article recommendation systems, web page ad\nplacement algorithms, and mobile health. Most of the existing algorithms have\nregret proportional to a polynomial function of the context dimension, $d$. In\nmany applications however, it is often the case that contexts are\nhigh-dimensional with only a sparse subset of size $s_0 (\\ll d)$ being\ncorrelated with the reward. We consider the stochastic linear contextual bandit\nproblem and propose a novel algorithm, namely the Doubly-Robust Lasso Bandit\nalgorithm, which exploits the sparse structure of the regression parameter as\nin Lasso, while blending the doubly-robust technique used in missing data\nliterature. The high-probability upper bound of the regret incurred by the\nproposed algorithm does not depend on the number of arms and scales with\n$\\mathrm{log}(d)$ instead of a polynomial function of $d$. The proposed\nalgorithm shows good performance when contexts of different arms are correlated\nand requires less tuning parameters than existing methods.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jul 2019 02:41:09 GMT"}, {"version": "v2", "created": "Thu, 13 Feb 2020 04:57:50 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["Kim", "Gi-Soo", ""], ["Paik", "Myunghee Cho", ""]]}, {"id": "1907.11367", "submitter": "Sunny Sanyal", "authors": "Sunny Sanyal", "title": "Data Aggregation Techniques for Internet of Things", "comments": "This is the master's thesis of Mr. Sunny Sanyal, who graduated from\n  Chongqing University of Posts and Telecommunications, Chongqing, China. This\n  thesis document has received the Excellent Master's thesis Award 2019\n  (includes all departments) from the University. All the chapters in this\n  thesis are published in various venues", "journal-ref": null, "doi": null, "report-no": "D-10617-308-2019", "categories": "cs.NI cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of this dissertation is to design efficient data aggregation\nframeworks for massive IoT networks in different scenarios to support the\nproper functioning of IoT analytics layer. This dissertation includes modern\nalgorithmic frameworks such as non convex optimization, machine learning,\nstochastic matrix perturbation theory and federated filtering along with modern\ncomputing infrastructure such as fog computing and cloud computing. The\ndevelopment of such an ambitious design involves many open challenges, this\nproposal envisions three major open challenges for IoT data aggregation: first,\nsevere resource constraints of IoT nodes due to limited power and computational\nability, second, the highly uncertain (unreliable) raw IoT data is not fit for\ndecisionmaking and third, network latency and privacy issue for critical\napplications. This dissertation presents three independent novel approaches for\ndistinct scenarios to solve one or more aforementioned open challenges. The\nfirst approach focuses on energy efficient routing; discusses a clustering\nprotocol based on device to device communication for both stationary and mobile\nIoT nodes. The second approach focuses on processing uncertain raw IoT data;\npresents an IoT data aggregation scheme to improve the quality of raw IoT data.\nFinally, the third approach focuses on power loss due to communication overhead\nand privacy issues for medical IoT devices (IoMT); describes a prediction based\ndata aggregation framework for massive IoMT devices.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jul 2019 18:21:58 GMT"}], "update_date": "2019-07-29", "authors_parsed": [["Sanyal", "Sunny", ""]]}, {"id": "1907.11374", "submitter": "Mert Sabuncu", "authors": "Cagla D. Bahadir, Alan Q. Wang, Adrian V. Dalca and Mert R. Sabuncu", "title": "Deep-learning-based Optimization of the Under-sampling Pattern in MRI", "comments": "18 pages, 9 figures, 2 tables", "journal-ref": "IEEE Transactions on Computational Imaging, 2020", "doi": null, "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In compressed sensing MRI (CS-MRI), k-space measurements are under-sampled to\nachieve accelerated scan times. CS-MRI presents two fundamental problems: (1)\nwhere to sample and (2) how to reconstruct an under-sampled scan. In this\npaper, we tackle both problems simultaneously for the specific case of 2D\nCartesian sampling, using a novel end-to-end learning framework that we call\nLOUPE (Learning-based Optimization of the Under-sampling PattErn). Our method\ntrains a neural network model on a set of full-resolution MRI scans, which are\nretrospectively under-sampled on a 2D Cartesian grid and forwarded to an\nanti-aliasing (a.k.a. reconstruction) model that computes a reconstruction,\nwhich is in turn compared with the input. This formulation enables a\ndata-driven optimized under-sampling pattern at a given sparsity level. In our\nexperiments, we demonstrate that LOUPE-optimized under-sampling masks are\ndata-dependent, varying significantly with the imaged anatomy, and perform well\nwith different reconstruction methods. We present empirical results obtained\nwith a large-scale, publicly available knee MRI dataset, where LOUPE offered\nsuperior reconstruction quality across different conditions. Even with an\naggressive 8-fold acceleration rate, LOUPE's reconstructions contained much of\nthe anatomical detail that was missed by alternative masks and reconstruction\nmethods. Our experiments also show how LOUPE yielded optimal under-sampling\npatterns that were significantly different for brain vs knee MRI scans. Our\ncode is made freely available at https://github.com/cagladbahadir/LOUPE/.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jul 2019 03:28:48 GMT"}, {"version": "v2", "created": "Fri, 24 Apr 2020 01:57:44 GMT"}, {"version": "v3", "created": "Thu, 18 Jun 2020 15:30:54 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["Bahadir", "Cagla D.", ""], ["Wang", "Alan Q.", ""], ["Dalca", "Adrian V.", ""], ["Sabuncu", "Mert R.", ""]]}, {"id": "1907.11377", "submitter": "Dongpeng Liu", "authors": "Ming Liu, Dongpeng Liu, Guangyu Sun, Yi Zhao, Duolin Wang, Fangxing\n  Liu, Xiang Fang, Qing He, Dong Xu", "title": "Deep Learning Detection of Inaccurate Smart Electricity Meters: A Case\n  Study", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Detecting inaccurate smart meters and targeting them for replacement can save\nsignificant resources. For this purpose, a novel deep-learning method was\ndeveloped based on long short-term memory (LSTM) and a modified convolutional\nneural network (CNN) to predict electricity usage trajectories based on\nhistorical data. From the significant difference between the predicted\ntrajectory and the observed one, the meters that cannot measure electricity\naccurately are located. In a case study, a proof of principle was demonstrated\nin detecting inaccurate meters with high accuracy for practical usage to\nprevent unnecessary replacement and increase the service life span of smart\nmeters.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jul 2019 04:05:07 GMT"}, {"version": "v2", "created": "Mon, 23 Sep 2019 01:10:07 GMT"}, {"version": "v3", "created": "Fri, 7 Aug 2020 23:29:32 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Liu", "Ming", ""], ["Liu", "Dongpeng", ""], ["Sun", "Guangyu", ""], ["Zhao", "Yi", ""], ["Wang", "Duolin", ""], ["Liu", "Fangxing", ""], ["Fang", "Xiang", ""], ["He", "Qing", ""], ["Xu", "Dong", ""]]}, {"id": "1907.11436", "submitter": "Sebastian Kleinschmidt", "authors": "Sebastian P. Kleinschmidt and Bernardo Wagner", "title": "Semantic Deep Intermodal Feature Transfer: Transferring Feature\n  Descriptors Between Imaging Modalities", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Under difficult environmental conditions, the view of RGB cameras may be\nrestricted by fog, dust or difficult lighting situations. Because thermal\ncameras visualize thermal radiation, they are not subject to the same\nlimitations as RGB cameras. However, because RGB and thermal imaging differ\nsignificantly in appearance, common, state-of-the-art feature descriptors are\nunsuitable for intermodal feature matching between these imaging modalities. As\na consequence, visual maps created with an RGB camera can currently not be used\nfor localization using a thermal camera. In this paper, we introduce the\nSemantic Deep Intermodal Feature Transfer (Se-DIFT), an approach for\ntransferring image feature descriptors from the visual to the thermal spectrum\nand vice versa. For this purpose, we predict potential feature appearance in\nvarying imaging modalities using a deep convolutional encoder-decoder\narchitecture in combination with a global feature vector. Since the\nrepresentation of a thermal image is not only affected by features which can be\nextracted from an RGB image, we introduce the global feature vector which\naugments the auto encoder's coding. The global feature vector contains\nadditional information about the thermal history of a scene which is\nautomatically extracted from external data sources. By augmenting the encoder's\ncoding, we decrease the L1 error of the prediction by more than 7% compared to\nthe prediction of a traditional U-Net architecture. To evaluate our approach,\nwe match image feature descriptors detected in RGB and thermal images using\nSe-DIFT. Subsequently, we make a competitive comparison on the intermodal\ntransferability of SIFT, SURF, and ORB features using our approach.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jul 2019 08:42:38 GMT"}], "update_date": "2019-07-29", "authors_parsed": [["Kleinschmidt", "Sebastian P.", ""], ["Wagner", "Bernardo", ""]]}, {"id": "1907.11452", "submitter": "Heinke Hihn", "authors": "Heinke Hihn, Sebastian Gottwald, and Daniel A. Braun", "title": "An Information-theoretic On-line Learning Principle for Specialization\n  in Hierarchical Decision-Making Systems", "comments": null, "journal-ref": null, "doi": "10.1109/CDC40024.2019.9029255", "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Information-theoretic bounded rationality describes utility-optimizing\ndecision-makers whose limited information-processing capabilities are\nformalized by information constraints. One of the consequences of bounded\nrationality is that resource-limited decision-makers can join together to solve\ndecision-making problems that are beyond the capabilities of each individual.\nHere, we study an information-theoretic principle that drives division of labor\nand specialization when decision-makers with information constraints are joined\ntogether. We devise an on-line learning rule of this principle that learns a\npartitioning of the problem space such that it can be solved by specialized\nlinear policies. We demonstrate the approach for decision-making problems whose\ncomplexity exceeds the capabilities of individual decision-makers, but can be\nsolved by combining the decision-makers optimally. The strength of the model is\nthat it is abstract and principled, yet has direct applications in\nclassification, regression, reinforcement learning and adaptive control.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jul 2019 09:28:18 GMT"}, {"version": "v2", "created": "Thu, 31 Oct 2019 12:37:49 GMT"}, {"version": "v3", "created": "Thu, 5 Dec 2019 09:22:15 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Hihn", "Heinke", ""], ["Gottwald", "Sebastian", ""], ["Braun", "Daniel A.", ""]]}, {"id": "1907.11454", "submitter": "Isabel Funke", "authors": "Isabel Funke, Sebastian Bodenstedt, Florian Oehme, Felix von\n  Bechtolsheim, J\\\"urgen Weitz, and Stefanie Speidel", "title": "Using 3D Convolutional Neural Networks to Learn Spatiotemporal Features\n  for Automatic Surgical Gesture Recognition in Video", "comments": "Accepted at MICCAI 2019. Source code will be made available", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatically recognizing surgical gestures is a crucial step towards a\nthorough understanding of surgical skill. Possible areas of application include\nautomatic skill assessment, intra-operative monitoring of critical surgical\nsteps, and semi-automation of surgical tasks. Solutions that rely only on the\nlaparoscopic video and do not require additional sensor hardware are especially\nattractive as they can be implemented at low cost in many scenarios. However,\nsurgical gesture recognition based only on video is a challenging problem that\nrequires effective means to extract both visual and temporal information from\nthe video. Previous approaches mainly rely on frame-wise feature extractors,\neither handcrafted or learned, which fail to capture the dynamics in surgical\nvideo. To address this issue, we propose to use a 3D Convolutional Neural\nNetwork (CNN) to learn spatiotemporal features from consecutive video frames.\nWe evaluate our approach on recordings of robot-assisted suturing on a\nbench-top model, which are taken from the publicly available JIGSAWS dataset.\nOur approach achieves high frame-wise surgical gesture recognition accuracies\nof more than 84%, outperforming comparable models that either extract only\nspatial features or model spatial and low-level temporal information\nseparately. For the first time, these results demonstrate the benefit of\nspatiotemporal CNNs for video-based surgical gesture recognition.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jul 2019 09:34:09 GMT"}], "update_date": "2019-07-29", "authors_parsed": [["Funke", "Isabel", ""], ["Bodenstedt", "Sebastian", ""], ["Oehme", "Florian", ""], ["von Bechtolsheim", "Felix", ""], ["Weitz", "J\u00fcrgen", ""], ["Speidel", "Stefanie", ""]]}, {"id": "1907.11457", "submitter": "Eduardo Paluzo-Hidalgo", "authors": "Rocio Gonzalez-Diaz, Miguel A. Guti\\'errez-Naranjo, Eduardo\n  Paluzo-Hidalgo", "title": "Two-hidden-layer Feedforward Neural Networks are Universal\n  Approximators: A Constructive Approach", "comments": null, "journal-ref": null, "doi": "10.1016/j.neunet.2020.07.021", "report-no": null, "categories": "cs.LG math.AT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is well known that Artificial Neural Networks are universal approximators.\nThe classical result proves that, given a continuous function on a compact set\non an n-dimensional space, then there exists a one-hidden-layer feedforward\nnetwork which approximates the function. Such result proves the existence, but\nit does not provide a method for finding it. In this paper, a constructive\napproach to the proof of this property is given for the case of\ntwo-hidden-layer feedforward networks. This approach is based on an\napproximation of continuous functions by simplicial maps. Once a triangulation\nof the space is given, a concrete architecture and set of weights can be\nobtained. The quality of the approximation depends on the refinement of the\ncovering of the space by simplicial complexes.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jul 2019 09:43:24 GMT"}, {"version": "v2", "created": "Thu, 16 Jul 2020 20:05:27 GMT"}], "update_date": "2020-07-23", "authors_parsed": [["Gonzalez-Diaz", "Rocio", ""], ["Guti\u00e9rrez-Naranjo", "Miguel A.", ""], ["Paluzo-Hidalgo", "Eduardo", ""]]}, {"id": "1907.11471", "submitter": "Francisco Javier Arag\\'on Artacho", "authors": "Francisco J. Arag\\'on Artacho, Rub\\'en Campoy, Phan T. Vuong", "title": "Using positive spanning sets to achieve d-stationarity with the Boosted\n  DC Algorithm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Difference of Convex functions Algorithm (DCA) is widely used for\nminimizing the difference of two convex functions. A recently proposed\naccelerated version, termed BDCA for Boosted DC Algorithm, incorporates a line\nsearch step to achieve a larger decrease of the objective value at each\niteration. Thanks to this step, BDCA usually converges much faster than DCA in\npractice. The solutions found by DCA are guaranteed to be critical points of\nthe problem, but these may not be local minima. Although BDCA tends to improve\nthe objective value of the solutions it finds, these are frequently just\ncritical points as well. In this paper we combine BDCA with a simple\nDerivative-Free Optimization (DFO) algorithm to force the d-stationarity (lack\nof descent direction) at the point obtained. The potential of this approach is\nillustrated through some computational experiments on a Minimum-Sum-of-Squares\nclustering problem. Our numerical results demonstrate that the new method\nprovides better solutions while still remains faster than DCA in the majority\nof test cases.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jul 2019 10:33:22 GMT"}, {"version": "v2", "created": "Wed, 12 Feb 2020 15:40:24 GMT"}], "update_date": "2020-02-13", "authors_parsed": [["Artacho", "Francisco J. Arag\u00f3n", ""], ["Campoy", "Rub\u00e9n", ""], ["Vuong", "Phan T.", ""]]}, {"id": "1907.11477", "submitter": "Farhan Khan Dr.", "authors": "Farhan Khan", "title": "Online Subspace Tracking for Damage Propagation Modeling and Predictive\n  Analytics: Big Data Perspective", "comments": "14 pages, 5 figures, two tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyze damage propagation modeling of turbo-engines in a data-driven\napproach. We investigate subspace tracking assuming a low dimensional manifold\nstructure and a static behavior during the healthy state of the machines. Our\ndamage propagation model is based on the deviation of the data from the static\nbehavior and uses the notion of health index as a measure of the condition.\nHence, we incorporate condition-based maintenance and estimate the remaining\nuseful life based on the current and previous health indexes. This paper\nproposes an algorithm that adapts well to the dynamics of the data and\nunderlying system, and reduces the computational complexity by utilizing the\nlow dimensional manifold structure of the data. A significant performance\nimprovement is demonstrated over existing methods by using the proposed\nalgorithm on CMAPSS Turbo-engine datasets.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jul 2019 10:56:06 GMT"}], "update_date": "2019-07-29", "authors_parsed": [["Khan", "Farhan", ""]]}, {"id": "1907.11496", "submitter": "Xin Wang", "authors": "Xin Wang, Bo Wu, Yun Ye, Yueqi Zhong", "title": "Outfit Compatibility Prediction and Diagnosis with Multi-Layered\n  Comparison Network", "comments": "9 pages, 6 figures, Proceedings of the 27th ACM International\n  Conference on Multimedia", "journal-ref": null, "doi": "10.1145/3343031.3350909", "report-no": null, "categories": "cs.CV cs.LG cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing works about fashion outfit compatibility focus on predicting the\noverall compatibility of a set of fashion items with their information from\ndifferent modalities. However, there are few works explore how to explain the\nprediction, which limits the persuasiveness and effectiveness of the model. In\nthis work, we propose an approach to not only predict but also diagnose the\noutfit compatibility. We introduce an end-to-end framework for this goal, which\nfeatures for: (1) The overall compatibility is learned from all type-specified\npairwise similarities between items, and the backpropagation gradients are used\nto diagnose the incompatible factors. (2) We leverage the hierarchy of CNN and\ncompare the features at different layers to take into account the\ncompatibilities of different aspects from the low level (such as color,\ntexture) to the high level (such as style). To support the proposed method, we\nbuild a new type-specified outfit dataset named Polyvore-T based on Polyvore\ndataset. We compare our method with the prior state-of-the-art in two tasks:\noutfit compatibility prediction and fill-in-the-blank. Experiments show that\nour approach has advantages in both prediction performance and diagnosis\nability.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jul 2019 11:39:15 GMT"}, {"version": "v2", "created": "Thu, 22 Aug 2019 03:56:30 GMT"}], "update_date": "2019-08-23", "authors_parsed": [["Wang", "Xin", ""], ["Wu", "Bo", ""], ["Ye", "Yun", ""], ["Zhong", "Yueqi", ""]]}, {"id": "1907.11499", "submitter": "Yumo Xu", "authors": "Yumo Xu and Mirella Lapata", "title": "Weakly Supervised Domain Detection", "comments": "To appear in Transactions of the Association for Computational\n  Linguistics (TACL); 16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we introduce domain detection as a new natural language\nprocessing task. We argue that the ability to detect textual segments which are\ndomain-heavy, i.e., sentences or phrases which are representative of and\nprovide evidence for a given domain could enhance the robustness and\nportability of various text classification applications. We propose an\nencoder-detector framework for domain detection and bootstrap classifiers with\nmultiple instance learning (MIL). The model is hierarchically organized and\nsuited to multilabel classification. We demonstrate that despite learning with\nminimal supervision, our model can be applied to text spans of different\ngranularities, languages, and genres. We also showcase the potential of domain\ndetection for text summarization.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jul 2019 11:53:15 GMT"}], "update_date": "2019-07-29", "authors_parsed": [["Xu", "Yumo", ""], ["Lapata", "Mirella", ""]]}, {"id": "1907.11503", "submitter": "Dr. Mohammed Javed", "authors": "Bulla Rajesh and Mohammed Javed and Ratnesh and Shubham Srivastava", "title": "DCT-CompCNN: A Novel Image Classification Network Using JPEG Compressed\n  DCT Coefficients", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The popularity of Convolutional Neural Network (CNN) in the field of Image\nProcessing and Computer Vision has motivated researchers and industrialist\nexperts across the globe to solve different challenges with high accuracy. The\nsimplest way to train a CNN classifier is to directly feed the original RGB\npixels images into the network. However, if we intend to classify images\ndirectly with its compressed data, the same approach may not work better, like\nin case of JPEG compressed images. This research paper investigates the issues\nof modifying the input representation of the JPEG compressed data, and then\nfeeding into the CNN. The architecture is termed as DCT-CompCNN. This novel\napproach has shown that CNNs can also be trained with JPEG compressed DCT\ncoefficients, and subsequently can produce a better performance in comparison\nwith the conventional CNN approach. The efficiency of the modified input\nrepresentation is tested with the existing ResNet-50 architecture and the\nproposed DCT-CompCNN architecture on a public image classification datasets\nlike Dog Vs Cat and CIFAR-10 datasets, reporting a better performance\n", "versions": [{"version": "v1", "created": "Fri, 26 Jul 2019 12:01:21 GMT"}], "update_date": "2019-07-29", "authors_parsed": [["Rajesh", "Bulla", ""], ["Javed", "Mohammed", ""], ["Ratnesh", "", ""], ["Srivastava", "Shubham", ""]]}, {"id": "1907.11505", "submitter": "Jos\\'e Enrique Chac\\'on", "authors": "Jos\\'e E. Chac\\'on", "title": "A close-up comparison of the misclassification error distance and the\n  adjusted Rand index for external clustering evaluation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The misclassification error distance and the adjusted Rand index are two of\nthe most commonly used criteria to evaluate the performance of clustering\nalgorithms. This paper provides an in-depth comparison of the two criteria,\naimed to better understand exactly what they measure, their properties and\ntheir differences. Starting from their population origins, the investigation\nincludes many data analysis examples and the study of particular cases in great\ndetail. An exhaustive simulation study allows inspecting the criteria\ndistributions and reveals some previous misconceptions.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jul 2019 12:11:40 GMT"}], "update_date": "2019-07-29", "authors_parsed": [["Chac\u00f3n", "Jos\u00e9 E.", ""]]}, {"id": "1907.11510", "submitter": "Fabien Ringeval", "authors": "Fabien Ringeval, Bj\\\"orn Schuller, Michel Valstar, NIcholas Cummins,\n  Roddy Cowie, Leili Tavabi, Maximilian Schmitt, Sina Alisamir, Shahin\n  Amiriparian, Eva-Maria Messner, Siyang Song, Shuo Liu, Ziping Zhao, Adria\n  Mallol-Ragolta, Zhao Ren, Mohammad Soleymani, Maja Pantic", "title": "AVEC 2019 Workshop and Challenge: State-of-Mind, Detecting Depression\n  with AI, and Cross-Cultural Affect Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CV cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Audio/Visual Emotion Challenge and Workshop (AVEC 2019) \"State-of-Mind,\nDetecting Depression with AI, and Cross-cultural Affect Recognition\" is the\nninth competition event aimed at the comparison of multimedia processing and\nmachine learning methods for automatic audiovisual health and emotion analysis,\nwith all participants competing strictly under the same conditions. The goal of\nthe Challenge is to provide a common benchmark test set for multimodal\ninformation processing and to bring together the health and emotion recognition\ncommunities, as well as the audiovisual processing communities, to compare the\nrelative merits of various approaches to health and emotion recognition from\nreal-life data. This paper presents the major novelties introduced this year,\nthe challenge guidelines, the data used, and the performance of the baseline\nsystems on the three proposed tasks: state-of-mind recognition, depression\nassessment with AI, and cross-cultural affect sensing, respectively.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jul 2019 13:41:42 GMT"}], "update_date": "2019-07-29", "authors_parsed": [["Ringeval", "Fabien", ""], ["Schuller", "Bj\u00f6rn", ""], ["Valstar", "Michel", ""], ["Cummins", "NIcholas", ""], ["Cowie", "Roddy", ""], ["Tavabi", "Leili", ""], ["Schmitt", "Maximilian", ""], ["Alisamir", "Sina", ""], ["Amiriparian", "Shahin", ""], ["Messner", "Eva-Maria", ""], ["Song", "Siyang", ""], ["Liu", "Shuo", ""], ["Zhao", "Ziping", ""], ["Mallol-Ragolta", "Adria", ""], ["Ren", "Zhao", ""], ["Soleymani", "Mohammad", ""], ["Pantic", "Maja", ""]]}, {"id": "1907.11519", "submitter": "Dumindu Tissera", "authors": "Dumindu Tissera, Kumara Kahatapitiya, Rukshan Wijesinghe, Subha\n  Fernando, Ranga Rodrigo", "title": "Context-Aware Multipath Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Making a single network effectively address diverse contexts---learning the\nvariations within a dataset or multiple datasets---is an intriguing step\ntowards achieving generalized intelligence. Existing approaches of deepening,\nwidening, and assembling networks are not cost effective in general. In view of\nthis, networks which can allocate resources according to the context of the\ninput and regulate flow of information across the network are effective. In\nthis paper, we present Context-Aware Multipath Network (CAMNet), a multi-path\nneural network with data-dependant routing between parallel tensors. We show\nthat our model performs as a generalized model capturing variations in\nindividual datasets and multiple different datasets, both simultaneously and\nsequentially. CAMNet surpasses the performance of classification and\npixel-labeling tasks in comparison with the equivalent single-path, multi-path,\nand deeper single-path networks, considering datasets individually,\nsequentially, and in combination. The data-dependent routing between tensors in\nCAMNet enables the model to control the flow of information end-to-end,\ndeciding which resources to be common or domain-specific.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jul 2019 12:34:31 GMT"}], "update_date": "2019-07-29", "authors_parsed": [["Tissera", "Dumindu", ""], ["Kahatapitiya", "Kumara", ""], ["Wijesinghe", "Rukshan", ""], ["Fernando", "Subha", ""], ["Rodrigo", "Ranga", ""]]}, {"id": "1907.11546", "submitter": "Simone Scardapane", "authors": "Riccardo Vecchi, Simone Scardapane, Danilo Comminiello, Aurelio Uncini", "title": "Compressing deep quaternion neural networks with targeted regularization", "comments": "Published on CAAI Transactions on Intelligence Technology,\n  https://digital-library.theiet.org/content/journals/10.1049/trit.2020.0020", "journal-ref": null, "doi": "10.1049/trit.2020.0020", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, hyper-complex deep networks (such as complex-valued and\nquaternion-valued neural networks) have received a renewed interest in the\nliterature. They find applications in multiple fields, ranging from image\nreconstruction to 3D audio processing. Similar to their real-valued\ncounterparts, quaternion neural networks (QVNNs) require custom regularization\nstrategies to avoid overfitting. In addition, for many real-world applications\nand embedded implementations, there is the need of designing sufficiently\ncompact networks, with few weights and neurons. However, the problem of\nregularizing and/or sparsifying QVNNs has not been properly addressed in the\nliterature as of now. In this paper, we show how to address both problems by\ndesigning targeted regularization strategies, which are able to minimize the\nnumber of connections and neurons of the network during training. To this end,\nwe investigate two extensions of l1 and structured regularization to the\nquaternion domain. In our experimental evaluation, we show that these tailored\nstrategies significantly outperform classical (real-valued) regularization\napproaches, resulting in small networks especially suitable for low-power and\nreal-time applications.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jul 2019 12:55:55 GMT"}, {"version": "v2", "created": "Tue, 28 Jan 2020 14:50:23 GMT"}, {"version": "v3", "created": "Mon, 13 Jul 2020 08:23:37 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Vecchi", "Riccardo", ""], ["Scardapane", "Simone", ""], ["Comminiello", "Danilo", ""], ["Uncini", "Aurelio", ""]]}, {"id": "1907.11555", "submitter": "Zach Eaton-Rosen", "authors": "Zach Eaton-Rosen, Thomas Varsavsky, Sebastien Ourselin and M. Jorge\n  Cardoso", "title": "As easy as 1, 2... 4? Uncertainty in counting tasks for medical imaging", "comments": "Early Accept to MICCAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Counting is a fundamental task in biomedical imaging and count is an\nimportant biomarker in a number of conditions. Estimating the uncertainty in\nthe measurement is thus vital to making definite, informed conclusions. In this\npaper, we first compare a range of existing methods to perform counting in\nmedical imaging and suggest ways of deriving predictive intervals from these.\nWe then propose and test a method for calculating intervals as an output of a\nmulti-task network. These predictive intervals are optimised to be as narrow as\npossible, while also enclosing a desired percentage of the data. We demonstrate\nthe effectiveness of this technique on histopathological cell counting and\nwhite matter hyperintensity counting. Finally, we offer insight into other\nareas where this technique may apply.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jul 2019 15:11:32 GMT"}], "update_date": "2019-07-29", "authors_parsed": [["Eaton-Rosen", "Zach", ""], ["Varsavsky", "Thomas", ""], ["Ourselin", "Sebastien", ""], ["Cardoso", "M. Jorge", ""]]}, {"id": "1907.11559", "submitter": "Guilherme Pombo", "authors": "Guilherme Pombo, Robert Gray, Tom Varsavsky, John Ashburner, Parashkev\n  Nachev", "title": "Bayesian Volumetric Autoregressive generative models for better\n  semisupervised learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV eess.IV stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep generative models are rapidly gaining traction in medical imaging.\nNonetheless, most generative architectures struggle to capture the underlying\nprobability distributions of volumetric data, exhibit convergence problems, and\noffer no robust indices of model uncertainty. By comparison, the autoregressive\ngenerative model PixelCNN can be extended to volumetric data with relative\nease, it readily attempts to learn the true underlying probability distribution\nand it still admits a Bayesian reformulation that provides a principled\nframework for reasoning about model uncertainty. Our contributions in this\npaper are two fold: first, we extend PixelCNN to work with volumetric brain\nmagnetic resonance imaging data. Second, we show that reformulating this model\nto approximate a deep Gaussian process yields a measure of uncertainty that\nimproves the performance of semi-supervised learning, in particular\nclassification performance in settings where the proportion of labelled data is\nlow. We quantify this improvement across classification, regression, and\nsemantic segmentation tasks, training and testing on clinical magnetic\nresonance brain imaging data comprising T1-weighted and diffusion-weighted\nsequences.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jul 2019 13:08:36 GMT"}], "update_date": "2019-07-29", "authors_parsed": [["Pombo", "Guilherme", ""], ["Gray", "Robert", ""], ["Varsavsky", "Tom", ""], ["Ashburner", "John", ""], ["Nachev", "Parashkev", ""]]}, {"id": "1907.11561", "submitter": "Jos\\'e Esgario", "authors": "J. G. M. Esgario, R. A. Krohling, J. A. Ventura", "title": "Deep Learning for Classification and Severity Estimation of Coffee Leaf\n  Biotic Stress", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Biotic stress consists of damage to plants through other living organisms.\nEfficient control of biotic agents such as pests and pathogens (viruses, fungi,\nbacteria, etc.) is closely related to the concept of agricultural\nsustainability. Agricultural sustainability promotes the development of new\ntechnologies that allow the reduction of environmental impacts, greater\naccessibility to farmers and, consequently, increase on productivity. The use\nof computer vision with deep learning methods allows the early and correct\nidentification of the stress-causing agent. So, corrective measures can be\napplied as soon as possible to mitigate the problem. The objective of this work\nis to design an effective and practical system capable of identifying and\nestimating the stress severity caused by biotic agents on coffee leaves. The\nproposed approach consists of a multi-task system based on convolutional neural\nnetworks. In addition, we have explored the use of data augmentation techniques\nto make the system more robust and accurate. The experimental results obtained\nfor classification as well as for severity estimation indicate that the\nproposed system might be a suitable tool to assist both experts and farmers in\nthe identification and quantification of biotic stresses in coffee plantations.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jul 2019 13:12:44 GMT"}], "update_date": "2019-07-29", "authors_parsed": [["Esgario", "J. G. M.", ""], ["Krohling", "R. A.", ""], ["Ventura", "J. A.", ""]]}, {"id": "1907.11569", "submitter": "Anna Nguyen", "authors": "Anna Nguyen and Tobias Weller and Michael F\\\"arber and York\n  Sure-Vetter", "title": "Making Neural Networks FAIR", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Research on neural networks has gained significant momentum over the past few\nyears. Because training is a resource-intensive process and training data\ncannot always be made available to everyone, there has been a trend to reuse\npre-trained neural networks. As such, neural networks themselves have become\nresearch data. In this paper, we first present the neural network ontology\nFAIRnets Ontology, an ontology to make existing neural network models findable,\naccessible, interoperable, and reusable according to the FAIR principles. Our\nontology allows us to model neural networks on a meta-level in a structured\nway, including the representation of all network layers and their\ncharacteristics. Secondly, we have modeled over 18,400 neural networks from\nGitHub based on this ontology, which we provide to the public as a knowledge\ngraph called FAIRnets, ready to be used for recommending suitable neural\nnetworks to data scientists.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jul 2019 13:30:02 GMT"}, {"version": "v2", "created": "Tue, 28 Jul 2020 12:32:41 GMT"}, {"version": "v3", "created": "Mon, 7 Sep 2020 21:51:37 GMT"}, {"version": "v4", "created": "Tue, 1 Dec 2020 16:02:49 GMT"}], "update_date": "2020-12-02", "authors_parsed": [["Nguyen", "Anna", ""], ["Weller", "Tobias", ""], ["F\u00e4rber", "Michael", ""], ["Sure-Vetter", "York", ""]]}, {"id": "1907.11572", "submitter": "Nathan Wycoff", "authors": "Nathan Wycoff and Mickael Binois and Stefan M. Wild", "title": "Sequential Learning of Active Subspaces", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, active subspace methods (ASMs) have become a popular means\nof performing subspace sensitivity analysis on black-box functions. Naively\napplied, however, ASMs require gradient evaluations of the target function. In\nthe event of noisy, expensive, or stochastic simulators, evaluating gradients\nvia finite differencing may be infeasible. In such cases, often a surrogate\nmodel is employed, on which finite differencing is performed. When the\nsurrogate model is a Gaussian process, we show that the ASM estimator is\navailable in closed form, rendering the finite-difference approximation\nunnecessary. We use our closed-form solution to develop acquisition functions\nfocused on sequential learning tailored to sensitivity analysis on top of ASMs.\nWe also show that the traditional ASM estimator may be viewed as a method of\nmoments estimator for a certain class of Gaussian processes. We demonstrate how\nuncertainty on Gaussian process hyperparameters may be propagated to\nuncertainty on the sensitivity analysis, allowing model-based confidence\nintervals on the active subspace. Our methodological developments are\nillustrated on several examples.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jul 2019 13:39:23 GMT"}, {"version": "v2", "created": "Sun, 20 Sep 2020 16:14:39 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Wycoff", "Nathan", ""], ["Binois", "Mickael", ""], ["Wild", "Stefan M.", ""]]}, {"id": "1907.11584", "submitter": "Xiang Geng", "authors": "Xiang Geng, Bin Gu, Xiang Li, Wanli Shi, Guansheng Zheng and Heng\n  Huang", "title": "Scalable Semi-Supervised SVM via Triply Stochastic Gradients", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semi-supervised learning (SSL) plays an increasingly important role in the\nbig data era because a large number of unlabeled samples can be used\neffectively to improve the performance of the classifier. Semi-supervised\nsupport vector machine (S$^3$VM) is one of the most appealing methods for SSL,\nbut scaling up S$^3$VM for kernel learning is still an open problem. Recently,\na doubly stochastic gradient (DSG) algorithm has been proposed to achieve\nefficient and scalable training for kernel methods. However, the algorithm and\ntheoretical analysis of DSG are developed based on the convexity assumption\nwhich makes them incompetent for non-convex problems such as S$^3$VM. To\naddress this problem, in this paper, we propose a triply stochastic gradient\nalgorithm for S$^3$VM, called TSGS$^3$VM. Specifically, to handle two types of\ndata instances involved in S$^3$VM, TSGS$^3$VM samples a labeled instance and\nan unlabeled instance as well with the random features in each iteration to\ncompute a triply stochastic gradient. We use the approximated gradient to\nupdate the solution. More importantly, we establish new theoretic analysis for\nTSGS$^3$VM which guarantees that TSGS$^3$VM can converge to a stationary point.\nExtensive experimental results on a variety of datasets demonstrate that\nTSGS$^3$VM is much more efficient and scalable than existing S$^3$VM\nalgorithms.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jul 2019 14:10:23 GMT"}], "update_date": "2019-07-29", "authors_parsed": [["Geng", "Xiang", ""], ["Gu", "Bin", ""], ["Li", "Xiang", ""], ["Shi", "Wanli", ""], ["Zheng", "Guansheng", ""], ["Huang", "Heng", ""]]}, {"id": "1907.11605", "submitter": "Cem Tekin", "authors": "Alihan H\\\"uy\\\"uk and Cem Tekin", "title": "Lexicographic Multiarmed Bandit", "comments": "22 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a multiobjective multiarmed bandit problem with lexicographically\nordered objectives. In this problem, the goal of the learner is to select arms\nthat are lexicographic optimal as much as possible without knowing the arm\nreward distributions beforehand. We capture this goal by defining a\nmultidimensional form of regret that measures the loss of the learner due to\nnot selecting lexicographic optimal arms, and then, consider two settings where\nthe learner has prior information on the expected arm rewards. In the first\nsetting, the learner only knows for each objective the lexicographic optimal\nexpected reward. In the second setting, it only knows for each objective\nnear-lexicographic optimal expected rewards. For both settings we prove that\nthe learner achieves expected regret uniformly bounded in time. The algorithm\nwe propose for the second setting also attains bounded regret for the\nmultiarmed bandit with satisficing objectives. In addition, we also consider\nthe harder prior-free case, and show that the learner can still achieve\nsublinear in time gap-free regret. Finally, we experimentally evaluate\nperformance of the proposed algorithms in a variety of multiobjective learning\nproblems.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jul 2019 14:48:07 GMT"}, {"version": "v2", "created": "Mon, 29 Jul 2019 10:52:11 GMT"}], "update_date": "2019-07-30", "authors_parsed": [["H\u00fcy\u00fck", "Alihan", ""], ["Tekin", "Cem", ""]]}, {"id": "1907.11612", "submitter": "Ido Hakimi", "authors": "Ido Hakimi, Saar Barkai, Moshe Gabel, Assaf Schuster", "title": "Taming Momentum in a Distributed Asynchronous Environment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although distributed computing can significantly reduce the training time of\ndeep neural networks, scaling the training process while maintaining high\nefficiency and final accuracy is challenging. Distributed asynchronous training\nenjoys near-linear speedup, but asynchrony causes gradient staleness - the main\ndifficulty in scaling stochastic gradient descent to large clusters. Momentum,\nwhich is often used to accelerate convergence and escape local minima,\nexacerbates the gradient staleness, thereby hindering convergence. We propose\nDANA: a novel technique for asynchronous distributed SGD with momentum that\nmitigates gradient staleness by computing the gradient on an estimated future\nposition of the model's parameters. Thereby, we show for the first time that\nmomentum can be fully incorporated in asynchronous training with almost no\nramifications to final accuracy. Our evaluation on the CIFAR and ImageNet\ndatasets shows that DANA outperforms existing methods, in both final accuracy\nand convergence speed while scaling up to a total batch size of 16K on 64\nasynchronous workers.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jul 2019 15:07:49 GMT"}, {"version": "v2", "created": "Tue, 13 Oct 2020 15:23:20 GMT"}, {"version": "v3", "created": "Wed, 14 Oct 2020 06:09:35 GMT"}], "update_date": "2020-10-15", "authors_parsed": [["Hakimi", "Ido", ""], ["Barkai", "Saar", ""], ["Gabel", "Moshe", ""], ["Schuster", "Assaf", ""]]}, {"id": "1907.11617", "submitter": "Ashesh Chattopadhyay", "authors": "Ashesh Chattopadhyay, Ebrahim Nabizadeh, Pedram Hassanzadeh", "title": "Analog forecasting of extreme-causing weather patterns using deep\n  learning", "comments": "Accepted in Journal of Advances in Modeling Earth System", "journal-ref": null, "doi": "10.1029/2019MS001958", "report-no": null, "categories": "physics.ao-ph cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Numerical weather prediction (NWP) models require ever-growing computing\ntime/resources, but still, have difficulties with predicting weather extremes.\nHere we introduce a data-driven framework that is based on analog forecasting\n(prediction using past similar patterns) and employs a novel deep learning\npattern-recognition technique (capsule neural networks, CapsNets) and\nimpact-based auto-labeling strategy. CapsNets are trained on mid-tropospheric\nlarge-scale circulation patterns (Z500) labeled $0-4$ depending on the\nexistence and geographical region of surface temperature extremes over North\nAmerica several days ahead. The trained networks predict the occurrence/region\nof cold or heat waves, only using Z500, with accuracies (recalls) of\n$69\\%-45\\%$ $(77\\%-48\\%)$ or $62\\%-41\\%$ $(73\\%-47\\%)$ $1-5$ days ahead.\nCapsNets outperform simpler techniques such as convolutional neural networks\nand logistic regression. Using both temperature and Z500, accuracies (recalls)\nwith CapsNets increase to $\\sim 80\\%$ $(88\\%)$, showing the promises of\nmulti-modal data-driven frameworks for accurate/fast extreme weather\npredictions, which can augment NWP efforts in providing early warnings.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jul 2019 15:13:57 GMT"}, {"version": "v2", "created": "Sun, 12 Jan 2020 16:58:42 GMT"}], "update_date": "2020-04-22", "authors_parsed": [["Chattopadhyay", "Ashesh", ""], ["Nabizadeh", "Ebrahim", ""], ["Hassanzadeh", "Pedram", ""]]}, {"id": "1907.11623", "submitter": "Mirco Mannucci Ph.D.", "authors": "Mirco A. Mannucci, Deborah Tylor", "title": "Node Alertness-Detecting changes in rapidly evolving graphs", "comments": "8 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article we describe a new approach for detecting changes in rapidly\nevolving large-scale graphs. The key notion involved is local alertness: nodes\nmonitor change within their neighborhoods at each time step. Here we propose a\nfinancial local alertness application for cointegrated stock pairs\n", "versions": [{"version": "v1", "created": "Tue, 2 Jul 2019 12:11:24 GMT"}], "update_date": "2019-07-29", "authors_parsed": [["Mannucci", "Mirco A.", ""], ["Tylor", "Deborah", ""]]}, {"id": "1907.11624", "submitter": "Hansi Zhang", "authors": "Hansi Zhang, Christopher Wheldon, Adam G. Dunn, Cui Tao, Jinhai Huo,\n  Rui Zhang, Mattia Prosperi, Yi Guo, Jiang Bian", "title": "Mining Twitter to Assess the Determinants of Health Behavior towards\n  Human Papillomavirus Vaccination in the United States", "comments": "6 figures, 5 tables, Journal of the American Medical Informatics\n  Association, Under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Objectives To test the feasibility of using Twitter data to assess\ndeterminants of consumers' health behavior towards Human papillomavirus (HPV)\nvaccination informed by the Integrated Behavior Model (IBM).\n  Methods We used three Twitter datasets spanning from 2014 to 2018. We\npreprocessed and geocoded the tweets, and then built a rule-based model that\nclassified each tweet into either promotional information or consumers'\ndiscussions. We applied topic modeling to discover major themes, and\nsubsequently explored the associations between the topics learned from\nconsumers' discussions and the responses of HPV-related questions in the Health\nInformation National Trends Survey (HINTS).\n  Results We collected 2,846,495 tweets and analyzed 335,681 geocoded tweets.\nThrough topic modeling, we identified 122 high-quality topics. The most\ndiscussed consumer topic is \"cervical cancer screening\"; while in promotional\ntweets, the most popular topic is to increase awareness of \"HPV causes cancer\".\n87 out of the 122 topics are correlated between promotional information and\nconsumers' discussions. Guided by IBM, we examined the alignment between our\nTwitter findings and the results obtained from HINTS. 35 topics can be mapped\nto HINTS questions by keywords, 112 topics can be mapped to IBM constructs, and\n45 topics have statistically significant correlations with HINTS responses in\nterms of geographic distributions.\n  Conclusion Not only mining Twitter to assess consumers' health behaviors can\nobtain results comparable to surveys but can yield additional insights via a\ntheory-driven approach. Limitations exist, nevertheless, these encouraging\nresults impel us to develop innovative ways of leveraging social media in the\nchanging health communication landscape.\n", "versions": [{"version": "v1", "created": "Sat, 6 Jul 2019 18:51:51 GMT"}], "update_date": "2019-07-29", "authors_parsed": [["Zhang", "Hansi", ""], ["Wheldon", "Christopher", ""], ["Dunn", "Adam G.", ""], ["Tao", "Cui", ""], ["Huo", "Jinhai", ""], ["Zhang", "Rui", ""], ["Prosperi", "Mattia", ""], ["Guo", "Yi", ""], ["Bian", "Jiang", ""]]}, {"id": "1907.11625", "submitter": "Harshavardhan Kamarthi", "authors": "Harshavardhan Kamarthi, Priyesh Vijayan, Bryan Wilder, Balaraman\n  Ravindran, Milind Tambe", "title": "Influence maximization in unknown social networks: Learning Policies for\n  Effective Graph Sampling", "comments": "Accepted at AAMAS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A serious challenge when finding influential actors in real-world social\nnetworks is the lack of knowledge about the structure of the underlying\nnetwork. Current state-of-the-art methods rely on hand-crafted sampling\nalgorithms; these methods sample nodes and their neighbours in a carefully\nconstructed order and choose opinion leaders from this discovered network to\nmaximize influence spread in the (unknown) complete network. In this work, we\npropose a reinforcement learning framework for network discovery that\nautomatically learns useful node and graph representations that encode\nimportant structural properties of the network. At training time, the method\nidentifies portions of the network such that the nodes selected from this\nsampled subgraph can effectively influence nodes in the complete network. The\nrealization of such transferable network structure based adaptable policies is\nattributed to the meticulous design of the framework that encodes relevant node\nand graph signatures driven by an appropriate reward scheme. We experiment with\nreal-world social networks from four different domains and show that the\npolicies learned by our RL agent provide a 10-36% improvement over the current\nstate-of-the-art method.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jul 2019 19:59:40 GMT"}, {"version": "v2", "created": "Mon, 23 Dec 2019 12:09:00 GMT"}, {"version": "v3", "created": "Thu, 23 Jan 2020 17:22:28 GMT"}, {"version": "v4", "created": "Tue, 18 Feb 2020 03:54:43 GMT"}, {"version": "v5", "created": "Thu, 20 Feb 2020 08:17:06 GMT"}], "update_date": "2020-02-21", "authors_parsed": [["Kamarthi", "Harshavardhan", ""], ["Vijayan", "Priyesh", ""], ["Wilder", "Bryan", ""], ["Ravindran", "Balaraman", ""], ["Tambe", "Milind", ""]]}, {"id": "1907.11629", "submitter": "Stefano B. Blumberg", "authors": "Stefano B. Blumberg, Marco Palombo, Can Son Khoo, Chantal M. W. Tax,\n  Ryutaro Tanno, and Daniel C. Alexander", "title": "Multi-Stage Prediction Networks for Data Harmonization", "comments": "Accepted In Medical Image Computing and Computer Assisted\n  Intervention (MICCAI) 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce multi-task learning (MTL) to data harmonization\n(DH); where we aim to harmonize images across different acquisition platforms\nand sites. This allows us to integrate information from multiple acquisitions\nand improve the predictive performance and learning efficiency of the\nharmonization model. Specifically, we introduce the Multi Stage Prediction\n(MSP) Network, a MTL framework that incorporates neural networks of potentially\ndisparate architectures, trained for different individual acquisition\nplatforms, into a larger architecture that is refined in unison. The MSP\nutilizes high-level features of single networks for individual tasks, as inputs\nof additional neural networks to inform the final prediction, therefore\nexploiting redundancy across tasks to make the most of limited training data.\nWe validate our methods on a dMRI harmonization challenge dataset, where we\npredict three modern platform types, from one obtained from an old scanner. We\nshow how MTL architectures, such as the MSP, produce around 20\\% improvement of\npatch-based mean-squared error over current state-of-the-art methods and that\nour MSP outperforms off-the-shelf MTL networks. Our code is available\nhttps://github.com/sbb-gh/ .\n", "versions": [{"version": "v1", "created": "Fri, 26 Jul 2019 15:29:46 GMT"}], "update_date": "2019-07-29", "authors_parsed": [["Blumberg", "Stefano B.", ""], ["Palombo", "Marco", ""], ["Khoo", "Can Son", ""], ["Tax", "Chantal M. W.", ""], ["Tanno", "Ryutaro", ""], ["Alexander", "Daniel C.", ""]]}, {"id": "1907.11634", "submitter": "Ke Ren", "authors": "Ke Ren and Avinash Malik", "title": "Recommendation Engine for Lower Interest Borrowing on Peer to Peer\n  Lending (P2PL) Platform", "comments": "Accepted in Web intelligence 2019, this is a long version", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.GN cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online Peer to Peer Lending (P2PL) systems connect lenders and borrowers\ndirectly, thereby making it convenient to borrow and lend money without\nintermediaries such as banks. Many recommendation systems have been developed\nfor lenders to achieve higher interest rates and avoid defaulting loans.\nHowever, there has not been much research in developing recommendation systems\nto help borrowers make wise decisions. On P2PL platforms, borrowers can either\napply for bidding loans, where the interest rate is determined by lenders\nbidding on a loan or traditional loans where the P2PL platform determines the\ninterest rate. Different borrower grades -- determining the credit worthiness\nof borrowers get different interest rates via these two mechanisms. Hence, it\nis essential to determine which type of loans borrowers should apply for. In\nthis paper, we build a recommendation system that recommends to any new\nborrower the type of loan they should apply for. Using our recommendation\nsystem, any borrower can achieve lowered interest rates with a higher\nlikelihood of getting funded.\n", "versions": [{"version": "v1", "created": "Sat, 20 Jul 2019 06:26:47 GMT"}], "update_date": "2019-07-29", "authors_parsed": [["Ren", "Ke", ""], ["Malik", "Avinash", ""]]}, {"id": "1907.11639", "submitter": "Michael Hauser", "authors": "Michael Hauser", "title": "Training capsules as a routing-weighted product of expert neurons", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Capsules are the multidimensional analogue to scalar neurons in neural\nnetworks, and because they are multidimensional, much more complex routing\nschemes can be used to pass information forward through the network than what\ncan be used in traditional neural networks. This work treats capsules as\ncollections of neurons in a fully connected neural network, where sub-networks\nconnecting capsules are weighted according to the routing coefficients\ndetermined by routing by agreement. An energy function is designed to reflect\nthis model, and it follows that capsule networks with dynamic routing can be\nformulated as a product of expert neurons. By alternating between dynamic\nrouting, which acts to both find subnetworks within the overall network as well\nas to mix the model distribution, and updating the parameters by the gradient\nof the contrastive divergence, a bottom-up, unsupervised learning algorithm is\nconstructed for capsule networks with dynamic routing. The model and its\ntraining algorithm are qualitatively tested in the generative sense, and is\nable to produce realistic looking images from standard vision datasets.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jul 2019 15:51:49 GMT"}], "update_date": "2019-07-29", "authors_parsed": [["Hauser", "Michael", ""]]}, {"id": "1907.11643", "submitter": "Michael Hauser", "authors": "Michael Hauser", "title": "Training products of expert capsules with mixing by dynamic routing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This study develops an unsupervised learning algorithm for products of expert\ncapsules with dynamic routing. Analogous to binary-valued neurons in Restricted\nBoltzmann Machines, the magnitude of a squashed capsule firing takes values\nbetween zero and one, representing the probability of the capsule being on.\nThis analogy motivates the design of an energy function for capsule networks.\nIn order to have an efficient sampling procedure where hidden layer nodes are\nnot connected, the energy function is made consistent with dynamic routing in\nthe sense of the probability of a capsule firing, and inference on the capsule\nnetwork is computed with the dynamic routing between capsules procedure. In\norder to optimize the log-likelihood of the visible layer capsules, the\ngradient is found in terms of this energy function. The developed unsupervised\nlearning algorithm is used to train a capsule network on standard vision\ndatasets, and is able to generate realistic looking images from its learned\ndistribution.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jul 2019 15:58:56 GMT"}], "update_date": "2019-07-29", "authors_parsed": [["Hauser", "Michael", ""]]}, {"id": "1907.11649", "submitter": "George Tang", "authors": "Ankit Gupta, George Tang, Sylesh Suresh", "title": "HeartFit: An Accurate Platform for Heart Murmur Diagnosis Utilizing Deep\n  Learning", "comments": "Paper stemmed from invalid, not even completed project and was\n  drafted by first author only. Project was never meant to submitted to arxiv\n  but first author, who had minimal contribution did so anyways. The other\n  authors (George, Sylesh) are appalled at this. Please do not use this\n  paper/project as a reference. Thank you very much", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cardiovascular disease (CD) is the number one leading cause of death\nworldwide, accounting for more than 17 million deaths in 2015. Critical\nindicators of CD include heart murmurs, intense sounds emitted by the heart\nduring periods of irregular blood flow. Current diagnosis of heart murmurs\nrelies on echocardiography (ECHO), which costs thousands of dollars and medical\nprofessionals to analyze the results, making it very unsuitable for areas with\ninadequate medical facilities. Thus, there is a need for an accessible\nalternative. Based on a simple interface and deep learning, HeartFit allows\nusers to administer diagnoses themselves. An inexpensive, custom designed\nstethoscope in conjunction with a mobile application allows users to record and\nupload audio of their heart to a database. Using a deep learning network\narchitecture, the database classifies the audio and returns the diagnosis to\nthe user. The model consists of a deep recurrent convolutional neural network\ntrained on 300 prelabeled heartbeat audio samples. After the model was\nvalidated on a previously unseen set of 100 heartbeat audio samples, it\nachieved a f beta score of 0.9545 and an accuracy of 95.5 percent. This value\nexceeds that of clinical examination accuracy, which is around 83 percent to 91\npercent and costs orders of magnitude less than ECHO, demonstrating the\neffectiveness of the HeartFit platform. Through the platform, users can obtain\nimmediate, accurate diagnosis of heart murmurs without any professional medical\nassistance, revolutionizing how we combat CD.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jul 2019 17:25:49 GMT"}, {"version": "v2", "created": "Wed, 30 Dec 2020 22:59:08 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Gupta", "Ankit", ""], ["Tang", "George", ""], ["Suresh", "Sylesh", ""]]}, {"id": "1907.11684", "submitter": "Pu Zhao", "authors": "Pu Zhao, Sijia Liu, Pin-Yu Chen, Nghia Hoang, Kaidi Xu, Bhavya\n  Kailkhura, Xue Lin", "title": "On the Design of Black-box Adversarial Examples by Leveraging\n  Gradient-free Optimization and Operator Splitting Method", "comments": "accepted by ICCV 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robust machine learning is currently one of the most prominent topics which\ncould potentially help shaping a future of advanced AI platforms that not only\nperform well in average cases but also in worst cases or adverse situations.\nDespite the long-term vision, however, existing studies on black-box\nadversarial attacks are still restricted to very specific settings of threat\nmodels (e.g., single distortion metric and restrictive assumption on target\nmodel's feedback to queries) and/or suffer from prohibitively high query\ncomplexity. To push for further advances in this field, we introduce a general\nframework based on an operator splitting method, the alternating direction\nmethod of multipliers (ADMM) to devise efficient, robust black-box attacks that\nwork with various distortion metrics and feedback settings without incurring\nhigh query complexity. Due to the black-box nature of the threat model, the\nproposed ADMM solution framework is integrated with zeroth-order (ZO)\noptimization and Bayesian optimization (BO), and thus is applicable to the\ngradient-free regime. This results in two new black-box adversarial attack\ngeneration methods, ZO-ADMM and BO-ADMM. Our empirical evaluations on image\nclassification datasets show that our proposed approaches have much lower\nfunction query complexities compared to state-of-the-art attack methods, but\nachieve very competitive attack success rates.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jul 2019 17:29:52 GMT"}, {"version": "v2", "created": "Wed, 23 Oct 2019 19:34:54 GMT"}, {"version": "v3", "created": "Mon, 28 Oct 2019 16:35:58 GMT"}, {"version": "v4", "created": "Wed, 4 Dec 2019 21:05:19 GMT"}], "update_date": "2019-12-06", "authors_parsed": [["Zhao", "Pu", ""], ["Liu", "Sijia", ""], ["Chen", "Pin-Yu", ""], ["Hoang", "Nghia", ""], ["Xu", "Kaidi", ""], ["Kailkhura", "Bhavya", ""], ["Lin", "Xue", ""]]}, {"id": "1907.11703", "submitter": "Pablo Hernandez-Leal", "authors": "Bilal Kartal, Pablo Hernandez-Leal and Matthew E. Taylor", "title": "Action Guidance with MCTS for Deep Reinforcement Learning", "comments": "AAAI Conference on Artificial Intelligence and Interactive Digital\n  Entertainment (AIIDE'19). arXiv admin note: substantial text overlap with\n  arXiv:1904.05759, arXiv:1812.00045", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning has achieved great successes in recent years,\nhowever, one main challenge is the sample inefficiency. In this paper, we focus\non how to use action guidance by means of a non-expert demonstrator to improve\nsample efficiency in a domain with sparse, delayed, and possibly deceptive\nrewards: the recently-proposed multi-agent benchmark of Pommerman. We propose a\nnew framework where even a non-expert simulated demonstrator, e.g., planning\nalgorithms such as Monte Carlo tree search with a small number rollouts, can be\nintegrated within asynchronous distributed deep reinforcement learning methods.\nCompared to a vanilla deep RL algorithm, our proposed methods both learn faster\nand converge to better policies on a two-player mini version of the Pommerman\ngame.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jul 2019 19:19:42 GMT"}], "update_date": "2019-07-30", "authors_parsed": [["Kartal", "Bilal", ""], ["Hernandez-Leal", "Pablo", ""], ["Taylor", "Matthew E.", ""]]}, {"id": "1907.11711", "submitter": "Jing Cheng", "authors": "Dong Liang, Jing Cheng, Ziwen Ke, Leslie Ying", "title": "Deep MRI Reconstruction: Unrolled Optimization Algorithms Meet Neural\n  Networks", "comments": "a review paper on deep learning MR reconstruction", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG eess.SP physics.med-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Image reconstruction from undersampled k-space data has been playing an\nimportant role for fast MRI. Recently, deep learning has demonstrated\ntremendous success in various fields and also shown potential to significantly\nspeed up MR reconstruction with reduced measurements. This article gives an\noverview of deep learning-based image reconstruction methods for MRI. Three\ntypes of deep learning-based approaches are reviewed, the data-driven,\nmodel-driven and integrated approaches. The main structure of each network in\nthree approaches is explained and the analysis of common parts of reviewed\nnetworks and differences in-between are highlighted. Based on the review, a\nnumber of signal processing issues are discussed for maximizing the potential\nof deep reconstruction for fast MRI. the discussion may facilitate further\ndevelopment of \"optimal\" network and performance analysis from a theoretical\npoint of view.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jul 2019 08:22:53 GMT"}], "update_date": "2019-07-30", "authors_parsed": [["Liang", "Dong", ""], ["Cheng", "Jing", ""], ["Ke", "Ziwen", ""], ["Ying", "Leslie", ""]]}, {"id": "1907.11713", "submitter": "Mo Deng", "authors": "Mo Deng, Shuai Li, Alexandre Goy, Iksung Kang and George Barbastathis", "title": "Learning to Synthesize: Robust Phase Retrieval at Low Photon counts", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The quality of inverse problem solutions obtained through deep learning\n[Barbastathis et al, 2019] is limited by the nature of the priors learned from\nexamples presented during the training phase. In the case of quantitative phase\nretrieval [Sinha et al, 2017, Goy et al, 2019], in particular, spatial\nfrequencies that are underrepresented in the training database, most often at\nthe high band, tend to be suppressed in the reconstruction. Ad hoc solutions\nhave been proposed, such as pre-amplifying the high spatial frequencies in the\nexamples [Li et al, 2018]; however, while that strategy improves resolution, it\nalso leads to high-frequency artifacts as well as low-frequency distortions in\nthe reconstructions. Here, we present a new approach that learns separately how\nto handle the two frequency bands, low and high; and also learns how to\nsynthesize these two bands into the full-band reconstructions. We show that\nthis \"learning to synthesize\" (LS) method yields phase reconstructions of high\nspatial resolution and artifact-free; and it is also resilient to high-noise\nconditions, e.g. in the case of very low photon flux. In addition to the\nproblem of quantitative phase retrieval, the LS method is applicable, in\nprinciple, to any inverse problem where the forward operator treats different\nfrequency bands unevenly, i.e. is ill-posed.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jul 2019 08:55:38 GMT"}], "update_date": "2019-07-30", "authors_parsed": [["Deng", "Mo", ""], ["Li", "Shuai", ""], ["Goy", "Alexandre", ""], ["Kang", "Iksung", ""], ["Barbastathis", "George", ""]]}, {"id": "1907.11718", "submitter": "Haoran Wang", "authors": "Haoran Wang", "title": "Large scale continuous-time mean-variance portfolio allocation via\n  reinforcement learning", "comments": "15 pages, 4 figures. arXiv admin note: substantial text overlap with\n  arXiv:1904.11392", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.PM cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose to solve large scale Markowitz mean-variance (MV) portfolio\nallocation problem using reinforcement learning (RL). By adopting the recently\ndeveloped continuous-time exploratory control framework, we formulate the\nexploratory MV problem in high dimensions. We further show the optimality of a\nmultivariate Gaussian feedback policy, with time-decaying variance, in trading\noff exploration and exploitation. Based on a provable policy improvement\ntheorem, we devise a scalable and data-efficient RL algorithm and conduct large\nscale empirical tests using data from the S&P 500 stocks. We found that our\nmethod consistently achieves over 10% annualized returns and it outperforms\neconometric methods and the deep RL method by large margins, for both long and\nmedium terms of investment with monthly and daily trading.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jul 2019 14:38:08 GMT"}, {"version": "v2", "created": "Fri, 2 Aug 2019 08:37:19 GMT"}], "update_date": "2019-08-05", "authors_parsed": [["Wang", "Haoran", ""]]}, {"id": "1907.11739", "submitter": "Sayan Ghosh", "authors": "Sayan Ghosh, Jesper Kristensen, Yiming Zhang, Waad Subber, Liping Wang", "title": "A Strategy for Adaptive Sampling of Multi-fidelity Gaussian Process to\n  Reduce Predictive Uncertainty", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-fidelity Gaussian process is a common approach to address the extensive\ncomputationally demanding algorithms such as optimization, calibration and\nuncertainty quantification. Adaptive sampling for multi-fidelity Gaussian\nprocess is a changing task due to the fact that not only we seek to estimate\nthe next sampling location of the design variable, but also the level of the\nsimulator fidelity. This issue is often addressed by including the cost of the\nsimulator as an another factor in the searching criterion in conjunction with\nthe uncertainty reduction metric. In this work, we extent the traditional\ndesign of experiment framework for the multi-fidelity Gaussian process by\npartitioning the prediction uncertainty based on the fidelity level and the\nassociated cost of execution. In addition, we utilize the concept of Believer\nwhich quantifies the effect of adding an exploratory design point on the\nGaussian process uncertainty prediction. We demonstrated our framework using\nacademic examples as well as a industrial application of steady-state\nthermodynamic operation point of a fluidized bed process\n", "versions": [{"version": "v1", "created": "Fri, 26 Jul 2019 18:17:45 GMT"}], "update_date": "2019-07-30", "authors_parsed": [["Ghosh", "Sayan", ""], ["Kristensen", "Jesper", ""], ["Zhang", "Yiming", ""], ["Subber", "Waad", ""], ["Wang", "Liping", ""]]}, {"id": "1907.11740", "submitter": "Wenxuan Zhou", "authors": "Wenxuan Zhou, Lerrel Pinto, Abhinav Gupta", "title": "Environment Probing Interaction Policies", "comments": "Published as a conference paper at ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A key challenge in reinforcement learning (RL) is environment generalization:\na policy trained to solve a task in one environment often fails to solve the\nsame task in a slightly different test environment. A common approach to\nimprove inter-environment transfer is to learn policies that are invariant to\nthe distribution of testing environments. However, we argue that instead of\nbeing invariant, the policy should identify the specific nuances of an\nenvironment and exploit them to achieve better performance. In this work, we\npropose the 'Environment-Probing' Interaction (EPI) policy, a policy that\nprobes a new environment to extract an implicit understanding of that\nenvironment's behavior. Once this environment-specific information is obtained,\nit is used as an additional input to a task-specific policy that can now\nperform environment-conditioned actions to solve a task. To learn these\nEPI-policies, we present a reward function based on transition predictability.\nSpecifically, a higher reward is given if the trajectory generated by the\nEPI-policy can be used to better predict transitions. We experimentally show\nthat EPI-conditioned task-specific policies significantly outperform commonly\nused policy generalization methods on novel testing environments.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jul 2019 18:19:25 GMT"}], "update_date": "2019-07-30", "authors_parsed": [["Zhou", "Wenxuan", ""], ["Pinto", "Lerrel", ""], ["Gupta", "Abhinav", ""]]}, {"id": "1907.11746", "submitter": "Denali Molitor", "authors": "Denali Molitor, Deanna Needell, Rachel Ward", "title": "Bias of Homotopic Gradient Descent for the Hinge Loss", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gradient descent is a simple and widely used optimization method for machine\nlearning. For homogeneous linear classifiers applied to separable data,\ngradient descent has been shown to converge to the maximal margin (or\nequivalently, the minimal norm) solution for various smooth loss functions. The\nprevious theory does not, however, apply to non-smooth functions such as the\nhinge loss which is widely used in practice. Here, we study the convergence of\na homotopic variant of gradient descent applied to the hinge loss and provide\nexplicit convergence rates to the max-margin solution for linearly separable\ndata.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jul 2019 18:38:44 GMT"}], "update_date": "2019-07-30", "authors_parsed": [["Molitor", "Denali", ""], ["Needell", "Deanna", ""], ["Ward", "Rachel", ""]]}, {"id": "1907.11754", "submitter": "Jiasheng Zhang", "authors": "Jason (Jiasheng) Zhang, Junming Yin, Dongwon Lee, Linhong Zhu", "title": "Deep Reinforcement Learning for Personalized Search Story Recommendation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, \\emph{search story}, a combined display with other organic\nchannels, has become a major source of user traffic on platforms such as\ne-commerce search platforms, news feed platforms and web and image search\nplatforms. The recommended search story guides a user to identify her own\npreference and personal intent, which subsequently influences the user's\nreal-time and long-term search behavior. %With such an increased importance of\nsearch stories, As search stories become increasingly important, in this work,\nwe study the problem of personalized search story recommendation within a\nsearch engine, which aims to suggest a search story relevant to both a search\nkeyword and an individual user's interest. To address the challenge of modeling\nboth immediate and future values of recommended search stories (i.e.,\ncross-channel effect), for which conventional supervised learning framework is\nnot applicable, we resort to a Markov decision process and propose a deep\nreinforcement learning architecture trained by both imitation learning and\nreinforcement learning. We empirically demonstrate the effectiveness of our\nproposed approach through extensive experiments on real-world data sets from\nJD.com.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jul 2019 19:01:48 GMT"}], "update_date": "2019-07-30", "authors_parsed": [["Jason", "", "", "Jiasheng"], ["Zhang", "", ""], ["Yin", "Junming", ""], ["Lee", "Dongwon", ""], ["Zhu", "Linhong", ""]]}, {"id": "1907.11778", "submitter": "Yingshui Tan", "authors": "Baihong Jin and Yingshui Tan and Alexander Nettekoven and Yuxin Chen\n  and Ufuk Topcu and Yisong Yue and Alberto Sangiovanni Vincentelli", "title": "An Encoder-Decoder Based Approach for Anomaly Detection with Application\n  in Additive Manufacturing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel unsupervised deep learning approach that utilizes the\nencoder-decoder architecture for detecting anomalies in sequential sensor data\ncollected during industrial manufacturing. Our approach is designed not only to\ndetect whether there exists an anomaly at a given time step, but also to\npredict what will happen next in the (sequential) process. We demonstrate our\napproach on a dataset collected from a real-world testbed. The dataset contains\nimages collected under both normal conditions and synthetic anomalies. We show\nthat the encoder-decoder model is able to identify the injected anomalies in a\nmodern manufacturing process in an unsupervised fashion. In addition, it also\ngives hints about the temperature non-uniformity of the testbed during\nmanufacturing, which is what we are not aware of before doing the experiment.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jul 2019 20:03:26 GMT"}], "update_date": "2019-07-30", "authors_parsed": [["Jin", "Baihong", ""], ["Tan", "Yingshui", ""], ["Nettekoven", "Alexander", ""], ["Chen", "Yuxin", ""], ["Topcu", "Ufuk", ""], ["Yue", "Yisong", ""], ["Vincentelli", "Alberto Sangiovanni", ""]]}, {"id": "1907.11780", "submitter": "Kaiwen Wu", "authors": "Kaiwen Wu and Yaoliang Yu", "title": "Understanding Adversarial Robustness: The Trade-off between Minimum and\n  Average Margin", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep models, while being extremely versatile and accurate, are vulnerable to\nadversarial attacks: slight perturbations that are imperceptible to humans can\ncompletely flip the prediction of deep models. Many attack and defense\nmechanisms have been proposed, although a satisfying solution still largely\nremains elusive. In this work, we give strong evidence that during training,\ndeep models maximize the minimum margin in order to achieve high accuracy, but\nat the same time decrease the \\emph{average} margin hence hurting robustness.\nOur empirical results highlight an intrinsic trade-off between accuracy and\nrobustness for current deep model training. To further address this issue, we\npropose a new regularizer to explicitly promote average margin, and we verify\nthrough extensive experiments that it does lead to better robustness. Our\nregularized objective remains Fisher-consistent, hence asymptotically can still\nrecover the Bayes optimal classifier.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jul 2019 20:05:19 GMT"}], "update_date": "2019-07-30", "authors_parsed": [["Wu", "Kaiwen", ""], ["Yu", "Yaoliang", ""]]}, {"id": "1907.11788", "submitter": "Pablo Hernandez-Leal", "authors": "Chao Gao, Bilal Kartal, Pablo Hernandez-Leal and Matthew E. Taylor", "title": "On Hard Exploration for Reinforcement Learning: a Case Study in\n  Pommerman", "comments": "AAAI Conference on Artificial Intelligence and Interactive Digital\n  Entertainment (AIIDE) 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How to best explore in domains with sparse, delayed, and deceptive rewards is\nan important open problem for reinforcement learning (RL). This paper considers\none such domain, the recently-proposed multi-agent benchmark of Pommerman. This\ndomain is very challenging for RL --- past work has shown that model-free RL\nalgorithms fail to achieve significant learning without artificially reducing\nthe environment's complexity. In this paper, we illuminate reasons behind this\nfailure by providing a thorough analysis on the hardness of random exploration\nin Pommerman. While model-free random exploration is typically futile, we\ndevelop a model-based automatic reasoning module that can be used for safer\nexploration by pruning actions that will surely lead the agent to death. We\nempirically demonstrate that this module can significantly improve learning.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jul 2019 20:36:09 GMT"}], "update_date": "2019-07-30", "authors_parsed": [["Gao", "Chao", ""], ["Kartal", "Bilal", ""], ["Hernandez-Leal", "Pablo", ""], ["Taylor", "Matthew E.", ""]]}, {"id": "1907.11792", "submitter": "Marcell Vazquez-Chanlatte", "authors": "Marcell Vazquez-Chanlatte, Sanjit A. Seshia", "title": "Maximum Causal Entropy Specification Inference from Demonstrations", "comments": "Computer Aided Verification, 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many settings (e.g., robotics) demonstrations provide a natural way to\nspecify tasks; however, most methods for learning from demonstrations either do\nnot provide guarantees that the artifacts learned for the tasks, such as\nrewards or policies, can be safely composed and/or do not explicitly capture\nhistory dependencies. Motivated by this deficit, recent works have proposed\nlearning Boolean task specifications, a class of Boolean non-Markovian rewards\nwhich admit well-defined composition and explicitly handle historical\ndependencies. This work continues this line of research by adapting maximum\ncausal entropy inverse reinforcement learning to estimate the posteriori\nprobability of a specification given a multi-set of demonstrations. The key\nalgorithmic insight is to leverage the extensive literature and tooling on\nreduced ordered binary decision diagrams to efficiently encode a time unrolled\nMarkov Decision Process. This enables transforming a naive exponential time\nalgorithm into a polynomial time algorithm.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jul 2019 21:03:53 GMT"}, {"version": "v2", "created": "Tue, 10 Dec 2019 02:08:37 GMT"}, {"version": "v3", "created": "Mon, 13 Jan 2020 22:38:12 GMT"}, {"version": "v4", "created": "Sat, 15 Feb 2020 01:02:41 GMT"}, {"version": "v5", "created": "Sat, 16 May 2020 18:55:44 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Vazquez-Chanlatte", "Marcell", ""], ["Seshia", "Sanjit A.", ""]]}, {"id": "1907.11797", "submitter": "Rahmadi Trimananda", "authors": "Rahmadi Trimananda, Janus Varmarken, Athina Markopoulou, and Brian\n  Demsky", "title": "PingPong: Packet-Level Signatures for Smart Home Device Events", "comments": "This is the technical report for the paper titled Packet-Level\n  Signatures for Smart Home Devices published at the Network and Distributed\n  System Security (NDSS) Symposium 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.CR cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Smart home devices are vulnerable to passive inference attacks based on\nnetwork traffic, even in the presence of encryption. In this paper, we present\nPINGPONG, a tool that can automatically extract packet-level signatures for\ndevice events (e.g., light bulb turning ON/OFF) from network traffic. We\nevaluated PINGPONG on popular smart home devices ranging from smart plugs and\nthermostats to cameras, voice-activated devices, and smart TVs. We were able\nto: (1) automatically extract previously unknown signatures that consist of\nsimple sequences of packet lengths and directions; (2) use those signatures to\ndetect the devices or specific events with an average recall of more than 97%;\n(3) show that the signatures are unique among hundreds of millions of packets\nof real world network traffic; (4) show that our methodology is also applicable\nto publicly available datasets; and (5) demonstrate its robustness in different\nsettings: events triggered by local and remote smartphones, as well as by\nhomeautomation systems.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jul 2019 21:48:13 GMT"}, {"version": "v2", "created": "Tue, 17 Sep 2019 17:26:19 GMT"}, {"version": "v3", "created": "Mon, 10 Feb 2020 19:07:10 GMT"}], "update_date": "2020-02-12", "authors_parsed": [["Trimananda", "Rahmadi", ""], ["Varmarken", "Janus", ""], ["Markopoulou", "Athina", ""], ["Demsky", "Brian", ""]]}, {"id": "1907.11804", "submitter": "Kartikeya Bhardwaj", "authors": "Kartikeya Bhardwaj, Chingyi Lin, Anderson Sartor, Radu Marculescu", "title": "Memory- and Communication-Aware Model Compression for Distributed Deep\n  Learning Inference on IoT", "comments": "This preprint is for personal use only. The official article will\n  appear as part of the ESWEEK-TECS special issue and will be presented in the\n  International Conference on Hardware/Software Codesign and System Synthesis\n  (CODES+ISSS), 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model compression has emerged as an important area of research for deploying\ndeep learning models on Internet-of-Things (IoT). However, for extremely\nmemory-constrained scenarios, even the compressed models cannot fit within the\nmemory of a single device and, as a result, must be distributed across multiple\ndevices. This leads to a distributed inference paradigm in which memory and\ncommunication costs represent a major bottleneck. Yet, existing model\ncompression techniques are not communication-aware. Therefore, we propose\nNetwork of Neural Networks (NoNN), a new distributed IoT learning paradigm that\ncompresses a large pretrained 'teacher' deep network into several disjoint and\nhighly-compressed 'student' modules, without loss of accuracy. Moreover, we\npropose a network science-based knowledge partitioning algorithm for the\nteacher model, and then train individual students on the resulting disjoint\npartitions. Extensive experimentation on five image classification datasets,\nfor user-defined memory/performance budgets, show that NoNN achieves higher\naccuracy than several baselines and similar accuracy as the teacher model,\nwhile using minimal communication among students. Finally, as a case study, we\ndeploy the proposed model for CIFAR-10 dataset on edge devices and demonstrate\nsignificant improvements in memory footprint (up to 24x), performance (up to\n12x), and energy per node (up to 14x) compared to the large teacher model. We\nfurther show that for distributed inference on multiple edge devices, our\nproposed NoNN model results in up to 33x reduction in total latency w.r.t. a\nstate-of-the-art model compression baseline.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jul 2019 22:17:42 GMT"}], "update_date": "2019-07-30", "authors_parsed": [["Bhardwaj", "Kartikeya", ""], ["Lin", "Chingyi", ""], ["Sartor", "Anderson", ""], ["Marculescu", "Radu", ""]]}, {"id": "1907.11806", "submitter": "Harish S. Bhat", "authors": "Harish S. Bhat", "title": "Learning and Interpreting Potentials for Classical Hamiltonian Systems", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.DS physics.class-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of learning an interpretable potential energy\nfunction from a Hamiltonian system's trajectories. We address this problem for\nclassical, separable Hamiltonian systems. Our approach first constructs a\nneural network model of the potential and then applies an equation discovery\ntechnique to extract from the neural potential a closed-form algebraic\nexpression. We demonstrate this approach for several systems, including\noscillators, a central force problem, and a problem of two charged particles in\na classical Coulomb potential. Through these test problems, we show close\nagreement between learned neural potentials, the interpreted potentials we\nobtain after training, and the ground truth. In particular, for the central\nforce problem, we show that our approach learns the correct effective\npotential, a reduced-order model of the system.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jul 2019 22:32:12 GMT"}], "update_date": "2019-07-30", "authors_parsed": [["Bhat", "Harish S.", ""]]}, {"id": "1907.11813", "submitter": "Ayush Raina", "authors": "Ayush Raina, Christopher McComb and Jonathan Cagan", "title": "Learning to design from humans: Imitating human designers through deep\n  learning", "comments": null, "journal-ref": "J. Mech. Des, ASME, November 2019", "doi": "10.1115/1.4044256", "report-no": "Volume 141 Issue 11", "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humans as designers have quite versatile problem-solving strategies. Computer\nagents on the other hand can access large scale computational resources to\nsolve certain design problems. Hence, if agents can learn from human behavior,\na synergetic human-agent problem solving team can be created. This paper\npresents an approach to extract human design strategies and implicit rules,\npurely from historical human data, and use that for design generation. A\ntwo-step framework that learns to imitate human design strategies from\nobservation is proposed and implemented. This framework makes use of deep\nlearning constructs to learn to generate designs without any explicit\ninformation about objective and performance metrics. The framework is designed\nto interact with the problem through a visual interface as humans did when\nsolving the problem. It is trained to imitate a set of human designers by\nobserving their design state sequences without inducing problem-specific\nmodelling bias or extra information about the problem. Furthermore, an\nend-to-end agent is developed that uses this deep learning framework as its\ncore in conjunction with image processing to map pixel-to-design moves as a\nmechanism to generate designs. Finally, the designs generated by a\ncomputational team of these agents are then compared to actual human data for\nteams solving a truss design problem. Results demonstrates that these agents\nare able to create feasible and efficient truss designs without guidance,\nshowing that this methodology allows agents to learn effective design\nstrategies.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jul 2019 23:09:57 GMT"}, {"version": "v2", "created": "Fri, 2 Aug 2019 15:16:50 GMT"}], "update_date": "2019-09-24", "authors_parsed": [["Raina", "Ayush", ""], ["McComb", "Christopher", ""], ["Cagan", "Jonathan", ""]]}, {"id": "1907.11815", "submitter": "Matthew Middlehurst", "authors": "Matthew Middlehurst, William Vickers and Anthony Bagnall", "title": "Scalable Dictionary Classifiers for Time Series Classification", "comments": null, "journal-ref": "In proceedings of Intelligent Data Engineering and Automated\n  Learning, pages 11-19. 2019", "doi": "10.1007/978-3-030-33607-3_2", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dictionary based classifiers are a family of algorithms for time series\nclassification (TSC), that focus on capturing the frequency of pattern\noccurrences in a time series. The ensemble based Bag of Symbolic Fourier\nApproximation Symbols (BOSS) was found to be a top performing TSC algorithm in\na recent evaluation, as well as the best performing dictionary based\nclassifier. A recent addition to the category, the Word Extraction for Time\nSeries Classification (WEASEL), claims an improvement on this performance. Both\nof these algorithms however have non-trivial scalability issues, taking a\nconsiderable amount of build time and space on larger datasets. We evaluate\nchanges to the way BOSS chooses classifiers for its ensemble, replacing its\nparameter search with random selection. This change allows for the easy\nimplementation of contracting, setting a build time limit for the classifier\nand check-pointing, saving progress during the classifiers build. To\ndifferentiate between the two BOSS ensemble methods we refer to our randomised\nversion as RBOSS. Additionally we test the application of common ensembling\ntechniques to help retain accuracy from the loss of the BOSS parameter search.\nWe achieve a significant reduction in build time without a significant change\nin accuracy on average when compared to BOSS by creating a size $n$ weighted\nensemble selecting the best performers from $k$ randomly chosen parameter sets.\nOur experiments are conducted on datasets from the recently expanded UCR time\nseries archive. We demonstrate the usability improvements to RBOSS with a case\nstudy using a large whale acoustics dataset for which BOSS proved infeasible.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jul 2019 23:13:46 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Middlehurst", "Matthew", ""], ["Vickers", "William", ""], ["Bagnall", "Anthony", ""]]}, {"id": "1907.11818", "submitter": "Il Yong Chun", "authors": "Il Yong Chun, Zhengyu Huang, Hongki Lim, Jeffrey A. Fessler", "title": "Momentum-Net: Fast and convergent iterative neural network for inverse\n  problems", "comments": "28 pages, 13 figures, 3 algorithms, 4 tables, submitted revision to\n  IEEE T-PAMI", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Iterative neural networks (INN) are rapidly gaining attention for solving\ninverse problems in imaging, image processing, and computer vision. INNs\ncombine regression NNs and an iterative model-based image reconstruction (MBIR)\nalgorithm, often leading to both good generalization capability and\noutperforming reconstruction quality over existing MBIR optimization models.\nThis paper proposes the first fast and convergent INN architecture,\nMomentum-Net, by generalizing a block-wise MBIR algorithm that uses momentum\nand majorizers with regression NNs. For fast MBIR, Momentum-Net uses momentum\nterms in extrapolation modules, and noniterative MBIR modules at each iteration\nby using majorizers, where each iteration of Momentum-Net consists of three\ncore modules: image refining, extrapolation, and MBIR. Momentum-Net guarantees\nconvergence to a fixed-point for general differentiable (non)convex MBIR\nfunctions (or data-fit terms) and convex feasible sets, under two asymptomatic\nconditions. To consider data-fit variations across training and testing\nsamples, we also propose a regularization parameter selection scheme based on\nthe \"spectral spread\" of majorization matrices. Numerical experiments for\nlight-field photography using a focal stack and sparse-view computational\ntomography demonstrate that, given identical regression NN architectures,\nMomentum-Net significantly improves MBIR speed and accuracy over several\nexisting INNs; it significantly improves reconstruction quality compared to a\nstate-of-the-art MBIR method in each application.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jul 2019 23:42:37 GMT"}, {"version": "v2", "created": "Wed, 11 Sep 2019 01:54:14 GMT"}, {"version": "v3", "created": "Sat, 20 Jun 2020 09:42:48 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Chun", "Il Yong", ""], ["Huang", "Zhengyu", ""], ["Lim", "Hongki", ""], ["Fessler", "Jeffrey A.", ""]]}, {"id": "1907.11826", "submitter": "Kush Bhatia", "authors": "Kush Bhatia, Yi-An Ma, Anca D. Dragan, Peter L. Bartlett, Michael I.\n  Jordan", "title": "Bayesian Robustness: A Nonasymptotic Viewpoint", "comments": "30 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of robustly estimating the posterior distribution for\nthe setting where observed data can be contaminated with potentially\nadversarial outliers. We propose Rob-ULA, a robust variant of the Unadjusted\nLangevin Algorithm (ULA), and provide a finite-sample analysis of its sampling\ndistribution. In particular, we show that after $T=\n\\tilde{\\mathcal{O}}(d/\\varepsilon_{\\textsf{acc}})$ iterations, we can sample\nfrom $p_T$ such that $\\text{dist}(p_T, p^*) \\leq \\varepsilon_{\\textsf{acc}} +\n\\tilde{\\mathcal{O}}(\\epsilon)$, where $\\epsilon$ is the fraction of\ncorruptions. We corroborate our theoretical analysis with experiments on both\nsynthetic and real-world data sets for mean estimation, regression and binary\nclassification.\n", "versions": [{"version": "v1", "created": "Sat, 27 Jul 2019 01:42:29 GMT"}], "update_date": "2019-07-30", "authors_parsed": [["Bhatia", "Kush", ""], ["Ma", "Yi-An", ""], ["Dragan", "Anca D.", ""], ["Bartlett", "Peter L.", ""], ["Jordan", "Michael I.", ""]]}, {"id": "1907.11835", "submitter": "Haidong Zhu", "authors": "Haidong Zhu, Jialin Shi and Ji Wu", "title": "Pick-and-Learn: Automatic Quality Evaluation for Noisy-Labeled Image\n  Segmentation", "comments": "Accepted for MICCAI2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning methods have achieved promising performance in many areas, but\nthey are still struggling with noisy-labeled images during the training\nprocess. Considering that the annotation quality indispensably relies on great\nexpertise, the problem is even more crucial in the medical image domain. How to\neliminate the disturbance from noisy labels for segmentation tasks without\nfurther annotations is still a significant challenge. In this paper, we\nintroduce our label quality evaluation strategy for deep neural networks\nautomatically assessing the quality of each label, which is not explicitly\nprovided, and training on clean-annotated ones. We propose a solution for\nnetwork automatically evaluating the relative quality of the labels in the\ntraining set and using good ones to tune the network parameters. We also design\nan overfitting control module to let the network maximally learn from the\nprecise annotations during the training process. Experiments on the public\nbiomedical image segmentation dataset have proved the method outperforms\nbaseline methods and retains both high accuracy and good generalization at\ndifferent noise levels.\n", "versions": [{"version": "v1", "created": "Sat, 27 Jul 2019 02:34:30 GMT"}], "update_date": "2019-07-30", "authors_parsed": [["Zhu", "Haidong", ""], ["Shi", "Jialin", ""], ["Wu", "Ji", ""]]}, {"id": "1907.11836", "submitter": "Chaojin Qing", "authors": "Chaojin Qing, Bin Cai, Qingyao Yang, Jiafan Wang, and Chuan Huang", "title": "Deep Learning for CSI Feedback Based on Superimposed Coding", "comments": "12 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Massive multiple-input multiple-output (MIMO) with frequency division duplex\n(FDD) mode is a promising approach to increasing system capacity and link\nrobustness for the fifth generation (5G) wireless cellular systems. The premise\nof these advantages is the accurate downlink channel state information (CSI)\nfed back from user equipment. However, conventional feedback methods have\ndifficulties in reducing feedback overhead due to significant amount of base\nstation (BS) antennas in massive MIMO systems. Recently, deep learning\n(DL)-based CSI feedback conquers many difficulties, yet still shows\ninsufficiency to decrease the occupation of uplink bandwidth resources. In this\npaper, to solve this issue, we combine DL and superimposed coding (SC) for CSI\nfeedback, in which the downlink CSI is spread and then superimposed on uplink\nuser data sequences (UL-US) toward the BS. Then, a multi-task neural network\n(NN) architecture is proposed at BS to recover the downlink CSI and UL-US by\nunfolding two iterations of the minimum mean-squared error (MMSE)\ncriterion-based interference reduction. In addition, for a network training, a\nsubnet-by-subnet approach is exploited to facilitate the parameter tuning and\nexpedite the convergence rate. Compared with standalone SC-based CSI scheme,\nour multi-task NN, trained in a specific signal-to-noise ratio (SNR) and power\nproportional coefficient (PPC), consistently improves the estimation of\ndownlink CSI with similar or better UL-US detection under SNR and PPC varying.\n", "versions": [{"version": "v1", "created": "Sat, 27 Jul 2019 02:35:26 GMT"}], "update_date": "2019-07-30", "authors_parsed": [["Qing", "Chaojin", ""], ["Cai", "Bin", ""], ["Yang", "Qingyao", ""], ["Wang", "Jiafan", ""], ["Huang", "Chuan", ""]]}, {"id": "1907.11837", "submitter": "Kai Han", "authors": "Kai Han, Yunhe Wang, Han Shu, Chuanjian Liu, Chunjing Xu, Chang Xu", "title": "Attribute Aware Pooling for Pedestrian Attribute Recognition", "comments": "Accepted by IJCAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper expands the strength of deep convolutional neural networks (CNNs)\nto the pedestrian attribute recognition problem by devising a novel attribute\naware pooling algorithm. Existing vanilla CNNs cannot be straightforwardly\napplied to handle multi-attribute data because of the larger label space as\nwell as the attribute entanglement and correlations. We tackle these challenges\nthat hampers the development of CNNs for multi-attribute classification by\nfully exploiting the correlation between different attributes. The multi-branch\narchitecture is adopted for fucusing on attributes at different regions.\nBesides the prediction based on each branch itself, context information of each\nbranch are employed for decision as well. The attribute aware pooling is\ndeveloped to integrate both kinds of information. Therefore, attributes which\nare indistinct or tangled with others can be accurately recognized by\nexploiting the context information. Experiments on benchmark datasets\ndemonstrate that the proposed pooling method appropriately explores and\nexploits the correlations between attributes for the pedestrian attribute\nrecognition.\n", "versions": [{"version": "v1", "created": "Sat, 27 Jul 2019 02:45:32 GMT"}], "update_date": "2019-07-30", "authors_parsed": [["Han", "Kai", ""], ["Wang", "Yunhe", ""], ["Shu", "Han", ""], ["Liu", "Chuanjian", ""], ["Xu", "Chunjing", ""], ["Xu", "Chang", ""]]}, {"id": "1907.11840", "submitter": "Kai Han", "authors": "Chuanjian Liu, Yunhe Wang, Kai Han, Chunjing Xu, Chang Xu", "title": "Learning Instance-wise Sparsity for Accelerating Deep Models", "comments": "Accepted by IJCAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Exploring deep convolutional neural networks of high efficiency and low\nmemory usage is very essential for a wide variety of machine learning tasks.\nMost of existing approaches used to accelerate deep models by manipulating\nparameters or filters without data, e.g., pruning and decomposition. In\ncontrast, we study this problem from a different perspective by respecting the\ndifference between data. An instance-wise feature pruning is developed by\nidentifying informative features for different instances. Specifically, by\ninvestigating a feature decay regularization, we expect intermediate feature\nmaps of each instance in deep neural networks to be sparse while preserving the\noverall network performance. During online inference, subtle features of input\nimages extracted by intermediate layers of a well-trained neural network can be\neliminated to accelerate the subsequent calculations. We further take\ncoefficient of variation as a measure to select the layers that are appropriate\nfor acceleration. Extensive experiments conducted on benchmark datasets and\nnetworks demonstrate the effectiveness of the proposed method.\n", "versions": [{"version": "v1", "created": "Sat, 27 Jul 2019 02:59:38 GMT"}], "update_date": "2019-07-30", "authors_parsed": [["Liu", "Chuanjian", ""], ["Wang", "Yunhe", ""], ["Han", "Kai", ""], ["Xu", "Chunjing", ""], ["Xu", "Chang", ""]]}, {"id": "1907.11842", "submitter": "Amin Babadi", "authors": "Amin Babadi, Kourosh Naderi, Perttu H\\\"am\\\"al\\\"ainen", "title": "Self-Imitation Learning of Locomotion Movements through Termination\n  Curriculum", "comments": "2019 ACM SIGGRAPH Conference on Motion, Interaction and Games (MIG\n  2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GR cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Animation and machine learning research have shown great advancements in the\npast decade, leading to robust and powerful methods for learning complex\nphysically-based animations. However, learning can take hours or days,\nespecially if no reference movement data is available. In this paper, we\npropose and evaluate a novel combination of techniques for accelerating the\nlearning of stable locomotion movements through self-imitation learning of\nsynthetic animations. First, we produce synthetic and cyclic reference movement\nusing a recent online tree search approach that can discover stable walking\ngaits in a few minutes. This allows us to use reinforcement learning with\nReference State Initialization (RSI) to find a neural network controller for\nimitating the synthesized reference motion. We further accelerate the learning\nusing a novel curriculum learning approach called Termination Curriculum (TC),\nthat adapts the episode termination threshold over time. The combination of the\nRSI and TC ensures that simulation budget is not wasted in regions of the state\nspace not visited by the final policy. As a result, our agents can learn\nlocomotion skills in just a few hours on a modest 4-core computer. We\ndemonstrate this by producing locomotion movements for a variety of characters.\n", "versions": [{"version": "v1", "created": "Sat, 27 Jul 2019 04:08:30 GMT"}, {"version": "v2", "created": "Sat, 21 Sep 2019 03:41:49 GMT"}], "update_date": "2019-09-24", "authors_parsed": [["Babadi", "Amin", ""], ["Naderi", "Kourosh", ""], ["H\u00e4m\u00e4l\u00e4inen", "Perttu", ""]]}, {"id": "1907.11845", "submitter": "Tianyi Chen", "authors": "Bo Ji, Tianyi Chen", "title": "Generative Adversarial Network for Handwritten Text", "comments": "12 pages, 7 figures, submitted for WACV 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative adversarial networks (GANs) have proven hugely successful in\nvariety of applications of image processing. However, generative adversarial\nnetworks for handwriting is relatively rare somehow because of difficulty of\nhandling sequential handwriting data by Convolutional Neural Network (CNN). In\nthis paper, we propose a handwriting generative adversarial network framework\n(HWGANs) for synthesizing handwritten stroke data. The main features of the new\nframework include: (i) A discriminator consists of an integrated\nCNN-Long-Short-Term- Memory (LSTM) based feature extraction with Path Signature\nFeatures (PSF) as input and a Feedforward Neural Network (FNN) based binary\nclassifier; (ii) A recurrent latent variable model as generator for\nsynthesizing sequential handwritten data. The numerical experiments show the\neffectivity of the new model. Moreover, comparing with sole handwriting\ngenerator, the HWGANs synthesize more natural and realistic handwritten text.\n", "versions": [{"version": "v1", "created": "Sat, 27 Jul 2019 04:15:10 GMT"}, {"version": "v2", "created": "Tue, 30 Jul 2019 05:11:09 GMT"}, {"version": "v3", "created": "Thu, 27 Feb 2020 07:17:16 GMT"}], "update_date": "2020-02-28", "authors_parsed": [["Ji", "Bo", ""], ["Chen", "Tianyi", ""]]}, {"id": "1907.11854", "submitter": "ByungSoo Ko", "authors": "Byungsoo Ko, Minchul Shin, Geonmo Gu, HeeJae Jun, Tae Kwan Lee,\n  Youngjoon Kim", "title": "A Benchmark on Tricks for Large-scale Image Retrieval", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many studies have been performed on metric learning, which has become a key\ningredient in top-performing methods of instance-level image retrieval.\nMeanwhile, less attention has been paid to pre-processing and post-processing\ntricks that can significantly boost performance. Furthermore, we found that\nmost previous studies used small scale datasets to simplify processing. Because\nthe behavior of a feature representation in a deep learning model depends on\nboth domain and data, it is important to understand how model behave in\nlarge-scale environments when a proper combination of retrieval tricks is used.\nIn this paper, we extensively analyze the effect of well-known pre-processing,\npost-processing tricks, and their combination for large-scale image retrieval.\nWe found that proper use of these tricks can significantly improve model\nperformance without necessitating complex architecture or introducing loss, as\nconfirmed by achieving a competitive result on the Google Landmark Retrieval\nChallenge 2019.\n", "versions": [{"version": "v1", "created": "Sat, 27 Jul 2019 05:58:00 GMT"}, {"version": "v2", "created": "Thu, 23 Apr 2020 06:29:25 GMT"}], "update_date": "2020-04-24", "authors_parsed": [["Ko", "Byungsoo", ""], ["Shin", "Minchul", ""], ["Gu", "Geonmo", ""], ["Jun", "HeeJae", ""], ["Lee", "Tae Kwan", ""], ["Kim", "Youngjoon", ""]]}, {"id": "1907.11857", "submitter": "Yi Zhang", "authors": "Yi Zhang, Cheng Zeng, Hao Cheng, Chongjun Wang, Lei Zhang", "title": "Many could be better than all: A novel instance-oriented algorithm for\n  Multi-modal Multi-label problem", "comments": "To be published in ICME 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.MM stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  With the emergence of diverse data collection techniques, objects in real\napplications can be represented as multi-modal features. What's more, objects\nmay have multiple semantic meanings. Multi-modal and Multi-label (MMML) problem\nbecomes a universal phenomenon. The quality of data collected from different\nchannels are inconsistent and some of them may not benefit for prediction. In\nreal life, not all the modalities are needed for prediction. As a result, we\npropose a novel instance-oriented Multi-modal Classifier Chains (MCC) algorithm\nfor MMML problem, which can make convince prediction with partial modalities.\nMCC extracts different modalities for different instances in the testing phase.\nExtensive experiments are performed on one real-world herbs dataset and two\npublic datasets to validate our proposed algorithm, which reveals that it may\nbe better to extract many instead of all of the modalities at hand.\n", "versions": [{"version": "v1", "created": "Sat, 27 Jul 2019 06:55:24 GMT"}], "update_date": "2019-07-30", "authors_parsed": [["Zhang", "Yi", ""], ["Zeng", "Cheng", ""], ["Cheng", "Hao", ""], ["Wang", "Chongjun", ""], ["Zhang", "Lei", ""]]}, {"id": "1907.11864", "submitter": "Cuong Nguyen", "authors": "Cuong Nguyen, Thanh-Toan Do, Gustavo Carneiro", "title": "Uncertainty in Model-Agnostic Meta-Learning using Variational Inference", "comments": "Revise Experiments by adding regression quantile calibration and\n  re-running classification calibration under the same setting", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new, rigorously-formulated Bayesian meta-learning algorithm\nthat learns a probability distribution of model parameter prior for few-shot\nlearning. The proposed algorithm employs a gradient-based variational inference\nto infer the posterior of model parameters to a new task. Our algorithm can be\napplied to any model architecture and can be implemented in various machine\nlearning paradigms, including regression and classification. We show that the\nmodels trained with our proposed meta-learning algorithm are well calibrated\nand accurate, with state-of-the-art calibration and classification results on\ntwo few-shot classification benchmarks (Omniglot and Mini-ImageNet), and\ncompetitive results in a multi-modal task-distribution regression.\n", "versions": [{"version": "v1", "created": "Sat, 27 Jul 2019 07:18:50 GMT"}, {"version": "v2", "created": "Wed, 30 Oct 2019 04:32:23 GMT"}], "update_date": "2019-10-31", "authors_parsed": [["Nguyen", "Cuong", ""], ["Do", "Thanh-Toan", ""], ["Carneiro", "Gustavo", ""]]}, {"id": "1907.11879", "submitter": "Aaqib Saeed", "authors": "Aaqib Saeed, Tanir Ozcelebi, Johan Lukkien", "title": "Multi-task Self-Supervised Learning for Human Activity Detection", "comments": null, "journal-ref": null, "doi": "10.1145/3328932", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deep learning methods are successfully used in applications pertaining to\nubiquitous computing, health, and well-being. Specifically, the area of human\nactivity recognition (HAR) is primarily transformed by the convolutional and\nrecurrent neural networks, thanks to their ability to learn semantic\nrepresentations from raw input. However, to extract generalizable features,\nmassive amounts of well-curated data are required, which is a notoriously\nchallenging task; hindered by privacy issues, and annotation costs. Therefore,\nunsupervised representation learning is of prime importance to leverage the\nvast amount of unlabeled data produced by smart devices. In this work, we\npropose a novel self-supervised technique for feature learning from sensory\ndata that does not require access to any form of semantic labels. We learn a\nmulti-task temporal convolutional network to recognize transformations applied\non an input signal. By exploiting these transformations, we demonstrate that\nsimple auxiliary tasks of the binary classification result in a strong\nsupervisory signal for extracting useful features for the downstream task. We\nextensively evaluate the proposed approach on several publicly available\ndatasets for smartphone-based HAR in unsupervised, semi-supervised, and\ntransfer learning settings. Our method achieves performance levels superior to\nor comparable with fully-supervised networks, and it performs significantly\nbetter than autoencoders. Notably, for the semi-supervised case, the\nself-supervised features substantially boost the detection rate by attaining a\nkappa score between 0.7-0.8 with only 10 labeled examples per class. We get\nsimilar impressive performance even if the features are transferred from a\ndifferent data source. While this paper focuses on HAR as the application\ndomain, the proposed technique is general and could be applied to a wide\nvariety of problems in other areas.\n", "versions": [{"version": "v1", "created": "Sat, 27 Jul 2019 09:14:43 GMT"}], "update_date": "2019-07-30", "authors_parsed": [["Saeed", "Aaqib", ""], ["Ozcelebi", "Tanir", ""], ["Lukkien", "Johan", ""]]}, {"id": "1907.11887", "submitter": "Trung V. Phan", "authors": "Trung V. Phan, T M Rayhan Gias, Syed Tasnimul Islam, Truong Thu Huong,\n  Nguyen Huu Thanh and Thomas Bauschert", "title": "Q-MIND: Defeating Stealthy DoS Attacks in SDN with a Machine-learning\n  based Defense Framework", "comments": "This paper has been accepted for publication in IEEE GLOBECOM\n  conference 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Software Defined Networking (SDN) enables flexible and scalable network\ncontrol and management. However, it also introduces new vulnerabilities that\ncan be exploited by attackers. In particular, low-rate and slow or stealthy\nDenial-of-Service (DoS) attacks are recently attracting attention from\nresearchers because of their detection challenges. In this paper, we propose a\nnovel machine learning based defense framework named Q-MIND, to effectively\ndetect and mitigate stealthy DoS attacks in SDN-based networks. We first\nanalyze the adversary model of stealthy DoS attacks, the related\nvulnerabilities in SDN-based networks and the key characteristics of stealthy\nDoS attacks. Next, we describe and analyze an anomaly detection system that\nuses a Reinforcement Learning-based approach based on Q-Learning in order to\nmaximize its detection performance. Finally, we outline the complete Q-MIND\ndefense framework that incorporates the optimal policy derived from the\nQ-Learning agent to efficiently defeat stealthy DoS attacks in SDN-based\nnetworks. An extensive comparison of the Q-MIND framework and currently\nexisting methods shows that significant improvements in attack detection and\nmitigation performance are obtained by Q-MIND.\n", "versions": [{"version": "v1", "created": "Sat, 27 Jul 2019 10:12:36 GMT"}, {"version": "v2", "created": "Tue, 3 Sep 2019 18:12:30 GMT"}], "update_date": "2019-09-05", "authors_parsed": [["Phan", "Trung V.", ""], ["Gias", "T M Rayhan", ""], ["Islam", "Syed Tasnimul", ""], ["Huong", "Truong Thu", ""], ["Thanh", "Nguyen Huu", ""], ["Bauschert", "Thomas", ""]]}, {"id": "1907.11889", "submitter": "Matan Orbach", "authors": "Tamar Lavee, Matan Orbach, Lili Kotlerman, Yoav Kantor, Shai Gretz,\n  Lena Dankin, Shachar Mirkin, Michal Jacovi, Yonatan Bilu, Ranit Aharonov and\n  Noam Slonim", "title": "Towards Effective Rebuttal: Listening Comprehension using Corpus-Wide\n  Claim Mining", "comments": "6th Argument Mining Workshop @ ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Engaging in a live debate requires, among other things, the ability to\neffectively rebut arguments claimed by your opponent. In particular, this\nrequires identifying these arguments. Here, we suggest doing so by\nautomatically mining claims from a corpus of news articles containing billions\nof sentences, and searching for them in a given speech. This raises the\nquestion of whether such claims indeed correspond to those made in spoken\nspeeches. To this end, we collected a large dataset of $400$ speeches in\nEnglish discussing $200$ controversial topics, mined claims for each topic, and\nasked annotators to identify the mined claims mentioned in each speech. Results\nshow that in the vast majority of speeches debaters indeed make use of such\nclaims. In addition, we present several baselines for the automatic detection\nof mined claims in speeches, forming the basis for future work. All collected\ndata is freely available for research.\n", "versions": [{"version": "v1", "created": "Sat, 27 Jul 2019 10:19:19 GMT"}], "update_date": "2019-07-30", "authors_parsed": [["Lavee", "Tamar", ""], ["Orbach", "Matan", ""], ["Kotlerman", "Lili", ""], ["Kantor", "Yoav", ""], ["Gretz", "Shai", ""], ["Dankin", "Lena", ""], ["Mirkin", "Shachar", ""], ["Jacovi", "Michal", ""], ["Bilu", "Yonatan", ""], ["Aharonov", "Ranit", ""], ["Slonim", "Noam", ""]]}, {"id": "1907.11891", "submitter": "Mingtian Zhang", "authors": "Mingtian Zhang, Thomas Bird, Raza Habib, Tianlin Xu, David Barber", "title": "Variational f-divergence Minimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Probabilistic models are often trained by maximum likelihood, which\ncorresponds to minimizing a specific f-divergence between the model and data\ndistribution. In light of recent successes in training Generative Adversarial\nNetworks, alternative non-likelihood training criteria have been proposed.\nWhilst not necessarily statistically efficient, these alternatives may better\nmatch user requirements such as sharp image generation. A general variational\nmethod for training probabilistic latent variable models using maximum\nlikelihood is well established; however, how to train latent variable models\nusing other f-divergences is comparatively unknown. We discuss a variational\napproach that, when combined with the recently introduced Spread Divergence,\ncan be applied to train a large class of latent variable models using any\nf-divergence.\n", "versions": [{"version": "v1", "created": "Sat, 27 Jul 2019 10:32:08 GMT"}], "update_date": "2019-07-30", "authors_parsed": [["Zhang", "Mingtian", ""], ["Bird", "Thomas", ""], ["Habib", "Raza", ""], ["Xu", "Tianlin", ""], ["Barber", "David", ""]]}, {"id": "1907.11900", "submitter": "Simon Wiedemann", "authors": "Simon Wiedemann, Heiner Kirchoffer, Stefan Matlage, Paul Haase, Arturo\n  Marban, Talmaj Marinc, David Neumann, Tung Nguyen, Ahmed Osman, Detlev Marpe,\n  Heiko Schwarz, Thomas Wiegand, Wojciech Samek", "title": "DeepCABAC: A Universal Compression Algorithm for Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The field of video compression has developed some of the most sophisticated\nand efficient compression algorithms known in the literature, enabling very\nhigh compressibility for little loss of information. Whilst some of these\ntechniques are domain specific, many of their underlying principles are\nuniversal in that they can be adapted and applied for compressing different\ntypes of data. In this work we present DeepCABAC, a compression algorithm for\ndeep neural networks that is based on one of the state-of-the-art video coding\ntechniques. Concretely, it applies a Context-based Adaptive Binary Arithmetic\nCoder (CABAC) to the network's parameters, which was originally designed for\nthe H.264/AVC video coding standard and became the state-of-the-art for\nlossless compression. Moreover, DeepCABAC employs a novel quantization scheme\nthat minimizes the rate-distortion function while simultaneously taking the\nimpact of quantization onto the accuracy of the network into account.\nExperimental results show that DeepCABAC consistently attains higher\ncompression rates than previously proposed coding techniques for neural network\ncompression. For instance, it is able to compress the VGG16 ImageNet model by\nx63.6 with no loss of accuracy, thus being able to represent the entire network\nwith merely 8.7MB. The source code for encoding and decoding can be found at\nhttps://github.com/fraunhoferhhi/DeepCABAC.\n", "versions": [{"version": "v1", "created": "Sat, 27 Jul 2019 12:00:01 GMT"}], "update_date": "2019-07-30", "authors_parsed": [["Wiedemann", "Simon", ""], ["Kirchoffer", "Heiner", ""], ["Matlage", "Stefan", ""], ["Haase", "Paul", ""], ["Marban", "Arturo", ""], ["Marinc", "Talmaj", ""], ["Neumann", "David", ""], ["Nguyen", "Tung", ""], ["Osman", "Ahmed", ""], ["Marpe", "Detlev", ""], ["Schwarz", "Heiko", ""], ["Wiegand", "Thomas", ""], ["Samek", "Wojciech", ""]]}, {"id": "1907.11911", "submitter": "Cheng Qian", "authors": "Cheng Qian, Amin Emad, and Nicholas D. Sidiropoulos", "title": "REP: Predicting the Time-Course of Drug Sensitivity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The biological processes involved in a drug's mechanisms of action are\noftentimes dynamic, complex and difficult to discern. Time-course gene\nexpression data is a rich source of information that can be used to unravel\nthese complex processes, identify biomarkers of drug sensitivity and predict\nthe response to a drug. However, the majority of previous work has not fully\nutilized this temporal dimension. In these studies, the gene expression data is\neither considered at one time-point (before the administration of the drug) or\ntwo timepoints (before and after the administration of the drug). This is\nclearly inadequate in modeling dynamic gene-drug interactions, especially for\napplications such as long-term drug therapy.\n  In this work, we present a novel REcursive Prediction (REP) framework for\ndrug response prediction by taking advantage of time-course gene expression\ndata. Our goal is to predict drug response values at every stage of a long-term\ntreatment, given the expression levels of genes collected in the previous\ntime-points. To this end, REP employs a built-in recursive structure that\nexploits the intrinsic time-course nature of the data and integrates past\nvalues of drug responses for subsequent predictions. It also incorporates\ntensor completion that can not only alleviate the impact of noise and missing\ndata, but also predict unseen gene expression levels (GELs). These advantages\nenable REP to estimate drug response at any stage of a given treatment from\nsome GELs measured in the beginning of the treatment. Extensive experiments on\na dataset corresponding to 53 multiple sclerosis patients treated with\ninterferon are included to showcase the effectiveness of REP.\n", "versions": [{"version": "v1", "created": "Sat, 27 Jul 2019 13:49:40 GMT"}], "update_date": "2019-07-30", "authors_parsed": [["Qian", "Cheng", ""], ["Emad", "Amin", ""], ["Sidiropoulos", "Nicholas D.", ""]]}, {"id": "1907.11922", "submitter": "Ziwei Liu", "authors": "Cheng-Han Lee, Ziwei Liu, Lingyun Wu, Ping Luo", "title": "MaskGAN: Towards Diverse and Interactive Facial Image Manipulation", "comments": "To appear in IEEE Conference on Computer Vision and Pattern\n  Recognition (CVPR), 2020. The code, models and dataset are available at:\n  https://github.com/switchablenorms/CelebAMask-HQ", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.GR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Facial image manipulation has achieved great progress in recent years.\nHowever, previous methods either operate on a predefined set of face attributes\nor leave users little freedom to interactively manipulate images. To overcome\nthese drawbacks, we propose a novel framework termed MaskGAN, enabling diverse\nand interactive face manipulation. Our key insight is that semantic masks serve\nas a suitable intermediate representation for flexible face manipulation with\nfidelity preservation. MaskGAN has two main components: 1) Dense Mapping\nNetwork (DMN) and 2) Editing Behavior Simulated Training (EBST). Specifically,\nDMN learns style mapping between a free-form user modified mask and a target\nimage, enabling diverse generation results. EBST models the user editing\nbehavior on the source mask, making the overall framework more robust to\nvarious manipulated inputs. Specifically, it introduces dual-editing\nconsistency as the auxiliary supervision signal. To facilitate extensive\nstudies, we construct a large-scale high-resolution face dataset with\nfine-grained mask annotations named CelebAMask-HQ. MaskGAN is comprehensively\nevaluated on two challenging tasks: attribute transfer and style copy,\ndemonstrating superior performance over other state-of-the-art methods. The\ncode, models, and dataset are available at\nhttps://github.com/switchablenorms/CelebAMask-HQ.\n", "versions": [{"version": "v1", "created": "Sat, 27 Jul 2019 14:23:19 GMT"}, {"version": "v2", "created": "Wed, 1 Apr 2020 05:34:29 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Lee", "Cheng-Han", ""], ["Liu", "Ziwei", ""], ["Wu", "Lingyun", ""], ["Luo", "Ping", ""]]}, {"id": "1907.11932", "submitter": "Zhijing Jin", "authors": "Di Jin, Zhijing Jin, Joey Tianyi Zhou, Peter Szolovits", "title": "Is BERT Really Robust? A Strong Baseline for Natural Language Attack on\n  Text Classification and Entailment", "comments": "AAAI 2020 (Oral)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Machine learning algorithms are often vulnerable to adversarial examples that\nhave imperceptible alterations from the original counterparts but can fool the\nstate-of-the-art models. It is helpful to evaluate or even improve the\nrobustness of these models by exposing the maliciously crafted adversarial\nexamples. In this paper, we present TextFooler, a simple but strong baseline to\ngenerate natural adversarial text. By applying it to two fundamental natural\nlanguage tasks, text classification and textual entailment, we successfully\nattacked three target models, including the powerful pre-trained BERT, and the\nwidely used convolutional and recurrent neural networks. We demonstrate the\nadvantages of this framework in three ways: (1) effective---it outperforms\nstate-of-the-art attacks in terms of success rate and perturbation rate, (2)\nutility-preserving---it preserves semantic content and grammaticality, and\nremains correctly classified by humans, and (3) efficient---it generates\nadversarial text with computational complexity linear to the text length. *The\ncode, pre-trained target models, and test examples are available at\nhttps://github.com/jind11/TextFooler.\n", "versions": [{"version": "v1", "created": "Sat, 27 Jul 2019 15:07:04 GMT"}, {"version": "v2", "created": "Sat, 7 Sep 2019 05:33:35 GMT"}, {"version": "v3", "created": "Sat, 23 Nov 2019 07:53:08 GMT"}, {"version": "v4", "created": "Thu, 23 Jan 2020 07:16:25 GMT"}, {"version": "v5", "created": "Sun, 5 Apr 2020 07:12:08 GMT"}, {"version": "v6", "created": "Wed, 8 Apr 2020 23:10:10 GMT"}], "update_date": "2020-04-10", "authors_parsed": [["Jin", "Di", ""], ["Jin", "Zhijing", ""], ["Zhou", "Joey Tianyi", ""], ["Szolovits", "Peter", ""]]}, {"id": "1907.11943", "submitter": "Guangcong Wang", "authors": "Guangcong Wang and Jianhuang Lai and Wenqi Liang and Guangrun Wang", "title": "Learnable Parameter Similarity", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most of the existing approaches focus on specific visual tasks while ignoring\nthe relations between them. Estimating task relation sheds light on the\nlearning of high-order semantic concepts, e.g., transfer learning. How to\nreveal the underlying relations between different visual tasks remains largely\nunexplored. In this paper, we propose a novel \\textbf{L}earnable\n\\textbf{P}arameter \\textbf{S}imilarity (\\textbf{LPS}) method that learns an\neffective metric to measure the similarity of second-order semantics hidden in\ntrained models. LPS is achieved by using a second-order neural network to align\nhigh-dimensional model parameters and learning second-order similarity in an\nend-to-end way. In addition, we create a model set called ModelSet500 as a\nparameter similarity learning benchmark that contains 500 trained models.\nExtensive experiments on ModelSet500 validate the effectiveness of the proposed\nmethod. Code will be released at\n\\url{https://github.com/Wanggcong/learnable-parameter-similarity}.\n", "versions": [{"version": "v1", "created": "Sat, 27 Jul 2019 16:14:08 GMT"}], "update_date": "2019-07-30", "authors_parsed": [["Wang", "Guangcong", ""], ["Lai", "Jianhuang", ""], ["Liang", "Wenqi", ""], ["Wang", "Guangrun", ""]]}, {"id": "1907.11951", "submitter": "Xin Liu", "authors": "Xin Liu, Konstantinos Pelechrinis, Alexandros Labrinidis", "title": "hood2vec: Identifying Similar Urban Areas Using Mobility Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Which area in NYC is the most similar to Lower East Side? What about the NoHo\nArts District in Los Angeles? Traditionally this task utilizes information\nabout the type of places located within the areas and some popularity/quality\nmetric. We take a different approach. In particular, urban dwellers'\ntime-variant mobility is a reflection of how they interact with their city over\ntime. Hence, in this paper, we introduce an approach, namely hood2vec, to\nidentify the similarity between urban areas through learning a node embedding\nof the mobility network captured through Foursquare check-ins. We compare the\npairwise similarities obtained from hood2vec with the ones obtained from\ncomparing the types of venues in the different areas. The low correlation\nbetween the two indicates that the mobility dynamics and the venue types\npotentially capture different aspects of similarity between urban areas.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jul 2019 12:34:12 GMT"}], "update_date": "2019-07-30", "authors_parsed": [["Liu", "Xin", ""], ["Pelechrinis", "Konstantinos", ""], ["Labrinidis", "Alexandros", ""]]}, {"id": "1907.11959", "submitter": "Wenye Li", "authors": "Wenye Li", "title": "Modeling Winner-Take-All Competition in Sparse Binary Projections", "comments": "9 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inspired by the advances in biological science, the study of sparse binary\nprojection models has attracted considerable recent research attention. The\nmodels project dense input samples into a higher-dimensional space and output\nsparse binary data representations after the Winner-Take-All competition,\nsubject to the constraint that the projection matrix is also sparse and binary.\nFollowing the work along this line, we developed a supervised-WTA model when\ntraining samples with both input and output representations are available, from\nwhich the optimal projection matrix can be obtained with a simple, effective\nyet efficient algorithm. We further extended the model and the algorithm to an\nunsupervised setting where only the input representation of the samples is\navailable. In a series of empirical evaluation on similarity search tasks, the\nproposed models reported significantly improved results over the\nstate-of-the-art methods in both search accuracies and running speed. The\nsuccessful results give us strong confidence that the work provides a highly\npractical tool to real world applications.\n", "versions": [{"version": "v1", "created": "Sat, 27 Jul 2019 18:23:48 GMT"}, {"version": "v2", "created": "Mon, 27 Jan 2020 03:51:07 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Li", "Wenye", ""]]}, {"id": "1907.11968", "submitter": "Chengbin Hou", "authors": "Chengbin Hou, Han Zhang, Ke Tang, Shan He", "title": "DynWalks: Global Topology and Recent Changes Awareness Dynamic Network\n  Embedding", "comments": "14 pages, 7 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning topological representation of a network in dynamic environments has\nrecently attracted considerable attention due to the time-evolving nature of\nmany real-world networks i.e. nodes/links might be added/removed as time goes\non. Dynamic network embedding aims to learn low dimensional embeddings for\nunseen and seen nodes by using any currently available snapshots of a dynamic\nnetwork. For seen nodes, the existing methods either treat them equally\nimportant or focus on the $k$ most affected nodes at each time step. However,\nthe former solution is time-consuming, and the later solution that relies on\nincoming changes may lose the global topology---an important feature for\ndownstream tasks. To address these challenges, we propose a dynamic network\nembedding method called DynWalks, which includes two key components: 1) An\nonline network embedding framework that can dynamically and efficiently learn\nembeddings based on the selected nodes; 2) A novel online node selecting scheme\nthat offers the flexible choices to balance global topology and recent changes,\nas well as to fulfill the real-time constraint if needed. The empirical studies\non six real-world dynamic networks under three different slicing ways show that\nDynWalks significantly outperforms the state-of-the-art methods in graph\nreconstruction tasks, and obtains comparable results in link prediction tasks.\nFurthermore, the wall-clock time and complexity analysis demonstrate its\nexcellent time and space efficiency. The source code of DynWalks is available\nat https://github.com/houchengbin/DynWalks\n", "versions": [{"version": "v1", "created": "Sat, 27 Jul 2019 19:32:33 GMT"}], "update_date": "2019-07-30", "authors_parsed": [["Hou", "Chengbin", ""], ["Zhang", "Han", ""], ["Tang", "Ke", ""], ["He", "Shan", ""]]}, {"id": "1907.11975", "submitter": "Soumya Basu", "authors": "Soumya Basu, Rajat Sen, Sujay Sanghavi, Sanjay Shakkottai", "title": "Blocking Bandits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a novel stochastic multi-armed bandit setting, where playing an\narm makes it unavailable for a fixed number of time slots thereafter. This\nmodels situations where reusing an arm too often is undesirable (e.g. making\nthe same product recommendation repeatedly) or infeasible (e.g. compute job\nscheduling on machines). We show that with prior knowledge of the rewards and\ndelays of all the arms, the problem of optimizing cumulative reward does not\nadmit any pseudo-polynomial time algorithm (in the number of arms) unless\nrandomized exponential time hypothesis is false, by mapping to the PINWHEEL\nscheduling problem. Subsequently, we show that a simple greedy algorithm that\nplays the available arm with the highest reward is asymptotically $(1-1/e)$\noptimal. When the rewards are unknown, we design a UCB based algorithm which is\nshown to have $c \\log T + o(\\log T)$ cumulative regret against the greedy\nalgorithm, leveraging the free exploration of arms due to the unavailability.\nFinally, when all the delays are equal the problem reduces to Combinatorial\nSemi-bandits providing us with a lower bound of $c' \\log T+ \\omega(\\log T)$.\n", "versions": [{"version": "v1", "created": "Sat, 27 Jul 2019 20:42:01 GMT"}], "update_date": "2019-07-30", "authors_parsed": [["Basu", "Soumya", ""], ["Sen", "Rajat", ""], ["Sanghavi", "Sujay", ""], ["Shakkottai", "Sanjay", ""]]}, {"id": "1907.11984", "submitter": "Tarik A. Rashid", "authors": "Naser Rostamni and Tarik A. Rashid", "title": "Investigating the effect of competitiveness power in estimating the\n  average weighted price in electricity market", "comments": "11 pages", "journal-ref": "The Electricity Journal, 2019", "doi": "10.1016/j.tej.2019.106628", "report-no": null, "categories": "q-fin.ST cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  This paper evaluates the impact of the power extent on price in the\nelectricity market. The competitiveness extent of the electricity market during\nspecific times in a day is considered to achieve this. Then, the effect of\ncompetitiveness extent on the forecasting precision of the daily power price is\nassessed. A price forecasting model based on multi-layer perception via back\npropagation with the Levenberg-Marquardt mechanism is used. The Residual Supply\nIndex (RSI) and other variables that affect prices are used as inputs to the\nmodel to evaluate the market competitiveness. The results show that using\nmarket power indices as inputs helps to increase forecasting accuracy. Thus,\nthe competitiveness extent of the market power in different daily time periods\nis a notable variable in price formation. Moreover, market players cannot\nignore the explanatory power of market power in price forecasting. In this\nresearch, the real data of the electricity market from 2013 is used and the\nmain source of data is the Grid Management Company in Iran.\n", "versions": [{"version": "v1", "created": "Sat, 27 Jul 2019 22:13:38 GMT"}], "update_date": "2019-07-30", "authors_parsed": [["Rostamni", "Naser", ""], ["Rashid", "Tarik A.", ""]]}, {"id": "1907.11985", "submitter": "Chenguang Dai", "authors": "Chenguang Dai and Jun S. Liu", "title": "The Wang-Landau Algorithm as Stochastic Optimization and Its\n  Acceleration", "comments": "10 pages, 3 figures", "journal-ref": "Phys. Rev. E 101, 033301 (2020)", "doi": "10.1103/PhysRevE.101.033301", "report-no": null, "categories": "stat.CO cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that the Wang-Landau algorithm can be formulated as a stochastic\ngradient descent algorithm minimizing a smooth and convex objective function,\nof which the gradient is estimated using Markov chain Monte Carlo iterations.\nThe optimization formulation provides us a new way to establish the convergence\nrate of the Wang-Landau algorithm, by exploiting the fact that almost surely,\nthe density estimates (on the logarithmic scale) remain in a compact set, upon\nwhich the objective function is strongly convex. The optimization viewpoint\nmotivates us to improve the efficiency of the Wang-Landau algorithm using\npopular tools including the momentum method and the adaptive learning rate\nmethod. We demonstrate the accelerated Wang-Landau algorithm on a\ntwo-dimensional Ising model and a two-dimensional ten-state Potts model.\n", "versions": [{"version": "v1", "created": "Sat, 27 Jul 2019 22:31:08 GMT"}, {"version": "v2", "created": "Sun, 2 Feb 2020 20:45:57 GMT"}], "update_date": "2020-03-11", "authors_parsed": [["Dai", "Chenguang", ""], ["Liu", "Jun S.", ""]]}, {"id": "1907.12003", "submitter": "Zhila Esna Ashari", "authors": "Zhila Esna Ashari and Hassan Ghasemzadeh", "title": "Mindful Active Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel active learning framework for activity recognition using\nwearable sensors. Our work is unique in that it takes physical and cognitive\nlimitations of the oracle into account when selecting sensor data to be\nannotated by the oracle. Our approach is inspired by human-beings' limited\ncapacity to respond to external stimulus such as responding to a prompt on\ntheir mobile devices. This capacity constraint is manifested not only in the\nnumber of queries that a person can respond to in a given time-frame but also\nin the lag between the time that a query is made and when it is responded to.\nWe introduce the notion of mindful active learning and propose a computational\nframework, called EMMA, to maximize the active learning performance taking\ninformativeness of sensor data, query budget, and human memory into account. We\nformulate this optimization problem, propose an approach to model memory\nretention, discuss complexity of the problem, and propose a greedy heuristic to\nsolve the problem. We demonstrate the effectiveness of our approach on three\npublicly available datasets and by simulating oracles with various memory\nstrengths. We show that the activity recognition accuracy ranges from 21% to\n97% depending on memory strength, query budget, and difficulty of the machine\nlearning task. Our results also indicate that EMMA achieves an accuracy level\nthat is, on average, 13.5% higher than the case when only informativeness of\nthe sensor data is considered for active learning. Additionally, we show that\nthe performance of our approach is at most 20% less than experimental\nupper-bound and up to 80% higher than experimental lower-bound. We observe that\nmindful active learning is most beneficial when query budget is small and/or\noracle's memory is weak, thus emphasizing contributions of our work in\nhuman-centered mobile health settings and for elderly with cognitive\nimpairments.\n", "versions": [{"version": "v1", "created": "Sun, 28 Jul 2019 02:44:52 GMT"}], "update_date": "2019-07-30", "authors_parsed": [["Ashari", "Zhila Esna", ""], ["Ghasemzadeh", "Hassan", ""]]}, {"id": "1907.12012", "submitter": "Michael Weylandt", "authors": "Michael Weylandt", "title": "Multi-Rank Sparse and Functional PCA: Manifold Optimization and\n  Iterative Deflation Techniques", "comments": "To appear in IEEE CAMSAP 2019", "journal-ref": "2019 IEEE 8th International Workshop on Computational Advances in\n  Multi-Sensor Adaptive Processing (CAMSAP), pp.500-504", "doi": "10.1109/CAMSAP45676.2019.9022486", "report-no": null, "categories": "stat.ML cs.LG stat.CO", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We consider the problem of estimating multiple principal components using the\nrecently-proposed Sparse and Functional Principal Components Analysis (SFPCA)\nestimator. We first propose an extension of SFPCA which estimates several\nprincipal components simultaneously using manifold optimization techniques to\nenforce orthogonality constraints. While effective, this approach is\ncomputationally burdensome so we also consider iterative deflation approaches\nwhich take advantage of existing fast algorithms for rank-one SFPCA. We show\nthat alternative deflation schemes can more efficiently extract signal from the\ndata, in turn improving estimation of subsequent components. Finally, we\ncompare the performance of our manifold optimization and deflation techniques\nin a scenario where orthogonality does not hold and find that they still lead\nto significantly improved performance.\n", "versions": [{"version": "v1", "created": "Sun, 28 Jul 2019 04:43:54 GMT"}, {"version": "v2", "created": "Thu, 10 Oct 2019 20:57:59 GMT"}], "update_date": "2020-12-10", "authors_parsed": [["Weylandt", "Michael", ""]]}, {"id": "1907.12022", "submitter": "Zongyue Zhao", "authors": "Zongyue Zhao, Min Liu, Karthik Ramani", "title": "DAR-Net: Dynamic Aggregation Network for Semantic Scene Segmentation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional grid/neighbor-based static pooling has become a constraint for\npoint cloud geometry analysis. In this paper, we propose DAR-Net, a novel\nnetwork architecture that focuses on dynamic feature aggregation. The central\nidea of DAR-Net is generating a self-adaptive pooling skeleton that considers\nboth scene complexity and local geometry features. Providing variable\nsemi-local receptive fields and weights, the skeleton serves as a bridge that\nconnect local convolutional feature extractors and a global recurrent feature\nintegrator. Experimental results on indoor scene datasets show advantages of\nthe proposed approach compared to state-of-the-art architectures that adopt\nstatic pooling methods.\n", "versions": [{"version": "v1", "created": "Sun, 28 Jul 2019 06:23:19 GMT"}, {"version": "v2", "created": "Thu, 26 Dec 2019 03:13:59 GMT"}], "update_date": "2019-12-30", "authors_parsed": [["Zhao", "Zongyue", ""], ["Liu", "Min", ""], ["Ramani", "Karthik", ""]]}, {"id": "1907.12048", "submitter": "Xavier Holt Mr", "authors": "Xavier Holt", "title": "Probabilistic Models of Relational Implication", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Relational data in its most basic form is a static collection of known facts.\nHowever, by learning to infer and deduct additional information and structure,\nwe can massively increase the usefulness of the underlying data. One common\nform of inferential reasoning in knowledge bases is implication discovery.\nHere, by learning when one relation implies another, we can extend our\nknowledge representation. There are several existing models for relational\nimplication, however we argue they are motivated but not principled. To this\nend, we define a formal probabilistic model of relational implication. By using\nestimators based on the empirical distribution of our dataset, we demonstrate\nthat our model outperforms existing approaches. While previous work achieves a\nbest score of 0.7812 AUC on an evaluatory dataset, our ProbE model improves\nthis to 0.7915. Furthermore, we demonstrate that our model can be improved\nsubstantially through the use of link prediction models and dense latent\nrepresentations of the underlying argument and relations. This variant, denoted\nProbL, improves the state of the art on our evaluation dataset to 0.8143. In\naddition to developing a new framework and providing novel scores of relational\nimplication, we provide two pragmatic resources to assist future research.\nFirst, we motivate and develop an improved crowd framework for constructing\nlabelled datasets of relational implication. Using this, we reannotate and make\npublic a dataset comprised of 17,848 instances of labelled relational\nimplication. We demonstrate that precision (as evaluated by expert consensus\nwith the crowd labels) on the resulting dataset improves from 53% to 95%.\n", "versions": [{"version": "v1", "created": "Sun, 28 Jul 2019 08:56:06 GMT"}], "update_date": "2019-07-30", "authors_parsed": [["Holt", "Xavier", ""]]}, {"id": "1907.12059", "submitter": "Silvia Chiappa", "authors": "Ray Jiang and Aldo Pacchiano and Tom Stepleton and Heinrich Jiang and\n  Silvia Chiappa", "title": "Wasserstein Fair Classification", "comments": null, "journal-ref": "Proceedings of the Thirty-Fifth Conference on Uncertainty in\n  Artificial Intelligence, 2019", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an approach to fair classification that enforces independence\nbetween the classifier outputs and sensitive information by minimizing\nWasserstein-1 distances. The approach has desirable theoretical properties and\nis robust to specific choices of the threshold used to obtain class predictions\nfrom model outputs. We introduce different methods that enable hiding sensitive\ninformation at test time or have a simple and fast implementation. We show\nempirical performance against different fairness baselines on several benchmark\nfairness datasets.\n", "versions": [{"version": "v1", "created": "Sun, 28 Jul 2019 09:57:37 GMT"}], "update_date": "2019-07-30", "authors_parsed": [["Jiang", "Ray", ""], ["Pacchiano", "Aldo", ""], ["Stepleton", "Tom", ""], ["Jiang", "Heinrich", ""], ["Chiappa", "Silvia", ""]]}, {"id": "1907.12071", "submitter": "Xiaohan Lin", "authors": "Yuanyuan Mi, Xiaohan Lin, Xiaolong Zou, Zilong Ji, Tiejun Huang, Si Wu", "title": "Spatiotemporal Information Processing with a Reservoir Decision-making\n  Network", "comments": "9 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spatiotemporal information processing is fundamental to brain functions. The\npresent study investigates a canonic neural network model for spatiotemporal\npattern recognition. Specifically, the model consists of two modules, a\nreservoir subnetwork and a decision-making subnetwork. The former projects\ncomplex spatiotemporal patterns into spatially separated neural\nrepresentations, and the latter reads out these neural representations via\nintegrating information over time; the two modules are combined together via\nsupervised-learning using known examples. We elucidate the working mechanism of\nthe model and demonstrate its feasibility for discriminating complex\nspatiotemporal patterns. Our model reproduces the phenomenon of recognizing\nlooming patterns in the neural system, and can learn to discriminate gait with\nvery few training examples. We hope this study gives us insight into\nunderstanding how spatiotemporal information is processed in the brain and\nhelps us to develop brain-inspired application algorithms.\n", "versions": [{"version": "v1", "created": "Sun, 28 Jul 2019 11:04:34 GMT"}], "update_date": "2019-07-30", "authors_parsed": [["Mi", "Yuanyuan", ""], ["Lin", "Xiaohan", ""], ["Zou", "Xiaolong", ""], ["Ji", "Zilong", ""], ["Huang", "Tiejun", ""], ["Wu", "Si", ""]]}, {"id": "1907.12087", "submitter": "Nupur Kumari", "authors": "Puneet Mangla, Mayank Singh, Abhishek Sinha, Nupur Kumari, Vineeth N\n  Balasubramanian, Balaji Krishnamurthy", "title": "Charting the Right Manifold: Manifold Mixup for Few-shot Learning", "comments": "WACV 2020, Code: https://github.com/nupurkmr9/S2M2_fewshot", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Few-shot learning algorithms aim to learn model parameters capable of\nadapting to unseen classes with the help of only a few labeled examples. A\nrecent regularization technique - Manifold Mixup focuses on learning a\ngeneral-purpose representation, robust to small changes in the data\ndistribution. Since the goal of few-shot learning is closely linked to robust\nrepresentation learning, we study Manifold Mixup in this problem setting.\nSelf-supervised learning is another technique that learns semantically\nmeaningful features, using only the inherent structure of the data. This work\ninvestigates the role of learning relevant feature manifold for few-shot tasks\nusing self-supervision and regularization techniques. We observe that\nregularizing the feature manifold, enriched via self-supervised techniques,\nwith Manifold Mixup significantly improves few-shot learning performance. We\nshow that our proposed method S2M2 beats the current state-of-the-art accuracy\non standard few-shot learning datasets like CIFAR-FS, CUB, mini-ImageNet and\ntiered-ImageNet by 3-8 %. Through extensive experimentation, we show that the\nfeatures learned using our approach generalize to complex few-shot evaluation\ntasks, cross-domain scenarios and are robust against slight changes to data\ndistribution.\n", "versions": [{"version": "v1", "created": "Sun, 28 Jul 2019 14:14:55 GMT"}, {"version": "v2", "created": "Wed, 7 Aug 2019 19:40:53 GMT"}, {"version": "v3", "created": "Wed, 4 Dec 2019 08:02:11 GMT"}, {"version": "v4", "created": "Sat, 18 Jan 2020 20:01:55 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Mangla", "Puneet", ""], ["Singh", "Mayank", ""], ["Sinha", "Abhishek", ""], ["Kumari", "Nupur", ""], ["Balasubramanian", "Vineeth N", ""], ["Krishnamurthy", "Balaji", ""]]}, {"id": "1907.12116", "submitter": "Ryan Giordano", "authors": "Ryan Giordano, Michael I. Jordan, Tamara Broderick", "title": "A Higher-Order Swiss Army Infinitesimal Jackknife", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cross validation (CV) and the bootstrap are ubiquitous model-agnostic tools\nfor assessing the error or variability of machine learning and statistical\nestimators. However, these methods require repeatedly re-fitting the model with\ndifferent weighted versions of the original dataset, which can be prohibitively\ntime-consuming. For sufficiently regular optimization problems the optimum\ndepends smoothly on the data weights, and so the process of repeatedly\nre-fitting can be approximated with a Taylor series that can be often evaluated\nrelatively quickly. The first-order approximation is known as the\n\"infinitesimal jackknife\" in the statistics literature and has been the subject\nof recent interest in machine learning for approximate CV. In this work, we\nconsider high-order approximations, which we call the \"higher-order\ninfinitesimal jackknife\" (HOIJ). Under mild regularity conditions, we provide a\nsimple recursive procedure to compute approximations of all orders with\nfinite-sample accuracy bounds. Additionally, we show that the HOIJ can be\nefficiently computed even in high dimensions using forward-mode automatic\ndifferentiation. We show that a linear approximation with bootstrap weights\napproximation is equivalent to those provided by asymptotic normal\napproximations. Consequently, the HOIJ opens up the possibility of enjoying\nhigher-order accuracy properties of the bootstrap using local approximations.\nConsistency of the HOIJ for leave-one-out CV under different asymptotic regimes\nfollows as corollaries from our finite-sample bounds under additional\nregularity assumptions. The generality of the computation and bounds motivate\nthe name \"higher-order Swiss Army infinitesimal jackknife.\"\n", "versions": [{"version": "v1", "created": "Sun, 28 Jul 2019 17:49:48 GMT"}], "update_date": "2019-07-30", "authors_parsed": [["Giordano", "Ryan", ""], ["Jordan", "Michael I.", ""], ["Broderick", "Tamara", ""]]}, {"id": "1907.12118", "submitter": "Xiao Yang", "authors": "Xiao Yang, Daren Sun, Ruiwei Zhu, Tao Deng, Zhi Guo, Jiao Ding, Shouke\n  Qin, Zongyao Ding, Yanfeng Zhu", "title": "AiAds: Automated and Intelligent Advertising System for Sponsored Search", "comments": "Accepted at ACM KDD 2019. arXiv admin note: text overlap with\n  arXiv:1701.05946 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sponsored search has more than 20 years of history, and it has been proven to\nbe a successful business model for online advertising. Based on the\npay-per-click pricing model and the keyword targeting technology, the sponsored\nsystem runs online auctions to determine the allocations and prices of search\nadvertisements. In the traditional setting, advertisers should manually create\nlots of ad creatives and bid on some relevant keywords to target their\naudience. Due to the huge amount of search traffic and a wide variety of ad\ncreations, the limits of manual optimizations from advertisers become the main\nbottleneck for improving the efficiency of this market. Moreover, as many\nemerging advertising forms and supplies are growing, it's crucial for sponsored\nsearch platform to pay more attention to the ROI metrics of ads for getting the\nmarketing budgets of advertisers. In this paper, we present the AiAds system\ndeveloped at Baidu, which use machine learning techniques to build an automated\nand intelligent advertising system. By designing and implementing the automated\nbidding strategy, the intelligent targeting and the intelligent creation\nmodels, the AiAds system can transform the manual optimizations into multiple\nautomated tasks and optimize these tasks in advanced methods. AiAds is a\nbrand-new architecture of sponsored search system which changes the bidding\nlanguage and allocation mechanism, breaks the limit of keyword targeting with\nend-to-end ad retrieval framework and provides global optimization of ad\ncreation. This system can increase the advertiser's campaign performance, the\nuser experience and the revenue of the advertising platform simultaneously and\nsignificantly. We present the overall architecture and modeling techniques for\neach module of the system and share our lessons learned in solving several key\nchallenges.\n", "versions": [{"version": "v1", "created": "Sun, 28 Jul 2019 17:55:42 GMT"}], "update_date": "2019-07-30", "authors_parsed": [["Yang", "Xiao", ""], ["Sun", "Daren", ""], ["Zhu", "Ruiwei", ""], ["Deng", "Tao", ""], ["Guo", "Zhi", ""], ["Ding", "Jiao", ""], ["Qin", "Shouke", ""], ["Ding", "Zongyao", ""], ["Zhu", "Yanfeng", ""]]}, {"id": "1907.12138", "submitter": "Hossein Hosseini", "authors": "Hossein Hosseini, Sreeram Kannan, Radha Poovendran", "title": "Are Odds Really Odd? Bypassing Statistical Detection of Adversarial\n  Examples", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning classifiers are known to be vulnerable to adversarial examples.\nA recent paper presented at ICML 2019 proposed a statistical test detection\nmethod based on the observation that logits of noisy adversarial examples are\nbiased toward the true class. The method is evaluated on CIFAR-10 dataset and\nis shown to achieve 99% true positive rate (TPR) at only 1% false positive rate\n(FPR). In this paper, we first develop a classifier-based adaptation of the\nstatistical test method and show that it improves the detection performance. We\nthen propose Logit Mimicry Attack method to generate adversarial examples such\nthat their logits mimic those of benign images. We show that our attack\nbypasses both statistical test and classifier-based methods, reducing their TPR\nto less than 2:2% and 1:6%, respectively, even at 5% FPR. We finally show that\na classifier-based detector that is trained with logits of mimicry adversarial\nexamples can be evaded by an adaptive attacker that specifically targets the\ndetector. Furthermore, even a detector that is iteratively trained to defend\nagainst adaptive attacker cannot be made robust, indicating that statistics of\nlogits cannot be used to detect adversarial examples.\n", "versions": [{"version": "v1", "created": "Sun, 28 Jul 2019 20:45:02 GMT"}], "update_date": "2019-07-30", "authors_parsed": [["Hosseini", "Hossein", ""], ["Kannan", "Sreeram", ""], ["Poovendran", "Radha", ""]]}, {"id": "1907.12160", "submitter": "Soumya Mohanty", "authors": "Soumya D. Mohanty, Ethan Fahnestock", "title": "Adaptive spline fitting with particle swarm optimization", "comments": "Accepted version; Typo corrected in equation 3; Minor changes to text", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO cs.LG cs.NE stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In fitting data with a spline, finding the optimal placement of knots can\nsignificantly improve the quality of the fit. However, the challenging\nhigh-dimensional and non-convex optimization problem associated with completely\nfree knot placement has been a major roadblock in using this approach. We\npresent a method that uses particle swarm optimization (PSO) combined with\nmodel selection to address this challenge. The problem of overfitting due to\nknot clustering that accompanies free knot placement is mitigated in this\nmethod by explicit regularization, resulting in a significantly improved\nperformance on highly noisy data. The principal design choices available in the\nmethod are delineated and a statistically rigorous study of their effect on\nperformance is carried out using simulated data and a wide variety of benchmark\nfunctions. Our results demonstrate that PSO-based free knot placement leads to\na viable and flexible adaptive spline fitting approach that allows the fitting\nof both smooth and non-smooth functions.\n", "versions": [{"version": "v1", "created": "Sun, 28 Jul 2019 23:30:15 GMT"}, {"version": "v2", "created": "Tue, 30 Jul 2019 02:29:55 GMT"}, {"version": "v3", "created": "Tue, 18 Feb 2020 23:52:23 GMT"}, {"version": "v4", "created": "Sun, 28 Jun 2020 17:37:24 GMT"}, {"version": "v5", "created": "Sun, 26 Jul 2020 21:43:33 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Mohanty", "Soumya D.", ""], ["Fahnestock", "Ethan", ""]]}, {"id": "1907.12175", "submitter": "Ramin Ramazi", "authors": "Ramin Ramazi, Christine Perndorfer, Emily Soriano, Jean-Philippe\n  Laurenceau, Rahmatollah Beheshti", "title": "Multi-modal Predictive Models of Diabetes Progression", "comments": null, "journal-ref": null, "doi": "10.1145/3307339.3342177", "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the increasing availability of wearable devices, continuous monitoring\nof individuals' physiological and behavioral patterns has become significantly\nmore accessible. Access to these continuous patterns about individuals'\nstatuses offers an unprecedented opportunity for studying complex diseases and\nhealth conditions such as type 2 diabetes (T2D). T2D is a widely common chronic\ndisease that its roots and progression patterns are not fully understood.\nPredicting the progression of T2D can inform timely and more effective\ninterventions to prevent or manage the disease. In this study, we have used a\ndataset related to 63 patients with T2D that includes the data from two\ndifferent types of wearable devices worn by the patients: continuous glucose\nmonitoring (CGM) devices and activity trackers (ActiGraphs). Using this\ndataset, we created a model for predicting the levels of four major biomarkers\nrelated to T2D after a one-year period. We developed a wide and deep neural\nnetwork and used the data from the demographic information, lab tests, and\nwearable sensors to create the model. The deep part of our method was developed\nbased on the long short-term memory (LSTM) structure to process the time-series\ndataset collected by the wearables. In predicting the patterns of the four\nbiomarkers, we have obtained a root mean square error of 1.67% for HBA1c, 6.22\nmg/dl for HDL cholesterol, 10.46 mg/dl for LDL cholesterol, and 18.38 mg/dl for\nTriglyceride. Compared to existing models for studying T2D, our model offers a\nmore comprehensive tool for combining a large variety of factors that\ncontribute to the disease.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jul 2019 02:19:05 GMT"}], "update_date": "2019-07-30", "authors_parsed": [["Ramazi", "Ramin", ""], ["Perndorfer", "Christine", ""], ["Soriano", "Emily", ""], ["Laurenceau", "Jean-Philippe", ""], ["Beheshti", "Rahmatollah", ""]]}, {"id": "1907.12179", "submitter": "Fatima Zahra Azayite", "authors": "Fatima Zahra Azayite, Said Achchab", "title": "A hybrid neural network model based on improved PSO and SA for\n  bankruptcy prediction", "comments": "13 pages", "journal-ref": "International Journal of Computer Science Issues, Vol 16, Issue 1,\n  January 2019", "doi": null, "report-no": null, "categories": "q-fin.RM cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predicting firm's failure is one of the most interesting subjects for\ninvestors and decision makers. In this paper, a bankruptcy prediction model is\nproposed based on Artificial Neural networks (ANN). Taking into consideration\nthat the choice of variables to discriminate between bankrupt and non-bankrupt\nfirms influences significantly the model's accuracy and considering the problem\nof local minima, we propose a hybrid ANN based on variables selection\ntechniques. Moreover, we evolve the convergence of Particle Swarm Optimization\n(PSO) by proposing a training algorithm based on an improved PSO and Simulated\nAnnealing. A comparative performance study is reported, and the proposed hybrid\nmodel shows a high performance and convergence in the context of missing data.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jul 2019 13:07:21 GMT"}], "update_date": "2019-07-30", "authors_parsed": [["Azayite", "Fatima Zahra", ""], ["Achchab", "Said", ""]]}, {"id": "1907.12189", "submitter": "Teodor Vanislavov Marinov", "authors": "Raman Arora, Teodor V. Marinov, Mehryar Mohri", "title": "Bandits with Feedback Graphs and Switching Costs", "comments": "Camera ready from NeurIPS 2019, new algorithm and improved results in\n  Section 3.2", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the adversarial multi-armed bandit problem where partial\nobservations are available and where, in addition to the loss incurred for each\naction, a \\emph{switching cost} is incurred for shifting to a new action. All\npreviously known results incur a factor proportional to the independence number\nof the feedback graph. We give a new algorithm whose regret guarantee depends\nonly on the domination number of the graph. We further supplement that result\nwith a lower bound. Finally, we also give a new algorithm with improved policy\nregret bounds when partial counterfactual feedback is available.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jul 2019 03:01:08 GMT"}, {"version": "v2", "created": "Sun, 22 Mar 2020 18:35:57 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Arora", "Raman", ""], ["Marinov", "Teodor V.", ""], ["Mohri", "Mehryar", ""]]}, {"id": "1907.12205", "submitter": "Shashank Rajput", "authors": "Shashank Rajput, Hongyi Wang, Zachary Charles and Dimitris\n  Papailiopoulos", "title": "DETOX: A Redundancy-based Framework for Faster and More Robust Gradient\n  Aggregation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To improve the resilience of distributed training to worst-case, or Byzantine\nnode failures, several recent approaches have replaced gradient averaging with\nrobust aggregation methods. Such techniques can have high computational costs,\noften quadratic in the number of compute nodes, and only have limited\nrobustness guarantees. Other methods have instead used redundancy to guarantee\nrobustness, but can only tolerate limited number of Byzantine failures. In this\nwork, we present DETOX, a Byzantine-resilient distributed training framework\nthat combines algorithmic redundancy with robust aggregation. DETOX operates in\ntwo steps, a filtering step that uses limited redundancy to significantly\nreduce the effect of Byzantine nodes, and a hierarchical aggregation step that\ncan be used in tandem with any state-of-the-art robust aggregation method. We\nshow theoretically that this leads to a substantial increase in robustness, and\nhas a per iteration runtime that can be nearly linear in the number of compute\nnodes. We provide extensive experiments over real distributed setups across a\nvariety of large-scale machine learning tasks, showing that DETOX leads to\norders of magnitude accuracy and speedup improvements over many\nstate-of-the-art Byzantine-resilient approaches.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jul 2019 04:02:35 GMT"}, {"version": "v2", "created": "Sun, 8 Mar 2020 03:02:12 GMT"}], "update_date": "2020-03-10", "authors_parsed": [["Rajput", "Shashank", ""], ["Wang", "Hongyi", ""], ["Charles", "Zachary", ""], ["Papailiopoulos", "Dimitris", ""]]}, {"id": "1907.12207", "submitter": "Ismael Lemhadri", "authors": "Ismael Lemhadri, Feng Ruan, Louis Abraham, Robert Tibshirani", "title": "LassoNet: A Neural Network with Feature Sparsity", "comments": "18 pages, 10 fg. arXiv admin note: text overlap with arXiv:1901.09346\n  by other authors", "journal-ref": "Journal of Machine Learning Research 22 (2021) 1-29", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Much work has been done recently to make neural networks more interpretable,\nand one obvious approach is to arrange for the network to use only a subset of\nthe available features. In linear models, Lasso (or $\\ell_1$-regularized)\nregression assigns zero weights to the most irrelevant or redundant features,\nand is widely used in data science. However the Lasso only applies to linear\nmodels. Here we introduce LassoNet, a neural network framework with global\nfeature selection. Our approach enforces a hierarchy: specifically a feature\ncan participate in a hidden unit only if its linear representative is active.\nUnlike other approaches to feature selection for neural nets, our method uses a\nmodified objective function with constraints, and so integrates feature\nselection with the parameter learning directly. As a result, it delivers an\nentire regularization path of solutions with a range of feature sparsity. On\nsystematic experiments, LassoNet significantly outperforms state-of-the-art\nmethods for feature selection and regression. The LassoNet method uses\nprojected proximal gradient descent, and generalizes directly to deep networks.\nIt can be implemented by adding just a few lines of code to a standard neural\nnetwork.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jul 2019 04:23:21 GMT"}, {"version": "v10", "created": "Wed, 16 Jun 2021 04:43:38 GMT"}, {"version": "v2", "created": "Fri, 9 Aug 2019 03:35:46 GMT"}, {"version": "v3", "created": "Thu, 5 Sep 2019 12:32:49 GMT"}, {"version": "v4", "created": "Wed, 30 Oct 2019 06:05:03 GMT"}, {"version": "v5", "created": "Sat, 8 Feb 2020 09:17:50 GMT"}, {"version": "v6", "created": "Fri, 12 Jun 2020 01:33:22 GMT"}, {"version": "v7", "created": "Mon, 16 Nov 2020 02:17:14 GMT"}, {"version": "v8", "created": "Thu, 21 Jan 2021 20:25:22 GMT"}, {"version": "v9", "created": "Tue, 23 Feb 2021 16:57:45 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Lemhadri", "Ismael", ""], ["Ruan", "Feng", ""], ["Abraham", "Louis", ""], ["Tibshirani", "Robert", ""]]}, {"id": "1907.12227", "submitter": "Kuang Xu", "authors": "Kuang Xu and Se-Young Yun", "title": "Reinforcement with Fading Memories", "comments": "Forthcoming in Mathematics of Operations Research; An extended\n  abstract appeared in the proceedings of ACM SIGMETRICS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the effect of imperfect memory on decision making in the context of\na stochastic sequential action-reward problem. An agent chooses a sequence of\nactions which generate discrete rewards at different rates. She is allowed to\nmake new choices at rate $\\beta$, while past rewards disappear from her memory\nat rate $\\mu$. We focus on a family of decision rules where the agent makes a\nnew choice by randomly selecting an action with a probability approximately\nproportional to the amount of past rewards associated with each action in her\nmemory.\n  We provide closed-form formulae for the agent's steady-state choice\ndistribution in the regime where the memory span is large ($\\mu \\to 0$), and\nshow that the agent's success critically depends on how quickly she updates her\nchoices relative to the speed of memory decay. If $\\beta \\gg \\mu$, the agent\nalmost always chooses the best action, i.e., the one with the highest reward\nrate. Conversely, if $\\beta \\ll \\mu$, the agent chooses an action with a\nprobability roughly proportional to its reward rate.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jul 2019 06:32:56 GMT"}, {"version": "v2", "created": "Wed, 18 Sep 2019 21:30:30 GMT"}], "update_date": "2019-09-20", "authors_parsed": [["Xu", "Kuang", ""], ["Yun", "Se-Young", ""]]}, {"id": "1907.12245", "submitter": "Kan Ming", "authors": "Chen He, Kan Ming, Yongwei Wang, and Z. Jane Wang", "title": "A Deep Learning Based Attack for The Chaos-based Image Encryption", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this letter, as a proof of concept, we propose a deep learning-based\napproach to attack the chaos-based image encryption algorithm in\n\\cite{guan2005chaos}. The proposed method first projects the chaos-based\nencrypted images into the low-dimensional feature space, where essential\ninformation of plain images has been largely preserved. With the\nlow-dimensional features, a deconvolutional generator is utilized to regenerate\nperceptually similar decrypted images to approximate the plain images in the\nhigh-dimensional space. Compared with conventional image encryption attack\nalgorithms, the proposed method does not require to manually analyze and infer\nkeys in a time-consuming way. Instead, we directly attack the chaos-based\nencryption algorithms in a key-independent manner. Moreover, the proposed\nmethod can be trained end-to-end. Given the chaos-based encrypted images, a\nwell-trained decryption model is able to automatically reconstruct plain images\nwith high fidelity. In the experiments, we successfully attack the chaos-based\nalgorithm \\cite{guan2005chaos} and the decrypted images are visually similar to\ntheir ground truth plain images. Experimental results on both static-key and\ndynamic-key scenarios verify the efficacy of the proposed method.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jul 2019 07:36:21 GMT"}], "update_date": "2019-07-30", "authors_parsed": [["He", "Chen", ""], ["Ming", "Kan", ""], ["Wang", "Yongwei", ""], ["Wang", "Z. Jane", ""]]}, {"id": "1907.12253", "submitter": "Chuhang Zou", "authors": "Chuhang Zou, Derek Hoiem", "title": "Silhouette Guided Point Cloud Reconstruction beyond Occlusion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One major challenge in 3D reconstruction is to infer the complete shape\ngeometry from partial foreground occlusions. In this paper, we propose a method\nto reconstruct the complete 3D shape of an object from a single RGB image, with\nrobustness to occlusion. Given the image and a silhouette of the visible\nregion, our approach completes the silhouette of the occluded region and then\ngenerates a point cloud. We show improvements for reconstruction of\nnon-occluded and partially occluded objects by providing the predicted complete\nsilhouette as guidance. We also improve state-of-the-art for 3D shape\nprediction with a 2D reprojection loss from multiple synthetic views and a\nsurface-based smoothing and refinement step. Experiments demonstrate the\nefficacy of our approach both quantitatively and qualitatively on synthetic and\nreal scene datasets.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jul 2019 08:00:08 GMT"}], "update_date": "2019-07-30", "authors_parsed": [["Zou", "Chuhang", ""], ["Hoiem", "Derek", ""]]}, {"id": "1907.12268", "submitter": "Jian Ma", "authors": "Jian Ma", "title": "Discovering Association with Copula Entropy", "comments": "Minor revision. The code is available at\n  https://github.com/majianthu/copent", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT q-bio.QM stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Discovering associations is of central importance in scientific practices.\nCurrently, most researches consider only linear association measured by\ncorrelation coefficient, which has its theoretical limitations. In this paper,\nwe propose a new method for discovering association with copula entropy -- a\nuniversal applicable association measure for not only linear cases, but\nnonlinear cases. The advantage of the method based on copula entropy over\ntraditional method is demonstrated on the NHANES data by discovering more\nbiomedical meaningful associations.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jul 2019 08:23:21 GMT"}, {"version": "v2", "created": "Tue, 14 Apr 2020 06:26:38 GMT"}], "update_date": "2020-04-15", "authors_parsed": [["Ma", "Jian", ""]]}, {"id": "1907.12279", "submitter": "Takuhiro Kaneko", "authors": "Takuhiro Kaneko, Hirokazu Kameoka, Kou Tanaka, Nobukatsu Hojo", "title": "StarGAN-VC2: Rethinking Conditional Methods for StarGAN-Based Voice\n  Conversion", "comments": "Accepted to Interspeech 2019. Project page:\n  http://www.kecl.ntt.co.jp/people/kaneko.takuhiro/projects/stargan-vc2/index.html", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Non-parallel multi-domain voice conversion (VC) is a technique for learning\nmappings among multiple domains without relying on parallel data. This is\nimportant but challenging owing to the requirement of learning multiple\nmappings and the non-availability of explicit supervision. Recently, StarGAN-VC\nhas garnered attention owing to its ability to solve this problem only using a\nsingle generator. However, there is still a gap between real and converted\nspeech. To bridge this gap, we rethink conditional methods of StarGAN-VC, which\nare key components for achieving non-parallel multi-domain VC in a single\nmodel, and propose an improved variant called StarGAN-VC2. Particularly, we\nrethink conditional methods in two aspects: training objectives and network\narchitectures. For the former, we propose a source-and-target conditional\nadversarial loss that allows all source domain data to be convertible to the\ntarget domain data. For the latter, we introduce a modulation-based conditional\nmethod that can transform the modulation of the acoustic feature in a\ndomain-specific manner. We evaluated our methods on non-parallel multi-speaker\nVC. An objective evaluation demonstrates that our proposed methods improve\nspeech quality in terms of both global and local structure measures.\nFurthermore, a subjective evaluation shows that StarGAN-VC2 outperforms\nStarGAN-VC in terms of naturalness and speaker similarity. The converted speech\nsamples are provided at\nhttp://www.kecl.ntt.co.jp/people/kaneko.takuhiro/projects/stargan-vc2/index.html.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jul 2019 08:51:52 GMT"}, {"version": "v2", "created": "Wed, 7 Aug 2019 10:21:30 GMT"}], "update_date": "2019-08-08", "authors_parsed": [["Kaneko", "Takuhiro", ""], ["Kameoka", "Hirokazu", ""], ["Tanaka", "Kou", ""], ["Hojo", "Nobukatsu", ""]]}, {"id": "1907.12293", "submitter": "Yajun Zhou", "authors": "Weinan E and Yajun Zhou", "title": "A mathematical model for universal semantics", "comments": "Main text (12 pages, 7 figures); Software Manual (ii+262 pages, 16\n  figures, 12 tables, available as two ancillary files). Revised according to\n  reviewers' comments", "journal-ref": null, "doi": "10.1109/TPAMI.2020.3022533", "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We characterize the meaning of words with language-independent numerical\nfingerprints, through a mathematical analysis of recurring patterns in texts.\nApproximating texts by Markov processes on a long-range time scale, we are able\nto extract topics, discover synonyms, and sketch semantic fields from a\nparticular document of moderate length, without consulting external\nknowledge-base or thesaurus. Our Markov semantic model allows us to represent\neach topical concept by a low-dimensional vector, interpretable as algebraic\ninvariants in succinct statistical operations on the document, targeting local\nenvironments of individual words. These language-independent semantic\nrepresentations enable a robot reader to both understand short texts in a given\nlanguage (automated question-answering) and match medium-length texts across\ndifferent languages (automated word translation). Our semantic fingerprints\nquantify local meaning of words in 14 representative languages across 5 major\nlanguage families, suggesting a universal and cost-effective mechanism by which\nhuman languages are processed at the semantic level. Our protocols and source\ncodes are publicly available on\nhttps://github.com/yajun-zhou/linguae-naturalis-principia-mathematica\n", "versions": [{"version": "v1", "created": "Mon, 29 Jul 2019 09:25:49 GMT"}, {"version": "v2", "created": "Wed, 31 Jul 2019 02:21:44 GMT"}, {"version": "v3", "created": "Thu, 10 Oct 2019 04:19:43 GMT"}, {"version": "v4", "created": "Sat, 23 Nov 2019 10:09:43 GMT"}, {"version": "v5", "created": "Thu, 16 Jan 2020 11:46:28 GMT"}, {"version": "v6", "created": "Sun, 15 Mar 2020 01:46:54 GMT"}, {"version": "v7", "created": "Sun, 12 Jul 2020 12:59:40 GMT"}], "update_date": "2020-09-10", "authors_parsed": [["E", "Weinan", ""], ["Zhou", "Yajun", ""]]}, {"id": "1907.12299", "submitter": "Victor Bouvier", "authors": "Victor Bouvier, Philippe Very, C\\'eline Hudelot, Cl\\'ement Chastagnol", "title": "Hidden Covariate Shift: A Minimal Assumption For Domain Adaptation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unsupervised Domain Adaptation aims to learn a model on a source domain with\nlabeled data in order to perform well on unlabeled data of a target domain.\nCurrent approaches focus on learning \\textit{Domain Invariant Representations}.\nIt relies on the assumption that such representations are well-suited for\nlearning the supervised task in the target domain. We rather believe that a\nbetter and minimal assumption for performing Domain Adaptation is the\n\\textit{Hidden Covariate Shift} hypothesis. Such approach consists in learning\na representation of the data such that the label distribution conditioned on\nthis representation is domain invariant. From the Hidden Covariate Shift\nassumption, we derive an optimization procedure which learns to match an\nestimated joint distribution on the target domain and a re-weighted joint\ndistribution on the source domain. The re-weighting is done in the\nrepresentation space and is learned during the optimization procedure. We show\non synthetic data and real world data that our approach deals with both\n\\textit{Target Shift} and \\textit{Concept Drift}. We report state-of-the-art\nperformances on Amazon Reviews dataset \\cite{blitzer2007biographies}\ndemonstrating the viability of this approach.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jul 2019 09:39:27 GMT"}], "update_date": "2019-07-30", "authors_parsed": [["Bouvier", "Victor", ""], ["Very", "Philippe", ""], ["Hudelot", "C\u00e9line", ""], ["Chastagnol", "Cl\u00e9ment", ""]]}, {"id": "1907.12305", "submitter": "Victor Bouvier", "authors": "Victor Bouvier, Philippe Very, C\\'eline Hudelot, Cl\\'ement Chastagnol", "title": "Learning Invariant Representations for Sentiment Analysis: The Missing\n  Material is Datasets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning representations which remain invariant to a nuisance factor has a\ngreat interest in Domain Adaptation, Transfer Learning, and Fair Machine\nLearning. Finding such representations becomes highly challenging in NLP tasks\nsince the nuisance factor is entangled in a raw text. To our knowledge, a major\nissue is also that only few NLP datasets allow assessing the impact of such\nfactor. In this paper, we introduce two generalization metrics to assess model\nrobustness to a nuisance factor: \\textit{generalization under target bias} and\n\\textit{generalization onto unknown}. We combine those metrics with a simple\ndata filtering approach to control the impact of the nuisance factor on the\ndata and thus to build experimental biased datasets. We apply our method to\nstandard datasets of the literature (\\textit{Amazon} and \\textit{Yelp}). Our\nwork shows that a simple text classification baseline (i.e., sentiment analysis\non reviews) may be badly affected by the \\textit{product ID} (considered as a\nnuisance factor) when learning the polarity of a review. The method proposed is\ngeneric and applicable as soon as the nuisance variable is annotated in the\ndataset.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jul 2019 09:44:49 GMT"}], "update_date": "2019-07-30", "authors_parsed": [["Bouvier", "Victor", ""], ["Very", "Philippe", ""], ["Hudelot", "C\u00e9line", ""], ["Chastagnol", "Cl\u00e9ment", ""]]}, {"id": "1907.12340", "submitter": "Zhi-Hua Zhou", "authors": "Peng Zhao and Guanghui Wang and Lijun Zhang and Zhi-Hua Zhou", "title": "Bandit Convex Optimization in Non-stationary Environments", "comments": null, "journal-ref": "AISTATS 2020", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bandit Convex Optimization (BCO) is a fundamental framework for modeling\nsequential decision-making with partial information, where the only feedback\navailable to the player is the one-point or two-point function values. In this\npaper, we investigate BCO in non-stationary environments and choose the\n\\emph{dynamic regret} as the performance measure, which is defined as the\ndifference between the cumulative loss incurred by the algorithm and that of\nany feasible comparator sequence. Let $T$ be the time horizon and $P_T$ be the\npath-length of the comparator sequence that reflects the non-stationarity of\nenvironments. We propose a novel algorithm that achieves\n$O(T^{3/4}(1+P_T)^{1/2})$ and $O(T^{1/2}(1+P_T)^{1/2})$ dynamic regret\nrespectively for the one-point and two-point feedback models. The latter result\nis optimal, matching the $\\Omega(T^{1/2}(1+P_T)^{1/2})$ lower bound established\nin this paper. Notably, our algorithm is more adaptive to non-stationary\nenvironments since it does not require prior knowledge of the path-length $P_T$\nahead of time, which is generally unknown.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jul 2019 11:33:28 GMT"}, {"version": "v2", "created": "Sun, 1 Mar 2020 16:24:37 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["Zhao", "Peng", ""], ["Wang", "Guanghui", ""], ["Zhang", "Lijun", ""], ["Zhou", "Zhi-Hua", ""]]}, {"id": "1907.12363", "submitter": "Eric Charton", "authors": "Louis Marceau and Lingling Qiu and Nick Vandewiele and Eric Charton", "title": "A comparison of Deep Learning performances with other machine learning\n  algorithms on credit scoring unbalanced data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training models on highly unbalanced data is admitted to be a challenging\ntask for machine learning algorithms. Current studies on deep learning mainly\nfocus on data sets with balanced class labels or unbalanced data, but with\nmassive amount of samples available, like in speech recognition. However, the\ncapacities of deep learning on imbalanced data with little samples is not\ndeeply investigated in literature, while it is a very common application\ncontext in numerous industries. To contribute to fill this gap, this paper\ncompares the performances of several popular machine learning algorithms\npreviously applied with success to unbalanced data set with deep learning\nalgorithms. We conduct those experiments on a highly unbalanced data set, used\nfor credit scoring. We evaluate various configuration including neural network\noptimization techniques and try to determine their capacities when they operate\nwith imbalanced corpora.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jul 2019 18:47:50 GMT"}, {"version": "v2", "created": "Tue, 25 Feb 2020 19:35:35 GMT"}], "update_date": "2020-02-27", "authors_parsed": [["Marceau", "Louis", ""], ["Qiu", "Lingling", ""], ["Vandewiele", "Nick", ""], ["Charton", "Eric", ""]]}, {"id": "1907.12365", "submitter": "Vikas Kumar", "authors": "Vikas Kumar", "title": "Collaborative Filtering and Multi-Label Classification with Matrix\n  Factorization", "comments": "Ph.D. Thesis", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning techniques for Recommendation System (RS) and Classification\nhas become a prime focus of research to tackle the problem of information\noverload. RS are software tools that aim at making informed decisions about the\nservices that a user may like. On the other hand, classification technique\ndeals with the categorization of a data object into one of the several\npredefined classes. In the multi-label classification problem, unlike the\ntraditional multi-class classification setting, each instance can be\nsimultaneously associated with a subset of labels. The focus of thesis is on\nthe development of novel techniques for collaborative filtering and multi-label\nclassification.\n  We propose a novel method of constructing a hierarchical bi-level maximum\nmargin matrix factorization to handle matrix completion of ordinal rating\nmatrix. Taking the cue from the alternative formulation of support vector\nmachines, a novel loss function is derived by considering proximity as an\nalternative criterion instead of margin maximization criterion for matrix\nfactorization framework.\n  We extended the concept of matrix factorization for yet another important\nproblem of machine learning namely multi-label classification which deals with\nthe classification of data with multiple labels. We propose a novel\npiecewise-linear embedding method with a low-rank constraint on parametrization\nto capture nonlinear intrinsic relationships that exist in the original feature\nand label space. We also study the embedding of labels together with the group\ninformation with an objective to build an efficient multi-label classifier. We\nassume the existence of a low-dimensional space onto which the feature vectors\nand label vectors can be embedded. We ensure that labels belonging to the same\ngroup share the same sparsity pattern in their low-rank representations.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jul 2019 11:39:39 GMT"}], "update_date": "2019-07-30", "authors_parsed": [["Kumar", "Vikas", ""]]}, {"id": "1907.12366", "submitter": "Lukas Galke", "authors": "Lukas Galke, Florian Mai, Iacopo Vagliano, Ansgar Scherp", "title": "Multi-Modal Adversarial Autoencoders for Recommendations of Citations\n  and Subject Labels", "comments": "Published in: UMAP '18 Proceedings of the 26th Conference on User\n  Modeling, Adaptation and Personalization Pages 197-205", "journal-ref": null, "doi": "10.1145/3209219.3209236", "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present multi-modal adversarial autoencoders for recommendation and\nevaluate them on two different tasks: citation recommendation and subject label\nrecommendation. We analyze the effects of adversarial regularization, sparsity,\nand different input modalities. By conducting 408 experiments, we show that\nadversarial regularization consistently improves the performance of\nautoencoders for recommendation. We demonstrate, however, that the two tasks\ndiffer in the semantics of item co-occurrence in the sense that item\nco-occurrence resembles relatedness in case of citations, yet implies diversity\nin case of subject labels. Our results reveal that supplying the partial item\nset as input is only helpful, when item co-occurrence resembles relatedness.\nWhen facing a new recommendation task it is therefore crucial to consider the\nsemantics of item co-occurrence for the choice of an appropriate model.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jul 2019 10:23:20 GMT"}], "update_date": "2019-07-30", "authors_parsed": [["Galke", "Lukas", ""], ["Mai", "Florian", ""], ["Vagliano", "Iacopo", ""], ["Scherp", "Ansgar", ""]]}, {"id": "1907.12368", "submitter": "Armaan Kaur", "authors": "Armaan Kaur, Jaspal Kaur Saini, Divya Bansal", "title": "Detecting Radical Text over Online Media using Deep Learning", "comments": "The Paper consists of 7 pages with 5 figures. The paper is accepted\n  in Intelligent Information Feed Workshop of 25th ACM SIGKDD Conference 2019\n  for oral presentation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Social Media has influenced the way people socially connect, interact and\nopinionize. The growth in technology has enhanced communication and\ndissemination of information. Unfortunately,many terror groups like jihadist\ncommunities have started consolidating a virtual community online for various\npurposes such as recruitment, online donations, targeting youth online and\nspread of extremist ideologies. Everyday a large number of articles, tweets,\nposts, posters, blogs, comments, views and news are posted online without a\ncheck which in turn imposes a threat to the security of any nation. However,\ndifferent agencies are working on getting down this radical content from\nvarious online social media platforms. The aim of our paper is to utilise deep\nlearning algorithm in detection of radicalization contrary to the existing\nworks based on machine learning algorithms. An LSTM based feed forward neural\nnetwork is employed to detect radical content. We collected total 61601 records\nfrom various online sources constituting news, articles and blogs. These\nrecords are annotated by domain experts into three categories: Radical(R),\nNon-Radical (NR) and Irrelevant(I) which are further applied to LSTM based\nnetwork to classify radical content. A precision of 85.9% has been achieved\nwith the proposed approach\n", "versions": [{"version": "v1", "created": "Mon, 22 Jul 2019 17:27:37 GMT"}, {"version": "v2", "created": "Tue, 30 Jul 2019 19:07:10 GMT"}], "update_date": "2019-08-01", "authors_parsed": [["Kaur", "Armaan", ""], ["Saini", "Jaspal Kaur", ""], ["Bansal", "Divya", ""]]}, {"id": "1907.12372", "submitter": "Murium Iqbal", "authors": "Murium Iqbal, Nishan Subedi, Kamelia Aryafar", "title": "Production Ranking Systems: A Review", "comments": "SIGIR eComm Accepted Paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of ranking is a multi-billion dollar problem. In this paper we\npresent an overview of several production quality ranking systems. We show that\ndue to conflicting goals of employing the most effective machine learning\nmodels and responding to users in real time, ranking systems have evolved into\na system of systems, where each subsystem can be viewed as a component layer.\nWe view these layers as being data processing, representation learning,\ncandidate selection and online inference. Each layer employs different\nalgorithms and tools, with every end-to-end ranking system spanning multiple\narchitectures. Our goal is to familiarize the general audience with a working\nknowledge of ranking at scale, the tools and algorithms employed and the\nchallenges introduced by adopting a layered approach.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jul 2019 19:30:28 GMT"}], "update_date": "2019-07-30", "authors_parsed": [["Iqbal", "Murium", ""], ["Subedi", "Nishan", ""], ["Aryafar", "Kamelia", ""]]}, {"id": "1907.12374", "submitter": "Feng Nan", "authors": "Feng Nan, Ran Ding, Ramesh Nallapati, Bing Xiang", "title": "Topic Modeling with Wasserstein Autoencoders", "comments": "In Proceedings of the 57th Annual Meeting of the Association for\n  Computational Linguistics (pp. 6345-6381)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel neural topic model in the Wasserstein autoencoders (WAE)\nframework. Unlike existing variational autoencoder based models, we directly\nenforce Dirichlet prior on the latent document-topic vectors. We exploit the\nstructure of the latent space and apply a suitable kernel in minimizing the\nMaximum Mean Discrepancy (MMD) to perform distribution matching. We discover\nthat MMD performs much better than the Generative Adversarial Network (GAN) in\nmatching high dimensional Dirichlet distribution. We further discover that\nincorporating randomness in the encoder output during training leads to\nsignificantly more coherent topics. To measure the diversity of the produced\ntopics, we propose a simple topic uniqueness metric. Together with the widely\nused coherence measure NPMI, we offer a more wholistic evaluation of topic\nquality. Experiments on several real datasets show that our model produces\nsignificantly better topics than existing topic models.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jul 2019 14:08:23 GMT"}, {"version": "v2", "created": "Fri, 6 Dec 2019 21:47:06 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["Nan", "Feng", ""], ["Ding", "Ran", ""], ["Nallapati", "Ramesh", ""], ["Xiang", "Bing", ""]]}, {"id": "1907.12378", "submitter": "Brett Vintch", "authors": "Tim Schmeier, Sam Garrett, Joseph Chisari, and Brett Vintch", "title": "Music Recommendations in Hyperbolic Space: An Application of Empirical\n  Bayes and Hierarchical Poincar\\'e Embeddings", "comments": null, "journal-ref": "Thirteenth ACM Conference on Recommender Systems (RecSys '19),\n  September 16--20, 2019, Copenhagen, Denmark", "doi": "10.1145/3298689.3347029", "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Matrix Factorization (MF) is a common method for generating recommendations,\nwhere the proximity of entities like users or items in the embedded space\nindicates their similarity to one another. Though almost all applications\nimplicitly use a Euclidean embedding space to represent two entity types,\nrecent work has suggested that a hyperbolic Poincar\\'e ball may be more well\nsuited to representing multiple entity types, and in particular, hierarchies.\nWe describe a novel method to embed a hierarchy of related music entities in\nhyperbolic space. We also describe how a parametric empirical Bayes approach\ncan be used to estimate link reliability between entities in the hierarchy.\nApplying these methods together to build personalized playlists for users in a\ndigital music service yielded a large and statistically significant increase in\nperformance during an A/B test, as compared to the Euclidean model.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jul 2019 15:53:40 GMT"}], "update_date": "2019-07-30", "authors_parsed": [["Schmeier", "Tim", ""], ["Garrett", "Sam", ""], ["Chisari", "Joseph", ""], ["Vintch", "Brett", ""]]}, {"id": "1907.12379", "submitter": "Mengshu Liu", "authors": "Mengshu Liu, Jingya Wang, Kareem Abdelfatah, Mohammed Korayem", "title": "Tripartite Vector Representations for Better Job Recommendation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Job recommendation is a crucial part of the online job recruitment business.\nTo match the right person with the right job, a good representation of job\npostings is required. Such representations should ideally recommend jobs with\nfitting titles, aligned skill set, and reasonable commute. To address these\naspects, we utilize three information graphs ( job-job, skill-skill, job-skill)\nfrom historical job data to learn a joint representation for both job titles\nand skills in a shared latent space. This allows us to gain a representation of\njob postings/ resume using both elements, which subsequently can be combined\nwith location. In this paper, we first present how the presentation of each\ncomponent is obtained, and then we discuss how these different representations\nare combined together into one single space to acquire the final\nrepresentation. The results of comparing the proposed methodology against\ndifferent base-line methods show significant improvement in terms of relevancy.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jul 2019 19:25:35 GMT"}], "update_date": "2019-07-30", "authors_parsed": [["Liu", "Mengshu", ""], ["Wang", "Jingya", ""], ["Abdelfatah", "Kareem", ""], ["Korayem", "Mohammed", ""]]}, {"id": "1907.12380", "submitter": "Agnieszka Maria S{\\l}owik", "authors": "Paula Ferm\\'in Cueto, Meeke Roet, Agnieszka S{\\l}owik", "title": "Completing partial recipes using item-based collaborative filtering to\n  recommend ingredients", "comments": "The authors contributed equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Increased public interest in healthy lifestyles has motivated the study of\nalgorithms that encourage people to follow a healthy diet. Applying\ncollaborative filtering to build recommendation systems in domains where only\nimplicit feedback is available is also a rapidly growing research area. In this\nreport we combine these two trends by developing a recommendation system to\nsuggest ingredients that can be added to a partial recipe. We implement the\nitem-based collaborative filtering algorithm using a high-dimensional, sparse\ndataset of recipes, which inherently contains only implicit feedback. We\nexplore the effect of different similarity measures and dimensionality\nreduction on the quality of the recommendations, and find that our best method\nachieves a recall@10 of circa 40%.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jul 2019 13:42:29 GMT"}, {"version": "v2", "created": "Tue, 4 Feb 2020 16:05:38 GMT"}], "update_date": "2020-02-05", "authors_parsed": [["Cueto", "Paula Ferm\u00edn", ""], ["Roet", "Meeke", ""], ["S\u0142owik", "Agnieszka", ""]]}, {"id": "1907.12384", "submitter": "Olivier Jeunen", "authors": "Olivier Jeunen, David Rohde, Flavian Vasile", "title": "On the Value of Bandit Feedback for Offline Recommender System\n  Evaluation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In academic literature, recommender systems are often evaluated on the task\nof next-item prediction. The procedure aims to give an answer to the question:\n\"Given the natural sequence of user-item interactions up to time t, can we\npredict which item the user will interact with at time t+1?\". Evaluation\nresults obtained through said methodology are then used as a proxy to predict\nwhich system will perform better in an online setting. The online setting,\nhowever, poses a subtly different question: \"Given the natural sequence of\nuser-item interactions up to time t, can we get the user to interact with a\nrecommended item at time t+1?\". From a causal perspective, the system performs\nan intervention, and we want to measure its effect. Next-item prediction is\noften used as a fall-back objective when information about interventions and\ntheir effects (shown recommendations and whether they received a click) is\nunavailable. When this type of data is available, however, it can provide great\nvalue for reliably estimating online recommender system performance. Through a\nseries of simulated experiments with the RecoGym environment, we show where\ntraditional offline evaluation schemes fall short. Additionally, we show how\nso-called bandit feedback can be exploited for effective offline evaluation\nthat more accurately reflects online performance.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jul 2019 12:50:50 GMT"}], "update_date": "2019-07-30", "authors_parsed": [["Jeunen", "Olivier", ""], ["Rohde", "David", ""], ["Vasile", "Flavian", ""]]}, {"id": "1907.12385", "submitter": "Ruizhe Li", "authors": "Xiao Li, Chenghua Lin, Ruizhe Li, Chaozheng Wang, Frank Guerin", "title": "Latent Space Factorisation and Manipulation via Matrix Subspace\n  Projection", "comments": "Final camera ready version for ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We tackle the problem disentangling the latent space of an autoencoder in\norder to separate labelled attribute information from other characteristic\ninformation. This then allows us to change selected attributes while preserving\nother information. Our method, matrix subspace projection, is much simpler than\nprevious approaches to latent space factorisation, for example not requiring\nmultiple discriminators or a careful weighting among their loss functions.\nFurthermore our new model can be applied to autoencoders as a plugin, and works\nacross diverse domains such as images or text. We demonstrate the utility of\nour method for attribute manipulation in autoencoders trained across varied\ndomains, using both human evaluation and automated methods. The quality of\ngeneration of our new model (e.g. reconstruction, conditional generation) is\nhighly competitive to a number of strong baselines.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jul 2019 06:37:18 GMT"}, {"version": "v2", "created": "Mon, 6 Jul 2020 13:09:24 GMT"}, {"version": "v3", "created": "Fri, 14 Aug 2020 22:33:16 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Li", "Xiao", ""], ["Lin", "Chenghua", ""], ["Li", "Ruizhe", ""], ["Wang", "Chaozheng", ""], ["Guerin", "Frank", ""]]}, {"id": "1907.12388", "submitter": "Murium Iqbal", "authors": "Murium Iqbal, Kamelia Aryafar, Timothy Anderton", "title": "Style Conditioned Recommendations", "comments": "9 pages, 10 figures, Accepted to RecSys '19", "journal-ref": null, "doi": "10.1145/3298689.3347007", "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose Style Conditioned Recommendations (SCR) and introduce style\ninjection as a method to diversify recommendations. We use Conditional\nVariational Autoencoder (CVAE) architecture, where both the encoder and decoder\nare conditioned on a user profile learned from item content data. This allows\nus to apply style transfer methodologies to the task of recommendations, which\nwe refer to as injection. To enable style injection, user profiles are learned\nto be interpretable such that they express users' propensities for specific\npredefined styles. These are learned via label-propagation from a dataset of\nitem content, with limited labeled points. To perform injection, the condition\non the encoder is learned while the condition on the decoder is selected per\nexplicit feedback. Explicit feedback can be taken either from a user's response\nto a style or interest quiz, or from item ratings. In the absence of explicit\nfeedback, the condition at the encoder is applied to the decoder. We show a 12%\nimprovement on NDCG@20 over the traditional VAE based approach and an average\n22% improvement on AUC across all classes for predicting user style profiles\nagainst our best performing baseline. After injecting styles we compare the\nuser style profile to the style of the recommendations and show that injected\nstyles have an average +133% increase in presence. Our results show that style\ninjection is a powerful method to diversify recommendations while maintaining\npersonal relevance. Our main contribution is an application of a\nsemi-supervised approach that extends item labels to interpretable user\nprofiles.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jul 2019 15:43:12 GMT"}, {"version": "v2", "created": "Mon, 5 Aug 2019 15:51:51 GMT"}], "update_date": "2019-08-06", "authors_parsed": [["Iqbal", "Murium", ""], ["Aryafar", "Kamelia", ""], ["Anderton", "Timothy", ""]]}, {"id": "1907.12392", "submitter": "Felix Leibfried", "authors": "Felix Leibfried and Sergio Pascual-Diaz and Jordi Grau-Moya", "title": "A Unified Bellman Optimality Principle Combining Reward Maximization and\n  Empowerment", "comments": "Proceedings of the 33rd Conference on Neural Information Processing\n  Systems (NeurIPS), Vancouver, Canada, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Empowerment is an information-theoretic method that can be used to\nintrinsically motivate learning agents. It attempts to maximize an agent's\ncontrol over the environment by encouraging visiting states with a large number\nof reachable next states. Empowered learning has been shown to lead to complex\nbehaviors, without requiring an explicit reward signal. In this paper, we\ninvestigate the use of empowerment in the presence of an extrinsic reward\nsignal. We hypothesize that empowerment can guide reinforcement learning (RL)\nagents to find good early behavioral solutions by encouraging highly empowered\nstates. We propose a unified Bellman optimality principle for empowered reward\nmaximization. Our empowered reward maximization approach generalizes both\nBellman's optimality principle as well as recent information-theoretical\nextensions to it. We prove uniqueness of the empowered values and show\nconvergence to the optimal solution. We then apply this idea to develop\noff-policy actor-critic RL algorithms which we validate in high-dimensional\ncontinuous robotics domains (MuJoCo). Our methods demonstrate improved initial\nand competitive final performance compared to model-free state-of-the-art\ntechniques.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jul 2019 16:34:21 GMT"}, {"version": "v2", "created": "Tue, 30 Jul 2019 12:13:31 GMT"}, {"version": "v3", "created": "Mon, 9 Sep 2019 14:24:58 GMT"}, {"version": "v4", "created": "Tue, 8 Oct 2019 15:25:58 GMT"}, {"version": "v5", "created": "Wed, 8 Jan 2020 11:08:57 GMT"}], "update_date": "2020-01-09", "authors_parsed": [["Leibfried", "Felix", ""], ["Pascual-Diaz", "Sergio", ""], ["Grau-Moya", "Jordi", ""]]}, {"id": "1907.12399", "submitter": "Tomoaki Niiyama", "authors": "Tomoaki Niiyama, Genki Furuhata, Atsushi Uchida, Makoto Naruse,\n  Satoshi Sunada", "title": "Lotka-Volterra competition mechanism embedded in a decision-making\n  method", "comments": "7 pages, 5 figures", "journal-ref": null, "doi": "10.7566/JPSJ.89.014801", "report-no": null, "categories": "physics.app-ph cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decision making is a fundamental capability of living organisms, and has\nrecently been gaining increasing importance in many engineering applications.\nHere, we consider a simple decision-making principle to identify an optimal\nchoice in multi-armed bandit (MAB) problems, which is fundamental in the\ncontext of reinforcement learning. We demonstrate that the identification\nmechanism of the method is well described by using a competitive ecosystem\nmodel, i.e., the competitive Lotka--Volterra (LV) model. Based on the\n\"winner-take-all\" mechanism in the competitive LV model, we demonstrate that\nnon-best choices are eliminated and only the best choice survives; the failure\nof the non-best choices exponentially decreases while repeating the choice\ntrials. Furthermore, we apply a mean-field approximation to the proposed\ndecision-making method and show that the method has an excellent scalability of\n$O(\\log N)$ with respect to the number of choices $N$. These results allow for\na new perspective on optimal search capabilities in competitive systems.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jul 2019 13:02:36 GMT"}, {"version": "v2", "created": "Thu, 26 Mar 2020 15:10:08 GMT"}], "update_date": "2020-03-27", "authors_parsed": [["Niiyama", "Tomoaki", ""], ["Furuhata", "Genki", ""], ["Uchida", "Atsushi", ""], ["Naruse", "Makoto", ""], ["Sunada", "Satoshi", ""]]}, {"id": "1907.12404", "submitter": "Michaela Regneri", "authors": "Michaela Regneri, Julia S. Georgi, Jurij Kost, Niklas Pietsch, and\n  Sabine Stamm", "title": "Computing the Value of Data: Towards Applied Data Minimalism", "comments": null, "journal-ref": "Second International Workshop on Energy Efficient Scalable Data\n  Mining and Machine Learning (Green Data Mining 2019)", "doi": null, "report-no": null, "categories": "cs.LG cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an approach to compute the monetary value of individual data\npoints, in context of an automated decision system. The proposed method enables\nus to explore and implement a paradigm of data minimalism for large-scale\nmachine learning systems. Data minimalistic implementations enhance\nscalability, while maintaining or even optimizing a system's performance. Using\ntwo types of recommender systems, we first demonstrate how much data is\nineffective in both settings. We then present a general account of computing\ndata value via sensitivity analysis, and how, in theory, individual data points\ncan be priced according to their informational contribution to automated\ndecisions. We further exemplify this method to lab-scale recommender systems\nand outline further steps towards commercial data-minimalistic applications.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jul 2019 13:08:22 GMT"}], "update_date": "2019-07-30", "authors_parsed": [["Regneri", "Michaela", ""], ["Georgi", "Julia S.", ""], ["Kost", "Jurij", ""], ["Pietsch", "Niklas", ""], ["Stamm", "Sabine", ""]]}, {"id": "1907.12410", "submitter": "Paul Patras", "authors": "Chaoyun Zhang, Marco Fiore, Iain Murray, Paul Patras", "title": "CloudLSTM: A Recurrent Neural Model for Spatiotemporal Point-cloud\n  Stream Forecasting", "comments": "17 pages, 15 figures, AAAI'21", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces CloudLSTM, a new branch of recurrent neural models\ntailored to forecasting over data streams generated by geospatial point-cloud\nsources. We design a Dynamic Point-cloud Convolution (DConv) operator as the\ncore component of CloudLSTMs, which performs convolution directly over\npoint-clouds and extracts local spatial features from sets of neighboring\npoints that surround different elements of the input. This operator maintains\nthe permutation invariance of sequence-to-sequence learning frameworks, while\nrepresenting neighboring correlations at each time step -- an important aspect\nin spatiotemporal predictive learning. The DConv operator resolves the\ngrid-structural data requirements of existing spatiotemporal forecasting models\nand can be easily plugged into traditional LSTM architectures with\nsequence-to-sequence learning and attention mechanisms. We apply our proposed\narchitecture to two representative, practical use cases that involve\npoint-cloud streams, i.e., mobile service traffic forecasting and air quality\nindicator forecasting. Our results, obtained with real-world datasets collected\nin diverse scenarios for each use case, show that CloudLSTM delivers accurate\nlong-term predictions, outperforming a variety of competitor neural network\nmodels.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jul 2019 13:20:52 GMT"}, {"version": "v2", "created": "Wed, 25 Sep 2019 13:42:28 GMT"}, {"version": "v3", "created": "Sun, 21 Feb 2021 22:13:18 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Zhang", "Chaoyun", ""], ["Fiore", "Marco", ""], ["Murray", "Iain", ""], ["Patras", "Paul", ""]]}, {"id": "1907.12415", "submitter": "Nantia Makrynioti", "authors": "Nantia Makrynioti, Ruy Ley-Wild, Vasilis Vassalos", "title": "sql4ml A declarative end-to-end workflow for machine learning", "comments": "14 pages, 9 figures, replaced code repository link", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.LG cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present sql4ml, a system for expressing supervised machine learning (ML)\nmodels in SQL and automatically training them in TensorFlow. The primary\nmotivation for this work stems from the observation that in many data science\ntasks there is a back-and-forth between a relational database that stores the\ndata and a machine learning framework. Data preprocessing and feature\nengineering typically happen in a database, whereas learning is usually\nexecuted in separate ML libraries. This fragmented workflow requires from the\nusers to juggle between different programming paradigms and software systems.\nWith sql4ml the user can express both feature engineering and ML algorithms in\nSQL, while the system translates this code to an appropriate representation for\ntraining inside a machine learning framework. We describe our translation\nmethod, present experimental results from applying it on three well-known ML\nalgorithms and discuss the usability benefits from concentrating the entire\nworkflow on the database side.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jul 2019 13:28:59 GMT"}, {"version": "v2", "created": "Fri, 2 Aug 2019 16:18:27 GMT"}], "update_date": "2019-08-05", "authors_parsed": [["Makrynioti", "Nantia", ""], ["Ley-Wild", "Ruy", ""], ["Vassalos", "Vasilis", ""]]}, {"id": "1907.12416", "submitter": "Wanli Shi", "authors": "Wanli Shi, Bin Gu, Xiang Li, Xiang Geng, Heng Huang", "title": "Quadruply Stochastic Gradients for Large Scale Nonlinear Semi-Supervised\n  AUC Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semi-supervised learning is pervasive in real-world applications, where only\na few labeled data are available and large amounts of instances remain\nunlabeled. Since AUC is an important model evaluation metric in classification,\ndirectly optimizing AUC in semi-supervised learning scenario has drawn much\nattention in the machine learning community. Recently, it has been shown that\none could find an unbiased solution for the semi-supervised AUC maximization\nproblem without knowing the class prior distribution. However, this method is\nhardly scalable for nonlinear classification problems with kernels. To address\nthis problem, in this paper, we propose a novel scalable quadruply stochastic\ngradient algorithm (QSG-S2AUC) for nonlinear semi-supervised AUC optimization.\nIn each iteration of the stochastic optimization process, our method randomly\nsamples a positive instance, a negative instance, an unlabeled instance and\ntheir random features to compute the gradient and then update the model by\nusing this quadruply stochastic gradient to approach the optimal solution. More\nimportantly, we prove that QSG-S2AUC can converge to the optimal solution in\nO(1/t), where t is the iteration number. Extensive experimental results on a\nvariety of benchmark datasets show that QSG-S2AUC is far more efficient than\nthe existing state-of-the-art algorithms for semi-supervised AUC maximization\nwhile retaining the similar generalization performance.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jul 2019 13:31:13 GMT"}], "update_date": "2019-07-30", "authors_parsed": [["Shi", "Wanli", ""], ["Gu", "Bin", ""], ["Li", "Xiang", ""], ["Geng", "Xiang", ""], ["Huang", "Heng", ""]]}, {"id": "1907.12436", "submitter": "Steven Frank", "authors": "Steven J. Frank and Andrea M. Frank", "title": "Salient Slices: Improved Neural Network Training and Performance with\n  Image Entropy", "comments": "Final version; article will be published in Neural Computation 32,\n  1222-1237 (June 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As a training and analysis strategy for convolutional neural networks (CNNs),\nwe slice images into tiled segments and use, for training and prediction,\nsegments that both satisfy a criterion of information diversity and contain\nsufficient content to support classification. In particular, we utilize image\nentropy as the diversity criterion. This ensures that each tile carries as much\ninformation diversity as the original image, and for many applications serves\nas an indicator of usefulness in classification. To make predictions, a\nprobability aggregation framework is applied to probabilities assigned by the\nCNN to the input image tiles. This technique facilitates the use of large,\nhigh-resolution images that would be impractical to analyze unmodified;\nprovides data augmentation for training, which is particularly valuable when\nimage availability is limited; and the ensemble nature of the input for\nprediction enhances its accuracy.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jul 2019 13:55:13 GMT"}, {"version": "v2", "created": "Tue, 29 Oct 2019 19:53:57 GMT"}, {"version": "v3", "created": "Sat, 28 Dec 2019 18:40:29 GMT"}, {"version": "v4", "created": "Mon, 4 May 2020 22:06:11 GMT"}], "update_date": "2020-05-06", "authors_parsed": [["Frank", "Steven J.", ""], ["Frank", "Andrea M.", ""]]}, {"id": "1907.12439", "submitter": "Hanbo Zhang", "authors": "Hanbo Zhang, Site Bai, Xuguang Lan, David Hsu, Nanning Zheng", "title": "Hindsight Trust Region Policy Optimization", "comments": "Accepted by IJCAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement Learning(RL) with sparse rewards is a major challenge. We\npropose \\emph{Hindsight Trust Region Policy Optimization}(HTRPO), a new RL\nalgorithm that extends the highly successful TRPO algorithm with\n\\emph{hindsight} to tackle the challenge of sparse rewards. Hindsight refers to\nthe algorithm's ability to learn from information across goals, including ones\nnot intended for the current task. HTRPO leverages two main ideas. It\nintroduces QKL, a quadratic approximation to the KL divergence constraint on\nthe trust region, leading to reduced variance in KL divergence estimation and\nimproved stability in policy update. It also presents Hindsight Goal\nFiltering(HGF) to select conductive hindsight goals. In experiments, we\nevaluate HTRPO in various sparse reward tasks, including simple benchmarks,\nimage-based Atari games, and simulated robot control. Ablation studies indicate\nthat QKL and HGF contribute greatly to learning stability and high performance.\nComparison results show that in all tasks, HTRPO consistently outperforms both\nTRPO and HPG, a state-of-the-art algorithm for RL with sparse rewards.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jul 2019 13:59:42 GMT"}, {"version": "v2", "created": "Tue, 24 Sep 2019 15:16:59 GMT"}, {"version": "v3", "created": "Tue, 11 Feb 2020 02:00:15 GMT"}, {"version": "v4", "created": "Wed, 12 May 2021 14:24:39 GMT"}, {"version": "v5", "created": "Mon, 17 May 2021 06:09:53 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Zhang", "Hanbo", ""], ["Bai", "Site", ""], ["Lan", "Xuguang", ""], ["Hsu", "David", ""], ["Zheng", "Nanning", ""]]}, {"id": "1907.12452", "submitter": "Kimberlin Van Wijnen", "authors": "Kimberlin M.H. van Wijnen, Florian Dubost, Pinar Yilmaz, M. Arfan\n  Ikram, Wiro J. Niessen, Hieab Adams, Meike W. Vernooij, Marleen de Bruijne", "title": "Automated Lesion Detection by Regressing Intensity-Based Distance with a\n  Neural Network", "comments": "MICCAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Localization of focal vascular lesions on brain MRI is an important component\nof research on the etiology of neurological disorders. However, manual\nannotation of lesions can be challenging, time-consuming and subject to\nobserver bias. Automated detection methods often need voxel-wise annotations\nfor training. We propose a novel approach for automated lesion detection that\ncan be trained on scans only annotated with a dot per lesion instead of a full\nsegmentation. From the dot annotations and their corresponding intensity images\nwe compute various distance maps (DMs), indicating the distance to a lesion\nbased on spatial distance, intensity distance, or both. We train a fully\nconvolutional neural network (FCN) to predict these DMs for unseen intensity\nimages. The local optima in the predicted DMs are expected to correspond to\nlesion locations. We show the potential of this approach to detect enlarged\nperivascular spaces in white matter on a large brain MRI dataset with an\nindependent test set of 1000 scans. Our method matches the intra-rater\nperformance of the expert rater that was computed on an independent set. We\ncompare the different types of distance maps, showing that incorporating\nintensity information in the distance maps used to train an FCN greatly\nimproves performance.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jul 2019 14:17:17 GMT"}], "update_date": "2019-07-30", "authors_parsed": [["van Wijnen", "Kimberlin M. H.", ""], ["Dubost", "Florian", ""], ["Yilmaz", "Pinar", ""], ["Ikram", "M. Arfan", ""], ["Niessen", "Wiro J.", ""], ["Adams", "Hieab", ""], ["Vernooij", "Meike W.", ""], ["de Bruijne", "Marleen", ""]]}, {"id": "1907.12475", "submitter": "Kai Yang", "authors": "Kai Yang, Yuanming Shi, Wei Yu, Zhi Ding", "title": "Energy-Efficient Processing and Robust Wireless Cooperative Transmission\n  for Edge Inference", "comments": "This paper has been accepted by IEEE Internet of Things Journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG eess.SP math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Edge machine learning can deliver low-latency and private artificial\nintelligent (AI) services for mobile devices by leveraging computation and\nstorage resources at the network edge. This paper presents an energy-efficient\nedge processing framework to execute deep learning inference tasks at the edge\ncomputing nodes whose wireless connections to mobile devices are prone to\nchannel uncertainties. Aimed at minimizing the sum of computation and\ntransmission power consumption with probabilistic quality-of-service (QoS)\nconstraints, we formulate a joint inference tasking and downlink beamforming\nproblem that is characterized by a group sparse objective function. We provide\na statistical learning based robust optimization approach to approximate the\nhighly intractable probabilistic-QoS constraints by nonconvex quadratic\nconstraints, which are further reformulated as matrix inequalities with a\nrank-one constraint via matrix lifting. We design a reweighted power\nminimization approach by iteratively reweighted $\\ell_1$ minimization with\ndifference-of-convex-functions (DC) regularization and updating weights, where\nthe reweighted approach is adopted for enhancing group sparsity whereas the DC\nregularization is designed for inducing rank-one solutions. Numerical results\ndemonstrate that the proposed approach outperforms other state-of-the-art\napproaches.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jul 2019 15:24:58 GMT"}, {"version": "v2", "created": "Mon, 2 Mar 2020 09:19:35 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Yang", "Kai", ""], ["Shi", "Yuanming", ""], ["Yu", "Wei", ""], ["Ding", "Zhi", ""]]}, {"id": "1907.12477", "submitter": "Robert Tjarko Lange", "authors": "Robert Tjarko Lange, Aldo Faisal", "title": "Semantic RL with Action Grammars: Data-Efficient Learning of\n  Hierarchical Task Abstractions", "comments": "11 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hierarchical Reinforcement Learning algorithms have successfully been applied\nto temporal credit assignment problems with sparse reward signals. However,\nstate-of-the-art algorithms require manual specification of sub-task\nstructures, a sample inefficient exploration phase or lack semantic\ninterpretability. Humans, on the other hand, efficiently detect hierarchical\nsub-structures induced by their surroundings. It has been argued that this\ninference process universally applies to language, logical reasoning as well as\nmotor control. Therefore, we propose a cognitive-inspired Reinforcement\nLearning architecture which uses grammar induction to identify sub-goal\npolicies. By treating an on-policy trajectory as a sentence sampled from the\npolicy-conditioned language of the environment, we identify hierarchical\nconstituents with the help of unsupervised grammatical inference. The resulting\nset of temporal abstractions is called action grammar (Pastra & Aloimonos,\n2012) and unifies symbolic and connectionist approaches to Reinforcement\nLearning. It can be used to facilitate efficient imitation, transfer and online\nlearning.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jul 2019 15:27:50 GMT"}, {"version": "v2", "created": "Mon, 23 Sep 2019 17:26:35 GMT"}], "update_date": "2019-09-24", "authors_parsed": [["Lange", "Robert Tjarko", ""], ["Faisal", "Aldo", ""]]}, {"id": "1907.12484", "submitter": "Julia Kreutzer", "authors": "Julia Kreutzer, Jasmijn Bastings, Stefan Riezler", "title": "Joey NMT: A Minimalist NMT Toolkit for Novices", "comments": null, "journal-ref": "EMNLP-IJCNLP 2019", "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present Joey NMT, a minimalist neural machine translation toolkit based on\nPyTorch that is specifically designed for novices. Joey NMT provides many\npopular NMT features in a small and simple code base, so that novices can\neasily and quickly learn to use it and adapt it to their needs. Despite its\nfocus on simplicity, Joey NMT supports classic architectures (RNNs,\ntransformers), fast beam search, weight tying, and more, and achieves\nperformance comparable to more complex toolkits on standard benchmarks. We\nevaluate the accessibility of our toolkit in a user study where novices with\ngeneral knowledge about Pytorch and NMT and experts work through a\nself-contained Joey NMT tutorial, showing that novices perform almost as well\nas experts in a subsequent code quiz. Joey NMT is available at\nhttps://github.com/joeynmt/joeynmt .\n", "versions": [{"version": "v1", "created": "Mon, 29 Jul 2019 15:35:13 GMT"}, {"version": "v2", "created": "Thu, 31 Oct 2019 14:49:02 GMT"}, {"version": "v3", "created": "Fri, 19 Jun 2020 03:51:37 GMT"}], "update_date": "2020-06-22", "authors_parsed": [["Kreutzer", "Julia", ""], ["Bastings", "Jasmijn", ""], ["Riezler", "Stefan", ""]]}, {"id": "1907.12489", "submitter": "Frederik Dennig", "authors": "Frederik L. Dennig, Tom Polk, Zudi Lin, Tobias Schreck, Hanspeter\n  Pfister, and Michael Behrisch", "title": "FDive: Learning Relevance Models using Pattern-based Similarity Measures", "comments": "12 pages, 7 figures, 2 tables, LaTeX; corrected typo; added DOI", "journal-ref": "2019 IEEE Conference on Visual Analytics Science and Technology\n  (VAST)", "doi": "10.1109/VAST47406.2019.8986940", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The detection of interesting patterns in large high-dimensional datasets is\ndifficult because of their dimensionality and pattern complexity. Therefore,\nanalysts require automated support for the extraction of relevant patterns. In\nthis paper, we present FDive, a visual active learning system that helps to\ncreate visually explorable relevance models, assisted by learning a\npattern-based similarity. We use a small set of user-provided labels to rank\nsimilarity measures, consisting of feature descriptor and distance function\ncombinations, by their ability to distinguish relevant from irrelevant data.\nBased on the best-ranked similarity measure, the system calculates an\ninteractive Self-Organizing Map-based relevance model, which classifies data\naccording to the cluster affiliation. It also automatically prompts further\nrelevance feedback to improve its accuracy. Uncertain areas, especially near\nthe decision boundaries, are highlighted and can be refined by the user. We\nevaluate our approach by comparison to state-of-the-art feature selection\ntechniques and demonstrate the usefulness of our approach by a case study\nclassifying electron microscopy images of brain cells. The results show that\nFDive enhances both the quality and understanding of relevance models and can\nthus lead to new insights for brain research.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jul 2019 15:37:43 GMT"}, {"version": "v2", "created": "Tue, 30 Jul 2019 09:10:47 GMT"}, {"version": "v3", "created": "Thu, 23 Apr 2020 15:09:51 GMT"}], "update_date": "2020-04-24", "authors_parsed": [["Dennig", "Frederik L.", ""], ["Polk", "Tom", ""], ["Lin", "Zudi", ""], ["Schreck", "Tobias", ""], ["Pfister", "Hanspeter", ""], ["Behrisch", "Michael", ""]]}, {"id": "1907.12508", "submitter": "Lu Wang", "authors": "Lu Wang and Dongxiao Zhu", "title": "Tackling Ordinal Regression Problem for Heterogeneous Data: Sparse and\n  Deep Multi-Task Learning Approaches", "comments": "21 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many real-world datasets are labeled with natural orders, i.e., ordinal\nlabels. Ordinal regression is a method to predict ordinal labels that finds a\nwide range of applications in data-rich domains, such as natural, health and\nsocial sciences. Most existing ordinal regression approaches work well for\nindependent and identically distributed (IID) instances via formulating a\nsingle ordinal regression task. However, for heterogeneous non-IID instances\nwith well-defined local geometric structures, e.g., subpopulation groups,\nmulti-task learning (MTL) provides a promising framework to encode task\n(subgroup) relatedness, bridge data from all tasks, and simultaneously learn\nmultiple related tasks in efforts to improve generalization performance. Even\nthough MTL methods have been extensively studied, there is barely existing work\ninvestigating MTL for heterogeneous data with ordinal labels. We tackle this\nimportant problem via sparse and deep multi-task approaches. Specifically, we\ndevelop a regularized multi-task ordinal regression (MTOR) model for smaller\ndatasets and a deep neural networks based MTOR model for large-scale datasets.\nWe evaluate the performance using three real-world healthcare datasets with\napplications to multi-stage disease progression diagnosis. Our experiments\nindicate that the proposed MTOR models markedly improve the prediction\nperformance comparing with single-task ordinal regression models.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jul 2019 16:20:00 GMT"}, {"version": "v2", "created": "Mon, 27 Apr 2020 03:37:11 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Wang", "Lu", ""], ["Zhu", "Dongxiao", ""]]}, {"id": "1907.12530", "submitter": "Thinh Thanh Doan", "authors": "Thinh T. Doan, Siva Theja Maguluri, Justin Romberg", "title": "Finite-Time Performance of Distributed Temporal Difference Learning with\n  Linear Function Approximation", "comments": "arXiv admin note: text overlap with arXiv:1902.07393", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the policy evaluation problem in multi-agent reinforcement learning,\nmodeled by a Markov decision process. In this problem, the agents operate in a\ncommon environment under a fixed control policy, working together to discover\nthe value (global discounted accumulative reward) associated with each\nenvironmental state. Over a series of time steps, the agents act, get rewarded,\nupdate their local estimate of the value function, then communicate with their\nneighbors. The local update at each agent can be interpreted as a distributed\nvariant of the popular temporal difference learning methods {\\sf TD}$\n(\\lambda)$.\n  Our main contribution is to provide a finite-analysis on the performance of\nthis distributed {\\sf TD}$(\\lambda)$ algorithm for both constant and\ntime-varying step sizes. The key idea in our analysis is to use the geometric\nmixing time $\\tau$ of the underlying Markov chain, that is, although the\n\"noise\" in our algorithm is Markovian, its dependence is very weak at samples\nspaced out at every $\\tau$. We provide an explicit upper bound on the\nconvergence rate of the proposed method as a function of the network topology,\nthe discount factor, the constant $\\lambda$, and the mixing time $\\tau$.\n  Our results also provide a mathematical explanation for observations that\nhave appeared previously in the literature about the choice of $\\lambda$. Our\nupper bound illustrates the trade-off between approximation accuracy and\nconvergence speed implicit in the choice of $\\lambda$. When $\\lambda=1$, the\nsolution will correspond to the best possible approximation of the value\nfunction, while choosing $\\lambda = 0$ leads to faster convergence when the\nnoise in the algorithm has large variance.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jul 2019 18:32:43 GMT"}, {"version": "v2", "created": "Thu, 9 Jan 2020 20:10:38 GMT"}], "update_date": "2020-01-13", "authors_parsed": [["Doan", "Thinh T.", ""], ["Maguluri", "Siva Theja", ""], ["Romberg", "Justin", ""]]}, {"id": "1907.12545", "submitter": "Dylan Cashman", "authors": "Dylan Cashman, Genevieve Patterson, Abigail Mosca, Nathan Watts,\n  Shannon Robinson, Remco Chang", "title": "RNNbow: Visualizing Learning via Backpropagation Gradients in Recurrent\n  Neural Networks", "comments": null, "journal-ref": "IEEE Computer Graphics and Applications ( Volume: 38 , Issue: 6 ,\n  Nov.-Dec. 1 2018 ) pg 39-50", "doi": "10.1109/MCG.2018.2878902", "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present RNNbow, an interactive tool for visualizing the gradient flow\nduring backpropagation training in recurrent neural networks. RNNbow is a web\napplication that displays the relative gradient contributions from Recurrent\nNeural Network (RNN) cells in a neighborhood of an element of a sequence. We\ndescribe the calculation of backpropagation through time (BPTT) that keeps\ntrack of itemized gradients, or gradient contributions from one element of a\nsequence to previous elements of a sequence. By visualizing the gradient, as\nopposed to activations, RNNbow offers insight into how the network is learning.\nWe use it to explore the learning of an RNN that is trained to generate code in\nthe C programming language. We show how it uncovers insights into the vanishing\ngradient as well as the evolution of training as the RNN works its way through\na corpus.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jul 2019 17:36:29 GMT"}], "update_date": "2019-07-30", "authors_parsed": [["Cashman", "Dylan", ""], ["Patterson", "Genevieve", ""], ["Mosca", "Abigail", ""], ["Watts", "Nathan", ""], ["Robinson", "Shannon", ""], ["Chang", "Remco", ""]]}, {"id": "1907.12596", "submitter": "Zhicheng Cui", "authors": "Zhicheng Cui, Bradley A Fritz, Christopher R King, Michael S Avidan,\n  Yixin Chen", "title": "A Factored Generalized Additive Model for Clinical Decision Support in\n  the Operating Room", "comments": "Accepted for publication in AMIA 2019 Annual Symposium", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Logistic regression (LR) is widely used in clinical prediction because it is\nsimple to deploy and easy to interpret. Nevertheless, being a linear model, LR\nhas limited expressive capability and often has unsatisfactory performance.\nGeneralized additive models (GAMs) extend the linear model with transformations\nof input features, though feature interaction is not allowed for all GAM\nvariants. In this paper, we propose a factored generalized additive model\n(F-GAM) to preserve the model interpretability for targeted features while\nallowing a rich model for interaction with features fixed within the\nindividual. We evaluate F-GAM on prediction of two targets, postoperative acute\nkidney injury and acute respiratory failure, from a single-center database. We\nfind superior model performance of F-GAM in terms of AUPRC and AUROC compared\nto several other GAM implementations, random forests, support vector machine,\nand a deep neural network. We find that the model interpretability is good with\nresults with high face validity.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jul 2019 18:39:50 GMT"}], "update_date": "2019-07-31", "authors_parsed": [["Cui", "Zhicheng", ""], ["Fritz", "Bradley A", ""], ["King", "Christopher R", ""], ["Avidan", "Michael S", ""], ["Chen", "Yixin", ""]]}, {"id": "1907.12608", "submitter": "Erhan Bilal", "authors": "Erhan Bilal", "title": "Deep Gradient Boosting -- Layer-wise Input Normalization of Neural\n  Networks", "comments": "Solving the pseudo-inverse with SVD and splitting this into two\n  separate papers. There are too many changes to just update this version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic gradient descent (SGD) has been the dominant optimization method\nfor training deep neural networks due to its many desirable properties. One of\nthe more remarkable and least understood quality of SGD is that it generalizes\nrelatively well on unseen data even when the neural network has millions of\nparameters. We hypothesize that in certain cases it is desirable to relax its\nintrinsic generalization properties and introduce an extension of SGD called\ndeep gradient boosting (DGB). The key idea of DGB is that back-propagated\ngradients inferred using the chain rule can be viewed as pseudo-residual\ntargets of a gradient boosting problem. Thus at each layer of a neural network\nthe weight update is calculated by solving the corresponding boosting problem\nusing a linear base learner. The resulting weight update formula can also be\nviewed as a normalization procedure of the data that arrives at each layer\nduring the forward pass. When implemented as a separate input normalization\nlayer (INN) the new architecture shows improved performance on image\nrecognition tasks when compared to the same architecture without normalization\nlayers. As opposed to batch normalization (BN), INN has no learnable parameters\nhowever it matches its performance on CIFAR10 and ImageNet classification\ntasks.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jul 2019 19:24:40 GMT"}, {"version": "v2", "created": "Thu, 24 Oct 2019 18:07:38 GMT"}, {"version": "v3", "created": "Thu, 2 Jul 2020 17:03:26 GMT"}], "update_date": "2020-07-03", "authors_parsed": [["Bilal", "Erhan", ""]]}, {"id": "1907.12616", "submitter": "Anastasios Dimas", "authors": "Anastasios Dimas, Dionysios S. Kalogerias, Athina P. Petropulu", "title": "Cooperative Beamforming with Predictive Relay Selection for Urban mmWave\n  Communications", "comments": null, "journal-ref": "10.1109/ACCESS.2019.2950274", "doi": null, "report-no": null, "categories": "eess.SP cs.IT cs.LG cs.NI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While millimeter wave (mmWave) communications promise high data rates, their\nsensitivity to blockage and severe signal attenuation presents challenges in\ntheir deployment in urban settings. To overcome these effects, we consider a\ndistributed cooperative beamforming system, which relies on static relays\ndeployed in clusters with similar channel characteristics, and where, at every\ntime instance, only one relay from each cluster is selected to participate in\nbeamforming to the destination. To meet the quality-of-service guarantees of\nthe network, a key prerequisite for beamforming is relay selection. However, as\nthe channels change with time, relay selection becomes a resource demanding\ntask. Indeed, estimation of channel state information for all candidate relays,\nessential for relay selection, is a process that takes up bandwidth, wastes\npower and introduces latency and interference in the network. We instead\npropose a unique, predictive scheme for resource efficient relay selection,\nwhich exploits the special propagation patterns of the mmWave medium, and can\nbe executed distributively across clusters, and in parallel to optimal\nbeamforming-based communication. The proposed predictive scheme efficiently\nexploits spatiotemporal channel correlations with current and past networkwide\nReceived Signal Strength (RSS), the latter being invariant to relay cluster\nsize, measured sequentially during the operation of the system. Our numerical\nresults confirm that our proposed relay selection strategy outperforms any\nrandomized selection policy that does not exploit channel correlations,\nwhereas, at the same time, it performs very close to an ideal scheme that uses\ncomplete, cluster size dependent RSS, and offers significant savings in terms\nof channel estimation overhead, providing substantially better network\nutilization, especially in dense topologies, typical in mmWave networks.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jul 2019 19:47:24 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Dimas", "Anastasios", ""], ["Kalogerias", "Dionysios S.", ""], ["Petropulu", "Athina P.", ""]]}, {"id": "1907.12629", "submitter": "Hai Phan", "authors": "Hai Phan and Dang Huynh and Yihui He and Marios Savvides and Zhiqiang\n  Shen", "title": "MoBiNet: A Mobile Binary Network for Image Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  MobileNet and Binary Neural Networks are two among the most widely used\ntechniques to construct deep learning models for performing a variety of tasks\non mobile and embedded platforms.In this paper, we present a simple yet\nefficient scheme to exploit MobileNet binarization at activation function and\nmodel weights. However, training a binary network from scratch with separable\ndepth-wise and point-wise convolutions in case of MobileNet is not trivial and\nprone to divergence. To tackle this training issue, we propose a novel neural\nnetwork architecture, namely MoBiNet - Mobile Binary Network in which skip\nconnections are manipulated to prevent information loss and vanishing gradient,\nthus facilitate the training process. More importantly, while existing binary\nneural networks often make use of cumbersome backbones such as Alex-Net,\nResNet, VGG-16 with float-type pre-trained weights initialization, our MoBiNet\nfocuses on binarizing the already-compressed neural networks like MobileNet\nwithout the need of a pre-trained model to start with. Therefore, our proposal\nresults in an effectively small model while keeping the accuracy comparable to\nexisting ones. Experiments on ImageNet dataset show the potential of the\nMoBiNet as it achieves 54.40% top-1 accuracy and dramatically reduces the\ncomputational cost with binary operators.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jul 2019 20:31:15 GMT"}, {"version": "v2", "created": "Wed, 31 Jul 2019 03:38:10 GMT"}], "update_date": "2019-08-01", "authors_parsed": [["Phan", "Hai", ""], ["Huynh", "Dang", ""], ["He", "Yihui", ""], ["Savvides", "Marios", ""], ["Shen", "Zhiqiang", ""]]}, {"id": "1907.12635", "submitter": "Anjul Tyagi", "authors": "Ayush Kumar, Anjul Tyagi, Michael Burch, Daniel Weiskopf, Klaus\n  Mueller", "title": "Task Classification Model for Visual Fixation, Exploration, and Search", "comments": "4 pages", "journal-ref": "In proceedings of the 11th ACM Symposium on Eye Tracking Research\n  and Applications, 2019", "doi": "10.1145/3314111.3323073", "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Yarbus' claim to decode the observer's task from eye movements has received\nmixed reactions. In this paper, we have supported the hypothesis that it is\npossible to decode the task. We conducted an exploratory analysis on the\ndataset by projecting features and data points into a scatter plot to visualize\nthe nuance properties for each task. Following this analysis, we eliminated\nhighly correlated features before training an SVM and Ada Boosting classifier\nto predict the tasks from this filtered eye movements data. We achieve an\naccuracy of 95.4% on this task classification problem and hence, support the\nhypothesis that task classification is possible from a user's eye movement\ndata.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jul 2019 20:50:37 GMT"}], "update_date": "2019-07-31", "authors_parsed": [["Kumar", "Ayush", ""], ["Tyagi", "Anjul", ""], ["Burch", "Michael", ""], ["Weiskopf", "Daniel", ""], ["Mueller", "Klaus", ""]]}, {"id": "1907.12647", "submitter": "Arpan Sainju", "authors": "Arpan Sainju and Zhe Jiang", "title": "Mapping road safety features from streetview imagery: A deep learning\n  approach", "comments": "17 pages, 16 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Each year, around 6 million car accidents occur in the U.S. on average. Road\nsafety features (e.g., concrete barriers, metal crash barriers, rumble strips)\nplay an important role in preventing or mitigating vehicle crashes. Accurate\nmaps of road safety features is an important component of safety management\nsystems for federal or state transportation agencies, helping traffic engineers\nidentify locations to invest on safety infrastructure. In current practice,\nmapping road safety features is largely done manually (e.g., observations on\nthe road or visual interpretation of streetview imagery), which is both\nexpensive and time consuming. In this paper, we propose a deep learning\napproach to automatically map road safety features from streetview imagery.\nUnlike existing Convolutional Neural Networks (CNNs) that classify each image\nindividually, we propose to further add Recurrent Neural Network (Long Short\nTerm Memory) to capture geographic context of images (spatial autocorrelation\neffect along linear road network paths). Evaluations on real world streetview\nimagery show that our proposed model outperforms several baseline methods.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jul 2019 20:38:33 GMT"}], "update_date": "2019-07-31", "authors_parsed": [["Sainju", "Arpan", ""], ["Jiang", "Zhe", ""]]}, {"id": "1907.12652", "submitter": "Christin Seifert", "authors": "Andrea Papenmeier and Gwenn Englebienne and Christin Seifert", "title": "How model accuracy and explanation fidelity influence user trust", "comments": "AI IJCAI Workshop on Explainable Artificial Intelligence (X-AI) 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning systems have become popular in fields such as marketing,\nfinancing, or data mining. While they are highly accurate, complex machine\nlearning systems pose challenges for engineers and users. Their inherent\ncomplexity makes it impossible to easily judge their fairness and the\ncorrectness of statistically learned relations between variables and classes.\nExplainable AI aims to solve this challenge by modelling explanations alongside\nwith the classifiers, potentially improving user trust and acceptance. However,\nusers should not be fooled by persuasive, yet untruthful explanations. We\ntherefore conduct a user study in which we investigate the effects of model\naccuracy and explanation fidelity, i.e. how truthfully the explanation\nrepresents the underlying model, on user trust. Our findings show that accuracy\nis more important for user trust than explainability. Adding an explanation for\na classification result can potentially harm trust, e.g. when adding\nnonsensical explanations. We also found that users cannot be tricked by\nhigh-fidelity explanations into having trust for a bad classifier. Furthermore,\nwe found a mismatch between observed (implicit) and self-reported (explicit)\ntrust.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jul 2019 09:22:16 GMT"}], "update_date": "2019-07-31", "authors_parsed": [["Papenmeier", "Andrea", ""], ["Englebienne", "Gwenn", ""], ["Seifert", "Christin", ""]]}, {"id": "1907.12659", "submitter": "Bin Wang", "authors": "Bin Wang, Bing Xue, Mengjie Zhang", "title": "Particle Swarm Optimisation for Evolving Deep Neural Networks for Image\n  Classification by Evolving and Stacking Transferable Blocks", "comments": "To appear in ieee wcci 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Convolutional Neural Networks (CNNs) have been widely used in image\nclassification tasks, but the process of designing CNN architectures is very\ncomplex, so Neural Architecture Search (NAS), automatically searching for\noptimal CNN architectures, has attracted more and more research interests.\nHowever, the computational cost of NAS is often too high to apply NAS on\nreal-life applications. In this paper, an efficient particle swarm optimisation\nmethod named EPSOCNN is proposed to evolve CNN architectures inspired by the\nidea of transfer learning. EPSOCNN successfully reduces the computation cost by\nminimising the search space to a single block and utilising a small subset of\nthe training set to evaluate CNNs during evolutionary process. Meanwhile,\nEPSOCNN also keeps very competitive classification accuracy by stacking the\nevolved block multiple times to fit the whole dataset. The proposed EPSOCNN\nalgorithm is evaluated on CIFAR-10 dataset and compared with 13 peer\ncompetitors comprised of deep CNNs crafted by hand, learned by reinforcement\nlearning methods and evolved by evolutionary computation approaches, which\nshows very promising results by outperforming all of the peer competitors with\nregard to the classification accuracy, number of parameters and the\ncomputational cost.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jul 2019 21:30:36 GMT"}, {"version": "v2", "created": "Sat, 21 Mar 2020 04:25:01 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Wang", "Bin", ""], ["Xue", "Bing", ""], ["Zhang", "Mengjie", ""]]}, {"id": "1907.12665", "submitter": "Pouya Rezazadeh Kalehbasti", "authors": "Pouya Rezazadeh Kalehbasti, Liubov Nikolenko, Hoormazd Rezaei", "title": "Airbnb Price Prediction Using Machine Learning and Sentiment Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pricing a rental property on Airbnb is a challenging task for the owner as it\ndetermines the number of customers for the place. On the other hand, customers\nhave to evaluate an offered price with minimal knowledge of an optimal value\nfor the property. This paper aims to develop a reliable price prediction model\nusing machine learning, deep learning, and natural language processing\ntechniques to aid both the property owners and the customers with price\nevaluation given minimal available information about the property. Features of\nthe rentals, owner characteristics, and the customer reviews will comprise the\npredictors, and a range of methods from linear regression to tree-based models,\nsupport-vector regression (SVR), K-means Clustering (KMC), and neural networks\n(NNs) will be used for creating the prediction model.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jul 2019 21:45:42 GMT"}], "update_date": "2019-07-31", "authors_parsed": [["Kalehbasti", "Pouya Rezazadeh", ""], ["Nikolenko", "Liubov", ""], ["Rezaei", "Hoormazd", ""]]}, {"id": "1907.12669", "submitter": "Muhammad Aurangzeb Ahmad", "authors": "Muhammad Aurangzeb Ahmad, Carly Eckert, Ankur Teredesai", "title": "The Challenge of Imputation in Explainable Artificial Intelligence\n  Models", "comments": "The IJCAI-19 Workshop on Artificial Intelligence Safety", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Explainable models in Artificial Intelligence are often employed to ensure\ntransparency and accountability of AI systems. The fidelity of the explanations\nare dependent upon the algorithms used as well as on the fidelity of the data.\nMany real world datasets have missing values that can greatly influence\nexplanation fidelity. The standard way to deal with such scenarios is\nimputation. This can, however, lead to situations where the imputed values may\ncorrespond to a setting which refer to counterfactuals. Acting on explanations\nfrom AI models with imputed values may lead to unsafe outcomes. In this paper,\nwe explore different settings where AI models with imputation can be\nproblematic and describe ways to address such scenarios.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jul 2019 22:06:21 GMT"}], "update_date": "2019-07-31", "authors_parsed": [["Ahmad", "Muhammad Aurangzeb", ""], ["Eckert", "Carly", ""], ["Teredesai", "Ankur", ""]]}, {"id": "1907.12690", "submitter": "Byunghyun Ban", "authors": "Byunghyun Ban, Soobin Kim", "title": "Control of nonlinear, complex and black-boxed greenhouse system with\n  reinforcement learning", "comments": "4 pages, 2 figures, 1 table. 2 pages of supplementary information.\n  Published on ICTC 2017", "journal-ref": "2017 International Conference on Information and Communication\n  Technology Convergence (ICTC)", "doi": "10.1109/ICTC.2017.8190813", "report-no": null, "categories": "cs.LG cs.AI cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern control theories such as systems engineering approaches try to solve\nnonlinear system problems by revelation of causal relationship or\nco-relationship among the components; most of those approaches focus on control\nof sophisticatedly modeled white-boxed systems. We suggest an application of\nactor-critic reinforcement learning approach to control a nonlinear, complex\nand black-boxed system. We demonstrated this approach on artificial green-house\nenvironment simulator all of whose control inputs have several side effects so\nhuman cannot figure out how to control this system easily. Our approach\nsucceeded to maintain the circumstance at least 20 times longer than PID and\nDeep Q Learning.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jul 2019 00:06:47 GMT"}], "update_date": "2021-01-07", "authors_parsed": [["Ban", "Byunghyun", ""], ["Kim", "Soobin", ""]]}, {"id": "1907.12697", "submitter": "Feng Wei", "authors": "Feng Wei, Uyen Trang Nguyen, Hui Jiang", "title": "Dual-FOFE-net Neural Models for Entity Linking with PageRank", "comments": "ICANN 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a simple and computationally efficient approach for\nentity linking (EL), compared with recurrent neural networks (RNNs) or\nconvolutional neural networks (CNNs), by making use of feedforward neural\nnetworks (FFNNs) and the recent dual fixed-size ordinally forgetting encoding\n(dual-FOFE) method to fully encode the sentence fragment and its left/right\ncontexts into a fixed-size representation. Furthermore, in this work, we\npropose to incorporate PageRank based distillation in our candidate generation\nmodule. Our neural linking models consist of three parts: a PageRank based\ncandidate generation module, a dual-FOFE-net neural ranking model and a simple\nNIL entity clustering system. Experimental results have shown that our proposed\nneural linking models achieved higher EL accuracy than state-of-the-art models\non the TAC2016 task dataset over the baseline system, without requiring any\nin-house data or complicated handcrafted features. Moreover, it achieves a\ncompetitive accuracy on the TAC2017 task dataset.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jul 2019 01:37:34 GMT"}], "update_date": "2019-07-31", "authors_parsed": [["Wei", "Feng", ""], ["Nguyen", "Uyen Trang", ""], ["Jiang", "Hui", ""]]}, {"id": "1907.12706", "submitter": "Dong Liu", "authors": "Chengjian Sun, Dong Liu, Chenyang Yang", "title": "Model-Free Unsupervised Learning for Optimization Problems with\n  Constraints", "comments": "Submitted to Asia-Pacific Conference on Communications (APCC)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many optimization problems in wireless communications, the expressions of\nobjective function or constraints are hard or even impossible to derive, which\nmakes the solutions difficult to find. In this paper, we propose a model-free\nlearning framework to solve constrained optimization problems without the\nsupervision of the optimal solution. Neural networks are used respectively for\nparameterizing the function to be optimized, parameterizing the Lagrange\nmultiplier associated with instantaneous constraints, and approximating the\nunknown objective function or constraints. We provide learning algorithms to\ntrain all the neural networks simultaneously, and reveal the connections of the\nproposed framework with reinforcement learning. Numerical and simulation\nresults validate the proposed framework and demonstrate the efficiency of\nmodel-free learning by taking power control problem as an example.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jul 2019 02:26:24 GMT"}], "update_date": "2019-07-31", "authors_parsed": [["Sun", "Chengjian", ""], ["Liu", "Dong", ""], ["Yang", "Chenyang", ""]]}, {"id": "1907.12720", "submitter": "Luke Oakden-Rayner", "authors": "Luke Oakden-Rayner", "title": "Exploring large scale public medical image datasets", "comments": "9 pages, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rationale and Objectives: Medical artificial intelligence systems are\ndependent on well characterised large scale datasets. Recently released public\ndatasets have been of great interest to the field, but pose specific challenges\ndue to the disconnect they cause between data generation and data usage,\npotentially limiting the utility of these datasets.\n  Materials and Methods: We visually explore two large public datasets, to\ndetermine how accurate the provided labels are and whether other subtle\nproblems exist. The ChestXray14 dataset contains 112,120 frontal chest films,\nand the MURA dataset contains 40,561 upper limb radiographs. A subset of around\n700 images from both datasets was reviewed by a board-certified radiologist,\nand the quality of the original labels was determined.\n  Results: The ChestXray14 labels did not accurately reflect the visual content\nof the images, with positive predictive values mostly between 10% and 30% lower\nthan the values presented in the original documentation. There were other\nsignificant problems, with examples of hidden stratification and label\ndisambiguation failure. The MURA labels were more accurate, but the original\nnormal/abnormal labels were inaccurate for the subset of cases with\ndegenerative joint disease, with a sensitivity of 60% and a specificity of 82%.\n  Conclusion: Visual inspection of images is a necessary component of\nunderstanding large image datasets. We recommend that teams producing public\ndatasets should perform this important quality control procedure and include a\nthorough description of their findings, along with an explanation of the data\ngenerating procedures and labelling rules, in the documentation for their\ndatasets.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jul 2019 03:09:27 GMT"}], "update_date": "2019-07-31", "authors_parsed": [["Oakden-Rayner", "Luke", ""]]}, {"id": "1907.12724", "submitter": "Matthew Hastings", "authors": "M. B. Hastings", "title": "Classical and Quantum Algorithms for Tensor Principal Component Analysis", "comments": "29 pages; v2 accepted in Quantum", "journal-ref": "Quantum 4, 237 (2020)", "doi": "10.22331/q-2020-02-27-237", "report-no": null, "categories": "quant-ph cs.DS cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present classical and quantum algorithms based on spectral methods for a\nproblem in tensor principal component analysis. The quantum algorithm achieves\na quartic speedup while using exponentially smaller space than the fastest\nclassical spectral algorithm, and a super-polynomial speedup over classical\nalgorithms that use only polynomial space. The classical algorithms that we\npresent are related to, but slightly different from those presented recently in\nRef. 1. In particular, we have an improved threshold for recovery and the\nalgorithms we present work for both even and odd order tensors. These results\nsuggest that large-scale inference problems are a promising future application\nfor quantum computers.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jul 2019 03:45:27 GMT"}, {"version": "v2", "created": "Mon, 24 Feb 2020 18:10:19 GMT"}], "update_date": "2020-03-04", "authors_parsed": [["Hastings", "M. B.", ""]]}, {"id": "1907.12727", "submitter": "Qingyu Zhao", "authors": "Qingyu Zhao, Ehsan Adeli, Adolf Pfefferbaum, Edith V. Sullivan, Kilian\n  M. Pohl", "title": "Confounder-Aware Visualization of ConvNets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With recent advances in deep learning, neuroimaging studies increasingly rely\non convolutional networks (ConvNets) to predict diagnosis based on MR images.\nTo gain a better understanding of how a disease impacts the brain, the studies\nvisualize the salience maps of the ConvNet highlighting voxels within the brain\nmajorly contributing to the prediction. However, these salience maps are\ngenerally confounded, i.e., some salient regions are more predictive of\nconfounding variables (such as age) than the diagnosis. To avoid such\nmisinterpretation, we propose in this paper an approach that aims to visualize\nconfounder-free saliency maps that only highlight voxels predictive of the\ndiagnosis. The approach incorporates univariate statistical tests to identify\nconfounding effects within the intermediate features learned by ConvNet. The\ninfluence from the subset of confounded features is then removed by a novel\npartial back-propagation procedure. We use this two-step approach to visualize\nconfounder-free saliency maps extracted from synthetic and two real datasets.\nThese experiments reveal the potential of our visualization in producing\nunbiased model-interpretation.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jul 2019 03:54:08 GMT"}, {"version": "v2", "created": "Sat, 26 Jun 2021 01:06:42 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Zhao", "Qingyu", ""], ["Adeli", "Ehsan", ""], ["Pfefferbaum", "Adolf", ""], ["Sullivan", "Edith V.", ""], ["Pohl", "Kilian M.", ""]]}, {"id": "1907.12736", "submitter": "Ho-Deok Jang", "authors": "Ho-Deok Jang, Sanghyun Woo, Philipp Benz, Jinsun Park, In So Kweon", "title": "Propose-and-Attend Single Shot Detector", "comments": "8 pages, 2 figures, 7 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a simple yet effective prediction module for a one-stage detector.\nThe main process is conducted in a coarse-to-fine manner. First, the module\nroughly adjusts the default boxes to well capture the extent of target objects\nin an image. Second, given the adjusted boxes, the module aligns the receptive\nfield of the convolution filters accordingly, not requiring any embedding\nlayers. Both steps build a propose-and-attend mechanism, mimicking two-stage\ndetectors in a highly efficient manner. To verify its effectiveness, we apply\nthe proposed module to a basic one-stage detector SSD. Our final model achieves\nan accuracy comparable to that of state-of-the-art detectors while using a\nfraction of their model parameters and computational overheads. Moreover, we\nfound that the proposed module has two strong applications. 1) The module can\nbe successfully integrated into a lightweight backbone, further pushing the\nefficiency of the one-stage detector. 2) The module also allows\ntrain-from-scratch without relying on any sophisticated base networks as\nprevious methods do.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jul 2019 04:56:25 GMT"}], "update_date": "2019-07-31", "authors_parsed": [["Jang", "Ho-Deok", ""], ["Woo", "Sanghyun", ""], ["Benz", "Philipp", ""], ["Park", "Jinsun", ""], ["Kweon", "In So", ""]]}, {"id": "1907.12740", "submitter": "Gioele Ciaparrone", "authors": "Gioele Ciaparrone, Francisco Luque S\\'anchez, Siham Tabik, Luigi\n  Troiano, Roberto Tagliaferri, Francisco Herrera", "title": "Deep Learning in Video Multi-Object Tracking: A Survey", "comments": "Accepted in Neurocomputing, 2019. New in v4: updated license in\n  compliance with Elsevier policy. Main text: 29 pages, 10 figures, 7 tables.\n  Summary table in appendix at the end of the paper", "journal-ref": null, "doi": "10.1016/j.neucom.2019.11.023", "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of Multiple Object Tracking (MOT) consists in following the\ntrajectory of different objects in a sequence, usually a video. In recent\nyears, with the rise of Deep Learning, the algorithms that provide a solution\nto this problem have benefited from the representational power of deep models.\nThis paper provides a comprehensive survey on works that employ Deep Learning\nmodels to solve the task of MOT on single-camera videos. Four main steps in MOT\nalgorithms are identified, and an in-depth review of how Deep Learning was\nemployed in each one of these stages is presented. A complete experimental\ncomparison of the presented works on the three MOTChallenge datasets is also\nprovided, identifying a number of similarities among the top-performing methods\nand presenting some possible future research directions.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jul 2019 11:51:26 GMT"}, {"version": "v2", "created": "Wed, 31 Jul 2019 02:11:24 GMT"}, {"version": "v3", "created": "Fri, 15 Nov 2019 11:49:43 GMT"}, {"version": "v4", "created": "Tue, 19 Nov 2019 11:26:20 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Ciaparrone", "Gioele", ""], ["S\u00e1nchez", "Francisco Luque", ""], ["Tabik", "Siham", ""], ["Troiano", "Luigi", ""], ["Tagliaferri", "Roberto", ""], ["Herrera", "Francisco", ""]]}, {"id": "1907.12743", "submitter": "Min-Hung Chen", "authors": "Min-Hung Chen, Zsolt Kira, Ghassan AlRegib, Jaekwon Yoo, Ruxin Chen,\n  Jian Zheng", "title": "Temporal Attentive Alignment for Large-Scale Video Domain Adaptation", "comments": "ICCV 2019 (Oral) camera-ready + supplementary. Code and data:\n  http://github.com/cmhungsteve/TA3N", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.MM eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although various image-based domain adaptation (DA) techniques have been\nproposed in recent years, domain shift in videos is still not well-explored.\nMost previous works only evaluate performance on small-scale datasets which are\nsaturated. Therefore, we first propose two large-scale video DA datasets with\nmuch larger domain discrepancy: UCF-HMDB_full and Kinetics-Gameplay. Second, we\ninvestigate different DA integration methods for videos, and show that\nsimultaneously aligning and learning temporal dynamics achieves effective\nalignment even without sophisticated DA methods. Finally, we propose Temporal\nAttentive Adversarial Adaptation Network (TA3N), which explicitly attends to\nthe temporal dynamics using domain discrepancy for more effective domain\nalignment, achieving state-of-the-art performance on four video DA datasets\n(e.g. 7.9% accuracy gain over \"Source only\" from 73.9% to 81.8% on \"HMDB -->\nUCF\", and 10.3% gain on \"Kinetics --> Gameplay\"). The code and data are\nreleased at http://github.com/cmhungsteve/TA3N.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jul 2019 05:43:55 GMT"}, {"version": "v2", "created": "Wed, 31 Jul 2019 16:06:39 GMT"}, {"version": "v3", "created": "Fri, 2 Aug 2019 05:17:51 GMT"}, {"version": "v4", "created": "Thu, 8 Aug 2019 05:50:11 GMT"}, {"version": "v5", "created": "Mon, 12 Aug 2019 15:28:47 GMT"}, {"version": "v6", "created": "Sun, 15 Sep 2019 00:48:41 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Chen", "Min-Hung", ""], ["Kira", "Zsolt", ""], ["AlRegib", "Ghassan", ""], ["Yoo", "Jaekwon", ""], ["Chen", "Ruxin", ""], ["Zheng", "Jian", ""]]}, {"id": "1907.12744", "submitter": "Utku Ozbulak", "authors": "Utku Ozbulak, Arnout Van Messem, Wesley De Neve", "title": "Not All Adversarial Examples Require a Complex Defense: Identifying\n  Over-optimized Adversarial Examples with IQR-based Logit Thresholding", "comments": "Accepted for the 2019 International Joint Conference on Neural\n  Networks (IJCNN-19)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Detecting adversarial examples currently stands as one of the biggest\nchallenges in the field of deep learning. Adversarial attacks, which produce\nadversarial examples, increase the prediction likelihood of a target class for\na particular data point. During this process, the adversarial example can be\nfurther optimized, even when it has already been wrongly classified with 100%\nconfidence, thus making the adversarial example even more difficult to detect.\nFor this kind of adversarial examples, which we refer to as over-optimized\nadversarial examples, we discovered that the logits of the model provide solid\nclues on whether the data point at hand is adversarial or genuine. In this\ncontext, we first discuss the masking effect of the softmax function for the\nprediction made and explain why the logits of the model are more useful in\ndetecting over-optimized adversarial examples. To identify this type of\nadversarial examples in practice, we propose a non-parametric and\ncomputationally efficient method which relies on interquartile range, with this\nmethod becoming more effective as the image resolution increases. We support\nour observations throughout the paper with detailed experiments for different\ndatasets (MNIST, CIFAR-10, and ImageNet) and several architectures.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jul 2019 05:46:49 GMT"}], "update_date": "2019-07-31", "authors_parsed": [["Ozbulak", "Utku", ""], ["Van Messem", "Arnout", ""], ["De Neve", "Wesley", ""]]}, {"id": "1907.12766", "submitter": "Min Zhang", "authors": "Min Zhang, Haoxuan You, Pranav Kadam, Shan Liu and C.-C. Jay Kuo", "title": "PointHop: An Explainable Machine Learning Method for Point Cloud\n  Classification", "comments": "13 pages with 9 figures", "journal-ref": null, "doi": "10.1109/TMM.2019.2963592", "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An explainable machine learning method for point cloud classification, called\nthe PointHop method, is proposed in this work. The PointHop method consists of\ntwo stages: 1) local-to-global attribute building through iterative one-hop\ninformation exchange, and 2) classification and ensembles. In the attribute\nbuilding stage, we address the problem of unordered point cloud data using a\nspace partitioning procedure and developing a robust descriptor that\ncharacterizes the relationship between a point and its one-hop neighbor in a\nPointHop unit. When we put multiple PointHop units in cascade, the attributes\nof a point will grow by taking its relationship with one-hop neighbor points\ninto account iteratively. Furthermore, to control the rapid dimension growth of\nthe attribute vector associated with a point, we use the Saab transform to\nreduce the attribute dimension in each PointHop unit. In the classification and\nensemble stage, we feed the feature vector obtained from multiple PointHop\nunits to a classifier. We explore ensemble methods to improve the\nclassification performance furthermore. It is shown by experimental results\nthat the PointHop method offers classification performance that is comparable\nwith state-of-the-art methods while demanding much lower training complexity.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jul 2019 07:39:40 GMT"}, {"version": "v2", "created": "Mon, 16 Dec 2019 01:37:28 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Zhang", "Min", ""], ["You", "Haoxuan", ""], ["Kadam", "Pranav", ""], ["Liu", "Shan", ""], ["Kuo", "C. -C. Jay", ""]]}, {"id": "1907.12778", "submitter": "Jingwen Wang", "authors": "Jingwen Wang, Jingxin Liu, Juntao Pu, Qinghong Yang, Zhongchen Miao,\n  Jian Gao, You Song", "title": "An anomaly prediction framework for financial IT systems using hybrid\n  machine learning methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In financial field, a robust software system is of vital importance to ensure\nthe smooth operation of financial transactions. However, many financial\ncorporations still depend on operators to identify and eliminate the system\nfailures when financial software systems break down. This traditional operation\nmethod is time consuming and extremely inefficient. To improve the efficiency\nand accuracy of system failure detection and thereby reduce the impact of\nsystem failures on financial services, we propose a novel machine\nlearning-based framework to predict the occurrence of system exceptions and\nfailures in a financial software system. In particular, we first extract rich\ninformation from system logs and eliminate noises in the data. Then the cleaned\ndata is leveraged as the input of our proposed anomaly prediction framework\nwhich consists of three modules: key performance indicator(KPI) data prediction\nmodule, anomaly identification module and severity classification module.\nNotably, we design a hierarchical architecture of alarm classifiers and try to\nalleviate the influence of class-imbalance problem on the overall performance.\nEmpirically, the experimental results demonstrate the superior performance of\nour proposed method on a real-world financial software system log data set.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jul 2019 08:36:37 GMT"}, {"version": "v2", "created": "Mon, 9 Dec 2019 14:53:57 GMT"}, {"version": "v3", "created": "Thu, 19 Dec 2019 17:10:01 GMT"}], "update_date": "2019-12-20", "authors_parsed": [["Wang", "Jingwen", ""], ["Liu", "Jingxin", ""], ["Pu", "Juntao", ""], ["Yang", "Qinghong", ""], ["Miao", "Zhongchen", ""], ["Gao", "Jian", ""], ["Song", "You", ""]]}, {"id": "1907.12796", "submitter": "Rafael Garcia-Dias", "authors": "Rafael Garcia-Dias, Carlos Allende Prieto, Jorge S\\'anchez Almeida,\n  Pedro Alonso Palicio", "title": "Machine learning in APOGEE: Identification of stellar populations\n  through chemical abundances", "comments": null, "journal-ref": "A&A 629, A34 (2019)", "doi": "10.1051/0004-6361/201935223", "report-no": null, "categories": "astro-ph.IM astro-ph.GA astro-ph.SR cs.LG", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  The vast volume of data generated by modern astronomical surveys offers test\nbeds for the application of machine-learning. It is important to evaluate\npotential existing tools and determine those that are optimal for extracting\nscientific knowledge from the available observations. We explore the\npossibility of using clustering algorithms to separate stellar populations with\ndistinct chemical patterns. Star clusters are likely the most chemically\nhomogeneous populations in the Galaxy, and therefore any practical approach to\nidentifying distinct stellar populations should at least be able to separate\nclusters from each other. We applied eight clustering algorithms combined with\nfour dimensionality reduction strategies to automatically distinguish stellar\nclusters using chemical abundances of 13 elements. Our sample includes 18\nstellar clusters with a total of 453 stars. We use statistical tests showing\nthat some pairs of clusters are indistinguishable from each other when chemical\nabundances from the Apache Point Galactic Evolution Experiment (APOGEE) are\nused. However, for most clusters we are able to automatically assign membership\nwith metric scores similar to previous works. The confusion level of the\nautomatically selected clusters is consistent with statistical tests that\ndemonstrate the impossibility of perfectly distinguishing all the clusters from\neach other. These statistical tests and confusion levels establish a limit for\nthe prospect of blindly identifying stars born in the same cluster based solely\non chemical abundances. We find that some of the algorithms we explored are\ncapable of blindly identify stellar populations with similar ages and chemical\ndistributions in the APOGEE data. Because some stellar clusters are chemically\nindistinguishable, our study supports the notion of extending weak chemical\ntagging that involves families of clusters instead of individual clusters\n", "versions": [{"version": "v1", "created": "Tue, 30 Jul 2019 09:21:53 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Garcia-Dias", "Rafael", ""], ["Prieto", "Carlos Allende", ""], ["Almeida", "Jorge S\u00e1nchez", ""], ["Palicio", "Pedro Alonso", ""]]}, {"id": "1907.12827", "submitter": "Junhua Li", "authors": "Tian Wang, Anastasios Bezerianos, Andrzej Cichocki, Junhua Li", "title": "Multi-Kernel Capsule Network for Schizophrenia Identification", "comments": "IEEE Transactions on Cybernetics (2020)", "journal-ref": null, "doi": "10.1109/TCYB.2020.3035282", "report-no": null, "categories": "cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Objective: Schizophrenia seriously affects the quality of life. To date, both\nsimple (linear discriminant analysis) and complex (deep neural network) machine\nlearning methods have been utilized to identify schizophrenia based on\nfunctional connectivity features. The existing simple methods need two separate\nsteps (i.e., feature extraction and classification) to achieve the\nidentification, which disables simultaneous tuning for the best feature\nextraction and classifier training. The complex methods integrate two steps and\ncan be simultaneously tuned to achieve optimal performance, but these methods\nrequire a much larger amount of data for model training. Methods: To overcome\nthe aforementioned drawbacks, we proposed a multi-kernel capsule network\n(MKCapsnet), which was developed by considering the brain anatomical structure.\nKernels were set to match with partition sizes of brain anatomical structure in\norder to capture interregional connectivities at the varying scales. With the\ninspiration of widely-used dropout strategy in deep learning, we developed\nvector dropout in the capsule layer to prevent overfitting of the model.\nResults: The comparison results showed that the proposed method outperformed\nthe state-of-the-art methods. Besides, we compared performances using different\nparameters and illustrated the routing process to reveal characteristics of the\nproposed method. Conclusion: MKCapsnet is promising for schizophrenia\nidentification. Significance: Our study not only proposed a multi-kernel\ncapsule network but also provided useful information in the parameter setting,\nwhich is informative for further studies using a capsule network for\nneurophysiological signal classification.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jul 2019 10:28:43 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Wang", "Tian", ""], ["Bezerianos", "Anastasios", ""], ["Cichocki", "Andrzej", ""], ["Li", "Junhua", ""]]}, {"id": "1907.12830", "submitter": "Daniel Lopez-Martinez", "authors": "Daniel Lopez-Martinez, Ke Peng, Arielle Lee, David Borsook, and\n  Rosalind Picard", "title": "Pain Detection with fNIRS-Measured Brain Signals: A Personalized Machine\n  Learning Approach Using the Wavelet Transform and Bayesian Hierarchical\n  Modeling with Dirichlet Process Priors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Currently self-report pain ratings are the gold standard in clinical pain\nassessment. However, the development of objective automatic measures of pain\ncould substantially aid pain diagnosis and therapy. Recent neuroimaging studies\nhave shown the potential of functional near-infrared spectroscopy (fNIRS) for\npain detection. This is a brain-imaging technique that provides non-invasive,\nlong-term measurements of cortical hemoglobin concentration changes. In this\nstudy, we focused on fNIRS signals acquired exclusively from the prefrontal\ncortex, which can be accessed unobtrusively, and derived an algorithm for the\ndetection of the presence of pain using Bayesian hierarchical modelling with\nwavelet features. This approach allows personalization of the inference process\nby accounting for inter-participant variability in pain responses. Our work\nhighlights the importance of adopting a personalized approach and supports the\nuse of fNIRS for pain assessment.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jul 2019 11:03:58 GMT"}], "update_date": "2019-07-31", "authors_parsed": [["Lopez-Martinez", "Daniel", ""], ["Peng", "Ke", ""], ["Lee", "Arielle", ""], ["Borsook", "David", ""], ["Picard", "Rosalind", ""]]}, {"id": "1907.12851", "submitter": "Waleed Yousef", "authors": "Waleed A. Yousef", "title": "AUC: Nonparametric Estimators and Their Smoothness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nonparametric estimation of a statistic, in general, and of the error rate of\na classification rule, in particular, from just one available dataset through\nresampling is well mathematically founded in the literature using several\nversions of bootstrap and influence function. This article first provides a\nconcise review of this literature to establish the theoretical framework that\nwe use to construct, in a single coherent framework, nonparametric estimators\nof the AUC (a two-sample statistic) other than the error rate (a one-sample\nstatistic). In addition, the smoothness of some of these estimators is well\ninvestigated and explained. Our experiments show that the behavior of the\ndesigned AUC estimators confirms the findings of the literature for the\nbehavior of error rate estimators in many aspects including: the weak\ncorrelation between the bootstrap-based estimators and the true conditional\nAUC; and the comparable accuracy of the different versions of the bootstrap\nestimators in terms of the RMS with little superiority of the .632+ bootstrap\nestimator.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jul 2019 12:03:18 GMT"}, {"version": "v2", "created": "Fri, 3 Apr 2020 04:11:18 GMT"}, {"version": "v3", "created": "Thu, 8 Apr 2021 04:26:30 GMT"}], "update_date": "2021-04-09", "authors_parsed": [["Yousef", "Waleed A.", ""]]}, {"id": "1907.12852", "submitter": "Waleed Yousef", "authors": "Waleed A. Yousef", "title": "Prudence When Assuming Normality: an advice for machine learning\n  practitioners", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a binary classification problem the feature vector (predictor) is the\ninput to a scoring function that produces a decision value (score), which is\ncompared to a particular chosen threshold to provide a final class prediction\n(output). Although the normal assumption of the scoring function is important\nin many applications, sometimes it is severely violated even under the simple\nmultinormal assumption of the feature vector. This article proves this result\nmathematically with a counter example to provide an advice for practitioners to\navoid blind assumptions of normality. On the other hand, the article provides a\nset of experiments that illustrate some of the expected and well-behaved\nresults of the Area Under the ROC curve (AUC) under the multinormal assumption\nof the feature vector. Therefore, the message of the article is not to avoid\nthe normal assumption of either the input feature vector or the output scoring\nfunction; however, a prudence is needed when adopting either of both.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jul 2019 12:04:01 GMT"}, {"version": "v2", "created": "Wed, 14 Aug 2019 12:26:05 GMT"}], "update_date": "2019-08-15", "authors_parsed": [["Yousef", "Waleed A.", ""]]}, {"id": "1907.12868", "submitter": "Lars Schmarje", "authors": "Lars Schmarje, Claudius Zelenka, Ulf Geisen, Claus-C. Gl\\\"uer,\n  Reinhard Koch", "title": "2D and 3D Segmentation of uncertain local collagen fiber orientations in\n  SHG microscopy", "comments": null, "journal-ref": "DAGM GCPR 2019", "doi": "10.1007/978-3-030-33676-9_26", "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Collagen fiber orientations in bones, visible with Second Harmonic Generation\n(SHG) microscopy, represent the inner structure and its alteration due to\ninfluences like cancer. While analyses of these orientations are valuable for\nmedical research, it is not feasible to analyze the needed large amounts of\nlocal orientations manually. Since we have uncertain borders for these local\norientations only rough regions can be segmented instead of a pixel-wise\nsegmentation. We analyze the effect of these uncertain borders on human\nperformance by a user study. Furthermore, we compare a variety of 2D and 3D\nmethods such as classical approaches like Fourier analysis with\nstate-of-the-art deep neural networks for the classification of local fiber\norientations. We present a general way to use pretrained 2D weights in 3D\nneural networks, such as Inception-ResNet-3D a 3D extension of\nInception-ResNet-v2. In a 10 fold cross-validation our two stage segmentation\nbased on Inception-ResNet-3D and transferred 2D ImageNet weights achieves a\nhuman comparable accuracy.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jul 2019 12:56:01 GMT"}], "update_date": "2020-06-29", "authors_parsed": [["Schmarje", "Lars", ""], ["Zelenka", "Claudius", ""], ["Geisen", "Ulf", ""], ["Gl\u00fcer", "Claus-C.", ""], ["Koch", "Reinhard", ""]]}, {"id": "1907.12887", "submitter": "Fabian B. Fuchs Mr", "authors": "Fabian B. Fuchs, Adam R. Kosiorek, Li Sun, Oiwi Parker Jones, Ingmar\n  Posner", "title": "End-to-end Recurrent Multi-Object Tracking and Trajectory Prediction\n  with Relational Reasoning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The majority of contemporary object-tracking approaches do not model\ninteractions between objects. This contrasts with the fact that objects' paths\nare not independent: a cyclist might abruptly deviate from a previously planned\ntrajectory in order to avoid colliding with a car. Building upon HART, a neural\nclass-agnostic single-object tracker, we introduce a multi-object tracking\nmethod MOHART capable of relational reasoning. Importantly, the entire system,\nincluding the understanding of interactions and relations between objects, is\nclass-agnostic and learned simultaneously in an end-to-end fashion. We explore\na number of relational reasoning architectures and show that\npermutation-invariant models outperform non-permutation-invariant alternatives.\nWe also find that architectures using a single permutation invariant operation\nlike DeepSets, despite, in theory, being universal function approximators, are\nnonetheless outperformed by a more complex architecture based on multi-headed\nattention. The latter better accounts for complex physical interactions in a\nchallenging toy experiment. Further, we find that modelling interactions leads\nto consistent performance gains in tracking as well as future trajectory\nprediction on three real-world datasets (MOTChallenge, UA-DETRAC, and Stanford\nDrone dataset), particularly in the presence of ego-motion, occlusions, crowded\nscenes, and faulty sensor inputs.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jul 2019 22:40:13 GMT"}, {"version": "v2", "created": "Fri, 9 Aug 2019 17:17:49 GMT"}, {"version": "v3", "created": "Mon, 30 Sep 2019 15:44:01 GMT"}, {"version": "v4", "created": "Thu, 30 Apr 2020 21:40:28 GMT"}, {"version": "v5", "created": "Mon, 28 Sep 2020 14:25:23 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Fuchs", "Fabian B.", ""], ["Kosiorek", "Adam R.", ""], ["Sun", "Li", ""], ["Jones", "Oiwi Parker", ""], ["Posner", "Ingmar", ""]]}, {"id": "1907.12888", "submitter": "Ts\\`i-U\\'i \\.Ik", "authors": "Tzu-Han Hsu, Ching-Hsuan Chen, Nyan Ping Ju, Ts\\`i-U\\'i \\.Ik, Wen-Chih\n  Peng, Chih-Chuan Wang, Yu-Shuen Wang, Yuan-Hsiang Lin, Yu-Chee Tseng,\n  Jiun-Long Huang, Yu-Tai Ching", "title": "CoachAI: A Project for Microscopic Badminton Match Data Collection and\n  Tactical Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computer vision based object tracking has been used to annotate and augment\nsports video. For sports learning and training, video replay is often used in\npost-match review and training review for tactical analysis and movement\nanalysis. For automatically and systematically competition data collection and\ntactical analysis, a project called CoachAI has been supported by the Ministry\nof Science and Technology, Taiwan. The proposed project also includes research\nof data visualization, connected training auxiliary devices, and data\nwarehouse. Deep learning techniques will be used to develop video-based\nreal-time microscopic competition data collection based on broadcast\ncompetition video. Machine learning techniques will be used to develop a\ntactical analysis. To reveal data in more understandable forms and to help in\npre-match training, AR/VR techniques will be used to visualize data, tactics,\nand so on. In addition, training auxiliary devices including smart badminton\nrackets and connected serving machines will be developed based on the IoT\ntechnology to further utilize competition data and tactical data and boost\ntraining efficiency. Especially, the connected serving machines will be\ndeveloped to perform specified tactics and to interact with players in their\ntraining.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jul 2019 08:33:00 GMT"}], "update_date": "2019-07-31", "authors_parsed": [["Hsu", "Tzu-Han", ""], ["Chen", "Ching-Hsuan", ""], ["Ju", "Nyan Ping", ""], ["\u0130k", "Ts\u00ec-U\u00ed", ""], ["Peng", "Wen-Chih", ""], ["Wang", "Chih-Chuan", ""], ["Wang", "Yu-Shuen", ""], ["Lin", "Yuan-Hsiang", ""], ["Tseng", "Yu-Chee", ""], ["Huang", "Jiun-Long", ""], ["Ching", "Yu-Tai", ""]]}, {"id": "1907.12892", "submitter": "Francis Brochu", "authors": "Francis Brochu", "title": "Increasing Shape Bias in ImageNet-Trained Networks Using Transfer\n  Learning and Domain-Adversarial Methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Convolutional Neural Networks (CNNs) have become the state-of-the-art method\nto learn from image data. However, recent research shows that they may include\na texture and colour bias in their representation, contrary to the intuition\nthat they learn the shapes of the image content and to human biological\nlearning. Thus, recent works have attempted to increase the shape bias in CNNs\nin order to train more robust and accurate networks on tasks. One such approach\nuses style-transfer in order to remove texture clues from the data. This work\nreproduces this methodology on four image classification datasets, as well as\nextends the method to use domain-adversarial training in order to further\nincrease the shape bias in the learned representation. The results show the\nproposed method increases the robustness and shape bias of the CNNs, while it\ndoes not provide a gain in accuracy.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jul 2019 13:30:46 GMT"}], "update_date": "2019-07-31", "authors_parsed": [["Brochu", "Francis", ""]]}, {"id": "1907.12894", "submitter": "Yang Gao", "authors": "Yang Gao, Christian M. Meyer, Mohsen Mesgar, Iryna Gurevych", "title": "Reward Learning for Efficient Reinforcement Learning in Extractive\n  Document Summarisation", "comments": "Accepted to IJCAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Document summarisation can be formulated as a sequential decision-making\nproblem, which can be solved by Reinforcement Learning (RL) algorithms. The\npredominant RL paradigm for summarisation learns a cross-input policy, which\nrequires considerable time, data and parameter tuning due to the huge search\nspaces and the delayed rewards. Learning input-specific RL policies is a more\nefficient alternative but so far depends on handcrafted rewards, which are\ndifficult to design and yield poor performance. We propose RELIS, a novel RL\nparadigm that learns a reward function with Learning-to-Rank (L2R) algorithms\nat training time and uses this reward function to train an input-specific RL\npolicy at test time. We prove that RELIS guarantees to generate near-optimal\nsummaries with appropriate L2R and RL algorithms. Empirically, we evaluate our\napproach on extractive multi-document summarisation. We show that RELIS reduces\nthe training time by two orders of magnitude compared to the state-of-the-art\nmodels while performing on par with them.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jul 2019 13:31:07 GMT"}], "update_date": "2019-07-31", "authors_parsed": [["Gao", "Yang", ""], ["Meyer", "Christian M.", ""], ["Mesgar", "Mohsen", ""], ["Gurevych", "Iryna", ""]]}, {"id": "1907.12898", "submitter": "Yang Hu", "authors": "Ling Jiang, Yang Hu, Xilin Xia, Qiuhua Liang, Andrea Soltoggio", "title": "A Multi-Scale Mapping Approach Based on a Deep Learning CNN Model for\n  Reconstructing High-Resolution Urban DEMs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The shortage of high-resolution urban digital elevation model (DEM) datasets\nhas been a challenge for modelling urban flood and managing its risk. A\nsolution is to develop effective approaches to reconstruct high-resolution DEMs\nfrom their low-resolution equivalents that are more widely available. However,\nthe current high-resolution DEM reconstruction approaches mainly focus on\nnatural topography. Few attempts have been made for urban topography which is\ntypically an integration of complex man-made and natural features. This study\nproposes a novel multi-scale mapping approach based on convolutional neural\nnetwork (CNN) to deal with the complex characteristics of urban topography and\nreconstruct high-resolution urban DEMs. The proposed multi-scale CNN model is\nfirstly trained using urban DEMs that contain topographic features at different\nresolutions, and then used to reconstruct the urban DEM at a specified (high)\nresolution from a low-resolution equivalent. A two-level accuracy assessment\napproach is also designed to evaluate the performance of the proposed urban DEM\nreconstruction method, in terms of numerical accuracy and morphological\naccuracy. The proposed DEM reconstruction approach is applied to a 121 km2\nurbanized area in London, UK. Compared with other commonly used methods, the\ncurrent CNN based approach produces superior results, providing a\ncost-effective innovative method to acquire high-resolution DEMs in other\ndata-scarce environments.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jul 2019 21:20:49 GMT"}, {"version": "v2", "created": "Tue, 8 Oct 2019 09:21:58 GMT"}], "update_date": "2019-10-09", "authors_parsed": [["Jiang", "Ling", ""], ["Hu", "Yang", ""], ["Xia", "Xilin", ""], ["Liang", "Qiuhua", ""], ["Soltoggio", "Andrea", ""]]}, {"id": "1907.12900", "submitter": "Yingwei Zhou", "authors": "Yingwei Zhou", "title": "Slot Based Image Augmentation System for Object Detection", "comments": "preprint draft", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Object Detection has been a significant topic in computer vision. As the\ncontinuous development of Deep Learning, many advanced academic and industrial\noutcomes are established on localising and classifying the target objects, such\nas instance segmentation, video tracking and robotic vision. As the core\nconcept of Deep Learning, Deep Neural Networks (DNNs) and associated training\nare highly integrated with task-driven modelling, having great effects on\naccurate detection. The main focus of improving detection performance is\nproposing DNNs with extra layers and novel topological connections to extract\nthe desired features from input data. However, training these models can be\ncomputationally expensive and laborious progress as the complicated model\narchitecture and enormous parameters. Besides, the dataset is another reason\ncausing this issue and low detection accuracy, because of insufficient data\nsamples or difficult instances. To address these training difficulties, this\nthesis presents two different approaches to improve the detection performance\nin the relatively light-weight way. As the intrinsic feature of data-driven in\ndeep learning, the first approach is \"slot-based image augmentation\" to enrich\nthe dataset with extra foreground and background combinations. Instead of the\ncommonly used image flipping method, the proposed system achieved similar mAP\nimprovement with less extra images which decrease training time. This proposed\naugmentation system has extra flexibility adapting to various scenarios and the\nperformance-driven analysis provides an alternative aspect of conducting image\naugmentation\n", "versions": [{"version": "v1", "created": "Fri, 19 Jul 2019 13:38:12 GMT"}], "update_date": "2019-07-31", "authors_parsed": [["Zhou", "Yingwei", ""]]}, {"id": "1907.12902", "submitter": "Matias Valdenegro-Toro", "authors": "Nour Soufi, Matias Valdenegro-Toro", "title": "Data augmentation with Symbolic-to-Real Image Translation GANs for\n  Traffic Sign Recognition", "comments": "6 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traffic sign recognition is an important component of many advanced driving\nassistance systems, and it is required for full autonomous driving.\nComputational performance is usually the bottleneck in using large scale neural\nnetworks for this purpose. SqueezeNet is a good candidate for efficient image\nclassification of traffic signs, but in our experiments it does not reach high\naccuracy, and we believe this is due to lack of data, requiring data\naugmentation. Generative adversarial networks can learn the high dimensional\ndistribution of empirical data, allowing the generation of new data points. In\nthis paper we apply pix2pix GANs architecture to generate new traffic sign\nimages and evaluate the use of these images in data augmentation. We were\nmotivated to use pix2pix to translate symbolic sign images to real ones due to\nthe mode collapse in Conditional GANs. Through our experiments we found that\ndata augmentation using GAN can increase classification accuracy for circular\ntraffic signs from 92.1% to 94.0%, and for triangular traffic signs from 93.8%\nto 95.3%, producing an overall improvement of 2%. However some traditional\naugmentation techniques can outperform GAN data augmentation, for example\ncontrast variation in circular traffic signs (95.5%) and displacement on\ntriangular traffic signs (96.7 %). Our negative results shows that while GANs\ncan be naively used for data augmentation, they are not always the best choice,\ndepending on the problem and variability in the data.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jul 2019 21:52:01 GMT"}], "update_date": "2019-07-31", "authors_parsed": [["Soufi", "Nour", ""], ["Valdenegro-Toro", "Matias", ""]]}, {"id": "1907.12906", "submitter": "Silvia Chiappa", "authors": "Silvia Chiappa and Ulrich Paquet", "title": "Unsupervised Separation of Dynamics from Pixels", "comments": null, "journal-ref": "METRON, Springer, 2019", "doi": "10.1007/s40300-019-00155-4", "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an approach to learn the dynamics of multiple objects from image\nsequences in an unsupervised way. We introduce a probabilistic model that first\ngenerate noisy positions for each object through a separate linear state-space\nmodel, and then renders the positions of all objects in the same image through\na highly non-linear process. Such a linear representation of the dynamics\nenables us to propose an inference method that uses exact and efficient\ninference tools and that can be deployed to query the model in different ways\nwithout retraining.\n", "versions": [{"version": "v1", "created": "Sat, 20 Jul 2019 10:22:14 GMT"}], "update_date": "2019-07-31", "authors_parsed": [["Chiappa", "Silvia", ""], ["Paquet", "Ulrich", ""]]}, {"id": "1907.12914", "submitter": "Farid Ghareh Mohammadi", "authors": "Farid Ghareh Mohammadi, Farzan Shenavarmasouleh, M. Hadi Amini, Hamid\n  R. Arabnia", "title": "Evolutionary Algorithms and Efficient Data Analytics for Image\n  Processing", "comments": "8 pages,5 figures,", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.MM cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Steganography algorithms facilitate communication between a source and a\ndestination in a secret manner. This is done by embedding messages/text/data\ninto images without impacting the appearance of the resultant images/videos.\nSteganalysis is the science of determining if an image has secret messages\nembedded/hidden in it. Because there are numerous steganography algorithms, and\nsince each one of them requires a different type of steganalysis, the\nsteganalysis process is extremely challenging. Thus, researchers aim to develop\none universal steganalysis to detect all known and unknown steganography\nalgorithms, ideally in real-time. Universal steganalysis extracts a large\nnumber of features to distinguish stego images from cover images. However, the\nincrease in features leads to the problem of the curse of dimensionality (CoD),\nwhich is considered to be an NP-hard problem. This COD problem additionally\nmakes real-time steganalysis hard. A large number of features generates large\ndatasets for which machine learning cannot generate an optimal model.\nGenerating a machine learning based model also takes a long time which makes\nreal-time processing appear impossible in any optimization for time-intensive\nfields such as visual computing. Possible solutions for CoD are deep learning\nand evolutionary algorithms that overcome the machine learning limitations. In\nthis study, we investigate previously developed evolutionary algorithms for\nboosting real-time image processing and argue that they provide the most\npromising solutions for the CoD problem.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jul 2019 16:13:53 GMT"}, {"version": "v2", "created": "Fri, 16 Oct 2020 05:14:06 GMT"}, {"version": "v3", "created": "Mon, 19 Oct 2020 16:10:16 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Mohammadi", "Farid Ghareh", ""], ["Shenavarmasouleh", "Farzan", ""], ["Amini", "M. Hadi", ""], ["Arabnia", "Hamid R.", ""]]}, {"id": "1907.12916", "submitter": "Subrata Mitra", "authors": "Subrata Mitra, Shanka Subhra Mondal, Nikhil Sheoran, Neeraj Dhake,\n  Ravinder Nehra, Ramanuja Simha", "title": "DeepPlace: Learning to Place Applications in Multi-Tenant Clusters", "comments": "APSys 2019", "journal-ref": null, "doi": "10.1145/3343737.3343741", "report-no": null, "categories": "cs.DC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large multi-tenant production clusters often have to handle a variety of jobs\nand applications with a variety of complex resource usage characteristics. It\nis non-trivial and non-optimal to manually create placement rules for\nscheduling that would decide which applications should co-locate. In this\npaper, we present DeepPlace, a scheduler that learns to exploits various\ntemporal resource usage patterns of applications using Deep Reinforcement\nLearning (Deep RL) to reduce resource competition across jobs running in the\nsame machine while at the same time optimizing for overall cluster utilization.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jul 2019 16:23:30 GMT"}], "update_date": "2019-07-31", "authors_parsed": [["Mitra", "Subrata", ""], ["Mondal", "Shanka Subhra", ""], ["Sheoran", "Nikhil", ""], ["Dhake", "Neeraj", ""], ["Nehra", "Ravinder", ""], ["Simha", "Ramanuja", ""]]}, {"id": "1907.12917", "submitter": "Dian Ang Yap", "authors": "Vinay Uday Prabhu, Dian Ang Yap, Alexander Wang, John Whaley", "title": "Covering up bias in CelebA-like datasets with Markov blankets: A\n  post-hoc cure for attribute prior avoidance", "comments": "Accepted for presentation at the first workshop on Invertible Neural\n  Networks and Normalizing Flows (ICML 2019), Long Beach, CA, USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Attribute prior avoidance entails subconscious or willful non-modeling of\n(meta)attributes that datasets are oft born with, such as the 40 semantic\nfacial attributes associated with the CelebA and CelebA-HQ datasets. The\nconsequences of this infirmity, we discover, are especially stark in\nstate-of-the-art deep generative models learned on these datasets that just\nmodel the pixel-space measurements, resulting in an inter-attribute bias-laden\nlatent space. This viscerally manifests itself when we perform face\nmanipulation experiments based on latent vector interpolations. In this paper,\nwe address this and propose a post-hoc solution that utilizes an Ising\nattribute prior learned in the attribute space and showcase its efficacy via\nqualitative experiments.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jul 2019 00:18:34 GMT"}], "update_date": "2019-07-31", "authors_parsed": [["Prabhu", "Vinay Uday", ""], ["Yap", "Dian Ang", ""], ["Wang", "Alexander", ""], ["Whaley", "John", ""]]}, {"id": "1907.12919", "submitter": "Jo\\~ao Antunes", "authors": "Jo\\~ao Antunes, Pedro Abreu, Alexandre Bernardino, Asim Smailagic,\n  Daniel Siewiorek", "title": "Attention Filtering for Multi-person Spatiotemporal Action Detection on\n  Deep Two-Stream CNN Architectures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Action detection and recognition tasks have been the target of much focus in\nthe computer vision community due to their many applications, namely, security,\nrobotics and recommendation systems. Recently, datasets like AVA, provide\nmulti-person, multi-label, spatiotemporal action detection and recognition\nchallenges. Being unable to discern which portions of the input to use for\nclassification is a limitation of two-stream CNN approaches, once the vision\ntask involves several people with several labels. We address this limitation\nand improve the state-of-the-art performance of two-stream CNNs. In this paper\nwe present four contributions: our fovea attention filtering that highlights\ntargets for classification without discarding background; a generalized binary\nloss function designed for the AVA dataset; miniAVA, a partition of AVA that\nmaintains temporal continuity and class distribution with only one tenth of the\ndataset size; and ablation studies on alternative attention filters. Our\nmethod, using fovea attention filtering and our generalized binary loss,\nachieves a relative video mAP improvement of 20% over the two-stream baseline\nin AVA, and is competitive with the state-of-the-art in the UCF101-24. We also\nshow a relative video mAP improvement of 12.6% when using our generalized\nbinary loss over the standard sum-of-sigmoids.\n", "versions": [{"version": "v1", "created": "Sun, 21 Jul 2019 16:53:43 GMT"}], "update_date": "2019-07-31", "authors_parsed": [["Antunes", "Jo\u00e3o", ""], ["Abreu", "Pedro", ""], ["Bernardino", "Alexandre", ""], ["Smailagic", "Asim", ""], ["Siewiorek", "Daniel", ""]]}, {"id": "1907.12920", "submitter": "Elie Aljalbout", "authors": "Axel Sauer, Elie Aljalbout, Sami Haddadin", "title": "Tracking Holistic Object Representations", "comments": "Accepted for oral presentation at BMVC 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in visual tracking are based on siamese feature extractors\nand template matching. For this category of trackers, latest research focuses\non better feature embeddings and similarity measures. In this work, we focus on\nbuilding holistic object representations for tracking. We propose a framework\nthat is designed to be used on top of previous trackers without any need for\nfurther training of the siamese network. The framework leverages the idea of\nobtaining additional object templates during the tracking process. Since the\nnumber of stored templates is limited, our method only keeps the most diverse\nones. We achieve this by providing a new diversity measure in the space of\nsiamese features. The obtained representation contains information beyond the\nground truth object location provided to the system. It is then useful for\ntracking itself but also for further tasks which require a visual understanding\nof objects. Strong empirical results on tracking benchmarks indicate that our\nmethod can improve the performance and robustness of the underlying trackers\nwhile barely reducing their speed. In addition, our method is able to match\ncurrent state-of-the-art results, while using a simpler and older network\narchitecture and running three times faster.\n", "versions": [{"version": "v1", "created": "Sun, 21 Jul 2019 10:51:21 GMT"}, {"version": "v2", "created": "Tue, 6 Aug 2019 09:27:19 GMT"}], "update_date": "2019-08-07", "authors_parsed": [["Sauer", "Axel", ""], ["Aljalbout", "Elie", ""], ["Haddadin", "Sami", ""]]}, {"id": "1907.12925", "submitter": "Hwijae Son", "authors": "Hyeontae Jo, Hwijae Son, Hyung Ju Hwang, Eunheui Kim", "title": "Deep Neural Network Approach to Forward-Inverse Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.LG cs.NA math.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we construct approximated solutions of Differential Equations\n(DEs) using the Deep Neural Network (DNN). Furthermore, we present an\narchitecture that includes the process of finding model parameters through\nexperimental data, the inverse problem. That is, we provide a unified framework\nof DNN architecture that approximates an analytic solution and its model\nparameters simultaneously. The architecture consists of a feed forward DNN with\nnon-linear activation functions depending on DEs, automatic differentiation,\nreduction of order, and gradient based optimization method. We also prove\ntheoretically that the proposed DNN solution converges to an analytic solution\nin a suitable function space for fundamental DEs. Finally, we perform numerical\nexperiments to validate the robustness of our simplistic DNN architecture for\n1D transport equation, 2D heat equation, 2D wave equation, and the\nLotka-Volterra system.\n", "versions": [{"version": "v1", "created": "Sat, 27 Jul 2019 04:52:14 GMT"}], "update_date": "2019-07-31", "authors_parsed": [["Jo", "Hyeontae", ""], ["Son", "Hwijae", ""], ["Hwang", "Hyung Ju", ""], ["Kim", "Eunheui", ""]]}, {"id": "1907.12926", "submitter": "Jayaraman J. Thiagarajan", "authors": "Jayaraman J. Thiagarajan, Satyananda Kashyap and Alexandros Karagyris", "title": "Distill-to-Label: Weakly Supervised Instance Labeling Using Knowledge\n  Distillation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Weakly supervised instance labeling using only image-level labels, in lieu of\nexpensive fine-grained pixel annotations, is crucial in several applications\nincluding medical image analysis. In contrast to conventional instance\nsegmentation scenarios in computer vision, the problems that we consider are\ncharacterized by a small number of training images and non-local patterns that\nlead to the diagnosis. In this paper, we explore the use of multiple instance\nlearning (MIL) to design an instance label generator under this weakly\nsupervised setting. Motivated by the observation that an MIL model can handle\nbags of varying sizes, we propose to repurpose an MIL model originally trained\nfor bag-level classification to produce reliable predictions for single\ninstances, i.e., bags of size $1$. To this end, we introduce a novel\nregularization strategy based on virtual adversarial training for improving MIL\ntraining, and subsequently develop a knowledge distillation technique for\nrepurposing the trained MIL model. Using empirical studies on colon cancer and\nbreast cancer detection from histopathological images, we show that the\nproposed approach produces high-quality instance-level prediction and\nsignificantly outperforms state-of-the MIL methods.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jul 2019 04:39:17 GMT"}], "update_date": "2019-07-31", "authors_parsed": [["Thiagarajan", "Jayaraman J.", ""], ["Kashyap", "Satyananda", ""], ["Karagyris", "Alexandros", ""]]}, {"id": "1907.12929", "submitter": "Lex Fridman", "authors": "Li Ding, Lex Fridman", "title": "Object as Distribution", "comments": "NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Object detection is a critical part of visual scene understanding. The\nrepresentation of the object in the detection task has important implications\non the efficiency and feasibility of annotation, robustness to occlusion, pose,\nlighting, and other visual sources of semantic uncertainty, and effectiveness\nin real-world applications (e.g., autonomous driving). Popular object\nrepresentations include 2D and 3D bounding boxes, polygons, splines, pixels,\nand voxels. Each have their strengths and weakness. In this work, we propose a\nnew representation of objects based on the bivariate normal distribution. This\ndistribution-based representation has the benefit of robust detection of\nhighly-overlapping objects and the potential for improved downstream tracking\nand instance segmentation tasks due to the statistical representation of object\nedges. We provide qualitative evaluation of this representation for the object\ndetection task and quantitative evaluation of its use in a baseline algorithm\nfor the instance segmentation task.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jul 2019 23:10:21 GMT"}], "update_date": "2019-07-31", "authors_parsed": [["Ding", "Li", ""], ["Fridman", "Lex", ""]]}, {"id": "1907.12933", "submitter": "Lucas Carvalho Cordeiro", "authors": "Luiz H. Sena, Iury V. Bessa, Mikhail R. Gadelha, Lucas C. Cordeiro,\n  and Edjard Mota", "title": "Incremental Bounded Model Checking of Artificial Neural Networks in CUDA", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial Neural networks (ANNs) are powerful computing systems employed for\nvarious applications due to their versatility to generalize and to respond to\nunexpected inputs/patterns. However, implementations of ANNs for\nsafety-critical systems might lead to failures, which are hardly predicted in\nthe design phase since ANNs are highly parallel and their parameters are hardly\ninterpretable. Here we develop and evaluate a novel symbolic software\nverification framework based on incremental bounded model checking (BMC) to\ncheck for adversarial cases and coverage methods in multi-layer perceptron\n(MLP). In particular, we further develop the efficient SMT-based\nContext-Bounded Model Checker for Graphical Processing Units (ESBMC-GPU) in\norder to ensure the reliability of certain safety properties in which\nsafety-critical systems can fail and make incorrect decisions, thereby leading\nto unwanted material damage or even put lives in danger. This paper marks the\nfirst symbolic verification framework to reason over ANNs implemented in CUDA.\nOur experimental results show that our approach implemented in ESBMC-GPU can\nsuccessfully verify safety properties and covering methods in ANNs and\ncorrectly generate 28 adversarial cases in MLPs.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jul 2019 13:50:34 GMT"}], "update_date": "2019-07-31", "authors_parsed": [["Sena", "Luiz H.", ""], ["Bessa", "Iury V.", ""], ["Gadelha", "Mikhail R.", ""], ["Cordeiro", "Lucas C.", ""], ["Mota", "Edjard", ""]]}, {"id": "1907.12934", "submitter": "Soufiane Belharbi", "authors": "Soufiane Belharbi, J\\'er\\^ome Rony, Jose Dolz, Ismail Ben Ayed, Luke\n  McCaffrey, Eric Granger", "title": "Min-max Entropy for Weakly Supervised Pointwise Localization", "comments": "27 pages, 15 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pointwise localization allows more precise localization and accurate\ninterpretability, compared to bounding box, in applications where objects are\nhighly unstructured such as in medical domain. In this work, we focus on weakly\nsupervised localization (WSL) where a model is trained to classify an image and\nlocalize regions of interest at pixel-level using only global image annotation.\nTypical convolutional attentions maps are prune to high false positive regions.\nTo alleviate this issue, we propose a new deep learning method for WSL,\ncomposed of a localizer and a classifier, where the localizer is constrained to\ndetermine relevant and irrelevant regions using conditional entropy (CE) with\nthe aim to reduce false positive regions. Experimental results on a public\nmedical dataset and two natural datasets, using Dice index, show that, compared\nto state of the art WSL methods, our proposal can provide significant\nimprovements in terms of image-level classification and pixel-level\nlocalization (low false positive) with robustness to overfitting. A public\nreproducible PyTorch implementation is provided in:\nhttps://github.com/sbelharbi/wsol-min-max-entropy-interpretability .\n", "versions": [{"version": "v1", "created": "Thu, 25 Jul 2019 00:51:18 GMT"}, {"version": "v2", "created": "Mon, 12 Aug 2019 22:00:15 GMT"}, {"version": "v3", "created": "Sat, 31 Aug 2019 14:54:43 GMT"}, {"version": "v4", "created": "Thu, 26 Sep 2019 04:42:50 GMT"}, {"version": "v5", "created": "Thu, 21 Jan 2021 04:08:10 GMT"}], "update_date": "2021-01-22", "authors_parsed": [["Belharbi", "Soufiane", ""], ["Rony", "J\u00e9r\u00f4me", ""], ["Dolz", "Jose", ""], ["Ayed", "Ismail Ben", ""], ["McCaffrey", "Luke", ""], ["Granger", "Eric", ""]]}, {"id": "1907.12935", "submitter": "Davit Soselia", "authors": "Davit Soselia, Shota Amashukeli, Irakli Koberidze, Levan Shugliashvili", "title": "RNN-based Online Handwritten Character Recognition Using Accelerometer\n  and Gyroscope Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This abstract explores an RNN-based approach to online handwritten\nrecognition problem. Our method uses data from an accelerometer and a gyroscope\nmounted on a handheld pen-like device to train and run a character pre-diction\nmodel. We have built a dataset of timestamped gyroscope and accelerometer data\ngathered during the manual process of handwriting Latin characters, labeled\nwith the character being written; in total, the dataset con-sists of 1500\ngyroscope and accelerometer data sequenc-es for 8 characters of the Latin\nalphabet from 6 different people, and 20 characters, each 1500 samples from\nGeorgian alphabet from 5 different people. with each sequence containing the\ngyroscope and accelerometer data captured during the writing of a particular\ncharacter sampled once every 10ms. We train an RNN-based neural network\narchitecture on this dataset to predict the character being written. The model\nis optimized with categorical cross-entropy loss and RMSprop optimizer and\nachieves high accuracy on test data.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jul 2019 20:44:00 GMT"}], "update_date": "2019-07-31", "authors_parsed": [["Soselia", "Davit", ""], ["Amashukeli", "Shota", ""], ["Koberidze", "Irakli", ""], ["Shugliashvili", "Levan", ""]]}, {"id": "1907.12952", "submitter": "Hosein Mohammadi Makrani", "authors": "Hosein Mohammadi Makrani, Farnoud Farahmand, Hossein Sayadi, Sara\n  Bondi, Sai Manoj Pudukotai Dinakarrao, Liang Zhao, Avesta Sasan, Houman\n  Homayoun, Setareh Rafatirad", "title": "Pyramid: Machine Learning Framework to Estimate the Optimal Timing and\n  Resource Usage of a High-Level Synthesis Design", "comments": "This paper has been accepted in The International Conference on\n  Field-Programmable Logic and Applications 2019 (FPL'19)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The emergence of High-Level Synthesis (HLS) tools shifted the paradigm of\nhardware design by making the process of mapping high-level programming\nlanguages to hardware design such as C to VHDL/Verilog feasible. HLS tools\noffer a plethora of techniques to optimize designs for both area and\nperformance, but resource usage and timing reports of HLS tools mostly deviate\nfrom the post-implementation results. In addition, to evaluate a hardware\ndesign performance, it is critical to determine the maximum achievable clock\nfrequency. Obtaining such information using static timing analysis provided by\nCAD tools is difficult, due to the multitude of tool options. Moreover, a\nbinary search to find the maximum frequency is tedious, time-consuming, and\noften does not obtain the optimal result. To address these challenges, we\npropose a framework, called Pyramid, that uses machine learning to accurately\nestimate the optimal performance and resource utilization of an HLS design. For\nthis purpose, we first create a database of C-to-FPGA results from a diverse\nset of benchmarks. To find the achievable maximum clock frequency, we use\nMinerva, which is an automated hardware optimization tool. Minerva determines\nthe close-to-optimal settings of tools, using static timing analysis and a\nheuristic algorithm, and targets either optimal throughput or\nthroughput-to-area. Pyramid uses the database to train an ensemble machine\nlearning model to map the HLS-reported features to the results of Minerva. To\nthis end, Pyramid re-calibrates the results of HLS to bridge the accuracy gap\nand enable developers to estimate the throughput or throughput-to-area of\nhardware design with more than 95% accuracy and alleviates the need to perform\nactual implementation for estimation.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jul 2019 01:34:20 GMT"}], "update_date": "2019-07-31", "authors_parsed": [["Makrani", "Hosein Mohammadi", ""], ["Farahmand", "Farnoud", ""], ["Sayadi", "Hossein", ""], ["Bondi", "Sara", ""], ["Dinakarrao", "Sai Manoj Pudukotai", ""], ["Zhao", "Liang", ""], ["Sasan", "Avesta", ""], ["Homayoun", "Houman", ""], ["Rafatirad", "Setareh", ""]]}, {"id": "1907.12953", "submitter": "Arindam Paul", "authors": "Arindam Paul, Mojtaba Mozaffar, Zijiang Yang, Wei-keng Liao, Alok\n  Choudhary, Jian Cao, Ankit Agrawal", "title": "A real-time iterative machine learning approach for temperature profile\n  prediction in additive manufacturing processes", "comments": "10 pages, 8 figures", "journal-ref": "6th IEEE International Conference on Data Science and Advanced\n  Analytics (DSAA), 2019", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Additive Manufacturing (AM) is a manufacturing paradigm that builds\nthree-dimensional objects from a computer-aided design model by successively\nadding material layer by layer. AM has become very popular in the past decade\ndue to its utility for fast prototyping such as 3D printing as well as\nmanufacturing functional parts with complex geometries using processes such as\nlaser metal deposition that would be difficult to create using traditional\nmachining. As the process for creating an intricate part for an expensive metal\nsuch as Titanium is prohibitive with respect to cost, computational models are\nused to simulate the behavior of AM processes before the experimental run.\nHowever, as the simulations are computationally costly and time-consuming for\npredicting multiscale multi-physics phenomena in AM, physics-informed\ndata-driven machine-learning systems for predicting the behavior of AM\nprocesses are immensely beneficial. Such models accelerate not only multiscale\nsimulation tools but also empower real-time control systems using in-situ data.\nIn this paper, we design and develop essential components of a scientific\nframework for developing a data-driven model-based real-time control system.\nFinite element methods are employed for solving time-dependent heat equations\nand developing the database. The proposed framework uses extremely randomized\ntrees - an ensemble of bagged decision trees as the regression algorithm\niteratively using temperatures of prior voxels and laser information as inputs\nto predict temperatures of subsequent voxels. The models achieve mean absolute\npercentage errors below 1% for predicting temperature profiles for AM\nprocesses. The code is made available for the research community at\nhttps://github.com/paularindam/ml-iter-additive.\n", "versions": [{"version": "v1", "created": "Sun, 28 Jul 2019 22:43:02 GMT"}, {"version": "v2", "created": "Fri, 9 Aug 2019 05:14:45 GMT"}], "update_date": "2019-08-12", "authors_parsed": [["Paul", "Arindam", ""], ["Mozaffar", "Mojtaba", ""], ["Yang", "Zijiang", ""], ["Liao", "Wei-keng", ""], ["Choudhary", "Alok", ""], ["Cao", "Jian", ""], ["Agrawal", "Ankit", ""]]}, {"id": "1907.12956", "submitter": "Shervin Minaee", "authors": "Shervin Minaee, Elham Azimi, Amirali Abdolrashidi", "title": "FingerNet: Pushing The Limits of Fingerprint Recognition Using\n  Convolutional Neural Network", "comments": "arXiv admin note: substantial text overlap with arXiv:1907.09380", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fingerprint recognition has been utilized for cellphone authentication,\nairport security and beyond. Many different features and algorithms have been\nproposed to improve fingerprint recognition. In this paper, we propose an\nend-to-end deep learning framework for fingerprint recognition using\nconvolutional neural networks (CNNs) which can jointly learn the feature\nrepresentation and perform recognition. We train our model on a large-scale\nfingerprint recognition dataset, and improve over previous approaches in terms\nof accuracy. Our proposed model is able to achieve a very high recognition\naccuracy on a well-known fingerprint dataset. We believe this framework can be\nwidely used for biometrics recognition tasks, making more scalable and accurate\nsystems possible. We have also used a visualization technique to highlight the\nimportant areas in an input fingerprint image, that mostly impact the\nrecognition results.\n", "versions": [{"version": "v1", "created": "Sun, 28 Jul 2019 21:00:56 GMT"}], "update_date": "2019-07-31", "authors_parsed": [["Minaee", "Shervin", ""], ["Azimi", "Elham", ""], ["Abdolrashidi", "Amirali", ""]]}, {"id": "1907.12972", "submitter": "Ron Levie", "authors": "Ron Levie, Wei Huang, Lorenzo Bucci, Michael M. Bronstein, Gitta\n  Kutyniok", "title": "Transferability of Spectral Graph Convolutional Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper focuses on spectral graph convolutional neural networks\n(ConvNets), where filters are defined as elementwise multiplication in the\nfrequency domain of a graph. In machine learning settings where the dataset\nconsists of signals defined on many different graphs, the trained ConvNet\nshould generalize to signals on graphs unseen in the training set. It is thus\nimportant to transfer ConvNets between graphs. Transferability, which is a\ncertain type of generalization capability, can be loosely defined as follows:\nif two graphs describe the same phenomenon, then a single filter or ConvNet\nshould have similar repercussions on both graphs. This paper aims at debunking\nthe common misconception that spectral filters are not transferable. We show\nthat if two graphs discretize the same \"continuous\" space, then a spectral\nfilter or ConvNet has approximately the same repercussion on both graphs. Our\nanalysis is more permissive than the standard analysis. Transferability is\ntypically described as the robustness of the filter to small graph\nperturbations and re-indexing of the vertices. Our analysis accounts also for\nlarge graph perturbations. We prove transferability between graphs that can\nhave completely different dimensions and topologies, only requiring that both\ngraphs discretize the same underlying space in some generic sense.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jul 2019 14:16:45 GMT"}, {"version": "v2", "created": "Thu, 5 Mar 2020 21:48:08 GMT"}, {"version": "v3", "created": "Sat, 12 Jun 2021 20:45:19 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Levie", "Ron", ""], ["Huang", "Wei", ""], ["Bucci", "Lorenzo", ""], ["Bronstein", "Michael M.", ""], ["Kutyniok", "Gitta", ""]]}, {"id": "1907.12991", "submitter": "Jorge Guevara", "authors": "Jorge Guevara, Roberto Hirata Jr, St\\'ephane Canu", "title": "Kernels on fuzzy sets: an overview", "comments": "Learning on Distributions, Functions, Graphs and Groups @ NIPS-2017,\n  8th Dec", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces the concept of kernels on fuzzy sets as a similarity\nmeasure for $[0,1]$-valued functions, a.k.a. \\emph{membership functions of\nfuzzy sets}.\n  We defined the following classes of kernels: the cross product, the\nintersection, the non-singleton and the distance-based kernels on fuzzy sets.\n  Applicability of those kernels are on machine learning and data science tasks\nwhere uncertainty in data has an ontic or epistemistic interpretation.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jul 2019 14:54:01 GMT"}], "update_date": "2019-07-31", "authors_parsed": [["Guevara", "Jorge", ""], ["Hirata", "Roberto", "Jr"], ["Canu", "St\u00e9phane", ""]]}, {"id": "1907.12996", "submitter": "Anna Stelzer", "authors": "Anna Stelzer", "title": "Predicting credit default probabilities using machine learning\n  techniques in the face of unequal class distributions", "comments": "Keywords: Forecasting, credit scoring, imbalanced data sets,\n  classification, benchmarking", "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.EM cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This study conducts a benchmarking study, comparing 23 different statistical\nand machine learning methods in a credit scoring application. In order to do\nso, the models' performance is evaluated over four different data sets in\ncombination with five data sampling strategies to tackle existing class\nimbalances in the data. Six different performance measures are used to cover\ndifferent aspects of predictive performance. The results indicate a strong\nsuperiority of ensemble methods and show that simple sampling strategies\ndeliver better results than more sophisticated ones.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jul 2019 15:01:10 GMT"}], "update_date": "2019-07-31", "authors_parsed": [["Stelzer", "Anna", ""]]}, {"id": "1907.12998", "submitter": "Tomasz Arodz", "authors": "Han Zhang, Xi Gao, Jacob Unterman, Tom Arodz", "title": "Approximation Capabilities of Neural ODEs and Invertible Residual\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural ODEs and i-ResNet are recently proposed methods for enforcing\ninvertibility of residual neural models. Having a generic technique for\nconstructing invertible models can open new avenues for advances in learning\nsystems, but so far the question of whether Neural ODEs and i-ResNets can model\nany continuous invertible function remained unresolved. Here, we show that both\nof these models are limited in their approximation capabilities. We then prove\nthat any homeomorphism on a $p$-dimensional Euclidean space can be approximated\nby a Neural ODE operating on a $2p$-dimensional Euclidean space, and a similar\nresult for i-ResNets. We conclude by showing that capping a Neural ODE or an\ni-ResNet with a single linear layer is sufficient to turn the model into a\nuniversal approximator for non-invertible continuous functions.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jul 2019 15:04:01 GMT"}, {"version": "v2", "created": "Sun, 1 Mar 2020 03:28:45 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Zhang", "Han", ""], ["Gao", "Xi", ""], ["Unterman", "Jacob", ""], ["Arodz", "Tom", ""]]}, {"id": "1907.13025", "submitter": "Carlos Caetano", "authors": "Carlos Caetano, Jessica Sena, Fran\\c{c}ois Br\\'emond, Jefersson A. dos\n  Santos and William Robson Schwartz", "title": "SkeleMotion: A New Representation of Skeleton Joint Sequences Based on\n  Motion Information for 3D Action Recognition", "comments": "16-th IEEE International Conference on Advanced Video and\n  Signal-based Surveillance (AVSS2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to the availability of large-scale skeleton datasets, 3D human action\nrecognition has recently called the attention of computer vision community.\nMany works have focused on encoding skeleton data as skeleton image\nrepresentations based on spatial structure of the skeleton joints, in which the\ntemporal dynamics of the sequence is encoded as variations in columns and the\nspatial structure of each frame is represented as rows of a matrix. To further\nimprove such representations, we introduce a novel skeleton image\nrepresentation to be used as input of Convolutional Neural Networks (CNNs),\nnamed SkeleMotion. The proposed approach encodes the temporal dynamics by\nexplicitly computing the magnitude and orientation values of the skeleton\njoints. Different temporal scales are employed to compute motion values to\naggregate more temporal dynamics to the representation making it able to\ncapture longrange joint interactions involved in actions as well as filtering\nnoisy motion values. Experimental results demonstrate the effectiveness of the\nproposed representation on 3D action recognition outperforming the\nstate-of-the-art on NTU RGB+D 120 dataset.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jul 2019 15:40:07 GMT"}], "update_date": "2019-07-31", "authors_parsed": [["Caetano", "Carlos", ""], ["Sena", "Jessica", ""], ["Br\u00e9mond", "Fran\u00e7ois", ""], ["Santos", "Jefersson A. dos", ""], ["Schwartz", "William Robson", ""]]}, {"id": "1907.13052", "submitter": "Martin Engelcke", "authors": "Martin Engelcke, Adam R. Kosiorek, Oiwi Parker Jones, Ingmar Posner", "title": "GENESIS: Generative Scene Inference and Sampling with Object-Centric\n  Latent Representations", "comments": "Published at the International Conference on Learning Representations\n  (ICLR) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative latent-variable models are emerging as promising tools in robotics\nand reinforcement learning. Yet, even though tasks in these domains typically\ninvolve distinct objects, most state-of-the-art generative models do not\nexplicitly capture the compositional nature of visual scenes. Two recent\nexceptions, MONet and IODINE, decompose scenes into objects in an unsupervised\nfashion. Their underlying generative processes, however, do not account for\ncomponent interactions. Hence, neither of them allows for principled sampling\nof novel scenes. Here we present GENESIS, the first object-centric generative\nmodel of 3D visual scenes capable of both decomposing and generating scenes by\ncapturing relationships between scene components. GENESIS parameterises a\nspatial GMM over images which is decoded from a set of object-centric latent\nvariables that are either inferred sequentially in an amortised fashion or\nsampled from an autoregressive prior. We train GENESIS on several publicly\navailable datasets and evaluate its performance on scene generation,\ndecomposition, and semi-supervised learning.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jul 2019 16:22:39 GMT"}, {"version": "v2", "created": "Sun, 29 Sep 2019 20:19:08 GMT"}, {"version": "v3", "created": "Mon, 3 Feb 2020 14:02:16 GMT"}, {"version": "v4", "created": "Mon, 23 Nov 2020 10:31:22 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Engelcke", "Martin", ""], ["Kosiorek", "Adam R.", ""], ["Jones", "Oiwi Parker", ""], ["Posner", "Ingmar", ""]]}, {"id": "1907.13054", "submitter": "Volker Fischer", "authors": "Lukas Hoyer, Mauricio Munoz, Prateek Katiyar, Anna Khoreva, Volker\n  Fischer", "title": "Grid Saliency for Context Explanations of Semantic Segmentation", "comments": "33rd Conference on Neural Information Processing Systems (NeurIPS\n  2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, there has been a growing interest in developing saliency methods\nthat provide visual explanations of network predictions. Still, the usability\nof existing methods is limited to image classification models. To overcome this\nlimitation, we extend the existing approaches to generate grid saliencies,\nwhich provide spatially coherent visual explanations for (pixel-level) dense\nprediction networks. As the proposed grid saliency allows to spatially\ndisentangle the object and its context, we specifically explore its potential\nto produce context explanations for semantic segmentation networks, discovering\nwhich context most influences the class predictions inside a target object\narea. We investigate the effectiveness of grid saliency on a synthetic dataset\nwith an artificially induced bias between objects and their context as well as\non the real-world Cityscapes dataset using state-of-the-art segmentation\nnetworks. Our results show that grid saliency can be successfully used to\nprovide easily interpretable context explanations and, moreover, can be\nemployed for detecting and localizing contextual biases present in the data.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jul 2019 16:25:52 GMT"}, {"version": "v2", "created": "Thu, 7 Nov 2019 12:29:44 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Hoyer", "Lukas", ""], ["Munoz", "Mauricio", ""], ["Katiyar", "Prateek", ""], ["Khoreva", "Anna", ""], ["Fischer", "Volker", ""]]}, {"id": "1907.13057", "submitter": "Jungkyu Park", "authors": "Jungkyu Park, Jason Phang, Yiqiu Shen, Nan Wu, S. Gene Kim, Linda Moy,\n  Kyunghyun Cho, Krzysztof J. Geras", "title": "Screening Mammogram Classification with Prior Exams", "comments": "MIDL 2019 [arXiv:1907.08612]", "journal-ref": null, "doi": null, "report-no": "MIDL/2019/ExtendedAbstract/HkgCdUaMq4", "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Radiologists typically compare a patient's most recent breast cancer\nscreening exam to their previous ones in making informed diagnoses. To reflect\nthis practice, we propose new neural network models that compare pairs of\nscreening mammograms from the same patient. We train and evaluate our proposed\nmodels on over 665,000 pairs of images (over 166,000 pairs of exams). Our best\nmodel achieves an AUC of 0.866 in predicting malignancy in patients who\nunderwent breast cancer screening, reducing the error rate of the corresponding\nbaseline.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jul 2019 16:34:53 GMT"}], "update_date": "2019-07-31", "authors_parsed": [["Park", "Jungkyu", ""], ["Phang", "Jason", ""], ["Shen", "Yiqiu", ""], ["Wu", "Nan", ""], ["Kim", "S. Gene", ""], ["Moy", "Linda", ""], ["Cho", "Kyunghyun", ""], ["Geras", "Krzysztof J.", ""]]}, {"id": "1907.13070", "submitter": "Telma Pereira", "authors": "Telma Pereira, Sofia Pires, Marta Gromicho, Susana Pinto, Mamede de\n  Carvalho, Sara C.Madeira", "title": "Predicting assisted ventilation in Amyotrophic Lateral Sclerosis using a\n  mixture of experts and conformal predictors", "comments": null, "journal-ref": "KDD 2019 Workshop on Applied Data Science for Healthcare", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Amyotrophic Lateral Sclerosis (ALS) is a neurodegenerative disease\ncharacterized by a rapid motor decline, leading to respiratory failure and\nsubsequently to death. In this context, researchers have sought for models to\nautomatically predict disease progression to assisted ventilation in ALS\npatients. However, the clinical translation of such models is limited by the\nlack of insight 1) on the risk of error for predictions at patient-level, and\n2) on the most adequate time to administer the non-invasive ventilation. To\naddress these issues, we combine Conformal Prediction (a machine learning\nframework that complements predictions with confidence measures) and a mixture\nexperts into a prognostic model which not only predicts whether an ALS patient\nwill suffer from respiratory insufficiency but also the most likely time window\nof occurrence, at a given reliability level. Promising results were obtained,\nwith near 80% of predictions being correctly identified.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jul 2019 16:55:29 GMT"}], "update_date": "2019-07-31", "authors_parsed": [["Pereira", "Telma", ""], ["Pires", "Sofia", ""], ["Gromicho", "Marta", ""], ["Pinto", "Susana", ""], ["de Carvalho", "Mamede", ""], ["Madeira", "Sara C.", ""]]}, {"id": "1907.13075", "submitter": "Pau Rodr\\'iguez L\\'opez", "authors": "Pau Rodr\\'iguez L\\'opez, Diego Velazquez Dorta, Guillem Cucurull\n  Preixens, Josep M. Gonfaus, F. Xavier Roca Marva, Jordi Gonz\\`alez Sabat\\'e", "title": "Pay attention to the activations: a modular attention mechanism for\n  fine-grained image recognition", "comments": "IEEE Transactions on Multimedia, ECCV extension", "journal-ref": null, "doi": "10.1109/TMM.2019.2928494", "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fine-grained image recognition is central to many multimedia tasks such as\nsearch, retrieval and captioning. Unfortunately, these tasks are still\nchallenging since the appearance of samples of the same class can be more\ndifferent than those from different classes. Attention has been typically\nimplemented in neural networks by selecting the most informative regions of the\nimage that improve classification. In contrast, in this paper, attention is not\napplied at the image level but to the convolutional feature activations. In\nessence, with our approach, the neural model learns to attend to lower-level\nfeature activations without requiring part annotations and uses those\nactivations to update and rectify the output likelihood distribution. The\nproposed mechanism is modular, architecture-independent and efficient in terms\nof both parameters and computation required. Experiments demonstrate that\nwell-known networks such as Wide Residual Networks and ResNeXt, when augmented\nwith our approach, systematically improve their classification accuracy and\nbecome more robust to changes in deformation and pose and to the presence of\nclutter. As a result, our proposal reaches state-of-the-art classification\naccuracies in CIFAR-10, the Adience gender recognition task, Stanford Dogs, and\nUEC-Food100 while obtaining competitive performance in ImageNet, CIFAR-100,\nCUB200 Birds, and Stanford Cars. In addition, we analyze the different\ncomponents of our model, showing that the proposed attention modules succeed in\nfinding the most discriminative regions of the image. Finally, as a proof of\nconcept, we demonstrate that with only local predictions, an augmented neural\nnetwork can successfully classify an image before reaching any fully connected\nlayer, thus reducing the computational amount up to 10%.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jul 2019 17:00:15 GMT"}], "update_date": "2019-07-31", "authors_parsed": [["L\u00f3pez", "Pau Rodr\u00edguez", ""], ["Dorta", "Diego Velazquez", ""], ["Preixens", "Guillem Cucurull", ""], ["Gonfaus", "Josep M.", ""], ["Marva", "F. Xavier Roca", ""], ["Sabat\u00e9", "Jordi Gonz\u00e0lez", ""]]}, {"id": "1907.13095", "submitter": "Fabio Sanchez PhD", "authors": "Paola V\\'asquez, Antonio Lor\\'ia, Fabio Sanchez, Luis A. Barboza", "title": "Climate-driven statistical models as effective predictors of local\n  dengue incidence in Costa Rica: A Generalized Additive Model and Random\n  Forest approach", "comments": "17 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG q-bio.PE q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Climate has been an important factor in shaping the distribution and\nincidence of dengue cases in tropical and subtropical countries. In Costa Rica,\na tropical country with distinctive micro-climates, dengue has been endemic\nsince its introduction in 1993, inflicting substantial economic, social, and\npublic health repercussions. Using the number of dengue reported cases and\nclimate data from 2007-2017, we fitted a prediction model applying a\nGeneralized Additive Model (GAM) and Random Forest (RF) approach, which allowed\nus to retrospectively predict the relative risk of dengue in five\nclimatological diverse municipalities around the country.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jul 2019 17:27:39 GMT"}, {"version": "v2", "created": "Mon, 30 Sep 2019 15:28:37 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["V\u00e1squez", "Paola", ""], ["Lor\u00eda", "Antonio", ""], ["Sanchez", "Fabio", ""], ["Barboza", "Luis A.", ""]]}, {"id": "1907.13098", "submitter": "Michelle A. Lee", "authors": "Michelle A. Lee, Yuke Zhu, Peter Zachares, Matthew Tan, Krishnan\n  Srinivasan, Silvio Savarese, Li Fei-Fei, Animesh Garg, Jeannette Bohg", "title": "Making Sense of Vision and Touch: Learning Multimodal Representations\n  for Contact-Rich Tasks", "comments": "arXiv admin note: substantial text overlap with arXiv:1810.10191", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Contact-rich manipulation tasks in unstructured environments often require\nboth haptic and visual feedback. It is non-trivial to manually design a robot\ncontroller that combines these modalities which have very different\ncharacteristics. While deep reinforcement learning has shown success in\nlearning control policies for high-dimensional inputs, these algorithms are\ngenerally intractable to deploy on real robots due to sample complexity. In\nthis work, we use self-supervision to learn a compact and multimodal\nrepresentation of our sensory inputs, which can then be used to improve the\nsample efficiency of our policy learning. Evaluating our method on a peg\ninsertion task, we show that it generalizes over varying geometries,\nconfigurations, and clearances, while being robust to external perturbations.\nWe also systematically study different self-supervised learning objectives and\nrepresentation learning architectures. Results are presented in simulation and\non a physical robot.\n", "versions": [{"version": "v1", "created": "Sun, 28 Jul 2019 02:03:08 GMT"}], "update_date": "2019-07-31", "authors_parsed": [["Lee", "Michelle A.", ""], ["Zhu", "Yuke", ""], ["Zachares", "Peter", ""], ["Tan", "Matthew", ""], ["Srinivasan", "Krishnan", ""], ["Savarese", "Silvio", ""], ["Fei-Fei", "Li", ""], ["Garg", "Animesh", ""], ["Bohg", "Jeannette", ""]]}, {"id": "1907.13113", "submitter": "Evita Bakopoulou", "authors": "Evita Bakopoulou, Balint Tillman, and Athina Markopoulou", "title": "A Federated Learning Approach for Mobile Packet Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to improve mobile data transparency, a number of network-based\napproaches have been proposed to inspect packets generated by mobile devices\nand detect personally identifiable information (PII), ad requests, or other\nactivities. State-of-the-art approaches train classifiers based on features\nextracted from HTTP packets. So far, these classifiers have only been trained\nin a centralized way, where mobile users label and upload their packet logs to\na central server, which then trains a global classifier and shares it with the\nusers to apply on their devices. However, packet logs used as training data may\ncontain sensitive information that users may not want to share/upload. In this\npaper, we apply, for the first time, a Federated Learning approach to mobile\npacket classification, which allows mobile devices to collaborate and train a\nglobal model, without sharing raw training data. Methodological challenges we\naddress in this context include: model and feature selection, and tuning the\nFederated Learning parameters. We apply our framework to two different packet\nclassification tasks (i.e., to predict PII exposure or ad requests in HTTP\npackets) and we demonstrate its effectiveness in terms of classification\nperformance, communication and computation cost, using three real-world\ndatasets.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jul 2019 17:54:50 GMT"}], "update_date": "2019-07-31", "authors_parsed": [["Bakopoulou", "Evita", ""], ["Tillman", "Balint", ""], ["Markopoulou", "Athina", ""]]}, {"id": "1907.13120", "submitter": "Boonsap Witchayangkoon Assoc Prof Dr", "authors": "Piyasak Thiandee, Boonsap Witchayangkoon, Sayan Sirimontree, Ponlathep\n  Lertworawanich", "title": "An Experiment on Measurement of Pavement Roughness via Android-Based\n  Smartphones", "comments": "9 pages, 11 figures", "journal-ref": "International Transaction Journal of Engineering, Management, &\n  Applied Sciences & Technologies (2019) 1-9", "doi": null, "report-no": "10A09G", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The study focuses on the experiment of using three different smartphones to\ncollect acceleration data from vibration for the road roughness detection. The\nAndroid operating system is used in the application. The study takes place on\nasphaltic pavement of the expressway system of Thailand, with 9 km distance.\nThe run vehicle has an inertial profiler with laser line sensors to record road\nroughness according to the IRI. The RMS and Machine Learning (ML) methods are\nused in this study. There is different ability of each smartphone to detect the\nvibration, thus different detected values are obtained. The results are\ncompared to the IRI observation. ML method gives better result compared to RMS.\nThis study finds little relationship between IRI and acceleration data from\nvibration collected from smartphones.\n", "versions": [{"version": "v1", "created": "Sun, 28 Jul 2019 09:37:10 GMT"}], "update_date": "2019-07-31", "authors_parsed": [["Thiandee", "Piyasak", ""], ["Witchayangkoon", "Boonsap", ""], ["Sirimontree", "Sayan", ""], ["Lertworawanich", "Ponlathep", ""]]}, {"id": "1907.13121", "submitter": "Tom Sercu", "authors": "Tom Sercu, Neil Mallinar", "title": "Multi-Frame Cross-Entropy Training for Convolutional Neural Networks in\n  Speech Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce Multi-Frame Cross-Entropy training (MFCE) for convolutional\nneural network acoustic models. Recognizing that similar to RNNs, CNNs are in\nnature sequence models that take variable length inputs, we propose to take as\ninput to the CNN a part of an utterance long enough that multiple labels are\npredicted at once, therefore getting cross-entropy loss signal from multiple\nadjacent frames. This increases the amount of label information drastically for\nsmall marginal computational cost. We show large WER improvements on hub5 and\nrt02 after training on the 2000-hour Switchboard benchmark.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jul 2019 19:56:46 GMT"}], "update_date": "2019-08-01", "authors_parsed": [["Sercu", "Tom", ""], ["Mallinar", "Neil", ""]]}, {"id": "1907.13122", "submitter": "Sumeet Singh", "authors": "Sumeet Singh, Spencer M. Richards, Vikas Sindhwani, Jean-Jacques E.\n  Slotine, Marco Pavone", "title": "Learning Stabilizable Nonlinear Dynamics with Contraction-Based\n  Regularization", "comments": "Invited submission for IJRR; under review. arXiv admin note: text\n  overlap with arXiv:1808.00113", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG cs.RO cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel framework for learning stabilizable nonlinear dynamical\nsystems for continuous control tasks in robotics. The key contribution is a\ncontrol-theoretic regularizer for dynamics fitting rooted in the notion of\nstabilizability, a constraint which guarantees the existence of robust tracking\ncontrollers for arbitrary open-loop trajectories generated with the learned\nsystem. Leveraging tools from contraction theory and statistical learning in\nReproducing Kernel Hilbert Spaces, we formulate stabilizable dynamics learning\nas a functional optimization with convex objective and bi-convex functional\nconstraints. Under a mild structural assumption and relaxation of the\nfunctional constraints to sampling-based constraints, we derive the optimal\nsolution with a modified Representer theorem. Finally, we utilize random matrix\nfeature approximations to reduce the dimensionality of the search parameters\nand formulate an iterative convex optimization algorithm that jointly fits the\ndynamics functions and searches for a certificate of stabilizability. We\nvalidate the proposed algorithm in simulation for a planar quadrotor, and on a\nquadrotor hardware testbed emulating planar dynamics. We verify, both in\nsimulation and on hardware, significantly improved trajectory generation and\ntracking performance with the control-theoretic regularized model over models\nlearned using traditional regression techniques, especially when learning from\nsmall supervised datasets. The results support the conjecture that the use of\nstabilizability constraints as a form of regularization can help prune the\nhypothesis space in a manner that is tailored to the downstream task of\ntrajectory generation and feedback control, resulting in models that are not\nonly dramatically better conditioned, but also data efficient.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jul 2019 21:14:34 GMT"}], "update_date": "2019-08-01", "authors_parsed": [["Singh", "Sumeet", ""], ["Richards", "Spencer M.", ""], ["Sindhwani", "Vikas", ""], ["Slotine", "Jean-Jacques E.", ""], ["Pavone", "Marco", ""]]}, {"id": "1907.13124", "submitter": "Utku Ozbulak", "authors": "Utku Ozbulak, Arnout Van Messem, Wesley De Neve", "title": "Impact of Adversarial Examples on Deep Learning Models for Biomedical\n  Image Segmentation", "comments": "Accepted for the 22nd International Conference on Medical Image\n  Computing and Computer Assisted Intervention (MICCAI-19)", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CR cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning models, which are increasingly being used in the field of\nmedical image analysis, come with a major security risk, namely, their\nvulnerability to adversarial examples. Adversarial examples are carefully\ncrafted samples that force machine learning models to make mistakes during\ntesting time. These malicious samples have been shown to be highly effective in\nmisguiding classification tasks. However, research on the influence of\nadversarial examples on segmentation is significantly lacking. Given that a\nlarge portion of medical imaging problems are effectively segmentation\nproblems, we analyze the impact of adversarial examples on deep learning-based\nimage segmentation models. Specifically, we expose the vulnerability of these\nmodels to adversarial examples by proposing the Adaptive Segmentation Mask\nAttack (ASMA). This novel algorithm makes it possible to craft targeted\nadversarial examples that come with (1) high intersection-over-union rates\nbetween the target adversarial mask and the prediction and (2) with\nperturbation that is, for the most part, invisible to the bare eye. We lay out\nexperimental and visual evidence by showing results obtained for the ISIC skin\nlesion segmentation challenge and the problem of glaucoma optic disc\nsegmentation. An implementation of this algorithm and additional examples can\nbe found at https://github.com/utkuozbulak/adaptive-segmentation-mask-attack.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jul 2019 06:03:57 GMT"}], "update_date": "2019-08-01", "authors_parsed": [["Ozbulak", "Utku", ""], ["Van Messem", "Arnout", ""], ["De Neve", "Wesley", ""]]}, {"id": "1907.13177", "submitter": "Huy Phan", "authors": "Huy Phan and Oliver Y. Ch\\'en and Philipp Koch and Zongqing Lu and Ian\n  McLoughlin and Alfred Mertins and Maarten De Vos", "title": "Towards More Accurate Automatic Sleep Staging via Deep Transfer Learning", "comments": "This article has been published in IEEE Transactions on Biomedical\n  Engineering", "journal-ref": null, "doi": "10.1109/TBME.2020.3020381", "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Background: Despite recent significant progress in the development of\nautomatic sleep staging methods, building a good model still remains a big\nchallenge for sleep studies with a small cohort due to the data-variability and\ndata-inefficiency issues. This work presents a deep transfer learning approach\nto overcome these issues and enable transferring knowledge from a large dataset\nto a small cohort for automatic sleep staging. Methods: We start from a generic\nend-to-end deep learning framework for sequence-to-sequence sleep staging and\nderive two networks as the means for transfer learning. The networks are first\ntrained in the source domain (i.e. the large database). The pretrained networks\nare then finetuned in the target domain (i.e. the small cohort) to complete\nknowledge transfer. We employ the Montreal Archive of Sleep Studies (MASS)\ndatabase consisting of 200 subjects as the source domain and study deep\ntransfer learning on three different target domains: the Sleep Cassette subset\nand the Sleep Telemetry subset of the Sleep-EDF Expanded database, and the\nSurrey-cEEGrid database. The target domains are purposely adopted to cover\ndifferent degrees of data mismatch to the source domains. Results: Our\nexperimental results show significant performance improvement on automatic\nsleep staging on the target domains achieved with the proposed deep transfer\nlearning approach. Conclusions: These results suggest the efficacy of the\nproposed approach in addressing the above-mentioned data-variability and\ndata-inefficiency issues. Significance: As a consequence, it would enable one\nto improve the quality of automatic sleep staging models when the amount of\ndata is relatively small. The source code and the pretrained models are\navailable at http://github.com/pquochuy/sleep_transfer_learning.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jul 2019 18:49:57 GMT"}, {"version": "v2", "created": "Fri, 12 Jun 2020 14:09:36 GMT"}, {"version": "v3", "created": "Thu, 27 Aug 2020 16:26:17 GMT"}], "update_date": "2020-08-28", "authors_parsed": [["Phan", "Huy", ""], ["Ch\u00e9n", "Oliver Y.", ""], ["Koch", "Philipp", ""], ["Lu", "Zongqing", ""], ["McLoughlin", "Ian", ""], ["Mertins", "Alfred", ""], ["De Vos", "Maarten", ""]]}, {"id": "1907.13188", "submitter": "Mark Thomas", "authors": "Mark Thomas, Bruce Martin, Katie Kowarski, Briand Gaudet, Stan Matwin", "title": "Marine Mammal Species Classification using Convolutional Neural Networks\n  and a Novel Acoustic Representation", "comments": "16 pages, To appear in ECML-PKDD 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Research into automated systems for detecting and classifying marine mammals\nin acoustic recordings is expanding internationally due to the necessity to\nanalyze large collections of data for conservation purposes. In this work, we\npresent a Convolutional Neural Network that is capable of classifying the\nvocalizations of three species of whales, non-biological sources of noise, and\na fifth class pertaining to ambient noise. In this way, the classifier is\ncapable of detecting the presence and absence of whale vocalizations in an\nacoustic recording. Through transfer learning, we show that the classifier is\ncapable of learning high-level representations and can generalize to additional\nspecies. We also propose a novel representation of acoustic signals that builds\nupon the commonly used spectrogram representation by way of interpolating and\nstacking multiple spectrograms produced using different Short-time Fourier\nTransform (STFT) parameters. The proposed representation is particularly\neffective for the task of marine mammal species classification where the\nacoustic events we are attempting to classify are sensitive to the parameters\nof the STFT.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jul 2019 19:17:41 GMT"}], "update_date": "2019-08-01", "authors_parsed": [["Thomas", "Mark", ""], ["Martin", "Bruce", ""], ["Kowarski", "Katie", ""], ["Gaudet", "Briand", ""], ["Matwin", "Stan", ""]]}, {"id": "1907.13196", "submitter": "Mohammed Amin Abdullah Dr", "authors": "Mohammed Amin Abdullah and Hang Ren and Haitham Bou Ammar and Vladimir\n  Milenkovic and Rui Luo and Mingtian Zhang and Jun Wang", "title": "Wasserstein Robust Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning algorithms, though successful, tend to over-fit to\ntraining environments hampering their application to the real-world. This paper\nproposes $\\text{W}\\text{R}^{2}\\text{L}$ -- a robust reinforcement learning\nalgorithm with significant robust performance on low and high-dimensional\ncontrol tasks. Our method formalises robust reinforcement learning as a novel\nmin-max game with a Wasserstein constraint for a correct and convergent solver.\nApart from the formulation, we also propose an efficient and scalable solver\nfollowing a novel zero-order optimisation method that we believe can be useful\nto numerical optimisation in general. We empirically demonstrate significant\ngains compared to standard and robust state-of-the-art algorithms on\nhigh-dimensional MuJuCo environments.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jul 2019 19:42:52 GMT"}, {"version": "v2", "created": "Sun, 4 Aug 2019 12:17:48 GMT"}, {"version": "v3", "created": "Sat, 10 Aug 2019 10:05:35 GMT"}, {"version": "v4", "created": "Mon, 16 Sep 2019 22:43:14 GMT"}], "update_date": "2019-09-18", "authors_parsed": [["Abdullah", "Mohammed Amin", ""], ["Ren", "Hang", ""], ["Ammar", "Haitham Bou", ""], ["Milenkovic", "Vladimir", ""], ["Luo", "Rui", ""], ["Zhang", "Mingtian", ""], ["Wang", "Jun", ""]]}, {"id": "1907.13208", "submitter": "Donghui Yan", "authors": "Donghui Yan, Ying Xu", "title": "Learning over inherently distributed data", "comments": "26 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.DC cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent decades have seen a surge of interests in distributed computing.\nExisting work focus primarily on either distributed computing platforms, data\nquery tools, or, algorithms to divide big data and conquer at individual\nmachines etc. It is, however, increasingly often that the data of interest are\ninherently distributed, i.e., data are stored at multiple distributed sites due\nto diverse collection channels, business operations etc. We propose to enable\nlearning and inference in such a setting via a general framework based on the\ndistortion minimizing local transformations. This framework only requires a\nsmall amount of local signatures to be shared among distributed sites,\neliminating the need of having to transmitting big data. Computation can be\ndone very efficiently via parallel local computation. The error incurred due to\ndistributed computing vanishes when increasing the size of local signatures. As\nthe shared data need not be in their original form, data privacy may also be\npreserved. Experiments on linear (logistic) regression and Random Forests have\nshown promise of this approach. This framework is expected to apply to a\ngeneral class of tools in learning and inference with the continuity property.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jul 2019 20:11:19 GMT"}], "update_date": "2019-08-01", "authors_parsed": [["Yan", "Donghui", ""], ["Xu", "Ying", ""]]}, {"id": "1907.13216", "submitter": "Seyed Hamed Fatemi Langroudi", "authors": "Hamed F. Langroudi, Zachariah Carmichael, and Dhireesha Kudithipudi", "title": "Deep Learning Training on the Edge with Low-Precision Posits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, the posit numerical format has shown promise for DNN data\nrepresentation and compute with ultra-low precision ([5..8]-bit). However,\nmajority of studies focus only on DNN inference. In this work, we propose DNN\ntraining using posits and compare with the floating point training. We evaluate\non both MNIST and Fashion MNIST corpuses, where 16-bit posits outperform 16-bit\nfloating point for end-to-end DNN training.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jul 2019 20:45:09 GMT"}], "update_date": "2019-08-01", "authors_parsed": [["Langroudi", "Hamed F.", ""], ["Carmichael", "Zachariah", ""], ["Kudithipudi", "Dhireesha", ""]]}, {"id": "1907.13220", "submitter": "Lantao Yu", "authors": "Lantao Yu, Jiaming Song, Stefano Ermon", "title": "Multi-Agent Adversarial Inverse Reinforcement Learning", "comments": "ICML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning agents are prone to undesired behaviors due to reward\nmis-specification. Finding a set of reward functions to properly guide agent\nbehaviors is particularly challenging in multi-agent scenarios. Inverse\nreinforcement learning provides a framework to automatically acquire suitable\nreward functions from expert demonstrations. Its extension to multi-agent\nsettings, however, is difficult due to the more complex notions of rational\nbehaviors. In this paper, we propose MA-AIRL, a new framework for multi-agent\ninverse reinforcement learning, which is effective and scalable for Markov\ngames with high-dimensional state-action space and unknown dynamics. We derive\nour algorithm based on a new solution concept and maximum pseudolikelihood\nestimation within an adversarial reward learning framework. In the experiments,\nwe demonstrate that MA-AIRL can recover reward functions that are highly\ncorrelated with ground truth ones, and significantly outperforms prior methods\nin terms of policy imitation.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jul 2019 20:57:43 GMT"}], "update_date": "2019-08-01", "authors_parsed": [["Yu", "Lantao", ""], ["Song", "Jiaming", ""], ["Ermon", "Stefano", ""]]}, {"id": "1907.13223", "submitter": "Iulia Comsa", "authors": "Iulia M. Comsa, Krzysztof Potempa, Luca Versari, Thomas Fischbacher,\n  Andrea Gesmundo and Jyrki Alakuijala", "title": "Temporal Coding in Spiking Neural Networks with Alpha Synaptic Function:\n  Learning with Backpropagation", "comments": "Open-source code related to this paper is available at\n  https://github.com/google/ihmehimmeli v2: Added references and added some\n  clarifications for the methods", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG q-bio.NC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The timing of individual neuronal spikes is essential for biological brains\nto make fast responses to sensory stimuli. However, conventional artificial\nneural networks lack the intrinsic temporal coding ability present in\nbiological networks. We propose a spiking neural network model that encodes\ninformation in the relative timing of individual neuron spikes. In\nclassification tasks, the output of the network is indicated by the first\nneuron to spike in the output layer. This temporal coding scheme allows the\nsupervised training of the network with backpropagation, using locally exact\nderivatives of the postsynaptic spike times with respect to presynaptic spike\ntimes. The network operates using a biologically-plausible alpha synaptic\ntransfer function. Additionally, we use trainable synchronisation pulses that\nprovide bias, add flexibility during training and exploit the decay part of the\nalpha function. We show that such networks can be trained successfully on noisy\nBoolean logic tasks and on the MNIST dataset encoded in time. The results show\nthat the spiking neural network outperforms comparable spiking models on MNIST\nand achieves similar quality to fully connected conventional networks with the\nsame architecture. We also find that the spiking network spontaneously\ndiscovers two operating regimes, mirroring the accuracy-speed trade-off\nobserved in human decision-making: a slow regime, where a decision is taken\nafter all hidden neurons have spiked and the accuracy is very high, and a fast\nregime, where a decision is taken very fast but the accuracy is lower. These\nresults demonstrate the computational power of spiking networks with biological\ncharacteristics that encode information in the timing of individual neurons. By\nstudying temporal coding in spiking networks, we aim to create building blocks\ntowards energy-efficient and more complex biologically-inspired neural\narchitectures.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jul 2019 21:05:18 GMT"}, {"version": "v2", "created": "Fri, 30 Aug 2019 11:20:25 GMT"}, {"version": "v3", "created": "Mon, 16 Nov 2020 21:34:55 GMT"}], "update_date": "2020-11-18", "authors_parsed": [["Comsa", "Iulia M.", ""], ["Potempa", "Krzysztof", ""], ["Versari", "Luca", ""], ["Fischbacher", "Thomas", ""], ["Gesmundo", "Andrea", ""], ["Alakuijala", "Jyrki", ""]]}, {"id": "1907.13237", "submitter": "Sajawel Ahmed", "authors": "Manuel Stoeckel, Sajawel Ahmed, Alexander Mehler", "title": "SenseFitting: Sense Level Semantic Specialization of Word Embeddings for\n  Word Sense Disambiguation", "comments": "Sketch for LREC 2020 submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We introduce a neural network-based system of Word Sense Disambiguation (WSD)\nfor German that is based on SenseFitting, a novel method for optimizing WSD. We\noutperform knowledge-based WSD methods by up to 25% F1-score and produce a new\nstate-of-the-art on the German sense-annotated dataset WebCAGe. Our method uses\nthree feature vectors consisting of a) sense, b) gloss, and c) relational\nvectors to represent target senses and to compare them with the vector\ncentroids of sample contexts. Utilizing widely available word embeddings and\nlexical resources, we are able to compensate for the lower resource\navailability of German. SenseFitting builds upon the recently introduced\nsemantic specialization procedure Attract-Repel, and leverages sense level\nsemantic constraints from lexical-semantic networks (e.g. GermaNet) or online\nsocial dictionaries (e.g. Wiktionary) to produce high-quality sense embeddings\nfrom pre-trained word embeddings. We evaluate our sense embeddings with a new\nSimLex-999 based similarity dataset, called SimSense, that we developed for\nthis work. We achieve results that outperform current lemma-based\nspecialization methods for German, making them comparable to results achieved\nfor English.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jul 2019 21:38:16 GMT"}], "update_date": "2019-08-01", "authors_parsed": [["Stoeckel", "Manuel", ""], ["Ahmed", "Sajawel", ""], ["Mehler", "Alexander", ""]]}, {"id": "1907.13246", "submitter": "Caio Ponte", "authors": "Caio Ponte, Carlos Caminha, Rafael Bomfim, Ronaldo Moreira, Vasco\n  Furtado", "title": "A Temporal Clustering Algorithm for Achieving the trade-off between the\n  User Experience and the Equipment Economy in the Context of IoT", "comments": "9 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present here the Temporal Clustering Algorithm (TCA), an incremental\nlearning algorithm applicable to problems of anticipatory computing in the\ncontext of the Internet of Things. This algorithm was tested in a specific\nprediction scenario of consumption of an electric water dispenser typically\nused in tropical countries, in which the ambient temperature is around\n30-degree Celsius. In this context, the user typically wants to drinking iced\nwater therefore uses the cooler function of the dispenser. Real and synthetic\nwater consumption data was used to test a forecasting capacity on how much\nenergy can be saved by predicting the pattern of use of the equipment. In\naddition to using a small constant amount of memory, which allows the algorithm\nto be implemented at the lowest cost, while using microcontrollers with a small\namount of memory (less than 1Kbyte) available on the market. The algorithm can\nalso be configured according to user preference, prioritizing comfort, keeping\nthe water at the desired temperature longer, or prioritizing energy savings.\nThe main result is that the TCA achieved energy savings of up to 40% compared\nto the conventional mode of operation of the dispenser with an average success\nrate higher than 90% in its times of use.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jul 2019 22:17:27 GMT"}], "update_date": "2019-08-01", "authors_parsed": [["Ponte", "Caio", ""], ["Caminha", "Carlos", ""], ["Bomfim", "Rafael", ""], ["Moreira", "Ronaldo", ""], ["Furtado", "Vasco", ""]]}, {"id": "1907.13257", "submitter": "Saptadeep Pal", "authors": "Saptadeep Pal and Eiman Ebrahimi and Arslan Zulfiqar and Yaosheng Fu\n  and Victor Zhang and Szymon Migacz and David Nellans and Puneet Gupta", "title": "Optimizing Multi-GPU Parallelization Strategies for Deep Learning\n  Training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DC stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Deploying deep learning (DL) models across multiple compute devices to train\nlarge and complex models continues to grow in importance because of the demand\nfor faster and more frequent training. Data parallelism (DP) is the most widely\nused parallelization strategy, but as the number of devices in data parallel\ntraining grows, so does the communication overhead between devices.\nAdditionally, a larger aggregate batch size per step leads to statistical\nefficiency loss, i.e., a larger number of epochs are required to converge to a\ndesired accuracy. These factors affect overall training time and beyond a\ncertain number of devices, the speedup from leveraging DP begins to scale\npoorly. In addition to DP, each training step can be accelerated by exploiting\nmodel parallelism (MP). This work explores hybrid parallelization, where each\ndata parallel worker is comprised of more than one device, across which the\nmodel dataflow graph (DFG) is split using MP. We show that at scale, hybrid\ntraining will be more effective at minimizing end-to-end training time than\nexploiting DP alone. We project that for Inception-V3, GNMT, and BigLSTM, the\nhybrid strategy provides an end-to-end training speedup of at least 26.5%, 8%,\nand 22% respectively compared to what DP alone can achieve at scale.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jul 2019 23:20:50 GMT"}], "update_date": "2019-08-01", "authors_parsed": [["Pal", "Saptadeep", ""], ["Ebrahimi", "Eiman", ""], ["Zulfiqar", "Arslan", ""], ["Fu", "Yaosheng", ""], ["Zhang", "Victor", ""], ["Migacz", "Szymon", ""], ["Nellans", "David", ""], ["Gupta", "Puneet", ""]]}, {"id": "1907.13266", "submitter": "Qisheng Wang", "authors": "Qisheng Wang, Keming Feng, Xiao Li, and Shi Jin", "title": "PrecoderNet: Hybrid Beamforming for Millimeter Wave Systems with Deep\n  Reinforcement Learning", "comments": "13 pages, 6 figures", "journal-ref": "IEEE Wireless Communication Letters, 2020", "doi": "10.1109/LWC.2020.3001121", "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this letter, we investigate the hybrid beamforming for millimeter wave\nmassive multiple-input multiple-output (MIMO) system based on deep\nreinforcement learning (DRL). Imperfect channel state information (CSI) is\nassumed to be available at the base station (BS). To achieve high spectral\nefficiency with low time consumption, we propose a novel DRL-based method\ncalled PrecoderNet to design the digital precoder and analog combiner. The DRL\nagent takes the digital beamformer and analog combiner of the previous learning\niteration as state, and these matrices of current learning iteration as action.\nSimulation results demonstrate that the PrecoderNet performs well in spectral\nefficiency, bit error rate (BER), as well as time consumption, and is robust to\nthe CSI imperfection.\n", "versions": [{"version": "v1", "created": "Wed, 31 Jul 2019 00:43:56 GMT"}, {"version": "v2", "created": "Fri, 19 Jun 2020 06:03:14 GMT"}], "update_date": "2020-06-22", "authors_parsed": [["Wang", "Qisheng", ""], ["Feng", "Keming", ""], ["Li", "Xiao", ""], ["Jin", "Shi", ""]]}, {"id": "1907.13276", "submitter": "Ji Meng Loh", "authors": "Laure Berti-Equille, Ji Meng Loh and Saravanan Thirumuruganathan", "title": "Are Outlier Detection Methods Resilient to Sampling?", "comments": "18 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Outlier detection is a fundamental task in data mining and has many\napplications including detecting errors in databases. While there has been\nextensive prior work on methods for outlier detection, modern datasets often\nhave sizes that are beyond the ability of commonly used methods to process the\ndata within a reasonable time. To overcome this issue, outlier detection\nmethods can be trained over samples of the full-sized dataset. However, it is\nnot clear how a model trained on a sample compares with one trained on the\nentire dataset. In this paper, we introduce the notion of resilience to\nsampling for outlier detection methods. Orthogonal to traditional performance\nmetrics such as precision/recall, resilience represents the extent to which the\noutliers detected by a method applied to samples from a sampling scheme matches\nthose when applied to the whole dataset. We propose a novel approach for\nestimating the resilience to sampling of both individual outlier methods and\ntheir ensembles. We performed an extensive experimental study on synthetic and\nreal-world datasets where we study seven diverse and representative outlier\ndetection methods, compare results obtained from samples versus those obtained\nfrom the whole datasets and evaluate the accuracy of our resilience estimates.\nWe observed that the methods are not equally resilient to a given sampling\nscheme and it is often the case that careful joint selection of both the\nsampling scheme and the outlier detection method is necessary. It is our hope\nthat the paper initiates research on designing outlier detection algorithms\nthat are resilient to sampling.\n", "versions": [{"version": "v1", "created": "Wed, 31 Jul 2019 01:32:26 GMT"}], "update_date": "2019-08-01", "authors_parsed": [["Berti-Equille", "Laure", ""], ["Loh", "Ji Meng", ""], ["Thirumuruganathan", "Saravanan", ""]]}, {"id": "1907.13301", "submitter": "Gal Sadeh", "authors": "Gal Sadeh and Edith Cohen and Haim Kaplan", "title": "Sample Complexity Bounds for Influence Maximization", "comments": "33 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Influence maximization (IM) is the problem of finding for a given $s\\geq 1$ a\nset $S$ of $|S|=s$ nodes in a network with maximum influence. With stochastic\ndiffusion models, the influence of a set $S$ of seed nodes is defined as the\nexpectation of its reachability over simulations, where each simulation\nspecifies a deterministic reachability function. Two well-studied special cases\nare the Independent Cascade (IC) and the Linear Threshold (LT) models of Kempe,\nKleinberg, and Tardos. The influence function in stochastic diffusion is\nunbiasedly estimated by averaging reachability values over i.i.d. simulations.\nWe study the IM sample complexity: the number of simulations needed to\ndetermine a $(1-\\epsilon)$-approximate maximizer with confidence $1-\\delta$.\nOur main result is a surprising upper bound of $O( s \\tau \\epsilon^{-2} \\ln\n\\frac{n}{\\delta})$ for a broad class of models that includes IC and LT models\nand their mixtures, where $n$ is the number of nodes and $\\tau$ is the number\nof diffusion steps. Generally $\\tau \\ll n$, so this significantly improves over\nthe generic upper bound of $O(s n \\epsilon^{-2} \\ln \\frac{n}{\\delta})$. Our\nsample complexity bounds are derived from novel upper bounds on the variance of\nthe reachability that allow for small relative error for influential sets and\nadditive error when influence is small. Moreover, we provide a data-adaptive\nmethod that can detect and utilize fewer simulations on models where it\nsuffices. Finally, we provide an efficient greedy design that computes an\n$(1-1/e-\\epsilon)$-approximate maximizer from simulations and applies to any\nsubmodular stochastic diffusion model that satisfies the variance bounds.\n", "versions": [{"version": "v1", "created": "Wed, 31 Jul 2019 03:57:00 GMT"}, {"version": "v2", "created": "Mon, 28 Oct 2019 22:30:43 GMT"}], "update_date": "2019-10-30", "authors_parsed": [["Sadeh", "Gal", ""], ["Cohen", "Edith", ""], ["Kaplan", "Haim", ""]]}, {"id": "1907.13304", "submitter": "Zekun Li", "authors": "Zekun Li, Zeyu Cui, Shu Wu, Xiaoyu Zhang, Liang Wang", "title": "Semi-supervised Compatibility Learning Across Categories for Clothing\n  Matching", "comments": "6 pages, 4 figures, accepted by ICME2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning the compatibility between fashion items across categories is a key\ntask in fashion analysis, which can decode the secret of clothing matching. The\nmain idea of this task is to map items into a latent style space where\ncompatible items stay close. Previous works try to build such a transformation\nby minimizing the distances between annotated compatible items, which require\nmassive item-level supervision. However, these annotated data are expensive to\nobtain and hard to cover the numerous items with various styles in real\napplications. In such cases, these supervised methods fail to achieve\nsatisfactory performances. In this work, we propose a semi-supervised method to\nlearn the compatibility across categories. We observe that the distributions of\ndifferent categories have intrinsic similar structures. Accordingly, the better\ndistributions align, the closer compatible items across these categories\nbecome. To achieve the alignment, we minimize the distances between\ndistributions with unsupervised adversarial learning, and also the distances\nbetween some annotated compatible items which play the role of anchor points to\nhelp align. Experimental results on two real-world datasets demonstrate the\neffectiveness of our method.\n", "versions": [{"version": "v1", "created": "Wed, 31 Jul 2019 04:45:34 GMT"}], "update_date": "2019-08-01", "authors_parsed": [["Li", "Zekun", ""], ["Cui", "Zeyu", ""], ["Wu", "Shu", ""], ["Zhang", "Xiaoyu", ""], ["Wang", "Liang", ""]]}, {"id": "1907.13307", "submitter": "Dmitriy Drusvyatskiy", "authors": "Damek Davis, Dmitriy Drusvyatskiy, Lin Xiao, Junyu Zhang", "title": "From low probability to high confidence in stochastic convex\n  optimization", "comments": "37 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Standard results in stochastic convex optimization bound the number of\nsamples that an algorithm needs to generate a point with small function value\nin expectation. More nuanced high probability guarantees are rare, and\ntypically either rely on \"light-tail\" noise assumptions or exhibit worse sample\ncomplexity. In this work, we show that a wide class of stochastic optimization\nalgorithms for strongly convex problems can be augmented with high confidence\nbounds at an overhead cost that is only logarithmic in the confidence level and\npolylogarithmic in the condition number. The procedure we propose, called\nproxBoost, is elementary and builds on two well-known ingredients: robust\ndistance estimation and the proximal point method. We discuss consequences for\nboth streaming (online) algorithms and offline algorithms based on empirical\nrisk minimization.\n", "versions": [{"version": "v1", "created": "Wed, 31 Jul 2019 04:58:02 GMT"}, {"version": "v2", "created": "Thu, 1 Aug 2019 22:30:06 GMT"}, {"version": "v3", "created": "Thu, 17 Oct 2019 03:16:03 GMT"}], "update_date": "2019-10-18", "authors_parsed": [["Davis", "Damek", ""], ["Drusvyatskiy", "Dmitriy", ""], ["Xiao", "Lin", ""], ["Zhang", "Junyu", ""]]}, {"id": "1907.13308", "submitter": "Thanh Tung Khuat", "authors": "Thanh Tung Khuat, Bogdan Gabrys", "title": "A comparative study of general fuzzy min-max neural networks for pattern\n  classification problems", "comments": "18 pages, 7 figures, 12 tables", "journal-ref": "Neurocomputing, 2019", "doi": "10.1016/j.neucom.2019.12.090", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  General fuzzy min-max (GFMM) neural network is a generalization of fuzzy\nneural networks formed by hyperbox fuzzy sets for classification and clustering\nproblems. Two principle algorithms are deployed to train this type of neural\nnetwork, i.e., incremental learning and agglomerative learning. This paper\npresents a comprehensive empirical study of performance influencing factors,\nadvantages, and drawbacks of the general fuzzy min-max neural network on\npattern classification problems. The subjects of this study include (1) the\nimpact of maximum hyperbox size, (2) the influence of the similarity threshold\nand measures on the agglomerative learning algorithm, (3) the effect of data\npresentation order, (4) comparative performance evaluation of the GFMM with\nother types of fuzzy min-max neural networks and prevalent machine learning\nalgorithms. The experimental results on benchmark datasets widely used in\nmachine learning showed overall strong and weak points of the GFMM classifier.\nThese outcomes also informed potential research directions for this class of\nmachine learning algorithms in the future.\n", "versions": [{"version": "v1", "created": "Wed, 31 Jul 2019 04:58:49 GMT"}, {"version": "v2", "created": "Wed, 8 Jan 2020 06:29:23 GMT"}], "update_date": "2020-01-09", "authors_parsed": [["Khuat", "Thanh Tung", ""], ["Gabrys", "Bogdan", ""]]}, {"id": "1907.13324", "submitter": "David Sarrut", "authors": "David Sarrut and Nils Krah and Jean-Michel L\\'etang", "title": "Generative Adversarial Networks (GAN) for compact beam source modelling\n  in Monte Carlo simulations", "comments": "Phys Med Biol (Accepted Manuscript online 30 August 2019)", "journal-ref": null, "doi": "10.1088/1361-6560/ab3fc1", "report-no": null, "categories": "physics.med-ph cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A method is proposed and evaluated to model large and inconvenient phase\nspace files used in Monte Carlo simulations by a compact Generative Adversarial\nNetwork (GAN). The GAN is trained based on a phase space dataset to create a\nneural network, called Generator (G), allowing G to mimic the multidimensional\ndata distribution of the phase space. At the end of the training process, G is\nstored with about 0.5 million weights, around 10 MB, instead of few GB of the\ninitial file. Particles are then generated with G to replace the phase space\ndataset.\n  This concept is applied to beam models from linear accelerators (linacs) and\nfrom brachytherapy seed models. Simulations using particles from the reference\nphase space on one hand and those generated by the GAN on the other hand were\ncompared. 3D distributions of deposited energy obtained from source\ndistributions generated by the GAN were close to the reference ones, with less\nthan 1% of voxel-by-voxel relative difference. Sharp parts such as the\nbrachytherapy emission lines in the energy spectra were not perfectly modeled\nby the GAN. Detailed statistical properties and limitations of the\nGAN-generated particles still require further investigation, but the proposed\nexploratory approach is already promising and paves the way for a wide range of\napplications.\n", "versions": [{"version": "v1", "created": "Wed, 31 Jul 2019 06:27:04 GMT"}, {"version": "v2", "created": "Fri, 4 Oct 2019 10:58:13 GMT"}], "update_date": "2019-10-07", "authors_parsed": [["Sarrut", "David", ""], ["Krah", "Nils", ""], ["L\u00e9tang", "Jean-Michel", ""]]}, {"id": "1907.13337", "submitter": "Jiawei Zhou", "authors": "Jiawei Zhou and Alexander M. Rush", "title": "Simple Unsupervised Summarization by Contextual Matching", "comments": null, "journal-ref": "Proceedings of the 57th Annual Meeting of the Association for\n  Computational Linguistics, 2019", "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We propose an unsupervised method for sentence summarization using only\nlanguage modeling. The approach employs two language models, one that is\ngeneric (i.e. pretrained), and the other that is specific to the target domain.\nWe show that by using a product-of-experts criteria these are enough for\nmaintaining continuous contextual matching while maintaining output fluency.\nExperiments on both abstractive and extractive sentence summarization data sets\nshow promising results of our method without being exposed to any paired data.\n", "versions": [{"version": "v1", "created": "Wed, 31 Jul 2019 07:11:59 GMT"}], "update_date": "2019-08-01", "authors_parsed": [["Zhou", "Jiawei", ""], ["Rush", "Alexander M.", ""]]}, {"id": "1907.13349", "submitter": "Ke Zhang", "authors": "Ke Zhang, Xinsheng Wang, Yurong Guo, Zhenbing Zhao, Zhanyu Ma, and\n  Tony X. Han", "title": "Competing Ratio Loss for Discriminative Multi-class Image Classification", "comments": "The method proposed in this paper has major technical shortcomings,\n  so we want to withdraw", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The development of deep convolutional neural network architecture is critical\nto the improvement of image classification task performance. A lot of studies\nof image classification based on deep convolutional neural network focus on the\nnetwork structure to improve the image classification performance. Contrary to\nthese studies, we focus on the loss function. Cross-entropy Loss (CEL) is\nwidely used for training a multi-class classification deep convolutional neural\nnetwork. While CEL has been successfully implemented in image classification\ntasks, it only focuses on the posterior probability of correct class when the\nlabels of training images are one-hot. It cannot be discriminated against the\nclasses not belong to correct class (wrong classes) directly. In order to solve\nthe problem of CEL, we propose Competing Ratio Loss (CRL), which calculates the\nposterior probability ratio between the correct class and competing wrong\nclasses to better discriminate the correct class from competing wrong classes,\nincreasing the difference between the negative log likelihood of the correct\nclass and the negative log likelihood of competing wrong classes, widening the\ndifference between the probability of the correct class and the probabilities\nof wrong classes. To demonstrate the effectiveness of our loss function, we\nperform some sets of experiments on different types of image classification\ndatasets, including CIFAR, SVHN, CUB200- 2011, Adience and ImageNet datasets.\nThe experimental results show the effectiveness and robustness of our loss\nfunction on different deep convolutional neural network architectures and\ndifferent image classification tasks, such as fine-grained image\nclassification, hard face age estimation and large-scale image classification.\n", "versions": [{"version": "v1", "created": "Wed, 31 Jul 2019 07:38:04 GMT"}, {"version": "v2", "created": "Thu, 1 Aug 2019 05:42:45 GMT"}], "update_date": "2019-08-02", "authors_parsed": [["Zhang", "Ke", ""], ["Wang", "Xinsheng", ""], ["Guo", "Yurong", ""], ["Zhao", "Zhenbing", ""], ["Ma", "Zhanyu", ""], ["Han", "Tony X.", ""]]}, {"id": "1907.13351", "submitter": "Xiang Zhang", "authors": "Xiang Zhang, Xiaocong Chen, Manqing Dong, Huan Liu, Chang Ge, Lina Yao", "title": "Multi-task Generative Adversarial Learning on Geometrical Shape\n  Reconstruction from EEG Brain Signals", "comments": "12 pages", "journal-ref": "Published on ICONIP 2019", "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Synthesizing geometrical shapes from human brain activities is an interesting\nand meaningful but very challenging topic. Recently, the advancements of deep\ngenerative models like Generative Adversarial Networks (GANs) have supported\nthe object generation from neurological signals. However, the\nElectroencephalograph (EEG)-based shape generation still suffer from the low\nrealism problem. In particular, the generated geometrical shapes lack clear\nedges and fail to contain necessary details. In light of this, we propose a\nnovel multi-task generative adversarial network to convert the individual's EEG\nsignals evoked by geometrical shapes to the original geometry. First, we adopt\na Convolutional Neural Network (CNN) to learn highly informative latent\nrepresentation for the raw EEG signals, which is vital for the subsequent shape\nreconstruction. Next, we build the discriminator based on multi-task learning\nto distinguish and classify fake samples simultaneously, where the mutual\npromotion between different tasks improves the quality of the recovered shapes.\nThen, we propose a semantic alignment constraint in order to force the\nsynthesized samples to approach the real ones in pixel-level, thus producing\nmore compelling shapes. The proposed approach is evaluated over a local dataset\nand the results show that our model outperforms the competitive\nstate-of-the-art baselines.\n", "versions": [{"version": "v1", "created": "Wed, 31 Jul 2019 07:44:35 GMT"}, {"version": "v2", "created": "Fri, 28 Feb 2020 10:12:15 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Zhang", "Xiang", ""], ["Chen", "Xiaocong", ""], ["Dong", "Manqing", ""], ["Liu", "Huan", ""], ["Ge", "Chang", ""], ["Yao", "Lina", ""]]}, {"id": "1907.13353", "submitter": "Zhen Gao", "authors": "Zhen Gao, Maryam Zand and Jianhua Ruan", "title": "A Novel Multiple Classifier Generation and Combination Framework Based\n  on Fuzzy Clustering and Individualized Ensemble Construction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multiple classifier system (MCS) has become a successful alternative for\nimproving classification performance. However, studies have shown inconsistent\nresults for different MCSs, and it is often difficult to predict which MCS\nalgorithm works the best on a particular problem. We believe that the two\ncrucial steps of MCS - base classifier generation and multiple classifier\ncombination, need to be designed coordinately to produce robust results.\n  In this work, we show that for different testing instances, better\nclassifiers may be trained from different subdomains of training instances\nincluding, for example, neighboring instances of the testing instance, or even\ninstances far away from the testing instance. To utilize this intuition, we\npropose Individualized Classifier Ensemble (ICE). ICE groups training data into\noverlapping clusters, builds a classifier for each cluster, and then associates\neach training instance to the top-performing models while taking into account\nmodel types and frequency. In testing, ICE finds the k most similar training\ninstances for a testing instance, then predicts class label of the testing\ninstance by averaging the prediction from models associated with these training\ninstances.\n  Evaluation results on 49 benchmarks show that ICE has a stable improvement on\na significant proportion of datasets over existing MCS methods. ICE provides a\nnovel choice of utilizing internal patterns among instances to improve\nclassification, and can be easily combined with various classification models\nand applied to many application domains.\n", "versions": [{"version": "v1", "created": "Wed, 31 Jul 2019 07:47:54 GMT"}], "update_date": "2019-08-01", "authors_parsed": [["Gao", "Zhen", ""], ["Zand", "Maryam", ""], ["Ruan", "Jianhua", ""]]}, {"id": "1907.13359", "submitter": "Xiang Zhang", "authors": "Xiang Zhang, Xiaocong Chen, Lina Yao, Chang Ge, Manqing Dong", "title": "Deep Neural Network Hyperparameter Optimization with Orthogonal Array\n  Tuning", "comments": null, "journal-ref": "Published on ICONIP 2019", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning algorithms have achieved excellent performance lately in a wide\nrange of fields (e.g., computer version). However, a severe challenge faced by\ndeep learning is the high dependency on hyper-parameters. The algorithm results\nmay fluctuate dramatically under the different configuration of\nhyper-parameters. Addressing the above issue, this paper presents an efficient\nOrthogonal Array Tuning Method (OATM) for deep learning hyper-parameter tuning.\nWe describe the OATM approach in five detailed steps and elaborate on it using\ntwo widely used deep neural network structures (Recurrent Neural Networks and\nConvolutional Neural Networks). The proposed method is compared to the\nstate-of-the-art hyper-parameter tuning methods including manually (e.g., grid\nsearch and random search) and automatically (e.g., Bayesian Optimization) ones.\nThe experiment results state that OATM can significantly save the tuning time\ncompared to the state-of-the-art methods while preserving the satisfying\nperformance. The codes are open in GitHub\n(https://github.com/xiangzhang1015/OATM)\n", "versions": [{"version": "v1", "created": "Wed, 31 Jul 2019 08:15:49 GMT"}, {"version": "v2", "created": "Fri, 28 Feb 2020 10:09:05 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Zhang", "Xiang", ""], ["Chen", "Xiaocong", ""], ["Yao", "Lina", ""], ["Ge", "Chang", ""], ["Dong", "Manqing", ""]]}, {"id": "1907.13372", "submitter": "Umberto Michieli", "authors": "Umberto Michieli and Pietro Zanuttigh", "title": "Incremental Learning Techniques for Semantic Segmentation", "comments": "8 pages, 3 figures, 4 tables", "journal-ref": "International Conference on Computer Vision (ICCV), Workshop on\n  Transferring and Adapting Source Knowledge in Computer Vision (TASK-CV) 2019", "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning architectures exhibit a critical drop of performance due to\ncatastrophic forgetting when they are required to incrementally learn new\ntasks. Contemporary incremental learning frameworks focus on image\nclassification and object detection while in this work we formally introduce\nthe incremental learning problem for semantic segmentation in which a\npixel-wise labeling is considered. To tackle this task we propose to distill\nthe knowledge of the previous model to retain the information about previously\nlearned classes, whilst updating the current model to learn the new ones. We\npropose various approaches working both on the output logits and on\nintermediate features. In opposition to some recent frameworks, we do not store\nany image from previously learned classes and only the last model is needed to\npreserve high accuracy on these classes. The experimental evaluation on the\nPascal VOC2012 dataset shows the effectiveness of the proposed approaches.\n", "versions": [{"version": "v1", "created": "Wed, 31 Jul 2019 09:00:15 GMT"}, {"version": "v2", "created": "Tue, 6 Aug 2019 11:59:30 GMT"}, {"version": "v3", "created": "Thu, 8 Aug 2019 12:43:59 GMT"}, {"version": "v4", "created": "Tue, 17 Sep 2019 07:33:25 GMT"}], "update_date": "2019-09-18", "authors_parsed": [["Michieli", "Umberto", ""], ["Zanuttigh", "Pietro", ""]]}, {"id": "1907.13401", "submitter": "Oliver Gordon Mr", "authors": "O. Gordon, F. Junqueira, P. Moriarty", "title": "Embedding Human Heuristics in Machine-Learning-Enabled Probe Microscopy", "comments": null, "journal-ref": null, "doi": "10.1088/2632-2153/ab42ec", "report-no": null, "categories": "physics.atm-clus cs.LG eess.IV physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Scanning probe microscopists generally do not rely on complete images to\nassess the quality of data acquired during a scan. Instead, assessments of the\nstate of the tip apex, which not only determines the resolution in any scanning\nprobe technique but can also generate a wide array of frustrating artefacts,\nare carried out in real time on the basis of a few lines of an image (and,\ntypically, their associated line profiles.) The very small number of machine\nlearning approaches to probe microscopy published to date, however, involve\nclassifications based on full images. Given that data acquisition is the most\ntime-consuming task during routine tip conditioning, automated methods are thus\ncurrently extremely slow in comparison to the tried-and-trusted strategies and\nheuristics used routinely by probe microscopists. Here, we explore various\nstrategies by which different STM image classes (arising from changes in the\ntip state) can be correctly identified from partial scans. By employing a\nsecondary temporal network and a rolling window of a small group of individual\nscanlines, we find that tip assessment is possible with a small fraction of a\ncomplete image. We achieve this with little-to-no performance penalty -- or,\nindeed, markedly improved performance in some cases -- and introduce a protocol\nto detect the state of the tip apex in real time.\n", "versions": [{"version": "v1", "created": "Wed, 31 Jul 2019 10:07:39 GMT"}], "update_date": "2020-08-31", "authors_parsed": [["Gordon", "O.", ""], ["Junqueira", "F.", ""], ["Moriarty", "P.", ""]]}, {"id": "1907.13411", "submitter": "Pablo Samuel Castro", "authors": "Pablo Samuel Castro, Shijian Li, Daqing Zhang", "title": "Inverse Reinforcement Learning with Multiple Ranked Experts", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of learning to behave optimally in a Markov Decision\nProcess when a reward function is not specified, but instead we have access to\na set of demonstrators of varying performance. We assume the demonstrators are\nclassified into one of k ranks, and use ideas from ordinal regression to find a\nreward function that maximizes the margin between the different ranks. This\napproach is based on the idea that agents should not only learn how to behave\nfrom experts, but also how not to behave from non-experts. We show there are\nMDPs where important differences in the reward function would be hidden from\nexisting algorithms by the behaviour of the expert. Our method is particularly\nuseful for problems where we have access to a large set of agent behaviours\nwith varying degrees of expertise (such as through GPS or cellphones). We\nhighlight the differences between our approach and existing methods using a\nsimple grid domain and demonstrate its efficacy on determining\npassenger-finding strategies for taxi drivers, using a large dataset of GPS\ntrajectories.\n", "versions": [{"version": "v1", "created": "Wed, 31 Jul 2019 10:49:26 GMT"}], "update_date": "2019-08-01", "authors_parsed": [["Castro", "Pablo Samuel", ""], ["Li", "Shijian", ""], ["Zhang", "Daqing", ""]]}, {"id": "1907.13413", "submitter": "Waleed Yousef", "authors": "Waleed A. Yousef", "title": "A Leisurely Look at Versions and Variants of the Cross Validation\n  Estimator", "comments": "The paper is currently under review in Pattern Recognition Letters\n  (PRL)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many versions of cross-validation (CV) exist in the literature; and each\nversion though has different variants. All are used interchangeably by many\npractitioners; yet, without explanation to the connection or difference among\nthem. This article has three contributions. First, it starts by mathematical\nformalization of these different versions and variants that estimate the error\nrate and the Area Under the ROC Curve (AUC) of a classification rule, to show\nthe connection and difference among them. Second, we prove some of their\nproperties and prove that many variants are either redundant or \"not smooth\".\nHence, we suggest to abandon all redundant versions and variants and only keep\nthe leave-one-out, the $K$-fold, and the repeated $K$-fold. We show that the\nlatter is the only among the three versions that is \"smooth\" and hence looks\nmathematically like estimating the mean performance of the classification\nrules. However, empirically, for the known phenomenon of \"weak correlation\",\nwhich we explain mathematically and experimentally, it estimates both\nconditional and mean performance almost with the same accuracy. Third, we\nconclude the article with suggesting two research points that may answer the\nremaining question of whether we can come up with a finalist among the three\nestimators: (1) a comparative study, that is much more comprehensive than those\navailable in literature and conclude no overall winner, is needed to consider a\nwide range of distributions, datasets, and classifiers including complex ones\nobtained via the recent deep learning approach. (2) we sketch the path of\nderiving a rigorous method for estimating the variance of the only \"smooth\"\nversion, repeated $K$-fold CV, rather than those ad-hoc methods available in\nthe literature that ignore the covariance structure among the folds of CV.\n", "versions": [{"version": "v1", "created": "Wed, 31 Jul 2019 10:55:51 GMT"}, {"version": "v2", "created": "Tue, 8 Sep 2020 15:39:25 GMT"}, {"version": "v3", "created": "Wed, 9 Sep 2020 15:50:49 GMT"}], "update_date": "2020-09-10", "authors_parsed": [["Yousef", "Waleed A.", ""]]}, {"id": "1907.13418", "submitter": "Ryutaro Tanno", "authors": "Ryutaro Tanno, Daniel Worrall, Enrico Kaden, Aurobrata Ghosh,\n  Francesco Grussu, Alberto Bizzi, Stamatios N. Sotiropoulos, Antonio\n  Criminisi, Daniel C. Alexander", "title": "Uncertainty Quantification in Deep Learning for Safer Neuroimage\n  Enhancement", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning (DL) has shown great potential in medical image enhancement\nproblems, such as super-resolution or image synthesis. However, to date, little\nconsideration has been given to uncertainty quantification over the output\nimage. Here we introduce methods to characterise different components of\nuncertainty in such problems and demonstrate the ideas using diffusion MRI\nsuper-resolution. Specifically, we propose to account for $intrinsic$\nuncertainty through a heteroscedastic noise model and for $parameter$\nuncertainty through approximate Bayesian inference, and integrate the two to\nquantify $predictive$ uncertainty over the output image. Moreover, we introduce\na method to propagate the predictive uncertainty on a multi-channelled image to\nderived scalar parameters, and separately quantify the effects of intrinsic and\nparameter uncertainty therein. The methods are evaluated for super-resolution\nof two different signal representations of diffusion MR images---DTIs and Mean\nApparent Propagator MRI---and their derived quantities such as MD and FA, on\nmultiple datasets of both healthy and pathological human brains. Results\nhighlight three key benefits of uncertainty modelling for improving the safety\nof DL-based image enhancement systems. Firstly, incorporating uncertainty\nimproves the predictive performance even when test data departs from training\ndata. Secondly, the predictive uncertainty highly correlates with errors, and\nis therefore capable of detecting predictive \"failures\". Results demonstrate\nthat such an uncertainty measure enables subject-specific and voxel-wise risk\nassessment of the output images. Thirdly, we show that the method for\ndecomposing predictive uncertainty into its independent sources provides\nhigh-level \"explanations\" for the performance by quantifying how much\nuncertainty arises from the inherent difficulty of the task or the limited\ntraining examples.\n", "versions": [{"version": "v1", "created": "Wed, 31 Jul 2019 11:17:45 GMT"}], "update_date": "2019-08-01", "authors_parsed": [["Tanno", "Ryutaro", ""], ["Worrall", "Daniel", ""], ["Kaden", "Enrico", ""], ["Ghosh", "Aurobrata", ""], ["Grussu", "Francesco", ""], ["Bizzi", "Alberto", ""], ["Sotiropoulos", "Stamatios N.", ""], ["Criminisi", "Antonio", ""], ["Alexander", "Daniel C.", ""]]}, {"id": "1907.13432", "submitter": "Dong Liu", "authors": "Dong Liu, Minh Th\\`anh Vu, Saikat Chatterjee, Lars K. Rasmussen", "title": "Neural Network based Explicit Mixture Models and\n  Expectation-maximization based Learning", "comments": "IJCNN 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose two neural network based mixture models in this article. The\nproposed mixture models are explicit in nature. The explicit models have\nanalytical forms with the advantages of computing likelihood and efficiency of\ngenerating samples. Computation of likelihood is an important aspect of our\nmodels. Expectation-maximization based algorithms are developed for learning\nparameters of the proposed models. We provide sufficient conditions to realize\nthe expectation-maximization based learning. The main requirements are\ninvertibility of neural networks that are used as generators and Jacobian\ncomputation of functional form of the neural networks. The requirements are\npractically realized using a flow-based neural network. In our first mixture\nmodel, we use multiple flow-based neural networks as generators. Naturally the\nmodel is complex. A single latent variable is used as the common input to all\nthe neural networks. The second mixture model uses a single flow-based neural\nnetwork as a generator to reduce complexity. The single generator has a latent\nvariable input that follows a Gaussian mixture distribution. We demonstrate\nefficiency of proposed mixture models through extensive experiments for\ngenerating samples and maximum likelihood based classification.\n", "versions": [{"version": "v1", "created": "Wed, 31 Jul 2019 11:57:17 GMT"}, {"version": "v2", "created": "Sun, 24 May 2020 19:57:55 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Liu", "Dong", ""], ["Vu", "Minh Th\u00e0nh", ""], ["Chatterjee", "Saikat", ""], ["Rasmussen", "Lars K.", ""]]}, {"id": "1907.13434", "submitter": "Yuwen Yang", "authors": "Yuwen Yang, Hoda Bidkhori, Jayant Rajgopal", "title": "Optimizing vaccine distribution networks in low and middle-income\n  countries", "comments": null, "journal-ref": "Omega 99 (2021) 102197", "doi": "10.1016/j.omega.2020.102197", "report-no": null, "categories": "physics.soc-ph cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Vaccination has been proven to be the most effective method to prevent\ninfectious diseases. However, there are still millions of children in low and\nmiddle-income countries who are not covered by routine vaccines and remain at\nrisk. The World Health Organization - Expanded Programme on Immunization\n(WHO-EPI) was designed to provide universal childhood vaccine access for\nchildren across the world and in this work, we address the design of the\ndistribution network for WHO-EPI vaccines. In particular, we formulate the\nnetwork design problem as a mixed integer program (MIP) and present a new\nalgorithm for typical problems that are too large to be solved using commercial\nMIP software. We test the algorithm using data derived from four different\ncountries in sub-Saharan Africa and show that the algorithm is able to obtain\nhigh-quality solutions for even the largest problems within a few minutes.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jul 2019 00:49:13 GMT"}, {"version": "v2", "created": "Wed, 7 Oct 2020 22:57:53 GMT"}], "update_date": "2021-04-30", "authors_parsed": [["Yang", "Yuwen", ""], ["Bidkhori", "Hoda", ""], ["Rajgopal", "Jayant", ""]]}, {"id": "1907.13440", "submitter": "William Guss", "authors": "William H. Guss, Brandon Houghton, Nicholay Topin, Phillip Wang,\n  Cayden Codel, Manuela Veloso, Ruslan Salakhutdinov", "title": "MineRL: A Large-Scale Dataset of Minecraft Demonstrations", "comments": "Accepted at IJCAI 2019, 7 pages, 6 figures. arXiv admin note: text\n  overlap with arXiv:1904.10079", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The sample inefficiency of standard deep reinforcement learning methods\nprecludes their application to many real-world problems. Methods which leverage\nhuman demonstrations require fewer samples but have been researched less. As\ndemonstrated in the computer vision and natural language processing\ncommunities, large-scale datasets have the capacity to facilitate research by\nserving as an experimental and benchmarking platform for new methods. However,\nexisting datasets compatible with reinforcement learning simulators do not have\nsufficient scale, structure, and quality to enable the further development and\nevaluation of methods focused on using human examples. Therefore, we introduce\na comprehensive, large-scale, simulator-paired dataset of human demonstrations:\nMineRL. The dataset consists of over 60 million automatically annotated\nstate-action pairs across a variety of related tasks in Minecraft, a dynamic,\n3D, open-world environment. We present a novel data collection scheme which\nallows for the ongoing introduction of new tasks and the gathering of complete\nstate information suitable for a variety of methods. We demonstrate the\nhierarchality, diversity, and scale of the MineRL dataset. Further, we show the\ndifficulty of the Minecraft domain along with the potential of MineRL in\ndeveloping techniques to solve key research challenges within it.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jul 2019 18:10:30 GMT"}], "update_date": "2019-08-01", "authors_parsed": [["Guss", "William H.", ""], ["Houghton", "Brandon", ""], ["Topin", "Nicholay", ""], ["Wang", "Phillip", ""], ["Codel", "Cayden", ""], ["Veloso", "Manuela", ""], ["Salakhutdinov", "Ruslan", ""]]}, {"id": "1907.13443", "submitter": "Jo\\~ao Pereira", "authors": "Jo\\~ao Pereira and Albert Groen and Erik Stroes and Evgeni Levin", "title": "Graph Space Embedding", "comments": "7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose the Graph Space Embedding (GSE), a technique that maps the input\ninto a space where interactions are implicitly encoded, with little\ncomputations required. We provide theoretical results on an optimal regime for\nthe GSE, namely a feasibility region for its parameters, and demonstrate the\nexperimental relevance of our findings. Next, we introduce a strategy to gain\ninsight on which interactions are responsible for the certain predictions,\npaving the way for a far more transparent model. In an empirical evaluation on\na real-world clinical cohort containing patients with suspected coronary artery\ndisease, the GSE achieves far better performance than traditional algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 31 Jul 2019 12:21:50 GMT"}], "update_date": "2019-08-01", "authors_parsed": [["Pereira", "Jo\u00e3o", ""], ["Groen", "Albert", ""], ["Stroes", "Erik", ""], ["Levin", "Evgeni", ""]]}, {"id": "1907.13463", "submitter": "Feihu Huang", "authors": "Feihu Huang, Shangqian Gao, Jian Pei and Heng Huang", "title": "Nonconvex Zeroth-Order Stochastic ADMM Methods with Lower Function Query\n  Complexity", "comments": "34 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Zeroth-order methods powerful optimization tools for solving many machine\nlearning problems because it only need function values (not gradient) in the\noptimization. Recently, although many zeroth-order methods have been developed,\nthese approaches still have two main drawbacks: 1) high function query\ncomplexity; 2) not being well suitable for solving the problems with complex\npenalties and constraints. To address these challenging drawbacks, in this\npaper, we propose a class of faster zeroth-order stochastic alternating\ndirection method of multipliers (ADMM) methods (ZO-SPIDER-ADMM) to solve the\nnonconvex finite-sum problems with multiple nonsmooth penalties. Moreover, we\nprove that the ZO-SPIDER-ADMM methods can achieve a lower function query\ncomplexity of $O(nd+dn^{\\frac{1}{2}}\\epsilon^{-1})$ for finding an\n$\\epsilon$-stationary point, which improves the existing best nonconvex\nzeroth-order ADMM methods by a factor of $O(d^{\\frac{1}{3}}n^{\\frac{1}{6}})$,\nwhere $n$ and $d$ denote the sample size and dimension of data, respectively.\nAt the same time, we propose a class of faster zeroth-order online ADMM methods\n(ZOO-ADMM+) to solve the nonconvex online problems with multiple nonsmooth\npenalties. We also prove that the proposed ZOO-ADMM+ methods can achieve a\nlower function query complexity of $O(d\\epsilon^{-\\frac{3}{2}})$, which\nimproves the existing best result by a factor of $O(\\epsilon^{-\\frac{1}{2}})$.\nExtensive experimental results on the structure adversarial attack on black-box\ndeep neural networks demonstrate the efficiency of our new algorithms.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jul 2019 02:21:43 GMT"}, {"version": "v2", "created": "Tue, 4 Aug 2020 15:17:25 GMT"}, {"version": "v3", "created": "Sat, 22 Aug 2020 19:52:49 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Huang", "Feihu", ""], ["Gao", "Shangqian", ""], ["Pei", "Jian", ""], ["Huang", "Heng", ""]]}, {"id": "1907.13485", "submitter": "Bastian Rieck", "authors": "Bastian Rieck and Markus Banagl and Filip Sadlo and Heike Leitte", "title": "Persistent Intersection Homology for the Analysis of Discrete Data", "comments": "Topology-based Methods in Visualization 2017", "journal-ref": null, "doi": "10.1007/978-3-030-43036-8_3", "report-no": null, "categories": "math.AT cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Topological data analysis is becoming increasingly relevant to support the\nanalysis of unstructured data sets. A common assumption in data analysis is\nthat the data set is a sample---not necessarily a uniform one---of some\nhigh-dimensional manifold. In such cases, persistent homology can be\nsuccessfully employed to extract features, remove noise, and compare data sets.\nThe underlying problems in some application domains, however, turn out to\nrepresent multiple manifolds with different dimensions. Algebraic topology\ntypically analyzes such problems using intersection homology, an extension of\nhomology that is capable of handling configurations with singularities. In this\npaper, we describe how the persistent variant of intersection homology can be\nused to assist data analysis in visualization. We point out potential pitfalls\nin approximating data sets with singularities and give strategies for resolving\nthem.\n", "versions": [{"version": "v1", "created": "Wed, 31 Jul 2019 13:18:59 GMT"}], "update_date": "2021-01-20", "authors_parsed": [["Rieck", "Bastian", ""], ["Banagl", "Markus", ""], ["Sadlo", "Filip", ""], ["Leitte", "Heike", ""]]}, {"id": "1907.13496", "submitter": "Bastian Rieck", "authors": "Bastian Rieck and Filip Sadlo and Heike Leitte", "title": "Topological Machine Learning with Persistence Indicator Functions", "comments": "Topology-based Methods in Visualization 2017", "journal-ref": null, "doi": "10.1007/978-3-030-43036-8_6", "report-no": null, "categories": "math.AT cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Techniques from computational topology, in particular persistent homology,\nare becoming increasingly relevant for data analysis. Their stable metrics\npermit the use of many distance-based data analysis methods, such as\nmultidimensional scaling, while providing a firm theoretical ground. Many\nmodern machine learning algorithms, however, are based on kernels. This paper\npresents persistence indicator functions (PIFs), which summarize persistence\ndiagrams, i.e., feature descriptors in topological data analysis. PIFs can be\ncalculated and compared in linear time and have many beneficial properties,\nsuch as the availability of a kernel-based similarity measure. We demonstrate\ntheir usage in common data analysis scenarios, such as confidence set\nestimation and classification of complex structured data.\n", "versions": [{"version": "v1", "created": "Wed, 31 Jul 2019 13:31:12 GMT"}], "update_date": "2021-01-20", "authors_parsed": [["Rieck", "Bastian", ""], ["Sadlo", "Filip", ""], ["Leitte", "Heike", ""]]}, {"id": "1907.13511", "submitter": "Joel Shor", "authors": "Joel Shor, Dotan Emanuel, Oran Lang, Omry Tuval, Michael Brenner,\n  Julie Cattiau, Fernando Vieira, Maeve McNally, Taylor Charbonneau, Melissa\n  Nollstadt, Avinatan Hassidim, Yossi Matias", "title": "Personalizing ASR for Dysarthric and Accented Speech with Limited Data", "comments": "5 pages", "journal-ref": null, "doi": "10.21437/Interspeech.2019-1427", "report-no": null, "categories": "cs.CL cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic speech recognition (ASR) systems have dramatically improved over\nthe last few years. ASR systems are most often trained from 'typical' speech,\nwhich means that underrepresented groups don't experience the same level of\nimprovement. In this paper, we present and evaluate finetuning techniques to\nimprove ASR for users with non-standard speech. We focus on two types of\nnon-standard speech: speech from people with amyotrophic lateral sclerosis\n(ALS) and accented speech. We train personalized models that achieve 62% and\n35% relative WER improvement on these two groups, bringing the absolute WER for\nALS speakers, on a test set of message bank phrases, down to 10% for mild\ndysarthria and 20% for more serious dysarthria. We show that 71% of the\nimprovement comes from only 5 minutes of training data. Finetuning a particular\nsubset of layers (with many fewer parameters) often gives better results than\nfinetuning the entire model. This is the first step towards building state of\nthe art ASR models for dysarthric speech.\n", "versions": [{"version": "v1", "created": "Wed, 31 Jul 2019 14:07:27 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Shor", "Joel", ""], ["Emanuel", "Dotan", ""], ["Lang", "Oran", ""], ["Tuval", "Omry", ""], ["Brenner", "Michael", ""], ["Cattiau", "Julie", ""], ["Vieira", "Fernando", ""], ["McNally", "Maeve", ""], ["Charbonneau", "Taylor", ""], ["Nollstadt", "Melissa", ""], ["Hassidim", "Avinatan", ""], ["Matias", "Yossi", ""]]}, {"id": "1907.13513", "submitter": "Ahmad Ilham", "authors": "Andy Arief Setyawan, Ahmad Ilham", "title": "A novel framework of the fuzzy c-means distances problem based weighted\n  distance", "comments": "25 pages, 6 figure, was submitted online submission at the Applied\n  Computing and Informatics, Elsevier, July 18, 2019. King Saud University,\n  Riyadh, Saudi Arabia", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Clustering is one of the major roles in data mining that is widely\napplication in pattern recognition and image segmentation. Fuzzy C-means (FCM)\nis the most used clustering algorithm that proven efficient, fast and easy to\nimplement, however, FCM uses the Euclidean distance that often leads to\nclustering errors, especially when handling multidimensional and noisy data. In\nthe last few years, many distances metric have been proposed by researchers to\nimprove the performance of the FCM algorithms, and the majority of researchers\npropose weighted distance. In this paper, we proposed Canberra Weighted\nDistance to improved performance of the FCM algorithm. The experimental result\nusing the UCI data set show the proposed method is superior to the original\nmethod and other clustering methods.\n", "versions": [{"version": "v1", "created": "Wed, 31 Jul 2019 14:10:19 GMT"}], "update_date": "2019-08-01", "authors_parsed": [["Setyawan", "Andy Arief", ""], ["Ilham", "Ahmad", ""]]}, {"id": "1907.13517", "submitter": "Song-Kyoo Amang Kim Ph.D.", "authors": "Amang Song-Kyoo Kim, Chan Yeob Yeun, Paul D. Yoo", "title": "An Enhanced Machine Learning-based Biometric Authentication System Using\n  RR-Interval Framed Electrocardiograms", "comments": "The paper has been accepted and published in the IEEE Access", "journal-ref": "IEEE Access 7 (2019), pp. 168669-168674", "doi": "10.1109/ACCESS.2019.2954576", "report-no": null, "categories": "cs.CR cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is targeted in the area of biometric data enabled security system\nbased on the machine learning for the digital health. The disadvantages of\ntraditional authentication systems include the risks of forgetfulness, loss,\nand theft. Biometric authentication is therefore rapidly replacing traditional\nauthentication methods and is becoming an everyday part of life. The\nelectrocardiogram (ECG) was recently introduced as a biometric authentication\nsystem suitable for security checks. The proposed authentication system helps\ninvestigators studying ECG-based biometric authentication techniques to reshape\ninput data by slicing based on the RR-interval, and defines the Overall\nPerformance (OP), which is the combined performance metric of multiple\nauthentication measures. We evaluated the performance of the proposed system\nusing a confusion matrix and achieved up to 95% accuracy by compact data\nanalysis. We also used the Amang ECG (amgecg) toolbox in MATLAB to investigate\nthe upper-range control limit (UCL) based on the mean square error, which\ndirectly affects three authentication performance metrics: the accuracy, the\nnumber of accepted samples, and the OP. Using this approach, we found that the\nOP can be optimized by using a UCL of 0.0028, which indicates 61 accepted\nsamples out of 70 and ensures that the proposed authentication system achieves\nan accuracy of 95%.\n", "versions": [{"version": "v1", "created": "Sat, 27 Jul 2019 08:50:50 GMT"}, {"version": "v2", "created": "Wed, 7 Aug 2019 05:34:11 GMT"}, {"version": "v3", "created": "Sun, 1 Dec 2019 01:46:56 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Kim", "Amang Song-Kyoo", ""], ["Yeun", "Chan Yeob", ""], ["Yoo", "Paul D.", ""]]}, {"id": "1907.13525", "submitter": "Tiago Botari T.B.", "authors": "Tiago Botari, Rafael Izbicki, and Andre C. P. L. F. de Carvalho", "title": "Local Interpretation Methods to Machine Learning Using the Domain of the\n  Feature Space", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As machine learning becomes an important part of many real world applications\naffecting human lives, new requirements, besides high predictive accuracy,\nbecome important. One important requirement is transparency, which has been\nassociated with model interpretability. Many machine learning algorithms induce\nmodels difficult to interpret, named black box. Moreover, people have\ndifficulty to trust models that cannot be explained. In particular for machine\nlearning, many groups are investigating new methods able to explain black box\nmodels. These methods usually look inside the black models to explain their\ninner work. By doing so, they allow the interpretation of the decision making\nprocess used by black box models. Among the recently proposed model\ninterpretation methods, there is a group, named local estimators, which are\ndesigned to explain how the label of particular instance is predicted. For\nsuch, they induce interpretable models on the neighborhood of the instance to\nbe explained. Local estimators have been successfully used to explain specific\npredictions. Although they provide some degree of model interpretability, it is\nstill not clear what is the best way to implement and apply them. Open\nquestions include: how to best define the neighborhood of an instance? How to\ncontrol the trade-off between the accuracy of the interpretation method and its\ninterpretability? How to make the obtained solution robust to small variations\non the instance to be explained? To answer to these questions, we propose and\ninvestigate two strategies: (i) using data instance properties to provide\nimproved explanations, and (ii) making sure that the neighborhood of an\ninstance is properly defined by taking the geometry of the domain of the\nfeature space into account. We evaluate these strategies in a regression task\nand present experimental results that show that they can improve local\nexplanations.\n", "versions": [{"version": "v1", "created": "Wed, 31 Jul 2019 14:28:55 GMT"}], "update_date": "2019-08-01", "authors_parsed": [["Botari", "Tiago", ""], ["Izbicki", "Rafael", ""], ["de Carvalho", "Andre C. P. L. F.", ""]]}, {"id": "1907.13548", "submitter": "Alessio Russo", "authors": "Alessio Russo, Alexandre Proutiere", "title": "Optimal Attacks on Reinforcement Learning Policies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Control policies, trained using the Deep Reinforcement Learning, have been\nrecently shown to be vulnerable to adversarial attacks introducing even very\nsmall perturbations to the policy input. The attacks proposed so far have been\ndesigned using heuristics, and build on existing adversarial example crafting\ntechniques used to dupe classifiers in supervised learning. In contrast, this\npaper investigates the problem of devising optimal attacks, depending on a\nwell-defined attacker's objective, e.g., to minimize the main agent average\nreward. When the policy and the system dynamics, as well as rewards, are known\nto the attacker, a scenario referred to as a white-box attack, designing\noptimal attacks amounts to solving a Markov Decision Process. For what we call\nblack-box attacks, where neither the policy nor the system is known, optimal\nattacks can be trained using Reinforcement Learning techniques. Through\nnumerical experiments, we demonstrate the efficiency of our attacks compared to\nexisting attacks (usually based on Gradient methods). We further quantify the\npotential impact of attacks and establish its connection to the smoothness of\nthe policy under attack. Smooth policies are naturally less prone to attacks\n(this explains why Lipschitz policies, with respect to the state, are more\nresilient). Finally, we show that from the main agent perspective, the system\nuncertainties and the attacker can be modeled as a Partially Observable Markov\nDecision Process. We actually demonstrate that using Reinforcement Learning\ntechniques tailored to POMDP (e.g. using Recurrent Neural Networks) leads to\nmore resilient policies.\n", "versions": [{"version": "v1", "created": "Wed, 31 Jul 2019 15:16:00 GMT"}], "update_date": "2019-08-02", "authors_parsed": [["Russo", "Alessio", ""], ["Proutiere", "Alexandre", ""]]}, {"id": "1907.13553", "submitter": "Anupama Nandi", "authors": "Anupama Nandi and Raef Bassily", "title": "Privately Answering Classification Queries in the Agnostic PAC Model", "comments": "Made a a small tweak in the analysis to save a factor of $1/\\epsilon$", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We revisit the problem of differentially private release of classification\nqueries. In this problem, the goal is to design an algorithm that can\naccurately answer a sequence of classification queries based on a private\ntraining set while ensuring differential privacy. We formally study this\nproblem in the agnostic PAC model and derive a new upper bound on the private\nsample complexity. Our results improve over those obtained in a recent work\n[BTT18] for the agnostic PAC setting. In particular, we give an improved\nconstruction that yields a tighter upper bound on the sample complexity.\nMoreover, unlike [BTT18], our accuracy guarantee does not involve any blow-up\nin the approximation error associated with the given hypothesis class.\n  Given any hypothesis class with VC-dimension $d$, we show that our\nconstruction can privately answer up to $m$ classification queries with average\nexcess error $\\alpha$ using a private sample of size $\\approx\n\\frac{d}{\\alpha^2}\\,\\max\\left(1, \\sqrt{m}\\,\\alpha^{3/2}\\right)$. Using recent\nresults on private learning with auxiliary public data, we extend our\nconstruction to show that one can privately answer any number of classification\nqueries with average excess error $\\alpha$ using a private sample of size\n$\\approx \\frac{d}{\\alpha^2}\\,\\max\\left(1, \\sqrt{d}\\,\\alpha\\right)$. When\n$\\alpha=O\\left(\\frac{1}{\\sqrt{d}}\\right)$, our private sample complexity bound\nis essentially optimal.\n", "versions": [{"version": "v1", "created": "Wed, 31 Jul 2019 15:28:12 GMT"}, {"version": "v2", "created": "Wed, 25 Sep 2019 05:22:10 GMT"}, {"version": "v3", "created": "Wed, 4 Dec 2019 04:09:58 GMT"}], "update_date": "2019-12-05", "authors_parsed": [["Nandi", "Anupama", ""], ["Bassily", "Raef", ""]]}, {"id": "1907.13561", "submitter": "Vahab Mostafapour", "authors": "Vahab Mostafapour, O\\u{g}uz Dikenelli", "title": "Attention-Wrapped Hierarchical BLSTMs for DDI Extraction", "comments": "7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Drug-Drug Interactions (DDIs) Extraction refers to the efforts to generate\nhand-made or automatic tools to extract embedded information from text and\nliterature in the biomedical domain.\n  Because of restrictions in hand-made efforts and their lower speed,\nMachine-Learning, or Deep-Learning approaches have become more popular for\nextracting DDIs. In this study, we propose a novel and generic Deep-Learning\nmodel which wraps Hierarchical Bidirectional LSTMs with two Attention\nMechanisms that outperforms state-of-the-art models for DDIs Extraction, based\non the DDIExtraction-2013 corpora. This model has obtained the macro F1-score\nof 0.785, and the precision of 0.80.\n", "versions": [{"version": "v1", "created": "Wed, 31 Jul 2019 15:42:26 GMT"}], "update_date": "2019-08-01", "authors_parsed": [["Mostafapour", "Vahab", ""], ["Dikenelli", "O\u011fuz", ""]]}, {"id": "1907.13612", "submitter": "Roberto Mag\\'an-Carri\\'on Dr.", "authors": "Roberto Mag\\'an-Carri\\'on, Jos\\'e Camacho, Gabriel Maci\\'a-Fern\\'andez\n  and \\'Angel Ru\\'iz-Zafra", "title": "MSNM-Sensor: An Applied Network Monitoring Tool for Anomaly Detection in\n  Complex Networks and Systems", "comments": null, "journal-ref": "International Journal of Distributed Sensor Networks-2020", "doi": "10.1177/1550147720921309", "report-no": null, "categories": "cs.CR cs.LG cs.NI stat.OT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Technology evolves quickly. Low-cost and ready-to-connect devices are\ndesigned to provide new services and applications. Smart grids or smart\nhealthcare systems are some examples of these applications, all of which are in\nthe context of smart cities. In this total-connectivity scenario, some security\nissues arise since the larger the number of connected devices is, the greater\nthe surface attack dimension. In this way, new solutions for monitoring and\ndetecting security events are needed to address new challenges brought about by\nthis scenario, among others, the large number of devices to monitor, the large\namount of data to manage and the real-time requirement to provide quick\nsecurity event detection and, consequently, quick response to attacks. In this\nwork, a practical and ready-to-use tool for monitoring and detecting security\nevents in these environments is developed and introduced. The tool is based on\nthe Multivariate Statistical Network Monitoring (MSNM) methodology for\nmonitoring and anomaly detection and we call it MSNM-Sensor. Although it is in\nits early development stages, experimental results based on the detection of\nwell-known attacks in hierarchical network systems prove the suitability of\nthis tool for more complex scenarios, such as those found in smart cities or\nIoT ecosystems.\n", "versions": [{"version": "v1", "created": "Wed, 31 Jul 2019 17:25:15 GMT"}, {"version": "v2", "created": "Sun, 16 Feb 2020 20:38:32 GMT"}], "update_date": "2021-01-12", "authors_parsed": [["Mag\u00e1n-Carri\u00f3n", "Roberto", ""], ["Camacho", "Jos\u00e9", ""], ["Maci\u00e1-Fern\u00e1ndez", "Gabriel", ""], ["Ru\u00edz-Zafra", "\u00c1ngel", ""]]}, {"id": "1907.13616", "submitter": "Krishnakumar Balasubramanian", "authors": "Abhishek Roy, Krishnakumar Balasubramanian, Saeed Ghadimi, Prasant\n  Mohapatra", "title": "Multi-Point Bandit Algorithms for Nonstationary Online Nonconvex\n  Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.DS cs.LG math.OC math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bandit algorithms have been predominantly analyzed in the convex setting with\nfunction-value based stationary regret as the performance measure. In this\npaper, motivated by online reinforcement learning problems, we propose and\nanalyze bandit algorithms for both general and structured nonconvex problems\nwith nonstationary (or dynamic) regret as the performance measure, in both\nstochastic and non-stochastic settings. First, for general nonconvex functions,\nwe consider nonstationary versions of first-order and second-order stationary\nsolutions as a regret measure, motivated by similar performance measures for\noffline nonconvex optimization. In the case of second-order stationary solution\nbased regret, we propose and analyze online and bandit versions of the cubic\nregularized Newton's method. The bandit version is based on estimating the\nHessian matrices in the bandit setting, based on second-order Gaussian Stein's\nidentity. Our nonstationary regret bounds in terms of second-order stationary\nsolutions have interesting consequences for avoiding saddle points in the\nbandit setting. Next, for weakly quasi convex functions and monotone weakly\nsubmodular functions we consider nonstationary regret measures in terms of\nfunction-values; such structured classes of nonconvex functions enable one to\nconsider regret measure defined in terms of function values, similar to convex\nfunctions. For this case of function-value, and first-order stationary solution\nbased regret measures, we provide regret bounds in both the low- and\nhigh-dimensional settings, for some scenarios.\n", "versions": [{"version": "v1", "created": "Wed, 31 Jul 2019 17:32:07 GMT"}, {"version": "v2", "created": "Wed, 11 Sep 2019 07:06:09 GMT"}], "update_date": "2019-09-12", "authors_parsed": [["Roy", "Abhishek", ""], ["Balasubramanian", "Krishnakumar", ""], ["Ghadimi", "Saeed", ""], ["Mohapatra", "Prasant", ""]]}, {"id": "1907.13625", "submitter": "Michael Tschannen", "authors": "Michael Tschannen, Josip Djolonga, Paul K. Rubenstein, Sylvain Gelly,\n  Mario Lucic", "title": "On Mutual Information Maximization for Representation Learning", "comments": "ICLR 2020. Michael Tschannen and Josip Djolonga contributed equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many recent methods for unsupervised or self-supervised representation\nlearning train feature extractors by maximizing an estimate of the mutual\ninformation (MI) between different views of the data. This comes with several\nimmediate problems: For example, MI is notoriously hard to estimate, and using\nit as an objective for representation learning may lead to highly entangled\nrepresentations due to its invariance under arbitrary invertible\ntransformations. Nevertheless, these methods have been repeatedly shown to\nexcel in practice. In this paper we argue, and provide empirical evidence, that\nthe success of these methods cannot be attributed to the properties of MI\nalone, and that they strongly depend on the inductive bias in both the choice\nof feature extractor architectures and the parametrization of the employed MI\nestimators. Finally, we establish a connection to deep metric learning and\nargue that this interpretation may be a plausible explanation for the success\nof the recently introduced methods.\n", "versions": [{"version": "v1", "created": "Wed, 31 Jul 2019 17:50:51 GMT"}, {"version": "v2", "created": "Thu, 23 Jan 2020 09:08:54 GMT"}], "update_date": "2020-01-24", "authors_parsed": [["Tschannen", "Michael", ""], ["Djolonga", "Josip", ""], ["Rubenstein", "Paul K.", ""], ["Gelly", "Sylvain", ""], ["Lucic", "Mario", ""]]}, {"id": "1907.13627", "submitter": "Yordan Hristov", "authors": "Yordan Hristov, Daniel Angelov, Michael Burke, Alex Lascarides,\n  Subramanian Ramamoorthy", "title": "Disentangled Relational Representations for Explaining and Learning from\n  Demonstration", "comments": "15 pages, 12 figures, accepted at the Conference on Robot Learning\n  (CoRL) 2019, Osaka, Japan", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning from demonstration is an effective method for human users to\ninstruct desired robot behaviour. However, for most non-trivial tasks of\npractical interest, efficient learning from demonstration depends crucially on\ninductive bias in the chosen structure for rewards/costs and policies. We\naddress the case where this inductive bias comes from an exchange with a human\nuser. We propose a method in which a learning agent utilizes the information\nbottleneck layer of a high-parameter variational neural model, with auxiliary\nloss terms, in order to ground abstract concepts such as spatial relations. The\nconcepts are referred to in natural language instructions and are manifested in\nthe high-dimensional sensory input stream the agent receives from the world. We\nevaluate the properties of the latent space of the learned model in a\nphotorealistic synthetic environment and particularly focus on examining its\nusability for downstream tasks. Additionally, through a series of controlled\ntable-top manipulation experiments, we demonstrate that the learned manifold\ncan be used to ground demonstrations as symbolic plans, which can then be\nexecuted on a PR2 robot.\n", "versions": [{"version": "v1", "created": "Wed, 31 Jul 2019 17:52:25 GMT"}, {"version": "v2", "created": "Sun, 6 Oct 2019 14:53:22 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Hristov", "Yordan", ""], ["Angelov", "Daniel", ""], ["Burke", "Michael", ""], ["Lascarides", "Alex", ""], ["Ramamoorthy", "Subramanian", ""]]}]