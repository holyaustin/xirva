[{"id": "1702.00001", "submitter": "Emilie Kaufmann", "authors": "Emilie Kaufmann (SEQUEL, CRIStAL, CNRS), Aur\\'elien Garivier (IMT)", "title": "Learning the distribution with largest mean: two bandit frameworks", "comments": null, "journal-ref": "ESAIM: Proceedings and Surveys, EDP Sciences, A Para{\\^i}tre,\n  2017, pp.1 - 10", "doi": null, "report-no": null, "categories": "cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the past few years, the multi-armed bandit model has become increasingly\npopular in the machine learning community, partly because of applications\nincluding online content optimization. This paper reviews two different\nsequential learning tasks that have been considered in the bandit literature ;\nthey can be formulated as (sequentially) learning which distribution has the\nhighest mean among a set of distributions, with some constraints on the\nlearning process. For both of them (regret minimization and best arm\nidentification) we present recent, asymptotically optimal algorithms. We\ncompare the behaviors of the sampling rule of each algorithm as well as the\ncomplexity terms associated to each problem.\n", "versions": [{"version": "v1", "created": "Tue, 31 Jan 2017 07:45:32 GMT"}, {"version": "v2", "created": "Fri, 24 Mar 2017 07:30:56 GMT"}, {"version": "v3", "created": "Tue, 7 Nov 2017 07:06:06 GMT"}], "update_date": "2017-11-08", "authors_parsed": [["Kaufmann", "Emilie", "", "SEQUEL, CRIStAL, CNRS"], ["Garivier", "Aur\u00e9lien", "", "IMT"]]}, {"id": "1702.00020", "submitter": "Marwin Segler", "authors": "Marwin Segler, Mike Preu{\\ss}, Mark P. Waller", "title": "Towards \"AlphaChem\": Chemical Synthesis Planning with Tree Search and\n  Deep Neural Network Policies", "comments": "4 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG physics.chem-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Retrosynthesis is a technique to plan the chemical synthesis of organic\nmolecules, for example drugs, agro- and fine chemicals. In retrosynthesis, a\nsearch tree is built by analysing molecules recursively and dissecting them\ninto simpler molecular building blocks until one obtains a set of known\nbuilding blocks. The search space is intractably large, and it is difficult to\ndetermine the value of retrosynthetic positions. Here, we propose to model\nretrosynthesis as a Markov Decision Process. In combination with a Deep Neural\nNetwork policy learned from essentially the complete published knowledge of\nchemistry, Monte Carlo Tree Search (MCTS) can be used to evaluate positions. In\nexploratory studies, we demonstrate that MCTS with neural network policies\noutperforms the traditionally used best-first search with hand-coded\nheuristics.\n", "versions": [{"version": "v1", "created": "Tue, 31 Jan 2017 19:07:43 GMT"}], "update_date": "2017-02-02", "authors_parsed": [["Segler", "Marwin", ""], ["Preu\u00df", "Mike", ""], ["Waller", "Mark P.", ""]]}, {"id": "1702.00027", "submitter": "C Van", "authors": "A.G.Ramm, C. Van", "title": "Representation of big data by dimension reduction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Suppose the data consist of a set $S$ of points $x_j, 1 \\leq j \\leq J$,\ndistributed in a bounded domain $D \\subset R^N$, where $N$ and $J$ are large\nnumbers. In this paper an algorithm is proposed for checking whether there\nexists a manifold $\\mathbb{M}$ of low dimension near which many of the points\nof $S$ lie and finding such $\\mathbb{M}$ if it exists. There are many dimension\nreduction algorithms, both linear and non-linear. Our algorithm is simple to\nimplement and has some advantages compared with the known algorithms. If there\nis a manifold of low dimension near which most of the data points lie, the\nproposed algorithm will find it. Some numerical results are presented\nillustrating the algorithm and analyzing its performance compared to the\nclassical PCA (principal component analysis) and Isomap.\n", "versions": [{"version": "v1", "created": "Tue, 31 Jan 2017 19:25:44 GMT"}], "update_date": "2017-02-02", "authors_parsed": [["Ramm", "A. G.", ""], ["Van", "C.", ""]]}, {"id": "1702.00071", "submitter": "Eugene Vorontsov", "authors": "Eugene Vorontsov, Chiheb Trabelsi, Samuel Kadoury, Chris Pal", "title": "On orthogonality and learning recurrent networks with long term\n  dependencies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is well known that it is challenging to train deep neural networks and\nrecurrent neural networks for tasks that exhibit long term dependencies. The\nvanishing or exploding gradient problem is a well known issue associated with\nthese challenges. One approach to addressing vanishing and exploding gradients\nis to use either soft or hard constraints on weight matrices so as to encourage\nor enforce orthogonality. Orthogonal matrices preserve gradient norm during\nbackpropagation and may therefore be a desirable property. This paper explores\nissues with optimization convergence, speed and gradient stability when\nencouraging or enforcing orthogonality. To perform this analysis, we propose a\nweight matrix factorization and parameterization strategy through which we can\nbound matrix norms and therein control the degree of expansivity induced during\nbackpropagation. We find that hard constraints on orthogonality can negatively\naffect the speed of convergence and model performance.\n", "versions": [{"version": "v1", "created": "Tue, 31 Jan 2017 22:14:59 GMT"}, {"version": "v2", "created": "Fri, 3 Mar 2017 11:09:28 GMT"}, {"version": "v3", "created": "Mon, 12 Jun 2017 23:12:14 GMT"}, {"version": "v4", "created": "Thu, 12 Oct 2017 17:18:51 GMT"}], "update_date": "2017-10-13", "authors_parsed": [["Vorontsov", "Eugene", ""], ["Trabelsi", "Chiheb", ""], ["Kadoury", "Samuel", ""], ["Pal", "Chris", ""]]}, {"id": "1702.00156", "submitter": "Anjan Dutta", "authors": "Anjan Dutta and Hichem Sahbi", "title": "Stochastic Graphlet Embedding", "comments": "Accepted in IEEE TNNLS (14 pages, 7 figures, 10 tables)", "journal-ref": "IEEE TNNLS, pages 1-14, 2018", "doi": "10.1109/TNNLS.2018.2884700", "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph-based methods are known to be successful in many machine learning and\npattern classification tasks. These methods consider semi-structured data as\ngraphs where nodes correspond to primitives (parts, interest points, segments,\netc.) and edges characterize the relationships between these primitives.\nHowever, these non-vectorial graph data cannot be straightforwardly plugged\ninto off-the-shelf machine learning algorithms without a preliminary step of --\nexplicit/implicit -- graph vectorization and embedding. This embedding process\nshould be resilient to intra-class graph variations while being highly\ndiscriminant. In this paper, we propose a novel high-order stochastic graphlet\nembedding (SGE) that maps graphs into vector spaces. Our main contribution\nincludes a new stochastic search procedure that efficiently parses a given\ngraph and extracts/samples unlimitedly high-order graphlets. We consider these\ngraphlets, with increasing orders, to model local primitives as well as their\nincreasingly complex interactions. In order to build our graph representation,\nwe measure the distribution of these graphlets into a given graph, using\nparticular hash functions that efficiently assign sampled graphlets into\nisomorphic sets with a very low probability of collision. When combined with\nmaximum margin classifiers, these graphlet-based representations have positive\nimpact on the performance of pattern comparison and recognition as corroborated\nthrough extensive experiments using standard benchmark databases.\n", "versions": [{"version": "v1", "created": "Wed, 1 Feb 2017 08:16:03 GMT"}, {"version": "v2", "created": "Fri, 17 Feb 2017 11:01:06 GMT"}, {"version": "v3", "created": "Wed, 5 Dec 2018 01:59:34 GMT"}], "update_date": "2019-01-01", "authors_parsed": [["Dutta", "Anjan", ""], ["Sahbi", "Hichem", ""]]}, {"id": "1702.00177", "submitter": "Mathias Seuret", "authors": "Mathias Seuret, Michele Alberti, Rolf Ingold, Marcus Liwicki", "title": "PCA-Initialized Deep Neural Networks Applied To Document Image Analysis", "comments": null, "journal-ref": "ICDAR 2017", "doi": "10.1109/ICDAR.2017.148", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a novel approach for initializing deep neural\nnetworks, i.e., by turning PCA into neural layers. Usually, the initialization\nof the weights of a deep neural network is done in one of the three following\nways: 1) with random values, 2) layer-wise, usually as Deep Belief Network or\nas auto-encoder, and 3) re-use of layers from another network (transfer\nlearning). Therefore, typically, many training epochs are needed before\nmeaningful weights are learned, or a rather similar dataset is required for\nseeding a fine-tuning of transfer learning. In this paper, we describe how to\nturn a PCA into an auto-encoder, by generating an encoder layer of the PCA\nparameters and furthermore adding a decoding layer. We analyze the\ninitialization technique on real documents. First, we show that a PCA-based\ninitialization is quick and leads to a very stable initialization. Furthermore,\nfor the task of layout analysis we investigate the effectiveness of PCA-based\ninitialization and show that it outperforms state-of-the-art random weight\ninitialization methods.\n", "versions": [{"version": "v1", "created": "Wed, 1 Feb 2017 09:41:52 GMT"}], "update_date": "2018-04-25", "authors_parsed": [["Seuret", "Mathias", ""], ["Alberti", "Michele", ""], ["Ingold", "Rolf", ""], ["Liwicki", "Marcus", ""]]}, {"id": "1702.00178", "submitter": "Filip Korzeniowski", "authors": "Filip Korzeniowski and Gerhard Widmer", "title": "On the Futility of Learning Complex Frame-Level Language Models for\n  Chord Recognition", "comments": "Published at AES Conference on Semantic Audio 2017", "journal-ref": null, "doi": "10.17743/aesconf.2017.978-1-942220-15-2", "report-no": null, "categories": "cs.SD cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Chord recognition systems use temporal models to post-process frame-wise\nchord preditions from acoustic models. Traditionally, first-order models such\nas Hidden Markov Models were used for this task, with recent works suggesting\nto apply Recurrent Neural Networks instead. Due to their ability to learn\nlonger-term dependencies, these models are supposed to learn and to apply\nmusical knowledge, instead of just smoothing the output of the acoustic model.\nIn this paper, we argue that learning complex temporal models at the level of\naudio frames is futile on principle, and that non-Markovian models do not\nperform better than their first-order counterparts. We support our argument\nthrough three experiments on the McGill Billboard dataset. The first two show\n1) that when learning complex temporal models at the frame level, improvements\nin chord sequence modelling are marginal; and 2) that these improvements do not\ntranslate when applied within a full chord recognition system. The third, still\nrather preliminary experiment gives first indications that the use of complex\nsequential models for chord prediction at higher temporal levels might be more\npromising.\n", "versions": [{"version": "v1", "created": "Wed, 1 Feb 2017 09:44:44 GMT"}, {"version": "v2", "created": "Fri, 31 Mar 2017 11:24:42 GMT"}], "update_date": "2017-06-27", "authors_parsed": [["Korzeniowski", "Filip", ""], ["Widmer", "Gerhard", ""]]}, {"id": "1702.00196", "submitter": "He Sun", "authors": "Jiecao Chen and He Sun and David P. Woodruff and Qin Zhang", "title": "Communication-Optimal Distributed Clustering", "comments": "A preliminary version of this paper appeared at the 30th Annual\n  Conference on Neural Information Processing Systems (NIPS), 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clustering large datasets is a fundamental problem with a number of\napplications in machine learning. Data is often collected on different sites\nand clustering needs to be performed in a distributed manner with low\ncommunication. We would like the quality of the clustering in the distributed\nsetting to match that in the centralized setting for which all the data resides\non a single site. In this work, we study both graph and geometric clustering\nproblems in two distributed models: (1) a point-to-point model, and (2) a model\nwith a broadcast channel. We give protocols in both models which we show are\nnearly optimal by proving almost matching communication lower bounds. Our work\nhighlights the surprising power of a broadcast channel for clustering problems;\nroughly speaking, to spectrally cluster $n$ points or $n$ vertices in a graph\ndistributed across $s$ servers, for a worst-case partitioning the communication\ncomplexity in a point-to-point model is $n \\cdot s$, while in the broadcast\nmodel it is $n + s$. A similar phenomenon holds for the geometric setting as\nwell. We implement our algorithms and demonstrate this phenomenon on real life\ndatasets, showing that our algorithms are also very efficient in practice.\n", "versions": [{"version": "v1", "created": "Wed, 1 Feb 2017 10:30:32 GMT"}], "update_date": "2017-02-02", "authors_parsed": [["Chen", "Jiecao", ""], ["Sun", "He", ""], ["Woodruff", "David P.", ""], ["Zhang", "Qin", ""]]}, {"id": "1702.00260", "submitter": "\\c{C}a\\u{g}r{\\i} Latifo\\u{g}lu", "authors": "Mirbek Turduev, \\c{C}a\\u{g}r{\\i} Latifo\\u{g}lu, \\.Ibrahim Halil Giden,\n  Y. Sinan Hanay", "title": "Machine learning based compact photonic structure design for strong\n  light confinement", "comments": "7 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.optics cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel approach based on machine learning for designing photonic\nstructures. In particular, we focus on strong light confinement that allows the\ndesign of an efficient free-space-to-waveguide coupler which is made of Si-\nslab overlying on the top of silica substrate. The learning algorithm is\nimplemented using bitwise square Si- cells and the whole optimized device has a\nfootprint of $\\boldsymbol{2 \\, \\mu m \\times 1\\, \\mu m}$, which is the smallest\nsize ever achieved numerically. To find the effect of Si- slab thickness on the\nsub-wavelength focusing and strong coupling characteristics of optimized\nphotonic structure, we carried out three-dimensional time-domain numerical\ncalculations. Corresponding optimum values of full width at half maximum and\ncoupling efficiency were calculated as $\\boldsymbol{0.158 \\lambda}$ and\n$\\boldsymbol{-1.87\\,dB}$ with slab thickness of $\\boldsymbol{280nm}$. Compared\nto the conventional counterparts, the optimized lens and coupler designs are\neasy-to-fabricate via optical lithography techniques, quite compact, and can\noperate at telecommunication wavelengths. The outcomes of the presented study\nshow that machine learning can be beneficial for efficient photonic designs in\nvarious potential applications such as polarization-division, beam manipulation\nand optical interconnects.\n", "versions": [{"version": "v1", "created": "Tue, 31 Jan 2017 10:48:39 GMT"}], "update_date": "2017-02-02", "authors_parsed": [["Turduev", "Mirbek", ""], ["Latifo\u011flu", "\u00c7a\u011fr\u0131", ""], ["Giden", "\u0130brahim Halil", ""], ["Hanay", "Y. Sinan", ""]]}, {"id": "1702.00317", "submitter": "Vivak Patel", "authors": "Vivak Patel", "title": "On SGD's Failure in Practice: Characterizing and Overcoming Stalling", "comments": "17 pages, 4 figures, 4 Tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic Gradient Descent (SGD) is widely used in machine learning problems\nto efficiently perform empirical risk minimization, yet, in practice, SGD is\nknown to stall before reaching the actual minimizer of the empirical risk. SGD\nstalling has often been attributed to its sensitivity to the conditioning of\nthe problem; however, as we demonstrate, SGD will stall even when applied to a\nsimple linear regression problem with unity condition number for standard\nlearning rates. Thus, in this work, we numerically demonstrate and\nmathematically argue that stalling is a crippling and generic limitation of SGD\nand its variants in practice. Once we have established the problem of stalling,\nwe generalize an existing framework for hedging against its effects, which (1)\ndeters SGD and its variants from stalling, (2) still provides convergence\nguarantees, and (3) makes SGD and its variants more practical methods for\nminimization.\n", "versions": [{"version": "v1", "created": "Wed, 1 Feb 2017 15:33:01 GMT"}, {"version": "v2", "created": "Tue, 7 Feb 2017 22:13:25 GMT"}], "update_date": "2017-02-09", "authors_parsed": [["Patel", "Vivak", ""]]}, {"id": "1702.00403", "submitter": "Kevin Schawinski", "authors": "Kevin Schawinski, Ce Zhang, Hantian Zhang, Lucas Fowler and Gokula\n  Krishnan Santhanam", "title": "Generative Adversarial Networks recover features in astrophysical images\n  of galaxies beyond the deconvolution limit", "comments": "Accepted for publication in MNRAS, for the full code and a virtual\n  machine set up to run it, see http://space.ml/proj/GalaxyGAN.html", "journal-ref": null, "doi": "10.1093/mnrasl/slx008", "report-no": null, "categories": "astro-ph.IM astro-ph.GA cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Observations of astrophysical objects such as galaxies are limited by various\nsources of random and systematic noise from the sky background, the optical\nsystem of the telescope and the detector used to record the data. Conventional\ndeconvolution techniques are limited in their ability to recover features in\nimaging data by the Shannon-Nyquist sampling theorem. Here we train a\ngenerative adversarial network (GAN) on a sample of $4,550$ images of nearby\ngalaxies at $0.01<z<0.02$ from the Sloan Digital Sky Survey and conduct\n$10\\times$ cross validation to evaluate the results. We present a method using\na GAN trained on galaxy images that can recover features from artificially\ndegraded images with worse seeing and higher noise than the original with a\nperformance which far exceeds simple deconvolution. The ability to better\nrecover detailed features such as galaxy morphology from low-signal-to-noise\nand low angular resolution imaging data significantly increases our ability to\nstudy existing data sets of astrophysical objects as well as future\nobservations with observatories such as the Large Synoptic Sky Telescope (LSST)\nand the Hubble and James Webb space telescopes.\n", "versions": [{"version": "v1", "created": "Wed, 1 Feb 2017 19:00:02 GMT"}], "update_date": "2017-04-19", "authors_parsed": [["Schawinski", "Kevin", ""], ["Zhang", "Ce", ""], ["Zhang", "Hantian", ""], ["Fowler", "Lucas", ""], ["Santhanam", "Gokula Krishnan", ""]]}, {"id": "1702.00458", "submitter": "Qiuyi Zhang", "authors": "Rina Panigrahy, Sushant Sachdeva, Qiuyi Zhang", "title": "Convergence Results for Neural Networks via Electrodynamics", "comments": "in ITCS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study whether a depth two neural network can learn another depth two\nnetwork using gradient descent. Assuming a linear output node, we show that the\nquestion of whether gradient descent converges to the target function is\nequivalent to the following question in electrodynamics: Given $k$ fixed\nprotons in $\\mathbb{R}^d,$ and $k$ electrons, each moving due to the attractive\nforce from the protons and repulsive force from the remaining electrons,\nwhether at equilibrium all the electrons will be matched up with the protons,\nup to a permutation. Under the standard electrical force, this follows from the\nclassic Earnshaw's theorem. In our setting, the force is determined by the\nactivation function and the input distribution. Building on this equivalence,\nwe prove the existence of an activation function such that gradient descent\nlearns at least one of the hidden nodes in the target network. Iterating, we\nshow that gradient descent can be used to learn the entire network one node at\na time.\n", "versions": [{"version": "v1", "created": "Wed, 1 Feb 2017 21:25:13 GMT"}, {"version": "v2", "created": "Tue, 7 Feb 2017 05:44:06 GMT"}, {"version": "v3", "created": "Tue, 12 Sep 2017 20:35:14 GMT"}, {"version": "v4", "created": "Tue, 21 Nov 2017 01:08:49 GMT"}, {"version": "v5", "created": "Tue, 4 Dec 2018 23:04:49 GMT"}], "update_date": "2018-12-06", "authors_parsed": [["Panigrahy", "Rina", ""], ["Sachdeva", "Sushant", ""], ["Zhang", "Qiuyi", ""]]}, {"id": "1702.00505", "submitter": "Luigi Nardi", "authors": "Luigi Nardi, Bruno Bodin, Sajad Saeedi, Emanuele Vespa, Andrew J.\n  Davison, Paul H. J. Kelly", "title": "Algorithmic Performance-Accuracy Trade-off in 3D Vision Applications\n  Using HyperMapper", "comments": "10 pages, Keywords: design space exploration, machine learning,\n  computer vision, SLAM, embedded systems, GPU, crowd-sourcing", "journal-ref": "31st IEEE International Parallel and Distributed Processing\n  Symposium May 29 - June 2, 2017 Orlando, Florida USA", "doi": null, "report-no": null, "categories": "cs.CV cs.DC cs.LG cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we investigate an emerging application, 3D scene understanding,\nlikely to be significant in the mobile space in the near future. The goal of\nthis exploration is to reduce execution time while meeting our quality of\nresult objectives. In previous work we showed for the first time that it is\npossible to map this application to power constrained embedded systems,\nhighlighting that decision choices made at the algorithmic design-level have\nthe most impact.\n  As the algorithmic design space is too large to be exhaustively evaluated, we\nuse a previously introduced multi-objective Random Forest Active Learning\nprediction framework dubbed HyperMapper, to find good algorithmic designs. We\nshow that HyperMapper generalizes on a recent cutting edge 3D scene\nunderstanding algorithm and on a modern GPU-based computer architecture.\nHyperMapper is able to beat an expert human hand-tuning the algorithmic\nparameters of the class of Computer Vision applications taken under\nconsideration in this paper automatically. In addition, we use crowd-sourcing\nusing a 3D scene understanding Android app to show that the Pareto front\nobtained on an embedded system can be used to accelerate the same application\non all the 83 smart-phones and tablets crowd-sourced with speedups ranging from\n2 to over 12.\n", "versions": [{"version": "v1", "created": "Thu, 2 Feb 2017 00:01:46 GMT"}, {"version": "v2", "created": "Tue, 21 Mar 2017 21:58:41 GMT"}], "update_date": "2017-03-23", "authors_parsed": [["Nardi", "Luigi", ""], ["Bodin", "Bruno", ""], ["Saeedi", "Sajad", ""], ["Vespa", "Emanuele", ""], ["Davison", "Andrew J.", ""], ["Kelly", "Paul H. J.", ""]]}, {"id": "1702.00509", "submitter": "Jen Hong Tan", "authors": "Jen Hong Tan, U. Rajendra Acharya, Sulatha V. Bhandary, Kuang Chua\n  Chua, Sobha Sivaprasad", "title": "Segmentation of optic disc, fovea and retinal vasculature using a single\n  convolutional neural network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We have developed and trained a convolutional neural network to automatically\nand simultaneously segment optic disc, fovea and blood vessels. Fundus images\nwere normalised before segmentation was performed to enforce consistency in\nbackground lighting and contrast. For every effective point in the fundus\nimage, our algorithm extracted three channels of input from the neighbourhood\nof the point and forward the response across the 7 layer network. In average,\nour segmentation achieved an accuracy of 92.68 percent on the testing set from\nDrive database.\n", "versions": [{"version": "v1", "created": "Thu, 2 Feb 2017 00:37:22 GMT"}], "update_date": "2017-02-03", "authors_parsed": [["Tan", "Jen Hong", ""], ["Acharya", "U. Rajendra", ""], ["Bhandary", "Sulatha V.", ""], ["Chua", "Kuang Chua", ""], ["Sivaprasad", "Sobha", ""]]}, {"id": "1702.00518", "submitter": "Shantanu Jain", "authors": "Shantanu Jain, Martha White, Predrag Radivojac", "title": "Recovering True Classifier Performance in Positive-Unlabeled Learning", "comments": "Full paper with supplement", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A common approach in positive-unlabeled learning is to train a classification\nmodel between labeled and unlabeled data. This strategy is in fact known to\ngive an optimal classifier under mild conditions; however, it results in biased\nempirical estimates of the classifier performance. In this work, we show that\nthe typically used performance measures such as the receiver operating\ncharacteristic curve, or the precision-recall curve obtained on such data can\nbe corrected with the knowledge of class priors; i.e., the proportions of the\npositive and negative examples in the unlabeled data. We extend the results to\na noisy setting where some of the examples labeled positive are in fact\nnegative and show that the correction also requires the knowledge of the\nproportion of noisy examples in the labeled positives. Using state-of-the-art\nalgorithms to estimate the positive class prior and the proportion of noise, we\nexperimentally evaluate two correction approaches and demonstrate their\nefficacy on real-life data.\n", "versions": [{"version": "v1", "created": "Thu, 2 Feb 2017 01:22:18 GMT"}], "update_date": "2017-02-03", "authors_parsed": [["Jain", "Shantanu", ""], ["White", "Martha", ""], ["Radivojac", "Predrag", ""]]}, {"id": "1702.00523", "submitter": "Satish Palaniappan", "authors": "Satish Palaniappan and Ronojoy Adhikari", "title": "Deep Learning the Indus Script", "comments": "17 pages, 10 figures, 7 supporting figures (2 pages)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Standardized corpora of undeciphered scripts, a necessary starting point for\ncomputational epigraphy, requires laborious human effort for their preparation\nfrom raw archaeological records. Automating this process through machine\nlearning algorithms can be of significant aid to epigraphical research. Here,\nwe take the first steps in this direction and present a deep learning pipeline\nthat takes as input images of the undeciphered Indus script, as found in\narchaeological artifacts, and returns as output a string of graphemes, suitable\nfor inclusion in a standard corpus. The image is first decomposed into regions\nusing Selective Search and these regions are classified as containing textual\nand/or graphical information using a convolutional neural network. Regions\nclassified as potentially containing text are hierarchically merged and trimmed\nto remove non-textual information. The remaining textual part of the image is\nsegmented using standard image processing techniques to isolate individual\ngraphemes. This set is finally passed to a second convolutional neural network\nto classify the graphemes, based on a standard corpus. The classifier can\nidentify the presence or absence of the most frequent Indus grapheme, the \"jar\"\nsign, with an accuracy of 92%. Our results demonstrate the great potential of\ndeep learning approaches in computational epigraphy and, more generally, in the\ndigital humanities.\n", "versions": [{"version": "v1", "created": "Thu, 2 Feb 2017 01:56:22 GMT"}], "update_date": "2017-02-03", "authors_parsed": [["Palaniappan", "Satish", ""], ["Adhikari", "Ronojoy", ""]]}, {"id": "1702.00610", "submitter": "Min Ye", "authors": "Min Ye and Alexander Barg", "title": "Optimal Schemes for Discrete Distribution Estimation under Locally\n  Differential Privacy", "comments": "A short version is submitted to ISIT 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the minimax estimation problem of a discrete distribution with\nsupport size $k$ under privacy constraints. A privatization scheme is applied\nto each raw sample independently, and we need to estimate the distribution of\nthe raw samples from the privatized samples. A positive number $\\epsilon$\nmeasures the privacy level of a privatization scheme. For a given $\\epsilon,$\nwe consider the problem of constructing optimal privatization schemes with\n$\\epsilon$-privacy level, i.e., schemes that minimize the expected estimation\nloss for the worst-case distribution. Two schemes in the literature provide\norder optimal performance in the high privacy regime where $\\epsilon$ is very\nclose to $0,$ and in the low privacy regime where $e^{\\epsilon}\\approx k,$\nrespectively.\n  In this paper, we propose a new family of schemes which substantially improve\nthe performance of the existing schemes in the medium privacy regime when $1\\ll\ne^{\\epsilon} \\ll k.$ More concretely, we prove that when $3.8 < \\epsilon\n<\\ln(k/9) ,$ our schemes reduce the expected estimation loss by $50\\%$ under\n$\\ell_2^2$ metric and by $30\\%$ under $\\ell_1$ metric over the existing\nschemes. We also prove a lower bound for the region $e^{\\epsilon} \\ll k,$ which\nimplies that our schemes are order optimal in this regime.\n", "versions": [{"version": "v1", "created": "Thu, 2 Feb 2017 10:37:55 GMT"}], "update_date": "2017-02-03", "authors_parsed": [["Ye", "Min", ""], ["Barg", "Alexander", ""]]}, {"id": "1702.00709", "submitter": "Aryan Mokhtari", "authors": "Aryan Mokhtari and Mark Eisen and Alejandro Ribeiro", "title": "IQN: An Incremental Quasi-Newton Method with Local Superlinear\n  Convergence Rate", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of minimizing an objective that can be written as the sum of a\nset of $n$ smooth and strongly convex functions is considered. The Incremental\nQuasi-Newton (IQN) method proposed here belongs to the family of stochastic and\nincremental methods that have a cost per iteration independent of $n$. IQN\niterations are a stochastic version of BFGS iterations that use memory to\nreduce the variance of stochastic approximations. The convergence properties of\nIQN bridge a gap between deterministic and stochastic quasi-Newton methods.\nDeterministic quasi-Newton methods exploit the possibility of approximating the\nNewton step using objective gradient differences. They are appealing because\nthey have a smaller computational cost per iteration relative to Newton's\nmethod and achieve a superlinear convergence rate under customary regularity\nassumptions. Stochastic quasi-Newton methods utilize stochastic gradient\ndifferences in lieu of actual gradient differences. This makes their\ncomputational cost per iteration independent of the number of objective\nfunctions $n$. However, existing stochastic quasi-Newton methods have sublinear\nor linear convergence at best. IQN is the first stochastic quasi-Newton method\nproven to converge superlinearly in a local neighborhood of the optimal\nsolution. IQN differs from state-of-the-art incremental quasi-Newton methods in\nthree aspects: (i) The use of aggregated information of variables, gradients,\nand quasi-Newton Hessian approximation matrices to reduce the noise of gradient\nand Hessian approximations. (ii) The approximation of each individual function\nby its Taylor's expansion in which the linear and quadratic terms are evaluated\nwith respect to the same iterate. (iii) The use of a cyclic scheme to update\nthe functions in lieu of a random selection routine. We use these fundamental\nproperties of IQN to establish its local superlinear convergence rate.\n", "versions": [{"version": "v1", "created": "Thu, 2 Feb 2017 15:13:06 GMT"}, {"version": "v2", "created": "Mon, 27 Mar 2017 19:16:55 GMT"}], "update_date": "2017-03-29", "authors_parsed": [["Mokhtari", "Aryan", ""], ["Eisen", "Mark", ""], ["Ribeiro", "Alejandro", ""]]}, {"id": "1702.00758", "submitter": "Zhangjie Cao", "authors": "Zhangjie Cao, Mingsheng Long, Jianmin Wang, Philip S. Yu", "title": "HashNet: Deep Learning to Hash by Continuation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning to hash has been widely applied to approximate nearest neighbor\nsearch for large-scale multimedia retrieval, due to its computation efficiency\nand retrieval quality. Deep learning to hash, which improves retrieval quality\nby end-to-end representation learning and hash encoding, has received\nincreasing attention recently. Subject to the ill-posed gradient difficulty in\nthe optimization with sign activations, existing deep learning to hash methods\nneed to first learn continuous representations and then generate binary hash\ncodes in a separated binarization step, which suffer from substantial loss of\nretrieval quality. This work presents HashNet, a novel deep architecture for\ndeep learning to hash by continuation method with convergence guarantees, which\nlearns exactly binary hash codes from imbalanced similarity data. The key idea\nis to attack the ill-posed gradient problem in optimizing deep networks with\nnon-smooth binary activations by continuation method, in which we begin from\nlearning an easier network with smoothed activation function and let it evolve\nduring the training, until it eventually goes back to being the original,\ndifficult to optimize, deep network with the sign activation function.\nComprehensive empirical evidence shows that HashNet can generate exactly binary\nhash codes and yield state-of-the-art multimedia retrieval performance on\nstandard benchmarks.\n", "versions": [{"version": "v1", "created": "Thu, 2 Feb 2017 17:29:24 GMT"}, {"version": "v2", "created": "Sun, 23 Apr 2017 22:14:09 GMT"}, {"version": "v3", "created": "Thu, 20 Jul 2017 14:59:45 GMT"}, {"version": "v4", "created": "Sat, 29 Jul 2017 17:55:50 GMT"}], "update_date": "2017-08-01", "authors_parsed": [["Cao", "Zhangjie", ""], ["Long", "Mingsheng", ""], ["Wang", "Jianmin", ""], ["Yu", "Philip S.", ""]]}, {"id": "1702.00763", "submitter": "Zeyuan Allen-Zhu", "authors": "Zeyuan Allen-Zhu", "title": "Natasha: Faster Non-Convex Stochastic Optimization Via Strongly\n  Non-Convex Parameter", "comments": "V2-V5 corrected typos, polished writing, and added citations. (We\n  mis-stated the complexity of the prior work repeatSVRG in V1-V4, and have\n  fixed this mistake in V5.)", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.DS cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a nonconvex function that is an average of $n$ smooth functions, we\ndesign stochastic first-order methods to find its approximate stationary\npoints. The convergence of our new methods depends on the smallest (negative)\neigenvalue $-\\sigma$ of the Hessian, a parameter that describes how nonconvex\nthe function is.\n  Our methods outperform known results for a range of parameter $\\sigma$, and\ncan be used to find approximate local minima. Our result implies an interesting\ndichotomy: there exists a threshold $\\sigma_0$ so that the currently fastest\nmethods for $\\sigma>\\sigma_0$ and for $\\sigma<\\sigma_0$ have different\nbehaviors: the former scales with $n^{2/3}$ and the latter scales with\n$n^{3/4}$.\n", "versions": [{"version": "v1", "created": "Thu, 2 Feb 2017 17:45:09 GMT"}, {"version": "v2", "created": "Mon, 27 Feb 2017 03:50:25 GMT"}, {"version": "v3", "created": "Tue, 5 Sep 2017 09:37:06 GMT"}, {"version": "v4", "created": "Sat, 16 Jun 2018 10:05:32 GMT"}, {"version": "v5", "created": "Thu, 27 Sep 2018 09:55:54 GMT"}], "update_date": "2018-09-28", "authors_parsed": [["Allen-Zhu", "Zeyuan", ""]]}, {"id": "1702.00783", "submitter": "Ryan Dahl", "authors": "Ryan Dahl, Mohammad Norouzi, Jonathon Shlens", "title": "Pixel Recursive Super Resolution", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a pixel recursive super resolution model that synthesizes\nrealistic details into images while enhancing their resolution. A low\nresolution image may correspond to multiple plausible high resolution images,\nthus modeling the super resolution process with a pixel independent conditional\nmodel often results in averaging different details--hence blurry edges. By\ncontrast, our model is able to represent a multimodal conditional distribution\nby properly modeling the statistical dependencies among the high resolution\nimage pixels, conditioned on a low resolution input. We employ a PixelCNN\narchitecture to define a strong prior over natural images and jointly optimize\nthis prior with a deep conditioning convolutional network. Human evaluations\nindicate that samples from our proposed model look more photo realistic than a\nstrong L2 regression baseline.\n", "versions": [{"version": "v1", "created": "Thu, 2 Feb 2017 18:59:17 GMT"}, {"version": "v2", "created": "Wed, 22 Mar 2017 16:13:21 GMT"}], "update_date": "2017-03-23", "authors_parsed": [["Dahl", "Ryan", ""], ["Norouzi", "Mohammad", ""], ["Shlens", "Jonathon", ""]]}, {"id": "1702.00832", "submitter": "Timothy O'Shea", "authors": "Timothy J. O'Shea, Jakob Hoydis", "title": "An Introduction to Deep Learning for the Physical Layer", "comments": "13 pages, 12 figures, 5 tables, under submission to academic journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG cs.NI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present and discuss several novel applications of deep learning for the\nphysical layer. By interpreting a communications system as an autoencoder, we\ndevelop a fundamental new way to think about communications system design as an\nend-to-end reconstruction task that seeks to jointly optimize transmitter and\nreceiver components in a single process. We show how this idea can be extended\nto networks of multiple transmitters and receivers and present the concept of\nradio transformer networks as a means to incorporate expert domain knowledge in\nthe machine learning model. Lastly, we demonstrate the application of\nconvolutional neural networks on raw IQ samples for modulation classification\nwhich achieves competitive accuracy with respect to traditional schemes relying\non expert features. The paper is concluded with a discussion of open challenges\nand areas for future investigation.\n", "versions": [{"version": "v1", "created": "Thu, 2 Feb 2017 21:30:08 GMT"}, {"version": "v2", "created": "Tue, 11 Jul 2017 21:57:19 GMT"}], "update_date": "2017-07-13", "authors_parsed": [["O'Shea", "Timothy J.", ""], ["Hoydis", "Jakob", ""]]}, {"id": "1702.00833", "submitter": "Maciej Wielgosz", "authors": "Maciej Wielgosz and Andrzej Skocze\\'n and Matej Mertik", "title": "Recurrent Neural Networks for anomaly detection in the Post-Mortem time\n  series of LHC superconducting magnets", "comments": "Related to arxiv:1611.06241", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.ins-det cs.LG physics.acc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a model based on Deep Learning algorithms of LSTM and GRU\nfor facilitating an anomaly detection in Large Hadron Collider superconducting\nmagnets. We used high resolution data available in Post Mortem database to\ntrain a set of models and chose the best possible set of their\nhyper-parameters. Using Deep Learning approach allowed to examine a vast body\nof data and extract the fragments which require further experts examination and\nare regarded as anomalies. The presented method does not require tedious manual\nthreshold setting and operator attention at the stage of the system setup.\nInstead, the automatic approach is proposed, which achieves according to our\nexperiments accuracy of 99%. This is reached for the largest dataset of 302 MB\nand the following architecture of the network: single layer LSTM, 128 cells, 20\nepochs of training, look_back=16, look_ahead=128, grid=100 and optimizer Adam.\nAll the experiments were run on GPU Nvidia Tesla K80\n", "versions": [{"version": "v1", "created": "Thu, 2 Feb 2017 21:32:32 GMT"}], "update_date": "2017-02-06", "authors_parsed": [["Wielgosz", "Maciej", ""], ["Skocze\u0144", "Andrzej", ""], ["Mertik", "Matej", ""]]}, {"id": "1702.00887", "submitter": "Yoon Kim", "authors": "Yoon Kim, Carl Denton, Luong Hoang, Alexander M. Rush", "title": "Structured Attention Networks", "comments": "ICLR 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Attention networks have proven to be an effective approach for embedding\ncategorical inference within a deep neural network. However, for many tasks we\nmay want to model richer structural dependencies without abandoning end-to-end\ntraining. In this work, we experiment with incorporating richer structural\ndistributions, encoded using graphical models, within deep networks. We show\nthat these structured attention networks are simple extensions of the basic\nattention procedure, and that they allow for extending attention beyond the\nstandard soft-selection approach, such as attending to partial segmentations or\nto subtrees. We experiment with two different classes of structured attention\nnetworks: a linear-chain conditional random field and a graph-based parsing\nmodel, and describe how these models can be practically implemented as neural\nnetwork layers. Experiments show that this approach is effective for\nincorporating structural biases, and structured attention networks outperform\nbaseline attention models on a variety of synthetic and real tasks: tree\ntransduction, neural machine translation, question answering, and natural\nlanguage inference. We further find that models trained in this way learn\ninteresting unsupervised hidden representations that generalize simple\nattention.\n", "versions": [{"version": "v1", "created": "Fri, 3 Feb 2017 01:40:45 GMT"}, {"version": "v2", "created": "Wed, 8 Feb 2017 16:37:44 GMT"}, {"version": "v3", "created": "Thu, 16 Feb 2017 17:52:03 GMT"}], "update_date": "2017-02-17", "authors_parsed": [["Kim", "Yoon", ""], ["Denton", "Carl", ""], ["Hoang", "Luong", ""], ["Rush", "Alexander M.", ""]]}, {"id": "1702.00953", "submitter": "Zhaowei Cai", "authors": "Zhaowei Cai, Xiaodong He, Jian Sun, Nuno Vasconcelos", "title": "Deep Learning with Low Precision by Half-wave Gaussian Quantization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of quantizing the activations of a deep neural network is\nconsidered. An examination of the popular binary quantization approach shows\nthat this consists of approximating a classical non-linearity, the hyperbolic\ntangent, by two functions: a piecewise constant sign function, which is used in\nfeedforward network computations, and a piecewise linear hard tanh function,\nused in the backpropagation step during network learning. The problem of\napproximating the ReLU non-linearity, widely used in the recent deep learning\nliterature, is then considered. An half-wave Gaussian quantizer (HWGQ) is\nproposed for forward approximation and shown to have efficient implementation,\nby exploiting the statistics of of network activations and batch normalization\noperations commonly used in the literature. To overcome the problem of gradient\nmismatch, due to the use of different forward and backward approximations,\nseveral piece-wise backward approximators are then investigated. The\nimplementation of the resulting quantized network, denoted as HWGQ-Net, is\nshown to achieve much closer performance to full precision networks, such as\nAlexNet, ResNet, GoogLeNet and VGG-Net, than previously available low-precision\nnetworks, with 1-bit binary weights and 2-bit quantized activations.\n", "versions": [{"version": "v1", "created": "Fri, 3 Feb 2017 10:11:40 GMT"}], "update_date": "2017-02-06", "authors_parsed": [["Cai", "Zhaowei", ""], ["He", "Xiaodong", ""], ["Sun", "Jian", ""], ["Vasconcelos", "Nuno", ""]]}, {"id": "1702.01005", "submitter": "Rudrasis Chakraborty Dr.", "authors": "Rudrasis Chakraborty, S{\\o}ren Hauberg, Baba C. Vemuri", "title": "Intrinsic Grassmann Averages for Online Linear, Robust and Nonlinear\n  Subspace Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Principal Component Analysis (PCA) and Kernel Principal Component Analysis\n(KPCA) are fundamental methods in machine learning for dimensionality\nreduction. The former is a technique for finding this approximation in finite\ndimensions and the latter is often in an infinite dimensional Reproducing\nKernel Hilbert-space (RKHS). In this paper, we present a geometric framework\nfor computing the principal linear subspaces in both situations as well as for\nthe robust PCA case, that amounts to computing the intrinsic average on the\nspace of all subspaces: the Grassmann manifold. Points on this manifold are\ndefined as the subspaces spanned by $K$-tuples of observations. The intrinsic\nGrassmann average of these subspaces are shown to coincide with the principal\ncomponents of the observations when they are drawn from a Gaussian\ndistribution. We show similar results in the RKHS case and provide an efficient\nalgorithm for computing the projection onto the this average subspace. The\nresult is a method akin to KPCA which is substantially faster. Further, we\npresent a novel online version of the KPCA using our geometric framework.\nCompetitive performance of all our algorithms are demonstrated on a variety of\nreal and synthetic data sets.\n", "versions": [{"version": "v1", "created": "Fri, 3 Feb 2017 13:44:44 GMT"}, {"version": "v2", "created": "Tue, 10 Jul 2018 02:29:39 GMT"}], "update_date": "2018-07-11", "authors_parsed": [["Chakraborty", "Rudrasis", ""], ["Hauberg", "S\u00f8ren", ""], ["Vemuri", "Baba C.", ""]]}, {"id": "1702.01182", "submitter": "Gregory Kahn", "authors": "Gregory Kahn, Adam Villaflor, Vitchyr Pong, Pieter Abbeel, Sergey\n  Levine", "title": "Uncertainty-Aware Reinforcement Learning for Collision Avoidance", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning can enable complex, adaptive behavior to be learned\nautomatically for autonomous robotic platforms. However, practical deployment\nof reinforcement learning methods must contend with the fact that the training\nprocess itself can be unsafe for the robot. In this paper, we consider the\nspecific case of a mobile robot learning to navigate an a priori unknown\nenvironment while avoiding collisions. In order to learn collision avoidance,\nthe robot must experience collisions at training time. However, high-speed\ncollisions, even at training time, could damage the robot. A successful\nlearning method must therefore proceed cautiously, experiencing only low-speed\ncollisions until it gains confidence. To this end, we present an\nuncertainty-aware model-based learning algorithm that estimates the probability\nof collision together with a statistical estimate of uncertainty. By\nformulating an uncertainty-dependent cost function, we show that the algorithm\nnaturally chooses to proceed cautiously in unfamiliar environments, and\nincreases the velocity of the robot in settings where it has high confidence.\nOur predictive model is based on bootstrapped neural networks using dropout,\nallowing it to process raw sensory inputs from high-bandwidth sensors such as\ncameras. Our experimental evaluation demonstrates that our method effectively\nminimizes dangerous collisions at training time in an obstacle avoidance task\nfor a simulated and real-world quadrotor, and a real-world RC car. Videos of\nthe experiments can be found at https://sites.google.com/site/probcoll.\n", "versions": [{"version": "v1", "created": "Fri, 3 Feb 2017 21:57:13 GMT"}], "update_date": "2017-02-07", "authors_parsed": [["Kahn", "Gregory", ""], ["Villaflor", "Adam", ""], ["Pong", "Vitchyr", ""], ["Abbeel", "Pieter", ""], ["Levine", "Sergey", ""]]}, {"id": "1702.01200", "submitter": "Oleksii Tyshchenko Dr", "authors": "Zhengbing Hu, Yevgeniy V. Bodyanskiy, Oleksii K. Tyshchenko and\n  Viktoriia O. Samitova", "title": "Fuzzy Clustering Data Given on the Ordinal Scale Based on Membership and\n  Likelihood Functions Sharing", "comments": "International Journal of Intelligent Systems and Applications(IJISA),\n  Vol. 9, No. 2, February 2017", "journal-ref": null, "doi": "10.5815/ijisa.2017.02.01", "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A task of clustering data given in the ordinal scale under conditions of\noverlapping clusters has been considered. It's proposed to use an approach\nbased on memberhsip and likelihood functions sharing. A number of performed\nexperiments proved effectiveness of the proposed method. The proposed method is\ncharacterized by robustness to outliers due to a way of ordering values while\nconstructing membership functions.\n", "versions": [{"version": "v1", "created": "Fri, 3 Feb 2017 23:17:48 GMT"}], "update_date": "2017-02-07", "authors_parsed": [["Hu", "Zhengbing", ""], ["Bodyanskiy", "Yevgeniy V.", ""], ["Tyshchenko", "Oleksii K.", ""], ["Samitova", "Viktoriia O.", ""]]}, {"id": "1702.01205", "submitter": "Shumeet Baluja", "authors": "Shumeet Baluja, Michele Covell, Rahul Sukthankar", "title": "Traffic Lights with Auction-Based Controllers: Algorithms and Real-World\n  Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Real-time optimization of traffic flow addresses important practical\nproblems: reducing a driver's wasted time, improving city-wide efficiency,\nreducing gas emissions and improving air quality. Much of the current research\nin traffic-light optimization relies on extending the capabilities of traffic\nlights to either communicate with each other or communicate with vehicles.\nHowever, before such capabilities become ubiquitous, opportunities exist to\nimprove traffic lights by being more responsive to current traffic situations\nwithin the current, already deployed, infrastructure. In this paper, we\nintroduce a traffic light controller that employs bidding within micro-auctions\nto efficiently incorporate traffic sensor information; no other outside sources\nof information are assumed. We train and test traffic light controllers on\nlarge-scale data collected from opted-in Android cell-phone users over a period\nof several months in Mountain View, California and the River North neighborhood\nof Chicago, Illinois. The learned auction-based controllers surpass (in both\nthe relevant metrics of road-capacity and mean travel time) the currently\ndeployed lights, optimized static-program lights, and longer-term planning\napproaches, in both cities, measured using real user driving data.\n", "versions": [{"version": "v1", "created": "Fri, 3 Feb 2017 23:44:02 GMT"}], "update_date": "2017-02-07", "authors_parsed": [["Baluja", "Shumeet", ""], ["Covell", "Michele", ""], ["Sukthankar", "Rahul", ""]]}, {"id": "1702.01208", "submitter": "Arya Mazumdar", "authors": "Arya Mazumdar, Barna Saha", "title": "A Theoretical Analysis of First Heuristics of Crowdsourced Entity\n  Resolution", "comments": "Appears in AAAI-17", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Entity resolution (ER) is the task of identifying all records in a database\nthat refer to the same underlying entity, and are therefore duplicates of each\nother. Due to inherent ambiguity of data representation and poor data quality,\nER is a challenging task for any automated process. As a remedy, human-powered\nER via crowdsourcing has become popular in recent years. Using crowd to answer\nqueries is costly and time consuming. Furthermore, crowd-answers can often be\nfaulty. Therefore, crowd-based ER methods aim to minimize human participation\nwithout sacrificing the quality and use a computer generated similarity matrix\nactively. While, some of these methods perform well in practice, no theoretical\nanalysis exists for them, and further their worst case performances do not\nreflect the experimental findings. This creates a disparity in the\nunderstanding of the popular heuristics for this problem. In this paper, we\nmake the first attempt to close this gap. We provide a thorough analysis of the\nprominent heuristic algorithms for crowd-based ER. We justify experimental\nobservations with our analysis and information theoretic lower bounds.\n", "versions": [{"version": "v1", "created": "Fri, 3 Feb 2017 23:56:58 GMT"}], "update_date": "2017-02-07", "authors_parsed": [["Mazumdar", "Arya", ""], ["Saha", "Barna", ""]]}, {"id": "1702.01226", "submitter": "Mengchen Liu", "authors": "Shixia Liu, Xiting Wang, Mengchen Liu, Jun Zhu", "title": "Towards Better Analysis of Machine Learning Models: A Visual Analytics\n  Perspective", "comments": "This article will be published in Visual Infomatics", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interactive model analysis, the process of understanding, diagnosing, and\nrefining a machine learning model with the help of interactive visualization,\nis very important for users to efficiently solve real-world artificial\nintelligence and data mining problems. Dramatic advances in big data analytics\nhas led to a wide variety of interactive model analysis tasks. In this paper,\nwe present a comprehensive analysis and interpretation of this rapidly\ndeveloping area. Specifically, we classify the relevant work into three\ncategories: understanding, diagnosis, and refinement. Each category is\nexemplified by recent influential work. Possible future research opportunities\nare also explored and discussed.\n", "versions": [{"version": "v1", "created": "Sat, 4 Feb 2017 02:23:55 GMT"}], "update_date": "2017-02-07", "authors_parsed": [["Liu", "Shixia", ""], ["Wang", "Xiting", ""], ["Liu", "Mengchen", ""], ["Zhu", "Jun", ""]]}, {"id": "1702.01228", "submitter": "Wenshuo Wang", "authors": "Wenshuo Wang and Ding Zhao and Junqiang Xi and Wei Han", "title": "A Learning-Based Approach for Lane Departure Warning Systems with a\n  Personalized Driver Model", "comments": "12 pages, 13 figures, Journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Misunderstanding of driver correction behaviors (DCB) is the primary reason\nfor false warnings of lane-departure-prediction systems. We propose a\nlearning-based approach to predicting unintended lane-departure behaviors (LDB)\nand the chance for drivers to bring the vehicle back to the lane. First, in\nthis approach, a personalized driver model for lane-departure and lane-keeping\nbehavior is established by combining the Gaussian mixture model and the hidden\nMarkov model. Second, based on this model, we develop an online model-based\nprediction algorithm to predict the forthcoming vehicle trajectory and judge\nwhether the driver will demonstrate an LDB or a DCB. We also develop a warning\nstrategy based on the model-based prediction algorithm that allows the\nlane-departure warning system to be acceptable for drivers according to the\npredicted trajectory. In addition, the naturalistic driving data of 10 drivers\nis collected through the University of Michigan Safety Pilot Model Deployment\nprogram to train the personalized driver model and validate this approach. We\ncompare the proposed method with a basic time-to-lane-crossing (TLC) method and\na TLC-directional sequence of piecewise lateral slopes (TLC-DSPLS) method. The\nresults show that the proposed approach can reduce the false-warning rate to\n3.07\\%.\n", "versions": [{"version": "v1", "created": "Sat, 4 Feb 2017 02:54:34 GMT"}], "update_date": "2017-02-07", "authors_parsed": [["Wang", "Wenshuo", ""], ["Zhao", "Ding", ""], ["Xi", "Junqiang", ""], ["Han", "Wei", ""]]}, {"id": "1702.01229", "submitter": "Minnan Luo", "authors": "Minnan Luo and Xiaojun Chang and Zhihui Li and Liqiang Nie and\n  Alexander G. Hauptmann and Qinghua Zheng", "title": "Simple to Complex Cross-modal Learning to Rank", "comments": "14 pages; Accepted by Computer Vision and Image Understanding", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The heterogeneity-gap between different modalities brings a significant\nchallenge to multimedia information retrieval. Some studies formalize the\ncross-modal retrieval tasks as a ranking problem and learn a shared multi-modal\nembedding space to measure the cross-modality similarity. However, previous\nmethods often establish the shared embedding space based on linear mapping\nfunctions which might not be sophisticated enough to reveal more complicated\ninter-modal correspondences. Additionally, current studies assume that the\nrankings are of equal importance, and thus all rankings are used\nsimultaneously, or a small number of rankings are selected randomly to train\nthe embedding space at each iteration. Such strategies, however, always suffer\nfrom outliers as well as reduced generalization capability due to their lack of\ninsightful understanding of procedure of human cognition. In this paper, we\ninvolve the self-paced learning theory with diversity into the cross-modal\nlearning to rank and learn an optimal multi-modal embedding space based on\nnon-linear mapping functions. This strategy enhances the model's robustness to\noutliers and achieves better generalization via training the model gradually\nfrom easy rankings by diverse queries to more complex ones. An efficient\nalternative algorithm is exploited to solve the proposed challenging problem\nwith fast convergence in practice. Extensive experimental results on several\nbenchmark datasets indicate that the proposed method achieves significant\nimprovements over the state-of-the-arts in this literature.\n", "versions": [{"version": "v1", "created": "Sat, 4 Feb 2017 03:06:01 GMT"}, {"version": "v2", "created": "Fri, 7 Jul 2017 18:31:28 GMT"}], "update_date": "2017-07-11", "authors_parsed": [["Luo", "Minnan", ""], ["Chang", "Xiaojun", ""], ["Li", "Zhihui", ""], ["Nie", "Liqiang", ""], ["Hauptmann", "Alexander G.", ""], ["Zheng", "Qinghua", ""]]}, {"id": "1702.01268", "submitter": "Giorgio Valentini", "authors": "Jessica Gliozzo", "title": "Network-based methods for outcome prediction in the \"sample space\"", "comments": "MSc Thesis, Advisor: G. Valentini, Co-Advisors: A. Paccanaro and M.\n  Re, 92 pages, 36 figures, 10 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this thesis we present the novel semi-supervised network-based algorithm\nP-Net, which is able to rank and classify patients with respect to a specific\nphenotype or clinical outcome under study. The peculiar and innovative\ncharacteristic of this method is that it builds a network of samples/patients,\nwhere the nodes represent the samples and the edges are functional or genetic\nrelationships between individuals (e.g. similarity of expression profiles), to\npredict the phenotype under study. In other words, it constructs the network in\nthe \"sample space\" and not in the \"biomarker space\" (where nodes represent\nbiomolecules (e.g. genes, proteins) and edges represent functional or genetic\nrelationships between nodes), as usual in state-of-the-art methods. To assess\nthe performances of P-Net, we apply it on three different publicly available\ndatasets from patients afflicted with a specific type of tumor: pancreatic\ncancer, melanoma and ovarian cancer dataset, by using the data and following\nthe experimental set-up proposed in two recently published papers [Barter et\nal., 2014, Winter et al., 2012]. We show that network-based methods in the\n\"sample space\" can achieve results competitive with classical supervised\ninductive systems. Moreover, the graph representation of the samples can be\neasily visualized through networks and can be used to gain visual clues about\nthe relationships between samples, taking into account the phenotype associated\nor predicted for each sample. To our knowledge this is one of the first works\nthat proposes graph-based algorithms working in the \"sample space\" of the\nbiomolecular profiles of the patients to predict their phenotype or outcome,\nthus contributing to a novel research line in the framework of the Network\nMedicine.\n", "versions": [{"version": "v1", "created": "Sat, 4 Feb 2017 11:18:53 GMT"}], "update_date": "2017-02-07", "authors_parsed": [["Gliozzo", "Jessica", ""]]}, {"id": "1702.01293", "submitter": "Margarita Osadchy", "authors": "Dolev Raviv and Margarita Osadchy", "title": "Latent Hinge-Minimax Risk Minimization for Inference from a Small Number\n  of Training Samples", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Learning (DL) methods show very good performance when trained on large,\nbalanced data sets. However, many practical problems involve imbalanced data\nsets, or/and classes with a small number of training samples. The performance\nof DL methods as well as more traditional classifiers drops significantly in\nsuch settings. Most of the existing solutions for imbalanced problems focus on\ncustomizing the data for training. A more principled solution is to use mixed\nHinge-Minimax risk [19] specifically designed to solve binary problems with\nimbalanced training sets. Here we propose a Latent Hinge Minimax (LHM) risk and\na training algorithm that generalizes this paradigm to an ensemble of\nhyperplanes that can form arbitrary complex, piecewise linear boundaries. To\nextract good features, we combine LHM model with CNN via transfer learning. To\nsolve multi-class problem we map pre-trained category-specific LHM classifiers\nto a multi-class neural network and adjust the weights with very fast tuning.\nLHM classifier enables the use of unlabeled data in its training and the\nmapping allows for multi-class inference, resulting in a classifier that\nperforms better than alternatives when trained on a small number of training\nsamples.\n", "versions": [{"version": "v1", "created": "Sat, 4 Feb 2017 14:33:16 GMT"}], "update_date": "2017-02-07", "authors_parsed": [["Raviv", "Dolev", ""], ["Osadchy", "Margarita", ""]]}, {"id": "1702.01313", "submitter": "Bas van Stein", "authors": "Bas van Stein, Hao Wang, Wojtek Kowalczyk, Michael Emmerich, Thomas\n  B\\\"ack", "title": "Cluster-based Kriging Approximation Algorithms for Complexity Reduction", "comments": "Submitted to IEEE Computational Intelligence Magazine for review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Kriging or Gaussian Process Regression is applied in many fields as a\nnon-linear regression model as well as a surrogate model in the field of\nevolutionary computation. However, the computational and space complexity of\nKriging, that is cubic and quadratic in the number of data points respectively,\nbecomes a major bottleneck with more and more data available nowadays. In this\npaper, we propose a general methodology for the complexity reduction, called\ncluster Kriging, where the whole data set is partitioned into smaller clusters\nand multiple Kriging models are built on top of them. In addition, four Kriging\napproximation algorithms are proposed as candidate algorithms within the new\nframework. Each of these algorithms can be applied to much larger data sets\nwhile maintaining the advantages and power of Kriging. The proposed algorithms\nare explained in detail and compared empirically against a broad set of\nexisting state-of-the-art Kriging approximation methods on a well-defined\ntesting framework. According to the empirical study, the proposed algorithms\nconsistently outperform the existing algorithms. Moreover, some practical\nsuggestions are provided for using the proposed algorithms.\n", "versions": [{"version": "v1", "created": "Sat, 4 Feb 2017 17:54:59 GMT"}], "update_date": "2017-02-07", "authors_parsed": [["van Stein", "Bas", ""], ["Wang", "Hao", ""], ["Kowalczyk", "Wojtek", ""], ["Emmerich", "Michael", ""], ["B\u00e4ck", "Thomas", ""]]}, {"id": "1702.01334", "submitter": "Shervin Minaee", "authors": "Shervin Minaee, Amirali Abdolrashidi and Yao Wang", "title": "An Experimental Study of Deep Convolutional Features For Iris\n  Recognition", "comments": "IEEE Signal Processing in Medicine and Biology Symposium, 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Iris is one of the popular biometrics that is widely used for identity\nauthentication. Different features have been used to perform iris recognition\nin the past. Most of them are based on hand-crafted features designed by\nbiometrics experts. Due to tremendous success of deep learning in computer\nvision problems, there has been a lot of interest in applying features learned\nby convolutional neural networks on general image recognition to other tasks\nsuch as segmentation, face recognition, and object detection. In this paper, we\nhave investigated the application of deep features extracted from VGG-Net for\niris recognition. The proposed scheme has been tested on two well-known iris\ndatabases, and has shown promising results with the best accuracy rate of\n99.4\\%, which outperforms the previous best result.\n", "versions": [{"version": "v1", "created": "Sat, 4 Feb 2017 19:54:48 GMT"}], "update_date": "2019-01-09", "authors_parsed": [["Minaee", "Shervin", ""], ["Abdolrashidi", "Amirali", ""], ["Wang", "Yao", ""]]}, {"id": "1702.01361", "submitter": "Kyle Mills", "authors": "Kyle Mills, Michael Spanner, and Isaac Tamblyn", "title": "Deep learning and the Schr\\\"odinger equation", "comments": null, "journal-ref": "Phys. Rev. A 96, 042113 (2017)", "doi": "10.1103/PhysRevA.96.042113", "report-no": null, "categories": "cond-mat.mtrl-sci cs.LG physics.chem-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We have trained a deep (convolutional) neural network to predict the\nground-state energy of an electron in four classes of confining two-dimensional\nelectrostatic potentials. On randomly generated potentials, for which there is\nno analytic form for either the potential or the ground-state energy, the\nneural network model was able to predict the ground-state energy to within\nchemical accuracy, with a median absolute error of 1.49 mHa. We also\ninvestigate the performance of the model in predicting other quantities such as\nthe kinetic energy and the first excited-state energy of random potentials.\n", "versions": [{"version": "v1", "created": "Sun, 5 Feb 2017 02:58:58 GMT"}, {"version": "v2", "created": "Thu, 8 Jun 2017 20:39:27 GMT"}, {"version": "v3", "created": "Fri, 3 Nov 2017 13:10:51 GMT"}], "update_date": "2017-11-06", "authors_parsed": [["Mills", "Kyle", ""], ["Spanner", "Michael", ""], ["Tamblyn", "Isaac", ""]]}, {"id": "1702.01460", "submitter": "Piotr Szyma\\'nski", "authors": "Piotr Szyma\\'nski, Tomasz Kajdanowicz", "title": "A scikit-based Python environment for performing multi-label\n  classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  scikit-multilearn is a Python library for performing multi-label\nclassification. The library is compatible with the scikit/scipy ecosystem and\nuses sparse matrices for all internal operations. It provides native Python\nimplementations of popular multi-label classification methods alongside a novel\nframework for label space partitioning and division. It includes modern\nalgorithm adaptation methods, network-based label space division approaches,\nwhich extracts label dependency information and multi-label embedding\nclassifiers. It provides python wrapped access to the extensive multi-label\nmethod stack from Java libraries and makes it possible to extend deep learning\nsingle-label methods for multi-label tasks. The library allows multi-label\nstratification and data set management. The implementation is more efficient in\nproblem transformation than other established libraries, has good test coverage\nand follows PEP8. Source code and documentation can be downloaded from\nhttp://scikit.ml and also via pip. The library follows BSD licensing scheme.\n", "versions": [{"version": "v1", "created": "Sun, 5 Feb 2017 22:28:20 GMT"}, {"version": "v2", "created": "Tue, 7 Feb 2017 17:28:44 GMT"}, {"version": "v3", "created": "Thu, 9 Feb 2017 15:03:23 GMT"}, {"version": "v4", "created": "Fri, 7 Dec 2018 10:39:48 GMT"}, {"version": "v5", "created": "Mon, 10 Dec 2018 15:01:50 GMT"}], "update_date": "2018-12-11", "authors_parsed": [["Szyma\u0144ski", "Piotr", ""], ["Kajdanowicz", "Tomasz", ""]]}, {"id": "1702.01504", "submitter": "Qiuyan Yan", "authors": "Qiuyan Yan, Shixiong Xia, Fanrong Meng", "title": "Optimizing Cost-Sensitive SVM for Imbalanced Data :Connecting Cluster to\n  Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Class imbalance is one of the challenging problems for machine learning in\nmany real-world applications, such as coal and gas burst accident monitoring:\nthe burst premonition data is extreme smaller than the normal data, however,\nwhich is the highlight we truly focus on. Cost-sensitive adjustment approach is\na typical algorithm-level method resisting the data set imbalance. For SVMs\nclassifier, which is modified to incorporate varying penalty parameter(C) for\neach of considered groups of examples. However, the C value is determined\nempirically, or is calculated according to the evaluation metric, which need to\nbe computed iteratively and time consuming. This paper presents a novel\ncost-sensitive SVM method whose penalty parameter C optimized on the basis of\ncluster probability density function(PDF) and the cluster PDF is estimated only\naccording to similarity matrix and some predefined hyper-parameters.\nExperimental results on various standard benchmark data sets and real-world\ndata with different ratios of imbalance show that the proposed method is\neffective in comparison with commonly used cost-sensitive techniques.\n", "versions": [{"version": "v1", "created": "Mon, 6 Feb 2017 06:14:29 GMT"}], "update_date": "2017-02-07", "authors_parsed": [["Yan", "Qiuyan", ""], ["Xia", "Shixiong", ""], ["Meng", "Fanrong", ""]]}, {"id": "1702.01691", "submitter": "Zihang Dai", "authors": "Zihang Dai, Amjad Almahairi, Philip Bachman, Eduard Hovy, Aaron\n  Courville", "title": "Calibrating Energy-based Generative Adversarial Networks", "comments": "ICLR 2017 camera ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we propose to equip Generative Adversarial Networks with the\nability to produce direct energy estimates for samples.Specifically, we propose\na flexible adversarial training framework, and prove this framework not only\nensures the generator converges to the true data distribution, but also enables\nthe discriminator to retain the density information at the global optimal. We\nderive the analytic form of the induced solution, and analyze the properties.\nIn order to make the proposed framework trainable in practice, we introduce two\neffective approximation techniques. Empirically, the experiment results closely\nmatch our theoretical analysis, verifying the discriminator is able to recover\nthe energy of data distribution.\n", "versions": [{"version": "v1", "created": "Mon, 6 Feb 2017 16:30:13 GMT"}, {"version": "v2", "created": "Fri, 24 Feb 2017 01:38:09 GMT"}], "update_date": "2017-02-27", "authors_parsed": [["Dai", "Zihang", ""], ["Almahairi", "Amjad", ""], ["Bachman", "Philip", ""], ["Hovy", "Eduard", ""], ["Courville", "Aaron", ""]]}, {"id": "1702.01717", "submitter": "Zeeshan Malik Khawar", "authors": "Zeeshan Khawar Malik, Mo Kobrosli and Peter Maas", "title": "Search Intelligence: Deep Learning For Dominant Category Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Neural Networks, and specifically fully-connected convolutional neural\nnetworks are achieving remarkable results across a wide variety of domains.\nThey have been trained to achieve state-of-the-art performance when applied to\nproblems such as speech recognition, image classification, natural language\nprocessing and bioinformatics. Most of these deep learning models when applied\nto classification employ the softmax activation function for prediction and aim\nto minimize cross-entropy loss. In this paper, we have proposed a supervised\nmodel for dominant category prediction to improve search recall across all eBay\nclassifieds platforms. The dominant category label for each query in the last\n90 days is first calculated by summing the total number of collaborative clicks\namong all categories. The category having the highest number of collaborative\nclicks for the given query will be considered its dominant category. Second,\neach query is transformed to a numeric vector by mapping each unique word in\nthe query document to a unique integer value; all padded to equal length based\non the maximum document length within the pre-defined vocabulary size. A\nfully-connected deep convolutional neural network (CNN) is then applied for\nclassification. The proposed model achieves very high classification accuracy\ncompared to other state-of-the-art machine learning techniques.\n", "versions": [{"version": "v1", "created": "Mon, 6 Feb 2017 17:27:12 GMT"}], "update_date": "2017-02-07", "authors_parsed": [["Malik", "Zeeshan Khawar", ""], ["Kobrosli", "Mo", ""], ["Maas", "Peter", ""]]}, {"id": "1702.01780", "submitter": "Randal Olson", "authors": "Andrew Sohn and Randal S. Olson and Jason H. Moore", "title": "Toward the automated analysis of complex diseases in genome-wide\n  association studies using genetic programming", "comments": "9 pages, 4 figures, submitted to GECCO 2017 conference and currently\n  under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning has been gaining traction in recent years to meet the demand\nfor tools that can efficiently analyze and make sense of the ever-growing\ndatabases of biomedical data in health care systems around the world. However,\neffectively using machine learning methods requires considerable domain\nexpertise, which can be a barrier of entry for bioinformaticians new to\ncomputational data science methods. Therefore, off-the-shelf tools that make\nmachine learning more accessible can prove invaluable for bioinformaticians. To\nthis end, we have developed an open source pipeline optimization tool\n(TPOT-MDR) that uses genetic programming to automatically design machine\nlearning pipelines for bioinformatics studies. In TPOT-MDR, we implement\nMultifactor Dimensionality Reduction (MDR) as a feature construction method for\nmodeling higher-order feature interactions, and combine it with a new expert\nknowledge-guided feature selector for large biomedical data sets. We\ndemonstrate TPOT-MDR's capabilities using a combination of simulated and real\nworld data sets from human genetics and find that TPOT-MDR significantly\noutperforms modern machine learning methods such as logistic regression and\neXtreme Gradient Boosting (XGBoost). We further analyze the best pipeline\ndiscovered by TPOT-MDR for a real world problem and highlight TPOT-MDR's\nability to produce a high-accuracy solution that is also easily interpretable.\n", "versions": [{"version": "v1", "created": "Mon, 6 Feb 2017 20:10:10 GMT"}], "update_date": "2017-02-08", "authors_parsed": [["Sohn", "Andrew", ""], ["Olson", "Randal S.", ""], ["Moore", "Jason H.", ""]]}, {"id": "1702.01824", "submitter": "Franziska Horn", "authors": "Franziska Horn and Klaus-Robert M\\\"uller", "title": "Predicting Pairwise Relations with Neural Similarity Encoders", "comments": "find code here: https://github.com/cod3licious/simec", "journal-ref": "Bulletin of the Polish Academy of Sciences: Technical Sciences,\n  66(6):821-830, 2018", "doi": "10.24425/bpas.2018.125929", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Matrix factorization is at the heart of many machine learning algorithms, for\nexample, dimensionality reduction (e.g. kernel PCA) or recommender systems\nrelying on collaborative filtering. Understanding a singular value\ndecomposition (SVD) of a matrix as a neural network optimization problem\nenables us to decompose large matrices efficiently while dealing naturally with\nmissing values in the given matrix. But most importantly, it allows us to learn\nthe connection between data points' feature vectors and the matrix containing\ninformation about their pairwise relations. In this paper we introduce a novel\nneural network architecture termed Similarity Encoder (SimEc), which is\ndesigned to simultaneously factorize a given target matrix while also learning\nthe mapping to project the data points' feature vectors into a similarity\npreserving embedding space. This makes it possible to, for example, easily\ncompute out-of-sample solutions for new data points. Additionally, we\ndemonstrate that SimEc can preserve non-metric similarities and even predict\nmultiple pairwise relations between data points at once.\n", "versions": [{"version": "v1", "created": "Mon, 6 Feb 2017 23:46:40 GMT"}, {"version": "v2", "created": "Wed, 9 Jan 2019 21:56:45 GMT"}], "update_date": "2019-01-11", "authors_parsed": [["Horn", "Franziska", ""], ["M\u00fcller", "Klaus-Robert", ""]]}, {"id": "1702.01829", "submitter": "Yangfeng Ji", "authors": "Yangfeng Ji, Noah Smith", "title": "Neural Discourse Structure for Text Categorization", "comments": "ACL 2017 camera ready version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that discourse structure, as defined by Rhetorical Structure Theory\nand provided by an existing discourse parser, benefits text categorization. Our\napproach uses a recursive neural network and a newly proposed attention\nmechanism to compute a representation of the text that focuses on salient\ncontent, from the perspective of both RST and the task. Experiments consider\nvariants of the approach and illustrate its strengths and weaknesses.\n", "versions": [{"version": "v1", "created": "Tue, 7 Feb 2017 00:26:56 GMT"}, {"version": "v2", "created": "Sat, 6 May 2017 02:08:57 GMT"}], "update_date": "2017-05-09", "authors_parsed": [["Ji", "Yangfeng", ""], ["Smith", "Noah", ""]]}, {"id": "1702.01847", "submitter": "Mostafa Rahmani", "authors": "Mostafa Rahmani, George Atia", "title": "Low Rank Matrix Recovery with Simultaneous Presence of Outliers and\n  Sparse Corruption", "comments": null, "journal-ref": null, "doi": "10.1109/JSTSP.2018.2876604", "report-no": null, "categories": "stat.ML cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a data model in which the data matrix D can be expressed as D = L +\nS + C, where L is a low rank matrix, S an element-wise sparse matrix and C a\nmatrix whose non-zero columns are outlying data points. To date, robust PCA\nalgorithms have solely considered models with either S or C, but not both. As\nsuch, existing algorithms cannot account for simultaneous element-wise and\ncolumn-wise corruptions. In this paper, a new robust PCA algorithm that is\nrobust to simultaneous types of corruption is proposed. Our approach hinges on\nthe sparse approximation of a sparsely corrupted column so that the sparse\nexpansion of a column with respect to the other data points is used to\ndistinguish a sparsely corrupted inlier column from an outlying data point. We\nalso develop a randomized design which provides a scalable implementation of\nthe proposed approach. The core idea of sparse approximation is analyzed\nanalytically where we show that the underlying ell_1-norm minimization can\nobtain the representation of an inlier in presence of sparse corruptions.\n", "versions": [{"version": "v1", "created": "Tue, 7 Feb 2017 02:08:51 GMT"}], "update_date": "2019-01-30", "authors_parsed": [["Rahmani", "Mostafa", ""], ["Atia", "George", ""]]}, {"id": "1702.01856", "submitter": "Lijun Zhu", "authors": "Lijun Zhu, Lindsay Chuang, James H. McClellan, Entao Liu, and Zhigang\n  Peng", "title": "A multi-channel approach for automatic microseismic event association\n  using RANSAC-based arrival time event clustering(RATEC)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.geo-ph cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the presence of background noise, arrival times picked from a surface\nmicroseismic data set usually include a number of false picks that can lead to\nuncertainty in location estimation. To eliminate false picks and improve the\naccuracy of location estimates, we develop an association algorithm termed\nRANSAC-based Arrival Time Event Clustering (RATEC) that clusters picked arrival\ntimes into event groups based on random sampling and fitting moveout curves\nthat approximate hyperbolas. Arrival times far from the fitted hyperbolas are\nclassified as false picks and removed from the data set prior to location\nestimation. Simulations of synthetic data for a 1-D linear array show that\nRATEC is robust under different noise conditions and generally applicable to\nvarious types of subsurface structures. By generalizing the underlying moveout\nmodel, RATEC is extended to the case of a 2-D surface monitoring array. The\neffectiveness of event location for the 2-D case is demonstrated using a data\nset collected by the 5200-element dense Long Beach array. The obtained results\nsuggest that RATEC is effective in removing false picks and hence can be used\nfor phase association before location estimates.\n", "versions": [{"version": "v1", "created": "Tue, 7 Feb 2017 02:48:34 GMT"}, {"version": "v2", "created": "Wed, 15 Feb 2017 21:16:12 GMT"}, {"version": "v3", "created": "Tue, 4 May 2021 14:27:44 GMT"}], "update_date": "2021-05-05", "authors_parsed": [["Zhu", "Lijun", ""], ["Chuang", "Lindsay", ""], ["McClellan", "James H.", ""], ["Liu", "Entao", ""], ["Peng", "Zhigang", ""]]}, {"id": "1702.01935", "submitter": "Shuisheng Zhou", "authors": "Li Chen and Shuisheng Zhou", "title": "Sparse Algorithm for Robust LSSVM in Primal Space", "comments": "22 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As enjoying the closed form solution, least squares support vector machine\n(LSSVM) has been widely used for classification and regression problems having\nthe comparable performance with other types of SVMs. However, LSSVM has two\ndrawbacks: sensitive to outliers and lacking sparseness. Robust LSSVM (R-LSSVM)\novercomes the first partly via nonconvex truncated loss function, but the\ncurrent algorithms for R-LSSVM with the dense solution are faced with the\nsecond drawback and are inefficient for training large-scale problems. In this\npaper, we interpret the robustness of R-LSSVM from a re-weighted viewpoint and\ngive a primal R-LSSVM by the representer theorem. The new model may have sparse\nsolution if the corresponding kernel matrix has low rank. Then approximating\nthe kernel matrix by a low-rank matrix and smoothing the loss function by\nentropy penalty function, we propose a convergent sparse R-LSSVM (SR-LSSVM)\nalgorithm to achieve the sparse solution of primal R-LSSVM, which overcomes two\ndrawbacks of LSSVM simultaneously. The proposed algorithm has lower complexity\nthan the existing algorithms and is very efficient for training large-scale\nproblems. Many experimental results illustrate that SR-LSSVM can achieve better\nor comparable performance with less training time than related algorithms,\nespecially for training large scale problems.\n", "versions": [{"version": "v1", "created": "Tue, 7 Feb 2017 09:24:26 GMT"}], "update_date": "2017-02-08", "authors_parsed": [["Chen", "Li", ""], ["Zhou", "Shuisheng", ""]]}, {"id": "1702.01948", "submitter": "Ali Khodadadi", "authors": "Ali Khodadadi, Seyed Abbas Hosseini, Erfan Tavakoli, Hamid R. Rabiee", "title": "Continuous-Time User Modeling in the Presence of Badges: A Probabilistic\n  Approach", "comments": "27 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  User modeling plays an important role in delivering customized web services\nto the users and improving their engagement. However, most user models in the\nliterature do not explicitly consider the temporal behavior of users. More\nrecently, continuous-time user modeling has gained considerable attention and\nmany user behavior models have been proposed based on temporal point processes.\nHowever, typical point process based models often considered the impact of peer\ninfluence and content on the user participation and neglected other factors.\nGamification elements, are among those factors that are neglected, while they\nhave a strong impact on user participation in online services. In this paper,\nwe propose interdependent multi-dimensional temporal point processes that\ncapture the impact of badges on user participation besides the peer influence\nand content factors. We extend the proposed processes to model user actions\nover the community based question and answering websites, and propose an\ninference algorithm based on Variational-EM that can efficiently learn the\nmodel parameters. Extensive experiments on both synthetic and real data\ngathered from Stack Overflow show that our inference algorithm learns the\nparameters efficiently and the proposed method can better predict the user\nbehavior compared to the alternatives.\n", "versions": [{"version": "v1", "created": "Tue, 7 Feb 2017 10:32:42 GMT"}], "update_date": "2017-02-08", "authors_parsed": [["Khodadadi", "Ali", ""], ["Hosseini", "Seyed Abbas", ""], ["Tavakoli", "Erfan", ""], ["Rabiee", "Hamid R.", ""]]}, {"id": "1702.01991", "submitter": "Grzegorz Chrupa{\\l}a", "authors": "Grzegorz Chrupa{\\l}a, Lieke Gelderloos, Afra Alishahi", "title": "Representations of language in a model of visually grounded speech\n  signal", "comments": "Accepted at ACL 2017", "journal-ref": null, "doi": "10.18653/v1/P17-1057", "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present a visually grounded model of speech perception which projects\nspoken utterances and images to a joint semantic space. We use a multi-layer\nrecurrent highway network to model the temporal nature of spoken speech, and\nshow that it learns to extract both form and meaning-based linguistic knowledge\nfrom the input signal. We carry out an in-depth analysis of the representations\nused by different components of the trained model and show that encoding of\nsemantic aspects tends to become richer as we go up the hierarchy of layers,\nwhereas encoding of form-related aspects of the language input tends to\ninitially increase and then plateau or decrease.\n", "versions": [{"version": "v1", "created": "Tue, 7 Feb 2017 13:02:09 GMT"}, {"version": "v2", "created": "Thu, 1 Jun 2017 12:57:36 GMT"}, {"version": "v3", "created": "Fri, 30 Jun 2017 07:34:55 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Chrupa\u0142a", "Grzegorz", ""], ["Gelderloos", "Lieke", ""], ["Alishahi", "Afra", ""]]}, {"id": "1702.01992", "submitter": "John Arevalo", "authors": "John Arevalo, Thamar Solorio, Manuel Montes-y-G\\'omez, Fabio A.\n  Gonz\\'alez", "title": "Gated Multimodal Units for Information Fusion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a novel model for multimodal learning based on gated\nneural networks. The Gated Multimodal Unit (GMU) model is intended to be used\nas an internal unit in a neural network architecture whose purpose is to find\nan intermediate representation based on a combination of data from different\nmodalities. The GMU learns to decide how modalities influence the activation of\nthe unit using multiplicative gates. It was evaluated on a multilabel scenario\nfor genre classification of movies using the plot and the poster. The GMU\nimproved the macro f-score performance of single-modality approaches and\noutperformed other fusion strategies, including mixture of experts models.\nAlong with this work, the MM-IMDb dataset is released which, to the best of our\nknowledge, is the largest publicly available multimodal dataset for genre\nprediction on movies.\n", "versions": [{"version": "v1", "created": "Tue, 7 Feb 2017 13:05:19 GMT"}], "update_date": "2017-02-08", "authors_parsed": [["Arevalo", "John", ""], ["Solorio", "Thamar", ""], ["Montes-y-G\u00f3mez", "Manuel", ""], ["Gonz\u00e1lez", "Fabio A.", ""]]}, {"id": "1702.01997", "submitter": "Dennis Forster", "authors": "Dennis Forster and J\\\"org L\\\"ucke", "title": "Truncated Variational EM for Semi-Supervised Neural Simpletrons", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inference and learning for probabilistic generative networks is often very\nchallenging and typically prevents scalability to as large networks as used for\ndeep discriminative approaches. To obtain efficiently trainable, large-scale\nand well performing generative networks for semi-supervised learning, we here\ncombine two recent developments: a neural network reformulation of hierarchical\nPoisson mixtures (Neural Simpletrons), and a novel truncated variational EM\napproach (TV-EM). TV-EM provides theoretical guarantees for learning in\ngenerative networks, and its application to Neural Simpletrons results in\nparticularly compact, yet approximately optimal, modifications of learning\nequations. If applied to standard benchmarks, we empirically find, that\nlearning converges in fewer EM iterations, that the complexity per EM iteration\nis reduced, and that final likelihood values are higher on average. For the\ntask of classification on data sets with few labels, learning improvements\nresult in consistently lower error rates if compared to applications without\ntruncation. Experiments on the MNIST data set herein allow for comparison to\nstandard and state-of-the-art models in the semi-supervised setting. Further\nexperiments on the NIST SD19 data set show the scalability of the approach when\na manifold of additional unlabeled data is available.\n", "versions": [{"version": "v1", "created": "Tue, 7 Feb 2017 13:16:05 GMT"}], "update_date": "2017-02-08", "authors_parsed": [["Forster", "Dennis", ""], ["L\u00fccke", "J\u00f6rg", ""]]}, {"id": "1702.02030", "submitter": "Lijun Zhang", "authors": "Lijun Zhang, Tianbao Yang, Rong Jin", "title": "Empirical Risk Minimization for Stochastic Convex Optimization:\n  $O(1/n)$- and $O(1/n^2)$-type of Risk Bounds", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although there exist plentiful theories of empirical risk minimization (ERM)\nfor supervised learning, current theoretical understandings of ERM for a\nrelated problem---stochastic convex optimization (SCO), are limited. In this\nwork, we strengthen the realm of ERM for SCO by exploiting smoothness and\nstrong convexity conditions to improve the risk bounds. First, we establish an\n$\\widetilde{O}(d/n + \\sqrt{F_*/n})$ risk bound when the random function is\nnonnegative, convex and smooth, and the expected function is Lipschitz\ncontinuous, where $d$ is the dimensionality of the problem, $n$ is the number\nof samples, and $F_*$ is the minimal risk. Thus, when $F_*$ is small we obtain\nan $\\widetilde{O}(d/n)$ risk bound, which is analogous to the\n$\\widetilde{O}(1/n)$ optimistic rate of ERM for supervised learning. Second, if\nthe objective function is also $\\lambda$-strongly convex, we prove an\n$\\widetilde{O}(d/n + \\kappa F_*/n )$ risk bound where $\\kappa$ is the condition\nnumber, and improve it to $O(1/[\\lambda n^2] + \\kappa F_*/n)$ when\n$n=\\widetilde{\\Omega}(\\kappa d)$. As a result, we obtain an $O(\\kappa/n^2)$\nrisk bound under the condition that $n$ is large and $F_*$ is small, which to\nthe best of our knowledge, is the first $O(1/n^2)$-type of risk bound of ERM.\nThird, we stress that the above results are established in a unified framework,\nwhich allows us to derive new risk bounds under weaker conditions, e.g.,\nwithout convexity of the random function and Lipschitz continuity of the\nexpected function. Finally, we demonstrate that to achieve an $O(1/[\\lambda\nn^2] + \\kappa F_*/n)$ risk bound for supervised learning, the\n$\\widetilde{\\Omega}(\\kappa d)$ requirement on $n$ can be replaced with\n$\\Omega(\\kappa^2)$, which is dimensionality-independent.\n", "versions": [{"version": "v1", "created": "Tue, 7 Feb 2017 14:14:19 GMT"}], "update_date": "2017-02-08", "authors_parsed": [["Zhang", "Lijun", ""], ["Yang", "Tianbao", ""], ["Jin", "Rong", ""]]}, {"id": "1702.02047", "submitter": "Ziyuan Gao", "authors": "Ziyuan Gao, Christoph Ries, Hans Ulrich Simon and Sandra Zilles", "title": "Preference-based Teaching", "comments": "35 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new model of teaching named \"preference-based teaching\" and a\ncorresponding complexity parameter---the preference-based teaching dimension\n(PBTD)---representing the worst-case number of examples needed to teach any\nconcept in a given concept class. Although the PBTD coincides with the\nwell-known recursive teaching dimension (RTD) on finite classes, it is\nradically different on infinite ones: the RTD becomes infinite already for\ntrivial infinite classes (such as half-intervals) whereas the PBTD evaluates to\nreasonably small values for a wide collection of infinite classes including\nclasses consisting of so-called closed sets w.r.t. a given closure operator,\nincluding various classes related to linear sets over $\\mathbb{N}_0$ (whose RTD\nhad been studied quite recently) and including the class of Euclidean\nhalf-spaces. On top of presenting these concrete results, we provide the reader\nwith a theoretical framework (of a combinatorial flavor) which helps to derive\nbounds on the PBTD.\n", "versions": [{"version": "v1", "created": "Mon, 6 Feb 2017 18:40:32 GMT"}, {"version": "v2", "created": "Wed, 8 Feb 2017 11:37:57 GMT"}], "update_date": "2017-02-09", "authors_parsed": [["Gao", "Ziyuan", ""], ["Ries", "Christoph", ""], ["Simon", "Hans Ulrich", ""], ["Zilles", "Sandra", ""]]}, {"id": "1702.02052", "submitter": "Sebastian Ruder", "authors": "Sebastian Ruder, Parsa Ghaffari, and John G. Breslin", "title": "Knowledge Adaptation: Teaching to Adapt", "comments": "11 pages, 4 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Domain adaptation is crucial in many real-world applications where the\ndistribution of the training data differs from the distribution of the test\ndata. Previous Deep Learning-based approaches to domain adaptation need to be\ntrained jointly on source and target domain data and are therefore unappealing\nin scenarios where models need to be adapted to a large number of domains or\nwhere a domain is evolving, e.g. spam detection where attackers continuously\nchange their tactics.\n  To fill this gap, we propose Knowledge Adaptation, an extension of Knowledge\nDistillation (Bucilua et al., 2006; Hinton et al., 2015) to the domain\nadaptation scenario. We show how a student model achieves state-of-the-art\nresults on unsupervised domain adaptation from multiple sources on a standard\nsentiment analysis benchmark by taking into account the domain-specific\nexpertise of multiple teachers and the similarities between their domains.\n  When learning from a single teacher, using domain similarity to gauge\ntrustworthiness is inadequate. To this end, we propose a simple metric that\ncorrelates well with the teacher's accuracy in the target domain. We\ndemonstrate that incorporating high-confidence examples selected by this metric\nenables the student model to achieve state-of-the-art performance in the\nsingle-source scenario.\n", "versions": [{"version": "v1", "created": "Tue, 7 Feb 2017 14:59:45 GMT"}], "update_date": "2017-02-08", "authors_parsed": [["Ruder", "Sebastian", ""], ["Ghaffari", "Parsa", ""], ["Breslin", "John G.", ""]]}, {"id": "1702.02125", "submitter": "Eug\\'enio Rodrigues", "authors": "Eug\\'enio Rodrigues and Lu\\'isa Dias Pereira and Ad\\'elio Rodrigues\n  Gaspar and \\'Alvaro Gomes and Manuel Carlos Gameiro da Silva", "title": "Estimation of classrooms occupancy using a multi-layer perceptron", "comments": "6 pages, 2 figures, conference article", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a multi-layer perceptron model for the estimation of\nclassrooms number of occupants from sensed indoor environmental data-relative\nhumidity, air temperature, and carbon dioxide concentration. The modelling\ndatasets were collected from two classrooms in the Secondary School of Pombal,\nPortugal. The number of occupants and occupation periods were obtained from\nclass attendance reports. However, post-class occupancy was unknown and the\ndeveloped model is used to reconstruct the classrooms occupancy by filling the\nunreported periods. Different model structure and environment variables\ncombination were tested. The model with best accuracy had as input vector 10\nvariables of five averaged time intervals of relative humidity and carbon\ndioxide concentration. The model presented a mean square error of 1.99,\ncoefficient of determination of 0.96 with a significance of p-value < 0.001,\nand a mean absolute error of 1 occupant. These results show promising\nestimation capabilities in uncertain indoor environment conditions.\n", "versions": [{"version": "v1", "created": "Tue, 7 Feb 2017 18:17:25 GMT"}], "update_date": "2017-02-08", "authors_parsed": [["Rodrigues", "Eug\u00e9nio", ""], ["Pereira", "Lu\u00edsa Dias", ""], ["Gaspar", "Ad\u00e9lio Rodrigues", ""], ["Gomes", "\u00c1lvaro", ""], ["da Silva", "Manuel Carlos Gameiro", ""]]}, {"id": "1702.02144", "submitter": "Jarek Duda dr", "authors": "Jarek Duda", "title": "Rapid parametric density estimation", "comments": "8 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Parametric density estimation, for example as Gaussian distribution, is the\nbase of the field of statistics. Machine learning requires inexpensive\nestimation of much more complex densities, and the basic approach is relatively\ncostly maximum likelihood estimation (MLE). There will be discussed inexpensive\ndensity estimation, for example literally fitting a polynomial (or Fourier\nseries) to the sample, which coefficients are calculated by just averaging\nmonomials (or sine/cosine) over the sample. Another discussed basic application\nis fitting distortion to some standard distribution like Gaussian - analogously\nto ICA, but additionally allowing to reconstruct the disturbed density.\nFinally, by using weighted average, it can be also applied for estimation of\nnon-probabilistic densities, like modelling mass distribution, or for various\nclustering problems by using negative (or complex) weights: fitting a function\nwhich sign (or argument) determines clusters. The estimated parameters are\napproaching the optimal values with error dropping like $1/\\sqrt{n}$, where $n$\nis the sample size.\n", "versions": [{"version": "v1", "created": "Tue, 7 Feb 2017 16:55:37 GMT"}, {"version": "v2", "created": "Mon, 20 Feb 2017 14:29:27 GMT"}], "update_date": "2017-02-21", "authors_parsed": [["Duda", "Jarek", ""]]}, {"id": "1702.02181", "submitter": "Moshe Looks", "authors": "Moshe Looks, Marcello Herreshoff, DeLesley Hutchins, Peter Norvig", "title": "Deep Learning with Dynamic Computation Graphs", "comments": "Published as a conference paper at ICLR 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks that compute over graph structures are a natural fit for\nproblems in a variety of domains, including natural language (parse trees) and\ncheminformatics (molecular graphs). However, since the computation graph has a\ndifferent shape and size for every input, such networks do not directly support\nbatched training or inference. They are also difficult to implement in popular\ndeep learning libraries, which are based on static data-flow graphs. We\nintroduce a technique called dynamic batching, which not only batches together\noperations between different input graphs of dissimilar shape, but also between\ndifferent nodes within a single input graph. The technique allows us to create\nstatic graphs, using popular libraries, that emulate dynamic computation graphs\nof arbitrary shape and size. We further present a high-level library of\ncompositional blocks that simplifies the creation of dynamic graph models.\nUsing the library, we demonstrate concise and batch-wise parallel\nimplementations for a variety of models from the literature.\n", "versions": [{"version": "v1", "created": "Tue, 7 Feb 2017 19:59:43 GMT"}, {"version": "v2", "created": "Wed, 22 Feb 2017 04:43:02 GMT"}], "update_date": "2017-02-23", "authors_parsed": [["Looks", "Moshe", ""], ["Herreshoff", "Marcello", ""], ["Hutchins", "DeLesley", ""], ["Norvig", "Peter", ""]]}, {"id": "1702.02184", "submitter": "Ramkumar Natarajan", "authors": "Sri Ramana Sekharan, Ramkumar Natarajan, Siddharthan Rajasekaran", "title": "Transfer from Multiple Linear Predictive State Representations (PSR)", "comments": "8 pages, 3 algorithms, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we tackle the problem of transferring policy from multiple\npartially observable source environments to a partially observable target\nenvironment modeled as predictive state representation. This is an entirely new\napproach with no previous work, other than the case of transfer in fully\nobservable domains. We develop algorithms to successfully achieve policy\ntransfer when we have the model of both the source and target tasks and discuss\nin detail their performance and shortcomings. These algorithms could be a\nstarting point for the field of transfer learning in partial observability.\n", "versions": [{"version": "v1", "created": "Tue, 7 Feb 2017 20:14:30 GMT"}], "update_date": "2017-02-09", "authors_parsed": [["Sekharan", "Sri Ramana", ""], ["Natarajan", "Ramkumar", ""], ["Rajasekaran", "Siddharthan", ""]]}, {"id": "1702.02206", "submitter": "Zhilin Yang", "authors": "Zhilin Yang, Junjie Hu, Ruslan Salakhutdinov, William W. Cohen", "title": "Semi-Supervised QA with Generative Domain-Adaptive Nets", "comments": "Accepted as a long paper at ACL2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of semi-supervised question answering----utilizing\nunlabeled text to boost the performance of question answering models. We\npropose a novel training framework, the Generative Domain-Adaptive Nets. In\nthis framework, we train a generative model to generate questions based on the\nunlabeled text, and combine model-generated questions with human-generated\nquestions for training question answering models. We develop novel domain\nadaptation algorithms, based on reinforcement learning, to alleviate the\ndiscrepancy between the model-generated data distribution and the\nhuman-generated data distribution. Experiments show that our proposed framework\nobtains substantial improvement from unlabeled text.\n", "versions": [{"version": "v1", "created": "Tue, 7 Feb 2017 21:23:01 GMT"}, {"version": "v2", "created": "Sat, 22 Apr 2017 20:31:01 GMT"}], "update_date": "2017-04-25", "authors_parsed": [["Yang", "Zhilin", ""], ["Hu", "Junjie", ""], ["Salakhutdinov", "Ruslan", ""], ["Cohen", "William W.", ""]]}, {"id": "1702.02215", "submitter": "Eleni Rozaki", "authors": "Cormac Dullaghan and Eleni Rozaki", "title": "Integration of Machine Learning Techniques to Evaluate Dynamic Customer\n  Segmentation Analysis for Mobile Customers", "comments": "12 pages", "journal-ref": "International Journal of Data Mining & Knowledge Management\n  Process (IJDKP) Vol.7, No.1, January 2017", "doi": "10.5121/ijdkp.2017.7102", "report-no": null, "categories": "cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The telecommunications industry is highly competitive, which means that the\nmobile providers need a business intelligence model that can be used to achieve\nan optimal level of churners, as well as a minimal level of cost in marketing\nactivities. Machine learning applications can be used to provide guidance on\nmarketing strategies. Furthermore, data mining techniques can be used in the\nprocess of customer segmentation. The purpose of this paper is to provide a\ndetailed analysis of the C.5 algorithm, within naive Bayesian modelling for the\ntask of segmenting telecommunication customers behavioural profiling according\nto their billing and socio-demographic aspects. Results have been\nexperimentally implemented.\n", "versions": [{"version": "v1", "created": "Tue, 31 Jan 2017 23:26:06 GMT"}], "update_date": "2017-02-09", "authors_parsed": [["Dullaghan", "Cormac", ""], ["Rozaki", "Eleni", ""]]}, {"id": "1702.02262", "submitter": "Quang N. Tran", "authors": "Quang N. Tran, Ba-Ngu Vo, Dinh Phung and Ba-Tuong Vo", "title": "Clustering For Point Pattern Data", "comments": "Preprint: 23rd Int. Conf. Pattern Recognition (ICPR). Cancun, Mexico,\n  December 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clustering is one of the most common unsupervised learning tasks in machine\nlearning and data mining. Clustering algorithms have been used in a plethora of\napplications across several scientific fields. However, there has been limited\nresearch in the clustering of point patterns - sets or multi-sets of unordered\nelements - that are found in numerous applications and data sources. In this\npaper, we propose two approaches for clustering point patterns. The first is a\nnon-parametric method based on novel distances for sets. The second is a\nmodel-based approach, formulated via random finite set theory, and solved by\nthe Expectation-Maximization algorithm. Numerical experiments show that the\nproposed methods perform well on both simulated and real data.\n", "versions": [{"version": "v1", "created": "Wed, 8 Feb 2017 03:21:22 GMT"}], "update_date": "2017-02-09", "authors_parsed": [["Tran", "Quang N.", ""], ["Vo", "Ba-Ngu", ""], ["Phung", "Dinh", ""], ["Vo", "Ba-Tuong", ""]]}, {"id": "1702.02267", "submitter": "Quan Li", "authors": "David Gamarnik, Quan Li and Hongyi Zhang", "title": "Matrix Completion from $O(n)$ Samples in Linear Time", "comments": "45 pages, 1 figure. Short version accepted for presentation at\n  Conference on Learning Theory (COLT) 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.DS cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of reconstructing a rank-$k$ $n \\times n$ matrix $M$\nfrom a sampling of its entries. Under a certain incoherence assumption on $M$\nand for the case when both the rank and the condition number of $M$ are\nbounded, it was shown in \\cite{CandesRecht2009, CandesTao2010, keshavan2010,\nRecht2011, Jain2012, Hardt2014} that $M$ can be recovered exactly or\napproximately (depending on some trade-off between accuracy and computational\ncomplexity) using $O(n \\, \\text{poly}(\\log n))$ samples in super-linear time\n$O(n^{a} \\, \\text{poly}(\\log n))$ for some constant $a \\geq 1$.\n  In this paper, we propose a new matrix completion algorithm using a novel\nsampling scheme based on a union of independent sparse random regular bipartite\ngraphs. We show that under the same conditions w.h.p. our algorithm recovers an\n$\\epsilon$-approximation of $M$ in terms of the Frobenius norm using $O(n\n\\log^2(1/\\epsilon))$ samples and in linear time $O(n \\log^2(1/\\epsilon))$. This\nprovides the best known bounds both on the sample complexity and computational\ncomplexity for reconstructing (approximately) an unknown low-rank matrix.\n  The novelty of our algorithm is two new steps of thresholding singular values\nand rescaling singular vectors in the application of the \"vanilla\" alternating\nminimization algorithm. The structure of sparse random regular graphs is used\nheavily for controlling the impact of these regularization steps.\n", "versions": [{"version": "v1", "created": "Wed, 8 Feb 2017 03:52:40 GMT"}, {"version": "v2", "created": "Sat, 3 Jun 2017 21:59:54 GMT"}, {"version": "v3", "created": "Tue, 6 Jun 2017 04:14:45 GMT"}, {"version": "v4", "created": "Tue, 22 Aug 2017 04:05:36 GMT"}], "update_date": "2017-08-23", "authors_parsed": [["Gamarnik", "David", ""], ["Li", "Quan", ""], ["Zhang", "Hongyi", ""]]}, {"id": "1702.02284", "submitter": "Sandy Huang", "authors": "Sandy Huang, Nicolas Papernot, Ian Goodfellow, Yan Duan, Pieter Abbeel", "title": "Adversarial Attacks on Neural Network Policies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning classifiers are known to be vulnerable to inputs maliciously\nconstructed by adversaries to force misclassification. Such adversarial\nexamples have been extensively studied in the context of computer vision\napplications. In this work, we show adversarial attacks are also effective when\ntargeting neural network policies in reinforcement learning. Specifically, we\nshow existing adversarial example crafting techniques can be used to\nsignificantly degrade test-time performance of trained policies. Our threat\nmodel considers adversaries capable of introducing small perturbations to the\nraw input of the policy. We characterize the degree of vulnerability across\ntasks and training algorithms, for a subclass of adversarial-example attacks in\nwhite-box and black-box settings. Regardless of the learned task or training\nalgorithm, we observe a significant drop in performance, even with small\nadversarial perturbations that do not interfere with human perception. Videos\nare available at http://rll.berkeley.edu/adversarial.\n", "versions": [{"version": "v1", "created": "Wed, 8 Feb 2017 04:33:55 GMT"}], "update_date": "2017-02-09", "authors_parsed": [["Huang", "Sandy", ""], ["Papernot", "Nicolas", ""], ["Goodfellow", "Ian", ""], ["Duan", "Yan", ""], ["Abbeel", "Pieter", ""]]}, {"id": "1702.02426", "submitter": "Sebastian Ruder", "authors": "Sebastian Ruder, Parsa Ghaffari, and John G. Breslin", "title": "Data Selection Strategies for Multi-Domain Sentiment Analysis", "comments": "10 pages, 2 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Domain adaptation is important in sentiment analysis as sentiment-indicating\nwords vary between domains. Recently, multi-domain adaptation has become more\npervasive, but existing approaches train on all available source domains\nincluding dissimilar ones. However, the selection of appropriate training data\nis as important as the choice of algorithm. We undertake -- to our knowledge\nfor the first time -- an extensive study of domain similarity metrics in the\ncontext of sentiment analysis and propose novel representations, metrics, and a\nnew scope for data selection. We evaluate the proposed methods on two\nlarge-scale multi-domain adaptation settings on tweets and reviews and\ndemonstrate that they consistently outperform strong random and balanced\nbaselines, while our proposed selection strategy outperforms instance-level\nselection and yields the best score on a large reviews corpus.\n", "versions": [{"version": "v1", "created": "Wed, 8 Feb 2017 13:49:59 GMT"}], "update_date": "2017-02-09", "authors_parsed": [["Ruder", "Sebastian", ""], ["Ghaffari", "Parsa", ""], ["Breslin", "John G.", ""]]}, {"id": "1702.02429", "submitter": "Jiatao Gu", "authors": "Jiatao Gu, Kyunghyun Cho and Victor O.K. Li", "title": "Trainable Greedy Decoding for Neural Machine Translation", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent research in neural machine translation has largely focused on two\naspects; neural network architectures and end-to-end learning algorithms. The\nproblem of decoding, however, has received relatively little attention from the\nresearch community. In this paper, we solely focus on the problem of decoding\ngiven a trained neural machine translation model. Instead of trying to build a\nnew decoding algorithm for any specific decoding objective, we propose the idea\nof trainable decoding algorithm in which we train a decoding algorithm to find\na translation that maximizes an arbitrary decoding objective. More\nspecifically, we design an actor that observes and manipulates the hidden state\nof the neural machine translation decoder and propose to train it using a\nvariant of deterministic policy gradient. We extensively evaluate the proposed\nalgorithm using four language pairs and two decoding objectives and show that\nwe can indeed train a trainable greedy decoder that generates a better\ntranslation (in terms of a target decoding objective) with minimal\ncomputational overhead.\n", "versions": [{"version": "v1", "created": "Wed, 8 Feb 2017 13:56:16 GMT"}], "update_date": "2017-02-09", "authors_parsed": [["Gu", "Jiatao", ""], ["Cho", "Kyunghyun", ""], ["Li", "Victor O. K.", ""]]}, {"id": "1702.02453", "submitter": "Wenhao Yu", "authors": "Wenhao Yu, Jie Tan, C. Karen Liu, Greg Turk", "title": "Preparing for the Unknown: Learning a Universal Policy with Online\n  System Identification", "comments": "Accepted as a conference paper at RSS 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new method of learning control policies that successfully\noperate under unknown dynamic models. We create such policies by leveraging a\nlarge number of training examples that are generated using a physical\nsimulator. Our system is made of two components: a Universal Policy (UP) and a\nfunction for Online System Identification (OSI). We describe our control policy\nas universal because it is trained over a wide array of dynamic models. These\nvariations in the dynamic model may include differences in mass and inertia of\nthe robots' components, variable friction coefficients, or unknown mass of an\nobject to be manipulated. By training the Universal Policy with this variation,\nthe control policy is prepared for a wider array of possible conditions when\nexecuted in an unknown environment. The second part of our system uses the\nrecent state and action history of the system to predict the dynamics model\nparameters mu. The value of mu from the Online System Identification is then\nprovided as input to the control policy (along with the system state).\nTogether, UP-OSI is a robust control policy that can be used across a wide\nrange of dynamic models, and that is also responsive to sudden changes in the\nenvironment. We have evaluated the performance of this system on a variety of\ntasks, including the problem of cart-pole swing-up, the double inverted\npendulum, locomotion of a hopper, and block-throwing of a manipulator. UP-OSI\nis effective at these tasks across a wide range of dynamic models. Moreover,\nwhen tested with dynamic models outside of the training range, UP-OSI\noutperforms the Universal Policy alone, even when UP is given the actual value\nof the model dynamics. In addition to the benefits of creating more robust\ncontrollers, UP-OSI also holds out promise of narrowing the Reality Gap between\nsimulated and real physical systems.\n", "versions": [{"version": "v1", "created": "Wed, 8 Feb 2017 14:53:45 GMT"}, {"version": "v2", "created": "Wed, 22 Feb 2017 17:08:31 GMT"}, {"version": "v3", "created": "Mon, 15 May 2017 13:37:58 GMT"}], "update_date": "2017-05-16", "authors_parsed": [["Yu", "Wenhao", ""], ["Tan", "Jie", ""], ["Liu", "C. Karen", ""], ["Turk", "Greg", ""]]}, {"id": "1702.02463", "submitter": "Ziwei Liu", "authors": "Ziwei Liu, Raymond A. Yeh, Xiaoou Tang, Yiming Liu, Aseem Agarwala", "title": "Video Frame Synthesis using Deep Voxel Flow", "comments": "To appear in ICCV 2017 as an oral paper. More details at the project\n  page: https://liuziwei7.github.io/projects/VoxelFlow.html", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.GR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the problem of synthesizing new video frames in an existing video,\neither in-between existing frames (interpolation), or subsequent to them\n(extrapolation). This problem is challenging because video appearance and\nmotion can be highly complex. Traditional optical-flow-based solutions often\nfail where flow estimation is challenging, while newer neural-network-based\nmethods that hallucinate pixel values directly often produce blurry results. We\ncombine the advantages of these two methods by training a deep network that\nlearns to synthesize video frames by flowing pixel values from existing ones,\nwhich we call deep voxel flow. Our method requires no human supervision, and\nany video can be used as training data by dropping, and then learning to\npredict, existing frames. The technique is efficient, and can be applied at any\nvideo resolution. We demonstrate that our method produces results that both\nquantitatively and qualitatively improve upon the state-of-the-art.\n", "versions": [{"version": "v1", "created": "Wed, 8 Feb 2017 15:20:14 GMT"}, {"version": "v2", "created": "Sat, 5 Aug 2017 04:43:44 GMT"}], "update_date": "2017-08-08", "authors_parsed": [["Liu", "Ziwei", ""], ["Yeh", "Raymond A.", ""], ["Tang", "Xiaoou", ""], ["Liu", "Yiming", ""], ["Agarwala", "Aseem", ""]]}, {"id": "1702.02519", "submitter": "Adrian Benton", "authors": "Adrian Benton, Huda Khayrallah, Biman Gujral, Dee Ann Reisinger, Sheng\n  Zhang, Raman Arora", "title": "Deep Generalized Canonical Correlation Analysis", "comments": "14 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present Deep Generalized Canonical Correlation Analysis (DGCCA) -- a\nmethod for learning nonlinear transformations of arbitrarily many views of\ndata, such that the resulting transformations are maximally informative of each\nother. While methods for nonlinear two-view representation learning (Deep CCA,\n(Andrew et al., 2013)) and linear many-view representation learning\n(Generalized CCA (Horst, 1961)) exist, DGCCA is the first CCA-style multiview\nrepresentation learning technique that combines the flexibility of nonlinear\n(deep) representation learning with the statistical power of incorporating\ninformation from many independent sources, or views. We present the DGCCA\nformulation as well as an efficient stochastic optimization algorithm for\nsolving it. We learn DGCCA representations on two distinct datasets for three\ndownstream tasks: phonetic transcription from acoustic and articulatory\nmeasurements, and recommending hashtags and friends on a dataset of Twitter\nusers. We find that DGCCA representations soundly beat existing methods at\nphonetic transcription and hashtag recommendation, and in general perform no\nworse than standard linear many-view techniques.\n", "versions": [{"version": "v1", "created": "Wed, 8 Feb 2017 16:57:48 GMT"}, {"version": "v2", "created": "Thu, 15 Jun 2017 00:06:08 GMT"}], "update_date": "2017-06-16", "authors_parsed": [["Benton", "Adrian", ""], ["Khayrallah", "Huda", ""], ["Gujral", "Biman", ""], ["Reisinger", "Dee Ann", ""], ["Zhang", "Sheng", ""], ["Arora", "Raman", ""]]}, {"id": "1702.02526", "submitter": "Michael Kampffmeyer", "authors": "Michael Kampffmeyer, Sigurd L{\\o}kse, Filippo Maria Bianchi, Robert\n  Jenssen and Lorenzo Livi", "title": "Deep Kernelized Autoencoders", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we introduce the deep kernelized autoencoder, a neural network\nmodel that allows an explicit approximation of (i) the mapping from an input\nspace to an arbitrary, user-specified kernel space and (ii) the back-projection\nfrom such a kernel space to input space. The proposed method is based on\ntraditional autoencoders and is trained through a new unsupervised loss\nfunction. During training, we optimize both the reconstruction accuracy of\ninput samples and the alignment between a kernel matrix given as prior and the\ninner products of the hidden representations computed by the autoencoder.\nKernel alignment provides control over the hidden representation learned by the\nautoencoder. Experiments have been performed to evaluate both reconstruction\nand kernel alignment performance. Additionally, we applied our method to\nemulate kPCA on a denoising task obtaining promising results.\n", "versions": [{"version": "v1", "created": "Wed, 8 Feb 2017 17:11:34 GMT"}], "update_date": "2017-02-09", "authors_parsed": [["Kampffmeyer", "Michael", ""], ["L\u00f8kse", "Sigurd", ""], ["Bianchi", "Filippo Maria", ""], ["Jenssen", "Robert", ""], ["Livi", "Lorenzo", ""]]}, {"id": "1702.02530", "submitter": "Lukas Machlica", "authors": "Lukas Machlica and Karel Bartos and Michal Sofka", "title": "Learning detectors of malicious web requests for intrusion detection in\n  network traffic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a generic classification system designed to detect\nsecurity threats based on the behavior of malware samples. The system relies on\nstatistical features computed from proxy log fields to train detectors using a\ndatabase of malware samples. The behavior detectors serve as basic reusable\nbuilding blocks of the multi-level detection architecture. The detectors\nidentify malicious communication exploiting encrypted URL strings and domains\ngenerated by a Domain Generation Algorithm (DGA) which are frequently used in\nCommand and Control (C&C), phishing, and click fraud. Surprisingly, very\nprecise detectors can be built given only a limited amount of information\nextracted from a single proxy log. This way, the computational requirements of\nthe detectors are kept low which allows for deployment on a wide range of\nsecurity devices and without depending on traffic context such as DNS logs,\nWhois records, webpage content, etc. Results on several weeks of live traffic\nfrom 100+ companies having 350k+ hosts show correct detection with a precision\nexceeding 95% of malicious flows, 95% of malicious URLs and 90% of infected\nhosts. In addition, a comparison with a signature and rule-based solution shows\nthat our system is able to detect significant amount of new threats.\n", "versions": [{"version": "v1", "created": "Wed, 8 Feb 2017 17:21:05 GMT"}], "update_date": "2017-02-09", "authors_parsed": [["Machlica", "Lukas", ""], ["Bartos", "Karel", ""], ["Sofka", "Michal", ""]]}, {"id": "1702.02555", "submitter": "Matthew Parker", "authors": "Matt Parker, Colin Parker", "title": "A Modified Construction for a Support Vector Classifier to Accommodate\n  Class Imbalances", "comments": "6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a training set with binary classification, the Support Vector Machine\nidentifies the hyperplane maximizing the margin between the two classes of\ntraining data. This general formulation is useful in that it can be applied\nwithout regard to variance differences between the classes. Ignoring these\ndifferences is not optimal, however, as the general SVM will give the class\nwith lower variance an unjustifiably wide berth. This increases the chance of\nmisclassification of the other class and results in an overall loss of\npredictive performance. An alternate construction is proposed in which the\nmargins of the separating hyperplane are different for each class, each\nproportional to the standard deviation of its class along the direction\nperpendicular to the hyperplane. The construction agrees with the SVM in the\ncase of equal class variances. This paper will then examine the impact to the\ndual representation of the modified constraint equations.\n", "versions": [{"version": "v1", "created": "Wed, 8 Feb 2017 18:34:15 GMT"}, {"version": "v2", "created": "Fri, 10 Feb 2017 05:26:13 GMT"}], "update_date": "2017-02-13", "authors_parsed": [["Parker", "Matt", ""], ["Parker", "Colin", ""]]}, {"id": "1702.02604", "submitter": "Mohammad Taha Bahadori", "authors": "Mohammad Taha Bahadori, Krzysztof Chalupka, Edward Choi, Robert Chen,\n  Walter F. Stewart, Jimeng Sun", "title": "Causal Regularization", "comments": "Adding theoretical analysis, revising the text", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In application domains such as healthcare, we want accurate predictive models\nthat are also causally interpretable. In pursuit of such models, we propose a\ncausal regularizer to steer predictive models towards causally-interpretable\nsolutions and theoretically study its properties. In a large-scale analysis of\nElectronic Health Records (EHR), our causally-regularized model outperforms its\nL1-regularized counterpart in causal accuracy and is competitive in predictive\nperformance. We perform non-linear causality analysis by causally regularizing\na special neural network architecture. We also show that the proposed causal\nregularizer can be used together with neural representation learning algorithms\nto yield up to 20% improvement over multilayer perceptron in detecting\nmultivariate causation, a situation common in healthcare, where many causal\nfactors should occur simultaneously to have an effect on the target variable.\n", "versions": [{"version": "v1", "created": "Wed, 8 Feb 2017 20:23:59 GMT"}, {"version": "v2", "created": "Thu, 23 Feb 2017 18:52:58 GMT"}], "update_date": "2017-02-24", "authors_parsed": [["Bahadori", "Mohammad Taha", ""], ["Chalupka", "Krzysztof", ""], ["Choi", "Edward", ""], ["Chen", "Robert", ""], ["Stewart", "Walter F.", ""], ["Sun", "Jimeng", ""]]}, {"id": "1702.02640", "submitter": "Zhe Gan", "authors": "Zhe Gan, P. D. Singh, Ameet Joshi, Xiaodong He, Jianshu Chen, Jianfeng\n  Gao, Li Deng", "title": "Character-level Deep Conflation for Business Data Analytics", "comments": "Accepted for publication, at ICASSP 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Connecting different text attributes associated with the same entity\n(conflation) is important in business data analytics since it could help merge\ntwo different tables in a database to provide a more comprehensive profile of\nan entity. However, the conflation task is challenging because two text strings\nthat describe the same entity could be quite different from each other for\nreasons such as misspelling. It is therefore critical to develop a conflation\nmodel that is able to truly understand the semantic meaning of the strings and\nmatch them at the semantic level. To this end, we develop a character-level\ndeep conflation model that encodes the input text strings from character level\ninto finite dimension feature vectors, which are then used to compute the\ncosine similarity between the text strings. The model is trained in an\nend-to-end manner using back propagation and stochastic gradient descent to\nmaximize the likelihood of the correct association. Specifically, we propose\ntwo variants of the deep conflation model, based on long-short-term memory\n(LSTM) recurrent neural network (RNN) and convolutional neural network (CNN),\nrespectively. Both models perform well on a real-world business analytics\ndataset and significantly outperform the baseline bag-of-character (BoC) model.\n", "versions": [{"version": "v1", "created": "Wed, 8 Feb 2017 22:24:14 GMT"}], "update_date": "2017-02-10", "authors_parsed": [["Gan", "Zhe", ""], ["Singh", "P. D.", ""], ["Joshi", "Ameet", ""], ["He", "Xiaodong", ""], ["Chen", "Jianshu", ""], ["Gao", "Jianfeng", ""], ["Deng", "Li", ""]]}, {"id": "1702.02655", "submitter": "Khadijeh Sadatnejad", "authors": "Khadijeh Sadatnejad, Saeed S. Ghidary, Reza Rostami, and Reza Kazemi", "title": "EEG Representation Using Multi-instance Framework on The Manifold of\n  Symmetric Positive Definite Matrices for EEG-based Computer Aided Diagnosis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The generalization and robustness of an electroencephalogram (EEG)-based\ncomputer aided diagnostic system are crucial requirements in actual clinical\npractice. To reach these goals, we propose a new EEG representation that\nprovides a more realistic view of brain functionality by applying\nmulti-instance (MI) framework to consider the non-stationarity of the EEG\nsignal. The non-stationary characteristic of EEG is considered by describing\nthe signal as a bag of relevant and irrelevant concepts. The concepts are\nprovided by a robust representation of homogenous segments of EEG signal using\nspatial covariance matrices. Due to the nonlinear geometry of the space of\ncovariance matrices, we determine the boundaries of the homogeneous segments\nbased on adaptive segmentation of the signal in a Riemannian framework. Each\nsubject is described as a bag of covariance matrices of homogenous segments and\nthe bag-level discriminative information is used for classification. To\nevaluate the performance of the proposed approach, we examine it in attention\ndeficit hyperactivity/bipolar mood disorder detection and depression/normal\ndiagnosis applications. Experimental results confirm the superiority of the\nproposed approach, which is gained due to the robustness of covariance\ndescriptor, the effectiveness of Riemannian geometry, and the benefits of\nconsidering the inherent non-stationary nature of the brain.\n", "versions": [{"version": "v1", "created": "Wed, 8 Feb 2017 23:56:32 GMT"}], "update_date": "2017-02-10", "authors_parsed": [["Sadatnejad", "Khadijeh", ""], ["Ghidary", "Saeed S.", ""], ["Rostami", "Reza", ""], ["Kazemi", "Reza", ""]]}, {"id": "1702.02661", "submitter": "U. N. Niranjan", "authors": "U.N. Niranjan, Arun Rajkumar", "title": "Inductive Pairwise Ranking: Going Beyond the n log(n) Barrier", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of ranking a set of items from nonactively chosen\npairwise preferences where each item has feature information with it. We\npropose and characterize a very broad class of preference matrices giving rise\nto the Feature Low Rank (FLR) model, which subsumes several models ranging from\nthe classic Bradley-Terry-Luce (BTL) (Bradley and Terry 1952) and Thurstone\n(Thurstone 1927) models to the recently proposed blade-chest (Chen and Joachims\n2016) and generic low-rank preference (Rajkumar and Agarwal 2016) models. We\nuse the technique of matrix completion in the presence of side information to\ndevelop the Inductive Pairwise Ranking (IPR) algorithm that provably learns a\ngood ranking under the FLR model, in a sample-efficient manner. In practice,\nthrough systematic synthetic simulations, we confirm our theoretical findings\nregarding improvements in the sample complexity due to the use of feature\ninformation. Moreover, on popular real-world preference learning datasets, with\nas less as 10% sampling of the pairwise comparisons, our method recovers a good\nranking.\n", "versions": [{"version": "v1", "created": "Thu, 9 Feb 2017 00:17:39 GMT"}], "update_date": "2017-02-10", "authors_parsed": [["Niranjan", "U. N.", ""], ["Rajkumar", "Arun", ""]]}, {"id": "1702.02676", "submitter": "Arman Afrasiyabi", "authors": "Arman Afrasiyabi, Ozan Yildiz, Baris Nasir, Fatos T. Yarman Vural and\n  A. Enis Cetin", "title": "Energy Saving Additive Neural Network", "comments": "8 pages (double column), 2 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In recent years, machine learning techniques based on neural networks for\nmobile computing become increasingly popular. Classical multi-layer neural\nnetworks require matrix multiplications at each stage. Multiplication operation\nis not an energy efficient operation and consequently it drains the battery of\nthe mobile device. In this paper, we propose a new energy efficient neural\nnetwork with the universal approximation property over space of Lebesgue\nintegrable functions. This network, called, additive neural network, is very\nsuitable for mobile computing. The neural structure is based on a novel vector\nproduct definition, called ef-operator, that permits a multiplier-free\nimplementation. In ef-operation, the \"product\" of two real numbers is defined\nas the sum of their absolute values, with the sign determined by the sign of\nthe product of the numbers. This \"product\" is used to construct a vector\nproduct in $R^N$. The vector product induces the $l_1$ norm. The proposed\nadditive neural network successfully solves the XOR problem. The experiments on\nMNIST dataset show that the classification performances of the proposed\nadditive neural networks are very similar to the corresponding multi-layer\nperceptron and convolutional neural networks (LeNet).\n", "versions": [{"version": "v1", "created": "Thu, 9 Feb 2017 02:02:27 GMT"}], "update_date": "2017-02-10", "authors_parsed": [["Afrasiyabi", "Arman", ""], ["Yildiz", "Ozan", ""], ["Nasir", "Baris", ""], ["Vural", "Fatos T. Yarman", ""], ["Cetin", "A. Enis", ""]]}, {"id": "1702.02686", "submitter": "Yining Wang", "authors": "Yining Wang, Jialei Wang, Sivaraman Balakrishnan, Aarti Singh", "title": "Rate Optimal Estimation and Confidence Intervals for High-dimensional\n  Regression with Missing Covariates", "comments": "41 pages, 1 figure, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although a majority of the theoretical literature in high-dimensional\nstatistics has focused on settings which involve fully-observed data, settings\nwith missing values and corruptions are common in practice. We consider the\nproblems of estimation and of constructing component-wise confidence intervals\nin a sparse high-dimensional linear regression model when some covariates of\nthe design matrix are missing completely at random. We analyze a variant of the\nDantzig selector [9] for estimating the regression model and we use a\nde-biasing argument to construct component-wise confidence intervals. Our first\nmain result is to establish upper bounds on the estimation error as a function\nof the model parameters (the sparsity level s, the expected fraction of\nobserved covariates $\\rho_*$, and a measure of the signal strength\n$\\|\\beta^*\\|_2$). We find that even in an idealized setting where the\ncovariates are assumed to be missing completely at random, somewhat\nsurprisingly and in contrast to the fully-observed setting, there is a\ndichotomy in the dependence on model parameters and much faster rates are\nobtained if the covariance matrix of the random design is known. To study this\nissue further, our second main contribution is to provide lower bounds on the\nestimation error showing that this discrepancy in rates is unavoidable in a\nminimax sense. We then consider the problem of high-dimensional inference in\nthe presence of missing data. We construct and analyze confidence intervals\nusing a de-biased estimator. In the presence of missing data, inference is\ncomplicated by the fact that the de-biasing matrix is correlated with the pilot\nestimator and this necessitates the design of a new estimator and a novel\nanalysis. We also complement our mathematical study with extensive simulations\non synthetic and semi-synthetic data that show the accuracy of our asymptotic\npredictions for finite sample sizes.\n", "versions": [{"version": "v1", "created": "Thu, 9 Feb 2017 03:10:13 GMT"}, {"version": "v2", "created": "Fri, 3 Nov 2017 00:04:20 GMT"}], "update_date": "2017-11-06", "authors_parsed": [["Wang", "Yining", ""], ["Wang", "Jialei", ""], ["Balakrishnan", "Sivaraman", ""], ["Singh", "Aarti", ""]]}, {"id": "1702.02715", "submitter": "Yanjun  Qi Dr.", "authors": "Beilun Wang, Ji Gao, Yanjun Qi", "title": "A Fast and Scalable Joint Estimator for Learning Multiple Related Sparse\n  Gaussian Graphical Models", "comments": "8 pages, accepted by AISTAT 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Estimating multiple sparse Gaussian Graphical Models (sGGMs) jointly for many\nrelated tasks (large $K$) under a high-dimensional (large $p$) situation is an\nimportant task. Most previous studies for the joint estimation of multiple\nsGGMs rely on penalized log-likelihood estimators that involve expensive and\ndifficult non-smooth optimizations. We propose a novel approach, FASJEM for\n\\underline{fa}st and \\underline{s}calable \\underline{j}oint\nstructure-\\underline{e}stimation of \\underline{m}ultiple sGGMs at a large\nscale. As the first study of joint sGGM using the Elementary Estimator\nframework, our work has three major contributions: (1) We solve FASJEM through\nan entry-wise manner which is parallelizable. (2) We choose a proximal\nalgorithm to optimize FASJEM. This improves the computational efficiency from\n$O(Kp^3)$ to $O(Kp^2)$ and reduces the memory requirement from $O(Kp^2)$ to\n$O(K)$. (3) We theoretically prove that FASJEM achieves a consistent estimation\nwith a convergence rate of $O(\\log(Kp)/n_{tot})$. On several synthetic and four\nreal-world datasets, FASJEM shows significant improvements over baselines on\naccuracy, computational complexity, and memory costs.\n", "versions": [{"version": "v1", "created": "Thu, 9 Feb 2017 06:09:48 GMT"}, {"version": "v2", "created": "Thu, 2 Mar 2017 06:49:21 GMT"}, {"version": "v3", "created": "Tue, 20 Mar 2018 10:44:16 GMT"}], "update_date": "2018-03-21", "authors_parsed": [["Wang", "Beilun", ""], ["Gao", "Ji", ""], ["Qi", "Yanjun", ""]]}, {"id": "1702.02738", "submitter": "Jean-Baptiste Alayrac", "authors": "Jean-Baptiste Alayrac, Josev Sivic, Ivan Laptev, Simon Lacoste-Julien", "title": "Joint Discovery of Object States and Manipulation Actions", "comments": "Appears in: International Conference on Computer Vision 2017 (ICCV\n  2017). 15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many human activities involve object manipulations aiming to modify the\nobject state. Examples of common state changes include full/empty bottle,\nopen/closed door, and attached/detached car wheel. In this work, we seek to\nautomatically discover the states of objects and the associated manipulation\nactions. Given a set of videos for a particular task, we propose a joint model\nthat learns to identify object states and to localize state-modifying actions.\nOur model is formulated as a discriminative clustering cost with constraints.\nWe assume a consistent temporal order for the changes in object states and\nmanipulation actions, and introduce new optimization techniques to learn model\nparameters without additional supervision. We demonstrate successful discovery\nof seven manipulation actions and corresponding object states on a new dataset\nof videos depicting real-life object manipulations. We show that our joint\nformulation results in an improvement of object state discovery by action\nrecognition and vice versa.\n", "versions": [{"version": "v1", "created": "Thu, 9 Feb 2017 08:04:33 GMT"}, {"version": "v2", "created": "Mon, 10 Apr 2017 08:23:00 GMT"}, {"version": "v3", "created": "Mon, 28 Aug 2017 08:04:18 GMT"}], "update_date": "2017-08-29", "authors_parsed": [["Alayrac", "Jean-Baptiste", ""], ["Sivic", "Josev", ""], ["Laptev", "Ivan", ""], ["Lacoste-Julien", "Simon", ""]]}, {"id": "1702.02817", "submitter": "Immanuel Bayer", "authors": "Immanuel Bayer, Uwe Nagel, Steffen Rendle", "title": "Graph Based Relational Features for Collective Classification", "comments": "Pacific-Asia Conference on Knowledge Discovery and Data Mining", "journal-ref": null, "doi": "10.1007/978-3-319-18032-8_35", "report-no": null, "categories": "cs.IR cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Statistical Relational Learning (SRL) methods have shown that classification\naccuracy can be improved by integrating relations between samples. Techniques\nsuch as iterative classification or relaxation labeling achieve this by\npropagating information between related samples during the inference process.\nWhen only a few samples are labeled and connections between samples are sparse,\ncollective inference methods have shown large improvements over standard\nfeature-based ML methods. However, in contrast to feature based ML, collective\ninference methods require complex inference procedures and often depend on the\nstrong assumption of label consistency among related samples. In this paper, we\nintroduce new relational features for standard ML methods by extracting\ninformation from direct and indirect relations. We show empirically on three\nstandard benchmark datasets that our relational features yield results\ncomparable to collective inference methods. Finally we show that our proposal\noutperforms these methods when additional information is available.\n", "versions": [{"version": "v1", "created": "Thu, 9 Feb 2017 12:58:23 GMT"}], "update_date": "2017-02-13", "authors_parsed": [["Bayer", "Immanuel", ""], ["Nagel", "Uwe", ""], ["Rendle", "Steffen", ""]]}, {"id": "1702.02828", "submitter": "Jason Klusowski M", "authors": "Jason M. Klusowski and Andrew R. Barron", "title": "Minimax Lower Bounds for Ridge Combinations Including Neural Nets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Estimation of functions of $ d $ variables is considered using ridge\ncombinations of the form $ \\textstyle\\sum_{k=1}^m c_{1,k}\n\\phi(\\textstyle\\sum_{j=1}^d c_{0,j,k}x_j-b_k) $ where the activation function $\n\\phi $ is a function with bounded value and derivative. These include\nsingle-hidden layer neural networks, polynomials, and sinusoidal models. From a\nsample of size $ n $ of possibly noisy values at random sites $ X \\in B =\n[-1,1]^d $, the minimax mean square error is examined for functions in the\nclosure of the $ \\ell_1 $ hull of ridge functions with activation $ \\phi $. It\nis shown to be of order $ d/n $ to a fractional power (when $ d $ is of smaller\norder than $ n $), and to be of order $ (\\log d)/n $ to a fractional power\n(when $ d $ is of larger order than $ n $). Dependence on constraints $ v_0 $\nand $ v_1 $ on the $ \\ell_1 $ norms of inner parameter $ c_0 $ and outer\nparameter $ c_1 $, respectively, is also examined. Also, lower and upper bounds\non the fractional power are given. The heart of the analysis is development of\ninformation-theoretic packing numbers for these classes of functions.\n", "versions": [{"version": "v1", "created": "Thu, 9 Feb 2017 13:34:21 GMT"}], "update_date": "2017-02-10", "authors_parsed": [["Klusowski", "Jason M.", ""], ["Barron", "Andrew R.", ""]]}, {"id": "1702.02849", "submitter": "Adish Singla", "authors": "Christoph Hirnschall, Adish Singla, Sebastian Tschiatschek, Andreas\n  Krause", "title": "Coordinated Online Learning With Applications to Learning User\n  Preferences", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study an online multi-task learning setting, in which instances of related\ntasks arrive sequentially, and are handled by task-specific online learners. We\nconsider an algorithmic framework to model the relationship of these tasks via\na set of convex constraints. To exploit this relationship, we design a novel\nalgorithm -- COOL -- for coordinating the individual online learners: Our key\nidea is to coordinate their parameters via weighted projections onto a convex\nset. By adjusting the rate and accuracy of the projection, the COOL algorithm\nallows for a trade-off between the benefit of coordination and the required\ncomputation/communication. We derive regret bounds for our approach and analyze\nhow they are influenced by these trade-off factors. We apply our results on the\napplication of learning users' preferences on the Airbnb marketplace with the\ngoal of incentivizing users to explore under-reviewed apartments.\n", "versions": [{"version": "v1", "created": "Thu, 9 Feb 2017 14:44:49 GMT"}], "update_date": "2017-02-10", "authors_parsed": [["Hirnschall", "Christoph", ""], ["Singla", "Adish", ""], ["Tschiatschek", "Sebastian", ""], ["Krause", "Andreas", ""]]}, {"id": "1702.02873", "submitter": "Xavier Navarro-Sune", "authors": "X. Navarro, F. Por\\'ee, M. Kuchenbuch, M. Chavez, A. Beuch\\'ee, G.\n  Carrault", "title": "Multi-feature classifiers for burst detection in single EEG channels\n  from preterm infants", "comments": "11 pages, 5 figures. Table 1 in the last page", "journal-ref": null, "doi": "10.1088/1741-2552/aa714a", "report-no": null, "categories": "q-bio.NC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The study of electroencephalographic (EEG) bursts in preterm infants provides\nvaluable information about maturation or prognostication after perinatal\nasphyxia. Over the last two decades, a number of works proposed algorithms to\nautomatically detect EEG bursts in preterm infants, but they were designed for\npopulations under 35 weeks of post menstrual age (PMA). However, as the brain\nactivity evolves rapidly during postnatal life, these solutions might be\nunder-performing with increasing PMA. In this work we focused on preterm\ninfants reaching term ages (PMA $\\geq$ 36 weeks) using multi-feature\nclassification on a single EEG channel. Five EEG burst detectors relying on\ndifferent machine learning approaches were compared: Logistic regression (LR),\nlinear discriminant analysis (LDA), k-nearest neighbors (kNN), support vector\nmachines (SVM) and thresholding (Th). Classifiers were trained by visually\nlabeled EEG recordings from 14 very preterm infants (born after 28 weeks of\ngestation) with 36 - 41 weeks PMA. The most performing classifiers reached\nabout 95\\% accuracy (kNN, SVM and LR) whereas Th obtained 84\\%. Compared to\nhuman-automatic agreements, LR provided the highest scores (Cohen's kappa =\n0.71) and the best computational efficiency using only three EEG features.\nApplying this classifier in a test database of 21 infants $\\geq$ 36 weeks PMA,\nwe show that long EEG bursts and short inter-bust periods are characteristic of\ninfants with the highest PMA and weights. In view of these results, LR-based\nburst detection could be a suitable tool to study maturation in monitoring or\nportable devices using a single EEG channel.\n", "versions": [{"version": "v1", "created": "Wed, 8 Feb 2017 09:58:49 GMT"}], "update_date": "2017-06-02", "authors_parsed": [["Navarro", "X.", ""], ["Por\u00e9e", "F.", ""], ["Kuchenbuch", "M.", ""], ["Chavez", "M.", ""], ["Beuch\u00e9e", "A.", ""], ["Carrault", "G.", ""]]}, {"id": "1702.02896", "submitter": "Stefan Wager", "authors": "Susan Athey and Stefan Wager", "title": "Policy Learning with Observational Data", "comments": "Forthcoming in Econometrica. Original title: Efficient Policy\n  Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG econ.EM stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many areas, practitioners seek to use observational data to learn a\ntreatment assignment policy that satisfies application-specific constraints,\nsuch as budget, fairness, simplicity, or other functional form constraints. For\nexample, policies may be restricted to take the form of decision trees based on\na limited set of easily observable individual characteristics. We propose a new\napproach to this problem motivated by the theory of semiparametrically\nefficient estimation. Our method can be used to optimize either binary\ntreatments or infinitesimal nudges to continuous treatments, and can leverage\nobservational data where causal effects are identified using a variety of\nstrategies, including selection on observables and instrumental variables.\nGiven a doubly robust estimator of the causal effect of assigning everyone to\ntreatment, we develop an algorithm for choosing whom to treat, and establish\nstrong guarantees for the asymptotic utilitarian regret of the resulting\npolicy.\n", "versions": [{"version": "v1", "created": "Thu, 9 Feb 2017 17:03:01 GMT"}, {"version": "v2", "created": "Sun, 1 Oct 2017 22:20:23 GMT"}, {"version": "v3", "created": "Tue, 9 Oct 2018 11:04:03 GMT"}, {"version": "v4", "created": "Tue, 4 Dec 2018 23:51:38 GMT"}, {"version": "v5", "created": "Mon, 16 Sep 2019 22:46:50 GMT"}, {"version": "v6", "created": "Fri, 4 Sep 2020 21:45:04 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Athey", "Susan", ""], ["Wager", "Stefan", ""]]}, {"id": "1702.02897", "submitter": "Dongrui Wu", "authors": "Dongrui Wu", "title": "Online and Offline Domain Adaptation for Reducing BCI Calibration Effort", "comments": "in press", "journal-ref": "IEEE Trans. on Human-Machine Systems, vol. 47, no. 4, pp. 550-563,\n  2017", "doi": "10.1109/THMS.2016.2608931", "report-no": null, "categories": "cs.LG cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many real-world brain-computer interface (BCI) applications rely on\nsingle-trial classification of event-related potentials (ERPs) in EEG signals.\nHowever, because different subjects have different neural responses to even the\nsame stimulus, it is very difficult to build a generic ERP classifier whose\nparameters fit all subjects. The classifier needs to be calibrated for each\nindividual subject, using some labeled subject-specific data. This paper\nproposes both online and offline weighted adaptation regularization (wAR)\nalgorithms to reduce this calibration effort, i.e., to minimize the amount of\nlabeled subject-specific EEG data required in BCI calibration, and hence to\nincrease the utility of the BCI system. We demonstrate using a visually-evoked\npotential oddball task and three different EEG headsets that both online and\noffline wAR algorithms significantly outperform several other algorithms.\nMoreover, through source domain selection, we can reduce their computational\ncost by about 50%, making them more suitable for real-time applications.\n", "versions": [{"version": "v1", "created": "Thu, 9 Feb 2017 17:03:12 GMT"}], "update_date": "2020-02-13", "authors_parsed": [["Wu", "Dongrui", ""]]}, {"id": "1702.02901", "submitter": "Dongrui Wu", "authors": "Dongrui Wu, Vernon J. Lawhern, Stephen Gordon, Brent J. Lance,\n  Chin-Teng Lin", "title": "Driver Drowsiness Estimation from EEG Signals Using Online Weighted\n  Adaptation Regularization for Regression (OwARR)", "comments": "in press", "journal-ref": "IEEE Trans.on Fuzzy Systems, 25(6), pp. 1522-1535, 2017", "doi": "10.1109/TFUZZ.2016.2633379", "report-no": null, "categories": "cs.LG cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One big challenge that hinders the transition of brain-computer interfaces\n(BCIs) from laboratory settings to real-life applications is the availability\nof high-performance and robust learning algorithms that can effectively handle\nindividual differences, i.e., algorithms that can be applied to a new subject\nwith zero or very little subject-specific calibration data. Transfer learning\nand domain adaptation have been extensively used for this purpose. However,\nmost previous works focused on classification problems. This paper considers an\nimportant regression problem in BCI, namely, online driver drowsiness\nestimation from EEG signals. By integrating fuzzy sets with domain adaptation,\nwe propose a novel online weighted adaptation regularization for regression\n(OwARR) algorithm to reduce the amount of subject-specific calibration data,\nand also a source domain selection (SDS) approach to save about half of the\ncomputational cost of OwARR. Using a simulated driving dataset with 15\nsubjects, we show that OwARR and OwARR-SDS can achieve significantly smaller\nestimation errors than several other approaches. We also provide comprehensive\nanalyses on the robustness of OwARR and OwARR-SDS.\n", "versions": [{"version": "v1", "created": "Thu, 9 Feb 2017 17:14:15 GMT"}], "update_date": "2020-02-13", "authors_parsed": [["Wu", "Dongrui", ""], ["Lawhern", "Vernon J.", ""], ["Gordon", "Stephen", ""], ["Lance", "Brent J.", ""], ["Lin", "Chin-Teng", ""]]}, {"id": "1702.02906", "submitter": "Dongrui Wu", "authors": "Dongrui Wu, Vernon J. Lawhern, W. David Hairston, Brent J. Lance", "title": "Switching EEG Headsets Made Easy: Reducing Offline Calibration Effort\n  Using Active Weighted Adaptation Regularization", "comments": null, "journal-ref": "IEEE Trans. on Neural Systems and Rehabilitation Engineering,\n  24(11), pp. 1125-1137 (2016)", "doi": "10.1109/TNSRE.2016.2544108", "report-no": null, "categories": "cs.LG cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Electroencephalography (EEG) headsets are the most commonly used sensing\ndevices for Brain-Computer Interface. In real-world applications, there are\nadvantages to extrapolating data from one user session to another. However,\nthese advantages are limited if the data arise from different hardware systems,\nwhich often vary between application spaces. Currently, this creates a need to\nrecalibrate classifiers, which negatively affects people's interest in using\nsuch systems. In this paper, we employ active weighted adaptation\nregularization (AwAR), which integrates weighted adaptation regularization\n(wAR) and active learning, to expedite the calibration process. wAR makes use\nof labeled data from the previous headset and handles class-imbalance, and\nactive learning selects the most informative samples from the new headset to\nlabel. Experiments on single-trial event-related potential classification show\nthat AwAR can significantly increase the classification accuracy, given the\nsame number of labeled samples from the new headset. In other words, AwAR can\neffectively reduce the number of labeled samples required from the new headset,\ngiven a desired classification accuracy, suggesting value in collating data for\nuse in wide scale transfer-learning applications.\n", "versions": [{"version": "v1", "created": "Thu, 9 Feb 2017 17:24:22 GMT"}], "update_date": "2017-02-10", "authors_parsed": [["Wu", "Dongrui", ""], ["Lawhern", "Vernon J.", ""], ["Hairston", "W. David", ""], ["Lance", "Brent J.", ""]]}, {"id": "1702.02914", "submitter": "Dongrui Wu", "authors": "Dongrui Wu, Jung-Tai King, Chun-Hsiang Chuang, Chin-Teng Lin,\n  Tzyy-Ping Jung", "title": "Spatial Filtering for EEG-Based Regression Problems in Brain-Computer\n  Interface (BCI)", "comments": null, "journal-ref": "IEEE Trans. on Fuzzy Systems, 26(2), pp. 771-781, 2018", "doi": null, "report-no": null, "categories": "cs.LG cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Electroencephalogram (EEG) signals are frequently used in brain-computer\ninterfaces (BCIs), but they are easily contaminated by artifacts and noises, so\npreprocessing must be done before they are fed into a machine learning\nalgorithm for classification or regression. Spatial filters have been widely\nused to increase the signal-to-noise ratio of EEG for BCI classification\nproblems, but their applications in BCI regression problems have been very\nlimited. This paper proposes two common spatial pattern (CSP) filters for\nEEG-based regression problems in BCI, which are extended from the CSP filter\nfor classification, by making use of fuzzy sets. Experimental results on\nEEG-based response speed estimation from a large-scale study, which collected\n143 sessions of sustained-attention psychomotor vigilance task data from 17\nsubjects during a 5-month period, demonstrate that the two proposed spatial\nfilters can significantly increase the EEG signal quality. When used in LASSO\nand k-nearest neighbors regression for user response speed estimation, the\nspatial filters can reduce the root mean square estimation error by\n10.02-19.77%, and at the same time increase the correlation to the true\nresponse speed by 19.39-86.47%.\n", "versions": [{"version": "v1", "created": "Thu, 9 Feb 2017 17:44:28 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Wu", "Dongrui", ""], ["King", "Jung-Tai", ""], ["Chuang", "Chun-Hsiang", ""], ["Lin", "Chin-Teng", ""], ["Jung", "Tzyy-Ping", ""]]}, {"id": "1702.02982", "submitter": "Danica J. Sutherland", "authors": "Danica J. Sutherland", "title": "Fixing an error in Caponnetto and de Vito (2007)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The seminal paper of Caponnetto and de Vito (2007) provides minimax-optimal\nrates for kernel ridge regression in a very general setting. Its proof,\nhowever, contains an error in its bound on the effective dimensionality. In\nthis note, we explain the mistake, provide a correct bound, and show that the\nmain theorem remains true.\n", "versions": [{"version": "v1", "created": "Thu, 9 Feb 2017 21:01:52 GMT"}, {"version": "v2", "created": "Thu, 14 Jan 2021 06:10:33 GMT"}], "update_date": "2021-01-15", "authors_parsed": [["Sutherland", "Danica J.", ""]]}, {"id": "1702.03006", "submitter": "Ashique Rupam Mahmood", "authors": "Ashique Rupam Mahmood, Huizhen Yu, Richard S. Sutton", "title": "Multi-step Off-policy Learning Without Importance Sampling Ratios", "comments": "24 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To estimate the value functions of policies from exploratory data, most\nmodel-free off-policy algorithms rely on importance sampling, where the use of\nimportance sampling ratios often leads to estimates with severe variance. It is\nthus desirable to learn off-policy without using the ratios. However, such an\nalgorithm does not exist for multi-step learning with function approximation.\nIn this paper, we introduce the first such algorithm based on\ntemporal-difference (TD) learning updates. We show that an explicit use of\nimportance sampling ratios can be eliminated by varying the amount of\nbootstrapping in TD updates in an action-dependent manner. Our new algorithm\nachieves stability using a two-timescale gradient-based TD update. A prior\nalgorithm based on lookup table representation called Tree Backup can also be\nretrieved using action-dependent bootstrapping, becoming a special case of our\nalgorithm. In two challenging off-policy tasks, we demonstrate that our\nalgorithm is stable, effectively avoids the large variance issue, and can\nperform substantially better than its state-of-the-art counterpart.\n", "versions": [{"version": "v1", "created": "Thu, 9 Feb 2017 22:36:25 GMT"}], "update_date": "2017-02-13", "authors_parsed": [["Mahmood", "Ashique Rupam", ""], ["Yu", "Huizhen", ""], ["Sutton", "Richard S.", ""]]}, {"id": "1702.03037", "submitter": "Marc Lanctot", "authors": "Joel Z. Leibo, Vinicius Zambaldi, Marc Lanctot, Janusz Marecki, Thore\n  Graepel", "title": "Multi-agent Reinforcement Learning in Sequential Social Dilemmas", "comments": "10 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.GT cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Matrix games like Prisoner's Dilemma have guided research on social dilemmas\nfor decades. However, they necessarily treat the choice to cooperate or defect\nas an atomic action. In real-world social dilemmas these choices are temporally\nextended. Cooperativeness is a property that applies to policies, not\nelementary actions. We introduce sequential social dilemmas that share the\nmixed incentive structure of matrix game social dilemmas but also require\nagents to learn policies that implement their strategic intentions. We analyze\nthe dynamics of policies learned by multiple self-interested independent\nlearning agents, each using its own deep Q-network, on two Markov games we\nintroduce here: 1. a fruit Gathering game and 2. a Wolfpack hunting game. We\ncharacterize how learned behavior in each domain changes as a function of\nenvironmental factors including resource abundance. Our experiments show how\nconflict can emerge from competition over shared resources and shed light on\nhow the sequential nature of real world social dilemmas affects cooperation.\n", "versions": [{"version": "v1", "created": "Fri, 10 Feb 2017 01:48:40 GMT"}], "update_date": "2017-02-13", "authors_parsed": [["Leibo", "Joel Z.", ""], ["Zambaldi", "Vinicius", ""], ["Lanctot", "Marc", ""], ["Marecki", "Janusz", ""], ["Graepel", "Thore", ""]]}, {"id": "1702.03040", "submitter": "Ruitong Huang", "authors": "Ruitong Huang, Tor Lattimore, Andr\\'as Gy\\\"orgy, Csaba Szepesv\\'ari", "title": "Following the Leader and Fast Rates in Linear Prediction: Curved\n  Constraint Sets and Other Regularities", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The follow the leader (FTL) algorithm, perhaps the simplest of all online\nlearning algorithms, is known to perform well when the loss functions it is\nused on are convex and positively curved. In this paper we ask whether there\nare other \"lucky\" settings when FTL achieves sublinear, \"small\" regret. In\nparticular, we study the fundamental problem of linear prediction over a\nnon-empty convex, compact domain. Amongst other results, we prove that the\ncurvature of the boundary of the domain can act as if the losses were curved:\nIn this case, we prove that as long as the mean of the loss vectors have\npositive lengths bounded away from zero, FTL enjoys a logarithmic growth rate\nof regret, while, e.g., for polytope domains and stochastic data it enjoys\nfinite expected regret. Building on a previously known meta-algorithm, we also\nget an algorithm that simultaneously enjoys the worst-case guarantees and the\nbound available for FTL.\n", "versions": [{"version": "v1", "created": "Fri, 10 Feb 2017 01:59:02 GMT"}], "update_date": "2017-02-13", "authors_parsed": [["Huang", "Ruitong", ""], ["Lattimore", "Tor", ""], ["Gy\u00f6rgy", "Andr\u00e1s", ""], ["Szepesv\u00e1ri", "Csaba", ""]]}, {"id": "1702.03118", "submitter": "Stefan Elfwing PhD", "authors": "Stefan Elfwing, Eiji Uchibe and Kenji Doya", "title": "Sigmoid-Weighted Linear Units for Neural Network Function Approximation\n  in Reinforcement Learning", "comments": "18 pages, 22 figures; added deep RL results for SZ-Tetris", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, neural networks have enjoyed a renaissance as function\napproximators in reinforcement learning. Two decades after Tesauro's TD-Gammon\nachieved near top-level human performance in backgammon, the deep reinforcement\nlearning algorithm DQN achieved human-level performance in many Atari 2600\ngames. The purpose of this study is twofold. First, we propose two activation\nfunctions for neural network function approximation in reinforcement learning:\nthe sigmoid-weighted linear unit (SiLU) and its derivative function (dSiLU).\nThe activation of the SiLU is computed by the sigmoid function multiplied by\nits input. Second, we suggest that the more traditional approach of using\non-policy learning with eligibility traces, instead of experience replay, and\nsoftmax action selection with simple annealing can be competitive with DQN,\nwithout the need for a separate target network. We validate our proposed\napproach by, first, achieving new state-of-the-art results in both stochastic\nSZ-Tetris and Tetris with a small 10$\\times$10 board, using TD($\\lambda$)\nlearning and shallow dSiLU network agents, and, then, by outperforming DQN in\nthe Atari 2600 domain by using a deep Sarsa($\\lambda$) agent with SiLU and\ndSiLU hidden units.\n", "versions": [{"version": "v1", "created": "Fri, 10 Feb 2017 10:04:30 GMT"}, {"version": "v2", "created": "Thu, 23 Feb 2017 07:40:05 GMT"}, {"version": "v3", "created": "Thu, 2 Nov 2017 02:48:38 GMT"}], "update_date": "2017-11-03", "authors_parsed": [["Elfwing", "Stefan", ""], ["Uchibe", "Eiji", ""], ["Doya", "Kenji", ""]]}, {"id": "1702.03192", "submitter": "Shaohuai Shi", "authors": "Shaohuai Shi, Pengfei Xu, Xiaowen Chu", "title": "Supervised Learning Based Algorithm Selection for Deep Neural Networks", "comments": "In review for a conference paper of ICPP2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many recent deep learning platforms rely on third-party libraries (such as\ncuBLAS) to utilize the computing power of modern hardware accelerators (such as\nGPUs). However, we observe that they may achieve suboptimal performance because\nthe library functions are not used appropriately. In this paper, we target at\noptimizing the operations of multiplying a matrix with the transpose of another\nmatrix (referred to as NT operation hereafter), which contribute about half of\nthe training time of fully connected deep neural networks. Rather than directly\ncalling the library function, we propose a supervised learning based algorithm\nselection approach named MTNN, which uses a gradient boosted decision tree to\nselect one from two alternative NT implementations intelligently: (1) calling\nthe cuBLAS library function; (2) calling our proposed algorithm TNN that uses\nan efficient out-of-place matrix transpose. We evaluate the performance of MTNN\non two modern GPUs: NVIDIA GTX 1080 and NVIDIA Titan X Pascal. MTNN can achieve\n96\\% of prediction accuracy with very low computational overhead, which results\nin an average of 54\\% performance improvement on a range of NT operations. To\nfurther evaluate the impact of MTNN on the training process of deep neural\nnetworks, we have integrated MTNN into a popular deep learning platform Caffe.\nOur experimental results show that the revised Caffe can outperform the\noriginal one by an average of 28\\%. Both MTNN and the revised Caffe are\nopen-source.\n", "versions": [{"version": "v1", "created": "Fri, 10 Feb 2017 14:51:42 GMT"}, {"version": "v2", "created": "Fri, 17 Mar 2017 02:06:06 GMT"}], "update_date": "2017-03-20", "authors_parsed": [["Shi", "Shaohuai", ""], ["Xu", "Pengfei", ""], ["Chu", "Xiaowen", ""]]}, {"id": "1702.03258", "submitter": "Jean-Baptiste Mouret", "authors": "John Rieffel and Jean-Baptiste Mouret", "title": "Adaptive and Resilient Soft Tensegrity Robots", "comments": "video: https://youtu.be/SuLQDhrk9tQ", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Living organisms intertwine soft (e.g., muscle) and hard (e.g., bones)\nmaterials, giving them an intrinsic flexibility and resiliency often lacking in\nconventional rigid robots. The emerging field of soft robotics seeks to harness\nthese same properties in order to create resilient machines. The nature of soft\nmaterials, however, presents considerable challenges to aspects of design,\nconstruction, and control -- and up until now, the vast majority of gaits for\nsoft robots have been hand-designed through empirical trial-and-error. This\nmanuscript describes an easy-to-assemble tensegrity-based soft robot capable of\nhighly dynamic locomotive gaits and demonstrating structural and behavioral\nresilience in the face of physical damage. Enabling this is the use of a\nmachine learning algorithm able to discover effective gaits with a minimal\nnumber of physical trials. These results lend further credence to soft-robotic\napproaches that seek to harness the interaction of complex material dynamics in\norder to generate a wealth of dynamical behaviors.\n", "versions": [{"version": "v1", "created": "Fri, 10 Feb 2017 17:26:59 GMT"}, {"version": "v2", "created": "Mon, 19 Feb 2018 21:50:15 GMT"}], "update_date": "2018-02-21", "authors_parsed": [["Rieffel", "John", ""], ["Mouret", "Jean-Baptiste", ""]]}, {"id": "1702.03260", "submitter": "Eric Tramel", "authors": "Eric W. Tramel and Marylou Gabri\\'e and Andre Manoel and Francesco\n  Caltagirone and Florent Krzakala", "title": "A Deterministic and Generalized Framework for Unsupervised Learning with\n  Restricted Boltzmann Machines", "comments": null, "journal-ref": "Phys. Rev. X 8, 041006 (2018)", "doi": "10.1103/PhysRevX.8.041006", "report-no": null, "categories": "cs.LG cond-mat.dis-nn cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Restricted Boltzmann machines (RBMs) are energy-based neural-networks which\nare commonly used as the building blocks for deep architectures neural\narchitectures. In this work, we derive a deterministic framework for the\ntraining, evaluation, and use of RBMs based upon the Thouless-Anderson-Palmer\n(TAP) mean-field approximation of widely-connected systems with weak\ninteractions coming from spin-glass theory. While the TAP approach has been\nextensively studied for fully-visible binary spin systems, our construction is\ngeneralized to latent-variable models, as well as to arbitrarily distributed\nreal-valued spin systems with bounded support. In our numerical experiments, we\ndemonstrate the effective deterministic training of our proposed models and are\nable to show interesting features of unsupervised learning which could not be\ndirectly observed with sampling. Additionally, we demonstrate how to utilize\nour TAP-based framework for leveraging trained RBMs as joint priors in\ndenoising problems.\n", "versions": [{"version": "v1", "created": "Fri, 10 Feb 2017 17:29:51 GMT"}, {"version": "v2", "created": "Mon, 2 Oct 2017 13:55:46 GMT"}, {"version": "v3", "created": "Tue, 9 Oct 2018 09:07:13 GMT"}], "update_date": "2018-10-17", "authors_parsed": [["Tramel", "Eric W.", ""], ["Gabri\u00e9", "Marylou", ""], ["Manoel", "Andre", ""], ["Caltagirone", "Francesco", ""], ["Krzakala", "Florent", ""]]}, {"id": "1702.03275", "submitter": "Sergey Ioffe", "authors": "Sergey Ioffe", "title": "Batch Renormalization: Towards Reducing Minibatch Dependence in\n  Batch-Normalized Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Batch Normalization is quite effective at accelerating and improving the\ntraining of deep models. However, its effectiveness diminishes when the\ntraining minibatches are small, or do not consist of independent samples. We\nhypothesize that this is due to the dependence of model layer inputs on all the\nexamples in the minibatch, and different activations being produced between\ntraining and inference. We propose Batch Renormalization, a simple and\neffective extension to ensure that the training and inference models generate\nthe same outputs that depend on individual examples rather than the entire\nminibatch. Models trained with Batch Renormalization perform substantially\nbetter than batchnorm when training with small or non-i.i.d. minibatches. At\nthe same time, Batch Renormalization retains the benefits of batchnorm such as\ninsensitivity to initialization and training efficiency.\n", "versions": [{"version": "v1", "created": "Fri, 10 Feb 2017 18:27:17 GMT"}, {"version": "v2", "created": "Thu, 30 Mar 2017 17:58:32 GMT"}], "update_date": "2017-03-31", "authors_parsed": [["Ioffe", "Sergey", ""]]}, {"id": "1702.03307", "submitter": "Ershad Banijamali Mr.", "authors": "Ershad Banijamali, Ali Ghodsi, Pascal Poupart", "title": "Generative Mixture of Networks", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A generative model based on training deep architectures is proposed. The\nmodel consists of K networks that are trained together to learn the underlying\ndistribution of a given data set. The process starts with dividing the input\ndata into K clusters and feeding each of them into a separate network. After\nfew iterations of training networks separately, we use an EM-like algorithm to\ntrain the networks together and update the clusters of the data. We call this\nmodel Mixture of Networks. The provided model is a platform that can be used\nfor any deep structure and be trained by any conventional objective function\nfor distribution modeling. As the components of the model are neural networks,\nit has high capability in characterizing complicated data distributions as well\nas clustering data. We apply the algorithm on MNIST hand-written digits and\nYale face datasets. We also demonstrate the clustering ability of the model\nusing some real-world and toy examples.\n", "versions": [{"version": "v1", "created": "Fri, 10 Feb 2017 19:21:02 GMT"}], "update_date": "2017-02-14", "authors_parsed": [["Banijamali", "Ershad", ""], ["Ghodsi", "Ali", ""], ["Poupart", "Pascal", ""]]}, {"id": "1702.03334", "submitter": "Kirthevasan Kandasamy", "authors": "Kirthevasan Kandasamy, Yoram Bachrach, Ryota Tomioka, Daniel Tarlow,\n  David Carter", "title": "Batch Policy Gradient Methods for Improving Neural Conversation Models", "comments": "International Conference on Learning Representations (ICLR) 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study reinforcement learning of chatbots with recurrent neural network\narchitectures when the rewards are noisy and expensive to obtain. For instance,\na chatbot used in automated customer service support can be scored by quality\nassurance agents, but this process can be expensive, time consuming and noisy.\nPrevious reinforcement learning work for natural language processing uses\non-policy updates and/or is designed for on-line learning settings. We\ndemonstrate empirically that such strategies are not appropriate for this\nsetting and develop an off-policy batch policy gradient method (BPG). We\ndemonstrate the efficacy of our method via a series of synthetic experiments\nand an Amazon Mechanical Turk experiment on a restaurant recommendations\ndataset.\n", "versions": [{"version": "v1", "created": "Fri, 10 Feb 2017 21:58:40 GMT"}], "update_date": "2017-02-14", "authors_parsed": [["Kandasamy", "Kirthevasan", ""], ["Bachrach", "Yoram", ""], ["Tomioka", "Ryota", ""], ["Tarlow", "Daniel", ""], ["Carter", "David", ""]]}, {"id": "1702.03380", "submitter": "Guoqiang Zhang", "authors": "Guoqiang Zhang and W. Bastiaan Kleijn", "title": "Training Deep Neural Networks via Optimization Over Graphs", "comments": "5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we propose to train a deep neural network by distributed\noptimization over a graph. Two nonlinear functions are considered: the\nrectified linear unit (ReLU) and a linear unit with both lower and upper\ncutoffs (DCutLU). The problem reformulation over a graph is realized by\nexplicitly representing ReLU or DCutLU using a set of slack variables. We then\napply the alternating direction method of multipliers (ADMM) to update the\nweights of the network layerwise by solving subproblems of the reformulated\nproblem. Empirical results suggest that the ADMM-based method is less sensitive\nto overfitting than the stochastic gradient descent (SGD) and Adam methods.\n", "versions": [{"version": "v1", "created": "Sat, 11 Feb 2017 04:02:40 GMT"}, {"version": "v2", "created": "Sat, 17 Jun 2017 11:18:48 GMT"}], "update_date": "2017-06-20", "authors_parsed": [["Zhang", "Guoqiang", ""], ["Kleijn", "W. Bastiaan", ""]]}, {"id": "1702.03402", "submitter": "Mohamed Bouaziz", "authors": "Mohamed Bouaziz, Mohamed Morchid, Richard Dufour, Georges Linar\\`es,\n  Renato De Mori", "title": "Parallel Long Short-Term Memory for Multi-stream Classification", "comments": "2016 IEEE Workshop on Spoken Language Technology", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, machine learning methods have provided a broad spectrum of original\nand efficient algorithms based on Deep Neural Networks (DNN) to automatically\npredict an outcome with respect to a sequence of inputs. Recurrent hidden cells\nallow these DNN-based models to manage long-term dependencies such as Recurrent\nNeural Networks (RNN) and Long Short-Term Memory (LSTM). Nevertheless, these\nRNNs process a single input stream in one (LSTM) or two (Bidirectional LSTM)\ndirections. But most of the information available nowadays is from multistreams\nor multimedia documents, and require RNNs to process these information\nsynchronously during the training. This paper presents an original LSTM-based\narchitecture, named Parallel LSTM (PLSTM), that carries out multiple parallel\nsynchronized input sequences in order to predict a common output. The proposed\nPLSTM method could be used for parallel sequence classification purposes. The\nPLSTM approach is evaluated on an automatic telecast genre sequences\nclassification task and compared with different state-of-the-art architectures.\nResults show that the proposed PLSTM method outperforms the baseline n-gram\nmodels as well as the state-of-the-art LSTM approach.\n", "versions": [{"version": "v1", "created": "Sat, 11 Feb 2017 09:50:40 GMT"}], "update_date": "2017-02-15", "authors_parsed": [["Bouaziz", "Mohamed", ""], ["Morchid", "Mohamed", ""], ["Dufour", "Richard", ""], ["Linar\u00e8s", "Georges", ""], ["De Mori", "Renato", ""]]}, {"id": "1702.03447", "submitter": "Alex Memory", "authors": "Angelika Kimmig, Alex Memory, Renee J. Miller, Lise Getoor", "title": "A Collective, Probabilistic Approach to Schema Mapping: Appendix", "comments": "This is the appendix to the paper \"A Collective, Probabilistic\n  Approach to Schema Mapping\" accepted to ICDE 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this appendix we provide additional supplementary material to \"A\nCollective, Probabilistic Approach to Schema Mapping.\" We include an additional\nextended example, supplementary experiment details, and proof for the\ncomplexity result stated in the main paper.\n", "versions": [{"version": "v1", "created": "Sat, 11 Feb 2017 19:18:41 GMT"}], "update_date": "2017-02-14", "authors_parsed": [["Kimmig", "Angelika", ""], ["Memory", "Alex", ""], ["Miller", "Renee J.", ""], ["Getoor", "Lise", ""]]}, {"id": "1702.03465", "submitter": "Sandy Huang", "authors": "Sandy H. Huang, David Held, Pieter Abbeel, Anca D. Dragan", "title": "Enabling Robots to Communicate their Objectives", "comments": "RSS 2017", "journal-ref": null, "doi": "10.15607/RSS.2017.XIII.059", "report-no": null, "categories": "cs.RO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The overarching goal of this work is to efficiently enable end-users to\ncorrectly anticipate a robot's behavior in novel situations. Since a robot's\nbehavior is often a direct result of its underlying objective function, our\ninsight is that end-users need to have an accurate mental model of this\nobjective function in order to understand and predict what the robot will do.\nWhile people naturally develop such a mental model over time through observing\nthe robot act, this familiarization process may be lengthy. Our approach\nreduces this time by having the robot model how people infer objectives from\nobserved behavior, and then it selects those behaviors that are maximally\ninformative. The problem of computing a posterior over objectives from observed\nbehavior is known as Inverse Reinforcement Learning (IRL), and has been applied\nto robots learning human objectives. We consider the problem where the roles of\nhuman and robot are swapped. Our main contribution is to recognize that unlike\nrobots, humans will not be exact in their IRL inference. We thus introduce two\nfactors to define candidate approximate-inference models for human learning in\nthis setting, and analyze them in a user study in the autonomous driving\ndomain. We show that certain approximate-inference models lead to the robot\ngenerating example behaviors that better enable users to anticipate what it\nwill do in novel situations. Our results also suggest, however, that additional\nresearch is needed in modeling how humans extrapolate from examples of robot\nbehavior.\n", "versions": [{"version": "v1", "created": "Sat, 11 Feb 2017 22:39:39 GMT"}, {"version": "v2", "created": "Thu, 18 Oct 2018 17:43:04 GMT"}], "update_date": "2018-10-19", "authors_parsed": [["Huang", "Sandy H.", ""], ["Held", "David", ""], ["Abbeel", "Pieter", ""], ["Dragan", "Anca D.", ""]]}, {"id": "1702.03500", "submitter": "Yu Sun", "authors": "Yu Sun, Ke Tang, Zexuan Zhu, Xin Yao", "title": "Concept Drift Adaptation by Exploiting Historical Knowledge", "comments": "First version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Incremental learning with concept drift has often been tackled by ensemble\nmethods, where models built in the past can be re-trained to attain new models\nfor the current data. Two design questions need to be addressed in developing\nensemble methods for incremental learning with concept drift, i.e., which\nhistorical (i.e., previously trained) models should be preserved and how to\nutilize them. A novel ensemble learning method, namely Diversity and Transfer\nbased Ensemble Learning (DTEL), is proposed in this paper. Given newly arrived\ndata, DTEL uses each preserved historical model as an initial model and further\ntrains it with the new data via transfer learning. Furthermore, DTEL preserves\na diverse set of historical models, rather than a set of historical models that\nare merely accurate in terms of classification accuracy. Empirical studies on\n15 synthetic data streams and 4 real-world data streams (all with concept\ndrifts) demonstrate that DTEL can handle concept drift more effectively than 4\nother state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Sun, 12 Feb 2017 07:35:49 GMT"}], "update_date": "2017-02-14", "authors_parsed": [["Sun", "Yu", ""], ["Tang", "Ke", ""], ["Zhu", "Zexuan", ""], ["Yao", "Xin", ""]]}, {"id": "1702.03522", "submitter": "Muni Sreenivas Pydi", "authors": "Muni Sreenivas Pydi and Ambedkar Dukkipati", "title": "On Consistency of Compressive Spectral Clustering", "comments": "Accepted for publication at the 2018 IEEE International Symposium on\n  Information Theory (ISIT), Vail, Colorado, USA", "journal-ref": "ISIT 2018", "doi": null, "report-no": null, "categories": "stat.ML cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spectral clustering is one of the most popular methods for community\ndetection in graphs. A key step in spectral clustering algorithms is the eigen\ndecomposition of the $n{\\times}n$ graph Laplacian matrix to extract its $k$\nleading eigenvectors, where $k$ is the desired number of clusters among $n$\nobjects. This is prohibitively complex to implement for very large datasets.\nHowever, it has recently been shown that it is possible to bypass the eigen\ndecomposition by computing an approximate spectral embedding through graph\nfiltering of random signals. In this paper, we analyze the working of spectral\nclustering performed via graph filtering on the stochastic block model.\nSpecifically, we characterize the effects of sparsity, dimensionality and\nfilter approximation error on the consistency of the algorithm in recovering\nplanted clusters.\n", "versions": [{"version": "v1", "created": "Sun, 12 Feb 2017 13:15:03 GMT"}, {"version": "v2", "created": "Sun, 5 Mar 2017 12:38:04 GMT"}, {"version": "v3", "created": "Tue, 29 May 2018 22:00:06 GMT"}], "update_date": "2018-09-10", "authors_parsed": [["Pydi", "Muni Sreenivas", ""], ["Dukkipati", "Ambedkar", ""]]}, {"id": "1702.03584", "submitter": "Qi Lei", "authors": "Qi Lei, Jinfeng Yi, Roman Vaculin, Lingfei Wu, Inderjit S. Dhillon", "title": "Similarity Preserving Representation Learning for Time Series Clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A considerable amount of clustering algorithms take instance-feature matrices\nas their inputs. As such, they cannot directly analyze time series data due to\nits temporal nature, usually unequal lengths, and complex properties. This is a\ngreat pity since many of these algorithms are effective, robust, efficient, and\neasy to use. In this paper, we bridge this gap by proposing an efficient\nrepresentation learning framework that is able to convert a set of time series\nwith various lengths to an instance-feature matrix. In particular, we guarantee\nthat the pairwise similarities between time series are well preserved after the\ntransformation, thus the learned feature representation is particularly\nsuitable for the time series clustering task. Given a set of $n$ time series,\nwe first construct an $n\\times n$ partially-observed similarity matrix by\nrandomly sampling $\\mathcal{O}(n \\log n)$ pairs of time series and computing\ntheir pairwise similarities. We then propose an efficient algorithm that solves\na non-convex and NP-hard problem to learn new features based on the\npartially-observed similarity matrix. By conducting extensive empirical\nstudies, we show that the proposed framework is more effective, efficient, and\nflexible, compared to other state-of-the-art time series clustering methods.\n", "versions": [{"version": "v1", "created": "Sun, 12 Feb 2017 22:38:42 GMT"}, {"version": "v2", "created": "Thu, 9 Mar 2017 02:03:48 GMT"}, {"version": "v3", "created": "Sun, 2 Jun 2019 04:15:50 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Lei", "Qi", ""], ["Yi", "Jinfeng", ""], ["Vaculin", "Roman", ""], ["Wu", "Lingfei", ""], ["Dhillon", "Inderjit S.", ""]]}, {"id": "1702.03605", "submitter": "Mingda Qiao", "authors": "Lijie Chen, Jian Li, Mingda Qiao", "title": "Nearly Instance Optimal Sample Complexity Bounds for Top-k Arm Selection", "comments": "Accepted by AISTATS 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the Best-$k$-Arm problem, we are given $n$ stochastic bandit arms, each\nassociated with an unknown reward distribution. We are required to identify the\n$k$ arms with the largest means by taking as few samples as possible. In this\npaper, we make progress towards a complete characterization of the\ninstance-wise sample complexity bounds for the Best-$k$-Arm problem. On the\nlower bound side, we obtain a novel complexity term to measure the sample\ncomplexity that every Best-$k$-Arm instance requires. This is derived by an\ninteresting and nontrivial reduction from the Best-$1$-Arm problem. We also\nprovide an elimination-based algorithm that matches the instance-wise lower\nbound within doubly-logarithmic factors. The sample complexity of our algorithm\nstrictly dominates the state-of-the-art for Best-$k$-Arm (module constant\nfactors).\n", "versions": [{"version": "v1", "created": "Mon, 13 Feb 2017 01:31:46 GMT"}], "update_date": "2017-02-15", "authors_parsed": [["Chen", "Lijie", ""], ["Li", "Jian", ""], ["Qiao", "Mingda", ""]]}, {"id": "1702.03613", "submitter": "Ming Yang", "authors": "You Lin, Ming Yang, Can Wan, Jianhui Wang, Yonghua Song", "title": "A Multi-model Combination Approach for Probabilistic Wind Power\n  Forecasting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Short-term probabilistic wind power forecasting can provide critical\nquantified uncertainty information of wind generation for power system\noperation and control. As the complicated characteristics of wind power\nprediction error, it would be difficult to develop a universal forecasting\nmodel dominating over other alternative models. Therefore, a novel multi-model\ncombination (MMC) approach for short-term probabilistic wind generation\nforecasting is proposed in this paper to exploit the advantages of different\nforecasting models. The proposed approach can combine different forecasting\nmodels those provide different kinds of probability density functions to\nimprove the probabilistic forecast accuracy. Three probabilistic forecasting\nmodels based on the sparse Bayesian learning, kernel density estimation and\nbeta distribution fitting are used to form the combined model. The parameters\nof the MMC model are solved based on Bayesian framework. Numerical tests\nillustrate the effectiveness of the proposed MMC approach.\n", "versions": [{"version": "v1", "created": "Mon, 13 Feb 2017 02:48:16 GMT"}], "update_date": "2017-02-14", "authors_parsed": [["Lin", "You", ""], ["Yang", "Ming", ""], ["Wan", "Can", ""], ["Wang", "Jianhui", ""], ["Song", "Yonghua", ""]]}, {"id": "1702.03644", "submitter": "Yan Zheng", "authors": "Yan Zheng and Jeff M. Phillips", "title": "Coresets for Kernel Regression", "comments": "11 pages, 20 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Kernel regression is an essential and ubiquitous tool for non-parametric data\nanalysis, particularly popular among time series and spatial data. However, the\ncentral operation which is performed many times, evaluating a kernel on the\ndata set, takes linear time. This is impractical for modern large data sets.\n  In this paper we describe coresets for kernel regression: compressed data\nsets which can be used as proxy for the original data and have provably bounded\nworst case error. The size of the coresets are independent of the raw number of\ndata points, rather they only depend on the error guarantee, and in some cases\nthe size of domain and amount of smoothing. We evaluate our methods on very\nlarge time series and spatial data, and demonstrate that they incur negligible\nerror, can be constructed extremely efficiently, and allow for great\ncomputational gains.\n", "versions": [{"version": "v1", "created": "Mon, 13 Feb 2017 06:17:16 GMT"}, {"version": "v2", "created": "Wed, 31 May 2017 14:34:08 GMT"}], "update_date": "2017-06-01", "authors_parsed": [["Zheng", "Yan", ""], ["Phillips", "Jeff M.", ""]]}, {"id": "1702.03767", "submitter": "Patrick O. Glauner", "authors": "Patrick Glauner, Angelo Migliosi, Jorge Meira, Petko Valtchev, Radu\n  State, Franck Bettinger", "title": "Is Big Data Sufficient for a Reliable Detection of Non-Technical Losses?", "comments": "Proceedings of the 19th International Conference on Intelligent\n  System Applications to Power Systems (ISAP 2017)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Non-technical losses (NTL) occur during the distribution of electricity in\npower grids and include, but are not limited to, electricity theft and faulty\nmeters. In emerging countries, they may range up to 40% of the total\nelectricity distributed. In order to detect NTLs, machine learning methods are\nused that learn irregular consumption patterns from customer data and\ninspection results. The Big Data paradigm followed in modern machine learning\nreflects the desire of deriving better conclusions from simply analyzing more\ndata, without the necessity of looking at theory and models. However, the\nsample of inspected customers may be biased, i.e. it does not represent the\npopulation of all customers. As a consequence, machine learning models trained\non these inspection results are biased as well and therefore lead to unreliable\npredictions of whether customers cause NTL or not. In machine learning, this\nissue is called covariate shift and has not been addressed in the literature on\nNTL detection yet. In this work, we present a novel framework for quantifying\nand visualizing covariate shift. We apply it to a commercial data set from\nBrazil that consists of 3.6M customers and 820K inspection results. We show\nthat some features have a stronger covariate shift than others, making\npredictions less reliable. In particular, previous inspections were focused on\ncertain neighborhoods or customer classes and that they were not sufficiently\nspread among the population of customers. This framework is about to be\ndeployed in a commercial product for NTL detection.\n", "versions": [{"version": "v1", "created": "Mon, 13 Feb 2017 13:33:47 GMT"}, {"version": "v2", "created": "Tue, 25 Jul 2017 04:35:45 GMT"}], "update_date": "2017-07-26", "authors_parsed": [["Glauner", "Patrick", ""], ["Migliosi", "Angelo", ""], ["Meira", "Jorge", ""], ["Valtchev", "Petko", ""], ["State", "Radu", ""], ["Bettinger", "Franck", ""]]}, {"id": "1702.03791", "submitter": "Hong Yu", "authors": "Hong Yu, Zheng-Hua Tan, Zhanyu Ma, Jun Guo", "title": "DNN Filter Bank Cepstral Coefficients for Spoofing Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the development of speech synthesis techniques, automatic speaker\nverification systems face the serious challenge of spoofing attack. In order to\nimprove the reliability of speaker verification systems, we develop a new\nfilter bank based cepstral feature, deep neural network filter bank cepstral\ncoefficients (DNN-FBCC), to distinguish between natural and spoofed speech. The\ndeep neural network filter bank is automatically generated by training a filter\nbank neural network (FBNN) using natural and synthetic speech. By adding\nrestrictions on the training rules, the learned weight matrix of FBNN is\nband-limited and sorted by frequency, similar to the normal filter bank. Unlike\nthe manually designed filter bank, the learned filter bank has different filter\nshapes in different channels, which can capture the differences between natural\nand synthetic speech more effectively. The experimental results on the ASVspoof\n{2015} database show that the Gaussian mixture model maximum-likelihood\n(GMM-ML) classifier trained by the new feature performs better than the\nstate-of-the-art linear frequency cepstral coefficients (LFCC) based\nclassifier, especially on detecting unknown attacks.\n", "versions": [{"version": "v1", "created": "Mon, 13 Feb 2017 14:44:17 GMT"}], "update_date": "2017-02-14", "authors_parsed": [["Yu", "Hong", ""], ["Tan", "Zheng-Hua", ""], ["Ma", "Zhanyu", ""], ["Guo", "Jun", ""]]}, {"id": "1702.03849", "submitter": "Maxim Raginsky", "authors": "Maxim Raginsky, Alexander Rakhlin, Matus Telgarsky", "title": "Non-convex learning via Stochastic Gradient Langevin Dynamics: a\n  nonasymptotic analysis", "comments": "29 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC math.PR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic Gradient Langevin Dynamics (SGLD) is a popular variant of\nStochastic Gradient Descent, where properly scaled isotropic Gaussian noise is\nadded to an unbiased estimate of the gradient at each iteration. This modest\nchange allows SGLD to escape local minima and suffices to guarantee asymptotic\nconvergence to global minimizers for sufficiently regular non-convex objectives\n(Gelfand and Mitter, 1991). The present work provides a nonasymptotic analysis\nin the context of non-convex learning problems, giving finite-time guarantees\nfor SGLD to find approximate minimizers of both empirical and population risks.\nAs in the asymptotic setting, our analysis relates the discrete-time SGLD\nMarkov chain to a continuous-time diffusion process. A new tool that drives the\nresults is the use of weighted transportation cost inequalities to quantify the\nrate of convergence of SGLD to a stationary distribution in the Euclidean\n$2$-Wasserstein distance.\n", "versions": [{"version": "v1", "created": "Mon, 13 Feb 2017 16:11:38 GMT"}, {"version": "v2", "created": "Tue, 14 Feb 2017 23:51:43 GMT"}, {"version": "v3", "created": "Sun, 4 Jun 2017 04:26:02 GMT"}], "update_date": "2017-06-06", "authors_parsed": [["Raginsky", "Maxim", ""], ["Rakhlin", "Alexander", ""], ["Telgarsky", "Matus", ""]]}, {"id": "1702.03865", "submitter": "Akosua Busia", "authors": "Akosua Busia and Navdeep Jaitly", "title": "Next-Step Conditioned Deep Convolutional Neural Networks Improve Protein\n  Secondary Structure Prediction", "comments": "11 pages, 3 figures, 4 tables, submitted to ISMB/ECCB 2017. arXiv\n  admin note: text overlap with arXiv:1611.01503", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-bio.BM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently developed deep learning techniques have significantly improved the\naccuracy of various speech and image recognition systems. In this paper we show\nhow to adapt some of these techniques to create a novel chained convolutional\narchitecture with next-step conditioning for improving performance on protein\nsequence prediction problems. We explore its value by demonstrating its ability\nto improve performance on eight-class secondary structure prediction. We first\nestablish a state-of-the-art baseline by adapting recent advances in\nconvolutional neural networks which were developed for vision tasks. This model\nachieves 70.0% per amino acid accuracy on the CB513 benchmark dataset without\nuse of standard performance-boosting techniques such as ensembling or multitask\nlearning. We then improve upon this state-of-the-art result using a novel\nchained prediction approach which frames the secondary structure prediction as\na next-step prediction problem. This sequential model achieves 70.3% Q8\naccuracy on CB513 with a single model; an ensemble of these models produces\n71.4% Q8 accuracy on the same test set, improving upon the previous overall\nstate of the art for the eight-class secondary structure problem. Our models\nare implemented using TensorFlow, an open-source machine learning software\nlibrary available at TensorFlow.org; we aim to release the code for these\nexperiments as part of the TensorFlow repository.\n", "versions": [{"version": "v1", "created": "Mon, 13 Feb 2017 16:44:18 GMT"}], "update_date": "2017-02-20", "authors_parsed": [["Busia", "Akosua", ""], ["Jaitly", "Navdeep", ""]]}, {"id": "1702.03920", "submitter": "Saurabh Gupta", "authors": "Saurabh Gupta, Varun Tolani, James Davidson, Sergey Levine, Rahul\n  Sukthankar, Jitendra Malik", "title": "Cognitive Mapping and Planning for Visual Navigation", "comments": "Extended IJCV Version of the original paper at CVPR17. Project\n  website with code, models, simulation environment and videos:\n  https://sites.google.com/view/cognitive-mapping-and-planning/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a neural architecture for navigation in novel environments. Our\nproposed architecture learns to map from first-person views and plans a\nsequence of actions towards goals in the environment. The Cognitive Mapper and\nPlanner (CMP) is based on two key ideas: a) a unified joint architecture for\nmapping and planning, such that the mapping is driven by the needs of the task,\nand b) a spatial memory with the ability to plan given an incomplete set of\nobservations about the world. CMP constructs a top-down belief map of the world\nand applies a differentiable neural net planner to produce the next action at\neach time step. The accumulated belief of the world enables the agent to track\nvisited regions of the environment. We train and test CMP on navigation\nproblems in simulation environments derived from scans of real world buildings.\nOur experiments demonstrate that CMP outperforms alternate learning-based\narchitectures, as well as, classical mapping and path planning approaches in\nmany cases. Furthermore, it naturally extends to semantically specified goals,\nsuch as 'going to a chair'. We also deploy CMP on physical robots in indoor\nenvironments, where it achieves reasonable performance, even though it is\ntrained entirely in simulation.\n", "versions": [{"version": "v1", "created": "Mon, 13 Feb 2017 18:52:04 GMT"}, {"version": "v2", "created": "Sun, 23 Apr 2017 01:59:30 GMT"}, {"version": "v3", "created": "Thu, 7 Feb 2019 18:54:58 GMT"}], "update_date": "2019-02-08", "authors_parsed": [["Gupta", "Saurabh", ""], ["Tolani", "Varun", ""], ["Davidson", "James", ""], ["Levine", "Sergey", ""], ["Sukthankar", "Rahul", ""], ["Malik", "Jitendra", ""]]}, {"id": "1702.04008", "submitter": "Karen Ullrich", "authors": "Karen Ullrich, Edward Meeds, Max Welling", "title": "Soft Weight-Sharing for Neural Network Compression", "comments": "ICLR2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The success of deep learning in numerous application domains created the de-\nsire to run and train them on mobile devices. This however, conflicts with\ntheir computationally, memory and energy intense nature, leading to a growing\ninterest in compression. Recent work by Han et al. (2015a) propose a pipeline\nthat involves retraining, pruning and quantization of neural network weights,\nobtaining state-of-the-art compression rates. In this paper, we show that\ncompetitive compression rates can be achieved by using a version of soft\nweight-sharing (Nowlan & Hinton, 1992). Our method achieves both quantization\nand pruning in one simple (re-)training procedure. This point of view also\nexposes the relation between compression and the minimum description length\n(MDL) principle.\n", "versions": [{"version": "v1", "created": "Mon, 13 Feb 2017 22:54:18 GMT"}, {"version": "v2", "created": "Tue, 9 May 2017 14:05:43 GMT"}], "update_date": "2017-05-10", "authors_parsed": [["Ullrich", "Karen", ""], ["Meeds", "Edward", ""], ["Welling", "Max", ""]]}, {"id": "1702.04013", "submitter": "Piotr Szyma\\'nski", "authors": "Piotr Szyma\\'nski and Tomasz Kajdanowicz", "title": "Is a Data-Driven Approach still Better than Random Choice with Naive\n  Bayes classifiers?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the performance of data-driven, a priori and random approaches to\nlabel space partitioning for multi-label classification with a Gaussian Naive\nBayes classifier. Experiments were performed on 12 benchmark data sets and\nevaluated on 5 established measures of classification quality: micro and macro\naveraged F1 score, Subset Accuracy and Hamming loss. Data-driven methods are\nsignificantly better than an average run of the random baseline. In case of F1\nscores and Subset Accuracy - data driven approaches were more likely to perform\nbetter than random approaches than otherwise in the worst case. There always\nexists a method that performs better than a priori methods in the worst case.\nThe advantage of data-driven methods against a priori methods with a weak\nclassifier is lesser than when tree classifiers are used.\n", "versions": [{"version": "v1", "created": "Mon, 13 Feb 2017 23:04:31 GMT"}], "update_date": "2017-02-15", "authors_parsed": [["Szyma\u0144ski", "Piotr", ""], ["Kajdanowicz", "Tomasz", ""]]}, {"id": "1702.04077", "submitter": "Rachelle Rivero", "authors": "Tsuyoshi Kato and Rachelle Rivero", "title": "Mutual Kernel Matrix Completion", "comments": "10 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the huge influx of various data nowadays, extracting knowledge from them\nhas become an interesting but tedious task among data scientists, particularly\nwhen the data come in heterogeneous form and have missing information. Many\ndata completion techniques had been introduced, especially in the advent of\nkernel methods. However, among the many data completion techniques available in\nthe literature, studies about mutually completing several incomplete kernel\nmatrices have not been given much attention yet. In this paper, we present a\nnew method, called Mutual Kernel Matrix Completion (MKMC) algorithm, that\ntackles this problem of mutually inferring the missing entries of multiple\nkernel matrices by combining the notions of data fusion and kernel matrix\ncompletion, applied on biological data sets to be used for classification task.\nWe first introduced an objective function that will be minimized by exploiting\nthe EM algorithm, which in turn results to an estimate of the missing entries\nof the kernel matrices involved. The completed kernel matrices are then\ncombined to produce a model matrix that can be used to further improve the\nobtained estimates. An interesting result of our study is that the E-step and\nthe M-step are given in closed form, which makes our algorithm efficient in\nterms of time and memory. After completion, the (completed) kernel matrices are\nthen used to train an SVM classifier to test how well the relationships among\nthe entries are preserved. Our empirical results show that the proposed\nalgorithm bested the traditional completion techniques in preserving the\nrelationships among the data points, and in accurately recovering the missing\nkernel matrix entries. By far, MKMC offers a promising solution to the problem\nof mutual estimation of a number of relevant incomplete kernel matrices.\n", "versions": [{"version": "v1", "created": "Tue, 14 Feb 2017 04:30:03 GMT"}, {"version": "v2", "created": "Fri, 17 Feb 2017 05:16:10 GMT"}, {"version": "v3", "created": "Wed, 10 May 2017 09:59:32 GMT"}], "update_date": "2017-05-11", "authors_parsed": [["Kato", "Tsuyoshi", ""], ["Rivero", "Rachelle", ""]]}, {"id": "1702.04121", "submitter": "Carlton Macdonald Downey", "authors": "Carlton Downey, Ahmed Hefny, Geoffrey Gordon", "title": "Practical Learning of Predictive State Representations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the past decade there has been considerable interest in spectral\nalgorithms for learning Predictive State Representations (PSRs). Spectral\nalgorithms have appealing theoretical guarantees; however, the resulting models\ndo not always perform well on inference tasks in practice. One reason for this\nbehavior is the mismatch between the intended task (accurate filtering or\nprediction) and the loss function being optimized by the algorithm (estimation\nerror in model parameters).\n  A natural idea is to improve performance by refining PSRs using an algorithm\nsuch as EM. Unfortunately it is not obvious how to apply apply an EM style\nalgorithm in the context of PSRs as the Log Likelihood is not well defined for\nall PSRs. We show that it is possible to overcome this problem using ideas from\nPredictive State Inference Machines.\n  We combine spectral algorithms for PSRs as a consistent and efficient\ninitialization with PSIM-style updates to refine the resulting model\nparameters. By combining these two ideas we develop Inference Gradients, a\nsimple, fast, and robust method for practical learning of PSRs. Inference\nGradients performs gradient descent in the PSR parameter space to optimize an\ninference-based loss function like PSIM. Because Inference Gradients uses a\nspectral initialization we get the same consistency benefits as PSRs. We show\nthat Inference Gradients outperforms both PSRs and PSIMs on real and synthetic\ndata sets.\n", "versions": [{"version": "v1", "created": "Tue, 14 Feb 2017 09:06:07 GMT"}], "update_date": "2017-02-15", "authors_parsed": [["Downey", "Carlton", ""], ["Hefny", "Ahmed", ""], ["Gordon", "Geoffrey", ""]]}, {"id": "1702.04126", "submitter": "Ian Osband", "authors": "Ian Osband and Benjamin Van Roy", "title": "Gaussian-Dirichlet Posterior Dominance in Sequential Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of sequential learning from categorical observations\nbounded in [0,1]. We establish an ordering between the Dirichlet posterior over\ncategorical outcomes and a Gaussian posterior under observations with N(0,1)\nnoise. We establish that, conditioned upon identical data with at least two\nobservations, the posterior mean of the categorical distribution will always\nsecond-order stochastically dominate the posterior mean of the Gaussian\ndistribution. These results provide a useful tool for the analysis of\nsequential learning under categorical outcomes.\n", "versions": [{"version": "v1", "created": "Tue, 14 Feb 2017 09:23:18 GMT"}, {"version": "v2", "created": "Thu, 1 Feb 2018 19:11:56 GMT"}, {"version": "v3", "created": "Fri, 9 Feb 2018 09:06:59 GMT"}], "update_date": "2018-02-12", "authors_parsed": [["Osband", "Ian", ""], ["Van Roy", "Benjamin", ""]]}, {"id": "1702.04165", "submitter": "Lorenzo Rimoldini", "authors": "Lorenzo Rimoldini, Krzysztof Nienartowicz, Maria S\\\"uveges, Jonathan\n  Charnas, Leanne P. Guy, Gr\\'egory Jevardat de Fombelle, Berry Holl, Isabelle\n  Lecoeur-Ta\\\"ibi, Nami Mowlavi, Diego Ord\\'o\\~nez-Blanco, and Laurent Eyer", "title": "Crossmatching variable objects with the Gaia data", "comments": "4 pages, 1 figure, in Astronomical Data Analysis Software and Systems\n  XXVI, Astronomical Society of the Pacific Conference Series", "journal-ref": null, "doi": null, "report-no": null, "categories": "astro-ph.IM cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tens of millions of new variable objects are expected to be identified in\nover a billion time series from the Gaia mission. Crossmatching known variable\nsources with those from Gaia is crucial to incorporate current knowledge,\nunderstand how these objects appear in the Gaia data, train supervised\nclassifiers to recognise known classes, and validate the results of the\nVariability Processing and Analysis Coordination Unit (CU7) within the Gaia\nData Analysis and Processing Consortium (DPAC). The method employed by CU7 to\ncrossmatch variables for the first Gaia data release includes a binary\nclassifier to take into account positional uncertainties, proper motion,\ntargeted variability signals, and artefacts present in the early calibration of\nthe Gaia data. Crossmatching with a classifier makes it possible to automate\nall those decisions which are typically made during visual inspection. The\nclassifier can be trained with objects characterized by a variety of attributes\nto ensure similarity in multiple dimensions (astrometry, photometry,\ntime-series features), with no need for a-priori transformations to compare\ndifferent photometric bands, or of predictive models of the motion of objects\nto compare positions. Other advantages as well as some disadvantages of the\nmethod are discussed. Implementation steps from the training to the assessment\nof the crossmatch classifier and selection of results are described.\n", "versions": [{"version": "v1", "created": "Tue, 14 Feb 2017 11:42:33 GMT"}], "update_date": "2017-02-15", "authors_parsed": [["Rimoldini", "Lorenzo", ""], ["Nienartowicz", "Krzysztof", ""], ["S\u00fcveges", "Maria", ""], ["Charnas", "Jonathan", ""], ["Guy", "Leanne P.", ""], ["de Fombelle", "Gr\u00e9gory Jevardat", ""], ["Holl", "Berry", ""], ["Lecoeur-Ta\u00efbi", "Isabelle", ""], ["Mowlavi", "Nami", ""], ["Ord\u00f3\u00f1ez-Blanco", "Diego", ""], ["Eyer", "Laurent", ""]]}, {"id": "1702.04267", "submitter": "Jan Hendrik Metzen", "authors": "Jan Hendrik Metzen, Tim Genewein, Volker Fischer, Bastian Bischoff", "title": "On Detecting Adversarial Perturbations", "comments": "Final version for ICLR2017 (see\n  https://openreview.net/forum?id=SJzCSf9xg&noteId=SJzCSf9xg)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning and deep learning in particular has advanced tremendously on\nperceptual tasks in recent years. However, it remains vulnerable against\nadversarial perturbations of the input that have been crafted specifically to\nfool the system while being quasi-imperceptible to a human. In this work, we\npropose to augment deep neural networks with a small \"detector\" subnetwork\nwhich is trained on the binary classification task of distinguishing genuine\ndata from data containing adversarial perturbations. Our method is orthogonal\nto prior work on addressing adversarial perturbations, which has mostly focused\non making the classification network itself more robust. We show empirically\nthat adversarial perturbations can be detected surprisingly well even though\nthey are quasi-imperceptible to humans. Moreover, while the detectors have been\ntrained to detect only a specific adversary, they generalize to similar and\nweaker adversaries. In addition, we propose an adversarial attack that fools\nboth the classifier and the detector and a novel training procedure for the\ndetector that counteracts this attack.\n", "versions": [{"version": "v1", "created": "Tue, 14 Feb 2017 15:44:26 GMT"}, {"version": "v2", "created": "Tue, 21 Feb 2017 06:53:38 GMT"}], "update_date": "2017-02-22", "authors_parsed": [["Metzen", "Jan Hendrik", ""], ["Genewein", "Tim", ""], ["Fischer", "Volker", ""], ["Bischoff", "Bastian", ""]]}, {"id": "1702.04283", "submitter": "Leslie Smith", "authors": "Leslie N. Smith and Nicholay Topin", "title": "Exploring loss function topology with cyclical learning rates", "comments": "Submitted as an ICLR 2017 Workshop paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present observations and discussion of previously unreported phenomena\ndiscovered while training residual networks. The goal of this work is to better\nunderstand the nature of neural networks through the examination of these new\nempirical results. These behaviors were identified through the application of\nCyclical Learning Rates (CLR) and linear network interpolation. Among these\nbehaviors are counterintuitive increases and decreases in training loss and\ninstances of rapid training. For example, we demonstrate how CLR can produce\ngreater testing accuracy than traditional training despite using large learning\nrates. Files to replicate these results are available at\nhttps://github.com/lnsmith54/exploring-loss\n", "versions": [{"version": "v1", "created": "Tue, 14 Feb 2017 16:46:19 GMT"}], "update_date": "2017-02-15", "authors_parsed": [["Smith", "Leslie N.", ""], ["Topin", "Nicholay", ""]]}, {"id": "1702.04415", "submitter": "Feng Mao", "authors": "Feng Mao, Edgar Blanco, Mingang Fu, Rohit Jain, Anurag Gupta,\n  Sebastien Mancel, Rong Yuan, Stephen Guo, Sai Kumar, Yayang Tian", "title": "Small Boxes Big Data: A Deep Learning Approach to Optimize Variable\n  Sized Bin Packing", "comments": "The Third IEEE International Conference on Big Data Computing Service\n  and Applications, 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bin Packing problems have been widely studied because of their broad\napplications in different domains. Known as a set of NP-hard problems, they\nhave different vari- ations and many heuristics have been proposed for\nobtaining approximate solutions. Specifically, for the 1D variable sized bin\npacking problem, the two key sets of optimization heuristics are the bin\nassignment and the bin allocation. Usually the performance of a single static\noptimization heuristic can not beat that of a dynamic one which is tailored for\neach bin packing instance. Building such an adaptive system requires modeling\nthe relationship between bin features and packing perform profiles. The primary\ndrawbacks of traditional AI machine learnings for this task are the natural\nlimitations of feature engineering, such as the curse of dimensionality and\nfeature selection quality. We introduce a deep learning approach to overcome\nthe drawbacks by applying a large training data set, auto feature selection and\nfast, accurate labeling. We show in this paper how to build such a system by\nboth theoretical formulation and engineering practices. Our prediction system\nachieves up to 89% training accuracy and 72% validation accuracy to select the\nbest heuristic that can generate a better quality bin packing solution.\n", "versions": [{"version": "v1", "created": "Tue, 14 Feb 2017 22:59:32 GMT"}], "update_date": "2017-02-16", "authors_parsed": [["Mao", "Feng", ""], ["Blanco", "Edgar", ""], ["Fu", "Mingang", ""], ["Jain", "Rohit", ""], ["Gupta", "Anurag", ""], ["Mancel", "Sebastien", ""], ["Yuan", "Rong", ""], ["Guo", "Stephen", ""], ["Kumar", "Sai", ""], ["Tian", "Yayang", ""]]}, {"id": "1702.04423", "submitter": "Han Zhao", "authors": "Han Zhao, Otilia Stretcu, Alex Smola, Geoff Gordon", "title": "Efficient Multitask Feature and Relationship Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a multitask learning problem, in which several predictors are\nlearned jointly. Prior research has shown that learning the relations between\ntasks, and between the input features, together with the predictor, can lead to\nbetter generalization and interpretability, which proved to be useful for\napplications in many domains. In this paper, we consider a formulation of\nmultitask learning that learns the relationships both between tasks and between\nfeatures, represented through a task covariance and a feature covariance\nmatrix, respectively. First, we demonstrate that existing methods proposed for\nthis problem present an issue that may lead to ill-posed optimization. We then\npropose an alternative formulation, as well as an efficient algorithm to\noptimize it. Using ideas from optimization and graph theory, we propose an\nefficient coordinate-wise minimization algorithm that has a closed form\nsolution for each block subproblem. Our experiments show that the proposed\noptimization method is orders of magnitude faster than its competitors. We also\nprovide a nonlinear extension that is able to achieve better generalization\nthan existing methods.\n", "versions": [{"version": "v1", "created": "Tue, 14 Feb 2017 23:43:32 GMT"}, {"version": "v2", "created": "Sun, 16 Sep 2018 21:35:41 GMT"}, {"version": "v3", "created": "Wed, 10 Jul 2019 06:00:02 GMT"}], "update_date": "2019-07-11", "authors_parsed": [["Zhao", "Han", ""], ["Stretcu", "Otilia", ""], ["Smola", "Alex", ""], ["Gordon", "Geoff", ""]]}, {"id": "1702.04459", "submitter": "Dianhui Wang", "authors": "Dianhui Wang, Ming Li", "title": "Robust Stochastic Configuration Networks with Kernel Density Estimation", "comments": "14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks have been widely used as predictive models to fit data\ndistribution, and they could be implemented through learning a collection of\nsamples. In many applications, however, the given dataset may contain noisy\nsamples or outliers which may result in a poor learner model in terms of\ngeneralization. This paper contributes to a development of robust stochastic\nconfiguration networks (RSCNs) for resolving uncertain data regression\nproblems. RSCNs are built on original stochastic configuration networks with\nweighted least squares method for evaluating the output weights, and the input\nweights and biases are incrementally and randomly generated by satisfying with\na set of inequality constrains. The kernel density estimation (KDE) method is\nemployed to set the penalty weights for each training samples, so that some\nnegative impacts, caused by noisy data or outliers, on the resulting learner\nmodel can be reduced. The alternating optimization technique is applied for\nupdating a RSCN model with improved penalty weights computed from the kernel\ndensity estimation function. Performance evaluation is carried out by a\nfunction approximation, four benchmark datasets and a case study on engineering\napplication. Comparisons to other robust randomised neural modelling\ntechniques, including the probabilistic robust learning algorithm for neural\nnetworks with random weights and improved RVFL networks, indicate that the\nproposed RSCNs with KDE perform favourably and demonstrate good potential for\nreal-world applications.\n", "versions": [{"version": "v1", "created": "Wed, 15 Feb 2017 03:54:29 GMT"}, {"version": "v2", "created": "Mon, 29 May 2017 15:29:47 GMT"}], "update_date": "2017-05-30", "authors_parsed": [["Wang", "Dianhui", ""], ["Li", "Ming", ""]]}, {"id": "1702.04521", "submitter": "Tim Rockt\\\"aschel", "authors": "Micha{\\l} Daniluk, Tim Rockt\\\"aschel, Johannes Welbl, Sebastian Riedel", "title": "Frustratingly Short Attention Spans in Neural Language Modeling", "comments": "Published as a conference paper at ICLR 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural language models predict the next token using a latent representation\nof the immediate token history. Recently, various methods for augmenting neural\nlanguage models with an attention mechanism over a differentiable memory have\nbeen proposed. For predicting the next token, these models query information\nfrom a memory of the recent history which can facilitate learning mid- and\nlong-range dependencies. However, conventional attention mechanisms used in\nmemory-augmented neural language models produce a single output vector per time\nstep. This vector is used both for predicting the next token as well as for the\nkey and value of a differentiable memory of a token history. In this paper, we\npropose a neural language model with a key-value attention mechanism that\noutputs separate representations for the key and value of a differentiable\nmemory, as well as for encoding the next-word distribution. This model\noutperforms existing memory-augmented neural language models on two corpora.\nYet, we found that our method mainly utilizes a memory of the five most recent\noutput representations. This led to the unexpected main finding that a much\nsimpler model based only on the concatenation of recent output representations\nfrom previous time steps is on par with more sophisticated memory-augmented\nneural language models.\n", "versions": [{"version": "v1", "created": "Wed, 15 Feb 2017 09:45:23 GMT"}], "update_date": "2017-02-16", "authors_parsed": [["Daniluk", "Micha\u0142", ""], ["Rockt\u00e4schel", "Tim", ""], ["Welbl", "Johannes", ""], ["Riedel", "Sebastian", ""]]}, {"id": "1702.04577", "submitter": "Mieczys{\\l}aw K{\\l}opotek", "authors": "Robert K{\\l}opotek and Mieczys{\\l}aw K{\\l}opotek", "title": "On the Discrepancy Between Kleinberg's Clustering Axioms and $k$-Means\n  Clustering Algorithm Behavior", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates the validity of Kleinberg's axioms for clustering\nfunctions with respect to the quite popular clustering algorithm called\n$k$-means. While Kleinberg's axioms have been discussed heavily in the past, we\nconcentrate here on the case predominantly relevant for $k$-means algorithm,\nthat is behavior embedded in Euclidean space. We point at some contradictions\nand counter intuitiveness aspects of this axiomatic set within $\\mathbb{R}^m$\nthat were evidently not discussed so far. Our results suggest that apparently\nwithout defining clearly what kind of clusters we expect we will not be able to\nconstruct a valid axiomatic system. In particular we look at the shape and the\ngaps between the clusters. Finally we demonstrate that there exist several ways\nto reconcile the formulation of the axioms with their intended meaning and that\nunder this reformulation the axioms stop to be contradictory and the real-world\n$k$-means algorithm conforms to this axiomatic system.\n", "versions": [{"version": "v1", "created": "Wed, 15 Feb 2017 12:25:28 GMT"}, {"version": "v2", "created": "Mon, 24 Apr 2017 06:48:26 GMT"}], "update_date": "2017-04-25", "authors_parsed": [["K\u0142opotek", "Robert", ""], ["K\u0142opotek", "Mieczys\u0142aw", ""]]}, {"id": "1702.04638", "submitter": "Mark Burgess", "authors": "Mark Burgess", "title": "A Spacetime Approach to Generalized Cognitive Reasoning in Multi-scale\n  Learning", "comments": "Typos corrected and new examples added to appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In modern machine learning, pattern recognition replaces realtime semantic\nreasoning. The mapping from input to output is learned with fixed semantics by\ntraining outcomes deliberately. This is an expensive and static approach which\ndepends heavily on the availability of a very particular kind of prior raining\ndata to make inferences in a single step. Conventional semantic network\napproaches, on the other hand, base multi-step reasoning on modal logics and\nhandcrafted ontologies, which are ad hoc, expensive to construct, and fragile\nto inconsistency. Both approaches may be enhanced by a hybrid approach, which\ncompletely separates reasoning from pattern recognition. In this report, a\nquasi-linguistic approach to knowledge representation is discussed, motivated\nby spacetime structure. Tokenized patterns from diverse sources are integrated\nto build a lightly constrained and approximately scale-free network. This is\nthen be parsed with very simple recursive algorithms to generate\n`brainstorming' sets of reasoned knowledge.\n", "versions": [{"version": "v1", "created": "Sun, 12 Feb 2017 14:58:45 GMT"}, {"version": "v2", "created": "Tue, 1 Aug 2017 11:32:42 GMT"}], "update_date": "2017-08-02", "authors_parsed": [["Burgess", "Mark", ""]]}, {"id": "1702.04649", "submitter": "Greg Wayne", "authors": "Mevlana Gemici, Chia-Chun Hung, Adam Santoro, Greg Wayne, Shakir\n  Mohamed, Danilo J. Rezende, David Amos, Timothy Lillicrap", "title": "Generative Temporal Models with Memory", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the general problem of modeling temporal data with long-range\ndependencies, wherein new observations are fully or partially predictable based\non temporally-distant, past observations. A sufficiently powerful temporal\nmodel should separate predictable elements of the sequence from unpredictable\nelements, express uncertainty about those unpredictable elements, and rapidly\nidentify novel elements that may help to predict the future. To create such\nmodels, we introduce Generative Temporal Models augmented with external memory\nsystems. They are developed within the variational inference framework, which\nprovides both a practical training methodology and methods to gain insight into\nthe models' operation. We show, on a range of problems with sparse, long-term\ntemporal dependencies, that these models store information from early in a\nsequence, and reuse this stored information efficiently. This allows them to\nperform substantially better than existing models based on well-known recurrent\nneural networks, like LSTMs.\n", "versions": [{"version": "v1", "created": "Wed, 15 Feb 2017 15:19:02 GMT"}, {"version": "v2", "created": "Tue, 21 Feb 2017 10:14:52 GMT"}], "update_date": "2017-02-22", "authors_parsed": [["Gemici", "Mevlana", ""], ["Hung", "Chia-Chun", ""], ["Santoro", "Adam", ""], ["Wayne", "Greg", ""], ["Mohamed", "Shakir", ""], ["Rezende", "Danilo J.", ""], ["Amos", "David", ""], ["Lillicrap", "Timothy", ""]]}, {"id": "1702.04683", "submitter": "Erwan Le Merrer", "authors": "Corentin Hardy, Erwan Le Merrer and Bruno Sericola", "title": "Distributed deep learning on edge-devices: feasibility via adaptive\n  compression", "comments": "Best paper award at IEEE International Symposium on Network Computing\n  and Applications (NCA 2017)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A large portion of data mining and analytic services use modern machine\nlearning techniques, such as deep learning. The state-of-the-art results by\ndeep learning come at the price of an intensive use of computing resources. The\nleading frameworks (e.g., TensorFlow) are executed on GPUs or on high-end\nservers in datacenters. On the other end, there is a proliferation of personal\ndevices with possibly free CPU cycles; this can enable services to run in\nusers' homes, embedding machine learning operations. In this paper, we ask the\nfollowing question: Is distributed deep learning computation on WAN connected\ndevices feasible, in spite of the traffic caused by learning tasks? We show\nthat such a setup rises some important challenges, most notably the ingress\ntraffic that the servers hosting the up-to-date model have to sustain.\n  In order to reduce this stress, we propose adaComp, a novel algorithm for\ncompressing worker updates to the model on the server. Applicable to stochastic\ngradient descent based approaches, it combines efficient gradient selection and\nlearning rate modulation. We then experiment and measure the impact of\ncompression, device heterogeneity and reliability on the accuracy of learned\nmodels, with an emulator platform that embeds TensorFlow into Linux containers.\nWe report a reduction of the total amount of data sent by workers to the server\nby two order of magnitude (e.g., 191-fold reduction for a convolutional network\non the MNIST dataset), when compared to a standard asynchronous stochastic\ngradient descent, while preserving model accuracy.\n", "versions": [{"version": "v1", "created": "Wed, 15 Feb 2017 16:57:24 GMT"}, {"version": "v2", "created": "Mon, 6 Nov 2017 12:54:36 GMT"}], "update_date": "2017-11-07", "authors_parsed": [["Hardy", "Corentin", ""], ["Merrer", "Erwan Le", ""], ["Sericola", "Bruno", ""]]}, {"id": "1702.04684", "submitter": "Hyukjun Gweon", "authors": "Hyukjun Gweon and Matthias Schonlau and Stefan Steiner", "title": "Nearest Labelset Using Double Distances for Multi-label Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-label classification is a type of supervised learning where an instance\nmay belong to multiple labels simultaneously. Predicting each label\nindependently has been criticized for not exploiting any correlation between\nlabels. In this paper we propose a novel approach, Nearest Labelset using\nDouble Distances (NLDD), that predicts the labelset observed in the training\ndata that minimizes a weighted sum of the distances in both the feature space\nand the label space to the new instance. The weights specify the relative\ntradeoff between the two distances. The weights are estimated from a binomial\nregression of the number of misclassified labels as a function of the two\ndistances. Model parameters are estimated by maximum likelihood. NLDD only\nconsiders labelsets observed in the training data, thus implicitly taking into\naccount label dependencies. Experiments on benchmark multi-label data sets show\nthat the proposed method on average outperforms other well-known approaches in\nterms of Hamming loss, 0/1 loss, and multi-label accuracy and ranks second\nafter ECC on the F-measure.\n", "versions": [{"version": "v1", "created": "Wed, 15 Feb 2017 17:01:08 GMT"}], "update_date": "2017-02-16", "authors_parsed": [["Gweon", "Hyukjun", ""], ["Schonlau", "Matthias", ""], ["Steiner", "Stefan", ""]]}, {"id": "1702.04686", "submitter": "Adrian Bevan", "authors": "Adrian Bevan, Rodrigo Gamboa Go\\~ni, Jon Hays, Tom Stevenson", "title": "Support Vector Machines and generalisation in HEP", "comments": "8 pages, submitted to the proceedings of the CHEP 2016 conference", "journal-ref": null, "doi": "10.1088/1742-6596/898/7/072021", "report-no": null, "categories": "physics.data-an cs.LG hep-ex", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We review the concept of Support Vector Machines (SVMs) and discuss examples\nof their use in a number of scenarios. Several SVM implementations have been\nused in HEP and we exemplify this algorithm using the Toolkit for Multivariate\nAnalysis (TMVA) implementation. We discuss examples relevant to HEP including\nbackground suppression for $H\\to\\tau^+\\tau^-$ at the LHC with several different\nkernel functions. Performance benchmarking leads to the issue of generalisation\nof hyper-parameter selection. The avoidance of fine tuning (over training or\nover fitting) in MVA hyper-parameter optimisation, i.e. the ability to ensure\ngeneralised performance of an MVA that is independent of the training,\nvalidation and test samples, is of utmost importance. We discuss this issue and\ncompare and contrast performance of hold-out and k-fold cross-validation. We\nhave extended the SVM functionality and introduced tools to facilitate cross\nvalidation in TMVA and present results based on these improvements.\n", "versions": [{"version": "v1", "created": "Wed, 15 Feb 2017 17:01:28 GMT"}], "update_date": "2017-12-06", "authors_parsed": [["Bevan", "Adrian", ""], ["Go\u00f1i", "Rodrigo Gamboa", ""], ["Hays", "Jon", ""], ["Stevenson", "Tom", ""]]}, {"id": "1702.04767", "submitter": "Han Zhao", "authors": "Han Zhao, Geoff Gordon", "title": "Linear Time Computation of Moments in Sum-Product Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian online algorithms for Sum-Product Networks (SPNs) need to update\ntheir posterior distribution after seeing one single additional instance. To do\nso, they must compute moments of the model parameters under this distribution.\nThe best existing method for computing such moments scales quadratically in the\nsize of the SPN, although it scales linearly for trees. This unfortunate\nscaling makes Bayesian online algorithms prohibitively expensive, except for\nsmall or tree-structured SPNs. We propose an optimal linear-time algorithm that\nworks even when the SPN is a general directed acyclic graph (DAG), which\nsignificantly broadens the applicability of Bayesian online algorithms for\nSPNs. There are three key ingredients in the design and analysis of our\nalgorithm: 1). For each edge in the graph, we construct a linear time reduction\nfrom the moment computation problem to a joint inference problem in SPNs. 2).\nUsing the property that each SPN computes a multilinear polynomial, we give an\nefficient procedure for polynomial evaluation by differentiation without\nexpanding the network that may contain exponentially many monomials. 3). We\npropose a dynamic programming method to further reduce the computation of the\nmoments of all the edges in the graph from quadratic to linear. We demonstrate\nthe usefulness of our linear time algorithm by applying it to develop a linear\ntime assume density filter (ADF) for SPNs.\n", "versions": [{"version": "v1", "created": "Wed, 15 Feb 2017 20:40:12 GMT"}, {"version": "v2", "created": "Sun, 5 Nov 2017 04:31:23 GMT"}], "update_date": "2017-11-07", "authors_parsed": [["Zhao", "Han", ""], ["Gordon", "Geoff", ""]]}, {"id": "1702.04770", "submitter": "Sam Wiseman", "authors": "Sam Wiseman, Sumit Chopra, Marc'Aurelio Ranzato, Arthur Szlam, Ruoyu\n  Sun, Soumith Chintala, Nicolas Vasilache", "title": "Training Language Models Using Target-Propagation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While Truncated Back-Propagation through Time (BPTT) is the most popular\napproach to training Recurrent Neural Networks (RNNs), it suffers from being\ninherently sequential (making parallelization difficult) and from truncating\ngradient flow between distant time-steps. We investigate whether Target\nPropagation (TPROP) style approaches can address these shortcomings.\nUnfortunately, extensive experiments suggest that TPROP generally underperforms\nBPTT, and we end with an analysis of this phenomenon, and suggestions for\nfuture work.\n", "versions": [{"version": "v1", "created": "Wed, 15 Feb 2017 20:56:30 GMT"}], "update_date": "2017-02-17", "authors_parsed": [["Wiseman", "Sam", ""], ["Chopra", "Sumit", ""], ["Ranzato", "Marc'Aurelio", ""], ["Szlam", "Arthur", ""], ["Sun", "Ruoyu", ""], ["Chintala", "Soumith", ""], ["Vasilache", "Nicolas", ""]]}, {"id": "1702.04782", "submitter": "Zachary Lipton", "authors": "Zachary C. Lipton, Subarna Tripathi", "title": "Precise Recovery of Latent Vectors from Generative Adversarial Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative adversarial networks (GANs) transform latent vectors into visually\nplausible images. It is generally thought that the original GAN formulation\ngives no out-of-the-box method to reverse the mapping, projecting images back\ninto latent space. We introduce a simple, gradient-based technique called\nstochastic clipping. In experiments, for images generated by the GAN, we\nprecisely recover their latent vector pre-images 100% of the time. Additional\nexperiments demonstrate that this method is robust to noise. Finally, we show\nthat even for unseen images, our method appears to recover unique encodings.\n", "versions": [{"version": "v1", "created": "Wed, 15 Feb 2017 21:26:21 GMT"}, {"version": "v2", "created": "Fri, 17 Feb 2017 01:56:36 GMT"}], "update_date": "2017-02-20", "authors_parsed": [["Lipton", "Zachary C.", ""], ["Tripathi", "Subarna", ""]]}, {"id": "1702.04825", "submitter": "Adish Singla", "authors": "Adish Singla, Hamed Hassani, Andreas Krause", "title": "Learning to Use Learners' Advice", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study a variant of the framework of online learning using\nexpert advice with limited/bandit feedback. We consider each expert as a\nlearning entity, seeking to more accurately reflecting certain real-world\napplications. In our setting, the feedback at any time $t$ is limited in a\nsense that it is only available to the expert $i^t$ that has been selected by\nthe central algorithm (forecaster), \\emph{i.e.}, only the expert $i^t$ receives\nfeedback from the environment and gets to learn at time $t$. We consider a\ngeneric black-box approach whereby the forecaster does not control or know the\nlearning dynamics of the experts apart from knowing the following no-regret\nlearning property: the average regret of any expert $j$ vanishes at a rate of\nat least $O(t_j^{\\regretRate-1})$ with $t_j$ learning steps where $\\regretRate\n\\in [0, 1]$ is a parameter.\n  In the spirit of competing against the best action in hindsight in\nmulti-armed bandits problem, our goal here is to be competitive w.r.t. the\ncumulative losses the algorithm could receive by following the policy of always\nselecting one expert. We prove the following hardness result: without any\ncoordination between the forecaster and the experts, it is impossible to design\na forecaster achieving no-regret guarantees. In order to circumvent this\nhardness result, we consider a practical assumption allowing the forecaster to\n\"guide\" the learning process of the experts by filtering/blocking some of the\nfeedbacks observed by them from the environment, \\emph{i.e.}, not allowing the\nselected expert $i^t$ to learn at time $t$ for some time steps. Then, we design\na novel no-regret learning algorithm \\algo for this problem setting by\ncarefully guiding the feedbacks observed by experts. We prove that \\algo\nachieves the worst-case expected cumulative regret of $O(\\Time^\\frac{1}{2 -\n\\regretRate})$ after $\\Time$ time steps.\n", "versions": [{"version": "v1", "created": "Thu, 16 Feb 2017 00:22:16 GMT"}, {"version": "v2", "created": "Fri, 17 Feb 2017 21:39:29 GMT"}], "update_date": "2017-02-21", "authors_parsed": [["Singla", "Adish", ""], ["Hassani", "Hamed", ""], ["Krause", "Andreas", ""]]}, {"id": "1702.04832", "submitter": "Marc Goessling", "authors": "Marc Goessling, Yali Amit", "title": "Dynamic Partition Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new approach for learning compact and intuitive distributed\nrepresentations with binary encoding. Rather than summing up expert votes as in\nproducts of experts, we employ for each variable the opinion of the most\nreliable expert. Data points are hence explained through a partitioning of the\nvariables into expert supports. The partitions are dynamically adapted based on\nwhich experts are active. During the learning phase we adopt a smoothed version\nof this model that uses separate mixtures for each data dimension. In our\nexperiments we achieve accurate reconstructions of high-dimensional data points\nwith at most a dozen experts.\n", "versions": [{"version": "v1", "created": "Thu, 16 Feb 2017 01:07:17 GMT"}], "update_date": "2017-02-17", "authors_parsed": [["Goessling", "Marc", ""], ["Amit", "Yali", ""]]}, {"id": "1702.04837", "submitter": "Shusen Wang", "authors": "Shusen Wang and Alex Gittens and Michael W. Mahoney", "title": "Sketched Ridge Regression: Optimization Perspective, Statistical\n  Perspective, and Model Averaging", "comments": "To appear in Journal of Machine Learning Research, 2018. A short\n  version has appeared in International Conference on Machine Learning (ICML),\n  2017", "journal-ref": "Journal of Machine Learning Research, 19, pp1-50, 2018", "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the statistical and optimization impacts of the classical sketch\nand Hessian sketch used to approximately solve the Matrix Ridge Regression\n(MRR) problem. Prior research has quantified the effects of classical sketch on\nthe strictly simpler least squares regression (LSR) problem. We establish that\nclassical sketch has a similar effect upon the optimization properties of MRR\nas it does on those of LSR: namely, it recovers nearly optimal solutions. By\ncontrast, Hessian sketch does not have this guarantee, instead, the\napproximation error is governed by a subtle interplay between the \"mass\" in the\nresponses and the optimal objective value.\n  For both types of approximation, the regularization in the sketched MRR\nproblem results in significantly different statistical properties from those of\nthe sketched LSR problem. In particular, there is a bias-variance trade-off in\nsketched MRR that is not present in sketched LSR. We provide upper and lower\nbounds on the bias and variance of sketched MRR, these bounds show that\nclassical sketch significantly increases the variance, while Hessian sketch\nsignificantly increases the bias. Empirically, sketched MRR solutions can have\nrisks that are higher by an order-of-magnitude than those of the optimal MRR\nsolutions.\n  We establish theoretically and empirically that model averaging greatly\ndecreases the gap between the risks of the true and sketched solutions to the\nMRR problem. Thus, in parallel or distributed settings, sketching combined with\nmodel averaging is a powerful technique that quickly obtains near-optimal\nsolutions to the MRR problem while greatly mitigating the increased statistical\nrisk incurred by sketching.\n", "versions": [{"version": "v1", "created": "Thu, 16 Feb 2017 02:01:26 GMT"}, {"version": "v2", "created": "Sat, 25 Feb 2017 02:59:41 GMT"}, {"version": "v3", "created": "Sat, 10 Jun 2017 17:52:18 GMT"}, {"version": "v4", "created": "Sat, 5 May 2018 20:58:25 GMT"}], "update_date": "2018-05-08", "authors_parsed": [["Wang", "Shusen", ""], ["Gittens", "Alex", ""], ["Mahoney", "Michael W.", ""]]}, {"id": "1702.04877", "submitter": "Frank Nielsen", "authors": "Frank Nielsen and Richard Nock", "title": "Generalizing Jensen and Bregman divergences with comparative convexity\n  and the statistical Bhattacharyya distances with comparable means", "comments": "24 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Comparative convexity is a generalization of convexity relying on abstract\nnotions of means. We define the Jensen divergence and the Jensen diversity from\nthe viewpoint of comparative convexity, and show how to obtain the generalized\nBregman divergences as limit cases of skewed Jensen divergences. In particular,\nwe report explicit formula of these generalized Bregman divergences when\nconsidering quasi-arithmetic means. Finally, we introduce a generalization of\nthe Bhattacharyya statistical distances based on comparative means using\nrelative convexity.\n", "versions": [{"version": "v1", "created": "Thu, 16 Feb 2017 07:21:05 GMT"}, {"version": "v2", "created": "Wed, 3 May 2017 18:58:00 GMT"}], "update_date": "2017-05-05", "authors_parsed": [["Nielsen", "Frank", ""], ["Nock", "Richard", ""]]}, {"id": "1702.04956", "submitter": "Aaron Gerow", "authors": "Aaron Gerow, Mingyang Zhou, Stan Matwin, Feng Shi", "title": "Reflexive Regular Equivalence for Bipartite Data", "comments": "A condensed version of this paper will appear in Proceedings of the\n  30th Canadian Conference on Artificial Intelligence, Edmonton, Alberta,\n  Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bipartite data is common in data engineering and brings unique challenges,\nparticularly when it comes to clustering tasks that impose on strong structural\nassumptions. This work presents an unsupervised method for assessing similarity\nin bipartite data. Similar to some co-clustering methods, the method is based\non regular equivalence in graphs. The algorithm uses spectral properties of a\nbipartite adjacency matrix to estimate similarity in both dimensions. The\nmethod is reflexive in that similarity in one dimension is used to inform\nsimilarity in the other. Reflexive regular equivalence can also use the\nstructure of transitivities -- in a network sense -- the contribution of which\nis controlled by the algorithm's only free-parameter, $\\alpha$. The method is\ncompletely unsupervised and can be used to validate assumptions of\nco-similarity, which are required but often untested, in co-clustering\nanalyses. Three variants of the method with different normalizations are tested\non synthetic data. The method is found to be robust to noise and well-suited to\nasymmetric co-similar structure, making it particularly informative for cluster\nanalysis and recommendation in bipartite data of unknown structure. In\nexperiments, the convergence and speed of the algorithm are found to be stable\nfor different levels of noise. Real-world data from a network of malaria genes\nare analyzed, where the similarity produced by the reflexive method is shown to\nout-perform other measures' ability to correctly classify genes.\n", "versions": [{"version": "v1", "created": "Thu, 16 Feb 2017 13:29:30 GMT"}], "update_date": "2017-02-17", "authors_parsed": [["Gerow", "Aaron", ""], ["Zhou", "Mingyang", ""], ["Matwin", "Stan", ""], ["Shi", "Feng", ""]]}, {"id": "1702.05043", "submitter": "Corentin Tallec", "authors": "Corentin Tallec and Yann Ollivier", "title": "Unbiased Online Recurrent Optimization", "comments": "11 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The novel Unbiased Online Recurrent Optimization (UORO) algorithm allows for\nonline learning of general recurrent computational graphs such as recurrent\nnetwork models. It works in a streaming fashion and avoids backtracking through\npast activations and inputs. UORO is computationally as costly as Truncated\nBackpropagation Through Time (truncated BPTT), a widespread algorithm for\nonline learning of recurrent networks. UORO is a modification of NoBackTrack\nthat bypasses the need for model sparsity and makes implementation easy in\ncurrent deep learning frameworks, even for complex models.\n  Like NoBackTrack, UORO provides unbiased gradient estimates; unbiasedness is\nthe core hypothesis in stochastic gradient descent theory, without which\nconvergence to a local optimum is not guaranteed. On the contrary, truncated\nBPTT does not provide this property, leading to possible divergence.\n  On synthetic tasks where truncated BPTT is shown to diverge, UORO converges.\nFor instance, when a parameter has a positive short-term but negative long-term\ninfluence, truncated BPTT diverges unless the truncation span is very\nsignificantly longer than the intrinsic temporal range of the interactions,\nwhile UORO performs well thanks to the unbiasedness of its gradients.\n", "versions": [{"version": "v1", "created": "Thu, 16 Feb 2017 16:38:08 GMT"}, {"version": "v2", "created": "Mon, 27 Mar 2017 15:29:33 GMT"}, {"version": "v3", "created": "Tue, 23 May 2017 11:42:03 GMT"}], "update_date": "2017-05-24", "authors_parsed": [["Tallec", "Corentin", ""], ["Ollivier", "Yann", ""]]}, {"id": "1702.05068", "submitter": "Adam Santoro", "authors": "David Raposo, Adam Santoro, David Barrett, Razvan Pascanu, Timothy\n  Lillicrap, Peter Battaglia", "title": "Discovering objects and their relations from entangled scene\n  representations", "comments": "ICLR Workshop 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Our world can be succinctly and compactly described as structured scenes of\nobjects and relations. A typical room, for example, contains salient objects\nsuch as tables, chairs and books, and these objects typically relate to each\nother by their underlying causes and semantics. This gives rise to correlated\nfeatures, such as position, function and shape. Humans exploit knowledge of\nobjects and their relations for learning a wide spectrum of tasks, and more\ngenerally when learning the structure underlying observed data. In this work,\nwe introduce relation networks (RNs) - a general purpose neural network\narchitecture for object-relation reasoning. We show that RNs are capable of\nlearning object relations from scene description data. Furthermore, we show\nthat RNs can act as a bottleneck that induces the factorization of objects from\nentangled scene description inputs, and from distributed deep representations\nof scene images provided by a variational autoencoder. The model can also be\nused in conjunction with differentiable memory mechanisms for implicit relation\ndiscovery in one-shot learning tasks. Our results suggest that relation\nnetworks are a potentially powerful architecture for solving a variety of\nproblems that require object relation reasoning.\n", "versions": [{"version": "v1", "created": "Thu, 16 Feb 2017 18:08:27 GMT"}], "update_date": "2017-02-17", "authors_parsed": [["Raposo", "David", ""], ["Santoro", "Adam", ""], ["Barrett", "David", ""], ["Pascanu", "Razvan", ""], ["Lillicrap", "Timothy", ""], ["Battaglia", "Peter", ""]]}, {"id": "1702.05137", "submitter": "Jie Yang", "authors": "Jie Yang, Sergey Shebalov, Diego Klabjan", "title": "Semi-supervised Learning for Discrete Choice Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a semi-supervised discrete choice model to calibrate discrete\nchoice models when relatively few requests have both choice sets and stated\npreferences but the majority only have the choice sets. Two classic\nsemi-supervised learning algorithms, the expectation maximization algorithm and\nthe cluster-and-label algorithm, have been adapted to our choice modeling\nproblem setting. We also develop two new algorithms based on the\ncluster-and-label algorithm. The new algorithms use the Bayesian Information\nCriterion to evaluate a clustering setting to automatically adjust the number\nof clusters. Two computational studies including a hotel booking case and a\nlarge-scale airline itinerary shopping case are presented to evaluate the\nprediction accuracy and computational effort of the proposed algorithms.\nAlgorithmic recommendations are rendered under various scenarios.\n", "versions": [{"version": "v1", "created": "Thu, 16 Feb 2017 19:59:40 GMT"}], "update_date": "2017-02-20", "authors_parsed": [["Yang", "Jie", ""], ["Shebalov", "Sergey", ""], ["Klabjan", "Diego", ""]]}, {"id": "1702.05148", "submitter": "Elizabeth Hou", "authors": "Elizabeth Hou, Kumar Sricharan, and Alfred O. Hero", "title": "Latent Laplacian Maximum Entropy Discrimination for Detection of\n  High-Utility Anomalies", "comments": null, "journal-ref": "IEEE Transactions on Information Forensics and Security ( Volume:\n  13, Issue: 6, June 2018 )", "doi": null, "report-no": null, "categories": "stat.ML cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data-driven anomaly detection methods suffer from the drawback of detecting\nall instances that are statistically rare, irrespective of whether the detected\ninstances have real-world significance or not. In this paper, we are interested\nin the problem of specifically detecting anomalous instances that are known to\nhave high real-world utility, while ignoring the low-utility statistically\nanomalous instances. To this end, we propose a novel method called Latent\nLaplacian Maximum Entropy Discrimination (LatLapMED) as a potential solution.\nThis method uses the EM algorithm to simultaneously incorporate the Geometric\nEntropy Minimization principle for identifying statistical anomalies, and the\nMaximum Entropy Discrimination principle to incorporate utility labels, in\norder to detect high-utility anomalies. We apply our method in both simulated\nand real datasets to demonstrate that it has superior performance over existing\nalternatives that independently pre-process with unsupervised anomaly detection\nalgorithms before classifying.\n", "versions": [{"version": "v1", "created": "Thu, 16 Feb 2017 20:37:47 GMT"}, {"version": "v2", "created": "Thu, 10 Aug 2017 03:56:11 GMT"}, {"version": "v3", "created": "Thu, 14 Dec 2017 04:24:46 GMT"}], "update_date": "2018-03-08", "authors_parsed": [["Hou", "Elizabeth", ""], ["Sricharan", "Kumar", ""], ["Hero", "Alfred O.", ""]]}, {"id": "1702.05181", "submitter": "Akshay Soni", "authors": "Akshay Soni and Yashar Mehdad", "title": "RIPML: A Restricted Isometry Property based Approach to Multilabel\n  Learning", "comments": "6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The multilabel learning problem with large number of labels, features, and\ndata-points has generated a tremendous interest recently. A recurring theme of\nthese problems is that only a few labels are active in any given datapoint as\ncompared to the total number of labels. However, only a small number of\nexisting work take direct advantage of this inherent extreme sparsity in the\nlabel space. By the virtue of Restricted Isometry Property (RIP), satisfied by\nmany random ensembles, we propose a novel procedure for multilabel learning\nknown as RIPML. During the training phase, in RIPML, labels are projected onto\na random low-dimensional subspace followed by solving a least-square problem in\nthis subspace. Inference is done by a k-nearest neighbor (kNN) based approach.\nWe demonstrate the effectiveness of RIPML by conducting extensive simulations\nand comparing results with the state-of-the-art linear dimensionality reduction\nbased approaches.\n", "versions": [{"version": "v1", "created": "Thu, 16 Feb 2017 23:08:50 GMT"}], "update_date": "2017-02-20", "authors_parsed": [["Soni", "Akshay", ""], ["Mehdad", "Yashar", ""]]}, {"id": "1702.05184", "submitter": "Nikos Kargas", "authors": "Nikos Kargas, Nicholas D. Sidiropoulos", "title": "Completing a joint PMF from projections: a low-rank coupled tensor\n  factorization approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There has recently been considerable interest in completing a low-rank matrix\nor tensor given only a small fraction (or few linear combinations) of its\nentries. Related approaches have found considerable success in the area of\nrecommender systems, under machine learning. From a statistical estimation\npoint of view, the gold standard is to have access to the joint probability\ndistribution of all pertinent random variables, from which any desired optimal\nestimator can be readily derived. In practice high-dimensional joint\ndistributions are very hard to estimate, and only estimates of low-dimensional\nprojections may be available. We show that it is possible to identify\nhigher-order joint PMFs from lower-order marginalized PMFs using coupled\nlow-rank tensor factorization. Our approach features guaranteed identifiability\nwhen the full joint PMF is of low-enough rank, and effective approximation\notherwise. We provide an algorithmic approach to compute the sought factors,\nand illustrate the merits of our approach using rating prediction as an\nexample.\n", "versions": [{"version": "v1", "created": "Thu, 16 Feb 2017 23:28:35 GMT"}], "update_date": "2017-02-20", "authors_parsed": [["Kargas", "Nikos", ""], ["Sidiropoulos", "Nicholas D.", ""]]}, {"id": "1702.05186", "submitter": "Max Simchowitz", "authors": "Max Simchowitz and Kevin Jamieson and Benjamin Recht", "title": "The Simulator: Understanding Adaptive Sampling in the\n  Moderate-Confidence Regime", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel technique for analyzing adaptive sampling called the {\\em\nSimulator}. Our approach differs from the existing methods by considering not\nhow much information could be gathered by any fixed sampling strategy, but how\ndifficult it is to distinguish a good sampling strategy from a bad one given\nthe limited amount of data collected up to any given time. This change of\nperspective allows us to match the strength of both Fano and change-of-measure\ntechniques, without succumbing to the limitations of either method. For\nconcreteness, we apply our techniques to a structured multi-arm bandit problem\nin the fixed-confidence pure exploration setting, where we show that the\nconstraints on the means imply a substantial gap between the\nmoderate-confidence sample complexity, and the asymptotic sample complexity as\n$\\delta \\to 0$ found in the literature. We also prove the first instance-based\nlower bounds for the top-k problem which incorporate the appropriate\nlog-factors. Moreover, our lower bounds zero-in on the number of times each\n\\emph{individual} arm needs to be pulled, uncovering new phenomena which are\ndrowned out in the aggregate sample complexity. Our new analysis inspires a\nsimple and near-optimal algorithm for the best-arm and top-k identification,\nthe first {\\em practical} algorithm of its kind for the latter problem which\nremoves extraneous log factors, and outperforms the state-of-the-art in\nexperiments.\n", "versions": [{"version": "v1", "created": "Thu, 16 Feb 2017 23:42:02 GMT"}], "update_date": "2017-02-20", "authors_parsed": [["Simchowitz", "Max", ""], ["Jamieson", "Kevin", ""], ["Recht", "Benjamin", ""]]}, {"id": "1702.05192", "submitter": "Mohammad-Parsa Hosseini", "authors": "Mohammad-Parsa Hosseini, Hamid Soltanian-Zadeh, Kost Elisevich, and\n  Dario Pompili", "title": "Cloud-based Deep Learning of Big EEG Data for Epileptic Seizure\n  Prediction", "comments": "IEEE Global Conference on Signal and Information Processing\n  (GlobalSIP), Greater Washington, DC, Dec 7-9, 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Developing a Brain-Computer Interface~(BCI) for seizure prediction can help\nepileptic patients have a better quality of life. However, there are many\ndifficulties and challenges in developing such a system as a real-life support\nfor patients. Because of the nonstationary nature of EEG signals, normal and\nseizure patterns vary across different patients. Thus, finding a group of\nmanually extracted features for the prediction task is not practical. Moreover,\nwhen using implanted electrodes for brain recording massive amounts of data are\nproduced. This big data calls for the need for safe storage and high\ncomputational resources for real-time processing. To address these challenges,\na cloud-based BCI system for the analysis of this big EEG data is presented.\nFirst, a dimensionality-reduction technique is developed to increase\nclassification accuracy as well as to decrease the communication bandwidth and\ncomputation time. Second, following a deep-learning approach, a stacked\nautoencoder is trained in two steps for unsupervised feature extraction and\nclassification. Third, a cloud-computing solution is proposed for real-time\nanalysis of big EEG data. The results on a benchmark clinical dataset\nillustrate the superiority of the proposed patient-specific BCI as an\nalternative method and its expected usefulness in real-life support of epilepsy\npatients.\n", "versions": [{"version": "v1", "created": "Fri, 17 Feb 2017 00:00:38 GMT"}], "update_date": "2017-02-20", "authors_parsed": [["Hosseini", "Mohammad-Parsa", ""], ["Soltanian-Zadeh", "Hamid", ""], ["Elisevich", "Kost", ""], ["Pompili", "Dario", ""]]}, {"id": "1702.05327", "submitter": "Sohail Bahmani", "authors": "Sohail Bahmani and Justin Romberg", "title": "Solving Equations of Random Convex Functions via Anchored Regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT math.OC math.PR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the question of estimating a solution to a system of equations\nthat involve convex nonlinearities, a problem that is common in machine\nlearning and signal processing. Because of these nonlinearities, conventional\nestimators based on empirical risk minimization generally involve solving a\nnon-convex optimization program. We propose anchored regression, a new approach\nbased on convex programming that amounts to maximizing a linear functional\n(perhaps augmented by a regularizer) over a convex set. The proposed convex\nprogram is formulated in the natural space of the problem, and avoids the\nintroduction of auxiliary variables, making it computationally favorable.\nWorking in the native space also provides great flexibility as structural\npriors (e.g., sparsity) can be seamlessly incorporated.\n  For our analysis, we model the equations as being drawn from a fixed set\naccording to a probability law. Our main results provide guarantees on the\naccuracy of the estimator in terms of the number of equations we are solving,\nthe amount of noise present, a measure of statistical complexity of the random\nequations, and the geometry of the regularizer at the true solution. We also\nprovide recipes for constructing the anchor vector (that determines the linear\nfunctional to maximize) directly from the observed data.\n", "versions": [{"version": "v1", "created": "Fri, 17 Feb 2017 13:05:04 GMT"}, {"version": "v2", "created": "Sat, 30 Sep 2017 00:12:02 GMT"}, {"version": "v3", "created": "Mon, 13 Aug 2018 15:46:23 GMT"}], "update_date": "2018-08-14", "authors_parsed": [["Bahmani", "Sohail", ""], ["Romberg", "Justin", ""]]}, {"id": "1702.05386", "submitter": "Zachary Lipton", "authors": "Nathan Ng, Rodney A Gabriel, Julian McAuley, Charles Elkan, Zachary C\n  Lipton", "title": "Predicting Surgery Duration with Neural Heteroscedastic Regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Scheduling surgeries is a challenging task due to the fundamental uncertainty\nof the clinical environment, as well as the risks and costs associated with\nunder- and over-booking. We investigate neural regression algorithms to\nestimate the parameters of surgery case durations, focusing on the issue of\nheteroscedasticity. We seek to simultaneously estimate the duration of each\nsurgery, as well as a surgery-specific notion of our uncertainty about its\nduration. Estimating this uncertainty can lead to more nuanced and effective\nscheduling strategies, as we are able to schedule surgeries more efficiently\nwhile allowing an informed and case-specific margin of error. Using surgery\nrecords %from the UC San Diego Health System, from a large United States health\nsystem we demonstrate potential improvements on the order of 20% (in terms of\nminutes overbooked) compared to current scheduling techniques. Moreover, we\ndemonstrate that surgery durations are indeed heteroscedastic. We show that\nmodels that estimate case-specific uncertainty better fit the data (log\nlikelihood). Additionally, we show that the heteroscedastic predictions can\nmore optimally trade off between over and under-booking minutes, especially\nwhen idle minutes and scheduling collisions confer disparate costs.\n", "versions": [{"version": "v1", "created": "Fri, 17 Feb 2017 15:28:28 GMT"}, {"version": "v2", "created": "Thu, 13 Apr 2017 22:26:47 GMT"}, {"version": "v3", "created": "Thu, 13 Jul 2017 03:48:14 GMT"}], "update_date": "2017-07-14", "authors_parsed": [["Ng", "Nathan", ""], ["Gabriel", "Rodney A", ""], ["McAuley", "Julian", ""], ["Elkan", "Charles", ""], ["Lipton", "Zachary C", ""]]}, {"id": "1702.05419", "submitter": "Romain Couillet", "authors": "Cosme Louart, Zhenyu Liao, Romain Couillet", "title": "A Random Matrix Approach to Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article studies the Gram random matrix model $G=\\frac1T\\Sigma^{\\rm\nT}\\Sigma$, $\\Sigma=\\sigma(WX)$, classically found in the analysis of random\nfeature maps and random neural networks, where $X=[x_1,\\ldots,x_T]\\in{\\mathbb\nR}^{p\\times T}$ is a (data) matrix of bounded norm, $W\\in{\\mathbb R}^{n\\times\np}$ is a matrix of independent zero-mean unit variance entries, and\n$\\sigma:{\\mathbb R}\\to{\\mathbb R}$ is a Lipschitz continuous (activation)\nfunction --- $\\sigma(WX)$ being understood entry-wise. By means of a key\nconcentration of measure lemma arising from non-asymptotic random matrix\narguments, we prove that, as $n,p,T$ grow large at the same rate, the resolvent\n$Q=(G+\\gamma I_T)^{-1}$, for $\\gamma>0$, has a similar behavior as that met in\nsample covariance matrix models, involving notably the moment\n$\\Phi=\\frac{T}n{\\mathbb E}[G]$, which provides in passing a deterministic\nequivalent for the empirical spectral measure of $G$. Application-wise, this\nresult enables the estimation of the asymptotic performance of single-layer\nrandom neural networks. This in turn provides practical insights into the\nunderlying mechanisms into play in random neural networks, entailing several\nunexpected consequences, as well as a fast practical means to tune the network\nhyperparameters.\n", "versions": [{"version": "v1", "created": "Fri, 17 Feb 2017 16:16:01 GMT"}, {"version": "v2", "created": "Thu, 29 Jun 2017 08:27:26 GMT"}], "update_date": "2017-06-30", "authors_parsed": [["Louart", "Cosme", ""], ["Liao", "Zhenyu", ""], ["Couillet", "Romain", ""]]}, {"id": "1702.05471", "submitter": "Soheil Feizi", "authors": "Soheil Feizi and David Tse", "title": "Maximally Correlated Principal Component Analysis", "comments": "35 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the era of big data, reducing data dimensionality is critical in many\nareas of science. Widely used Principal Component Analysis (PCA) addresses this\nproblem by computing a low dimensional data embedding that maximally explain\nvariance of the data. However, PCA has two major weaknesses. Firstly, it only\nconsiders linear correlations among variables (features), and secondly it is\nnot suitable for categorical data. We resolve these issues by proposing\nMaximally Correlated Principal Component Analysis (MCPCA). MCPCA computes\ntransformations of variables whose covariance matrix has the largest Ky Fan\nnorm. Variable transformations are unknown, can be nonlinear and are computed\nin an optimization. MCPCA can also be viewed as a multivariate extension of\nMaximal Correlation. For jointly Gaussian variables we show that the covariance\nmatrix corresponding to the identity (or the negative of the identity)\ntransformations majorizes covariance matrices of non-identity functions. Using\nthis result we characterize global MCPCA optimizers for nonlinear functions of\njointly Gaussian variables for every rank constraint. For categorical variables\nwe characterize global MCPCA optimizers for the rank one constraint based on\nthe leading eigenvector of a matrix computed using pairwise joint\ndistributions. For a general rank constraint we propose a block coordinate\ndescend algorithm and show its convergence to stationary points of the MCPCA\noptimization. We compare MCPCA with PCA and other state-of-the-art\ndimensionality reduction methods including Isomap, LLE, multilayer autoencoders\n(neural networks), kernel PCA, probabilistic PCA and diffusion maps on several\nsynthetic and real datasets. We show that MCPCA consistently provides improved\nperformance compared to other methods.\n", "versions": [{"version": "v1", "created": "Fri, 17 Feb 2017 18:43:58 GMT"}, {"version": "v2", "created": "Tue, 21 Feb 2017 20:38:13 GMT"}], "update_date": "2017-02-24", "authors_parsed": [["Feizi", "Soheil", ""], ["Tse", "David", ""]]}, {"id": "1702.05536", "submitter": "Zifan Li", "authors": "Zifan Li, Ambuj Tewari", "title": "Beyond the Hazard Rate: More Perturbation Algorithms for Adversarial\n  Multi-armed Bandits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.GT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work on follow the perturbed leader (FTPL) algorithms for the\nadversarial multi-armed bandit problem has highlighted the role of the hazard\nrate of the distribution generating the perturbations. Assuming that the hazard\nrate is bounded, it is possible to provide regret analyses for a variety of\nFTPL algorithms for the multi-armed bandit problem. This paper pushes the\ninquiry into regret bounds for FTPL algorithms beyond the bounded hazard rate\ncondition. There are good reasons to do so: natural distributions such as the\nuniform and Gaussian violate the condition. We give regret bounds for both\nbounded support and unbounded support distributions without assuming the hazard\nrate condition. We also disprove a conjecture that the Gaussian distribution\ncannot lead to a low-regret algorithm. In fact, it turns out that it leads to\nnear optimal regret, up to logarithmic factors. A key ingredient in our\napproach is the introduction of a new notion called the generalized hazard\nrate.\n", "versions": [{"version": "v1", "created": "Fri, 17 Feb 2017 22:39:37 GMT"}, {"version": "v2", "created": "Fri, 5 Jan 2018 19:31:42 GMT"}], "update_date": "2018-01-09", "authors_parsed": [["Li", "Zifan", ""], ["Tewari", "Ambuj", ""]]}, {"id": "1702.05538", "submitter": "Terrance DeVries", "authors": "Terrance DeVries, Graham W. Taylor", "title": "Dataset Augmentation in Feature Space", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dataset augmentation, the practice of applying a wide array of\ndomain-specific transformations to synthetically expand a training set, is a\nstandard tool in supervised learning. While effective in tasks such as visual\nrecognition, the set of transformations must be carefully designed,\nimplemented, and tested for every new domain, limiting its re-use and\ngenerality. In this paper, we adopt a simpler, domain-agnostic approach to\ndataset augmentation. We start with existing data points and apply simple\ntransformations such as adding noise, interpolating, or extrapolating between\nthem. Our main insight is to perform the transformation not in input space, but\nin a learned feature space. A re-kindling of interest in unsupervised\nrepresentation learning makes this technique timely and more effective. It is a\nsimple proposal, but to-date one that has not been tested empirically. Working\nin the space of context vectors generated by sequence-to-sequence models, we\ndemonstrate a technique that is effective for both static and sequential data.\n", "versions": [{"version": "v1", "created": "Fri, 17 Feb 2017 23:13:15 GMT"}], "update_date": "2017-02-21", "authors_parsed": [["DeVries", "Terrance", ""], ["Taylor", "Graham W.", ""]]}, {"id": "1702.05548", "submitter": "Andrey Bernstein", "authors": "Andrey Bernstein", "title": "Bi-Level Online Control without Regret", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers a bi-level discrete-time control framework with\nreal-time constraints, consisting of several local controllers and a central\ncontroller. The objective is to bridge the gap between the online convex\noptimization and real-time control literature by proposing an online control\nalgorithm with small dynamic regret, which is a natural performance criterion\nin nonstationary environments related to real-time control problems. We\nillustrate how the proposed algorithm can be applied to real-time control of\npower setpoints in an electrical grid.\n", "versions": [{"version": "v1", "created": "Sat, 18 Feb 2017 00:39:57 GMT"}], "update_date": "2017-02-21", "authors_parsed": [["Bernstein", "Andrey", ""]]}, {"id": "1702.05563", "submitter": "Masashi Shimbo", "authors": "Katsuhiko Hayashi and Masashi Shimbo", "title": "On the Equivalence of Holographic and Complex Embeddings for Link\n  Prediction", "comments": "This is a slightly modified version of the paper of the same title\n  that appeared in ACL 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show the equivalence of two state-of-the-art link prediction/knowledge\ngraph completion methods: Nickel et al's holographic embedding and Trouillon et\nal.'s complex embedding. We first consider a spectral version of the\nholographic embedding, exploiting the frequency domain in the Fourier transform\nfor efficient computation. The analysis of the resulting method reveals that it\ncan be viewed as an instance of the complex embedding with certain constraints\ncast on the initial vectors upon training. Conversely, any complex embedding\ncan be converted to an equivalent holographic embedding.\n", "versions": [{"version": "v1", "created": "Sat, 18 Feb 2017 03:38:12 GMT"}, {"version": "v2", "created": "Sat, 11 Mar 2017 11:30:19 GMT"}, {"version": "v3", "created": "Fri, 22 Sep 2017 10:06:53 GMT"}], "update_date": "2017-09-25", "authors_parsed": [["Hayashi", "Katsuhiko", ""], ["Shimbo", "Masashi", ""]]}, {"id": "1702.05571", "submitter": "Yeshwanth Cherapanamjeri", "authors": "Yeshwanth Cherapanamjeri and Prateek Jain and Praneeth Netrapalli", "title": "Thresholding based Efficient Outlier Robust PCA", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of outlier robust PCA (OR-PCA) where the goal is to\nrecover principal directions despite the presence of outlier data points. That\nis, given a data matrix $M^*$, where $(1-\\alpha)$ fraction of the points are\nnoisy samples from a low-dimensional subspace while $\\alpha$ fraction of the\npoints can be arbitrary outliers, the goal is to recover the subspace\naccurately. Existing results for \\OR-PCA have serious drawbacks: while some\nresults are quite weak in the presence of noise, other results have runtime\nquadratic in dimension, rendering them impractical for large scale\napplications.\n  In this work, we provide a novel thresholding based iterative algorithm with\nper-iteration complexity at most linear in the data size. Moreover, the\nfraction of outliers, $\\alpha$, that our method can handle is tight up to\nconstants while providing nearly optimal computational complexity for a general\nnoise setting. For the special case where the inliers are obtained from a\nlow-dimensional subspace with additive Gaussian noise, we show that a\nmodification of our thresholding based method leads to significant improvement\nin recovery error (of the subspace) even in the presence of a large fraction of\noutliers.\n", "versions": [{"version": "v1", "created": "Sat, 18 Feb 2017 05:00:04 GMT"}], "update_date": "2017-02-21", "authors_parsed": [["Cherapanamjeri", "Yeshwanth", ""], ["Jain", "Prateek", ""], ["Netrapalli", "Praneeth", ""]]}, {"id": "1702.05575", "submitter": "Yuchen Zhang", "authors": "Yuchen Zhang, Percy Liang, Moses Charikar", "title": "A Hitting Time Analysis of Stochastic Gradient Langevin Dynamics", "comments": "Correct two mistakes in the proofs of Lemma 3 and Lemma 5", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the Stochastic Gradient Langevin Dynamics (SGLD) algorithm for\nnon-convex optimization. The algorithm performs stochastic gradient descent,\nwhere in each step it injects appropriately scaled Gaussian noise to the\nupdate. We analyze the algorithm's hitting time to an arbitrary subset of the\nparameter space. Two results follow from our general theory: First, we prove\nthat for empirical risk minimization, if the empirical risk is point-wise close\nto the (smooth) population risk, then the algorithm achieves an approximate\nlocal minimum of the population risk in polynomial time, escaping suboptimal\nlocal minima that only exist in the empirical risk. Second, we show that SGLD\nimproves on one of the best known learnability results for learning linear\nclassifiers under the zero-one loss.\n", "versions": [{"version": "v1", "created": "Sat, 18 Feb 2017 06:33:55 GMT"}, {"version": "v2", "created": "Tue, 6 Jun 2017 18:59:05 GMT"}, {"version": "v3", "created": "Mon, 9 Apr 2018 07:14:34 GMT"}], "update_date": "2018-04-10", "authors_parsed": [["Zhang", "Yuchen", ""], ["Liang", "Percy", ""], ["Charikar", "Moses", ""]]}, {"id": "1702.05581", "submitter": "Chicheng Zhang", "authors": "Songbai Yan and Chicheng Zhang", "title": "Revisiting Perceptron: Efficient and Label-Optimal Learning of\n  Halfspaces", "comments": "NIPS 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It has been a long-standing problem to efficiently learn a halfspace using as\nfew labels as possible in the presence of noise. In this work, we propose an\nefficient Perceptron-based algorithm for actively learning homogeneous\nhalfspaces under the uniform distribution over the unit sphere. Under the\nbounded noise condition~\\cite{MN06}, where each label is flipped with\nprobability at most $\\eta < \\frac 1 2$, our algorithm achieves a near-optimal\nlabel complexity of\n$\\tilde{O}\\left(\\frac{d}{(1-2\\eta)^2}\\ln\\frac{1}{\\epsilon}\\right)$ in time\n$\\tilde{O}\\left(\\frac{d^2}{\\epsilon(1-2\\eta)^3}\\right)$. Under the adversarial\nnoise condition~\\cite{ABL14, KLS09, KKMS08}, where at most a $\\tilde\n\\Omega(\\epsilon)$ fraction of labels can be flipped, our algorithm achieves a\nnear-optimal label complexity of $\\tilde{O}\\left(d\\ln\\frac{1}{\\epsilon}\\right)$\nin time $\\tilde{O}\\left(\\frac{d^2}{\\epsilon}\\right)$. Furthermore, we show that\nour active learning algorithm can be converted to an efficient passive learning\nalgorithm that has near-optimal sample complexities with respect to $\\epsilon$\nand $d$.\n", "versions": [{"version": "v1", "created": "Sat, 18 Feb 2017 07:26:08 GMT"}, {"version": "v2", "created": "Mon, 6 Nov 2017 15:01:39 GMT"}], "update_date": "2017-11-07", "authors_parsed": [["Yan", "Songbai", ""], ["Zhang", "Chicheng", ""]]}, {"id": "1702.05594", "submitter": "Hiroyuki Sato", "authors": "Hiroyuki Sato, Hiroyuki Kasai, Bamdev Mishra", "title": "Riemannian stochastic variance reduced gradient algorithm with\n  retraction and vector transport", "comments": "Published in SIAM Journal on Optimization. Extended and revised\n  version of arXiv:1605.07367", "journal-ref": "SIAM Journal on Optimization 29 (2019) 1444-1472", "doi": "10.1137/17M1116787", "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, stochastic variance reduction algorithms have attracted\nconsiderable attention for minimizing the average of a large but finite number\nof loss functions. This paper proposes a novel Riemannian extension of the\nEuclidean stochastic variance reduced gradient (R-SVRG) algorithm to a manifold\nsearch space. The key challenges of averaging, adding, and subtracting multiple\ngradients are addressed with retraction and vector transport. For the proposed\nalgorithm, we present a global convergence analysis with a decaying step size\nas well as a local convergence rate analysis with a fixed step size under some\nnatural assumptions. In addition, the proposed algorithm is applied to the\ncomputation problem of the Riemannian centroid on the symmetric positive\ndefinite (SPD) manifold as well as the principal component analysis and\nlow-rank matrix completion problems on the Grassmann manifold. The results show\nthat the proposed algorithm outperforms the standard Riemannian stochastic\ngradient descent algorithm in each case.\n", "versions": [{"version": "v1", "created": "Sat, 18 Feb 2017 10:39:23 GMT"}, {"version": "v2", "created": "Mon, 10 Apr 2017 17:27:05 GMT"}, {"version": "v3", "created": "Fri, 31 May 2019 10:03:25 GMT"}], "update_date": "2019-06-03", "authors_parsed": [["Sato", "Hiroyuki", ""], ["Kasai", "Hiroyuki", ""], ["Mishra", "Bamdev", ""]]}, {"id": "1702.05639", "submitter": "Dianhui Wang", "authors": "Dianhui Wang, Ming Li", "title": "Deep Stochastic Configuration Networks with Universal Approximation\n  Property", "comments": "To appear in the Proceedings of IJCNN 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper develops a randomized approach for incrementally building deep\nneural networks, where a supervisory mechanism is proposed to constrain the\nrandom assignment of the weights and biases, and all the hidden layers have\ndirect links to the output layer. A fundamental result on the universal\napproximation property is established for such a class of randomized leaner\nmodels, namely deep stochastic configuration networks (DeepSCNs). A learning\nalgorithm is presented to implement DeepSCNs with either specific architecture\nor self-organization. The read-out weights attached with all direct links from\neach hidden layer to the output layer are evaluated by the least squares\nmethod. Given a set of training examples, DeepSCNs can speedily produce a\nlearning representation, that is, a collection of random basis functions with\nthe cascaded inputs together with the read-out weights. An empirical study on a\nfunction approximation is carried out to demonstrate some properties of the\nproposed deep learner model.\n", "versions": [{"version": "v1", "created": "Sat, 18 Feb 2017 18:18:32 GMT"}, {"version": "v2", "created": "Sat, 20 May 2017 02:38:56 GMT"}, {"version": "v3", "created": "Sat, 10 Mar 2018 10:42:47 GMT"}, {"version": "v4", "created": "Fri, 16 Mar 2018 08:08:57 GMT"}], "update_date": "2018-03-19", "authors_parsed": [["Wang", "Dianhui", ""], ["Li", "Ming", ""]]}, {"id": "1702.05659", "submitter": "Wojciech Czarnecki", "authors": "Katarzyna Janocha, Wojciech Marian Czarnecki", "title": "On Loss Functions for Deep Neural Networks in Classification", "comments": "Presented at Theoretical Foundations of Machine Learning 2017 (TFML\n  2017)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks are currently among the most commonly used classifiers.\nDespite easily achieving very good performance, one of the best selling points\nof these models is their modular design - one can conveniently adapt their\narchitecture to specific needs, change connectivity patterns, attach\nspecialised layers, experiment with a large amount of activation functions,\nnormalisation schemes and many others. While one can find impressively wide\nspread of various configurations of almost every aspect of the deep nets, one\nelement is, in authors' opinion, underrepresented - while solving\nclassification problems, vast majority of papers and applications simply use\nlog loss. In this paper we try to investigate how particular choices of loss\nfunctions affect deep models and their learning dynamics, as well as resulting\nclassifiers robustness to various effects. We perform experiments on classical\ndatasets, as well as provide some additional, theoretical insights into the\nproblem. In particular we show that L1 and L2 losses are, quite surprisingly,\njustified classification objectives for deep nets, by providing probabilistic\ninterpretation in terms of expected misclassification. We also introduce two\nlosses which are not typically used as deep nets objectives and show that they\nare viable alternatives to the existing ones.\n", "versions": [{"version": "v1", "created": "Sat, 18 Feb 2017 21:39:36 GMT"}], "update_date": "2017-02-21", "authors_parsed": [["Janocha", "Katarzyna", ""], ["Czarnecki", "Wojciech Marian", ""]]}, {"id": "1702.05677", "submitter": "Lunjia Hu", "authors": "Lunjia Hu, Ruihan Wu, Tianhong Li, Liwei Wang", "title": "Quadratic Upper Bound for Recursive Teaching Dimension of Finite VC\n  Classes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we study the quantitative relation between the recursive\nteaching dimension (RTD) and the VC dimension (VCD) of concept classes of\nfinite sizes. The RTD of a concept class $\\mathcal C \\subseteq \\{0, 1\\}^n$,\nintroduced by Zilles et al. (2011), is a combinatorial complexity measure\ncharacterized by the worst-case number of examples necessary to identify a\nconcept in $\\mathcal C$ according to the recursive teaching model.\n  For any finite concept class $\\mathcal C \\subseteq \\{0,1\\}^n$ with\n$\\mathrm{VCD}(\\mathcal C)=d$, Simon & Zilles (2015) posed an open problem\n$\\mathrm{RTD}(\\mathcal C) = O(d)$, i.e., is RTD linearly upper bounded by VCD?\nPreviously, the best known result is an exponential upper bound\n$\\mathrm{RTD}(\\mathcal C) = O(d \\cdot 2^d)$, due to Chen et al. (2016). In this\npaper, we show a quadratic upper bound: $\\mathrm{RTD}(\\mathcal C) = O(d^2)$,\nmuch closer to an answer to the open problem. We also discuss the challenges in\nfully solving the problem.\n", "versions": [{"version": "v1", "created": "Sat, 18 Feb 2017 23:46:10 GMT"}], "update_date": "2017-02-21", "authors_parsed": [["Hu", "Lunjia", ""], ["Wu", "Ruihan", ""], ["Li", "Tianhong", ""], ["Wang", "Liwei", ""]]}, {"id": "1702.05678", "submitter": "Cl\\'ement Canonne", "authors": "Clement Canonne and Tom Gur", "title": "An Adaptivity Hierarchy Theorem for Property Testing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adaptivity is known to play a crucial role in property testing. In\nparticular, there exist properties for which there is an exponential gap\nbetween the power of \\emph{adaptive} testing algorithms, wherein each query may\nbe determined by the answers received to prior queries, and their\n\\emph{non-adaptive} counterparts, in which all queries are independent of\nanswers obtained from previous queries.\n  In this work, we investigate the role of adaptivity in property testing at a\nfiner level. We first quantify the degree of adaptivity of a testing algorithm\nby considering the number of \"rounds of adaptivity\" it uses. More accurately,\nwe say that a tester is $k$-(round) adaptive if it makes queries in $k+1$\nrounds, where the queries in the $i$'th round may depend on the answers\nobtained in the previous $i-1$ rounds. Then, we ask the following question:\n  Does the power of testing algorithms smoothly grow with the number of rounds\nof adaptivity?\n  We provide a positive answer to the foregoing question by proving an\nadaptivity hierarchy theorem for property testing. Specifically, our main\nresult shows that for every $n\\in \\mathbb{N}$ and $0 \\le k \\le n^{0.99}$ there\nexists a property $\\mathcal{P}_{n,k}$ of functions for which (1) there exists a\n$k$-adaptive tester for $\\mathcal{P}_{n,k}$ with query complexity\n$\\tilde{O}(k)$, yet (2) any $(k-1)$-adaptive tester for $\\mathcal{P}_{n,k}$\nmust make $\\Omega(n)$ queries. In addition, we show that such a qualitative\nadaptivity hierarchy can be witnessed for testing natural properties of graphs.\n", "versions": [{"version": "v1", "created": "Sun, 19 Feb 2017 00:03:09 GMT"}], "update_date": "2017-02-21", "authors_parsed": [["Canonne", "Clement", ""], ["Gur", "Tom", ""]]}, {"id": "1702.05695", "submitter": "Emilio Ferrara", "authors": "Anna Sapienza, Alessandro Bessi, Emilio Ferrara", "title": "Non-negative Tensor Factorization for Human Behavioral Pattern Mining in\n  Online Games", "comments": "9 pages, 6 figures, submitted to KDD'17", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.HC cs.SI physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multiplayer online battle arena has become a popular game genre. It also\nreceived increasing attention from our research community because they provide\na wealth of information about human interactions and behaviors. A major problem\nis extracting meaningful patterns of activity from this type of data, in a way\nthat is also easy to interpret. Here, we propose to exploit tensor\ndecomposition techniques, and in particular Non-negative Tensor Factorization,\nto discover hidden correlated behavioral patterns of play in a popular game:\nLeague of Legends. We first collect the entire gaming history of a group of\nabout one thousand players, totaling roughly $100K$ matches. By applying our\nmethodological framework, we then separate players into groups that exhibit\nsimilar features and playing strategies, as well as similar temporal\ntrajectories, i.e., behavioral progressions over the course of their gaming\nhistory: this will allow us to investigate how players learn and improve their\nskills.\n", "versions": [{"version": "v1", "created": "Sun, 19 Feb 2017 03:19:50 GMT"}], "update_date": "2017-02-21", "authors_parsed": [["Sapienza", "Anna", ""], ["Bessi", "Alessandro", ""], ["Ferrara", "Emilio", ""]]}, {"id": "1702.05698", "submitter": "Wei Xiao", "authors": "Wei Xiao, Xiaolin Huang, Jorge Silva, Saba Emrani and Arin Chaudhuri", "title": "Online Robust Principal Component Analysis with Change Point Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.AP stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robust PCA methods are typically batch algorithms which requires loading all\nobservations into memory before processing. This makes them inefficient to\nprocess big data. In this paper, we develop an efficient online robust\nprincipal component methods, namely online moving window robust principal\ncomponent analysis (OMWRPCA). Unlike existing algorithms, OMWRPCA can\nsuccessfully track not only slowly changing subspace but also abruptly changed\nsubspace. By embedding hypothesis testing into the algorithm, OMWRPCA can\ndetect change points of the underlying subspaces. Extensive simulation studies\ndemonstrate the superior performance of OMWRPCA compared with other\nstate-of-art approaches. We also apply the algorithm for real-time background\nsubtraction of surveillance video.\n", "versions": [{"version": "v1", "created": "Sun, 19 Feb 2017 04:08:18 GMT"}, {"version": "v2", "created": "Mon, 20 Mar 2017 19:49:02 GMT"}], "update_date": "2017-03-22", "authors_parsed": [["Xiao", "Wei", ""], ["Huang", "Xiaolin", ""], ["Silva", "Jorge", ""], ["Emrani", "Saba", ""], ["Chaudhuri", "Arin", ""]]}, {"id": "1702.05796", "submitter": "Kaixiang Lin Kaixiang Lin", "authors": "Kaixiang Lin, Shu Wang and Jiayu Zhou", "title": "Collaborative Deep Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Besides independent learning, human learning process is highly improved by\nsummarizing what has been learned, communicating it with peers, and\nsubsequently fusing knowledge from different sources to assist the current\nlearning goal. This collaborative learning procedure ensures that the knowledge\nis shared, continuously refined, and concluded from different perspectives to\nconstruct a more profound understanding. The idea of knowledge transfer has led\nto many advances in machine learning and data mining, but significant\nchallenges remain, especially when it comes to reinforcement learning,\nheterogeneous model structures, and different learning tasks. Motivated by\nhuman collaborative learning, in this paper we propose a collaborative deep\nreinforcement learning (CDRL) framework that performs adaptive knowledge\ntransfer among heterogeneous learning agents. Specifically, the proposed CDRL\nconducts a novel deep knowledge distillation method to address the\nheterogeneity among different learning tasks with a deep alignment network.\nFurthermore, we present an efficient collaborative Asynchronous Advantage\nActor-Critic (cA3C) algorithm to incorporate deep knowledge distillation into\nthe online training of agents, and demonstrate the effectiveness of the CDRL\nframework using extensive empirical evaluation on OpenAI gym.\n", "versions": [{"version": "v1", "created": "Sun, 19 Feb 2017 21:13:45 GMT"}], "update_date": "2017-02-21", "authors_parsed": [["Lin", "Kaixiang", ""], ["Wang", "Shu", ""], ["Zhou", "Jiayu", ""]]}, {"id": "1702.05800", "submitter": "Xinghao Pan", "authors": "Xinghao Pan, Jianmin Chen, Rajat Monga, Samy Bengio, Rafal Jozefowicz", "title": "Revisiting Distributed Synchronous SGD", "comments": "This article will be superseded by arXiv:1604.00981", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributed training of deep learning models on large-scale training data is\ntypically conducted with asynchronous stochastic optimization to maximize the\nrate of updates, at the cost of additional noise introduced from asynchrony. In\ncontrast, the synchronous approach is often thought to be impractical due to\nidle time wasted on waiting for straggling workers. We revisit these\nconventional beliefs in this paper, and examine the weaknesses of both\napproaches. We demonstrate that a third approach, synchronous optimization with\nbackup workers, can avoid asynchronous noise while mitigating for the worst\nstragglers. Our approach is empirically validated and shown to converge faster\nand to better test accuracies.\n", "versions": [{"version": "v1", "created": "Sun, 19 Feb 2017 21:51:48 GMT"}, {"version": "v2", "created": "Sat, 18 Mar 2017 23:02:17 GMT"}], "update_date": "2017-03-21", "authors_parsed": [["Pan", "Xinghao", ""], ["Chen", "Jianmin", ""], ["Monga", "Rajat", ""], ["Bengio", "Samy", ""], ["Jozefowicz", "Rafal", ""]]}, {"id": "1702.05815", "submitter": "Johann Paratte", "authors": "Johan Paratte, Nathana\\\"el Perraudin, Pierre Vandergheynst", "title": "Compressive Embedding and Visualization using Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Visualizing high-dimensional data has been a focus in data analysis\ncommunities for decades, which has led to the design of many algorithms, some\nof which are now considered references (such as t-SNE for example). In our era\nof overwhelming data volumes, the scalability of such methods have become more\nand more important. In this work, we present a method which allows to apply any\nvisualization or embedding algorithm on very large datasets by considering only\na fraction of the data as input and then extending the information to all data\npoints using a graph encoding its global similarity. We show that in most\ncases, using only $\\mathcal{O}(\\log(N))$ samples is sufficient to diffuse the\ninformation to all $N$ data points. In addition, we propose quantitative\nmethods to measure the quality of embeddings and demonstrate the validity of\nour technique on both synthetic and real-world datasets.\n", "versions": [{"version": "v1", "created": "Sun, 19 Feb 2017 22:59:12 GMT"}], "update_date": "2017-02-21", "authors_parsed": [["Paratte", "Johan", ""], ["Perraudin", "Nathana\u00ebl", ""], ["Vandergheynst", "Pierre", ""]]}, {"id": "1702.05860", "submitter": "Jerry Li", "authors": "Jerry Li", "title": "Robust Sparse Estimation Tasks in High Dimensions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we initiate the study of whether or not sparse estimation tasks\ncan be performed efficiently in high dimensions, in the robust setting where an\n$\\eps$-fraction of samples are corrupted adversarially. We study the natural\nrobust version of two classical sparse estimation problems, namely, sparse mean\nestimation and sparse PCA in the spiked covariance model. For both of these\nproblems, we provide the first efficient algorithms that provide non-trivial\nerror guarantees in the presence of noise, using only a number of samples which\nis similar to the number required for these problems without noise. In\nparticular, our sample complexities are sublinear in the ambient dimension $d$.\nOur work also suggests evidence for new computational-vs-statistical gaps for\nthese problems (similar to those for sparse PCA without noise) which only arise\nin the presence of noise.\n", "versions": [{"version": "v1", "created": "Mon, 20 Feb 2017 05:22:55 GMT"}, {"version": "v2", "created": "Tue, 28 Feb 2017 20:49:30 GMT"}], "update_date": "2017-03-02", "authors_parsed": [["Li", "Jerry", ""]]}, {"id": "1702.05865", "submitter": "Xinghao Pan", "authors": "Xinghao Pan, Shivaram Venkataraman, Zizheng Tai, Joseph Gonzalez", "title": "Hemingway: Modeling Distributed Optimization Algorithms", "comments": "Presented at ML Systems Workshop at NIPS, Dec 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributed optimization algorithms are widely used in many industrial\nmachine learning applications. However choosing the appropriate algorithm and\ncluster size is often difficult for users as the performance and convergence\nrate of optimization algorithms vary with the size of the cluster. In this\npaper we make the case for an ML-optimizer that can select the appropriate\nalgorithm and cluster size to use for a given problem. To do this we propose\nbuilding two models: one that captures the system level characteristics of how\ncomputation, communication change as we increase cluster sizes and another that\ncaptures how convergence rates change with cluster sizes. We present\npreliminary results from our prototype implementation called Hemingway and\ndiscuss some of the challenges involved in developing such a system.\n", "versions": [{"version": "v1", "created": "Mon, 20 Feb 2017 05:51:18 GMT"}], "update_date": "2017-02-21", "authors_parsed": [["Pan", "Xinghao", ""], ["Venkataraman", "Shivaram", ""], ["Tai", "Zizheng", ""], ["Gonzalez", "Joseph", ""]]}, {"id": "1702.05870", "submitter": "Luo Chunjie", "authors": "Chunjie Luo, Jianfeng Zhan, Lei Wang, Qiang Yang", "title": "Cosine Normalization: Using Cosine Similarity Instead of Dot Product in\n  Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditionally, multi-layer neural networks use dot product between the output\nvector of previous layer and the incoming weight vector as the input to\nactivation function. The result of dot product is unbounded, thus increases the\nrisk of large variance. Large variance of neuron makes the model sensitive to\nthe change of input distribution, thus results in poor generalization, and\naggravates the internal covariate shift which slows down the training. To bound\ndot product and decrease the variance, we propose to use cosine similarity or\ncentered cosine similarity (Pearson Correlation Coefficient) instead of dot\nproduct in neural networks, which we call cosine normalization. We compare\ncosine normalization with batch, weight and layer normalization in\nfully-connected neural networks as well as convolutional networks on the data\nsets of MNIST, 20NEWS GROUP, CIFAR-10/100 and SVHN. Experiments show that\ncosine normalization achieves better performance than other normalization\ntechniques.\n", "versions": [{"version": "v1", "created": "Mon, 20 Feb 2017 06:17:02 GMT"}, {"version": "v2", "created": "Wed, 22 Feb 2017 06:33:34 GMT"}, {"version": "v3", "created": "Mon, 12 Jun 2017 06:05:03 GMT"}, {"version": "v4", "created": "Tue, 13 Jun 2017 07:22:58 GMT"}, {"version": "v5", "created": "Mon, 23 Oct 2017 03:31:59 GMT"}], "update_date": "2017-10-24", "authors_parsed": [["Luo", "Chunjie", ""], ["Zhan", "Jianfeng", ""], ["Wang", "Lei", ""], ["Yang", "Qiang", ""]]}, {"id": "1702.05882", "submitter": "Daniele Tantari", "authors": "Adriano Barra, Giuseppe Genovese, Peter Sollich, Daniele Tantari", "title": "Phase Diagram of Restricted Boltzmann Machines and Generalised Hopfield\n  Networks with Arbitrary Priors", "comments": "18 pages, 9 figures; typos added", "journal-ref": "Phys. Rev. E 97, 022310 (2018)", "doi": "10.1103/PhysRevE.97.022310", "report-no": null, "categories": "cond-mat.dis-nn cs.LG physics.data-an stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Restricted Boltzmann Machines are described by the Gibbs measure of a\nbipartite spin glass, which in turn corresponds to the one of a generalised\nHopfield network. This equivalence allows us to characterise the state of these\nsystems in terms of retrieval capabilities, both at low and high load. We study\nthe paramagnetic-spin glass and the spin glass-retrieval phase transitions, as\nthe pattern (i.e. weight) distribution and spin (i.e. unit) priors vary\nsmoothly from Gaussian real variables to Boolean discrete variables. Our\nanalysis shows that the presence of a retrieval phase is robust and not\npeculiar to the standard Hopfield model with Boolean patterns. The retrieval\nregion is larger when the pattern entries and retrieval units get more peaked\nand, conversely, when the hidden units acquire a broader prior and therefore\nhave a stronger response to high fields. Moreover, at low load retrieval always\nexists below some critical temperature, for every pattern distribution ranging\nfrom the Boolean to the Gaussian case.\n", "versions": [{"version": "v1", "created": "Mon, 20 Feb 2017 07:29:37 GMT"}, {"version": "v2", "created": "Sat, 29 Jul 2017 08:58:42 GMT"}], "update_date": "2018-02-28", "authors_parsed": [["Barra", "Adriano", ""], ["Genovese", "Giuseppe", ""], ["Sollich", "Peter", ""], ["Tantari", "Daniele", ""]]}, {"id": "1702.05931", "submitter": "Francesco Ciompi", "authors": "Francesco Ciompi, Oscar Geessink, Babak Ehteshami Bejnordi, Gabriel\n  Silva de Souza, Alexi Baidoshvili, Geert Litjens, Bram van Ginneken, Iris\n  Nagtegaal, Jeroen van der Laak", "title": "The importance of stain normalization in colorectal tissue\n  classification with convolutional networks", "comments": "Published in Proceedings of IEEE International Symposium on\n  Biomedical Imaging (ISBI) 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The development of reliable imaging biomarkers for the analysis of colorectal\ncancer (CRC) in hematoxylin and eosin (H&E) stained histopathology images\nrequires an accurate and reproducible classification of the main tissue\ncomponents in the image. In this paper, we propose a system for CRC tissue\nclassification based on convolutional networks (ConvNets). We investigate the\nimportance of stain normalization in tissue classification of CRC tissue\nsamples in H&E-stained images. Furthermore, we report the performance of\nConvNets on a cohort of rectal cancer samples and on an independent publicly\navailable dataset of colorectal H&E images.\n", "versions": [{"version": "v1", "created": "Mon, 20 Feb 2017 11:11:50 GMT"}, {"version": "v2", "created": "Tue, 23 May 2017 12:34:17 GMT"}], "update_date": "2017-05-24", "authors_parsed": [["Ciompi", "Francesco", ""], ["Geessink", "Oscar", ""], ["Bejnordi", "Babak Ehteshami", ""], ["de Souza", "Gabriel Silva", ""], ["Baidoshvili", "Alexi", ""], ["Litjens", "Geert", ""], ["van Ginneken", "Bram", ""], ["Nagtegaal", "Iris", ""], ["van der Laak", "Jeroen", ""]]}, {"id": "1702.05982", "submitter": "Albrecht Zimmermann", "authors": "Albrecht Zimmermann", "title": "Wages of wins: could an amateur make money from match outcome\n  predictions?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Evaluating the accuracies of models for match outcome predictions is nice and\nwell but in the end the real proof is in the money to be made by betting. To\nevaluate the question whether the models developed by us could be used easily\nto make money via sports betting, we evaluate three cases: NCAAB post-season,\nNBA season, and NFL season, and find that it is possible yet not without its\npitfalls. In particular, we illustrate that high accuracy does not\nautomatically equal high pay-out, by looking at the type of match-ups that are\npredicted correctly by different models.\n", "versions": [{"version": "v1", "created": "Fri, 17 Feb 2017 12:12:57 GMT"}], "update_date": "2017-02-21", "authors_parsed": [["Zimmermann", "Albrecht", ""]]}, {"id": "1702.05983", "submitter": "Weiwei Hu", "authors": "Weiwei Hu and Ying Tan", "title": "Generating Adversarial Malware Examples for Black-Box Attacks Based on\n  GAN", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning has been used to detect new malware in recent years, while\nmalware authors have strong motivation to attack such algorithms. Malware\nauthors usually have no access to the detailed structures and parameters of the\nmachine learning models used by malware detection systems, and therefore they\ncan only perform black-box attacks. This paper proposes a generative\nadversarial network (GAN) based algorithm named MalGAN to generate adversarial\nmalware examples, which are able to bypass black-box machine learning based\ndetection models. MalGAN uses a substitute detector to fit the black-box\nmalware detection system. A generative network is trained to minimize the\ngenerated adversarial examples' malicious probabilities predicted by the\nsubstitute detector. The superiority of MalGAN over traditional gradient based\nadversarial example generation algorithms is that MalGAN is able to decrease\nthe detection rate to nearly zero and make the retraining based defensive\nmethod against adversarial examples hard to work.\n", "versions": [{"version": "v1", "created": "Mon, 20 Feb 2017 14:32:17 GMT"}], "update_date": "2017-02-21", "authors_parsed": [["Hu", "Weiwei", ""], ["Tan", "Ying", ""]]}, {"id": "1702.05993", "submitter": "Gabriela Csurka", "authors": "Gabriela Csurka, Boris Chidlovski, Stephane Clinchant and Sophia\n  Michel", "title": "An Extended Framework for Marginalized Domain Adaptation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an extended framework for marginalized domain adaptation, aimed at\naddressing unsupervised, supervised and semi-supervised scenarios. We argue\nthat the denoising principle should be extended to explicitly promote\ndomain-invariant features as well as help the classification task. Therefore we\npropose to jointly learn the data auto-encoders and the target classifiers.\nFirst, in order to make the denoised features domain-invariant, we propose a\ndomain regularization that may be either a domain prediction loss or a maximum\nmean discrepancy between the source and target data. The noise marginalization\nin this case is reduced to solving the linear matrix system $AX=B$ which has a\nclosed-form solution. Second, in order to help the classification, we include a\nclass regularization term. Adding this component reduces the learning problem\nto solving a Sylvester linear matrix equation $AX+BX=C$, for which an efficient\niterative procedure exists as well. We did an extensive study to assess how\nthese regularization terms improve the baseline performance in the three domain\nadaptation scenarios and present experimental results on two image and one text\nbenchmark datasets, conventionally used for validating domain adaptation\nmethods. We report our findings and comparison with state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Mon, 20 Feb 2017 15:00:13 GMT"}], "update_date": "2017-02-21", "authors_parsed": [["Csurka", "Gabriela", ""], ["Chidlovski", "Boris", ""], ["Clinchant", "Stephane", ""], ["Michel", "Sophia", ""]]}, {"id": "1702.06053", "submitter": "Sahil Sharma", "authors": "Sahil Sharma, Ashutosh Jha, Parikshit Hegde, Balaraman Ravindran", "title": "Learning to Multi-Task by Active Sampling", "comments": "11 pages + 30 page appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the long-standing challenges in Artificial Intelligence for learning\ngoal-directed behavior is to build a single agent which can solve multiple\ntasks. Recent progress in multi-task learning for goal-directed sequential\nproblems has been in the form of distillation based learning wherein a student\nnetwork learns from multiple task-specific expert networks by mimicking the\ntask-specific policies of the expert networks. While such approaches offer a\npromising solution to the multi-task learning problem, they require supervision\nfrom large expert networks which require extensive data and computation time\nfor training. In this work, we propose an efficient multi-task learning\nframework which solves multiple goal-directed tasks in an on-line setup without\nthe need for expert supervision. Our work uses active learning principles to\nachieve multi-task learning by sampling the harder tasks more than the easier\nones. We propose three distinct models under our active sampling framework. An\nadaptive method with extremely competitive multi-tasking performance. A\nUCB-based meta-learner which casts the problem of picking the next task to\ntrain on as a multi-armed bandit problem. A meta-learning method that casts the\nnext-task picking problem as a full Reinforcement Learning problem and uses\nactor critic methods for optimizing the multi-tasking performance directly. We\ndemonstrate results in the Atari 2600 domain on seven multi-tasking instances:\nthree 6-task instances, one 8-task instance, two 12-task instances and one\n21-task instance.\n", "versions": [{"version": "v1", "created": "Mon, 20 Feb 2017 16:31:56 GMT"}, {"version": "v2", "created": "Tue, 21 Feb 2017 04:38:43 GMT"}, {"version": "v3", "created": "Sat, 25 Feb 2017 08:49:45 GMT"}, {"version": "v4", "created": "Sun, 21 May 2017 12:47:34 GMT"}], "update_date": "2017-05-23", "authors_parsed": [["Sharma", "Sahil", ""], ["Jha", "Ashutosh", ""], ["Hegde", "Parikshit", ""], ["Ravindran", "Balaraman", ""]]}, {"id": "1702.06054", "submitter": "Aravind Srinivas", "authors": "Sahil Sharma, Aravind Srinivas, Balaraman Ravindran", "title": "Learning to Repeat: Fine Grained Action Repetition for Deep\n  Reinforcement Learning", "comments": "24 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement Learning algorithms can learn complex behavioral patterns for\nsequential decision making tasks wherein an agent interacts with an environment\nand acquires feedback in the form of rewards sampled from it. Traditionally,\nsuch algorithms make decisions, i.e., select actions to execute, at every\nsingle time step of the agent-environment interactions. In this paper, we\npropose a novel framework, Fine Grained Action Repetition (FiGAR), which\nenables the agent to decide the action as well as the time scale of repeating\nit. FiGAR can be used for improving any Deep Reinforcement Learning algorithm\nwhich maintains an explicit policy estimate by enabling temporal abstractions\nin the action space. We empirically demonstrate the efficacy of our framework\nby showing performance improvements on top of three policy search algorithms in\ndifferent domains: Asynchronous Advantage Actor Critic in the Atari 2600\ndomain, Trust Region Policy Optimization in Mujoco domain and Deep\nDeterministic Policy Gradients in the TORCS car racing domain.\n", "versions": [{"version": "v1", "created": "Mon, 20 Feb 2017 16:32:07 GMT"}, {"version": "v2", "created": "Mon, 21 Sep 2020 22:22:25 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Sharma", "Sahil", ""], ["Srinivas", "Aravind", ""], ["Ravindran", "Balaraman", ""]]}, {"id": "1702.06081", "submitter": "Blake Woodworth", "authors": "Blake Woodworth, Suriya Gunasekar, Mesrob I. Ohannessian, Nathan\n  Srebro", "title": "Learning Non-Discriminatory Predictors", "comments": "28 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider learning a predictor which is non-discriminatory with respect to\na \"protected attribute\" according to the notion of \"equalized odds\" proposed by\nHardt et al. [2016]. We study the problem of learning such a non-discriminatory\npredictor from a finite training set, both statistically and computationally.\nWe show that a post-hoc correction approach, as suggested by Hardt et al, can\nbe highly suboptimal, present a nearly-optimal statistical procedure, argue\nthat the associated computational problem is intractable, and suggest a second\nmoment relaxation of the non-discrimination definition for which learning is\ntractable.\n", "versions": [{"version": "v1", "created": "Mon, 20 Feb 2017 17:52:14 GMT"}, {"version": "v2", "created": "Fri, 29 Sep 2017 14:52:10 GMT"}, {"version": "v3", "created": "Wed, 1 Nov 2017 18:23:40 GMT"}], "update_date": "2017-11-03", "authors_parsed": [["Woodworth", "Blake", ""], ["Gunasekar", "Suriya", ""], ["Ohannessian", "Mesrob I.", ""], ["Srebro", "Nathan", ""]]}, {"id": "1702.06086", "submitter": "Wei Shen", "authors": "Wei Shen, Kai Zhao, Yilu Guo, Alan Yuille", "title": "Label Distribution Learning Forests", "comments": "Accepted by NIPS2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Label distribution learning (LDL) is a general learning framework, which\nassigns to an instance a distribution over a set of labels rather than a single\nlabel or multiple labels. Current LDL methods have either restricted\nassumptions on the expression form of the label distribution or limitations in\nrepresentation learning, e.g., to learn deep features in an end-to-end manner.\nThis paper presents label distribution learning forests (LDLFs) - a novel label\ndistribution learning algorithm based on differentiable decision trees, which\nhave several advantages: 1) Decision trees have the potential to model any\ngeneral form of label distributions by a mixture of leaf node predictions. 2)\nThe learning of differentiable decision trees can be combined with\nrepresentation learning. We define a distribution-based loss function for a\nforest, enabling all the trees to be learned jointly, and show that an update\nfunction for leaf node predictions, which guarantees a strict decrease of the\nloss function, can be derived by variational bounding. The effectiveness of the\nproposed LDLFs is verified on several LDL tasks and a computer vision\napplication, showing significant improvements to the state-of-the-art LDL\nmethods.\n", "versions": [{"version": "v1", "created": "Mon, 20 Feb 2017 18:04:31 GMT"}, {"version": "v2", "created": "Tue, 11 Jul 2017 19:17:32 GMT"}, {"version": "v3", "created": "Wed, 20 Sep 2017 06:48:22 GMT"}, {"version": "v4", "created": "Mon, 16 Oct 2017 21:05:45 GMT"}], "update_date": "2017-10-18", "authors_parsed": [["Shen", "Wei", ""], ["Zhao", "Kai", ""], ["Guo", "Yilu", ""], ["Yuille", "Alan", ""]]}, {"id": "1702.06103", "submitter": "Yevgeny Seldin", "authors": "Yevgeny Seldin and G\\'abor Lugosi", "title": "An Improved Parametrization and Analysis of the EXP3++ Algorithm for\n  Stochastic and Adversarial Bandits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new strategy for gap estimation in randomized algorithms for\nmultiarmed bandits and combine it with the EXP3++ algorithm of Seldin and\nSlivkins (2014). In the stochastic regime the strategy reduces dependence of\nregret on a time horizon from $(\\ln t)^3$ to $(\\ln t)^2$ and eliminates an\nadditive factor of order $\\Delta e^{1/\\Delta^2}$, where $\\Delta$ is the minimal\ngap of a problem instance. In the adversarial regime regret guarantee remains\nunchanged.\n", "versions": [{"version": "v1", "created": "Mon, 20 Feb 2017 18:43:05 GMT"}, {"version": "v2", "created": "Tue, 9 May 2017 14:29:38 GMT"}], "update_date": "2017-05-10", "authors_parsed": [["Seldin", "Yevgeny", ""], ["Lugosi", "G\u00e1bor", ""]]}, {"id": "1702.06106", "submitter": "Baiyang Wang", "authors": "Baiyang Wang, Diego Klabjan", "title": "An Attention-Based Deep Net for Learning to Rank", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In information retrieval, learning to rank constructs a machine-based ranking\nmodel which given a query, sorts the search results by their degree of\nrelevance or importance to the query. Neural networks have been successfully\napplied to this problem, and in this paper, we propose an attention-based deep\nneural network which better incorporates different embeddings of the queries\nand search results with an attention-based mechanism. This model also applies a\ndecoder mechanism to learn the ranks of the search results in a listwise\nfashion. The embeddings are trained with convolutional neural networks or the\nword2vec model. We demonstrate the performance of this model with image\nretrieval and text querying data sets.\n", "versions": [{"version": "v1", "created": "Mon, 20 Feb 2017 18:47:25 GMT"}, {"version": "v2", "created": "Mon, 15 May 2017 23:57:57 GMT"}, {"version": "v3", "created": "Sun, 10 Dec 2017 21:26:46 GMT"}], "update_date": "2017-12-12", "authors_parsed": [["Wang", "Baiyang", ""], ["Klabjan", "Diego", ""]]}, {"id": "1702.06120", "submitter": "Mieczys{\\l}aw K{\\l}opotek", "authors": "Mieczys{\\l}aw A. K{\\l}opotek", "title": "On the Consistency of $k$-means++ algorithm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove in this paper that the expected value of the objective function of\nthe $k$-means++ algorithm for samples converges to population expected value.\nAs $k$-means++, for samples, provides with constant factor approximation for\n$k$-means objectives, such an approximation can be achieved for the population\nwith increase of the sample size.\n  This result is of potential practical relevance when one is considering using\nsubsampling when clustering large data sets (large data bases).\n", "versions": [{"version": "v1", "created": "Mon, 20 Feb 2017 10:09:02 GMT"}], "update_date": "2017-02-22", "authors_parsed": [["K\u0142opotek", "Mieczys\u0142aw A.", ""]]}, {"id": "1702.06151", "submitter": "Tal Yarkoni", "authors": "Quinten McNamara, Alejandro de la Vega, and Tal Yarkoni", "title": "Developing a comprehensive framework for multimodal feature extraction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.IR cs.LG cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Feature extraction is a critical component of many applied data science\nworkflows. In recent years, rapid advances in artificial intelligence and\nmachine learning have led to an explosion of feature extraction tools and\nservices that allow data scientists to cheaply and effectively annotate their\ndata along a vast array of dimensions---ranging from detecting faces in images\nto analyzing the sentiment expressed in coherent text. Unfortunately, the\nproliferation of powerful feature extraction services has been mirrored by a\ncorresponding expansion in the number of distinct interfaces to feature\nextraction services. In a world where nearly every new service has its own API,\ndocumentation, and/or client library, data scientists who need to combine\ndiverse features obtained from multiple sources are often forced to write and\nmaintain ever more elaborate feature extraction pipelines. To address this\nchallenge, we introduce a new open-source framework for comprehensive\nmultimodal feature extraction. Pliers is an open-source Python package that\nsupports standardized annotation of diverse data types (video, images, audio,\nand text), and is expressly with both ease-of-use and extensibility in mind.\nUsers can apply a wide range of pre-existing feature extraction tools to their\ndata in just a few lines of Python code, and can also easily add their own\ncustom extractors by writing modular classes. A graph-based API enables rapid\ndevelopment of complex feature extraction pipelines that output results in a\nsingle, standardized format. We describe the package's architecture, detail its\nmajor advantages over previous feature extraction toolboxes, and use a sample\napplication to a large functional MRI dataset to illustrate how pliers can\nsignificantly reduce the time and effort required to construct sophisticated\nfeature extraction workflows while increasing code clarity and maintainability.\n", "versions": [{"version": "v1", "created": "Mon, 20 Feb 2017 19:22:21 GMT"}], "update_date": "2017-02-22", "authors_parsed": [["McNamara", "Quinten", ""], ["de la Vega", "Alejandro", ""], ["Yarkoni", "Tal", ""]]}, {"id": "1702.06166", "submitter": "Tammo Rukat", "authors": "Tammo Rukat and Chris C. Holmes and Michalis K. Titsias and\n  Christopher Yau", "title": "Bayesian Boolean Matrix Factorisation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.NA q-bio.GN q-bio.QM stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Boolean matrix factorisation aims to decompose a binary data matrix into an\napproximate Boolean product of two low rank, binary matrices: one containing\nmeaningful patterns, the other quantifying how the observations can be\nexpressed as a combination of these patterns. We introduce the OrMachine, a\nprobabilistic generative model for Boolean matrix factorisation and derive a\nMetropolised Gibbs sampler that facilitates efficient parallel posterior\ninference. On real world and simulated data, our method outperforms all\ncurrently existing approaches for Boolean matrix factorisation and completion.\nThis is the first method to provide full posterior inference for Boolean Matrix\nfactorisation which is relevant in applications, e.g. for controlling false\npositive rates in collaborative filtering and, crucially, improves the\ninterpretability of the inferred patterns. The proposed algorithm scales to\nlarge datasets as we demonstrate by analysing single cell gene expression data\nin 1.3 million mouse brain cells across 11 thousand genes on commodity\nhardware.\n", "versions": [{"version": "v1", "created": "Mon, 20 Feb 2017 20:31:39 GMT"}, {"version": "v2", "created": "Sat, 25 Feb 2017 14:17:44 GMT"}], "update_date": "2017-02-28", "authors_parsed": [["Rukat", "Tammo", ""], ["Holmes", "Chris C.", ""], ["Titsias", "Michalis K.", ""], ["Yau", "Christopher", ""]]}, {"id": "1702.06175", "submitter": "Mahdi Soltanolkotabi", "authors": "Mahdi Soltanolkotabi", "title": "Structured signal recovery from quadratic measurements: Breaking sample\n  complexity barriers via nonconvex optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.FA math.IT math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper concerns the problem of recovering an unknown but structured\nsignal $x \\in R^n$ from $m$ quadratic measurements of the form\n$y_r=|<a_r,x>|^2$ for $r=1,2,...,m$. We focus on the under-determined setting\nwhere the number of measurements is significantly smaller than the dimension of\nthe signal ($m<<n$). We formulate the recovery problem as a nonconvex\noptimization problem where prior structural information about the signal is\nenforced through constrains on the optimization variables. We prove that\nprojected gradient descent, when initialized in a neighborhood of the desired\nsignal, converges to the unknown signal at a linear rate. These results hold\nfor any constraint set (convex or nonconvex) providing convergence guarantees\nto the global optimum even when the objective function and constraint set is\nnonconvex. Furthermore, these results hold with a number of measurements that\nis only a constant factor away from the minimal number of measurements required\nto uniquely identify the unknown signal. Our results provide the first provably\ntractable algorithm for this data-poor regime, breaking local sample complexity\nbarriers that have emerged in recent literature. In a companion paper we\ndemonstrate favorable properties for the optimization problem that may enable\nsimilar results to continue to hold more globally (over the entire ambient\nspace). Collectively these two papers utilize and develop powerful tools for\nuniform convergence of empirical processes that may have broader implications\nfor rigorous understanding of constrained nonconvex optimization heuristics.\nThe mathematical results in this paper also pave the way for a new generation\nof data-driven phase-less imaging systems that can utilize prior information to\nsignificantly reduce acquisition time and enhance image reconstruction,\nenabling nano-scale imaging at unprecedented speeds and resolutions.\n", "versions": [{"version": "v1", "created": "Mon, 20 Feb 2017 21:04:36 GMT"}], "update_date": "2017-02-22", "authors_parsed": [["Soltanolkotabi", "Mahdi", ""]]}, {"id": "1702.06186", "submitter": "Amit Sahu", "authors": "Amit Sahu", "title": "Survey of reasoning using Neural networks", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reason and inference require process as well as memory skills by humans.\nNeural networks are able to process tasks like image recognition (better than\nhumans) but in memory aspects are still limited (by attention mechanism, size).\nRecurrent Neural Network (RNN) and it's modified version LSTM are able to solve\nsmall memory contexts, but as context becomes larger than a threshold, it is\ndifficult to use them. The Solution is to use large external memory. Still, it\nposes many challenges like, how to train neural networks for discrete memory\nrepresentation, how to describe long term dependencies in sequential data etc.\nMost prominent neural architectures for such tasks are Memory networks:\ninference components combined with long term memory and Neural Turing Machines:\nneural networks using external memory resources. Also, additional techniques\nlike attention mechanism, end to end gradient descent on discrete memory\nrepresentation are needed to support these solutions. Preliminary results of\nabove neural architectures on simple algorithms (sorting, copying) and Question\nAnswering (based on story, dialogs) application are comparable with the state\nof the art. In this paper, I explain these architectures (in general), the\nadditional techniques used and the results of their application.\n", "versions": [{"version": "v1", "created": "Tue, 14 Feb 2017 17:24:04 GMT"}, {"version": "v2", "created": "Thu, 2 Mar 2017 09:36:24 GMT"}], "update_date": "2017-03-03", "authors_parsed": [["Sahu", "Amit", ""]]}, {"id": "1702.06216", "submitter": "Michael Bloodgood", "authors": "Alan Mishler, Kevin Wonus, Wendy Chambers and Michael Bloodgood", "title": "Filtering Tweets for Social Unrest", "comments": "7 pages, 8 figures, 3 tables; published in Proceedings of the 2017\n  IEEE 11th International Conference on Semantic Computing (ICSC), San Diego,\n  CA, USA, pages 17-23, January 2017", "journal-ref": "In Proceedings of the 2017 IEEE 11th International Conference on\n  Semantic Computing (ICSC), pages 17-23, San Diego, CA, USA, January 2017.\n  IEEE", "doi": "10.1109/ICSC.2017.75", "report-no": null, "categories": "cs.CL cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Since the events of the Arab Spring, there has been increased interest in\nusing social media to anticipate social unrest. While efforts have been made\ntoward automated unrest prediction, we focus on filtering the vast volume of\ntweets to identify tweets relevant to unrest, which can be provided to\ndownstream users for further analysis. We train a supervised classifier that is\nable to label Arabic language tweets as relevant to unrest with high\nreliability. We examine the relationship between training data size and\nperformance and investigate ways to optimize the model building process while\nminimizing cost. We also explore how confidence thresholds can be set to\nachieve desired levels of performance.\n", "versions": [{"version": "v1", "created": "Mon, 20 Feb 2017 23:48:39 GMT"}, {"version": "v2", "created": "Sat, 1 Apr 2017 22:37:35 GMT"}], "update_date": "2017-04-04", "authors_parsed": [["Mishler", "Alan", ""], ["Wonus", "Kevin", ""], ["Chambers", "Wendy", ""], ["Bloodgood", "Michael", ""]]}, {"id": "1702.06221", "submitter": "Joshua Chang", "authors": "Joshua C. Chang", "title": "Determination of hysteresis in finite-state random walks using Bayesian\n  cross validation", "comments": "Reworked as totally different paper in arXiv:1706.08881", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.LG physics.data-an q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider the problem of modeling hysteresis for finite-state random walks\nusing higher-order Markov chains. This Letter introduces a Bayesian framework\nto determine, from data, the number of prior states of recent history upon\nwhich a trajectory is statistically dependent. The general recommendation is to\nuse leave-one-out cross validation, using an easily-computable formula that is\nprovided in closed form. Importantly, Bayes factors using flat model priors are\nbiased in favor of too-complex a model (more hysteresis) when a large amount of\ndata is present and the Akaike information criterion (AIC) is biased in favor\nof too-sparse a model (less hysteresis) when few data are present.\n", "versions": [{"version": "v1", "created": "Tue, 21 Feb 2017 00:28:39 GMT"}, {"version": "v2", "created": "Fri, 20 Jul 2018 04:47:05 GMT"}], "update_date": "2018-07-23", "authors_parsed": [["Chang", "Joshua C.", ""]]}, {"id": "1702.06230", "submitter": "Vlad Firoiu", "authors": "Vlad Firoiu, William F. Whitney, Joshua B. Tenenbaum", "title": "Beating the World's Best at Super Smash Bros. with Deep Reinforcement\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There has been a recent explosion in the capabilities of game-playing\nartificial intelligence. Many classes of RL tasks, from Atari games to motor\ncontrol to board games, are now solvable by fairly generic algorithms, based on\ndeep learning, that learn to play from experience with minimal knowledge of the\nspecific domain of interest. In this work, we will investigate the performance\nof these methods on Super Smash Bros. Melee (SSBM), a popular console fighting\ngame. The SSBM environment has complex dynamics and partial observability,\nmaking it challenging for human and machine alike. The multi-player aspect\nposes an additional challenge, as the vast majority of recent advances in RL\nhave focused on single-agent environments. Nonetheless, we will show that it is\npossible to train agents that are competitive against and even surpass human\nprofessionals, a new result for the multi-player video game setting.\n", "versions": [{"version": "v1", "created": "Tue, 21 Feb 2017 01:06:11 GMT"}, {"version": "v2", "created": "Thu, 2 Mar 2017 01:54:33 GMT"}, {"version": "v3", "created": "Mon, 8 May 2017 15:03:25 GMT"}], "update_date": "2017-05-09", "authors_parsed": [["Firoiu", "Vlad", ""], ["Whitney", "William F.", ""], ["Tenenbaum", "Joshua B.", ""]]}, {"id": "1702.06237", "submitter": "David Steurer", "authors": "Aaron Potechin, David Steurer", "title": "Exact tensor completion with sum-of-squares", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CC cs.DS cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We obtain the first polynomial-time algorithm for exact tensor completion\nthat improves over the bound implied by reduction to matrix completion. The\nalgorithm recovers an unknown 3-tensor with $r$ incoherent, orthogonal\ncomponents in $\\mathbb R^n$ from $r\\cdot \\tilde O(n^{1.5})$ randomly observed\nentries of the tensor. This bound improves over the previous best one of\n$r\\cdot \\tilde O(n^{2})$ by reduction to exact matrix completion. Our bound\nalso matches the best known results for the easier problem of approximate\ntensor completion (Barak & Moitra, 2015).\n  Our algorithm and analysis extends seminal results for exact matrix\ncompletion (Candes & Recht, 2009) to the tensor setting via the sum-of-squares\nmethod. The main technical challenge is to show that a small number of randomly\nchosen monomials are enough to construct a degree-3 polynomial with precisely\nplanted orthogonal global optima over the sphere and that this fact can be\ncertified within the sum-of-squares proof system.\n", "versions": [{"version": "v1", "created": "Tue, 21 Feb 2017 02:14:31 GMT"}, {"version": "v2", "created": "Thu, 23 Feb 2017 02:48:22 GMT"}, {"version": "v3", "created": "Fri, 23 Jun 2017 18:24:50 GMT"}], "update_date": "2017-06-27", "authors_parsed": [["Potechin", "Aaron", ""], ["Steurer", "David", ""]]}, {"id": "1702.06238", "submitter": "Karan Goel", "authors": "Karan Goel, Christoph Dann and Emma Brunskill", "title": "Sample Efficient Policy Search for Optimal Stopping Domains", "comments": "To appear in IJCAI-2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optimal stopping problems consider the question of deciding when to stop an\nobservation-generating process in order to maximize a return. We examine the\nproblem of simultaneously learning and planning in such domains, when data is\ncollected directly from the environment. We propose GFSE, a simple and flexible\nmodel-free policy search method that reuses data for sample efficiency by\nleveraging problem structure. We bound the sample complexity of our approach to\nguarantee uniform convergence of policy value estimates, tightening existing\nPAC bounds to achieve logarithmic dependence on horizon length for our setting.\nWe also examine the benefit of our method against prevalent model-based and\nmodel-free approaches on 3 domains taken from diverse fields.\n", "versions": [{"version": "v1", "created": "Tue, 21 Feb 2017 02:14:47 GMT"}, {"version": "v2", "created": "Wed, 24 May 2017 06:40:07 GMT"}], "update_date": "2017-05-25", "authors_parsed": [["Goel", "Karan", ""], ["Dann", "Christoph", ""], ["Brunskill", "Emma", ""]]}, {"id": "1702.06247", "submitter": "Han Xiao Almighty", "authors": "Han Xiao, Lian Meng", "title": "SAR: Semantic Analysis for Recommendation", "comments": "Submitting to IJCAI-2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recommendation system is a common demand in daily life and matrix completion\nis a widely adopted technique for this task. However, most matrix completion\nmethods lack semantic interpretation and usually result in weak-semantic\nrecommendations. To this end, this paper proposes a $S$emantic $A$nalysis\napproach for $R$ecommendation systems $(SAR)$, which applies a two-level\nhierarchical generative process that assigns semantic properties and categories\nfor user and item. $SAR$ learns semantic representations of users/items merely\nfrom user ratings on items, which offers a new path to recommendation by\nsemantic matching with the learned representations. Extensive experiments\ndemonstrate $SAR$ outperforms other state-of-the-art baselines substantially.\n", "versions": [{"version": "v1", "created": "Tue, 21 Feb 2017 03:09:10 GMT"}, {"version": "v2", "created": "Tue, 13 Jun 2017 02:20:47 GMT"}, {"version": "v3", "created": "Sat, 2 Dec 2017 11:29:58 GMT"}, {"version": "v4", "created": "Sat, 16 Dec 2017 11:18:33 GMT"}], "update_date": "2017-12-19", "authors_parsed": [["Xiao", "Han", ""], ["Meng", "Lian", ""]]}, {"id": "1702.06269", "submitter": "Weiran Wang", "authors": "Jialei Wang, Weiran Wang, Nathan Srebro", "title": "Memory and Communication Efficient Distributed Stochastic Optimization\n  with Minibatch-Prox", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present and analyze an approach for distributed stochastic optimization\nwhich is statistically optimal and achieves near-linear speedups (up to\nlogarithmic factors). Our approach allows a communication-memory tradeoff, with\neither logarithmic communication but linear memory, or polynomial communication\nand a corresponding polynomial reduction in required memory. This\ncommunication-memory tradeoff is achieved through minibatch-prox iterations\n(minibatch passive-aggressive updates), where a subproblem on a minibatch is\nsolved at each iteration. We provide a novel analysis for such a minibatch-prox\nprocedure which achieves the statistical optimal rate regardless of minibatch\nsize and smoothness, thus significantly improving on prior work.\n", "versions": [{"version": "v1", "created": "Tue, 21 Feb 2017 05:19:23 GMT"}, {"version": "v2", "created": "Fri, 9 Jun 2017 16:14:48 GMT"}], "update_date": "2017-06-12", "authors_parsed": [["Wang", "Jialei", ""], ["Wang", "Weiran", ""], ["Srebro", "Nathan", ""]]}, {"id": "1702.06280", "submitter": "Kathrin Grosse", "authors": "Kathrin Grosse, Praveen Manoharan, Nicolas Papernot, Michael Backes,\n  Patrick McDaniel", "title": "On the (Statistical) Detection of Adversarial Examples", "comments": "13 pages, 4 figures, 5 tables. New version: improved writing,\n  incorporating external feedback", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine Learning (ML) models are applied in a variety of tasks such as\nnetwork intrusion detection or Malware classification. Yet, these models are\nvulnerable to a class of malicious inputs known as adversarial examples. These\nare slightly perturbed inputs that are classified incorrectly by the ML model.\nThe mitigation of these adversarial inputs remains an open problem. As a step\ntowards understanding adversarial examples, we show that they are not drawn\nfrom the same distribution than the original data, and can thus be detected\nusing statistical tests. Using thus knowledge, we introduce a complimentary\napproach to identify specific inputs that are adversarial. Specifically, we\naugment our ML model with an additional output, in which the model is trained\nto classify all adversarial inputs. We evaluate our approach on multiple\nadversarial example crafting methods (including the fast gradient sign and\nsaliency map methods) with several datasets. The statistical test flags sample\nsets containing adversarial inputs confidently at sample sizes between 10 and\n100 data points. Furthermore, our augmented model either detects adversarial\nexamples as outliers with high accuracy (> 80%) or increases the adversary's\ncost - the perturbation added - by more than 150%. In this way, we show that\nstatistical properties of adversarial examples are essential to their\ndetection.\n", "versions": [{"version": "v1", "created": "Tue, 21 Feb 2017 07:03:11 GMT"}, {"version": "v2", "created": "Tue, 17 Oct 2017 11:12:44 GMT"}], "update_date": "2017-10-18", "authors_parsed": [["Grosse", "Kathrin", ""], ["Manoharan", "Praveen", ""], ["Papernot", "Nicolas", ""], ["Backes", "Michael", ""], ["McDaniel", "Patrick", ""]]}, {"id": "1702.06286", "submitter": "Emre Cakir", "authors": "Emre \\c{C}ak{\\i}r, Giambattista Parascandolo, Toni Heittola, Heikki\n  Huttunen and Tuomas Virtanen", "title": "Convolutional Recurrent Neural Networks for Polyphonic Sound Event\n  Detection", "comments": "Accepted for IEEE Transactions on Audio, Speech and Language\n  Processing, Special Issue on Sound Scene and Event Analysis", "journal-ref": null, "doi": "10.1109/TASLP.2017.2690575", "report-no": null, "categories": "cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sound events often occur in unstructured environments where they exhibit wide\nvariations in their frequency content and temporal structure. Convolutional\nneural networks (CNN) are able to extract higher level features that are\ninvariant to local spectral and temporal variations. Recurrent neural networks\n(RNNs) are powerful in learning the longer term temporal context in the audio\nsignals. CNNs and RNNs as classifiers have recently shown improved performances\nover established methods in various sound recognition tasks. We combine these\ntwo approaches in a Convolutional Recurrent Neural Network (CRNN) and apply it\non a polyphonic sound event detection task. We compare the performance of the\nproposed CRNN method with CNN, RNN, and other established methods, and observe\na considerable improvement for four different datasets consisting of everyday\nsound events.\n", "versions": [{"version": "v1", "created": "Tue, 21 Feb 2017 07:37:59 GMT"}], "update_date": "2017-05-31", "authors_parsed": [["\u00c7ak\u0131r", "Emre", ""], ["Parascandolo", "Giambattista", ""], ["Heittola", "Toni", ""], ["Huttunen", "Heikki", ""], ["Virtanen", "Tuomas", ""]]}, {"id": "1702.06295", "submitter": "Armen Aghajanyan", "authors": "Armen Aghajanyan", "title": "Convolution Aware Initialization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Initialization of parameters in deep neural networks has been shown to have a\nbig impact on the performance of the networks (Mishkin & Matas, 2015). The\ninitialization scheme devised by He et al, allowed convolution activations to\ncarry a constrained mean which allowed deep networks to be trained effectively\n(He et al., 2015a). Orthogonal initializations and more generally orthogonal\nmatrices in standard recurrent networks have been proved to eradicate the\nvanishing and exploding gradient problem (Pascanu et al., 2012). Majority of\ncurrent initialization schemes do not take fully into account the intrinsic\nstructure of the convolution operator. Using the duality of the Fourier\ntransform and the convolution operator, Convolution Aware Initialization builds\northogonal filters in the Fourier space, and using the inverse Fourier\ntransform represents them in the standard space. With Convolution Aware\nInitialization we noticed not only higher accuracy and lower loss, but faster\nconvergence. We achieve new state of the art on the CIFAR10 dataset, and\nachieve close to state of the art on various other tasks.\n", "versions": [{"version": "v1", "created": "Tue, 21 Feb 2017 09:01:46 GMT"}, {"version": "v2", "created": "Thu, 23 Feb 2017 06:00:34 GMT"}, {"version": "v3", "created": "Mon, 27 Feb 2017 17:38:58 GMT"}], "update_date": "2017-02-28", "authors_parsed": [["Aghajanyan", "Armen", ""]]}, {"id": "1702.06329", "submitter": "Angel Martinez-Tenor", "authors": "Angel Mart\\'inez-Tenor, Juan Antonio Fern\\'andez-Madrigal, Ana\n  Cruz-Mart\\'in and Javier Gonz\\'alez-Jim\\'enez", "title": "Towards a Common Implementation of Reinforcement Learning for Multiple\n  Robotic Tasks", "comments": "15 pages, 10 figures, 7 tables. To be published in a scientific\n  journal", "journal-ref": null, "doi": "10.1016/j.eswa.2017.11.011", "report-no": null, "categories": "cs.AI cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mobile robots are increasingly being employed for performing complex tasks in\ndynamic environments. Reinforcement learning (RL) methods are recognized to be\npromising for specifying such tasks in a relatively simple manner. However, the\nstrong dependency between the learning method and the task to learn is a\nwell-known problem that restricts practical implementations of RL in robotics,\noften requiring major modifications of parameters and adding other techniques\nfor each particular task. In this paper we present a practical core\nimplementation of RL which enables the learning process for multiple robotic\ntasks with minimal per-task tuning or none. Based on value iteration methods,\nthis implementation includes a novel approach for action selection, called\nQ-biased softmax regression (QBIASSR), which avoids poor performance of the\nlearning process when the robot reaches new unexplored states. Our approach\ntakes advantage of the structure of the state space by attending the physical\nvariables involved (e.g., distances to obstacles, X,Y,{\\theta} pose, etc.),\nthus experienced sets of states may favor the decision-making process of\nunexplored or rarely-explored states. This improvement has a relevant role in\nreducing the tuning of the algorithm for particular tasks. Experiments with\nreal and simulated robots, performed with the software framework also\nintroduced here, show that our implementation is effectively able to learn\ndifferent robotic tasks without tuning the learning method. Results also\nsuggest that the combination of true online SARSA({\\lambda}) with QBIASSR can\noutperform the existing RL core algorithms in low-dimensional robotic tasks.\n", "versions": [{"version": "v1", "created": "Tue, 21 Feb 2017 11:07:27 GMT"}], "update_date": "2017-11-08", "authors_parsed": [["Mart\u00ednez-Tenor", "Angel", ""], ["Fern\u00e1ndez-Madrigal", "Juan Antonio", ""], ["Cruz-Mart\u00edn", "Ana", ""], ["Gonz\u00e1lez-Jim\u00e9nez", "Javier", ""]]}, {"id": "1702.06341", "submitter": "Gergely Neu", "authors": "Gergely Neu and Vicen\\c{c} G\\'omez", "title": "Fast rates for online learning in Linearly Solvable Markov Decision\n  Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of online learning in a class of Markov decision\nprocesses known as linearly solvable MDPs. In the stationary version of this\nproblem, a learner interacts with its environment by directly controlling the\nstate transitions, attempting to balance a fixed state-dependent cost and a\ncertain smooth cost penalizing extreme control inputs. In the current paper, we\nconsider an online setting where the state costs may change arbitrarily between\nconsecutive rounds, and the learner only observes the costs at the end of each\nrespective round. We are interested in constructing algorithms for the learner\nthat guarantee small regret against the best stationary control policy chosen\nin full knowledge of the cost sequence. Our main result is showing that the\nsmoothness of the control cost enables the simple algorithm of following the\nleader to achieve a regret of order $\\log^2 T$ after $T$ rounds, vastly\nimproving on the best known regret bound of order $T^{3/4}$ for this setting.\n", "versions": [{"version": "v1", "created": "Tue, 21 Feb 2017 11:56:33 GMT"}, {"version": "v2", "created": "Tue, 6 Jun 2017 11:01:30 GMT"}], "update_date": "2017-06-07", "authors_parsed": [["Neu", "Gergely", ""], ["G\u00f3mez", "Vicen\u00e7", ""]]}, {"id": "1702.06347", "submitter": "Jinfeng Yi", "authors": "Jinfeng Yi, Cho-Jui Hsieh, Kush Varshney, Lijun Zhang, Yao Li", "title": "Scalable Demand-Aware Recommendation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recommendation for e-commerce with a mix of durable and nondurable goods has\ncharacteristics that distinguish it from the well-studied media recommendation\nproblem. The demand for items is a combined effect of form utility and time\nutility, i.e., a product must both be intrinsically appealing to a consumer and\nthe time must be right for purchase. In particular for durable goods, time\nutility is a function of inter-purchase duration within product category\nbecause consumers are unlikely to purchase two items in the same category in\nclose temporal succession. Moreover, purchase data, in contrast to ratings\ndata, is implicit with non-purchases not necessarily indicating dislike.\nTogether, these issues give rise to the positive-unlabeled demand-aware\nrecommendation problem that we pose via joint low-rank tensor completion and\nproduct category inter-purchase duration vector estimation. We further relax\nthis problem and propose a highly scalable alternating minimization approach\nwith which we can solve problems with millions of users and millions of items\nin a single thread. We also show superior prediction accuracies on multiple\nreal-world data sets.\n", "versions": [{"version": "v1", "created": "Tue, 21 Feb 2017 12:10:28 GMT"}, {"version": "v2", "created": "Tue, 23 May 2017 04:05:35 GMT"}, {"version": "v3", "created": "Sun, 26 Nov 2017 10:06:57 GMT"}], "update_date": "2017-11-28", "authors_parsed": [["Yi", "Jinfeng", ""], ["Hsieh", "Cho-Jui", ""], ["Varshney", "Kush", ""], ["Zhang", "Lijun", ""], ["Li", "Yao", ""]]}, {"id": "1702.06354", "submitter": "Makoto Yamada", "authors": "Makoto Yamada, Song Liu, Samuel Kaski", "title": "Interpreting Outliers: Localized Logistic Regression for Density Ratio\n  Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an inlier-based outlier detection method capable of both\nidentifying the outliers and explaining why they are outliers, by identifying\nthe outlier-specific features. Specifically, we employ an inlier-based outlier\ndetection criterion, which uses the ratio of inlier and test probability\ndensities as a measure of plausibility of being an outlier. For estimating the\ndensity ratio function, we propose a localized logistic regression algorithm.\nThanks to the locality of the model, variable selection can be\noutlier-specific, and will help interpret why points are outliers in a\nhigh-dimensional space. Through synthetic experiments, we show that the\nproposed algorithm can successfully detect the important features for outliers.\nMoreover, we show that the proposed algorithm tends to outperform existing\nalgorithms in benchmark datasets.\n", "versions": [{"version": "v1", "created": "Tue, 21 Feb 2017 12:37:35 GMT"}], "update_date": "2017-02-22", "authors_parsed": [["Yamada", "Makoto", ""], ["Liu", "Song", ""], ["Kaski", "Samuel", ""]]}, {"id": "1702.06362", "submitter": "Jinfeng Yi", "authors": "Jinfeng Yi, Qi Lei, Wesley Gifford, Ji Liu, Junchi Yan", "title": "Negative-Unlabeled Tensor Factorization for Location Category Inference\n  from Highly Inaccurate Mobility Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Identifying significant location categories visited by mobile users is the\nkey to a variety of applications. This is an extremely challenging task due to\nthe possible deviation between the estimated location coordinate and the actual\nlocation, which could be on the order of kilometers. To estimate the actual\nlocation category more precisely, we propose a novel tensor factorization\nframework, through several key observations including the intrinsic\ncorrelations between users, to infer the most likely location categories within\nthe location uncertainty circle. In addition, the proposed algorithm can also\npredict where users are even in the absence of location information. In order\nto efficiently solve the proposed framework, we propose a parameter-free and\nscalable optimization algorithm by effectively exploring the sparse and\nlow-rank structure of the tensor. Our empirical studies show that the proposed\nalgorithm is both efficient and effective: it can solve problems with millions\nof users and billions of location updates, and also provides superior\nprediction accuracies on real-world location updates and check-in data sets.\n", "versions": [{"version": "v1", "created": "Tue, 21 Feb 2017 12:55:56 GMT"}, {"version": "v2", "created": "Thu, 9 Mar 2017 01:41:45 GMT"}, {"version": "v3", "created": "Wed, 24 May 2017 07:23:53 GMT"}], "update_date": "2017-05-25", "authors_parsed": [["Yi", "Jinfeng", ""], ["Lei", "Qi", ""], ["Gifford", "Wesley", ""], ["Liu", "Ji", ""], ["Yan", "Junchi", ""]]}, {"id": "1702.06385", "submitter": "Alexander Marx", "authors": "Alexander Marx and Jilles Vreeken", "title": "Causal Inference on Multivariate and Mixed-Type Data", "comments": "9 pages, submitted to sdm", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given data over the joint distribution of two random variables $X$ and $Y$,\nwe consider the problem of inferring the most likely causal direction between\n$X$ and $Y$. In particular, we consider the general case where both $X$ and $Y$\nmay be univariate or multivariate, and of the same or mixed data types. We take\nan information theoretic approach, based on Kolmogorov complexity, from which\nit follows that first describing the data over cause and then that of effect\ngiven cause is shorter than the reverse direction.\n  The ideal score is not computable, but can be approximated through the\nMinimum Description Length (MDL) principle. Based on MDL, we propose two\nscores, one for when both $X$ and $Y$ are of the same single data type, and one\nfor when they are mixed-type. We model dependencies between $X$ and $Y$ using\nclassification and regression trees. As inferring the optimal model is NP-hard,\nwe propose Crack, a fast greedy algorithm to determine the most likely causal\ndirection directly from the data.\n  Empirical evaluation on a wide range of data shows that Crack reliably, and\nwith high accuracy, infers the correct causal direction on both univariate and\nmultivariate cause-effect pairs over both single and mixed-type data.\n", "versions": [{"version": "v1", "created": "Tue, 21 Feb 2017 13:59:23 GMT"}, {"version": "v2", "created": "Mon, 16 Oct 2017 12:18:45 GMT"}], "update_date": "2017-10-17", "authors_parsed": [["Marx", "Alexander", ""], ["Vreeken", "Jilles", ""]]}, {"id": "1702.06392", "submitter": "Yixing Li", "authors": "Yixing Li, Zichuan Liu, Kai Xu, Hao Yu and Fengbo Ren", "title": "A GPU-Outperforming FPGA Accelerator Architecture for Binary\n  Convolutional Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AR cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  FPGA-based hardware accelerators for convolutional neural networks (CNNs)\nhave obtained great attentions due to their higher energy efficiency than GPUs.\nHowever, it is challenging for FPGA-based solutions to achieve a higher\nthroughput than GPU counterparts. In this paper, we demonstrate that FPGA\nacceleration can be a superior solution in terms of both throughput and energy\nefficiency when a CNN is trained with binary constraints on weights and\nactivations. Specifically, we propose an optimized FPGA accelerator\narchitecture tailored for bitwise convolution and normalization that features\nmassive spatial parallelism with deep pipelines stages. A key advantage of the\nFPGA accelerator is that its performance is insensitive to data batch size,\nwhile the performance of GPU acceleration varies largely depending on the batch\nsize of the data. Experiment results show that the proposed accelerator\narchitecture for binary CNNs running on a Virtex-7 FPGA is 8.3x faster and 75x\nmore energy-efficient than a Titan X GPU for processing online individual\nrequests in small batch sizes. For processing static data in large batch sizes,\nthe proposed solution is on a par with a Titan X GPU in terms of throughput\nwhile delivering 9.5x higher energy efficiency.\n", "versions": [{"version": "v1", "created": "Mon, 20 Feb 2017 05:21:34 GMT"}, {"version": "v2", "created": "Thu, 8 Jun 2017 16:09:55 GMT"}], "update_date": "2017-06-09", "authors_parsed": [["Li", "Yixing", ""], ["Liu", "Zichuan", ""], ["Xu", "Kai", ""], ["Yu", "Hao", ""], ["Ren", "Fengbo", ""]]}, {"id": "1702.06457", "submitter": "Martin Jaggi", "authors": "Francesco Locatello, Rajiv Khanna, Michael Tschannen, Martin Jaggi", "title": "A Unified Optimization View on Generalized Matching Pursuit and\n  Frank-Wolfe", "comments": "appearing at AISTATS 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Two of the most fundamental prototypes of greedy optimization are the\nmatching pursuit and Frank-Wolfe algorithms. In this paper, we take a unified\nview on both classes of methods, leading to the first explicit convergence\nrates of matching pursuit methods in an optimization sense, for general sets of\natoms. We derive sublinear ($1/t$) convergence for both classes on general\nsmooth objectives, and linear convergence on strongly convex objectives, as\nwell as a clear correspondence of algorithm variants. Our presented algorithms\nand rates are affine invariant, and do not need any incoherence or sparsity\nassumptions.\n", "versions": [{"version": "v1", "created": "Tue, 21 Feb 2017 16:04:10 GMT"}, {"version": "v2", "created": "Tue, 7 Mar 2017 18:49:43 GMT"}], "update_date": "2017-03-08", "authors_parsed": [["Locatello", "Francesco", ""], ["Khanna", "Rajiv", ""], ["Tschannen", "Michael", ""], ["Jaggi", "Martin", ""]]}, {"id": "1702.06463", "submitter": "Aditya Gilra", "authors": "Aditya Gilra, Wulfram Gerstner", "title": "Predicting non-linear dynamics by stable local learning in a recurrent\n  spiking neural network", "comments": null, "journal-ref": "eLife 2017;6:e28295", "doi": "10.7554/eLife.28295", "report-no": null, "categories": "q-bio.NC cs.LG cs.NE cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Brains need to predict how the body reacts to motor commands. It is an open\nquestion how networks of spiking neurons can learn to reproduce the non-linear\nbody dynamics caused by motor commands, using local, online and stable learning\nrules. Here, we present a supervised learning scheme for the feedforward and\nrecurrent connections in a network of heterogeneous spiking neurons. The error\nin the output is fed back through fixed random connections with a negative\ngain, causing the network to follow the desired dynamics, while an online and\nlocal rule changes the weights. The rule for Feedback-based Online Local\nLearning Of Weights (FOLLOW) is local in the sense that weight changes depend\non the presynaptic activity and the error signal projected onto the\npostsynaptic neuron. We provide examples of learning linear, non-linear and\nchaotic dynamics, as well as the dynamics of a two-link arm. Using the Lyapunov\nmethod, and under reasonable assumptions and approximations, we show that\nFOLLOW learning is stable uniformly, with the error going to zero\nasymptotically.\n", "versions": [{"version": "v1", "created": "Tue, 21 Feb 2017 16:15:34 GMT"}, {"version": "v2", "created": "Wed, 26 Apr 2017 17:58:00 GMT"}], "update_date": "2017-11-30", "authors_parsed": [["Gilra", "Aditya", ""], ["Gerstner", "Wulfram", ""]]}, {"id": "1702.06506", "submitter": "Aayush Bansal", "authors": "Aayush Bansal, Xinlei Chen, Bryan Russell, Abhinav Gupta, Deva Ramanan", "title": "PixelNet: Representation of the pixels, by the pixels, and for the\n  pixels", "comments": "Project Page: http://www.cs.cmu.edu/~aayushb/pixelNet/. arXiv admin\n  note: substantial text overlap with arXiv:1609.06694", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore design principles for general pixel-level prediction problems,\nfrom low-level edge detection to mid-level surface normal estimation to\nhigh-level semantic segmentation. Convolutional predictors, such as the\nfully-convolutional network (FCN), have achieved remarkable success by\nexploiting the spatial redundancy of neighboring pixels through convolutional\nprocessing. Though computationally efficient, we point out that such approaches\nare not statistically efficient during learning precisely because spatial\nredundancy limits the information learned from neighboring pixels. We\ndemonstrate that stratified sampling of pixels allows one to (1) add diversity\nduring batch updates, speeding up learning; (2) explore complex nonlinear\npredictors, improving accuracy; and (3) efficiently train state-of-the-art\nmodels tabula rasa (i.e., \"from scratch\") for diverse pixel-labeling tasks. Our\nsingle architecture produces state-of-the-art results for semantic segmentation\non PASCAL-Context dataset, surface normal estimation on NYUDv2 depth dataset,\nand edge detection on BSDS.\n", "versions": [{"version": "v1", "created": "Tue, 21 Feb 2017 18:20:30 GMT"}], "update_date": "2017-02-27", "authors_parsed": [["Bansal", "Aayush", ""], ["Chen", "Xinlei", ""], ["Russell", "Bryan", ""], ["Gupta", "Abhinav", ""], ["Ramanan", "Deva", ""]]}, {"id": "1702.06533", "submitter": "Weiran Wang", "authors": "Chao Gao, Dan Garber, Nathan Srebro, Jialei Wang, Weiran Wang", "title": "Stochastic Canonical Correlation Analysis", "comments": "Accepted by JMLR", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the sample complexity of canonical correlation analysis (CCA), \\ie,\nthe number of samples needed to estimate the population canonical correlation\nand directions up to arbitrarily small error. With mild assumptions on the data\ndistribution, we show that in order to achieve $\\epsilon$-suboptimality in a\nproperly defined measure of alignment between the estimated canonical\ndirections and the population solution, we can solve the empirical objective\nexactly with $N(\\epsilon, \\Delta, \\gamma)$ samples, where $\\Delta$ is the\nsingular value gap of the whitened cross-covariance matrix and $1/\\gamma$ is an\nupper bound of the condition number of auto-covariance matrices. Moreover, we\ncan achieve the same learning accuracy by drawing the same level of samples and\nsolving the empirical objective approximately with a stochastic optimization\nalgorithm; this algorithm is based on the shift-and-invert power iterations and\nonly needs to process the dataset for $\\mathcal{O}\\left(\\log \\frac{1}{\\epsilon}\n\\right)$ passes. Finally, we show that, given an estimate of the canonical\ncorrelation, the streaming version of the shift-and-invert power iterations\nachieves the same learning accuracy with the same level of sample complexity,\nby processing the data only once.\n", "versions": [{"version": "v1", "created": "Tue, 21 Feb 2017 04:23:41 GMT"}, {"version": "v2", "created": "Mon, 21 Oct 2019 16:21:26 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Gao", "Chao", ""], ["Garber", "Dan", ""], ["Srebro", "Nathan", ""], ["Wang", "Jialei", ""], ["Wang", "Weiran", ""]]}, {"id": "1702.06559", "submitter": "Mark Woodward", "authors": "Mark Woodward and Chelsea Finn", "title": "Active One-shot Learning", "comments": "NIPS 2016, Deep Reinforcement Learning Workshop, Barcelona, Spain.\n  See https://cs.stanford.edu/~woodward/ for the poster and a short video\n  description of the paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in one-shot learning have produced models that can learn from\na handful of labeled examples, for passive classification and regression tasks.\nThis paper combines reinforcement learning with one-shot learning, allowing the\nmodel to decide, during classification, which examples are worth labeling. We\nintroduce a classification task in which a stream of images are presented and,\non each time step, a decision must be made to either predict a label or pay to\nreceive the correct label. We present a recurrent neural network based\naction-value function, and demonstrate its ability to learn how and when to\nrequest labels. Through the choice of reward function, the model can achieve a\nhigher prediction accuracy than a similar model on a purely supervised task, or\ntrade prediction accuracy for fewer label requests.\n", "versions": [{"version": "v1", "created": "Tue, 21 Feb 2017 19:31:46 GMT"}], "update_date": "2017-02-23", "authors_parsed": [["Woodward", "Mark", ""], ["Finn", "Chelsea", ""]]}, {"id": "1702.06602", "submitter": "Hongyu Guo", "authors": "Martin Renqiang Min, Hongyu Guo, Dongjin Song", "title": "Exemplar-Centered Supervised Shallow Parametric Data Embedding", "comments": "accepted to IJCAI2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Metric learning methods for dimensionality reduction in combination with\nk-Nearest Neighbors (kNN) have been extensively deployed in many\nclassification, data embedding, and information retrieval applications.\nHowever, most of these approaches involve pairwise training data comparisons,\nand thus have quadratic computational complexity with respect to the size of\ntraining set, preventing them from scaling to fairly big datasets. Moreover,\nduring testing, comparing test data against all the training data points is\nalso expensive in terms of both computational cost and resources required.\nFurthermore, previous metrics are either too constrained or too expressive to\nbe well learned. To effectively solve these issues, we present an\nexemplar-centered supervised shallow parametric data embedding model, using a\nMaximally Collapsing Metric Learning (MCML) objective. Our strategy learns a\nshallow high-order parametric embedding function and compares training/test\ndata only with learned or precomputed exemplars, resulting in a cost function\nwith linear computational complexity for both training and testing. We also\nempirically demonstrate, using several benchmark datasets, that for\nclassification in two-dimensional embedding space, our approach not only gains\nspeedup of kNN by hundreds of times, but also outperforms state-of-the-art\nsupervised embedding approaches.\n", "versions": [{"version": "v1", "created": "Tue, 21 Feb 2017 22:05:13 GMT"}, {"version": "v2", "created": "Wed, 5 Jul 2017 19:19:11 GMT"}], "update_date": "2017-07-07", "authors_parsed": [["Min", "Martin Renqiang", ""], ["Guo", "Hongyu", ""], ["Song", "Dongjin", ""]]}, {"id": "1702.06676", "submitter": "Nicholas Guttenberg", "authors": "Nicholas Guttenberg, Yen Yu, Ryota Kanai", "title": "Counterfactual Control for Free from Generative Models", "comments": "6 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a method by which a generative model learning the joint\ndistribution between actions and future states can be used to automatically\ninfer a control scheme for any desired reward function, which may be altered on\nthe fly without retraining the model. In this method, the problem of action\nselection is reduced to one of gradient descent on the latent space of the\ngenerative model, with the model itself providing the means of evaluating\noutcomes and finding the gradient, much like how the reward network in Deep\nQ-Networks (DQN) provides gradient information for the action generator. Unlike\nDQN or Actor-Critic, which are conditional models for a specific reward, using\na generative model of the full joint distribution permits the reward to be\nchanged on the fly. In addition, the generated futures can be inspected to gain\ninsight in to what the network 'thinks' will happen, and to what went wrong\nwhen the outcomes deviate from prediction.\n", "versions": [{"version": "v1", "created": "Wed, 22 Feb 2017 04:50:47 GMT"}, {"version": "v2", "created": "Thu, 9 Mar 2017 06:35:45 GMT"}], "update_date": "2017-03-10", "authors_parsed": [["Guttenberg", "Nicholas", ""], ["Yu", "Yen", ""], ["Kanai", "Ryota", ""]]}, {"id": "1702.06712", "submitter": "Atif Raza", "authors": "Atif Raza and Stefan Kramer", "title": "Ensembles of Randomized Time Series Shapelets Provide Improved Accuracy\n  while Reducing Computational Costs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Shapelets are discriminative time series subsequences that allow generation\nof interpretable classification models, which provide faster and generally\nbetter classification than the nearest neighbor approach. However, the shapelet\ndiscovery process requires the evaluation of all possible subsequences of all\ntime series in the training set, making it extremely computation intensive.\nConsequently, shapelet discovery for large time series datasets quickly becomes\nintractable. A number of improvements have been proposed to reduce the training\ntime. These techniques use approximation or discretization and often lead to\nreduced classification accuracy compared to the exact method.\n  We are proposing the use of ensembles of shapelet-based classifiers obtained\nusing random sampling of the shapelet candidates. Using random sampling reduces\nthe number of evaluated candidates and consequently the required computational\ncost, while the classification accuracy of the resulting models is also not\nsignificantly different than that of the exact algorithm. The combination of\nrandomized classifiers rectifies the inaccuracies of individual models because\nof the diversity of the solutions. Based on the experiments performed, it is\nshown that the proposed approach of using an ensemble of inexpensive\nclassifiers provides better classification accuracy compared to the exact\nmethod at a significantly lesser computational cost.\n", "versions": [{"version": "v1", "created": "Wed, 22 Feb 2017 09:07:00 GMT"}], "update_date": "2017-02-23", "authors_parsed": [["Raza", "Atif", ""], ["Kramer", "Stefan", ""]]}, {"id": "1702.06760", "submitter": "Yanjun  Qi Dr.", "authors": "Jack Lanchantin, Ritambhara Singh, Yanjun Qi", "title": "Memory Matching Networks for Genomic Sequence Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-bio.GN stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When analyzing the genome, researchers have discovered that proteins bind to\nDNA based on certain patterns of the DNA sequence known as \"motifs\". However,\nit is difficult to manually construct motifs due to their complexity. Recently,\nexternally learned memory models have proven to be effective methods for\nreasoning over inputs and supporting sets. In this work, we present memory\nmatching networks (MMN) for classifying DNA sequences as protein binding sites.\nOur model learns a memory bank of encoded motifs, which are dynamic memory\nmodules, and then matches a new test sequence to each of the motifs to classify\nthe sequence as a binding or nonbinding site.\n", "versions": [{"version": "v1", "created": "Wed, 22 Feb 2017 11:37:49 GMT"}], "update_date": "2017-02-23", "authors_parsed": [["Lanchantin", "Jack", ""], ["Singh", "Ritambhara", ""], ["Qi", "Yanjun", ""]]}, {"id": "1702.06762", "submitter": "Yanjun  Qi Dr.", "authors": "Muthuraman Chidambaram, Yanjun Qi", "title": "Style Transfer Generative Adversarial Networks: Learning to Play Chess\n  Differently", "comments": "style transfer, Generative Adversarial Networks", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The idea of style transfer has largely only been explored in image-based\ntasks, which we attribute in part to the specific nature of loss functions used\nfor style transfer. We propose a general formulation of style transfer as an\nextension of generative adversarial networks, by using a discriminator to\nregularize a generator with an otherwise separate loss function. We apply our\napproach to the task of learning to play chess in the style of a specific\nplayer, and present empirical evidence for the viability of our approach.\n", "versions": [{"version": "v1", "created": "Wed, 22 Feb 2017 11:43:50 GMT"}, {"version": "v2", "created": "Sun, 7 May 2017 13:42:01 GMT"}], "update_date": "2017-05-09", "authors_parsed": [["Chidambaram", "Muthuraman", ""], ["Qi", "Yanjun", ""]]}, {"id": "1702.06763", "submitter": "Ji Gao", "authors": "Ji Gao, Beilun Wang, Zeming Lin, Weilin Xu, Yanjun Qi", "title": "DeepCloak: Masking Deep Neural Network Models for Robustness Against\n  Adversarial Samples", "comments": "adversarial samples, deep neural network", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent studies have shown that deep neural networks (DNN) are vulnerable to\nadversarial samples: maliciously-perturbed samples crafted to yield incorrect\nmodel outputs. Such attacks can severely undermine DNN systems, particularly in\nsecurity-sensitive settings. It was observed that an adversary could easily\ngenerate adversarial samples by making a small perturbation on irrelevant\nfeature dimensions that are unnecessary for the current classification task. To\novercome this problem, we introduce a defensive mechanism called DeepCloak. By\nidentifying and removing unnecessary features in a DNN model, DeepCloak limits\nthe capacity an attacker can use generating adversarial samples and therefore\nincrease the robustness against such inputs. Comparing with other defensive\napproaches, DeepCloak is easy to implement and computationally efficient.\nExperimental results show that DeepCloak can increase the performance of\nstate-of-the-art DNN models against adversarial samples.\n", "versions": [{"version": "v1", "created": "Wed, 22 Feb 2017 11:48:35 GMT"}, {"version": "v2", "created": "Wed, 1 Mar 2017 05:55:00 GMT"}, {"version": "v3", "created": "Thu, 2 Mar 2017 16:42:12 GMT"}, {"version": "v4", "created": "Wed, 8 Mar 2017 17:18:19 GMT"}, {"version": "v5", "created": "Fri, 10 Mar 2017 00:02:04 GMT"}, {"version": "v6", "created": "Tue, 21 Mar 2017 16:26:33 GMT"}, {"version": "v7", "created": "Sat, 25 Mar 2017 22:16:05 GMT"}, {"version": "v8", "created": "Mon, 17 Apr 2017 21:54:30 GMT"}], "update_date": "2017-04-28", "authors_parsed": [["Gao", "Ji", ""], ["Wang", "Beilun", ""], ["Lin", "Zeming", ""], ["Xu", "Weilin", ""], ["Qi", "Yanjun", ""]]}, {"id": "1702.06776", "submitter": "Kailash Budhathoki", "authors": "Kailash Budhathoki and Jilles Vreeken", "title": "Causal Inference by Stochastic Complexity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The algorithmic Markov condition states that the most likely causal direction\nbetween two random variables X and Y can be identified as that direction with\nthe lowest Kolmogorov complexity. Due to the halting problem, however, this\nnotion is not computable.\n  We hence propose to do causal inference by stochastic complexity. That is, we\npropose to approximate Kolmogorov complexity via the Minimum Description Length\n(MDL) principle, using a score that is mini-max optimal with regard to the\nmodel class under consideration. This means that even in an adversarial\nsetting, such as when the true distribution is not in this class, we still\nobtain the optimal encoding for the data relative to the class.\n  We instantiate this framework, which we call CISC, for pairs of univariate\ndiscrete variables, using the class of multinomial distributions. Experiments\nshow that CISC is highly accurate on synthetic, benchmark, as well as\nreal-world data, outperforming the state of the art by a margin, and scales\nextremely well with regard to sample and domain sizes.\n", "versions": [{"version": "v1", "created": "Wed, 22 Feb 2017 12:36:21 GMT"}], "update_date": "2017-02-23", "authors_parsed": [["Budhathoki", "Kailash", ""], ["Vreeken", "Jilles", ""]]}, {"id": "1702.06818", "submitter": "Poorya Mianjy", "authors": "Raman Arora and Teodor V. Marinov and Poorya Mianjy and Nathan Srebro", "title": "Stochastic Approximation for Canonical Correlation Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose novel first-order stochastic approximation algorithms for\ncanonical correlation analysis (CCA). Algorithms presented are instances of\ninexact matrix stochastic gradient (MSG) and inexact matrix exponentiated\ngradient (MEG), and achieve $\\epsilon$-suboptimality in the population\nobjective in $\\operatorname{poly}(\\frac{1}{\\epsilon})$ iterations. We also\nconsider practical variants of the proposed algorithms and compare them with\nother methods for CCA both theoretically and empirically.\n", "versions": [{"version": "v1", "created": "Wed, 22 Feb 2017 14:45:02 GMT"}, {"version": "v2", "created": "Mon, 26 Feb 2018 16:52:53 GMT"}], "update_date": "2018-02-27", "authors_parsed": [["Arora", "Raman", ""], ["Marinov", "Teodor V.", ""], ["Mianjy", "Poorya", ""], ["Srebro", "Nathan", ""]]}, {"id": "1702.06819", "submitter": "Mohammad Raihanul Islam", "authors": "Mohammad Raihanul Islam and B. Aditya Prakash and Naren Ramakrishnan", "title": "Distributed Representations of Signed Networks", "comments": "Published in PAKDD 2018", "journal-ref": null, "doi": "10.1007/978-3-319-93037-4_13", "report-no": null, "categories": "stat.ML cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent successes in word embedding and document embedding have motivated\nresearchers to explore similar representations for networks and to use such\nrepresentations for tasks such as edge prediction, node label prediction, and\ncommunity detection. Such network embedding methods are largely focused on\nfinding distributed representations for unsigned networks and are unable to\ndiscover embeddings that respect polarities inherent in edges. We propose\nSIGNet, a fast scalable embedding method suitable for signed networks. Our\nproposed objective function aims to carefully model the social structure\nimplicit in signed networks by reinforcing the principles of social balance\ntheory. Our method builds upon the traditional word2vec family of embedding\napproaches and adds a new targeted node sampling strategy to maintain\nstructural balance in higher-order neighborhoods. We demonstrate the\nsuperiority of SIGNet over state-of-the-art methods proposed for both signed\nand unsigned networks on several real world datasets from different domains. In\nparticular, SIGNet offers an approach to generate a richer vocabulary of\nfeatures of signed networks to support representation and reasoning.\n", "versions": [{"version": "v1", "created": "Wed, 22 Feb 2017 14:51:48 GMT"}, {"version": "v2", "created": "Sat, 27 May 2017 02:51:37 GMT"}, {"version": "v3", "created": "Sat, 3 Jun 2017 15:31:59 GMT"}, {"version": "v4", "created": "Thu, 22 Mar 2018 17:23:06 GMT"}, {"version": "v5", "created": "Mon, 8 Apr 2019 01:30:49 GMT"}], "update_date": "2019-04-09", "authors_parsed": [["Islam", "Mohammad Raihanul", ""], ["Prakash", "B. Aditya", ""], ["Ramakrishnan", "Naren", ""]]}, {"id": "1702.06832", "submitter": "Jernej Kos", "authors": "Jernej Kos, Ian Fischer, Dawn Song", "title": "Adversarial examples for generative models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore methods of producing adversarial examples on deep generative\nmodels such as the variational autoencoder (VAE) and the VAE-GAN. Deep learning\narchitectures are known to be vulnerable to adversarial examples, but previous\nwork has focused on the application of adversarial examples to classification\ntasks. Deep generative models have recently become popular due to their ability\nto model input data distributions and generate realistic examples from those\ndistributions. We present three classes of attacks on the VAE and VAE-GAN\narchitectures and demonstrate them against networks trained on MNIST, SVHN and\nCelebA. Our first attack leverages classification-based adversaries by\nattaching a classifier to the trained encoder of the target generative model,\nwhich can then be used to indirectly manipulate the latent representation. Our\nsecond attack directly uses the VAE loss function to generate a target\nreconstruction image from the adversarial example. Our third attack moves\nbeyond relying on classification or the standard loss for the gradient and\ndirectly optimizes against differences in source and target latent\nrepresentations. We also motivate why an attacker might be interested in\ndeploying such techniques against a target generative network.\n", "versions": [{"version": "v1", "created": "Wed, 22 Feb 2017 15:11:25 GMT"}], "update_date": "2017-02-23", "authors_parsed": [["Kos", "Jernej", ""], ["Fischer", "Ian", ""], ["Song", "Dawn", ""]]}, {"id": "1702.06850", "submitter": "Jobin Wilson", "authors": "Jobin Wilson and Muhammad Arif", "title": "Scene Recognition by Combining Local and Global Image Descriptors", "comments": "A full implementation of our model is available at\n  https://github.com/flytxtds/scene-recognition", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Object recognition is an important problem in computer vision, having diverse\napplications. In this work, we construct an end-to-end scene recognition\npipeline consisting of feature extraction, encoding, pooling and\nclassification. Our approach simultaneously utilize global feature descriptors\nas well as local feature descriptors from images, to form a hybrid feature\ndescriptor corresponding to each image. We utilize DAISY features associated\nwith key points within images as our local feature descriptor and histogram of\noriented gradients (HOG) corresponding to an entire image as a global\ndescriptor. We make use of a bag-of-visual-words encoding and apply Mini- Batch\nK-Means algorithm to reduce the complexity of our feature encoding scheme. A\n2-level pooling procedure is used to combine DAISY and HOG features\ncorresponding to each image. Finally, we experiment with a multi-class SVM\nclassifier with several kernels, in a cross-validation setting, and tabulate\nour results on the fifteen scene categories dataset. The average accuracy of\nour model was 76.4% in the case of a 40%-60% random split of images into\ntraining and testing datasets respectively. The primary objective of this work\nis to clearly outline the practical implementation of a basic\nscrene-recognition pipeline having a reasonable accuracy, in python, using\nopen-source libraries. A full implementation of the proposed model is available\nin our github repository.\n", "versions": [{"version": "v1", "created": "Tue, 21 Feb 2017 06:57:37 GMT"}], "update_date": "2017-02-23", "authors_parsed": [["Wilson", "Jobin", ""], ["Arif", "Muhammad", ""]]}, {"id": "1702.06856", "submitter": "Christian Gagn\\'e", "authors": "Mahdieh Abbasi and Christian Gagn\\'e", "title": "Robustness to Adversarial Examples through an Ensemble of Specialists", "comments": "Submitted to ICLR 2017 Workshop Track", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We are proposing to use an ensemble of diverse specialists, where speciality\nis defined according to the confusion matrix. Indeed, we observed that for\nadversarial instances originating from a given class, labeling tend to be done\ninto a small subset of (incorrect) classes. Therefore, we argue that an\nensemble of specialists should be better able to identify and reject fooling\ninstances, with a high entropy (i.e., disagreement) over the decisions in the\npresence of adversaries. Experimental results obtained confirm that\ninterpretation, opening a way to make the system more robust to adversarial\nexamples through a rejection mechanism, rather than trying to classify them\nproperly at any cost.\n", "versions": [{"version": "v1", "created": "Wed, 22 Feb 2017 15:37:50 GMT"}, {"version": "v2", "created": "Tue, 28 Feb 2017 05:14:14 GMT"}, {"version": "v3", "created": "Fri, 10 Mar 2017 04:10:18 GMT"}], "update_date": "2017-03-13", "authors_parsed": [["Abbasi", "Mahdieh", ""], ["Gagn\u00e9", "Christian", ""]]}, {"id": "1702.06861", "submitter": "Simon Du", "authors": "Simon S. Du and Yining Wang and Aarti Singh", "title": "On the Power of Truncated SVD for General High-rank Matrix Estimation\n  Problems", "comments": "Accepted by NIPS 2017. Add gap-dependent bounds", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that given an estimate $\\widehat{A}$ that is close to a general\nhigh-rank positive semi-definite (PSD) matrix $A$ in spectral norm (i.e.,\n$\\|\\widehat{A}-A\\|_2 \\leq \\delta$), the simple truncated SVD of $\\widehat{A}$\nproduces a multiplicative approximation of $A$ in Frobenius norm. This\nobservation leads to many interesting results on general high-rank matrix\nestimation problems, which we briefly summarize below ($A$ is an $n\\times n$\nhigh-rank PSD matrix and $A_k$ is the best rank-$k$ approximation of $A$):\n  (1) High-rank matrix completion: By observing\n$\\Omega(\\frac{n\\max\\{\\epsilon^{-4},k^2\\}\\mu_0^2\\|A\\|_F^2\\log\nn}{\\sigma_{k+1}(A)^2})$ elements of $A$ where $\\sigma_{k+1}\\left(A\\right)$ is\nthe $\\left(k+1\\right)$-th singular value of $A$ and $\\mu_0$ is the incoherence,\nthe truncated SVD on a zero-filled matrix satisfies $\\|\\widehat{A}_k-A\\|_F \\leq\n(1+O(\\epsilon))\\|A-A_k\\|_F$ with high probability.\n  (2)High-rank matrix de-noising: Let $\\widehat{A}=A+E$ where $E$ is a Gaussian\nrandom noise matrix with zero mean and $\\nu^2/n$ variance on each entry. Then\nthe truncated SVD of $\\widehat{A}$ satisfies $\\|\\widehat{A}_k-A\\|_F \\leq\n(1+O(\\sqrt{\\nu/\\sigma_{k+1}(A)}))\\|A-A_k\\|_F + O(\\sqrt{k}\\nu)$.\n  (3) Low-rank Estimation of high-dimensional covariance: Given $N$\ni.i.d.~samples $X_1,\\cdots,X_N\\sim\\mathcal N_n(0,A)$, can we estimate $A$ with\na relative-error Frobenius norm bound? We show that if $N =\n\\Omega\\left(n\\max\\{\\epsilon^{-4},k^2\\}\\gamma_k(A)^2\\log N\\right)$ for\n$\\gamma_k(A)=\\sigma_1(A)/\\sigma_{k+1}(A)$, then $\\|\\widehat{A}_k-A\\|_F \\leq\n(1+O(\\epsilon))\\|A-A_k\\|_F$ with high probability, where\n$\\widehat{A}=\\frac{1}{N}\\sum_{i=1}^N{X_iX_i^\\top}$ is the sample covariance.\n", "versions": [{"version": "v1", "created": "Wed, 22 Feb 2017 15:43:15 GMT"}, {"version": "v2", "created": "Sun, 5 Nov 2017 16:15:43 GMT"}], "update_date": "2017-11-07", "authors_parsed": [["Du", "Simon S.", ""], ["Wang", "Yining", ""], ["Singh", "Aarti", ""]]}, {"id": "1702.06879", "submitter": "Th\\'eo Trouillon", "authors": "Th\\'eo Trouillon, Christopher R. Dance, Johannes Welbl, Sebastian\n  Riedel, \\'Eric Gaussier, Guillaume Bouchard", "title": "Knowledge Graph Completion via Complex Tensor Factorization", "comments": "38 pages, accepted in JMLR. This is an extended version of the\n  article \"Complex embeddings for simple link prediction\" (ICML 2016)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG math.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In statistical relational learning, knowledge graph completion deals with\nautomatically understanding the structure of large knowledge graphs---labeled\ndirected graphs---and predicting missing relationships---labeled edges.\nState-of-the-art embedding models propose different trade-offs between modeling\nexpressiveness, and time and space complexity. We reconcile both expressiveness\nand complexity through the use of complex-valued embeddings and explore the\nlink between such complex-valued embeddings and unitary diagonalization. We\ncorroborate our approach theoretically and show that all real square\nmatrices---thus all possible relation/adjacency matrices---are the real part of\nsome unitarily diagonalizable matrix. This results opens the door to a lot of\nother applications of square matrices factorization. Our approach based on\ncomplex embeddings is arguably simple, as it only involves a Hermitian dot\nproduct, the complex counterpart of the standard dot product between real\nvectors, whereas other methods resort to more and more complicated composition\nfunctions to increase their expressiveness. The proposed complex embeddings are\nscalable to large data sets as it remains linear in both space and time, while\nconsistently outperforming alternative approaches on standard link prediction\nbenchmarks.\n", "versions": [{"version": "v1", "created": "Wed, 22 Feb 2017 16:28:11 GMT"}, {"version": "v2", "created": "Sun, 26 Nov 2017 20:39:34 GMT"}], "update_date": "2017-11-28", "authors_parsed": [["Trouillon", "Th\u00e9o", ""], ["Dance", "Christopher R.", ""], ["Welbl", "Johannes", ""], ["Riedel", "Sebastian", ""], ["Gaussier", "\u00c9ric", ""], ["Bouchard", "Guillaume", ""]]}, {"id": "1702.06890", "submitter": "Hongyang Li", "authors": "Yu Liu and Hongyang Li and Xiaogang Wang", "title": "Learning Deep Features via Congenerous Cosine Loss for Person\n  Recognition", "comments": "Post-rebuttal update. Add some comparison results; correct some\n  technical part; rewrite some sections to make it more readable; code link\n  available", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Person recognition aims at recognizing the same identity across time and\nspace with complicated scenes and similar appearance. In this paper, we propose\na novel method to address this task by training a network to obtain robust and\nrepresentative features. The intuition is that we directly compare and optimize\nthe cosine distance between two features - enlarging inter-class distinction as\nwell as alleviating inner-class variance. We propose a congenerous cosine loss\nby minimizing the cosine distance between samples and their cluster centroid in\na cooperative way. Such a design reduces the complexity and could be\nimplemented via softmax with normalized inputs. Our method also differs from\nprevious work in person recognition that we do not conduct a second training on\nthe test subset. The identity of a person is determined by measuring the\nsimilarity from several body regions in the reference set. Experimental results\nshow that the proposed approach achieves better classification accuracy against\nprevious state-of-the-arts.\n", "versions": [{"version": "v1", "created": "Wed, 22 Feb 2017 16:45:48 GMT"}, {"version": "v2", "created": "Fri, 31 Mar 2017 17:27:50 GMT"}], "update_date": "2017-04-03", "authors_parsed": [["Liu", "Yu", ""], ["Li", "Hongyang", ""], ["Wang", "Xiaogang", ""]]}, {"id": "1702.06899", "submitter": "Philipp Thomann", "authors": "Ingo Steinwart and Philipp Thomann", "title": "liquidSVM: A Fast and Versatile SVM package", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  liquidSVM is a package written in C++ that provides SVM-type solvers for\nvarious classification and regression tasks. Because of a fully integrated\nhyper-parameter selection, very carefully implemented solvers, multi-threading\nand GPU support, and several built-in data decomposition strategies it provides\nunprecedented speed for small training sizes as well as for data sets of tens\nof millions of samples. Besides the C++ API and a command line interface,\nbindings to R, MATLAB, Java, Python, and Spark are available. We present a\nbrief description of the package and report experimental comparisons to other\nSVM packages.\n", "versions": [{"version": "v1", "created": "Wed, 22 Feb 2017 17:17:26 GMT"}], "update_date": "2017-02-23", "authors_parsed": [["Steinwart", "Ingo", ""], ["Thomann", "Philipp", ""]]}, {"id": "1702.06914", "submitter": "Colin Raffel", "authors": "Colin Raffel and Dieterich Lawson", "title": "Training a Subsampling Mechanism in Expectation", "comments": "Camera-ready version. Includes additional figures in an appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a mechanism for subsampling sequences and show how to compute its\nexpected output so that it can be trained with standard backpropagation. We\ntest this approach on a simple toy problem and discuss its shortcomings.\n", "versions": [{"version": "v1", "created": "Wed, 22 Feb 2017 17:54:03 GMT"}, {"version": "v2", "created": "Fri, 10 Mar 2017 18:53:32 GMT"}, {"version": "v3", "created": "Sat, 8 Apr 2017 00:40:26 GMT"}], "update_date": "2017-04-11", "authors_parsed": [["Raffel", "Colin", ""], ["Lawson", "Dieterich", ""]]}, {"id": "1702.06917", "submitter": "Quentin Berthet", "authors": "Quentin Berthet, Vianney Perchet", "title": "Fast Rates for Bandit Optimization with Upper-Confidence Frank-Wolfe", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of bandit optimization, inspired by stochastic\noptimization and online learning problems with bandit feedback. In this\nproblem, the objective is to minimize a global loss function of all the\nactions, not necessarily a cumulative loss. This framework allows us to study a\nvery general class of problems, with applications in statistics, machine\nlearning, and other fields. To solve this problem, we analyze the\nUpper-Confidence Frank-Wolfe algorithm, inspired by techniques for bandits and\nconvex optimization. We give theoretical guarantees for the performance of this\nalgorithm over various classes of functions, and discuss the optimality of\nthese results.\n", "versions": [{"version": "v1", "created": "Wed, 22 Feb 2017 17:55:09 GMT"}, {"version": "v2", "created": "Wed, 6 Sep 2017 16:09:56 GMT"}], "update_date": "2017-09-07", "authors_parsed": [["Berthet", "Quentin", ""], ["Perchet", "Vianney", ""]]}, {"id": "1702.06921", "submitter": "Bijaya Adhikari", "authors": "Bijaya Adhikari, Yao Zhang, Naren Ramakrishnan, and B. Aditya Prakash", "title": "Distributed Representation of Subgraphs", "comments": "9 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network embeddings have become very popular in learning effective feature\nrepresentations of networks. Motivated by the recent successes of embeddings in\nnatural language processing, researchers have tried to find network embeddings\nin order to exploit machine learning algorithms for mining tasks like node\nclassification and edge prediction. However, most of the work focuses on\nfinding distributed representations of nodes, which are inherently ill-suited\nto tasks such as community detection which are intuitively dependent on\nsubgraphs.\n  Here, we propose sub2vec, an unsupervised scalable algorithm to learn feature\nrepresentations of arbitrary subgraphs. We provide means to characterize\nsimilarties between subgraphs and provide theoretical analysis of sub2vec and\ndemonstrate that it preserves the so-called local proximity. We also highlight\nthe usability of sub2vec by leveraging it for network mining tasks, like\ncommunity detection. We show that sub2vec gets significant gains over\nstate-of-the-art methods and node-embedding methods. In particular, sub2vec\noffers an approach to generate a richer vocabulary of features of subgraphs to\nsupport representation and reasoning.\n", "versions": [{"version": "v1", "created": "Wed, 22 Feb 2017 18:06:13 GMT"}], "update_date": "2017-02-23", "authors_parsed": [["Adhikari", "Bijaya", ""], ["Zhang", "Yao", ""], ["Ramakrishnan", "Naren", ""], ["Prakash", "B. Aditya", ""]]}, {"id": "1702.06925", "submitter": "Xiang Xiang", "authors": "Feng Wang, Xiang Xiang, Chang Liu, Trac D. Tran, Austin Reiter,\n  Gregory D. Hager, Harry Quon, Jian Cheng, Alan L. Yuille", "title": "Regularizing Face Verification Nets For Pain Intensity Regression", "comments": "5 pages, 3 figure; Camera-ready version to appear at IEEE ICIP 2017", "journal-ref": null, "doi": "10.13140/RG.2.2.20841.49765", "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Limited labeled data are available for the research of estimating facial\nexpression intensities. For instance, the ability to train deep networks for\nautomated pain assessment is limited by small datasets with labels of\npatient-reported pain intensities. Fortunately, fine-tuning from a\ndata-extensive pre-trained domain, such as face verification, can alleviate\nthis problem. In this paper, we propose a network that fine-tunes a\nstate-of-the-art face verification network using a regularized regression loss\nand additional data with expression labels. In this way, the expression\nintensity regression task can benefit from the rich feature representations\ntrained on a huge amount of data for face verification. The proposed\nregularized deep regressor is applied to estimate the pain expression intensity\nand verified on the widely-used UNBC-McMaster Shoulder-Pain dataset, achieving\nthe state-of-the-art performance. A weighted evaluation metric is also proposed\nto address the imbalance issue of different pain intensities.\n", "versions": [{"version": "v1", "created": "Wed, 22 Feb 2017 18:15:42 GMT"}, {"version": "v2", "created": "Tue, 9 May 2017 17:58:58 GMT"}, {"version": "v3", "created": "Thu, 1 Jun 2017 17:49:56 GMT"}], "update_date": "2017-06-02", "authors_parsed": [["Wang", "Feng", ""], ["Xiang", "Xiang", ""], ["Liu", "Chang", ""], ["Tran", "Trac D.", ""], ["Reiter", "Austin", ""], ["Hager", "Gregory D.", ""], ["Quon", "Harry", ""], ["Cheng", "Jian", ""], ["Yuille", "Alan L.", ""]]}, {"id": "1702.06941", "submitter": "Ai Azuma", "authors": "Ai Azuma, Masashi Shimbo, Yuji Matsumoto", "title": "An Algebraic Formalization of Forward and Forward-backward Algorithms", "comments": "55 pages, in submission to JMLR", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose an algebraic formalization of the two important\nclasses of dynamic programming algorithms called forward and forward-backward\nalgorithms. They are generalized extensively in this study so that a wide range\nof other existing algorithms is subsumed. Forward algorithms generalized in\nthis study subsume the ordinary forward algorithm on trellises for sequence\nlabeling, the inside algorithm on derivation forests for CYK parsing, a\nunidirectional message passing on acyclic factor graphs, the forward mode of\nautomatic differentiation on computation graphs with addition and\nmultiplication, and so on. In addition, we reveal algebraic structures\nunderlying complicated computation with forward algorithms. By the aid of the\nrevealed algebraic structures, we also propose a systematic framework to design\ncomplicated variants of forward algorithms. Forward-backward algorithms\ngeneralized in this study subsume the ordinary forward-backward algorithm on\ntrellises for sequence labeling, the inside-outside algorithm on derivation\nforests for CYK parsing, the sum-product algorithm on acyclic factor graphs,\nthe reverse mode of automatic differentiation (a.k.a. back propagation) on\ncomputation graphs with addition and multiplication, and so on. We also propose\nan algebraic characterization of what can be computed by forward-backward\nalgorithms and elucidate the relationship between forward and forward-backward\nalgorithms.\n", "versions": [{"version": "v1", "created": "Wed, 22 Feb 2017 18:56:44 GMT"}], "update_date": "2017-02-23", "authors_parsed": [["Azuma", "Ai", ""], ["Shimbo", "Masashi", ""], ["Matsumoto", "Yuji", ""]]}, {"id": "1702.06943", "submitter": "Fengan Li", "authors": "Fengan Li, Lingjiao Chen, Yijing Zeng, Arun Kumar, Jeffrey F.\n  Naughton, Jignesh M. Patel, Xi Wu", "title": "Tuple-oriented Compression for Large-scale Mini-batch Stochastic\n  Gradient Descent", "comments": "Accepted to Sigmod 2019", "journal-ref": null, "doi": "10.1145/3299869.3300070", "report-no": null, "categories": "cs.LG cs.DB stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data compression is a popular technique for improving the efficiency of data\nprocessing workloads such as SQL queries and more recently, machine learning\n(ML) with classical batch gradient methods. But the efficacy of such ideas for\nmini-batch stochastic gradient descent (MGD), arguably the workhorse algorithm\nof modern ML, is an open question. MGD's unique data access pattern renders\nprior art, including those designed for batch gradient methods, less effective.\nWe fill this crucial research gap by proposing a new lossless compression\nscheme we call tuple-oriented compression (TOC) that is inspired by an unlikely\nsource, the string/text compression scheme Lempel-Ziv-Welch, but tailored to\nMGD in a way that preserves tuple boundaries within mini-batches. We then\npresent a suite of novel compressed matrix operation execution techniques\ntailored to the TOC compression scheme that operate directly over the\ncompressed data representation and avoid decompression overheads. An extensive\nempirical evaluation with real-world datasets shows that TOC consistently\nachieves substantial compression ratios by up to 51x and reduces runtimes for\nMGD workloads by up to 10.2x in popular ML systems.\n", "versions": [{"version": "v1", "created": "Wed, 22 Feb 2017 18:58:25 GMT"}, {"version": "v2", "created": "Wed, 1 Mar 2017 05:43:41 GMT"}, {"version": "v3", "created": "Sun, 20 Jan 2019 05:13:18 GMT"}], "update_date": "2019-01-23", "authors_parsed": [["Li", "Fengan", ""], ["Chen", "Lingjiao", ""], ["Zeng", "Yijing", ""], ["Kumar", "Arun", ""], ["Naughton", "Jeffrey F.", ""], ["Patel", "Jignesh M.", ""], ["Wu", "Xi", ""]]}, {"id": "1702.06972", "submitter": "Azadeh Khaleghi", "authors": "Steffen Grunewalder and Azadeh Khaleghi", "title": "Approximations of the Restless Bandit Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG math.PR stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The multi-armed restless bandit problem is studied in the case where the\npay-off distributions are stationary $\\varphi$-mixing. This version of the\nproblem provides a more realistic model for most real-world applications, but\ncannot be optimally solved in practice, since it is known to be PSPACE-hard.\nThe objective of this paper is to characterize a sub-class of the problem where\n{\\em good} approximate solutions can be found using tractable approaches.\nSpecifically, it is shown that under some conditions on the $\\varphi$-mixing\ncoefficients, a modified version of UCB can prove effective. The main challenge\nis that, unlike in the i.i.d. setting, the distributions of the sampled\npay-offs may not have the same characteristics as those of the original bandit\narms. In particular, the $\\varphi$-mixing property does not necessarily carry\nover. This is overcome by carefully controlling the effect of a sampling policy\non the pay-off distributions. Some of the proof techniques developed in this\npaper can be more generally used in the context of online sampling under\ndependence. Proposed algorithms are accompanied with corresponding regret\nanalysis.\n", "versions": [{"version": "v1", "created": "Wed, 22 Feb 2017 19:22:55 GMT"}, {"version": "v2", "created": "Thu, 5 Jul 2018 17:17:14 GMT"}, {"version": "v3", "created": "Fri, 28 Dec 2018 14:21:04 GMT"}], "update_date": "2018-12-31", "authors_parsed": [["Grunewalder", "Steffen", ""], ["Khaleghi", "Azadeh", ""]]}, {"id": "1702.06976", "submitter": "Joseph Anderson", "authors": "Joseph Anderson and Navin Goyal and Anupama Nandi and Luis Rademacher", "title": "Heavy-Tailed Analogues of the Covariance Matrix for ICA", "comments": "16 Pages, 9 Figures, AAAI 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Independent Component Analysis (ICA) is the problem of learning a square\nmatrix $A$, given samples of $X=AS$, where $S$ is a random vector with\nindependent coordinates. Most existing algorithms are provably efficient only\nwhen each $S_i$ has finite and moderately valued fourth moment. However, there\nare practical applications where this assumption need not be true, such as\nspeech and finance. Algorithms have been proposed for heavy-tailed ICA, but\nthey are not practical, using random walks and the full power of the ellipsoid\nalgorithm multiple times. The main contributions of this paper are:\n  (1) A practical algorithm for heavy-tailed ICA that we call HTICA. We provide\ntheoretical guarantees and show that it outperforms other algorithms in some\nheavy-tailed regimes, both on real and synthetic data. Like the current\nstate-of-the-art, the new algorithm is based on the centroid body (a first\nmoment analogue of the covariance matrix). Unlike the state-of-the-art, our\nalgorithm is practically efficient. To achieve this, we use explicit analytic\nrepresentations of the centroid body, which bypasses the use of the ellipsoid\nmethod and random walks.\n  (2) We study how heavy tails affect different ICA algorithms, including\nHTICA. Somewhat surprisingly, we show that some algorithms that use the\ncovariance matrix or higher moments can successfully solve a range of ICA\ninstances with infinite second moment. We study this theoretically and\nexperimentally, with both synthetic and real-world heavy-tailed data.\n", "versions": [{"version": "v1", "created": "Wed, 22 Feb 2017 19:27:38 GMT"}], "update_date": "2017-02-24", "authors_parsed": [["Anderson", "Joseph", ""], ["Goyal", "Navin", ""], ["Nandi", "Anupama", ""], ["Rademacher", "Luis", ""]]}, {"id": "1702.06980", "submitter": "Dong Xia", "authors": "Dong Xia and Ming Yuan", "title": "On Polynomial Time Methods for Exact Low Rank Tensor Completion", "comments": "56 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we investigate the sample size requirement for exact recovery\nof a high order tensor of low rank from a subset of its entries. We show that a\ngradient descent algorithm with initial value obtained from a spectral method\ncan, in particular, reconstruct a ${d\\times d\\times d}$ tensor of multilinear\nranks $(r,r,r)$ with high probability from as few as\n$O(r^{7/2}d^{3/2}\\log^{7/2}d+r^7d\\log^6d)$ entries. In the case when the ranks\n$r=O(1)$, our sample size requirement matches those for nuclear norm\nminimization (Yuan and Zhang, 2016a), or alternating least squares assuming\northogonal decomposability (Jain and Oh, 2014). Unlike these earlier\napproaches, however, our method is efficient to compute, easy to implement, and\ndoes not impose extra structures on the tensor. Numerical results are presented\nto further demonstrate the merits of the proposed approach.\n", "versions": [{"version": "v1", "created": "Wed, 22 Feb 2017 19:36:25 GMT"}], "update_date": "2017-02-27", "authors_parsed": [["Xia", "Dong", ""], ["Yuan", "Ming", ""]]}, {"id": "1702.07005", "submitter": "Thomas Parnelll", "authors": "Thomas Parnell, Celestine D\\\"unner, Kubilay Atasu, Manolis Sifalakis\n  and Haris Pozidis", "title": "Large-Scale Stochastic Learning using GPUs", "comments": "Accepted for publication in ParLearning 2017: The 6th International\n  Workshop on Parallel and Distributed Computing for Large Scale Machine\n  Learning and Big Data Analytics, Orlando, Florida, May 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we propose an accelerated stochastic learning system for very\nlarge-scale applications. Acceleration is achieved by mapping the training\nalgorithm onto massively parallel processors: we demonstrate a parallel,\nasynchronous GPU implementation of the widely used stochastic coordinate\ndescent/ascent algorithm that can provide up to 35x speed-up over a sequential\nCPU implementation. In order to train on very large datasets that do not fit\ninside the memory of a single GPU, we then consider techniques for distributed\nstochastic learning. We propose a novel method for optimally aggregating model\nupdates from worker nodes when the training data is distributed either by\nexample or by feature. Using this technique, we demonstrate that one can scale\nout stochastic learning across up to 8 worker nodes without any significant\nloss of training time. Finally, we combine GPU acceleration with the optimized\ndistributed method to train on a dataset consisting of 200 million training\nexamples and 75 million features. We show by scaling out across 4 GPUs, one can\nattain a high degree of training accuracy in around 4 seconds: a 20x speed-up\nin training time compared to a multi-threaded, distributed implementation\nacross 4 CPUs.\n", "versions": [{"version": "v1", "created": "Wed, 22 Feb 2017 21:03:11 GMT"}], "update_date": "2017-02-24", "authors_parsed": [["Parnell", "Thomas", ""], ["D\u00fcnner", "Celestine", ""], ["Atasu", "Kubilay", ""], ["Sifalakis", "Manolis", ""], ["Pozidis", "Haris", ""]]}, {"id": "1702.07013", "submitter": "Hongteng Xu", "authors": "Hongteng Xu, Dixin Luo, Hongyuan Zha", "title": "Learning Hawkes Processes from Short Doubly-Censored Event Sequences", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.PR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many real-world applications require robust algorithms to learn point\nprocesses based on a type of incomplete data --- the so-called short\ndoubly-censored (SDC) event sequences. We study this critical problem of\nquantitative asynchronous event sequence analysis under the framework of Hawkes\nprocesses by leveraging the idea of data synthesis. Given SDC event sequences\nobserved in a variety of time intervals, we propose a sampling-stitching data\nsynthesis method --- sampling predecessors and successors for each SDC event\nsequence from potential candidates and stitching them together to synthesize\nlong training sequences. The rationality and the feasibility of our method are\ndiscussed in terms of arguments based on likelihood. Experiments on both\nsynthetic and real-world data demonstrate that the proposed data synthesis\nmethod improves learning results indeed for both time-invariant and\ntime-varying Hawkes processes.\n", "versions": [{"version": "v1", "created": "Wed, 22 Feb 2017 21:41:05 GMT"}, {"version": "v2", "created": "Wed, 7 Jun 2017 20:36:45 GMT"}], "update_date": "2017-06-09", "authors_parsed": [["Xu", "Hongteng", ""], ["Luo", "Dixin", ""], ["Zha", "Hongyuan", ""]]}, {"id": "1702.07021", "submitter": "Trang Pham", "authors": "Trang Pham, Truyen Tran, Svetha Venkatesh", "title": "One Size Fits Many: Column Bundle for Multi-X Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Much recent machine learning research has been directed towards leveraging\nshared statistics among labels, instances and data views, commonly referred to\nas multi-label, multi-instance and multi-view learning. The underlying premises\nare that there exist correlations among input parts and among output targets,\nand the predictive performance would increase when the correlations are\nincorporated. In this paper, we propose Column Bundle (CLB), a novel deep\nneural network for capturing the shared statistics in data. CLB is generic that\nthe same architecture can be applied for various types of shared statistics by\nchanging only input and output handling. CLB is capable of scaling to thousands\nof input parts and output labels by avoiding explicit modeling of pairwise\nrelations. We evaluate CLB on different types of data: (a) multi-label, (b)\nmulti-view, (c) multi-view/multi-label and (d) multi-instance. CLB demonstrates\na comparable and competitive performance in all datasets against\nstate-of-the-art methods designed specifically for each type.\n", "versions": [{"version": "v1", "created": "Wed, 22 Feb 2017 21:54:12 GMT"}, {"version": "v2", "created": "Tue, 14 Mar 2017 00:44:14 GMT"}], "update_date": "2017-03-16", "authors_parsed": [["Pham", "Trang", ""], ["Tran", "Truyen", ""], ["Venkatesh", "Svetha", ""]]}, {"id": "1702.07028", "submitter": "Holden Lee", "authors": "Holden Lee, Rong Ge, Tengyu Ma, Andrej Risteski, Sanjeev Arora", "title": "On the ability of neural nets to express distributions", "comments": "Accepted to COLT 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural nets have caused a revolution in many classification tasks. A\nrelated ongoing revolution -- also theoretically not understood -- concerns\ntheir ability to serve as generative models for complicated types of data such\nas images and texts. These models are trained using ideas like variational\nautoencoders and Generative Adversarial Networks.\n  We take a first cut at explaining the expressivity of multilayer nets by\ngiving a sufficient criterion for a function to be approximable by a neural\nnetwork with $n$ hidden layers. A key ingredient is Barron's Theorem\n\\cite{Barron1993}, which gives a Fourier criterion for approximability of a\nfunction by a neural network with 1 hidden layer. We show that a composition of\n$n$ functions which satisfy certain Fourier conditions (\"Barron functions\") can\nbe approximated by a $n+1$-layer neural network.\n  For probability distributions, this translates into a criterion for a\nprobability distribution to be approximable in Wasserstein distance -- a\nnatural metric on probability distributions -- by a neural network applied to a\nfixed base distribution (e.g., multivariate gaussian).\n  Building up recent lower bound work, we also give an example function that\nshows that composition of Barron functions is more expressive than Barron\nfunctions alone.\n", "versions": [{"version": "v1", "created": "Wed, 22 Feb 2017 22:21:38 GMT"}, {"version": "v2", "created": "Fri, 2 Jun 2017 15:14:17 GMT"}, {"version": "v3", "created": "Sat, 17 Apr 2021 22:12:27 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Lee", "Holden", ""], ["Ge", "Rong", ""], ["Ma", "Tengyu", ""], ["Risteski", "Andrej", ""], ["Arora", "Sanjeev", ""]]}, {"id": "1702.07064", "submitter": "Ugo Rosolia", "authors": "Ugo Rosolia and Francesco Borrelli", "title": "Learning Model Predictive Control for Iterative Tasks: A Computationally\n  Efficient Approach for Linear System", "comments": "arXiv admin note: substantial text overlap with arXiv:1609.01387", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A Learning Model Predictive Controller (LMPC) for linear system in presented.\nThe proposed controller is an extension of the LMPC [1] and it aims to decrease\nthe computational burden. The control scheme is reference-free and is able to\nimprove its performance by learning from previous iterations. A convex safe set\nand a terminal cost function are used in order to guarantee recursive\nfeasibility and non-increasing performance at each iteration. The paper\npresents the control design approach, and shows how to recursively construct\nthe convex terminal set and the terminal cost from state and input trajectories\nof previous iterations. Simulation results show the effectiveness of the\nproposed control logic.\n", "versions": [{"version": "v1", "created": "Thu, 23 Feb 2017 02:01:00 GMT"}, {"version": "v2", "created": "Wed, 10 May 2017 04:01:12 GMT"}, {"version": "v3", "created": "Fri, 14 Sep 2018 02:51:49 GMT"}, {"version": "v4", "created": "Tue, 29 Oct 2019 20:20:43 GMT"}], "update_date": "2019-10-31", "authors_parsed": [["Rosolia", "Ugo", ""], ["Borrelli", "Francesco", ""]]}, {"id": "1702.07083", "submitter": "Jianfei Chen", "authors": "Jianfei Chen, Jun Zhu, Jie Lu, Shixia Liu", "title": "Scalable Inference for Nested Chinese Restaurant Process Topic Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.DC cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nested Chinese Restaurant Process (nCRP) topic models are powerful\nnonparametric Bayesian methods to extract a topic hierarchy from a given text\ncorpus, where the hierarchical structure is automatically determined by the\ndata. Hierarchical Latent Dirichlet Allocation (hLDA) is a popular instance of\nnCRP topic models. However, hLDA has only been evaluated at small scale,\nbecause the existing collapsed Gibbs sampling and instantiated weight\nvariational inference algorithms either are not scalable or sacrifice inference\nquality with mean-field assumptions. Moreover, an efficient distributed\nimplementation of the data structures, such as dynamically growing count\nmatrices and trees, is challenging.\n  In this paper, we propose a novel partially collapsed Gibbs sampling (PCGS)\nalgorithm, which combines the advantages of collapsed and instantiated weight\nalgorithms to achieve good scalability as well as high model quality. An\ninitialization strategy is presented to further improve the model quality.\nFinally, we propose an efficient distributed implementation of PCGS through\nvectorization, pre-processing, and a careful design of the concurrent data\nstructures and communication strategy.\n  Empirical studies show that our algorithm is 111 times more efficient than\nthe previous open-source implementation for hLDA, with comparable or even\nbetter model quality. Our distributed implementation can extract 1,722 topics\nfrom a 131-million-document corpus with 28 billion tokens, which is 4-5 orders\nof magnitude larger than the previous largest corpus, with 50 machines in 7\nhours.\n", "versions": [{"version": "v1", "created": "Thu, 23 Feb 2017 03:34:07 GMT"}], "update_date": "2017-02-24", "authors_parsed": [["Chen", "Jianfei", ""], ["Zhu", "Jun", ""], ["Lu", "Jie", ""], ["Liu", "Shixia", ""]]}, {"id": "1702.07097", "submitter": "Hongyin Luo", "authors": "Hongyin Luo, Jie Fu, James Glass", "title": "Adaptive Bidirectional Backpropagation: Towards Biologically Plausible\n  Error Signal Transmission in Neural Networks", "comments": "[v2]Extended the paper to the length of a long paper; added\n  references in introduction; corrected the experiments of BFA. [v3] Added link\n  to source code [v4] Added references", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The back-propagation (BP) algorithm has been considered the de-facto method\nfor training deep neural networks. It back-propagates errors from the output\nlayer to the hidden layers in an exact manner using the transpose of the\nfeedforward weights. However, it has been argued that this is not biologically\nplausible because back-propagating error signals with the exact incoming\nweights are not considered possible in biological neural systems. In this work,\nwe propose a biologically plausible paradigm of neural architecture based on\nrelated literature in neuroscience and asymmetric BP-like methods.\nSpecifically, we propose two bidirectional learning algorithms with trainable\nfeedforward and feedback weights. The feedforward weights are used to relay\nactivations from the inputs to target outputs. The feedback weights pass the\nerror signals from the output layer to the hidden layers. Different from other\nasymmetric BP-like methods, the feedback weights are also plastic in our\nframework and are trained to approximate the forward activations. Preliminary\nresults show that our models outperform other asymmetric BP-like methods on the\nMNIST and the CIFAR-10 datasets.\n", "versions": [{"version": "v1", "created": "Thu, 23 Feb 2017 05:00:54 GMT"}, {"version": "v2", "created": "Sun, 26 Feb 2017 16:41:35 GMT"}, {"version": "v3", "created": "Mon, 20 Mar 2017 01:16:07 GMT"}, {"version": "v4", "created": "Sun, 29 Apr 2018 23:53:18 GMT"}], "update_date": "2018-05-01", "authors_parsed": [["Luo", "Hongyin", ""], ["Fu", "Jie", ""], ["Glass", "James", ""]]}, {"id": "1702.07103", "submitter": "Saeid Tizpaz-Niari", "authors": "Saeid Tizpaz-Niari, Pavol Cerny, Bor-Yuh Evan Chang, Sriram\n  Sankaranarayanan, Ashutosh Trivedi", "title": "Discriminating Traces with Time", "comments": "Published in TACAS 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.CR cs.FL cs.LG cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  What properties about the internals of a program explain the possible\ndifferences in its overall running time for different inputs? In this paper, we\npropose a formal framework for considering this question we dub trace-set\ndiscrimination. We show that even though the algorithmic problem of computing\nmaximum likelihood discriminants is NP-hard, approaches based on integer linear\nprogramming (ILP) and decision tree learning can be useful in zeroing-in on the\nprogram internals. On a set of Java benchmarks, we find that\ncompactly-represented decision trees scalably discriminate with high\naccuracy---more scalably than maximum likelihood discriminants and with\ncomparable accuracy. We demonstrate on three larger case studies how\ndecision-tree discriminants produced by our tool are useful for debugging\ntiming side-channel vulnerabilities (i.e., where a malicious observer infers\nsecrets simply from passively watching execution times) and availability\nvulnerabilities.\n", "versions": [{"version": "v1", "created": "Thu, 23 Feb 2017 05:48:22 GMT"}], "update_date": "2017-02-24", "authors_parsed": [["Tizpaz-Niari", "Saeid", ""], ["Cerny", "Pavol", ""], ["Chang", "Bor-Yuh Evan", ""], ["Sankaranarayanan", "Sriram", ""], ["Trivedi", "Ashutosh", ""]]}, {"id": "1702.07121", "submitter": "Assaf Hallak", "authors": "Assaf Hallak and Shie Mannor", "title": "Consistent On-Line Off-Policy Evaluation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of on-line off-policy evaluation (OPE) has been actively studied\nin the last decade due to its importance both as a stand-alone problem and as a\nmodule in a policy improvement scheme. However, most Temporal Difference (TD)\nbased solutions ignore the discrepancy between the stationary distribution of\nthe behavior and target policies and its effect on the convergence limit when\nfunction approximation is applied. In this paper we propose the Consistent\nOff-Policy Temporal Difference (COP-TD($\\lambda$, $\\beta$)) algorithm that\naddresses this issue and reduces this bias at some computational expense. We\nshow that COP-TD($\\lambda$, $\\beta$) can be designed to converge to the same\nvalue that would have been obtained by using on-policy TD($\\lambda$) with the\ntarget policy. Subsequently, the proposed scheme leads to a related and\npromising heuristic we call log-COP-TD($\\lambda$, $\\beta$). Both algorithms\nhave favorable empirical results to the current state of the art on-line OPE\nalgorithms. Finally, our formulation sheds some new light on the recently\nproposed Emphatic TD learning.\n", "versions": [{"version": "v1", "created": "Thu, 23 Feb 2017 07:44:43 GMT"}], "update_date": "2017-02-24", "authors_parsed": [["Hallak", "Assaf", ""], ["Mannor", "Shie", ""]]}, {"id": "1702.07125", "submitter": "Assaf Hallak", "authors": "Assaf Hallak, Yishay Mansour and Elad Yom-Tov", "title": "Automatic Representation for Lifetime Value Recommender Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many modern commercial sites employ recommender systems to propose relevant\ncontent to users. While most systems are focused on maximizing the immediate\ngain (clicks, purchases or ratings), a better notion of success would be the\nlifetime value (LTV) of the user-system interaction. The LTV approach considers\nthe future implications of the item recommendation, and seeks to maximize the\ncumulative gain over time. The Reinforcement Learning (RL) framework is the\nstandard formulation for optimizing cumulative successes over time. However, RL\nis rarely used in practice due to its associated representation, optimization\nand validation techniques which can be complex. In this paper we propose a new\narchitecture for combining RL with recommendation systems which obviates the\nneed for hand-tuned features, thus automating the state-space representation\nconstruction process. We analyze the practical difficulties in this formulation\nand test our solutions on batch off-line real-world recommendation data.\n", "versions": [{"version": "v1", "created": "Thu, 23 Feb 2017 07:59:22 GMT"}], "update_date": "2017-02-24", "authors_parsed": [["Hallak", "Assaf", ""], ["Mansour", "Yishay", ""], ["Yom-Tov", "Elad", ""]]}, {"id": "1702.07186", "submitter": "Derek Greene", "authors": "Mark Belford and Brian Mac Namee and Derek Greene", "title": "Stability of Topic Modeling via Matrix Factorization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Topic models can provide us with an insight into the underlying latent\nstructure of a large corpus of documents. A range of methods have been proposed\nin the literature, including probabilistic topic models and techniques based on\nmatrix factorization. However, in both cases, standard implementations rely on\nstochastic elements in their initialization phase, which can potentially lead\nto different results being generated on the same corpus when using the same\nparameter values. This corresponds to the concept of \"instability\" which has\npreviously been studied in the context of $k$-means clustering. In many\napplications of topic modeling, this problem of instability is not considered\nand topic models are treated as being definitive, even though the results may\nchange considerably if the initialization process is altered. In this paper we\ndemonstrate the inherent instability of popular topic modeling approaches,\nusing a number of new measures to assess stability. To address this issue in\nthe context of matrix factorization for topic modeling, we propose the use of\nensemble learning strategies. Based on experiments performed on annotated text\ncorpora, we show that a K-Fold ensemble strategy, combining both ensembles and\nstructured initialization, can significantly reduce instability, while\nsimultaneously yielding more accurate topic models.\n", "versions": [{"version": "v1", "created": "Thu, 23 Feb 2017 12:00:10 GMT"}, {"version": "v2", "created": "Sat, 9 Sep 2017 17:06:18 GMT"}], "update_date": "2017-09-12", "authors_parsed": [["Belford", "Mark", ""], ["Mac Namee", "Brian", ""], ["Greene", "Derek", ""]]}, {"id": "1702.07211", "submitter": "Pierre Menard", "authors": "Pierre M\\'enard (1), Aur\\'elien Garivier (1) ((1) IMT)", "title": "A minimax and asymptotically optimal algorithm for stochastic bandits", "comments": null, "journal-ref": "Algorithmic Learning Theory, Springer, 2017, 2017 Algorithmic\n  Learning Theory Conference 76", "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose the kl-UCB ++ algorithm for regret minimization in stochastic\nbandit models with exponential families of distributions. We prove that it is\nsimultaneously asymptotically optimal (in the sense of Lai and Robbins' lower\nbound) and minimax optimal. This is the first algorithm proved to enjoy these\ntwo properties at the same time. This work thus merges two different lines of\nresearch with simple and clear proofs.\n", "versions": [{"version": "v1", "created": "Thu, 23 Feb 2017 13:49:57 GMT"}, {"version": "v2", "created": "Wed, 20 Sep 2017 14:26:03 GMT"}], "update_date": "2017-09-21", "authors_parsed": [["M\u00e9nard", "Pierre", "", "IMT"], ["Garivier", "Aur\u00e9lien", "", "IMT"]]}, {"id": "1702.07274", "submitter": "Nir Levine", "authors": "Nir Levine, Koby Crammer, Shie Mannor", "title": "Rotting Bandits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Multi-Armed Bandits (MAB) framework highlights the tension between\nacquiring new knowledge (Exploration) and leveraging available knowledge\n(Exploitation). In the classical MAB problem, a decision maker must choose an\narm at each time step, upon which she receives a reward. The decision maker's\nobjective is to maximize her cumulative expected reward over the time horizon.\nThe MAB problem has been studied extensively, specifically under the assumption\nof the arms' rewards distributions being stationary, or quasi-stationary, over\ntime. We consider a variant of the MAB framework, which we termed Rotting\nBandits, where each arm's expected reward decays as a function of the number of\ntimes it has been pulled. We are motivated by many real-world scenarios such as\nonline advertising, content recommendation, crowdsourcing, and more. We present\nalgorithms, accompanied by simulations, and derive theoretical guarantees.\n", "versions": [{"version": "v1", "created": "Thu, 23 Feb 2017 16:03:30 GMT"}, {"version": "v2", "created": "Fri, 24 Feb 2017 11:09:19 GMT"}, {"version": "v3", "created": "Mon, 12 Jun 2017 13:48:30 GMT"}, {"version": "v4", "created": "Thu, 2 Nov 2017 15:32:09 GMT"}], "update_date": "2017-11-03", "authors_parsed": [["Levine", "Nir", ""], ["Crammer", "Koby", ""], ["Mannor", "Shie", ""]]}, {"id": "1702.07305", "submitter": "Young Hun Jung", "authors": "Young Hun Jung, Jack Goetz, Ambuj Tewari", "title": "Online Multiclass Boosting", "comments": "28 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work has extended the theoretical analysis of boosting algorithms to\nmulticlass problems and to online settings. However, the multiclass extension\nis in the batch setting and the online extensions only consider binary\nclassification. We fill this gap in the literature by defining, and justifying,\na weak learning condition for online multiclass boosting. This condition leads\nto an optimal boosting algorithm that requires the minimal number of weak\nlearners to achieve a certain accuracy. Additionally, we propose an adaptive\nalgorithm which is near optimal and enjoys an excellent performance on real\ndata due to its adaptive property.\n", "versions": [{"version": "v1", "created": "Thu, 23 Feb 2017 17:46:22 GMT"}, {"version": "v2", "created": "Fri, 26 May 2017 01:41:47 GMT"}, {"version": "v3", "created": "Sun, 25 Feb 2018 01:09:26 GMT"}], "update_date": "2018-02-27", "authors_parsed": [["Jung", "Young Hun", ""], ["Goetz", "Jack", ""], ["Tewari", "Ambuj", ""]]}, {"id": "1702.07306", "submitter": "David Lopez-Paz", "authors": "Mateo Rojas-Carulla, Marco Baroni, David Lopez-Paz", "title": "Causal Discovery Using Proxy Variables", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Discovering causal relations is fundamental to reasoning and intelligence. In\nparticular, observational causal discovery algorithms estimate the cause-effect\nrelation between two random entities $X$ and $Y$, given $n$ samples from\n$P(X,Y)$.\n  In this paper, we develop a framework to estimate the cause-effect relation\nbetween two static entities $x$ and $y$: for instance, an art masterpiece $x$\nand its fraudulent copy $y$. To this end, we introduce the notion of proxy\nvariables, which allow the construction of a pair of random entities $(A,B)$\nfrom the pair of static entities $(x,y)$. Then, estimating the cause-effect\nrelation between $A$ and $B$ using an observational causal discovery algorithm\nleads to an estimation of the cause-effect relation between $x$ and $y$. For\nexample, our framework detects the causal relation between unprocessed\nphotographs and their modifications, and orders in time a set of shuffled\nframes from a video.\n  As our main case study, we introduce a human-elicited dataset of 10,000 pairs\nof casually-linked pairs of words from natural language. Our methods discover\n75% of these causal relations. Finally, we discuss the role of proxy variables\nin machine learning, as a general tool to incorporate static knowledge into\nprediction tasks.\n", "versions": [{"version": "v1", "created": "Thu, 23 Feb 2017 17:46:39 GMT"}], "update_date": "2017-02-24", "authors_parsed": [["Rojas-Carulla", "Mateo", ""], ["Baroni", "Marco", ""], ["Lopez-Paz", "David", ""]]}, {"id": "1702.07319", "submitter": "John Pearson", "authors": "Shariq Iqbal and John Pearson", "title": "A Goal-Based Movement Model for Continuous Multi-Agent Tasks", "comments": "New title; substantial simplifications of model", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite increasing attention paid to the need for fast, scalable methods to\nanalyze next-generation neuroscience data, comparatively little attention has\nbeen paid to the development of similar methods for behavioral analysis. Just\nas the volume and complexity of brain data have grown, behavioral paradigms in\nsystems neuroscience have likewise become more naturalistic and less\nconstrained, necessitating an increase in the flexibility and scalability of\nthe models used to study them. In particular, key assumptions made in the\nanalysis of typical decision paradigms --- optimality; analytic tractability;\ndiscrete, low-dimensional action spaces --- may be untenable in richer tasks.\nHere, using the case of a two-player, real-time, continuous strategic game as\nan example, we show how the use of modern machine learning methods allows us to\nrelax each of these assumptions. Following an inverse reinforcement learning\napproach, we are able to succinctly characterize the joint distribution over\nplayers' actions via a generative model that allows us to simulate realistic\ngame play. We compare simulated play from a number of generative time series\nmodels and show that ours successfully resists mode collapse while generating\ntrajectories with the rich variability of real behavior. Together, these\nmethods offer a rich class of models for the analysis of continuous action\ntasks at the single-trial level.\n", "versions": [{"version": "v1", "created": "Thu, 23 Feb 2017 18:09:14 GMT"}, {"version": "v2", "created": "Tue, 31 Oct 2017 20:14:11 GMT"}], "update_date": "2017-11-02", "authors_parsed": [["Iqbal", "Shariq", ""], ["Pearson", "John", ""]]}, {"id": "1702.07339", "submitter": "Emmanouil Zampetakis", "authors": "Constantinos Daskalakis, Christos Tzamos, Manolis Zampetakis", "title": "A Converse to Banach's Fixed Point Theorem and its CLS Completeness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.LG math.GN stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Banach's fixed point theorem for contraction maps has been widely used to\nanalyze the convergence of iterative methods in non-convex problems. It is a\ncommon experience, however, that iterative maps fail to be globally contracting\nunder the natural metric in their domain, making the applicability of Banach's\ntheorem limited. We explore how generally we can apply Banach's fixed point\ntheorem to establish the convergence of iterative methods when pairing it with\ncarefully designed metrics.\n  Our first result is a strong converse of Banach's theorem, showing that it is\na universal analysis tool for establishing global convergence of iterative\nmethods to unique fixed points, and for bounding their convergence rate. In\nother words, we show that, whenever an iterative map globally converges to a\nunique fixed point, there exists a metric under which the iterative map is\ncontracting and which can be used to bound the number of iterations until\nconvergence. We illustrate our approach in the widely used power method,\nproviding a new way of bounding its convergence rate through contraction\narguments.\n  We next consider the computational complexity of Banach's fixed point\ntheorem. Making the proof of our converse theorem constructive, we show that\ncomputing a fixed point whose existence is guaranteed by Banach's fixed point\ntheorem is CLS-complete. We thus provide the first natural complete problem for\nthe class CLS, which was defined in [Daskalakis, Papadimitriou 2011] to capture\nthe complexity of problems such as P-matrix LCP, computing KKT-points, and\nfinding mixed Nash equilibria in congestion and network coordination games.\n", "versions": [{"version": "v1", "created": "Thu, 23 Feb 2017 18:52:31 GMT"}, {"version": "v2", "created": "Wed, 5 Apr 2017 20:25:27 GMT"}, {"version": "v3", "created": "Tue, 13 Feb 2018 23:33:13 GMT"}], "update_date": "2018-02-15", "authors_parsed": [["Daskalakis", "Constantinos", ""], ["Tzamos", "Christos", ""], ["Zampetakis", "Manolis", ""]]}, {"id": "1702.07360", "submitter": "Randall Balestriero", "authors": "Randall Balestriero", "title": "Neural Decision Trees", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In this paper we propose a synergistic melting of neural networks and\ndecision trees (DT) we call neural decision trees (NDT). NDT is an architecture\na la decision tree where each splitting node is an independent multilayer\nperceptron allowing oblique decision functions or arbritrary nonlinear decision\nfunction if more than one layer is used. This way, each MLP can be seen as a\nnode of the tree. We then show that with the weight sharing asumption among\nthose units, we end up with a Hashing Neural Network (HNN) which is a\nmultilayer perceptron with sigmoid activation function for the last layer as\nopposed to the standard softmax. The output units then jointly represent the\nprobability to be in a particular region. The proposed framework allows for\nglobal optimization as opposed to greedy in DT and differentiability w.r.t. all\nparameters and the input, allowing easy integration in any learnable pipeline,\nfor example after CNNs for computer vision tasks. We also demonstrate the\nmodeling power of HNN allowing to learn union of disjoint regions for final\nclustering or classification making it more general and powerful than standard\nsoftmax MLP requiring linear separability thus reducing the need on the inner\nlayer to perform complex data transformations. We finally show experiments for\nsupervised, semi-suppervised and unsupervised tasks and compare results with\nstandard DTs and MLPs.\n", "versions": [{"version": "v1", "created": "Thu, 23 Feb 2017 19:02:32 GMT"}, {"version": "v2", "created": "Mon, 6 Mar 2017 15:39:47 GMT"}], "update_date": "2017-03-07", "authors_parsed": [["Balestriero", "Randall", ""]]}, {"id": "1702.07444", "submitter": "Tomer Koren", "authors": "Tomer Koren, Roi Livni, Yishay Mansour", "title": "Bandits with Movement Costs and Adaptive Pricing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We extend the model of Multi-armed Bandit with unit switching cost to\nincorporate a metric between the actions. We consider the case where the metric\nover the actions can be modeled by a complete binary tree, and the distance\nbetween two leaves is the size of the subtree of their least common ancestor,\nwhich abstracts the case that the actions are points on the continuous interval\n$[0,1]$ and the switching cost is their distance. In this setting, we give a\nnew algorithm that establishes a regret of $\\widetilde{O}(\\sqrt{kT} + T/k)$,\nwhere $k$ is the number of actions and $T$ is the time horizon. When the set of\nactions corresponds to whole $[0,1]$ interval we can exploit our method for the\ntask of bandit learning with Lipschitz loss functions, where our algorithm\nachieves an optimal regret rate of $\\widetilde{\\Theta}(T^{2/3})$, which is the\nsame rate one obtains when there is no penalty for movements. As our main\napplication, we use our new algorithm to solve an adaptive pricing problem.\nSpecifically, we consider the case of a single seller faced with a stream of\npatient buyers. Each buyer has a private value and a window of time in which\nthey are interested in buying, and they buy at the lowest price in the window,\nif it is below their value. We show that with an appropriate discretization of\nthe prices, the seller can achieve a regret of $\\widetilde{O}(T^{2/3})$\ncompared to the best fixed price in hindsight, which outperform the previous\nregret bound of $\\widetilde{O}(T^{3/4})$ for the problem.\n", "versions": [{"version": "v1", "created": "Fri, 24 Feb 2017 01:51:48 GMT"}], "update_date": "2017-02-27", "authors_parsed": [["Koren", "Tomer", ""], ["Livni", "Roi", ""], ["Mansour", "Yishay", ""]]}, {"id": "1702.07450", "submitter": "David Balduzzi", "authors": "David Balduzzi", "title": "Strongly-Typed Agents are Guaranteed to Interact Safely", "comments": "ICML 2017, final version", "journal-ref": "PMLR volume 70, 2017", "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As artificial agents proliferate, it is becoming increasingly important to\nensure that their interactions with one another are well-behaved. In this\npaper, we formalize a common-sense notion of when algorithms are well-behaved:\nan algorithm is safe if it does no harm. Motivated by recent progress in deep\nlearning, we focus on the specific case where agents update their actions\naccording to gradient descent. The paper shows that that gradient descent\nconverges to a Nash equilibrium in safe games. The main contribution is to\ndefine strongly-typed agents and show they are guaranteed to interact safely,\nthereby providing sufficient conditions to guarantee safe interactions. A\nseries of examples show that strong-typing generalizes certain key features of\nconvexity, is closely related to blind source separation, and introduces a new\nperspective on classical multilinear games based on tensor decomposition.\n", "versions": [{"version": "v1", "created": "Fri, 24 Feb 2017 02:30:15 GMT"}, {"version": "v2", "created": "Wed, 6 Jun 2018 12:37:57 GMT"}], "update_date": "2018-06-07", "authors_parsed": [["Balduzzi", "David", ""]]}, {"id": "1702.07463", "submitter": "Po-Sen Huang", "authors": "Chong Wang and Yining Wang and Po-Sen Huang and Abdelrahman Mohamed\n  and Dengyong Zhou and Li Deng", "title": "Sequence Modeling via Segmentations", "comments": "recurrent neural networks, dynamic programming, structured prediction", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Segmental structure is a common pattern in many types of sequences such as\nphrases in human languages. In this paper, we present a probabilistic model for\nsequences via their segmentations. The probability of a segmented sequence is\ncalculated as the product of the probabilities of all its segments, where each\nsegment is modeled using existing tools such as recurrent neural networks.\nSince the segmentation of a sequence is usually unknown in advance, we sum over\nall valid segmentations to obtain the final probability for the sequence. An\nefficient dynamic programming algorithm is developed for forward and backward\ncomputations without resorting to any approximation. We demonstrate our\napproach on text segmentation and speech recognition tasks. In addition to\nquantitative results, we also show that our approach can discover meaningful\nsegments in their respective application contexts.\n", "versions": [{"version": "v1", "created": "Fri, 24 Feb 2017 04:55:44 GMT"}, {"version": "v2", "created": "Mon, 27 Feb 2017 01:16:23 GMT"}, {"version": "v3", "created": "Sun, 19 Mar 2017 17:17:06 GMT"}, {"version": "v4", "created": "Wed, 7 Jun 2017 04:25:34 GMT"}, {"version": "v5", "created": "Mon, 19 Jun 2017 17:45:31 GMT"}, {"version": "v6", "created": "Fri, 20 Apr 2018 04:32:08 GMT"}, {"version": "v7", "created": "Wed, 18 Jul 2018 21:52:02 GMT"}], "update_date": "2018-07-20", "authors_parsed": [["Wang", "Chong", ""], ["Wang", "Yining", ""], ["Huang", "Po-Sen", ""], ["Mohamed", "Abdelrahman", ""], ["Zhou", "Dengyong", ""], ["Deng", "Li", ""]]}, {"id": "1702.07464", "submitter": "Briland Hitaj", "authors": "Briland Hitaj, Giuseppe Ateniese, Fernando Perez-Cruz", "title": "Deep Models Under the GAN: Information Leakage from Collaborative Deep\n  Learning", "comments": "ACM CCS'17, 16 pages, 18 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Learning has recently become hugely popular in machine learning,\nproviding significant improvements in classification accuracy in the presence\nof highly-structured and large databases.\n  Researchers have also considered privacy implications of deep learning.\nModels are typically trained in a centralized manner with all the data being\nprocessed by the same training algorithm. If the data is a collection of users'\nprivate data, including habits, personal pictures, geographical positions,\ninterests, and more, the centralized server will have access to sensitive\ninformation that could potentially be mishandled. To tackle this problem,\ncollaborative deep learning models have recently been proposed where parties\nlocally train their deep learning structures and only share a subset of the\nparameters in the attempt to keep their respective training sets private.\nParameters can also be obfuscated via differential privacy (DP) to make\ninformation extraction even more challenging, as proposed by Shokri and\nShmatikov at CCS'15.\n  Unfortunately, we show that any privacy-preserving collaborative deep\nlearning is susceptible to a powerful attack that we devise in this paper. In\nparticular, we show that a distributed, federated, or decentralized deep\nlearning approach is fundamentally broken and does not protect the training\nsets of honest participants. The attack we developed exploits the real-time\nnature of the learning process that allows the adversary to train a Generative\nAdversarial Network (GAN) that generates prototypical samples of the targeted\ntraining set that was meant to be private (the samples generated by the GAN are\nintended to come from the same distribution as the training data).\nInterestingly, we show that record-level DP applied to the shared parameters of\nthe model, as suggested in previous work, is ineffective (i.e., record-level DP\nis not designed to address our attack).\n", "versions": [{"version": "v1", "created": "Fri, 24 Feb 2017 05:00:37 GMT"}, {"version": "v2", "created": "Tue, 23 May 2017 20:21:27 GMT"}, {"version": "v3", "created": "Thu, 14 Sep 2017 16:38:23 GMT"}], "update_date": "2017-09-15", "authors_parsed": [["Hitaj", "Briland", ""], ["Ateniese", "Giuseppe", ""], ["Perez-Cruz", "Fernando", ""]]}, {"id": "1702.07490", "submitter": "Stefan Elfwing PhD", "authors": "Stefan Elfwing, Eiji Uchibe, Kenji Doya", "title": "Online Meta-learning by Parallel Algorithm Competition", "comments": "15 pages, 10 figures. arXiv admin note: text overlap with\n  arXiv:1702.03118", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The efficiency of reinforcement learning algorithms depends critically on a\nfew meta-parameters that modulates the learning updates and the trade-off\nbetween exploration and exploitation. The adaptation of the meta-parameters is\nan open question in reinforcement learning, which arguably has become more of\nan issue recently with the success of deep reinforcement learning in\nhigh-dimensional state spaces. The long learning times in domains such as Atari\n2600 video games makes it not feasible to perform comprehensive searches of\nappropriate meta-parameter values. We propose the Online Meta-learning by\nParallel Algorithm Competition (OMPAC) method. In the OMPAC method, several\ninstances of a reinforcement learning algorithm are run in parallel with small\ndifferences in the initial values of the meta-parameters. After a fixed number\nof episodes, the instances are selected based on their performance in the task\nat hand. Before continuing the learning, Gaussian noise is added to the\nmeta-parameters with a predefined probability. We validate the OMPAC method by\nimproving the state-of-the-art results in stochastic SZ-Tetris and in standard\nTetris with a smaller, 10$\\times$10, board, by 31% and 84%, respectively, and\nby improving the results for deep Sarsa($\\lambda$) agents in three Atari 2600\ngames by 62% or more. The experiments also show the ability of the OMPAC method\nto adapt the meta-parameters according to the learning progress in different\ntasks.\n", "versions": [{"version": "v1", "created": "Fri, 24 Feb 2017 08:25:23 GMT"}], "update_date": "2017-02-27", "authors_parsed": [["Elfwing", "Stefan", ""], ["Uchibe", "Eiji", ""], ["Doya", "Kenji", ""]]}, {"id": "1702.07539", "submitter": "Alon Cohen", "authors": "Alon Cohen, Tamir Hazan, Tomer Koren", "title": "Tight Bounds for Bandit Combinatorial Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We revisit the study of optimal regret rates in bandit combinatorial\noptimization---a fundamental framework for sequential decision making under\nuncertainty that abstracts numerous combinatorial prediction problems. We prove\nthat the attainable regret in this setting grows as\n$\\widetilde{\\Theta}(k^{3/2}\\sqrt{dT})$ where $d$ is the dimension of the\nproblem and $k$ is a bound over the maximal instantaneous loss, disproving a\nconjecture of Audibert, Bubeck, and Lugosi (2013) who argued that the optimal\nrate should be of the form $\\widetilde{\\Theta}(k\\sqrt{dT})$. Our bounds apply\nto several important instances of the framework, and in particular, imply a\ntight bound for the well-studied bandit shortest path problem. By that, we also\nresolve an open problem posed by Cesa-Bianchi and Lugosi (2012).\n", "versions": [{"version": "v1", "created": "Fri, 24 Feb 2017 11:17:33 GMT"}], "update_date": "2017-02-27", "authors_parsed": [["Cohen", "Alon", ""], ["Hazan", "Tamir", ""], ["Koren", "Tomer", ""]]}, {"id": "1702.07552", "submitter": "Muhammad Farooq", "authors": "Muhammad Farooq and Ingo Steinwart", "title": "Learning Rates for Kernel-Based Expectile Regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conditional expectiles are becoming an increasingly important tool in finance\nas well as in other areas of applications. We analyse a support vector machine\ntype approach for estimating conditional expectiles and establish learning\nrates that are minimax optimal modulo a logarithmic factor if Gaussian RBF\nkernels are used and the desired expectile is smooth in a Besov sense. As a\nspecial case, our learning rates improve the best known rates for kernel-based\nleast squares regression in this scenario. Key ingredients of our statistical\nanalysis are a general calibration inequality for the asymmetric least squares\nloss, a corresponding variance bound as well as an improved entropy number\nbound for Gaussian RBF kernels.\n", "versions": [{"version": "v1", "created": "Fri, 24 Feb 2017 12:06:47 GMT"}, {"version": "v2", "created": "Mon, 27 Feb 2017 11:09:08 GMT"}], "update_date": "2017-02-28", "authors_parsed": [["Farooq", "Muhammad", ""], ["Steinwart", "Ingo", ""]]}, {"id": "1702.07560", "submitter": "Eliya Nachmani", "authors": "Eliya Nachmani, Elad Marciano, David Burshtein and Yair Be'ery", "title": "RNN Decoding of Linear Block Codes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG cs.NE math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Designing a practical, low complexity, close to optimal, channel decoder for\npowerful algebraic codes with short to moderate block length is an open\nresearch problem. Recently it has been shown that a feed-forward neural network\narchitecture can improve on standard belief propagation decoding, despite the\nlarge example space. In this paper we introduce a recurrent neural network\narchitecture for decoding linear block codes. Our method shows comparable bit\nerror rate results compared to the feed-forward neural network with\nsignificantly less parameters. We also demonstrate improved performance over\nbelief propagation on sparser Tanner graph representations of the codes.\nFurthermore, we demonstrate that the RNN decoder can be used to improve the\nperformance or alternatively reduce the computational complexity of the mRRD\nalgorithm for low complexity, close to optimal, decoding of short BCH codes.\n", "versions": [{"version": "v1", "created": "Fri, 24 Feb 2017 12:49:29 GMT"}], "update_date": "2017-02-27", "authors_parsed": [["Nachmani", "Eliya", ""], ["Marciano", "Elad", ""], ["Burshtein", "David", ""], ["Be'ery", "Yair", ""]]}, {"id": "1702.07652", "submitter": "Mahdi Imani", "authors": "Mahdi Imani and Ulisses Braga-Neto", "title": "Control of Gene Regulatory Networks with Noisy Measurements and\n  Uncertain Inputs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.MN cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is concerned with the problem of stochastic control of gene\nregulatory networks (GRNs) observed indirectly through noisy measurements and\nwith uncertainty in the intervention inputs. The partial observability of the\ngene states and uncertainty in the intervention process are accounted for by\nmodeling GRNs using the partially-observed Boolean dynamical system (POBDS)\nsignal model with noisy gene expression measurements. Obtaining the optimal\ninfinite-horizon control strategy for this problem is not attainable in\ngeneral, and we apply reinforcement learning and Gaussian process techniques to\nfind a near-optimal solution. The POBDS is first transformed to a\ndirectly-observed Markov Decision Process in a continuous belief space, and the\nGaussian process is used for modeling the cost function over the belief and\nintervention spaces. Reinforcement learning then is used to learn the cost\nfunction from the available gene expression data. In addition, we employ\nsparsification, which enables the control of large partially-observed GRNs. The\nperformance of the resulting algorithm is studied through a comprehensive set\nof numerical experiments using synthetic gene expression data generated from a\nmelanoma gene regulatory network.\n", "versions": [{"version": "v1", "created": "Fri, 24 Feb 2017 16:32:57 GMT"}], "update_date": "2017-02-27", "authors_parsed": [["Imani", "Mahdi", ""], ["Braga-Neto", "Ulisses", ""]]}, {"id": "1702.07664", "submitter": "Dipan Pal", "authors": "Dipan K. Pal, Marios Savvides", "title": "How ConvNets model Non-linear Transformations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we theoretically address three fundamental problems involving\ndeep convolutional networks regarding invariance, depth and hierarchy. We\nintroduce the paradigm of Transformation Networks (TN) which are a direct\ngeneralization of Convolutional Networks (ConvNets). Theoretically, we show\nthat TNs (and thereby ConvNets) are can be invariant to non-linear\ntransformations of the input despite pooling over mere local translations. Our\nanalysis provides clear insights into the increase in invariance with depth in\nthese networks. Deeper networks are able to model much richer classes of\ntransformations. We also find that a hierarchical architecture allows the\nnetwork to generate invariance much more efficiently than a non-hierarchical\nnetwork. Our results provide useful insight into these three fundamental\nproblems in deep learning using ConvNets.\n", "versions": [{"version": "v1", "created": "Fri, 24 Feb 2017 17:09:22 GMT"}], "update_date": "2017-02-27", "authors_parsed": [["Pal", "Dipan K.", ""], ["Savvides", "Marios", ""]]}, {"id": "1702.07694", "submitter": "Stephen Pallone", "authors": "Stephen N. Pallone, Peter I. Frazier, and Shane G. Henderson", "title": "Bayes-Optimal Entropy Pursuit for Active Choice-Based Preference\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyze the problem of learning a single user's preferences in an active\nlearning setting, sequentially and adaptively querying the user over a finite\ntime horizon. Learning is conducted via choice-based queries, where the user\nselects her preferred option among a small subset of offered alternatives.\nThese queries have been shown to be a robust and efficient way to learn an\nindividual's preferences. We take a parametric approach and model the user's\npreferences through a linear classifier, using a Bayesian prior to encode our\ncurrent knowledge of this classifier. The rate at which we learn depends on the\nalternatives offered at every time epoch. Under certain noise assumptions, we\nshow that the Bayes-optimal policy for maximally reducing entropy of the\nposterior distribution of this linear classifier is a greedy policy, and that\nthis policy achieves a linear lower bound when alternatives can be constructed\nfrom the continuum. Further, we analyze a different metric called\nmisclassification error, proving that the performance of the optimal policy\nthat minimizes misclassification error is bounded below by a linear function of\ndifferential entropy. Lastly, we numerically compare the greedy entropy\nreduction policy with a knowledge gradient policy under a number of scenarios,\nexamining their performance under both differential entropy and\nmisclassification error.\n", "versions": [{"version": "v1", "created": "Fri, 24 Feb 2017 18:28:18 GMT"}], "update_date": "2017-02-27", "authors_parsed": [["Pallone", "Stephen N.", ""], ["Frazier", "Peter I.", ""], ["Henderson", "Shane G.", ""]]}, {"id": "1702.07709", "submitter": "Simon Du", "authors": "Simon S. Du, Sivaraman Balakrishnan, Aarti Singh", "title": "Computationally Efficient Robust Estimation of Sparse Functionals", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many conventional statistical procedures are extremely sensitive to seemingly\nminor deviations from modeling assumptions. This problem is exacerbated in\nmodern high-dimensional settings, where the problem dimension can grow with and\npossibly exceed the sample size. We consider the problem of robust estimation\nof sparse functionals, and provide a computationally and statistically\nefficient algorithm in the high-dimensional setting. Our theory identifies a\nunified set of deterministic conditions under which our algorithm guarantees\naccurate recovery. By further establishing that these deterministic conditions\nhold with high-probability for a wide range of statistical models, our theory\napplies to many problems of considerable interest including sparse mean and\ncovariance estimation; sparse linear regression; and sparse generalized linear\nmodels.\n", "versions": [{"version": "v1", "created": "Fri, 24 Feb 2017 18:59:08 GMT"}], "update_date": "2017-02-27", "authors_parsed": [["Du", "Simon S.", ""], ["Balakrishnan", "Sivaraman", ""], ["Singh", "Aarti", ""]]}, {"id": "1702.07752", "submitter": "Benjamin Fish", "authors": "Benjamin Fish, Rajmonda S. Caceres", "title": "A supervised approach to time scale detection in dynamic networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For any stream of time-stamped edges that form a dynamic network, an\nimportant choice is the aggregation granularity that an analyst uses to bin the\ndata. Picking such a windowing of the data is often done by hand, or left up to\nthe technology that is collecting the data. However, the choice can make a big\ndifference in the properties of the dynamic network. This is the time scale\ndetection problem. In previous work, this problem is often solved with a\nheuristic as an unsupervised task. As an unsupervised problem, it is difficult\nto measure how well a given algorithm performs. In addition, we show that the\nquality of the windowing is dependent on which task an analyst wants to perform\non the network after windowing. Therefore the time scale detection problem\nshould not be handled independently from the rest of the analysis of the\nnetwork.\n  We introduce a framework that tackles both of these issues: By measuring the\nperformance of the time scale detection algorithm based on how well a given\ntask is accomplished on the resulting network, we are for the first time able\nto directly compare different time scale detection algorithms to each other.\nUsing this framework, we introduce time scale detection algorithms that take a\nsupervised approach: they leverage ground truth on training data to find a good\nwindowing of the test data. We compare the supervised approach to previous\napproaches and several baselines on real data.\n", "versions": [{"version": "v1", "created": "Fri, 24 Feb 2017 20:45:02 GMT"}], "update_date": "2017-02-28", "authors_parsed": [["Fish", "Benjamin", ""], ["Caceres", "Rajmonda S.", ""]]}, {"id": "1702.07780", "submitter": "Augustus Odena", "authors": "Augustus Odena, Dieterich Lawson, Christopher Olah", "title": "Changing Model Behavior at Test-Time Using Reinforcement Learning", "comments": "Submitted to ICLR 2017 Workshop Track", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning models are often used at test-time subject to constraints\nand trade-offs not present at training-time. For example, a computer vision\nmodel operating on an embedded device may need to perform real-time inference,\nor a translation model operating on a cell phone may wish to bound its average\ncompute time in order to be power-efficient. In this work we describe a\nmixture-of-experts model and show how to change its test-time resource-usage on\na per-input basis using reinforcement learning. We test our method on a small\nMNIST-based example.\n", "versions": [{"version": "v1", "created": "Fri, 24 Feb 2017 22:00:41 GMT"}], "update_date": "2017-02-28", "authors_parsed": [["Odena", "Augustus", ""], ["Lawson", "Dieterich", ""], ["Olah", "Christopher", ""]]}, {"id": "1702.07787", "submitter": "Yong Xu", "authors": "Yong Xu and Qiuqiang Kong and Qiang Huang and Wenwu Wang and Mark D.\n  Plumbley", "title": "Convolutional Gated Recurrent Neural Network Incorporating Spatial\n  Features for Audio Tagging", "comments": "Accepted to IJCNN2017, Anchorage, Alaska, USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Environmental audio tagging is a newly proposed task to predict the presence\nor absence of a specific audio event in a chunk. Deep neural network (DNN)\nbased methods have been successfully adopted for predicting the audio tags in\nthe domestic audio scene. In this paper, we propose to use a convolutional\nneural network (CNN) to extract robust features from mel-filter banks (MFBs),\nspectrograms or even raw waveforms for audio tagging. Gated recurrent unit\n(GRU) based recurrent neural networks (RNNs) are then cascaded to model the\nlong-term temporal structure of the audio signal. To complement the input\ninformation, an auxiliary CNN is designed to learn on the spatial features of\nstereo recordings. We evaluate our proposed methods on Task 4 (audio tagging)\nof the Detection and Classification of Acoustic Scenes and Events 2016 (DCASE\n2016) challenge. Compared with our recent DNN-based method, the proposed\nstructure can reduce the equal error rate (EER) from 0.13 to 0.11 on the\ndevelopment set. The spatial features can further reduce the EER to 0.10. The\nperformance of the end-to-end learning on raw waveforms is also comparable.\nFinally, on the evaluation set, we get the state-of-the-art performance with\n0.12 EER while the performance of the best existing system is 0.15 EER.\n", "versions": [{"version": "v1", "created": "Fri, 24 Feb 2017 22:27:29 GMT"}], "update_date": "2017-02-28", "authors_parsed": [["Xu", "Yong", ""], ["Kong", "Qiuqiang", ""], ["Huang", "Qiang", ""], ["Wang", "Wenwu", ""], ["Plumbley", "Mark D.", ""]]}, {"id": "1702.07790", "submitter": "Mark Harmon", "authors": "Mark Harmon, Diego Klabjan", "title": "Activation Ensembles for Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many activation functions have been proposed in the past, but selecting an\nadequate one requires trial and error. We propose a new methodology of\ndesigning activation functions within a neural network at each layer. We call\nthis technique an \"activation ensemble\" because it allows the use of multiple\nactivation functions at each layer. This is done by introducing additional\nvariables, $\\alpha$, at each activation layer of a network to allow for\nmultiple activation functions to be active at each neuron. By design,\nactivations with larger $\\alpha$ values at a neuron is equivalent to having the\nlargest magnitude. Hence, those higher magnitude activations are \"chosen\" by\nthe network. We implement the activation ensembles on a variety of datasets\nusing an array of Feed Forward and Convolutional Neural Networks. By using the\nactivation ensemble, we achieve superior results compared to traditional\ntechniques. In addition, because of the flexibility of this methodology, we\nmore deeply explore activation functions and the features that they capture.\n", "versions": [{"version": "v1", "created": "Fri, 24 Feb 2017 22:30:29 GMT"}], "update_date": "2017-02-28", "authors_parsed": [["Harmon", "Mark", ""], ["Klabjan", "Diego", ""]]}, {"id": "1702.07798", "submitter": "Swayambhoo Jain", "authors": "Swayambhoo Jain, Akshay Soni, Nikolay Laptev, and Yashar Mehdad", "title": "Rank-to-engage: New Listwise Approaches to Maximize Engagement", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For many internet businesses, presenting a given list of items in an order\nthat maximizes a certain metric of interest (e.g., click-through-rate, average\nengagement time etc.) is crucial. We approach the aforementioned task from a\nlearning-to-rank perspective which reveals a new problem setup. In traditional\nlearning-to-rank literature, it is implicitly assumed that during the training\ndata generation one has access to the \\emph{best or desired} order for the\ngiven list of items. In this work, we consider a problem setup where we do not\nobserve the desired ranking. We present two novel solutions: the first solution\nis an extension of already existing listwise learning-to-rank\ntechnique--Listwise maximum likelihood estimation (ListMLE)--while the second\none is a generic machine learning based framework that tackles the problem in\nits entire generality. We discuss several challenges associated with this\ngeneric framework, and propose a simple \\emph{item-payoff} and\n\\emph{positional-gain} model that addresses these challenges. We provide\ntraining algorithms, inference procedures, and demonstrate the effectiveness of\nthe two approaches over traditional ListMLE on synthetic as well as on\nreal-life setting of ranking news articles for increased dwell time.\n", "versions": [{"version": "v1", "created": "Fri, 24 Feb 2017 23:20:03 GMT"}], "update_date": "2017-02-28", "authors_parsed": [["Jain", "Swayambhoo", ""], ["Soni", "Akshay", ""], ["Laptev", "Nikolay", ""], ["Mehdad", "Yashar", ""]]}, {"id": "1702.07800", "submitter": "Haohan Wang", "authors": "Haohan Wang and Bhiksha Raj", "title": "On the Origin of Deep Learning", "comments": "70 pages, 200 references", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is a review of the evolutionary history of deep learning models.\nIt covers from the genesis of neural networks when associationism modeling of\nthe brain is studied, to the models that dominate the last decade of research\nin deep learning like convolutional neural networks, deep belief networks, and\nrecurrent neural networks. In addition to a review of these models, this paper\nprimarily focuses on the precedents of the models above, examining how the\ninitial ideas are assembled to construct the early models and how these\npreliminary models are developed into their current forms. Many of these\nevolutionary paths last more than half a century and have a diversity of\ndirections. For example, CNN is built on prior knowledge of biological vision\nsystem; DBN is evolved from a trade-off of modeling power and computation\ncomplexity of graphical models and many nowadays models are neural counterparts\nof ancient linear models. This paper reviews these evolutionary paths and\noffers a concise thought flow of how these models are developed, and aims to\nprovide a thorough background for deep learning. More importantly, along with\nthe path, this paper summarizes the gist behind these milestones and proposes\nmany directions to guide the future research of deep learning.\n", "versions": [{"version": "v1", "created": "Fri, 24 Feb 2017 23:30:08 GMT"}, {"version": "v2", "created": "Wed, 1 Mar 2017 08:30:41 GMT"}, {"version": "v3", "created": "Thu, 2 Mar 2017 01:41:09 GMT"}, {"version": "v4", "created": "Fri, 3 Mar 2017 03:03:32 GMT"}], "update_date": "2017-03-06", "authors_parsed": [["Wang", "Haohan", ""], ["Raj", "Bhiksha", ""]]}, {"id": "1702.07811", "submitter": "Tolga Bolukbasi", "authors": "Tolga Bolukbasi, Joseph Wang, Ofer Dekel, Venkatesh Saligrama", "title": "Adaptive Neural Networks for Efficient Inference", "comments": null, "journal-ref": "Proceedings of the 34th International Conference on Machine\n  Learning, PMLR 70:527-536, 2017", "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an approach to adaptively utilize deep neural networks in order to\nreduce the evaluation time on new examples without loss of accuracy. Rather\nthan attempting to redesign or approximate existing networks, we propose two\nschemes that adaptively utilize networks. We first pose an adaptive network\nevaluation scheme, where we learn a system to adaptively choose the components\nof a deep network to be evaluated for each example. By allowing examples\ncorrectly classified using early layers of the system to exit, we avoid the\ncomputational time associated with full evaluation of the network. We extend\nthis to learn a network selection system that adaptively selects the network to\nbe evaluated for each example. We show that computational time can be\ndramatically reduced by exploiting the fact that many examples can be correctly\nclassified using relatively efficient networks and that complex,\ncomputationally costly networks are only necessary for a small fraction of\nexamples. We pose a global objective for learning an adaptive early exit or\nnetwork selection policy and solve it by reducing the policy learning problem\nto a layer-by-layer weighted binary classification problem. Empirically, these\napproaches yield dramatic reductions in computational cost, with up to a 2.8x\nspeedup on state-of-the-art networks from the ImageNet image recognition\nchallenge with minimal (<1%) loss of top5 accuracy.\n", "versions": [{"version": "v1", "created": "Sat, 25 Feb 2017 00:22:51 GMT"}, {"version": "v2", "created": "Mon, 18 Sep 2017 18:14:49 GMT"}], "update_date": "2017-09-20", "authors_parsed": [["Bolukbasi", "Tolga", ""], ["Wang", "Joseph", ""], ["Dekel", "Ofer", ""], ["Saligrama", "Venkatesh", ""]]}, {"id": "1702.07817", "submitter": "Jianshu Chen", "authors": "Yu Liu, Jianshu Chen, Li Deng", "title": "Unsupervised Sequence Classification using Sequential Output Statistics", "comments": "All authors contributed equally to the paper. 17 pages, 7 figures and\n  2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider learning a sequence classifier without labeled data by using\nsequential output statistics. The problem is highly valuable since obtaining\nlabels in training data is often costly, while the sequential output statistics\n(e.g., language models) could be obtained independently of input data and thus\nwith low or no cost. To address the problem, we propose an unsupervised\nlearning cost function and study its properties. We show that, compared to\nearlier works, it is less inclined to be stuck in trivial solutions and avoids\nthe need for a strong generative model. Although it is harder to optimize in\nits functional form, a stochastic primal-dual gradient method is developed to\neffectively solve the problem. Experiment results on real-world datasets\ndemonstrate that the new unsupervised learning method gives drastically lower\nerrors than other baseline methods. Specifically, it reaches test errors about\ntwice of those obtained by fully supervised learning.\n", "versions": [{"version": "v1", "created": "Sat, 25 Feb 2017 01:55:38 GMT"}, {"version": "v2", "created": "Fri, 26 May 2017 18:30:24 GMT"}], "update_date": "2017-05-30", "authors_parsed": [["Liu", "Yu", ""], ["Chen", "Jianshu", ""], ["Deng", "Li", ""]]}, {"id": "1702.07825", "submitter": "Andrew Gibiansky", "authors": "Sercan O. Arik, Mike Chrzanowski, Adam Coates, Gregory Diamos, Andrew\n  Gibiansky, Yongguo Kang, Xian Li, John Miller, Andrew Ng, Jonathan Raiman,\n  Shubho Sengupta, Mohammad Shoeybi", "title": "Deep Voice: Real-time Neural Text-to-Speech", "comments": "Submitted to ICML 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.NE cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present Deep Voice, a production-quality text-to-speech system constructed\nentirely from deep neural networks. Deep Voice lays the groundwork for truly\nend-to-end neural speech synthesis. The system comprises five major building\nblocks: a segmentation model for locating phoneme boundaries, a\ngrapheme-to-phoneme conversion model, a phoneme duration prediction model, a\nfundamental frequency prediction model, and an audio synthesis model. For the\nsegmentation model, we propose a novel way of performing phoneme boundary\ndetection with deep neural networks using connectionist temporal classification\n(CTC) loss. For the audio synthesis model, we implement a variant of WaveNet\nthat requires fewer parameters and trains faster than the original. By using a\nneural network for each component, our system is simpler and more flexible than\ntraditional text-to-speech systems, where each component requires laborious\nfeature engineering and extensive domain expertise. Finally, we show that\ninference with our system can be performed faster than real time and describe\noptimized WaveNet inference kernels on both CPU and GPU that achieve up to 400x\nspeedups over existing implementations.\n", "versions": [{"version": "v1", "created": "Sat, 25 Feb 2017 03:11:04 GMT"}, {"version": "v2", "created": "Tue, 7 Mar 2017 23:09:23 GMT"}], "update_date": "2017-03-09", "authors_parsed": [["Arik", "Sercan O.", ""], ["Chrzanowski", "Mike", ""], ["Coates", "Adam", ""], ["Diamos", "Gregory", ""], ["Gibiansky", "Andrew", ""], ["Kang", "Yongguo", ""], ["Li", "Xian", ""], ["Miller", "John", ""], ["Ng", "Andrew", ""], ["Raiman", "Jonathan", ""], ["Sengupta", "Shubho", ""], ["Shoeybi", "Mohammad", ""]]}, {"id": "1702.07826", "submitter": "Upol Ehsan", "authors": "Upol Ehsan, Brent Harrison, Larry Chan, Mark O. Riedl", "title": "Rationalization: A Neural Machine Translation Approach to Generating\n  Natural Language Explanations", "comments": "9 pages, 4 figures; added human evaluation section; added author;\n  changed author order-Upol Ehsan and Brent Harrison both contributed equally\n  to this work", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce AI rationalization, an approach for generating explanations of\nautonomous system behavior as if a human had performed the behavior. We\ndescribe a rationalization technique that uses neural machine translation to\ntranslate internal state-action representations of an autonomous agent into\nnatural language. We evaluate our technique in the Frogger game environment,\ntraining an autonomous game playing agent to rationalize its action choices\nusing natural language. A natural language training corpus is collected from\nhuman players thinking out loud as they play the game. We motivate the use of\nrationalization as an approach to explanation generation and show the results\nof two experiments evaluating the effectiveness of rationalization. Results of\nthese evaluations show that neural machine translation is able to accurately\ngenerate rationalizations that describe agent behavior, and that\nrationalizations are more satisfying to humans than other alternative methods\nof explanation.\n", "versions": [{"version": "v1", "created": "Sat, 25 Feb 2017 03:20:49 GMT"}, {"version": "v2", "created": "Tue, 19 Dec 2017 05:20:09 GMT"}], "update_date": "2017-12-20", "authors_parsed": [["Ehsan", "Upol", ""], ["Harrison", "Brent", ""], ["Chan", "Larry", ""], ["Riedl", "Mark O.", ""]]}, {"id": "1702.07834", "submitter": "Weiran Wang", "authors": "Jialei Wang, Weiran Wang, Dan Garber, Nathan Srebro", "title": "Efficient coordinate-wise leading eigenvector computation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop and analyze efficient \"coordinate-wise\" methods for finding the\nleading eigenvector, where each step involves only a vector-vector product. We\nestablish global convergence with overall runtime guarantees that are at least\nas good as Lanczos's method and dominate it for slowly decaying spectrum. Our\nmethods are based on combining a shift-and-invert approach with coordinate-wise\nalgorithms for linear regression.\n", "versions": [{"version": "v1", "created": "Sat, 25 Feb 2017 05:11:25 GMT"}], "update_date": "2017-02-28", "authors_parsed": [["Wang", "Jialei", ""], ["Wang", "Weiran", ""], ["Garber", "Dan", ""], ["Srebro", "Nathan", ""]]}, {"id": "1702.07870", "submitter": "Alon Cohen", "authors": "Alon Cohen, Shie Mannor", "title": "Online Learning with Many Experts", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of prediction with expert advice when the number of\nexperts in question may be extremely large or even infinite. We devise an\nalgorithm that obtains a tight regret bound of $\\widetilde{O}(\\epsilon T + N +\n\\sqrt{NT})$, where $N$ is the empirical $\\epsilon$-covering number of the\nsequence of loss functions generated by the environment. In addition, we\npresent a hedging procedure that allows us to find the optimal $\\epsilon$ in\nhindsight.\n  Finally, we discuss a few interesting applications of our algorithm. We show\nhow our algorithm is applicable in the approximately low rank experts model of\nHazan et al. (2016), and discuss the case of experts with bounded variation, in\nwhich there is a surprisingly large gap between the regret bounds obtained in\nthe statistical and online settings.\n", "versions": [{"version": "v1", "created": "Sat, 25 Feb 2017 10:27:29 GMT"}], "update_date": "2017-02-28", "authors_parsed": [["Cohen", "Alon", ""], ["Mannor", "Shie", ""]]}, {"id": "1702.07884", "submitter": "Mehran Safayani", "authors": "Mehran Safayani, Seyed Hashem Ahmadi, Homayun Afrabandpey and\n  Abdolreza Mirzaei", "title": "An EM Based Probabilistic Two-Dimensional CCA with Application to Face\n  Recognition", "comments": null, "journal-ref": null, "doi": "10.1007/s10489-017-1012-2", "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, two-dimensional canonical correlation analysis (2DCCA) has been\nsuccessfully applied for image feature extraction. The method instead of\nconcatenating the columns of the images to the one-dimensional vectors,\ndirectly works with two-dimensional image matrices. Although 2DCCA works well\nin different recognition tasks, it lacks a probabilistic interpretation. In\nthis paper, we present a probabilistic framework for 2DCCA called probabilistic\n2DCCA (P2DCCA) and an iterative EM based algorithm for optimizing the\nparameters. Experimental results on synthetic and real data demonstrate\nsuperior performance in loading factor estimation for P2DCCA compared to 2DCCA.\nFor real data, three subsets of AR face database and also the UMIST face\ndatabase confirm the robustness of the proposed algorithm in face recognition\ntasks with different illumination conditions, facial expressions, poses and\nocclusions.\n", "versions": [{"version": "v1", "created": "Sat, 25 Feb 2017 12:50:35 GMT"}], "update_date": "2017-08-07", "authors_parsed": [["Safayani", "Mehran", ""], ["Ahmadi", "Seyed Hashem", ""], ["Afrabandpey", "Homayun", ""], ["Mirzaei", "Abdolreza", ""]]}, {"id": "1702.07904", "submitter": "Ke Sun", "authors": "Ke Sun, Xiangliang Zhang", "title": "Coarse Grained Exponential Variational Autoencoders", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variational autoencoders (VAE) often use Gaussian or category distribution to\nmodel the inference process. This puts a limit on variational learning because\nthis simplified assumption does not match the true posterior distribution,\nwhich is usually much more sophisticated. To break this limitation and apply\narbitrary parametric distribution during inference, this paper derives a\n\\emph{semi-continuous} latent representation, which approximates a continuous\ndensity up to a prescribed precision, and is much easier to analyze than its\ncontinuous counterpart because it is fundamentally discrete. We showcase the\nproposition by applying polynomial exponential family distributions as the\nposterior, which are universal probability density function generators. Our\nexperimental results show consistent improvements over commonly used VAE\nmodels.\n", "versions": [{"version": "v1", "created": "Sat, 25 Feb 2017 15:08:53 GMT"}], "update_date": "2017-02-28", "authors_parsed": [["Sun", "Ke", ""], ["Zhang", "Xiangliang", ""]]}, {"id": "1702.07908", "submitter": "Sabri Pllana", "authors": "Andre Viebke, Suejb Memeti, Sabri Pllana, Ajith Abraham", "title": "CHAOS: A Parallelization Scheme for Training Convolutional Neural\n  Networks on Intel Xeon Phi", "comments": "The Journal of Supercomputing, 2017", "journal-ref": null, "doi": "10.1007/s11227-017-1994-x", "report-no": null, "categories": "cs.DC cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning is an important component of big-data analytic tools and\nintelligent applications, such as, self-driving cars, computer vision, speech\nrecognition, or precision medicine. However, the training process is\ncomputationally intensive, and often requires a large amount of time if\nperformed sequentially. Modern parallel computing systems provide the\ncapability to reduce the required training time of deep neural networks. In\nthis paper, we present our parallelization scheme for training convolutional\nneural networks (CNN) named Controlled Hogwild with Arbitrary Order of\nSynchronization (CHAOS). Major features of CHAOS include the support for thread\nand vector parallelism, non-instant updates of weight parameters during\nback-propagation without a significant delay, and implicit synchronization in\narbitrary order. CHAOS is tailored for parallel computing systems that are\naccelerated with the Intel Xeon Phi. We evaluate our parallelization approach\nempirically using measurement techniques and performance modeling for various\nnumbers of threads and CNN architectures. Experimental results for the MNIST\ndataset of handwritten digits using the total number of threads on the Xeon Phi\nshow speedups of up to 103x compared to the execution on one thread of the Xeon\nPhi, 14x compared to the sequential execution on Intel Xeon E5, and 58x\ncompared to the sequential execution on Intel Core i5.\n", "versions": [{"version": "v1", "created": "Sat, 25 Feb 2017 15:48:44 GMT"}], "update_date": "2017-02-28", "authors_parsed": [["Viebke", "Andre", ""], ["Memeti", "Suejb", ""], ["Pllana", "Sabri", ""], ["Abraham", "Ajith", ""]]}, {"id": "1702.07933", "submitter": "Zilong Tan", "authors": "Zilong Tan and Sayan Mukherjee", "title": "Efficient Learning of Mixed Membership Models", "comments": "23 pages, Proceedings of the 34th International Conference on Machine\n  Learning (ICML), Sydney, Australia, 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an efficient algorithm for learning mixed membership models when\nthe number of variables $p$ is much larger than the number of hidden components\n$k$. This algorithm reduces the computational complexity of state-of-the-art\ntensor methods, which require decomposing an $O\\left(p^3\\right)$ tensor, to\nfactorizing $O\\left(p/k\\right)$ sub-tensors each of size $O\\left(k^3\\right)$.\nIn addition, we address the issue of negative entries in the empirical method\nof moments based estimators. We provide sufficient conditions under which our\napproach has provable guarantees. Our approach obtains competitive empirical\nresults on both simulated and real data.\n", "versions": [{"version": "v1", "created": "Sat, 25 Feb 2017 18:00:57 GMT"}, {"version": "v2", "created": "Sun, 16 Apr 2017 19:53:50 GMT"}, {"version": "v3", "created": "Sun, 2 Jul 2017 21:03:37 GMT"}], "update_date": "2017-07-04", "authors_parsed": [["Tan", "Zilong", ""], ["Mukherjee", "Sayan", ""]]}, {"id": "1702.07944", "submitter": "Simon Du", "authors": "Simon S. Du, Jianshu Chen, Lihong Li, Lin Xiao, Dengyong Zhou", "title": "Stochastic Variance Reduction Methods for Policy Evaluation", "comments": "Accepted by ICML 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.SY math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Policy evaluation is a crucial step in many reinforcement-learning\nprocedures, which estimates a value function that predicts states' long-term\nvalue under a given policy. In this paper, we focus on policy evaluation with\nlinear function approximation over a fixed dataset. We first transform the\nempirical policy evaluation problem into a (quadratic) convex-concave saddle\npoint problem, and then present a primal-dual batch gradient method, as well as\ntwo stochastic variance reduction methods for solving the problem. These\nalgorithms scale linearly in both sample size and feature dimension. Moreover,\nthey achieve linear convergence even when the saddle-point problem has only\nstrong concavity in the dual variables but no strong convexity in the primal\nvariables. Numerical experiments on benchmark problems demonstrate the\neffectiveness of our methods.\n", "versions": [{"version": "v1", "created": "Sat, 25 Feb 2017 20:15:55 GMT"}, {"version": "v2", "created": "Fri, 9 Jun 2017 06:02:47 GMT"}], "update_date": "2017-06-12", "authors_parsed": [["Du", "Simon S.", ""], ["Chen", "Jianshu", ""], ["Li", "Lihong", ""], ["Xiao", "Lin", ""], ["Zhou", "Dengyong", ""]]}, {"id": "1702.07956", "submitter": "Jia-Jie Zhu", "authors": "Jia-Jie Zhu, Jos\\'e Bento", "title": "Generative Adversarial Active Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new active learning by query synthesis approach using Generative\nAdversarial Networks (GAN). Different from regular active learning, the\nresulting algorithm adaptively synthesizes training instances for querying to\nincrease learning speed. We generate queries according to the uncertainty\nprinciple, but our idea can work with other active learning principles. We\nreport results from various numerical experiments to demonstrate the\neffectiveness the proposed approach. In some settings, the proposed algorithm\noutperforms traditional pool-based approaches. To the best our knowledge, this\nis the first active learning work using GAN.\n", "versions": [{"version": "v1", "created": "Sat, 25 Feb 2017 22:45:20 GMT"}, {"version": "v2", "created": "Tue, 28 Feb 2017 21:04:00 GMT"}, {"version": "v3", "created": "Sat, 20 May 2017 06:25:51 GMT"}, {"version": "v4", "created": "Sun, 28 May 2017 05:40:22 GMT"}, {"version": "v5", "created": "Wed, 15 Nov 2017 21:50:12 GMT"}], "update_date": "2017-11-17", "authors_parsed": [["Zhu", "Jia-Jie", ""], ["Bento", "Jos\u00e9", ""]]}, {"id": "1702.07958", "submitter": "Chicheng Zhang", "authors": "Alina Beygelzimer, Francesco Orabona, Chicheng Zhang", "title": "Efficient Online Bandit Multiclass Learning with $\\tilde{O}(\\sqrt{T})$\n  Regret", "comments": "22 pages, 2 figures; ICML 2017; this version includes additional\n  discussions of Newtron, and a variant of SOBA that directly uses an online\n  exp-concave optimization oracle", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an efficient second-order algorithm with\n$\\tilde{O}(\\frac{1}{\\eta}\\sqrt{T})$ regret for the bandit online multiclass\nproblem. The regret bound holds simultaneously with respect to a family of loss\nfunctions parameterized by $\\eta$, for a range of $\\eta$ restricted by the norm\nof the competitor. The family of loss functions ranges from hinge loss\n($\\eta=0$) to squared hinge loss ($\\eta=1$). This provides a solution to the\nopen problem of (J. Abernethy and A. Rakhlin. An efficient bandit algorithm for\n$\\sqrt{T}$-regret in online multiclass prediction? In COLT, 2009). We test our\nalgorithm experimentally, showing that it also performs favorably against\nearlier algorithms.\n", "versions": [{"version": "v1", "created": "Sat, 25 Feb 2017 23:15:55 GMT"}, {"version": "v2", "created": "Tue, 13 Jun 2017 06:06:03 GMT"}, {"version": "v3", "created": "Wed, 17 Jan 2018 19:22:21 GMT"}], "update_date": "2018-01-19", "authors_parsed": [["Beygelzimer", "Alina", ""], ["Orabona", "Francesco", ""], ["Zhang", "Chicheng", ""]]}, {"id": "1702.07959", "submitter": "Abraham Smith", "authors": "Abraham Smith and Paul Bendich and John Harer and Alex Pieloch and Jay\n  Hineman", "title": "Supervised Learning of Labeled Pointcloud Differences via Cover-Tree\n  Entropy Reduction", "comments": "Distribution Statement A - Approved for public release, distribution\n  is unlimited. Version 2: added link to code, and some minor improvements.\n  Version 3: updated authors and thanks", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new algorithm, called CDER, for supervised machine learning\nthat merges the multi-scale geometric properties of Cover Trees with the\ninformation-theoretic properties of entropy. CDER applies to a training set of\nlabeled pointclouds embedded in a common Euclidean space. If typical\npointclouds corresponding to distinct labels tend to differ at any scale in any\nsub-region, CDER can identify these differences in (typically) linear time,\ncreating a set of distributional coordinates which act as a feature extraction\nmechanism for supervised learning. We describe theoretical properties and\nimplementation details of CDER, and illustrate its benefits on several\nsynthetic examples.\n", "versions": [{"version": "v1", "created": "Sun, 26 Feb 2017 00:17:42 GMT"}, {"version": "v2", "created": "Wed, 28 Jun 2017 14:15:31 GMT"}, {"version": "v3", "created": "Fri, 19 Jan 2018 19:30:37 GMT"}], "update_date": "2018-01-23", "authors_parsed": [["Smith", "Abraham", ""], ["Bendich", "Paul", ""], ["Harer", "John", ""], ["Pieloch", "Alex", ""], ["Hineman", "Jay", ""]]}, {"id": "1702.07966", "submitter": "Alon Brutzkus", "authors": "Alon Brutzkus, Amir Globerson", "title": "Globally Optimal Gradient Descent for a ConvNet with Gaussian Inputs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning models are often successfully trained using gradient descent,\ndespite the worst case hardness of the underlying non-convex optimization\nproblem. The key question is then under what conditions can one prove that\noptimization will succeed. Here we provide a strong result of this kind. We\nconsider a neural net with one hidden layer and a convolutional structure with\nno overlap and a ReLU activation function. For this architecture we show that\nlearning is NP-complete in the general case, but that when the input\ndistribution is Gaussian, gradient descent converges to the global optimum in\npolynomial time. To the best of our knowledge, this is the first global\noptimality guarantee of gradient descent on a convolutional neural network with\nReLU activations.\n", "versions": [{"version": "v1", "created": "Sun, 26 Feb 2017 01:12:20 GMT"}], "update_date": "2017-02-28", "authors_parsed": [["Brutzkus", "Alon", ""], ["Globerson", "Amir", ""]]}, {"id": "1702.07976", "submitter": "Mert Al", "authors": "Mert Al, Shibiao Wan, Sun-Yuan Kung", "title": "Ratio Utility and Cost Analysis for Privacy Preserving Subspace\n  Projection", "comments": "Submitted to ICASSP 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With a rapidly increasing number of devices connected to the internet, big\ndata has been applied to various domains of human life. Nevertheless, it has\nalso opened new venues for breaching users' privacy. Hence it is highly\nrequired to develop techniques that enable data owners to privatize their data\nwhile keeping it useful for intended applications. Existing methods, however,\ndo not offer enough flexibility for controlling the utility-privacy trade-off\nand may incur unfavorable results when privacy requirements are high. To tackle\nthese drawbacks, we propose a compressive-privacy based method, namely RUCA\n(Ratio Utility and Cost Analysis), which can not only maximize performance for\na privacy-insensitive classification task but also minimize the ability of any\nclassifier to infer private information from the data. Experimental results on\nCensus and Human Activity Recognition data sets demonstrate that RUCA\nsignificantly outperforms existing privacy preserving data projection\ntechniques for a wide range of privacy pricings.\n", "versions": [{"version": "v1", "created": "Sun, 26 Feb 2017 02:14:05 GMT"}], "update_date": "2017-02-28", "authors_parsed": [["Al", "Mert", ""], ["Wan", "Shibiao", ""], ["Kung", "Sun-Yuan", ""]]}, {"id": "1702.07983", "submitter": "Yanran Li", "authors": "Tong Che, Yanran Li, Ruixiang Zhang, R Devon Hjelm, Wenjie Li, Yangqiu\n  Song, Yoshua Bengio", "title": "Maximum-Likelihood Augmented Discrete Generative Adversarial Networks", "comments": "11 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the successes in capturing continuous distributions, the application\nof generative adversarial networks (GANs) to discrete settings, like natural\nlanguage tasks, is rather restricted. The fundamental reason is the difficulty\nof back-propagation through discrete random variables combined with the\ninherent instability of the GAN training objective. To address these problems,\nwe propose Maximum-Likelihood Augmented Discrete Generative Adversarial\nNetworks. Instead of directly optimizing the GAN objective, we derive a novel\nand low-variance objective using the discriminator's output that follows\ncorresponds to the log-likelihood. Compared with the original, the new\nobjective is proved to be consistent in theory and beneficial in practice. The\nexperimental results on various discrete datasets demonstrate the effectiveness\nof the proposed approach.\n", "versions": [{"version": "v1", "created": "Sun, 26 Feb 2017 03:19:13 GMT"}], "update_date": "2017-02-28", "authors_parsed": [["Che", "Tong", ""], ["Li", "Yanran", ""], ["Zhang", "Ruixiang", ""], ["Hjelm", "R Devon", ""], ["Li", "Wenjie", ""], ["Song", "Yangqiu", ""], ["Bengio", "Yoshua", ""]]}, {"id": "1702.08000", "submitter": "Rahul  Singh", "authors": "Rahul Singh and Taposh Banerjee", "title": "Kiefer Wolfowitz Algorithm is Asymptotically Optimal for a Class of\n  Non-Stationary Bandit Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of designing an allocation rule or an \"online\nlearning algorithm\" for a class of bandit problems in which the set of control\nactions available at each time $s$ is a convex, compact subset of\n$\\mathbb{R}^d$. Upon choosing an action $x$ at time $s$, the algorithm obtains\na noisy value of the unknown and time-varying function $f_s$ evaluated at $x$.\nThe \"regret\" of an algorithm is the gap between its expected reward, and the\nreward earned by a strategy which has the knowledge of the function $f_s$ at\neach time $s$ and hence chooses the action $x_s$ that maximizes $f_s$.\n  For this non-stationary bandit problem set-up, we consider two variants of\nthe Kiefer Wolfowitz (KW) algorithm i) KW with fixed step-size $\\beta$, and ii)\nKW with sliding window of length $L$. We show that if the number of times that\nthe function $f_s$ varies during time $T$ is $o(T)$, and if the learning rates\nof the proposed algorithms are chosen \"optimally\", then the regret of the\nproposed algorithms is $o(T)$, and hence the algorithms are asymptotically\nefficient.\n", "versions": [{"version": "v1", "created": "Sun, 26 Feb 2017 08:24:11 GMT"}, {"version": "v2", "created": "Wed, 8 Mar 2017 08:38:08 GMT"}], "update_date": "2017-03-09", "authors_parsed": [["Singh", "Rahul", ""], ["Banerjee", "Taposh", ""]]}, {"id": "1702.08001", "submitter": "J\\\"urgen Hahn", "authors": "J\\\"urgen Hahn and Abdelhak M. Zoubir", "title": "Bayesian Nonparametric Feature and Policy Learning for Decision-Making", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning from demonstrations has gained increasing interest in the recent\npast, enabling an agent to learn how to make decisions by observing an\nexperienced teacher. While many approaches have been proposed to solve this\nproblem, there is only little work that focuses on reasoning about the observed\nbehavior. We assume that, in many practical problems, an agent makes its\ndecision based on latent features, indicating a certain action. Therefore, we\npropose a generative model for the states and actions. Inference reveals the\nnumber of features, the features, and the policies, allowing us to learn and to\nanalyze the underlying structure of the observed behavior. Further, our\napproach enables prediction of actions for new states. Simulations are used to\nassess the performance of the algorithm based upon this model. Moreover, the\nproblem of learning a driver's behavior is investigated, demonstrating the\nperformance of the proposed model in a real-world scenario.\n", "versions": [{"version": "v1", "created": "Sun, 26 Feb 2017 08:34:26 GMT"}], "update_date": "2017-02-28", "authors_parsed": [["Hahn", "J\u00fcrgen", ""], ["Zoubir", "Abdelhak M.", ""]]}, {"id": "1702.08019", "submitter": "Kazuyoshi Yata", "authors": "Yugo Nakayama, Kazuyoshi Yata, Makoto Aoshima", "title": "Support vector machine and its bias correction in high-dimension,\n  low-sample-size settings", "comments": "23 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider asymptotic properties of the support vector\nmachine (SVM) in high-dimension, low-sample-size (HDLSS) settings. We show that\nthe hard-margin linear SVM holds a consistency property in which\nmisclassification rates tend to zero as the dimension goes to infinity under\ncertain severe conditions. We show that the SVM is very biased in HDLSS\nsettings and its performance is affected by the bias directly. In order to\novercome such difficulties, we propose a bias-corrected SVM (BC-SVM). We show\nthat the BC-SVM gives preferable performances in HDLSS settings. We also\ndiscuss the SVMs in multiclass HDLSS settings. Finally, we check the\nperformance of the classifiers in actual data analyses.\n", "versions": [{"version": "v1", "created": "Sun, 26 Feb 2017 10:38:39 GMT"}], "update_date": "2017-02-28", "authors_parsed": [["Nakayama", "Yugo", ""], ["Yata", "Kazuyoshi", ""], ["Aoshima", "Makoto", ""]]}, {"id": "1702.08039", "submitter": "Dan Oprisa", "authors": "Dan Oprisa, Peter Toth", "title": "Criticality & Deep Learning I: Generally Weighted Nets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by the idea that criticality and universality of phase transitions\nmight play a crucial role in achieving and sustaining learning and intelligent\nbehaviour in biological and artificial networks, we analyse a theoretical and a\npragmatic experimental set up for critical phenomena in deep learning. On the\ntheoretical side, we use results from statistical physics to carry out critical\npoint calculations in feed-forward/fully connected networks, while on the\nexperimental side we set out to find traces of criticality in deep neural\nnetworks. This is our first step in a series of upcoming investigations to map\nout the relationship between criticality and learning in deep networks.\n", "versions": [{"version": "v1", "created": "Sun, 26 Feb 2017 14:43:38 GMT"}, {"version": "v2", "created": "Wed, 31 May 2017 09:38:30 GMT"}], "update_date": "2017-06-01", "authors_parsed": [["Oprisa", "Dan", ""], ["Toth", "Peter", ""]]}, {"id": "1702.08074", "submitter": "Ayal Taitler", "authors": "Ayal Taitler and Nahum Shimkin", "title": "Learning Control for Air Hockey Striking using Deep Reinforcement\n  Learning", "comments": "Corrected typos Graphs added in results section", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the task of learning control policies for a robotic mechanism\nstriking a puck in an air hockey game. The control signal is a direct command\nto the robot's motors. We employ a model free deep reinforcement learning\nframework to learn the motoric skills of striking the puck accurately in order\nto score. We propose certain improvements to the standard learning scheme which\nmake the deep Q-learning algorithm feasible when it might otherwise fail. Our\nimprovements include integrating prior knowledge into the learning scheme, and\naccounting for the changing distribution of samples in the experience replay\nbuffer. Finally we present our simulation results for aimed striking which\ndemonstrate the successful learning of this task, and the improvement in\nalgorithm stability due to the proposed modifications.\n", "versions": [{"version": "v1", "created": "Sun, 26 Feb 2017 19:59:59 GMT"}, {"version": "v2", "created": "Tue, 25 Apr 2017 10:52:33 GMT"}], "update_date": "2017-04-26", "authors_parsed": [["Taitler", "Ayal", ""], ["Shimkin", "Nahum", ""]]}, {"id": "1702.08088", "submitter": "Deniz Akdemir", "authors": "Deniz Akdemir", "title": "Selection of training populations (and other subset selection problems)\n  with an accelerated genetic algorithm (STPGA: An R-package for selection of\n  training populations with a genetic algorithm)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.LG q-bio.GN q-bio.QM stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optimal subset selection is an important task that has numerous algorithms\ndesigned for it and has many application areas. STPGA contains a special\ngenetic algorithm supplemented with a tabu memory property (that keeps track of\npreviously tried solutions and their fitness for a number of iterations), and\nwith a regression of the fitness of the solutions on their coding that is used\nto form the ideal estimated solution (look ahead property) to search for\nsolutions of generic optimal subset selection problems. I have initially\ndeveloped the programs for the specific problem of selecting training\npopulations for genomic prediction or association problems, therefore I give\ndiscussion of the theory behind optimal design of experiments to explain the\ndefault optimization criteria in STPGA, and illustrate the use of the programs\nin this endeavor. Nevertheless, I have picked a few other areas of application:\nsupervised and unsupervised variable selection based on kernel alignment,\nsupervised variable selection with design criteria, influential observation\nidentification for regression, solving mixed integer quadratic optimization\nproblems, balancing gains and inbreeding in a breeding population. Some of\nthese illustrations pertain new statistical approaches.\n", "versions": [{"version": "v1", "created": "Sun, 26 Feb 2017 21:23:33 GMT"}], "update_date": "2017-02-28", "authors_parsed": [["Akdemir", "Deniz", ""]]}, {"id": "1702.08134", "submitter": "Zhehui Chen", "authors": "Zhehui Chen, Lin F. Yang, Chris J. Li, Tuo Zhao", "title": "Dropping Convexity for More Efficient and Scalable Online Multiview\n  Learning", "comments": "A preliminary version appears in ICML 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multiview representation learning is very popular for latent factor analysis.\nIt naturally arises in many data analysis, machine learning, and information\nretrieval applications to model dependent structures among multiple data\nsources. For computational convenience, existing approaches usually formulate\nthe multiview representation learning as convex optimization problems, where\nglobal optima can be obtained by certain algorithms in polynomial time.\nHowever, many pieces of evidence have corroborated that heuristic nonconvex\napproaches also have good empirical computational performance and convergence\nto the global optima, although there is a lack of theoretical justification.\nSuch a gap between theory and practice motivates us to study a nonconvex\nformulation for multiview representation learning, which can be efficiently\nsolved by a simple stochastic gradient descent (SGD) algorithm. We first\nillustrate the geometry of the nonconvex formulation; Then, we establish\nasymptotic global rates of convergence to the global optima by diffusion\napproximations. Numerical experiments are provided to support our theory.\n", "versions": [{"version": "v1", "created": "Mon, 27 Feb 2017 03:51:46 GMT"}, {"version": "v10", "created": "Mon, 16 Sep 2019 01:00:53 GMT"}, {"version": "v2", "created": "Thu, 2 Mar 2017 18:50:40 GMT"}, {"version": "v3", "created": "Fri, 24 Mar 2017 00:21:18 GMT"}, {"version": "v4", "created": "Mon, 5 Jun 2017 22:20:23 GMT"}, {"version": "v5", "created": "Sat, 22 Jul 2017 17:58:40 GMT"}, {"version": "v6", "created": "Sat, 14 Oct 2017 19:19:19 GMT"}, {"version": "v7", "created": "Wed, 23 May 2018 13:47:47 GMT"}, {"version": "v8", "created": "Thu, 31 May 2018 18:41:42 GMT"}, {"version": "v9", "created": "Sun, 6 Jan 2019 15:46:41 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Chen", "Zhehui", ""], ["Yang", "Lin F.", ""], ["Li", "Chris J.", ""], ["Zhao", "Tuo", ""]]}, {"id": "1702.08138", "submitter": "Hossein Hosseini", "authors": "Hossein Hosseini, Sreeram Kannan, Baosen Zhang and Radha Poovendran", "title": "Deceiving Google's Perspective API Built for Detecting Toxic Comments", "comments": "4 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Social media platforms provide an environment where people can freely engage\nin discussions. Unfortunately, they also enable several problems, such as\nonline harassment. Recently, Google and Jigsaw started a project called\nPerspective, which uses machine learning to automatically detect toxic\nlanguage. A demonstration website has been also launched, which allows anyone\nto type a phrase in the interface and instantaneously see the toxicity score\n[1]. In this paper, we propose an attack on the Perspective toxic detection\nsystem based on the adversarial examples. We show that an adversary can subtly\nmodify a highly toxic phrase in a way that the system assigns significantly\nlower toxicity score to it. We apply the attack on the sample phrases provided\nin the Perspective website and show that we can consistently reduce the\ntoxicity scores to the level of the non-toxic phrases. The existence of such\nadversarial examples is very harmful for toxic detection systems and seriously\nundermines their usability.\n", "versions": [{"version": "v1", "created": "Mon, 27 Feb 2017 04:07:36 GMT"}], "update_date": "2017-02-28", "authors_parsed": [["Hosseini", "Hossein", ""], ["Kannan", "Sreeram", ""], ["Zhang", "Baosen", ""], ["Poovendran", "Radha", ""]]}, {"id": "1702.08139", "submitter": "Zichao Yang", "authors": "Zichao Yang, Zhiting Hu, Ruslan Salakhutdinov, Taylor Berg-Kirkpatrick", "title": "Improved Variational Autoencoders for Text Modeling using Dilated\n  Convolutions", "comments": "camera ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work on generative modeling of text has found that variational\nauto-encoders (VAE) incorporating LSTM decoders perform worse than simpler LSTM\nlanguage models (Bowman et al., 2015). This negative result is so far poorly\nunderstood, but has been attributed to the propensity of LSTM decoders to\nignore conditioning information from the encoder. In this paper, we experiment\nwith a new type of decoder for VAE: a dilated CNN. By changing the decoder's\ndilation architecture, we control the effective context from previously\ngenerated words. In experiments, we find that there is a trade off between the\ncontextual capacity of the decoder and the amount of encoding information used.\nWe show that with the right decoder, VAE can outperform LSTM language models.\nWe demonstrate perplexity gains on two datasets, representing the first\npositive experimental result on the use VAE for generative modeling of text.\nFurther, we conduct an in-depth investigation of the use of VAE (with our new\ndecoding architecture) for semi-supervised and unsupervised labeling tasks,\ndemonstrating gains over several strong baselines.\n", "versions": [{"version": "v1", "created": "Mon, 27 Feb 2017 04:16:01 GMT"}, {"version": "v2", "created": "Sun, 18 Jun 2017 00:31:34 GMT"}], "update_date": "2017-06-20", "authors_parsed": [["Yang", "Zichao", ""], ["Hu", "Zhiting", ""], ["Salakhutdinov", "Ruslan", ""], ["Berg-Kirkpatrick", "Taylor", ""]]}, {"id": "1702.08159", "submitter": "J. D. Curt\\'o", "authors": "J. D. Curt\\'o and I. C. Zarza and Feng Yang and Alex Smola and\n  Fernando de la Torre and Chong Wah Ngo and Luc van Gool", "title": "McKernel: A Library for Approximate Kernel Expansions in Log-linear Time", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  McKernel introduces a framework to use kernel approximates in the mini-batch\nsetting with Stochastic Gradient Descent (SGD) as an alternative to Deep\nLearning. Based on Random Kitchen Sinks [Rahimi and Recht 2007], we provide a\nC++ library for Large-scale Machine Learning. It contains a CPU optimized\nimplementation of the algorithm in [Le et al. 2013], that allows the\ncomputation of approximated kernel expansions in log-linear time. The algorithm\nrequires to compute the product of matrices Walsh Hadamard. A cache friendly\nFast Walsh Hadamard that achieves compelling speed and outperforms current\nstate-of-the-art methods has been developed. McKernel establishes the\nfoundation of a new architecture of learning that allows to obtain large-scale\nnon-linear classification combining lightning kernel expansions and a linear\nclassifier. It travails in the mini-batch setting working analogously to Neural\nNetworks. We show the validity of our method through extensive experiments on\nMNIST and FASHION MNIST [Xiao et al. 2017].\n", "versions": [{"version": "v1", "created": "Mon, 27 Feb 2017 06:30:47 GMT"}, {"version": "v10", "created": "Sun, 6 Jan 2019 22:23:07 GMT"}, {"version": "v11", "created": "Thu, 24 Jan 2019 16:57:42 GMT"}, {"version": "v12", "created": "Wed, 20 Feb 2019 16:43:18 GMT"}, {"version": "v13", "created": "Sun, 24 Mar 2019 17:06:08 GMT"}, {"version": "v14", "created": "Tue, 31 Dec 2019 18:54:43 GMT"}, {"version": "v15", "created": "Fri, 17 Apr 2020 16:47:47 GMT"}, {"version": "v2", "created": "Tue, 27 Mar 2018 17:23:07 GMT"}, {"version": "v3", "created": "Thu, 19 Apr 2018 13:00:28 GMT"}, {"version": "v4", "created": "Tue, 24 Apr 2018 11:20:51 GMT"}, {"version": "v5", "created": "Thu, 10 May 2018 12:20:03 GMT"}, {"version": "v6", "created": "Sun, 20 May 2018 12:03:42 GMT"}, {"version": "v7", "created": "Wed, 30 May 2018 17:07:46 GMT"}, {"version": "v8", "created": "Thu, 31 May 2018 06:26:35 GMT"}, {"version": "v9", "created": "Sun, 10 Jun 2018 11:04:31 GMT"}], "update_date": "2020-04-20", "authors_parsed": [["Curt\u00f3", "J. D.", ""], ["Zarza", "I. C.", ""], ["Yang", "Feng", ""], ["Smola", "Alex", ""], ["de la Torre", "Fernando", ""], ["Ngo", "Chong Wah", ""], ["van Gool", "Luc", ""]]}, {"id": "1702.08165", "submitter": "Tuomas Haarnoja", "authors": "Tuomas Haarnoja, Haoran Tang, Pieter Abbeel, Sergey Levine", "title": "Reinforcement Learning with Deep Energy-Based Policies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a method for learning expressive energy-based policies for\ncontinuous states and actions, which has been feasible only in tabular domains\nbefore. We apply our method to learning maximum entropy policies, resulting\ninto a new algorithm, called soft Q-learning, that expresses the optimal policy\nvia a Boltzmann distribution. We use the recently proposed amortized Stein\nvariational gradient descent to learn a stochastic sampling network that\napproximates samples from this distribution. The benefits of the proposed\nalgorithm include improved exploration and compositionality that allows\ntransferring skills between tasks, which we confirm in simulated experiments\nwith swimming and walking robots. We also draw a connection to actor-critic\nmethods, which can be viewed performing approximate inference on the\ncorresponding energy-based model.\n", "versions": [{"version": "v1", "created": "Mon, 27 Feb 2017 07:16:41 GMT"}, {"version": "v2", "created": "Fri, 21 Jul 2017 20:25:54 GMT"}], "update_date": "2017-07-25", "authors_parsed": [["Haarnoja", "Tuomas", ""], ["Tang", "Haoran", ""], ["Abbeel", "Pieter", ""], ["Levine", "Sergey", ""]]}, {"id": "1702.08169", "submitter": "Dan Garber", "authors": "Dan Garber, Ohad Shamir, Nathan Srebro", "title": "Communication-efficient Algorithms for Distributed Stochastic Principal\n  Component Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the fundamental problem of Principal Component Analysis in a\nstatistical distributed setting in which each machine out of $m$ stores a\nsample of $n$ points sampled i.i.d. from a single unknown distribution. We\nstudy algorithms for estimating the leading principal component of the\npopulation covariance matrix that are both communication-efficient and achieve\nestimation error of the order of the centralized ERM solution that uses all\n$mn$ samples. On the negative side, we show that in contrast to results\nobtained for distributed estimation under convexity assumptions, for the PCA\nobjective, simply averaging the local ERM solutions cannot guarantee error that\nis consistent with the centralized ERM. We show that this unfortunate phenomena\ncan be remedied by performing a simple correction step which correlates between\nthe individual solutions, and provides an estimator that is consistent with the\ncentralized ERM for sufficiently-large $n$. We also introduce an iterative\ndistributed algorithm that is applicable in any regime of $n$, which is based\non distributed matrix-vector products. The algorithm gives significant\nacceleration in terms of communication rounds over previous distributed\nalgorithms, in a wide regime of parameters.\n", "versions": [{"version": "v1", "created": "Mon, 27 Feb 2017 07:45:58 GMT"}], "update_date": "2017-02-28", "authors_parsed": [["Garber", "Dan", ""], ["Shamir", "Ohad", ""], ["Srebro", "Nathan", ""]]}, {"id": "1702.08171", "submitter": "Sungho Shin", "authors": "Sungho Shin, Yoonho Boo, and Wonyong Sung", "title": "Fixed-point optimization of deep neural networks with adaptive step size\n  retraining", "comments": "This paper is accepted in ICASSP 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fixed-point optimization of deep neural networks plays an important role in\nhardware based design and low-power implementations. Many deep neural networks\nshow fairly good performance even with 2- or 3-bit precision when quantized\nweights are fine-tuned by retraining. We propose an improved fixedpoint\noptimization algorithm that estimates the quantization step size dynamically\nduring the retraining. In addition, a gradual quantization scheme is also\ntested, which sequentially applies fixed-point optimizations from high- to\nlow-precision. The experiments are conducted for feed-forward deep neural\nnetworks (FFDNNs), convolutional neural networks (CNNs), and recurrent neural\nnetworks (RNNs).\n", "versions": [{"version": "v1", "created": "Mon, 27 Feb 2017 08:00:58 GMT"}], "update_date": "2017-02-28", "authors_parsed": [["Shin", "Sungho", ""], ["Boo", "Yoonho", ""], ["Sung", "Wonyong", ""]]}, {"id": "1702.08192", "submitter": "Christian Wachinger", "authors": "Christian Wachinger, Martin Reuter, Tassilo Klein", "title": "DeepNAT: Deep Convolutional Neural Network for Segmenting Neuroanatomy", "comments": "Accepted for publication in NeuroImage, special issue \"Brain\n  Segmentation and Parcellation\", 2017", "journal-ref": null, "doi": "10.1016/j.neuroimage.2017.02.035", "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce DeepNAT, a 3D Deep convolutional neural network for the\nautomatic segmentation of NeuroAnaTomy in T1-weighted magnetic resonance\nimages. DeepNAT is an end-to-end learning-based approach to brain segmentation\nthat jointly learns an abstract feature representation and a multi-class\nclassification. We propose a 3D patch-based approach, where we do not only\npredict the center voxel of the patch but also neighbors, which is formulated\nas multi-task learning. To address a class imbalance problem, we arrange two\nnetworks hierarchically, where the first one separates foreground from\nbackground, and the second one identifies 25 brain structures on the\nforeground. Since patches lack spatial context, we augment them with\ncoordinates. To this end, we introduce a novel intrinsic parameterization of\nthe brain volume, formed by eigenfunctions of the Laplace-Beltrami operator. As\nnetwork architecture, we use three convolutional layers with pooling, batch\nnormalization, and non-linearities, followed by fully connected layers with\ndropout. The final segmentation is inferred from the probabilistic output of\nthe network with a 3D fully connected conditional random field, which ensures\nlabel agreement between close voxels. The roughly 2.7 million parameters in the\nnetwork are learned with stochastic gradient descent. Our results show that\nDeepNAT compares favorably to state-of-the-art methods. Finally, the purely\nlearning-based method may have a high potential for the adaptation to young,\nold, or diseased brains by fine-tuning the pre-trained network with a small\ntraining sample on the target application, where the availability of larger\ndatasets with manual annotations may boost the overall segmentation accuracy in\nthe future.\n", "versions": [{"version": "v1", "created": "Mon, 27 Feb 2017 08:53:31 GMT"}], "update_date": "2017-02-28", "authors_parsed": [["Wachinger", "Christian", ""], ["Reuter", "Martin", ""], ["Klein", "Tassilo", ""]]}, {"id": "1702.08211", "submitter": "Sebastien Gerchinovitz", "authors": "Nicol\\`o Cesa-Bianchi, Pierre Gaillard (SIERRA), Claudio Gentile,\n  S\\'ebastien Gerchinovitz (IMT)", "title": "Algorithmic Chaining and the Role of Partial Feedback in Online\n  Nonparametric Learning", "comments": "This document is the full version of an extended abstract accepted\n  for presentation at COLT 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate contextual online learning with nonparametric (Lipschitz)\ncomparison classes under different assumptions on losses and feedback\ninformation. For full information feedback and Lipschitz losses, we design the\nfirst explicit algorithm achieving the minimax regret rate (up to log factors).\nIn a partial feedback model motivated by second-price auctions, we obtain\nalgorithms for Lipschitz and semi-Lipschitz losses with regret bounds improving\non the known bounds for standard bandit feedback. Our analysis combines novel\nresults for contextual second-price auctions with a novel algorithmic approach\nbased on chaining. When the context space is Euclidean, our chaining approach\nis efficient and delivers an even better regret bound.\n", "versions": [{"version": "v1", "created": "Mon, 27 Feb 2017 10:01:36 GMT"}, {"version": "v2", "created": "Fri, 30 Jun 2017 08:19:49 GMT"}], "update_date": "2017-07-03", "authors_parsed": [["Cesa-Bianchi", "Nicol\u00f2", "", "SIERRA"], ["Gaillard", "Pierre", "", "SIERRA"], ["Gentile", "Claudio", "", "IMT"], ["Gerchinovitz", "S\u00e9bastien", "", "IMT"]]}, {"id": "1702.08235", "submitter": "Ferenc Husz\\'ar", "authors": "Ferenc Husz\\'ar", "title": "Variational Inference using Implicit Distributions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative adversarial networks (GANs) have given us a great tool to fit\nimplicit generative models to data. Implicit distributions are ones we can\nsample from easily, and take derivatives of samples with respect to model\nparameters. These models are highly expressive and we argue they can prove just\nas useful for variational inference (VI) as they are for generative modelling.\nSeveral papers have proposed GAN-like algorithms for inference, however,\nconnections to the theory of VI are not always well understood. This paper\nprovides a unifying review of existing algorithms establishing connections\nbetween variational autoencoders, adversarially learned inference, operator VI,\nGAN-based image reconstruction, and more. Secondly, the paper provides a\nframework for building new algorithms: depending on the way the variational\nbound is expressed we introduce prior-contrastive and joint-contrastive\nmethods, and show practical inference algorithms based on either density ratio\nestimation or denoising.\n", "versions": [{"version": "v1", "created": "Mon, 27 Feb 2017 11:16:54 GMT"}], "update_date": "2017-02-28", "authors_parsed": [["Husz\u00e1r", "Ferenc", ""]]}, {"id": "1702.08248", "submitter": "Olivier Bachem", "authors": "Olivier Bachem, Mario Lucic, Andreas Krause", "title": "Scalable k-Means Clustering via Lightweight Coresets", "comments": "To appear in the 24th ACM SIGKDD International Conference on\n  Knowledge Discovery & Data Mining (KDD)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.DC cs.DS cs.LG stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Coresets are compact representations of data sets such that models trained on\na coreset are provably competitive with models trained on the full data set. As\nsuch, they have been successfully used to scale up clustering models to massive\ndata sets. While existing approaches generally only allow for multiplicative\napproximation errors, we propose a novel notion of lightweight coresets that\nallows for both multiplicative and additive errors. We provide a single\nalgorithm to construct lightweight coresets for k-means clustering as well as\nsoft and hard Bregman clustering. The algorithm is substantially faster than\nexisting constructions, embarrassingly parallel, and the resulting coresets are\nsmaller. We further show that the proposed approach naturally generalizes to\nstatistical k-means clustering and that, compared to existing results, it can\nbe used to compute smaller summaries for empirical risk minimization. In\nextensive experiments, we demonstrate that the proposed algorithm outperforms\nexisting data summarization strategies in practice.\n", "versions": [{"version": "v1", "created": "Mon, 27 Feb 2017 12:03:01 GMT"}, {"version": "v2", "created": "Wed, 6 Jun 2018 21:49:52 GMT"}], "update_date": "2018-06-08", "authors_parsed": [["Bachem", "Olivier", ""], ["Lucic", "Mario", ""], ["Krause", "Andreas", ""]]}, {"id": "1702.08249", "submitter": "Olivier Bachem", "authors": "Olivier Bachem, Mario Lucic, S. Hamed Hassani, Andreas Krause", "title": "Uniform Deviation Bounds for Unbounded Loss Functions like k-Means", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Uniform deviation bounds limit the difference between a model's expected loss\nand its loss on an empirical sample uniformly for all models in a learning\nproblem. As such, they are a critical component to empirical risk minimization.\nIn this paper, we provide a novel framework to obtain uniform deviation bounds\nfor loss functions which are *unbounded*. In our main application, this allows\nus to obtain bounds for $k$-Means clustering under weak assumptions on the\nunderlying distribution. If the fourth moment is bounded, we prove a rate of\n$\\mathcal{O}\\left(m^{-\\frac12}\\right)$ compared to the previously known\n$\\mathcal{O}\\left(m^{-\\frac14}\\right)$ rate. Furthermore, we show that the rate\nalso depends on the kurtosis - the normalized fourth moment which measures the\n\"tailedness\" of a distribution. We further provide improved rates under\nprogressively stronger assumptions, namely, bounded higher moments,\nsubgaussianity and bounded support.\n", "versions": [{"version": "v1", "created": "Mon, 27 Feb 2017 12:03:41 GMT"}], "update_date": "2017-02-28", "authors_parsed": [["Bachem", "Olivier", ""], ["Lucic", "Mario", ""], ["Hassani", "S. Hamed", ""], ["Krause", "Andreas", ""]]}, {"id": "1702.08259", "submitter": "Hiroshi Inoue", "authors": "Hiroshi Inoue", "title": "Adaptive Ensemble Prediction for Deep Neural Networks based on\n  Confidence Level", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ensembling multiple predictions is a widely used technique for improving the\naccuracy of various machine learning tasks. One obvious drawback of ensembling\nis its higher execution cost during inference. In this paper, we first describe\nour insights on the relationship between the probability of prediction and the\neffect of ensembling with current deep neural networks; ensembling does not\nhelp mispredictions for inputs predicted with a high probability even when\nthere is a non-negligible number of mispredicted inputs. This finding motivated\nus to develop a way to adaptively control the ensembling. If the prediction for\nan input reaches a high enough probability, i.e., the output from the softmax\nfunction, on the basis of the confidence level, we stop ensembling for this\ninput to avoid wasting computation power. We evaluated the adaptive ensembling\nby using various datasets and showed that it reduces the computation cost\nsignificantly while achieving accuracy similar to that of static ensembling\nusing a pre-defined number of local predictions. We also show that our\nstatistically rigorous confidence-level-based early-exit condition reduces the\nburden of task-dependent threshold tuning better compared with naive early exit\nbased on a pre-defined threshold in addition to yielding a better accuracy with\nthe same cost.\n", "versions": [{"version": "v1", "created": "Mon, 27 Feb 2017 12:54:54 GMT"}, {"version": "v2", "created": "Sat, 28 Jul 2018 13:35:42 GMT"}, {"version": "v3", "created": "Fri, 8 Mar 2019 11:46:51 GMT"}], "update_date": "2019-03-11", "authors_parsed": [["Inoue", "Hiroshi", ""]]}, {"id": "1702.08283", "submitter": "Valentina Gregori", "authors": "Valentina Gregori, Arjan Gijsberts, Barbara Caputo", "title": "Adaptive Learning to Speed-Up Control of Prosthetic Hands: a Few Things\n  Everybody Should Know", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A number of studies have proposed to use domain adaptation to reduce the\ntraining efforts needed to control an upper-limb prosthesis exploiting\npre-trained models from prior subjects. These studies generally reported\nimpressive reductions in the required number of training samples to achieve a\ncertain level of accuracy for intact subjects. We further investigate two\npopular methods in this field to verify whether this result equally applies to\namputees. Our findings show instead that this improvement can largely be\nattributed to a suboptimal hyperparameter configuration. When hyperparameters\nare appropriately tuned, the standard approach that does not exploit prior\ninformation performs on par with the more complicated transfer learning\nalgorithms. Additionally, earlier studies erroneously assumed that the number\nof training samples relates proportionally to the efforts required from the\nsubject. However, a repetition of a movement is the atomic unit for subjects\nand the total number of repetitions should therefore be used as reliable\nmeasure for training efforts. Also when correcting for this mistake, we do not\nfind any performance increase due to the use of prior models.\n", "versions": [{"version": "v1", "created": "Mon, 27 Feb 2017 13:49:42 GMT"}], "update_date": "2017-02-28", "authors_parsed": [["Gregori", "Valentina", ""], ["Gijsberts", "Arjan", ""], ["Caputo", "Barbara", ""]]}, {"id": "1702.08343", "submitter": "Yingzhen Li", "authors": "Yingzhen Li, Richard E. Turner, Qiang Liu", "title": "Approximate Inference with Amortised MCMC", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel approximate inference algorithm that approximates a target\ndistribution by amortising the dynamics of a user-selected MCMC sampler. The\nidea is to initialise MCMC using samples from an approximation network, apply\nthe MCMC operator to improve these samples, and finally use the samples to\nupdate the approximation network thereby improving its quality. This provides a\nnew generic framework for approximate inference, allowing us to deploy highly\ncomplex, or implicitly defined approximation families with intractable\ndensities, including approximations produced by warping a source of randomness\nthrough a deep neural network. Experiments consider image modelling with deep\ngenerative models as a challenging test for the method. Deep models trained\nusing amortised MCMC are shown to generate realistic looking samples as well as\nproducing diverse imputations for images with regions of missing pixels.\n", "versions": [{"version": "v1", "created": "Mon, 27 Feb 2017 16:01:46 GMT"}, {"version": "v2", "created": "Mon, 22 May 2017 10:50:32 GMT"}], "update_date": "2017-05-23", "authors_parsed": [["Li", "Yingzhen", ""], ["Turner", "Richard E.", ""], ["Liu", "Qiang", ""]]}, {"id": "1702.08359", "submitter": "Robert Bamler", "authors": "Robert Bamler and Stephan Mandt", "title": "Dynamic Word Embeddings", "comments": "In the proceedings of the International Conference on Machine\n  Learning (ICML 2017); 8 pages + references and supplement", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a probabilistic language model for time-stamped text data which\ntracks the semantic evolution of individual words over time. The model\nrepresents words and contexts by latent trajectories in an embedding space. At\neach moment in time, the embedding vectors are inferred from a probabilistic\nversion of word2vec [Mikolov et al., 2013]. These embedding vectors are\nconnected in time through a latent diffusion process. We describe two scalable\nvariational inference algorithms--skip-gram smoothing and skip-gram\nfiltering--that allow us to train the model jointly over all times; thus\nlearning on all data while simultaneously allowing word and context vectors to\ndrift. Experimental results on three different corpora demonstrate that our\ndynamic model infers word embedding trajectories that are more interpretable\nand lead to higher predictive likelihoods than competing methods that are based\non static models trained separately on time slices.\n", "versions": [{"version": "v1", "created": "Mon, 27 Feb 2017 16:31:48 GMT"}, {"version": "v2", "created": "Mon, 17 Jul 2017 23:45:06 GMT"}], "update_date": "2017-07-19", "authors_parsed": [["Bamler", "Robert", ""], ["Mandt", "Stephan", ""]]}, {"id": "1702.08360", "submitter": "Emilio Parisotto", "authors": "Emilio Parisotto and Ruslan Salakhutdinov", "title": "Neural Map: Structured Memory for Deep Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A critical component to enabling intelligent reasoning in partially\nobservable environments is memory. Despite this importance, Deep Reinforcement\nLearning (DRL) agents have so far used relatively simple memory architectures,\nwith the main methods to overcome partial observability being either a temporal\nconvolution over the past k frames or an LSTM layer. More recent work (Oh et\nal., 2016) has went beyond these architectures by using memory networks which\ncan allow more sophisticated addressing schemes over the past k frames. But\neven these architectures are unsatisfactory due to the reason that they are\nlimited to only remembering information from the last k frames. In this paper,\nwe develop a memory system with an adaptable write operator that is customized\nto the sorts of 3D environments that DRL agents typically interact with. This\narchitecture, called the Neural Map, uses a spatially structured 2D memory\nimage to learn to store arbitrary information about the environment over long\ntime lags. We demonstrate empirically that the Neural Map surpasses previous\nDRL memories on a set of challenging 2D and 3D maze environments and show that\nit is capable of generalizing to environments that were not seen during\ntraining.\n", "versions": [{"version": "v1", "created": "Mon, 27 Feb 2017 16:32:27 GMT"}], "update_date": "2017-02-28", "authors_parsed": [["Parisotto", "Emilio", ""], ["Salakhutdinov", "Ruslan", ""]]}, {"id": "1702.08396", "submitter": "Shengjia Zhao", "authors": "Shengjia Zhao, Jiaming Song, Stefano Ermon", "title": "Learning Hierarchical Features from Generative Models", "comments": "ICML'2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks have been shown to be very successful at learning\nfeature hierarchies in supervised learning tasks. Generative models, on the\nother hand, have benefited less from hierarchical models with multiple layers\nof latent variables. In this paper, we prove that hierarchical latent variable\nmodels do not take advantage of the hierarchical structure when trained with\nexisting variational methods, and provide some limitations on the kind of\nfeatures existing models can learn. Finally we propose an alternative\narchitecture that do not suffer from these limitations. Our model is able to\nlearn highly interpretable and disentangled hierarchical features on several\nnatural image datasets with no task specific regularization or prior knowledge.\n", "versions": [{"version": "v1", "created": "Mon, 27 Feb 2017 17:43:34 GMT"}, {"version": "v2", "created": "Fri, 9 Jun 2017 17:19:15 GMT"}], "update_date": "2017-06-12", "authors_parsed": [["Zhao", "Shengjia", ""], ["Song", "Jiaming", ""], ["Ermon", "Stefano", ""]]}, {"id": "1702.08398", "submitter": "Tom Sercu", "authors": "Youssef Mroueh, Tom Sercu, Vaibhava Goel", "title": "McGan: Mean and Covariance Feature Matching GAN", "comments": "15 pages; published at ICML 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce new families of Integral Probability Metrics (IPM) for training\nGenerative Adversarial Networks (GAN). Our IPMs are based on matching\nstatistics of distributions embedded in a finite dimensional feature space.\nMean and covariance feature matching IPMs allow for stable training of GANs,\nwhich we will call McGan. McGan minimizes a meaningful loss between\ndistributions.\n", "versions": [{"version": "v1", "created": "Mon, 27 Feb 2017 17:46:30 GMT"}, {"version": "v2", "created": "Thu, 8 Jun 2017 23:45:25 GMT"}], "update_date": "2017-06-12", "authors_parsed": [["Mroueh", "Youssef", ""], ["Sercu", "Tom", ""], ["Goel", "Vaibhava", ""]]}, {"id": "1702.08415", "submitter": "He Sun", "authors": "Yin Tat Lee and He Sun", "title": "An SDP-Based Algorithm for Linear-Sized Spectral Sparsification", "comments": "To appear at STOC'17", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For any undirected and weighted graph $G=(V,E,w)$ with $n$ vertices and $m$\nedges, we call a sparse subgraph $H$ of $G$, with proper reweighting of the\nedges, a $(1+\\varepsilon)$-spectral sparsifier if \\[\n(1-\\varepsilon)x^{\\intercal}L_Gx\\leq x^{\\intercal} L_{H} x\\leq (1+\\varepsilon)\nx^{\\intercal} L_Gx \\] holds for any $x\\in\\mathbb{R}^n$, where $L_G$ and $L_{H}$\nare the respective Laplacian matrices of $G$ and $H$. Noticing that $\\Omega(m)$\ntime is needed for any algorithm to construct a spectral sparsifier and a\nspectral sparsifier of $G$ requires $\\Omega(n)$ edges, a natural question is to\ninvestigate, for any constant $\\varepsilon$, if a $(1+\\varepsilon)$-spectral\nsparsifier of $G$ with $O(n)$ edges can be constructed in $\\tilde{O}(m)$ time,\nwhere the $\\tilde{O}$ notation suppresses polylogarithmic factors. All previous\nconstructions on spectral sparsification require either super-linear number of\nedges or $m^{1+\\Omega(1)}$ time.\n  In this work we answer this question affirmatively by presenting an algorithm\nthat, for any undirected graph $G$ and $\\varepsilon>0$, outputs a\n$(1+\\varepsilon)$-spectral sparsifier of $G$ with $O(n/\\varepsilon^2)$ edges in\n$\\tilde{O}(m/\\varepsilon^{O(1)})$ time. Our algorithm is based on three novel\ntechniques: (1) a new potential function which is much easier to compute yet\nhas similar guarantees as the potential functions used in previous references;\n(2) an efficient reduction from a two-sided spectral sparsifier to a one-sided\nspectral sparsifier; (3) constructing a one-sided spectral sparsifier by a\nsemi-definite program.\n", "versions": [{"version": "v1", "created": "Mon, 27 Feb 2017 18:23:28 GMT"}], "update_date": "2017-02-28", "authors_parsed": [["Lee", "Yin Tat", ""], ["Sun", "He", ""]]}, {"id": "1702.08431", "submitter": "R Devon Hjelm", "authors": "R Devon Hjelm and Athul Paul Jacob and Tong Che and Adam Trischler and\n  Kyunghyun Cho and Yoshua Bengio", "title": "Boundary-Seeking Generative Adversarial Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative adversarial networks (GANs) are a learning framework that rely on\ntraining a discriminator to estimate a measure of difference between a target\nand generated distributions. GANs, as normally formulated, rely on the\ngenerated samples being completely differentiable w.r.t. the generative\nparameters, and thus do not work for discrete data. We introduce a method for\ntraining GANs with discrete data that uses the estimated difference measure\nfrom the discriminator to compute importance weights for generated samples,\nthus providing a policy gradient for training the generator. The importance\nweights have a strong connection to the decision boundary of the discriminator,\nand we call our method boundary-seeking GANs (BGANs). We demonstrate the\neffectiveness of the proposed algorithm with discrete image and character-based\nnatural language generation. In addition, the boundary-seeking objective\nextends to continuous data, which can be used to improve stability of training,\nand we demonstrate this on Celeba, Large-scale Scene Understanding (LSUN)\nbedrooms, and Imagenet without conditioning.\n", "versions": [{"version": "v1", "created": "Mon, 27 Feb 2017 18:51:41 GMT"}, {"version": "v2", "created": "Mon, 22 May 2017 21:16:58 GMT"}, {"version": "v3", "created": "Wed, 31 Jan 2018 19:28:42 GMT"}, {"version": "v4", "created": "Wed, 21 Feb 2018 20:52:11 GMT"}], "update_date": "2018-02-23", "authors_parsed": [["Hjelm", "R Devon", ""], ["Jacob", "Athul Paul", ""], ["Che", "Tong", ""], ["Trischler", "Adam", ""], ["Cho", "Kyunghyun", ""], ["Bengio", "Yoshua", ""]]}, {"id": "1702.08484", "submitter": "Aditya Grover", "authors": "Aditya Grover, Stefano Ermon", "title": "Boosted Generative Models", "comments": "AAAI 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel approach for using unsupervised boosting to create an\nensemble of generative models, where models are trained in sequence to correct\nearlier mistakes. Our meta-algorithmic framework can leverage any existing base\nlearner that permits likelihood evaluation, including recent deep expressive\nmodels. Further, our approach allows the ensemble to include discriminative\nmodels trained to distinguish real data from model-generated data. We show\ntheoretical conditions under which incorporating a new model in the ensemble\nwill improve the fit and empirically demonstrate the effectiveness of our\nblack-box boosting algorithms on density estimation, classification, and sample\ngeneration on benchmark datasets for a wide range of generative models.\n", "versions": [{"version": "v1", "created": "Mon, 27 Feb 2017 19:28:40 GMT"}, {"version": "v2", "created": "Fri, 22 Dec 2017 10:13:51 GMT"}], "update_date": "2017-12-25", "authors_parsed": [["Grover", "Aditya", ""], ["Ermon", "Stefano", ""]]}, {"id": "1702.08489", "submitter": "Amit Daniely", "authors": "Amit Daniely", "title": "Depth Separation for Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $f:\\mathbb{S}^{d-1}\\times \\mathbb{S}^{d-1}\\to\\mathbb{S}$ be a function of\nthe form $f(\\mathbf{x},\\mathbf{x}') = g(\\langle\\mathbf{x},\\mathbf{x}'\\rangle)$\nfor $g:[-1,1]\\to \\mathbb{R}$. We give a simple proof that shows that poly-size\ndepth two neural networks with (exponentially) bounded weights cannot\napproximate $f$ whenever $g$ cannot be approximated by a low degree polynomial.\nMoreover, for many $g$'s, such as $g(x)=\\sin(\\pi d^3x)$, the number of neurons\nmust be $2^{\\Omega\\left(d\\log(d)\\right)}$. Furthermore, the result holds\nw.r.t.\\ the uniform distribution on $\\mathbb{S}^{d-1}\\times \\mathbb{S}^{d-1}$.\nAs many functions of the above form can be well approximated by poly-size depth\nthree networks with poly-bounded weights, this establishes a separation between\ndepth two and depth three networks w.r.t.\\ the uniform distribution on\n$\\mathbb{S}^{d-1}\\times \\mathbb{S}^{d-1}$.\n", "versions": [{"version": "v1", "created": "Mon, 27 Feb 2017 19:46:15 GMT"}], "update_date": "2017-03-01", "authors_parsed": [["Daniely", "Amit", ""]]}, {"id": "1702.08503", "submitter": "Amit Daniely", "authors": "Amit Daniely", "title": "SGD Learns the Conjugate Kernel Class of the Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that the standard stochastic gradient decent (SGD) algorithm is\nguaranteed to learn, in polynomial time, a function that is competitive with\nthe best function in the conjugate kernel space of the network, as defined in\nDaniely, Frostig and Singer. The result holds for log-depth networks from a\nrich family of architectures. To the best of our knowledge, it is the first\npolynomial-time guarantee for the standard neural network learning algorithm\nfor networks of depth more that two.\n  As corollaries, it follows that for neural networks of any depth between $2$\nand $\\log(n)$, SGD is guaranteed to learn, in polynomial time, constant degree\npolynomials with polynomially bounded coefficients. Likewise, it follows that\nSGD on large enough networks can learn any continuous function (not in\npolynomial time), complementing classical expressivity results.\n", "versions": [{"version": "v1", "created": "Mon, 27 Feb 2017 20:05:43 GMT"}, {"version": "v2", "created": "Fri, 19 May 2017 18:32:42 GMT"}], "update_date": "2017-05-23", "authors_parsed": [["Daniely", "Amit", ""]]}, {"id": "1702.08513", "submitter": "Nizar Massouh", "authors": "Nizar Massouh, Francesca Babiloni, Tatiana Tommasi, Jay Young, Nick\n  Hawes and Barbara Caputo", "title": "Learning Deep Visual Object Models From Noisy Web Data: How to Make it\n  Work", "comments": "8 pages, 7 figures, 3 tables", "journal-ref": "2017 IEEE/RSJ International Conference on Intelligent Robots and\n  Systems (IROS)", "doi": "10.1109/IROS.2017.8206444", "report-no": null, "categories": "cs.CV cs.DB cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep networks thrive when trained on large scale data collections. This has\ngiven ImageNet a central role in the development of deep architectures for\nvisual object classification. However, ImageNet was created during a specific\nperiod in time, and as such it is prone to aging, as well as dataset bias\nissues. Moving beyond fixed training datasets will lead to more robust visual\nsystems, especially when deployed on robots in new environments which must\ntrain on the objects they encounter there. To make this possible, it is\nimportant to break free from the need for manual annotators. Recent work has\nbegun to investigate how to use the massive amount of images available on the\nWeb in place of manual image annotations. We contribute to this research thread\nwith two findings: (1) a study correlating a given level of noisily labels to\nthe expected drop in accuracy, for two deep architectures, on two different\ntypes of noise, that clearly identifies GoogLeNet as a suitable architecture\nfor learning from Web data; (2) a recipe for the creation of Web datasets with\nminimal noise and maximum visual variability, based on a visual and natural\nlanguage processing concept expansion strategy. By combining these two results,\nwe obtain a method for learning powerful deep object models automatically from\nthe Web. We confirm the effectiveness of our approach through object\ncategorization experiments using our Web-derived version of ImageNet on a\npopular robot vision benchmark database, and on a lifelong object discovery\ntask on a mobile robot.\n", "versions": [{"version": "v1", "created": "Tue, 28 Feb 2017 10:02:36 GMT"}], "update_date": "2018-05-23", "authors_parsed": [["Massouh", "Nizar", ""], ["Babiloni", "Francesca", ""], ["Tommasi", "Tatiana", ""], ["Young", "Jay", ""], ["Hawes", "Nick", ""], ["Caputo", "Barbara", ""]]}, {"id": "1702.08530", "submitter": "Richard Nock", "authors": "Amir Dezfouli, Edwin V. Bonilla, Richard Nock", "title": "Semi-parametric Network Structure Discovery Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a network structure discovery model for continuous observations\nthat generalizes linear causal models by incorporating a Gaussian process (GP)\nprior on a network-independent component, and random sparsity and weight\nmatrices as the network-dependent parameters. This approach provides flexible\nmodeling of network-independent trends in the observations as well as\nuncertainty quantification around the discovered network structure. We\nestablish a connection between our model and multi-task GPs and develop an\nefficient stochastic variational inference algorithm for it. Furthermore, we\nformally show that our approach is numerically stable and in fact numerically\neasy to carry out almost everywhere on the support of the random variables\ninvolved. Finally, we evaluate our model on three applications, showing that it\noutperforms previous approaches. We provide a qualitative and quantitative\nanalysis of the structures discovered for domains such as the study of the full\ngenome regulation of the yeast Saccharomyces cerevisiae.\n", "versions": [{"version": "v1", "created": "Mon, 27 Feb 2017 21:04:05 GMT"}], "update_date": "2017-03-01", "authors_parsed": [["Dezfouli", "Amir", ""], ["Bonilla", "Edwin V.", ""], ["Nock", "Richard", ""]]}, {"id": "1702.08533", "submitter": "Zhiwei Steven Wu", "authors": "Yishay Mansour, Aleksandrs Slivkins, Zhiwei Steven Wu", "title": "Competing Bandits: Learning under Competition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most modern systems strive to learn from interactions with users, and many\nengage in exploration: making potentially suboptimal choices for the sake of\nacquiring new information. We initiate a study of the interplay between\nexploration and competition--how such systems balance the exploration for\nlearning and the competition for users. Here the users play three distinct\nroles: they are customers that generate revenue, they are sources of data for\nlearning, and they are self-interested agents which choose among the competing\nsystems. In our model, we consider competition between two multi-armed bandit\nalgorithms faced with the same bandit instance. Users arrive one by one and\nchoose among the two algorithms, so that each algorithm makes progress if and\nonly if it is chosen. We ask whether and to what extent competition\nincentivizes the adoption of better bandit algorithms. We investigate this\nissue for several models of user response, as we vary the degree of rationality\nand competitiveness in the model. Our findings are closely related to the\n\"competition vs. innovation\" relationship, a well-studied theme in economics.\n", "versions": [{"version": "v1", "created": "Mon, 27 Feb 2017 21:13:57 GMT"}, {"version": "v2", "created": "Mon, 20 Nov 2017 04:00:06 GMT"}], "update_date": "2017-11-21", "authors_parsed": [["Mansour", "Yishay", ""], ["Slivkins", "Aleksandrs", ""], ["Wu", "Zhiwei Steven", ""]]}, {"id": "1702.08536", "submitter": "Emma Pierson", "authors": "Emma Pierson, Sam Corbett-Davies, Sharad Goel", "title": "Fast Threshold Tests for Detecting Discrimination", "comments": "Accepted at AISTATS 2018; slightly shorter camera-ready version", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Threshold tests have recently been proposed as a useful method for detecting\nbias in lending, hiring, and policing decisions. For example, in the case of\ncredit extensions, these tests aim to estimate the bar for granting loans to\nwhite and minority applicants, with a higher inferred threshold for minorities\nindicative of discrimination. This technique, however, requires fitting a\ncomplex Bayesian latent variable model for which inference is often\ncomputationally challenging. Here we develop a method for fitting threshold\ntests that is two orders of magnitude faster than the existing approach,\nreducing computation from hours to minutes. To achieve these performance gains,\nwe introduce and analyze a flexible family of probability distributions on the\ninterval [0, 1] -- which we call discriminant distributions -- that is\ncomputationally efficient to work with. We demonstrate our technique by\nanalyzing 2.7 million police stops of pedestrians in New York City.\n", "versions": [{"version": "v1", "created": "Mon, 27 Feb 2017 21:18:19 GMT"}, {"version": "v2", "created": "Tue, 13 Feb 2018 19:00:29 GMT"}, {"version": "v3", "created": "Sat, 10 Mar 2018 20:17:57 GMT"}], "update_date": "2018-03-13", "authors_parsed": [["Pierson", "Emma", ""], ["Corbett-Davies", "Sam", ""], ["Goel", "Sharad", ""]]}, {"id": "1702.08540", "submitter": "Yazhou Yang", "authors": "Yazhou Yang and Marco Loog", "title": "Active Learning Using Uncertainty Information", "comments": "6 pages, 1 figure, International Conference on Pattern Recognition\n  (ICPR) 2016, Cancun, Mexico", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many active learning methods belong to the retraining-based approaches, which\nselect one unlabeled instance, add it to the training set with its possible\nlabels, retrain the classification model, and evaluate the criteria that we\nbase our selection on. However, since the true label of the selected instance\nis unknown, these methods resort to calculating the average-case or worse-case\nperformance with respect to the unknown label. In this paper, we propose a\ndifferent method to solve this problem. In particular, our method aims to make\nuse of the uncertainty information to enhance the performance of\nretraining-based models. We apply our method to two state-of-the-art algorithms\nand carry out extensive experiments on a wide variety of real-world datasets.\nThe results clearly demonstrate the effectiveness of the proposed method and\nindicate it can reduce human labeling efforts in many real-life applications.\n", "versions": [{"version": "v1", "created": "Mon, 27 Feb 2017 21:33:47 GMT"}], "update_date": "2017-03-01", "authors_parsed": [["Yang", "Yazhou", ""], ["Loog", "Marco", ""]]}, {"id": "1702.08553", "submitter": "Christopher Tosh", "authors": "Christopher Tosh, Sanjoy Dasgupta", "title": "Diameter-Based Active Learning", "comments": "16 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To date, the tightest upper and lower-bounds for the active learning of\ngeneral concept classes have been in terms of a parameter of the learning\nproblem called the splitting index. We provide, for the first time, an\nefficient algorithm that is able to realize this upper bound, and we\nempirically demonstrate its good performance.\n", "versions": [{"version": "v1", "created": "Mon, 27 Feb 2017 21:59:24 GMT"}, {"version": "v2", "created": "Fri, 9 Jun 2017 00:39:57 GMT"}], "update_date": "2017-06-12", "authors_parsed": [["Tosh", "Christopher", ""], ["Dasgupta", "Sanjoy", ""]]}, {"id": "1702.08567", "submitter": "AmirEmad Ghassami", "authors": "AmirEmad Ghassami, Saber Salehkaleybar, Negar Kiyavash", "title": "Optimal Experiment Design for Causal Discovery from Fixed Number of\n  Experiments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of causal structure learning over a set of random\nvariables when the experimenter is allowed to perform at most $M$ experiments\nin a non-adaptive manner. We consider the optimal learning strategy in terms of\nminimizing the portions of the structure that remains unknown given the limited\nnumber of experiments in both Bayesian and minimax setting. We characterize the\ntheoretical optimal solution and propose an algorithm, which designs the\nexperiments efficiently in terms of time complexity. We show that for bounded\ndegree graphs, in the minimax case and in the Bayesian case with uniform\npriors, our proposed algorithm is a $\\rho$-approximation algorithm, where\n$\\rho$ is independent of the order of the underlying graph. Simulations on both\nsynthetic and real data show that the performance of our algorithm is very\nclose to the optimal solution.\n", "versions": [{"version": "v1", "created": "Mon, 27 Feb 2017 22:30:43 GMT"}], "update_date": "2017-03-01", "authors_parsed": [["Ghassami", "AmirEmad", ""], ["Salehkaleybar", "Saber", ""], ["Kiyavash", "Negar", ""]]}, {"id": "1702.08568", "submitter": "Konstantin Berlin", "authors": "Joshua Saxe and Konstantin Berlin", "title": "eXpose: A Character-Level Convolutional Neural Network with Embeddings\n  For Detecting Malicious URLs, File Paths and Registry Keys", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For years security machine learning research has promised to obviate the need\nfor signature based detection by automatically learning to detect indicators of\nattack. Unfortunately, this vision hasn't come to fruition: in fact, developing\nand maintaining today's security machine learning systems can require\nengineering resources that are comparable to that of signature-based detection\nsystems, due in part to the need to develop and continuously tune the\n\"features\" these machine learning systems look at as attacks evolve. Deep\nlearning, a subfield of machine learning, promises to change this by operating\non raw input signals and automating the process of feature design and\nextraction. In this paper we propose the eXpose neural network, which uses a\ndeep learning approach we have developed to take generic, raw short character\nstrings as input (a common case for security inputs, which include artifacts\nlike potentially malicious URLs, file paths, named pipes, named mutexes, and\nregistry keys), and learns to simultaneously extract features and classify\nusing character-level embeddings and convolutional neural network. In addition\nto completely automating the feature design and extraction process, eXpose\noutperforms manual feature extraction based baselines on all of the intrusion\ndetection problems we tested it on, yielding a 5%-10% detection rate gain at\n0.1% false positive rate compared to these baselines.\n", "versions": [{"version": "v1", "created": "Mon, 27 Feb 2017 22:32:13 GMT"}], "update_date": "2017-03-01", "authors_parsed": [["Saxe", "Joshua", ""], ["Berlin", "Konstantin", ""]]}, {"id": "1702.08575", "submitter": "Saber Salehkaleybar", "authors": "Saber Salehkaleybar, Jalal Etesami, Negar Kiyavash, Kun Zhang", "title": "Learning Vector Autoregressive Models with Latent Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of learning the support of transition matrix between\nrandom processes in a Vector Autoregressive (VAR) model from samples when a\nsubset of the processes are latent. It is well known that ignoring the effect\nof the latent processes may lead to very different estimates of the influences\namong observed processes, and we are concerned with identifying the influences\namong the observed processes, those between the latent ones, and those from the\nlatent to the observed ones. We show that the support of transition matrix\namong the observed processes and lengths of all latent paths between any two\nobserved processes can be identified successfully under some conditions on the\nVAR model. From the lengths of latent paths, we reconstruct the latent subgraph\n(representing the influences among the latent processes) with a minimum number\nof variables uniquely if its topology is a directed tree. Furthermore, we\npropose an algorithm that finds all possible minimal latent graphs under some\nconditions on the lengths of latent paths. Our results apply to both\nnon-Gaussian and Gaussian cases, and experimental results on various synthetic\nand real-world datasets validate our theoretical results.\n", "versions": [{"version": "v1", "created": "Mon, 27 Feb 2017 23:00:28 GMT"}, {"version": "v2", "created": "Wed, 31 May 2017 18:36:05 GMT"}, {"version": "v3", "created": "Fri, 10 Nov 2017 04:36:01 GMT"}], "update_date": "2017-11-13", "authors_parsed": [["Salehkaleybar", "Saber", ""], ["Etesami", "Jalal", ""], ["Kiyavash", "Negar", ""], ["Zhang", "Kun", ""]]}, {"id": "1702.08580", "submitter": "Haihao Lu", "authors": "Haihao Lu and Kenji Kawaguchi", "title": "Depth Creates No Bad Local Minima", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In deep learning, \\textit{depth}, as well as \\textit{nonlinearity}, create\nnon-convex loss surfaces. Then, does depth alone create bad local minima? In\nthis paper, we prove that without nonlinearity, depth alone does not create bad\nlocal minima, although it induces non-convex loss surface. Using this insight,\nwe greatly simplify a recently proposed proof to show that all of the local\nminima of feedforward deep linear neural networks are global minima. Our\ntheoretical results generalize previous results with fewer assumptions, and\nthis analysis provides a method to show similar results beyond square loss in\ndeep linear models.\n", "versions": [{"version": "v1", "created": "Mon, 27 Feb 2017 23:27:36 GMT"}, {"version": "v2", "created": "Wed, 24 May 2017 03:42:41 GMT"}], "update_date": "2017-05-25", "authors_parsed": [["Lu", "Haihao", ""], ["Kawaguchi", "Kenji", ""]]}, {"id": "1702.08586", "submitter": "Lei Wang", "authors": "Lei Wang", "title": "Can Boltzmann Machines Discover Cluster Updates ?", "comments": "4 pages, 4 figures, and half page appendix", "journal-ref": "Phys. Rev. E 96, 051301 (2017)", "doi": "10.1103/PhysRevE.96.051301", "report-no": null, "categories": "physics.comp-ph cond-mat.stat-mech cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Boltzmann machines are physics informed generative models with wide\napplications in machine learning. They can learn the probability distribution\nfrom an input dataset and generate new samples accordingly. Applying them back\nto physics, the Boltzmann machines are ideal recommender systems to accelerate\nMonte Carlo simulation of physical systems due to their flexibility and\neffectiveness. More intriguingly, we show that the generative sampling of the\nBoltzmann Machines can even discover unknown cluster Monte Carlo algorithms.\nThe creative power comes from the latent representation of the Boltzmann\nmachines, which learn to mediate complex interactions and identify clusters of\nthe physical system. We demonstrate these findings with concrete examples of\nthe classical Ising model with and without four spin plaquette interactions.\nOur results endorse a fresh research paradigm where intelligent machines are\ndesigned to create or inspire human discovery of innovative algorithms.\n", "versions": [{"version": "v1", "created": "Tue, 28 Feb 2017 00:39:04 GMT"}], "update_date": "2017-11-20", "authors_parsed": [["Wang", "Lei", ""]]}, {"id": "1702.08591", "submitter": "David Balduzzi", "authors": "David Balduzzi, Marcus Frean, Lennox Leary, JP Lewis, Kurt Wan-Duo Ma,\n  Brian McWilliams", "title": "The Shattered Gradients Problem: If resnets are the answer, then what is\n  the question?", "comments": "ICML 2017, final version", "journal-ref": "PMLR volume 70 (2017)", "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A long-standing obstacle to progress in deep learning is the problem of\nvanishing and exploding gradients. Although, the problem has largely been\novercome via carefully constructed initializations and batch normalization,\narchitectures incorporating skip-connections such as highway and resnets\nperform much better than standard feedforward architectures despite well-chosen\ninitialization and batch normalization. In this paper, we identify the\nshattered gradients problem. Specifically, we show that the correlation between\ngradients in standard feedforward networks decays exponentially with depth\nresulting in gradients that resemble white noise whereas, in contrast, the\ngradients in architectures with skip-connections are far more resistant to\nshattering, decaying sublinearly. Detailed empirical evidence is presented in\nsupport of the analysis, on both fully-connected networks and convnets.\nFinally, we present a new \"looks linear\" (LL) initialization that prevents\nshattering, with preliminary experiments showing the new initialization allows\nto train very deep networks without the addition of skip-connections.\n", "versions": [{"version": "v1", "created": "Tue, 28 Feb 2017 01:06:13 GMT"}, {"version": "v2", "created": "Wed, 6 Jun 2018 10:08:21 GMT"}], "update_date": "2018-06-07", "authors_parsed": [["Balduzzi", "David", ""], ["Frean", "Marcus", ""], ["Leary", "Lennox", ""], ["Lewis", "JP", ""], ["Ma", "Kurt Wan-Duo", ""], ["McWilliams", "Brian", ""]]}, {"id": "1702.08608", "submitter": "Been Kim", "authors": "Finale Doshi-Velez and Been Kim", "title": "Towards A Rigorous Science of Interpretable Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As machine learning systems become ubiquitous, there has been a surge of\ninterest in interpretable machine learning: systems that provide explanation\nfor their outputs. These explanations are often used to qualitatively assess\nother criteria such as safety or non-discrimination. However, despite the\ninterest in interpretability, there is very little consensus on what\ninterpretable machine learning is and how it should be measured. In this\nposition paper, we first define interpretability and describe when\ninterpretability is needed (and when it is not). Next, we suggest a taxonomy\nfor rigorous evaluation and expose open questions towards a more rigorous\nscience of interpretable machine learning.\n", "versions": [{"version": "v1", "created": "Tue, 28 Feb 2017 02:19:20 GMT"}, {"version": "v2", "created": "Thu, 2 Mar 2017 19:32:10 GMT"}], "update_date": "2017-03-06", "authors_parsed": [["Doshi-Velez", "Finale", ""], ["Kim", "Been", ""]]}, {"id": "1702.08623", "submitter": "Xinyu Li", "authors": "Xinyu Li, Yanyi Zhang, Jianyu Zhang, Yueyang Chen, Shuhong Chen, Yue\n  Gu, Moliang Zhou, Richard A. Farneth, Ivan Marsic and Randall S. Burd", "title": "Progress Estimation and Phase Detection for Sequential Processes", "comments": "Accepted by IMWUT/Ubicomp 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Process modeling and understanding are fundamental for advanced\nhuman-computer interfaces and automation systems. Most recent research has\nfocused on activity recognition, but little has been done on sensor-based\ndetection of process progress. We introduce a real-time, sensor-based system\nfor modeling, recognizing and estimating the progress of a work process. We\nimplemented a multimodal deep learning structure to extract the relevant\nspatio-temporal features from multiple sensory inputs and used a novel deep\nregression structure for overall completeness estimation. Using process\ncompleteness estimation with a Gaussian mixture model, our system can predict\nthe phase for sequential processes. The performance speed, calculated using\ncompleteness estimation, allows online estimation of the remaining time. To\ntrain our system, we introduced a novel rectified hyperbolic tangent (rtanh)\nactivation function and conditional loss. Our system was tested on data\nobtained from the medical process (trauma resuscitation) and sports events\n(Olympic swimming competition). Our system outperformed the existing\ntrauma-resuscitation phase detectors with a phase detection accuracy of over\n86%, an F1-score of 0.67, a completeness estimation error of under 12.6%, and a\nremaining-time estimation error of less than 7.5 minutes. For the Olympic\nswimming dataset, our system achieved an accuracy of 88%, an F1-score of 0.58,\na completeness estimation error of 6.3% and a remaining-time estimation error\nof 2.9 minutes.\n", "versions": [{"version": "v1", "created": "Tue, 28 Feb 2017 03:11:33 GMT"}, {"version": "v2", "created": "Thu, 29 Jun 2017 05:04:49 GMT"}, {"version": "v3", "created": "Fri, 14 Jul 2017 20:01:31 GMT"}], "update_date": "2017-07-18", "authors_parsed": [["Li", "Xinyu", ""], ["Zhang", "Yanyi", ""], ["Zhang", "Jianyu", ""], ["Chen", "Yueyang", ""], ["Chen", "Shuhong", ""], ["Gu", "Yue", ""], ["Zhou", "Moliang", ""], ["Farneth", "Richard A.", ""], ["Marsic", "Ivan", ""], ["Burd", "Randall S.", ""]]}, {"id": "1702.08628", "submitter": "Isaac Sledge", "authors": "Isaac J. Sledge, Jose C. Principe", "title": "Analysis of Agent Expertise in Ms. Pac-Man using\n  Value-of-Information-based Policies", "comments": "IEEE Transactions on Computational Intelligence and Artificial\n  Intelligence in Games", "journal-ref": null, "doi": "10.1109/TG.2018.2808201", "report-no": null, "categories": "cs.LG cs.AI cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conventional reinforcement learning methods for Markov decision processes\nrely on weakly-guided, stochastic searches to drive the learning process. It\ncan therefore be difficult to predict what agent behaviors might emerge. In\nthis paper, we consider an information-theoretic cost function for performing\nconstrained stochastic searches that promote the formation of risk-averse to\nrisk-favoring behaviors. This cost function is the value of information, which\nprovides the optimal trade-off between the expected return of a policy and the\npolicy's complexity; policy complexity is measured by number of bits and\ncontrolled by a single hyperparameter on the cost function. As the policy\ncomplexity is reduced, the agents will increasingly eschew risky actions. This\nreduces the potential for high accrued rewards. As the policy complexity\nincreases, the agents will take actions, regardless of the risk, that can raise\nthe long-term rewards. The obtainable reward depends on a single, tunable\nhyperparameter that regulates the degree of policy complexity.\n  We evaluate the performance of value-of-information-based policies on a\nstochastic version of Ms. Pac-Man. A major component of this paper is the\ndemonstration that ranges of policy complexity values yield different game-play\nstyles and explaining why this occurs. We also show that our\nreinforcement-learning search mechanism is more efficient than the others we\nutilize. This result implies that the value of information theory is\nappropriate for framing the exploitation-exploration trade-off in reinforcement\nlearning.\n", "versions": [{"version": "v1", "created": "Tue, 28 Feb 2017 03:23:20 GMT"}, {"version": "v2", "created": "Mon, 28 Aug 2017 14:06:44 GMT"}, {"version": "v3", "created": "Sat, 4 Nov 2017 16:15:07 GMT"}], "update_date": "2018-02-20", "authors_parsed": [["Sledge", "Isaac J.", ""], ["Principe", "Jose C.", ""]]}, {"id": "1702.08635", "submitter": "Fei Tian", "authors": "Yang Fan and Fei Tian and Tao Qin and Jiang Bian and Tie-Yan Liu", "title": "Learning What Data to Learn", "comments": "A preliminary version will appear in ICLR 2017, workshop track.\n  https://openreview.net/forum?id=SyJNmVqgg&noteId=SyJNmVqgg", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning is essentially the sciences of playing with data. An\nadaptive data selection strategy, enabling to dynamically choose different data\nat various training stages, can reach a more effective model in a more\nefficient way. In this paper, we propose a deep reinforcement learning\nframework, which we call \\emph{\\textbf{N}eural \\textbf{D}ata \\textbf{F}ilter}\n(\\textbf{NDF}), to explore automatic and adaptive data selection in the\ntraining process. In particular, NDF takes advantage of a deep neural network\nto adaptively select and filter important data instances from a sequential\nstream of training data, such that the future accumulative reward (e.g., the\nconvergence speed) is maximized. In contrast to previous studies in data\nselection that is mainly based on heuristic strategies, NDF is quite generic\nand thus can be widely suitable for many machine learning tasks. Taking neural\nnetwork training with stochastic gradient descent (SGD) as an example,\ncomprehensive experiments with respect to various neural network modeling\n(e.g., multi-layer perceptron networks, convolutional neural networks and\nrecurrent neural networks) and several applications (e.g., image classification\nand text understanding) demonstrate that NDF powered SGD can achieve comparable\naccuracy with standard SGD process by using less data and fewer iterations.\n", "versions": [{"version": "v1", "created": "Tue, 28 Feb 2017 03:52:06 GMT"}], "update_date": "2017-03-01", "authors_parsed": [["Fan", "Yang", ""], ["Tian", "Fei", ""], ["Qin", "Tao", ""], ["Bian", "Jiang", ""], ["Liu", "Tie-Yan", ""]]}, {"id": "1702.08648", "submitter": "Ozsel Kilinc", "authors": "Ozsel Kilinc, Ismail Uysal", "title": "Auto-clustering Output Layer: Automatic Learning of Latent Annotations\n  in Neural Networks", "comments": "Submitted to IEEE Transactions on Neural Networks and Learning\n  Systems, 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we discuss a different type of semi-supervised setting: a\ncoarse level of labeling is available for all observations but the model has to\nlearn a fine level of latent annotation for each one of them. Problems in this\nsetting are likely to be encountered in many domains such as text\ncategorization, protein function prediction, image classification as well as in\nexploratory scientific studies such as medical and genomics research. We\nconsider this setting as simultaneously performed supervised classification\n(per the available coarse labels) and unsupervised clustering (within each one\nof the coarse labels) and propose a novel output layer modification called\nauto-clustering output layer (ACOL) that allows concurrent classification and\nclustering based on Graph-based Activity Regularization (GAR) technique. As the\nproposed output layer modification duplicates the softmax nodes at the output\nlayer for each class, GAR allows for competitive learning between these\nduplicates on a traditional error-correction learning framework to ultimately\nenable a neural network to learn the latent annotations in this partially\nsupervised setup. We demonstrate how the coarse label supervision impacts\nperformance and helps propagate useful clustering information between\nsub-classes. Comparative tests on three of the most popular image datasets\nMNIST, SVHN and CIFAR-100 rigorously demonstrate the effectiveness and\ncompetitiveness of the proposed approach.\n", "versions": [{"version": "v1", "created": "Tue, 28 Feb 2017 05:21:31 GMT"}, {"version": "v2", "created": "Wed, 9 Aug 2017 00:02:45 GMT"}], "update_date": "2017-08-10", "authors_parsed": [["Kilinc", "Ozsel", ""], ["Uysal", "Ismail", ""]]}, {"id": "1702.08651", "submitter": "Quanquan Gu", "authors": "Pan Xu and Jian Ma and Quanquan Gu", "title": "Speeding Up Latent Variable Gaussian Graphical Model Estimation via\n  Nonconvex Optimizations", "comments": "29 pages, 5 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the estimation of the latent variable Gaussian graphical model\n(LVGGM), where the precision matrix is the superposition of a sparse matrix and\na low-rank matrix. In order to speed up the estimation of the sparse plus\nlow-rank components, we propose a sparsity constrained maximum likelihood\nestimator based on matrix factorization, and an efficient alternating gradient\ndescent algorithm with hard thresholding to solve it. Our algorithm is orders\nof magnitude faster than the convex relaxation based methods for LVGGM. In\naddition, we prove that our algorithm is guaranteed to linearly converge to the\nunknown sparse and low-rank components up to the optimal statistical precision.\nExperiments on both synthetic and genomic data demonstrate the superiority of\nour algorithm over the state-of-the-art algorithms and corroborate our theory.\n", "versions": [{"version": "v1", "created": "Tue, 28 Feb 2017 05:38:40 GMT"}], "update_date": "2017-03-01", "authors_parsed": [["Xu", "Pan", ""], ["Ma", "Jian", ""], ["Gu", "Quanquan", ""]]}, {"id": "1702.08658", "submitter": "Shengjia Zhao", "authors": "Shengjia Zhao, Jiaming Song, Stefano Ermon", "title": "Towards Deeper Understanding of Variational Autoencoding Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new family of optimization criteria for variational\nauto-encoding models, generalizing the standard evidence lower bound. We\nprovide conditions under which they recover the data distribution and learn\nlatent features, and formally show that common issues such as blurry samples\nand uninformative latent features arise when these conditions are not met.\nBased on these new insights, we propose a new sequential VAE model that can\ngenerate sharp samples on the LSUN image dataset based on pixel-wise\nreconstruction loss, and propose an optimization criterion that encourages\nunsupervised learning of informative latent features.\n", "versions": [{"version": "v1", "created": "Tue, 28 Feb 2017 06:04:23 GMT"}], "update_date": "2017-03-01", "authors_parsed": [["Zhao", "Shengjia", ""], ["Song", "Jiaming", ""], ["Ermon", "Stefano", ""]]}, {"id": "1702.08670", "submitter": "Vamsi Ithapu", "authors": "Vamsi K Ithapu, Sathya N Ravi, Vikas Singh", "title": "On architectural choices in deep learning: From network structure to\n  gradient convergence and parameter estimation", "comments": "87 Pages; 14 figures; Under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study mechanisms to characterize how the asymptotic convergence of\nbackpropagation in deep architectures, in general, is related to the network\nstructure, and how it may be influenced by other design choices including\nactivation type, denoising and dropout rate. We seek to analyze whether network\narchitecture and input data statistics may guide the choices of learning\nparameters and vice versa. Given the broad applicability of deep architectures,\nthis issue is interesting both from theoretical and a practical standpoint.\nUsing properties of general nonconvex objectives (with first-order\ninformation), we first build the association between structural, distributional\nand learnability aspects of the network vis-\\`a-vis their interaction with\nparameter convergence rates. We identify a nice relationship between feature\ndenoising and dropout, and construct families of networks that achieve the same\nlevel of convergence. We then derive a workflow that provides systematic\nguidance regarding the choice of network sizes and learning parameters often\nmediated4 by input statistics. Our technical results are corroborated by an\nextensive set of evaluations, presented in this paper as well as independent\nempirical observations reported by other groups. We also perform experiments\nshowing the practical implications of our framework for choosing the best\nfully-connected design for a given problem.\n", "versions": [{"version": "v1", "created": "Tue, 28 Feb 2017 07:05:27 GMT"}], "update_date": "2017-03-02", "authors_parsed": [["Ithapu", "Vamsi K", ""], ["Ravi", "Sathya N", ""], ["Singh", "Vikas", ""]]}, {"id": "1702.08690", "submitter": "Weifeng Ge", "authors": "Weifeng Ge, Yizhou Yu", "title": "Borrowing Treasures from the Wealthy: Deep Transfer Learning through\n  Selective Joint Fine-tuning", "comments": "To appear in 2017 IEEE Conference on Computer Vision and Pattern\n  Recognition (CVPR 2017)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks require a large amount of labeled training data during\nsupervised learning. However, collecting and labeling so much data might be\ninfeasible in many cases. In this paper, we introduce a source-target selective\njoint fine-tuning scheme for improving the performance of deep learning tasks\nwith insufficient training data. In this scheme, a target learning task with\ninsufficient training data is carried out simultaneously with another source\nlearning task with abundant training data. However, the source learning task\ndoes not use all existing training data. Our core idea is to identify and use a\nsubset of training images from the original source learning task whose\nlow-level characteristics are similar to those from the target learning task,\nand jointly fine-tune shared convolutional layers for both tasks. Specifically,\nwe compute descriptors from linear or nonlinear filter bank responses on\ntraining images from both tasks, and use such descriptors to search for a\ndesired subset of training samples for the source learning task.\n  Experiments demonstrate that our selective joint fine-tuning scheme achieves\nstate-of-the-art performance on multiple visual classification tasks with\ninsufficient training data for deep learning. Such tasks include Caltech 256,\nMIT Indoor 67, Oxford Flowers 102 and Stanford Dogs 120. In comparison to\nfine-tuning without a source domain, the proposed method can improve the\nclassification accuracy by 2% - 10% using a single model.\n", "versions": [{"version": "v1", "created": "Tue, 28 Feb 2017 08:40:44 GMT"}, {"version": "v2", "created": "Tue, 6 Jun 2017 11:51:03 GMT"}], "update_date": "2018-03-06", "authors_parsed": [["Ge", "Weifeng", ""], ["Yu", "Yizhou", ""]]}, {"id": "1702.08694", "submitter": "Mahito Sugiyama", "authors": "Mahito Sugiyama and Karsten Borgwardt", "title": "Finding Statistically Significant Interactions between Continuous\n  Features", "comments": "13 pages, 5 figures, 2 tables, accepted to the 28th International\n  Joint Conference on Artificial Intelligence (IJCAI 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The search for higher-order feature interactions that are statistically\nsignificantly associated with a class variable is of high relevance in fields\nsuch as Genetics or Healthcare, but the combinatorial explosion of the\ncandidate space makes this problem extremely challenging in terms of\ncomputational efficiency and proper correction for multiple testing. While\nrecent progress has been made regarding this challenge for binary features, we\nhere present the first solution for continuous features. We propose an\nalgorithm which overcomes the combinatorial explosion of the search space of\nhigher-order interactions by deriving a lower bound on the p-value for each\ninteraction, which enables us to massively prune interactions that can never\nreach significance and to thereby gain more statistical power. In our\nexperiments, our approach efficiently detects all significant interactions in a\nvariety of synthetic and real-world datasets.\n", "versions": [{"version": "v1", "created": "Tue, 28 Feb 2017 08:46:37 GMT"}, {"version": "v2", "created": "Mon, 22 May 2017 08:39:03 GMT"}, {"version": "v3", "created": "Fri, 10 May 2019 15:46:12 GMT"}], "update_date": "2019-05-13", "authors_parsed": [["Sugiyama", "Mahito", ""], ["Borgwardt", "Karsten", ""]]}, {"id": "1702.08701", "submitter": "Jinshan Zeng", "authors": "Shao-Bo Lin, Jinshan Zeng, Xiangyu Chang", "title": "Learning rates for classification with Gaussian kernels", "comments": "This paper has been accepted by Neural Computation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper aims at refined error analysis for binary classification using\nsupport vector machine (SVM) with Gaussian kernel and convex loss. Our first\nresult shows that for some loss functions such as the truncated quadratic loss\nand quadratic loss, SVM with Gaussian kernel can reach the almost optimal\nlearning rate, provided the regression function is smooth. Our second result\nshows that, for a large number of loss functions, under some Tsybakov noise\nassumption, if the regression function is infinitely smooth, then SVM with\nGaussian kernel can achieve the learning rate of order $m^{-1}$, where $m$ is\nthe number of samples.\n", "versions": [{"version": "v1", "created": "Tue, 28 Feb 2017 09:01:32 GMT"}, {"version": "v2", "created": "Wed, 16 Aug 2017 16:04:09 GMT"}, {"version": "v3", "created": "Thu, 5 Oct 2017 12:00:16 GMT"}], "update_date": "2017-10-06", "authors_parsed": [["Lin", "Shao-Bo", ""], ["Zeng", "Jinshan", ""], ["Chang", "Xiangyu", ""]]}, {"id": "1702.08712", "submitter": "Dacheng Tao", "authors": "Tongliang Liu and G\\'abor Lugosi and Gergely Neu and Dacheng Tao", "title": "Algorithmic stability and hypothesis complexity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a notion of algorithmic stability of learning algorithms---that\nwe term \\emph{argument stability}---that captures stability of the hypothesis\noutput by the learning algorithm in the normed space of functions from which\nhypotheses are selected. The main result of the paper bounds the generalization\nerror of any learning algorithm in terms of its argument stability. The bounds\nare based on martingale inequalities in the Banach space to which the\nhypotheses belong. We apply the general bounds to bound the performance of some\nlearning algorithms based on empirical risk minimization and stochastic\ngradient descent.\n", "versions": [{"version": "v1", "created": "Tue, 28 Feb 2017 09:39:03 GMT"}, {"version": "v2", "created": "Thu, 3 Aug 2017 11:45:15 GMT"}], "update_date": "2017-08-04", "authors_parsed": [["Liu", "Tongliang", ""], ["Lugosi", "G\u00e1bor", ""], ["Neu", "Gergely", ""], ["Tao", "Dacheng", ""]]}, {"id": "1702.08720", "submitter": "Weihua Hu", "authors": "Weihua Hu, Takeru Miyato, Seiya Tokui, Eiichi Matsumoto, Masashi\n  Sugiyama", "title": "Learning Discrete Representations via Information Maximizing\n  Self-Augmented Training", "comments": "To appear at ICML 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning discrete representations of data is a central machine learning task\nbecause of the compactness of the representations and ease of interpretation.\nThe task includes clustering and hash learning as special cases. Deep neural\nnetworks are promising to be used because they can model the non-linearity of\ndata and scale to large datasets. However, their model complexity is huge, and\ntherefore, we need to carefully regularize the networks in order to learn\nuseful representations that exhibit intended invariance for applications of\ninterest. To this end, we propose a method called Information Maximizing\nSelf-Augmented Training (IMSAT). In IMSAT, we use data augmentation to impose\nthe invariance on discrete representations. More specifically, we encourage the\npredicted representations of augmented data points to be close to those of the\noriginal data points in an end-to-end fashion. At the same time, we maximize\nthe information-theoretic dependency between data and their predicted discrete\nrepresentations. Extensive experiments on benchmark datasets show that IMSAT\nproduces state-of-the-art results for both clustering and unsupervised hash\nlearning.\n", "versions": [{"version": "v1", "created": "Tue, 28 Feb 2017 09:57:27 GMT"}, {"version": "v2", "created": "Wed, 1 Mar 2017 10:14:51 GMT"}, {"version": "v3", "created": "Wed, 14 Jun 2017 04:18:11 GMT"}], "update_date": "2017-06-15", "authors_parsed": [["Hu", "Weihua", ""], ["Miyato", "Takeru", ""], ["Tokui", "Seiya", ""], ["Matsumoto", "Eiichi", ""], ["Sugiyama", "Masashi", ""]]}, {"id": "1702.08782", "submitter": "Alexandre Boulch", "authors": "Alexandre Boulch", "title": "ShaResNet: reducing residual network parameter number by sharing weights", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Residual Networks have reached the state of the art in many image\nprocessing tasks such image classification. However, the cost for a gain in\naccuracy in terms of depth and memory is prohibitive as it requires a higher\nnumber of residual blocks, up to double the initial value. To tackle this\nproblem, we propose in this paper a way to reduce the redundant information of\nthe networks. We share the weights of convolutional layers between residual\nblocks operating at the same spatial scale. The signal flows multiple times in\nthe same convolutional layer. The resulting architecture, called ShaResNet,\ncontains block specific layers and shared layers. These ShaResNet are trained\nexactly in the same fashion as the commonly used residual networks. We show, on\nthe one hand, that they are almost as efficient as their sequential\ncounterparts while involving less parameters, and on the other hand that they\nare more efficient than a residual network with the same number of parameters.\nFor example, a 152-layer-deep residual network can be reduced to 106\nconvolutional layers, i.e. a parameter gain of 39\\%, while loosing less than\n0.2\\% accuracy on ImageNet.\n", "versions": [{"version": "v1", "created": "Tue, 28 Feb 2017 13:37:59 GMT"}, {"version": "v2", "created": "Mon, 6 Mar 2017 13:49:15 GMT"}], "update_date": "2017-03-07", "authors_parsed": [["Boulch", "Alexandre", ""]]}, {"id": "1702.08791", "submitter": "Matthew Staib", "authors": "Matthew Staib and Stefanie Jegelka", "title": "Robust Budget Allocation via Continuous Submodular Functions", "comments": "ICML 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DS cs.SI math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The optimal allocation of resources for maximizing influence, spread of\ninformation or coverage, has gained attention in the past years, in particular\nin machine learning and data mining. But in applications, the parameters of the\nproblem are rarely known exactly, and using wrong parameters can lead to\nundesirable outcomes. We hence revisit a continuous version of the Budget\nAllocation or Bipartite Influence Maximization problem introduced by Alon et\nal. (2012) from a robust optimization perspective, where an adversary may\nchoose the least favorable parameters within a confidence set. The resulting\nproblem is a nonconvex-concave saddle point problem (or game). We show that\nthis nonconvex problem can be solved exactly by leveraging connections to\ncontinuous submodular functions, and by solving a constrained submodular\nminimization problem. Although constrained submodular minimization is hard in\ngeneral, here, we establish conditions under which such a problem can be solved\nto arbitrary precision $\\epsilon$.\n", "versions": [{"version": "v1", "created": "Tue, 28 Feb 2017 14:07:42 GMT"}, {"version": "v2", "created": "Tue, 13 Jun 2017 15:24:28 GMT"}], "update_date": "2017-06-14", "authors_parsed": [["Staib", "Matthew", ""], ["Jegelka", "Stefanie", ""]]}, {"id": "1702.08811", "submitter": "Werner Zellinger", "authors": "Werner Zellinger, Thomas Grubinger, Edwin Lughofer, Thomas\n  Natschl\\\"ager, Susanne Saminger-Platz", "title": "Central Moment Discrepancy (CMD) for Domain-Invariant Representation\n  Learning", "comments": "Extended journal version published:\n  https://doi.org/10.1016/j.ins.2019.01.025", "journal-ref": "International Conference on Learning Representations (ICLR), 2017", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The learning of domain-invariant representations in the context of domain\nadaptation with neural networks is considered. We propose a new regularization\nmethod that minimizes the discrepancy between domain-specific latent feature\nrepresentations directly in the hidden activation space. Although some standard\ndistribution matching approaches exist that can be interpreted as the matching\nof weighted sums of moments, e.g. Maximum Mean Discrepancy (MMD), an explicit\norder-wise matching of higher order moments has not been considered before. We\npropose to match the higher order central moments of probability distributions\nby means of order-wise moment differences. Our model does not require\ncomputationally expensive distance and kernel matrix computations. We utilize\nthe equivalent representation of probability distributions by moment sequences\nto define a new distance function, called Central Moment Discrepancy (CMD). We\nprove that CMD is a metric on the set of probability distributions on a compact\ninterval. We further prove that convergence of probability distributions on\ncompact intervals w.r.t. the new metric implies convergence in distribution of\nthe respective random variables. We test our approach on two different\nbenchmark data sets for object recognition (Office) and sentiment analysis of\nproduct reviews (Amazon reviews). CMD achieves a new state-of-the-art\nperformance on most domain adaptation tasks of Office and outperforms networks\ntrained with MMD, Variational Fair Autoencoders and Domain Adversarial Neural\nNetworks on Amazon reviews. In addition, a post-hoc parameter sensitivity\nanalysis shows that the new approach is stable w.r.t. parameter changes in a\ncertain interval. The source code of the experiments is publicly available.\n", "versions": [{"version": "v1", "created": "Tue, 28 Feb 2017 15:04:54 GMT"}, {"version": "v2", "created": "Tue, 4 Jul 2017 13:51:34 GMT"}, {"version": "v3", "created": "Thu, 2 May 2019 07:23:00 GMT"}], "update_date": "2019-05-03", "authors_parsed": [["Zellinger", "Werner", ""], ["Grubinger", "Thomas", ""], ["Lughofer", "Edwin", ""], ["Natschl\u00e4ger", "Thomas", ""], ["Saminger-Platz", "Susanne", ""]]}, {"id": "1702.08833", "submitter": "Daniel Zoran", "authors": "Daniel Zoran, Balaji Lakshminarayanan, Charles Blundell", "title": "Learning Deep Nearest Neighbor Representations Using Differentiable\n  Boundary Trees", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nearest neighbor (kNN) methods have been gaining popularity in recent years\nin light of advances in hardware and efficiency of algorithms. There is a\nplethora of methods to choose from today, each with their own advantages and\ndisadvantages. One requirement shared between all kNN based methods is the need\nfor a good representation and distance measure between samples.\n  We introduce a new method called differentiable boundary tree which allows\nfor learning deep kNN representations. We build on the recently proposed\nboundary tree algorithm which allows for efficient nearest neighbor\nclassification, regression and retrieval. By modelling traversals in the tree\nas stochastic events, we are able to form a differentiable cost function which\nis associated with the tree's predictions. Using a deep neural network to\ntransform the data and back-propagating through the tree allows us to learn\ngood representations for kNN methods.\n  We demonstrate that our method is able to learn suitable representations\nallowing for very efficient trees with a clearly interpretable structure.\n", "versions": [{"version": "v1", "created": "Tue, 28 Feb 2017 16:01:22 GMT"}], "update_date": "2017-03-01", "authors_parsed": [["Zoran", "Daniel", ""], ["Lakshminarayanan", "Balaji", ""], ["Blundell", "Charles", ""]]}, {"id": "1702.08835", "submitter": "Zhi-Hua Zhou", "authors": "Zhi-Hua Zhou and Ji Feng", "title": "Deep Forest", "comments": null, "journal-ref": "National Science Review, 2019, 6(1): 74-86", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current deep learning models are mostly build upon neural networks, i.e.,\nmultiple layers of parameterized differentiable nonlinear modules that can be\ntrained by backpropagation. In this paper, we explore the possibility of\nbuilding deep models based on non-differentiable modules. We conjecture that\nthe mystery behind the success of deep neural networks owes much to three\ncharacteristics, i.e., layer-by-layer processing, in-model feature\ntransformation and sufficient model complexity. We propose the gcForest\napproach, which generates \\textit{deep forest} holding these characteristics.\nThis is a decision tree ensemble approach, with much less hyper-parameters than\ndeep neural networks, and its model complexity can be automatically determined\nin a data-dependent way. Experiments show that its performance is quite robust\nto hyper-parameter settings, such that in most cases, even across different\ndata from different domains, it is able to get excellent performance by using\nthe same default setting. This study opens the door of deep learning based on\nnon-differentiable modules, and exhibits the possibility of constructing deep\nmodels without using backpropagation.\n", "versions": [{"version": "v1", "created": "Tue, 28 Feb 2017 16:10:31 GMT"}, {"version": "v2", "created": "Wed, 31 May 2017 17:15:34 GMT"}, {"version": "v3", "created": "Mon, 14 May 2018 18:06:13 GMT"}, {"version": "v4", "created": "Mon, 6 Jul 2020 12:23:49 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["Zhou", "Zhi-Hua", ""], ["Feng", "Ji", ""]]}, {"id": "1702.08840", "submitter": "Jungseul Ok", "authors": "Jungseul Ok, Sewoong Oh, Yunhun Jang, Jinwoo Shin, and Yung Yi", "title": "Iterative Bayesian Learning for Crowdsourced Regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Crowdsourcing platforms emerged as popular venues for purchasing human\nintelligence at low cost for large volume of tasks. As many low-paid workers\nare prone to give noisy answers, a common practice is to add redundancy by\nassigning multiple workers to each task and then simply average out these\nanswers. However, to fully harness the wisdom of the crowd, one needs to learn\nthe heterogeneous quality of each worker. We resolve this fundamental challenge\nin crowdsourced regression tasks, i.e., the answer takes continuous labels,\nwhere identifying good or bad workers becomes much more non-trivial compared to\na classification setting of discrete labels. In particular, we introduce a\nBayesian iterative scheme and show that it provably achieves the optimal mean\nsquared error. Our evaluations on synthetic and real-world datasets support our\ntheoretical results and show the superiority of the proposed scheme.\n", "versions": [{"version": "v1", "created": "Tue, 28 Feb 2017 16:15:13 GMT"}, {"version": "v2", "created": "Tue, 23 May 2017 11:27:14 GMT"}, {"version": "v3", "created": "Mon, 8 Oct 2018 17:02:49 GMT"}], "update_date": "2018-10-09", "authors_parsed": [["Ok", "Jungseul", ""], ["Oh", "Sewoong", ""], ["Jang", "Yunhun", ""], ["Shin", "Jinwoo", ""], ["Yi", "Yung", ""]]}, {"id": "1702.08882", "submitter": "Kenji Kawaguchi", "authors": "Kenji Kawaguchi, Bo Xie, Vikas Verma, Le Song", "title": "Deep Semi-Random Features for Nonlinear Function Approximation", "comments": "AAAI 2018 - Extended version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose semi-random features for nonlinear function approximation. The\nflexibility of semi-random feature lies between the fully adjustable units in\ndeep learning and the random features used in kernel methods. For one hidden\nlayer models with semi-random features, we prove with no unrealistic\nassumptions that the model classes contain an arbitrarily good function as the\nwidth increases (universality), and despite non-convexity, we can find such a\ngood function (optimization theory) that generalizes to unseen new data\n(generalization bound). For deep models, with no unrealistic assumptions, we\nprove universal approximation ability, a lower bound on approximation error, a\npartial optimization guarantee, and a generalization bound. Depending on the\nproblems, the generalization bound of deep semi-random features can be\nexponentially better than the known bounds of deep ReLU nets; our\ngeneralization error bound can be independent of the depth, the number of\ntrainable weights as well as the input dimensionality. In experiments, we show\nthat semi-random features can match the performance of neural networks by using\nslightly more units, and it outperforms random features by using significantly\nfewer units. Moreover, we introduce a new implicit ensemble method by using\nsemi-random features.\n", "versions": [{"version": "v1", "created": "Tue, 28 Feb 2017 17:47:34 GMT"}, {"version": "v2", "created": "Sun, 12 Mar 2017 22:51:06 GMT"}, {"version": "v3", "created": "Thu, 20 Apr 2017 22:31:17 GMT"}, {"version": "v4", "created": "Fri, 19 May 2017 02:39:31 GMT"}, {"version": "v5", "created": "Fri, 2 Jun 2017 04:05:15 GMT"}, {"version": "v6", "created": "Sat, 10 Jun 2017 17:11:27 GMT"}, {"version": "v7", "created": "Tue, 21 Nov 2017 03:44:50 GMT"}], "update_date": "2017-11-22", "authors_parsed": [["Kawaguchi", "Kenji", ""], ["Xie", "Bo", ""], ["Verma", "Vikas", ""], ["Song", "Le", ""]]}, {"id": "1702.08884", "submitter": "Raphael Petegrosso", "authors": "Raphael Petegrosso, Wei Zhang, Zhuliu Li, Yousef Saad and Rui Kuang", "title": "Low-rank Label Propagation for Semi-supervised Learning with 100\n  Millions Samples", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The success of semi-supervised learning crucially relies on the scalability\nto a huge amount of unlabelled data that are needed to capture the underlying\nmanifold structure for better classification. Since computing the pairwise\nsimilarity between the training data is prohibitively expensive in most kinds\nof input data, currently, there is no general ready-to-use semi-supervised\nlearning method/tool available for learning with tens of millions or more data\npoints. In this paper, we adopted the idea of two low-rank label propagation\nalgorithms, GLNP (Global Linear Neighborhood Propagation) and Kernel Nystr\\\"om\nApproximation, and implemented the parallelized version of the two algorithms\naccelerated with Nesterov's accelerated projected gradient descent for Big-data\nLabel Propagation (BigLP).\n  The parallel algorithms are tested on five real datasets ranging from 7000 to\n10,000,000 in size and a simulation dataset of 100,000,000 samples. In the\nexperiments, the implementation can scale up to datasets with 100,000,000\nsamples and hundreds of features and the algorithms also significantly improved\nthe prediction accuracy when only a very small percentage of the data is\nlabeled. The results demonstrate that the BigLP implementation is highly\nscalable to big data and effective in utilizing the unlabeled data for\nsemi-supervised learning.\n", "versions": [{"version": "v1", "created": "Tue, 28 Feb 2017 17:48:21 GMT"}], "update_date": "2017-03-01", "authors_parsed": [["Petegrosso", "Raphael", ""], ["Zhang", "Wei", ""], ["Li", "Zhuliu", ""], ["Saad", "Yousef", ""], ["Kuang", "Rui", ""]]}, {"id": "1702.08887", "submitter": "Nantas Nardelli", "authors": "Jakob Foerster, Nantas Nardelli, Gregory Farquhar, Triantafyllos\n  Afouras, Philip H. S. Torr, Pushmeet Kohli, Shimon Whiteson", "title": "Stabilising Experience Replay for Deep Multi-Agent Reinforcement\n  Learning", "comments": "Camera-ready version, International Conference of Machine Learning\n  2017; updated to fix print-breaking image", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many real-world problems, such as network packet routing and urban traffic\ncontrol, are naturally modeled as multi-agent reinforcement learning (RL)\nproblems. However, existing multi-agent RL methods typically scale poorly in\nthe problem size. Therefore, a key challenge is to translate the success of\ndeep learning on single-agent RL to the multi-agent setting. A major stumbling\nblock is that independent Q-learning, the most popular multi-agent RL method,\nintroduces nonstationarity that makes it incompatible with the experience\nreplay memory on which deep Q-learning relies. This paper proposes two methods\nthat address this problem: 1) using a multi-agent variant of importance\nsampling to naturally decay obsolete data and 2) conditioning each agent's\nvalue function on a fingerprint that disambiguates the age of the data sampled\nfrom the replay memory. Results on a challenging decentralised variant of\nStarCraft unit micromanagement confirm that these methods enable the successful\ncombination of experience replay with multi-agent RL.\n", "versions": [{"version": "v1", "created": "Tue, 28 Feb 2017 17:56:41 GMT"}, {"version": "v2", "created": "Mon, 12 Jun 2017 22:00:56 GMT"}, {"version": "v3", "created": "Mon, 21 May 2018 08:24:02 GMT"}], "update_date": "2018-05-22", "authors_parsed": [["Foerster", "Jakob", ""], ["Nardelli", "Nantas", ""], ["Farquhar", "Gregory", ""], ["Afouras", "Triantafyllos", ""], ["Torr", "Philip H. S.", ""], ["Kohli", "Pushmeet", ""], ["Whiteson", "Shimon", ""]]}, {"id": "1702.08892", "submitter": "Ofir Nachum", "authors": "Ofir Nachum, Mohammad Norouzi, Kelvin Xu, Dale Schuurmans", "title": "Bridging the Gap Between Value and Policy Based Reinforcement Learning", "comments": "NIPS 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We establish a new connection between value and policy based reinforcement\nlearning (RL) based on a relationship between softmax temporal value\nconsistency and policy optimality under entropy regularization. Specifically,\nwe show that softmax consistent action values correspond to optimal entropy\nregularized policy probabilities along any action sequence, regardless of\nprovenance. From this observation, we develop a new RL algorithm, Path\nConsistency Learning (PCL), that minimizes a notion of soft consistency error\nalong multi-step action sequences extracted from both on- and off-policy\ntraces. We examine the behavior of PCL in different scenarios and show that PCL\ncan be interpreted as generalizing both actor-critic and Q-learning algorithms.\nWe subsequently deepen the relationship by showing how a single model can be\nused to represent both a policy and the corresponding softmax state values,\neliminating the need for a separate critic. The experimental evaluation\ndemonstrates that PCL significantly outperforms strong actor-critic and\nQ-learning baselines across several benchmarks.\n", "versions": [{"version": "v1", "created": "Tue, 28 Feb 2017 18:06:15 GMT"}, {"version": "v2", "created": "Thu, 8 Jun 2017 19:31:32 GMT"}, {"version": "v3", "created": "Wed, 22 Nov 2017 23:11:20 GMT"}], "update_date": "2017-11-27", "authors_parsed": [["Nachum", "Ofir", ""], ["Norouzi", "Mohammad", ""], ["Xu", "Kelvin", ""], ["Schuurmans", "Dale", ""]]}, {"id": "1702.08896", "submitter": "Dustin Tran", "authors": "Dustin Tran, Rajesh Ranganath, David M. Blei", "title": "Hierarchical Implicit Models and Likelihood-Free Variational Inference", "comments": "Appears in Neural Information Processing Systems, 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Implicit probabilistic models are a flexible class of models defined by a\nsimulation process for data. They form the basis for theories which encompass\nour understanding of the physical world. Despite this fundamental nature, the\nuse of implicit models remains limited due to challenges in specifying complex\nlatent structure in them, and in performing inferences in such models with\nlarge data sets. In this paper, we first introduce hierarchical implicit models\n(HIMs). HIMs combine the idea of implicit densities with hierarchical Bayesian\nmodeling, thereby defining models via simulators of data with rich hidden\nstructure. Next, we develop likelihood-free variational inference (LFVI), a\nscalable variational inference algorithm for HIMs. Key to LFVI is specifying a\nvariational family that is also implicit. This matches the model's flexibility\nand allows for accurate approximation of the posterior. We demonstrate diverse\napplications: a large-scale physical simulator for predator-prey populations in\necology; a Bayesian generative adversarial network for discrete data; and a\ndeep implicit model for text generation.\n", "versions": [{"version": "v1", "created": "Tue, 28 Feb 2017 18:33:32 GMT"}, {"version": "v2", "created": "Mon, 13 Mar 2017 17:28:04 GMT"}, {"version": "v3", "created": "Sun, 5 Nov 2017 01:52:45 GMT"}], "update_date": "2017-11-07", "authors_parsed": [["Tran", "Dustin", ""], ["Ranganath", "Rajesh", ""], ["Blei", "David M.", ""]]}, {"id": "1702.08898", "submitter": "Jan-Peter Calliess", "authors": "Jan-Peter Calliess", "title": "Lipschitz Optimisation for Lipschitz Interpolation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Techniques known as Nonlinear Set Membership prediction, Kinky Inference or\nLipschitz Interpolation are fast and numerically robust approaches to\nnonparametric machine learning that have been proposed to be utilised in the\ncontext of system identification and learning-based control. They utilise\npresupposed Lipschitz properties in order to compute inferences over unobserved\nfunction values. Unfortunately, most of these approaches rely on exact\nknowledge about the input space metric as well as about the Lipschitz constant.\nFurthermore, existing techniques to estimate the Lipschitz constants from the\ndata are not robust to noise or seem to be ad-hoc and typically are decoupled\nfrom the ultimate learning and prediction task. To overcome these limitations,\nwe propose an approach for optimising parameters of the presupposed metrics by\nminimising validation set prediction errors. To avoid poor performance due to\nlocal minima, we propose to utilise Lipschitz properties of the optimisation\nobjective to ensure global optimisation success. The resulting approach is a\nnew flexible method for nonparametric black-box learning. We provide\nexperimental evidence of the competitiveness of our approach on artificial as\nwell as on real data.\n", "versions": [{"version": "v1", "created": "Tue, 28 Feb 2017 18:36:16 GMT"}], "update_date": "2017-03-01", "authors_parsed": [["Calliess", "Jan-Peter", ""]]}]