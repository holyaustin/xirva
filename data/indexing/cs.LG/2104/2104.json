[{"id": "2104.00008", "submitter": "Dan Roberts", "authors": "Daniel A. Roberts", "title": "Why is AI hard and Physics simple?", "comments": "written for a special issue of Machine Learning: Science and\n  Technology as an invited perspective piece", "journal-ref": null, "doi": null, "report-no": "MIT-CTP/5269", "categories": "hep-th cs.AI cs.LG physics.hist-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We discuss why AI is hard and why physics is simple. We discuss how physical\nintuition and the approach of theoretical physics can be brought to bear on the\nfield of artificial intelligence and specifically machine learning. We suggest\nthat the underlying project of machine learning and the underlying project of\nphysics are strongly coupled through the principle of sparsity, and we call\nupon theoretical physicists to work on AI as physicists. As a first step in\nthat direction, we discuss an upcoming book on the principles of deep learning\ntheory that attempts to realize this approach.\n", "versions": [{"version": "v1", "created": "Wed, 31 Mar 2021 18:00:01 GMT"}], "update_date": "2021-04-09", "authors_parsed": [["Roberts", "Daniel A.", ""]]}, {"id": "2104.00031", "submitter": "Tien-Ju Yang", "authors": "Tien-Ju Yang, Yi-Lun Liao, Vivienne Sze", "title": "NetAdaptV2: Efficient Neural Architecture Search with Fast Super-Network\n  Training and Architecture Optimization", "comments": "Accepted by CVPR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural architecture search (NAS) typically consists of three main steps:\ntraining a super-network, training and evaluating sampled deep neural networks\n(DNNs), and training the discovered DNN. Most of the existing efforts speed up\nsome steps at the cost of a significant slowdown of other steps or sacrificing\nthe support of non-differentiable search metrics. The unbalanced reduction in\nthe time spent per step limits the total search time reduction, and the\ninability to support non-differentiable search metrics limits the performance\nof discovered DNNs.\n  In this paper, we present NetAdaptV2 with three innovations to better balance\nthe time spent for each step while supporting non-differentiable search\nmetrics. First, we propose channel-level bypass connections that merge network\ndepth and layer width into a single search dimension to reduce the time for\ntraining and evaluating sampled DNNs. Second, ordered dropout is proposed to\ntrain multiple DNNs in a single forward-backward pass to decrease the time for\ntraining a super-network. Third, we propose the multi-layer coordinate descent\noptimizer that considers the interplay of multiple layers in each iteration of\noptimization to improve the performance of discovered DNNs while supporting\nnon-differentiable search metrics. With these innovations, NetAdaptV2 reduces\nthe total search time by up to $5.8\\times$ on ImageNet and $2.4\\times$ on NYU\nDepth V2, respectively, and discovers DNNs with better\naccuracy-latency/accuracy-MAC trade-offs than state-of-the-art NAS works.\nMoreover, the discovered DNN outperforms NAS-discovered MobileNetV3 by 1.8%\nhigher top-1 accuracy with the same latency. The project website is\nhttp://netadapt.mit.edu.\n", "versions": [{"version": "v1", "created": "Wed, 31 Mar 2021 18:03:46 GMT"}], "update_date": "2021-04-02", "authors_parsed": [["Yang", "Tien-Ju", ""], ["Liao", "Yi-Lun", ""], ["Sze", "Vivienne", ""]]}, {"id": "2104.00032", "submitter": "Moritz B\\\"ohle", "authors": "Moritz B\\\"ohle and Mario Fritz and Bernt Schiele", "title": "Convolutional Dynamic Alignment Networks for Interpretable\n  Classifications", "comments": "Accepted at CVRP 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new family of neural network models called Convolutional\nDynamic Alignment Networks (CoDA-Nets), which are performant classifiers with a\nhigh degree of inherent interpretability. Their core building blocks are\nDynamic Alignment Units (DAUs), which linearly transform their input with\nweight vectors that dynamically align with task-relevant patterns. As a result,\nCoDA-Nets model the classification prediction through a series of\ninput-dependent linear transformations, allowing for linear decomposition of\nthe output into individual input contributions. Given the alignment of the\nDAUs, the resulting contribution maps align with discriminative input patterns.\nThese model-inherent decompositions are of high visual quality and outperform\nexisting attribution methods under quantitative metrics. Further, CoDA-Nets\nconstitute performant classifiers, achieving on par results to ResNet and VGG\nmodels on e.g. CIFAR-10 and TinyImagenet.\n", "versions": [{"version": "v1", "created": "Wed, 31 Mar 2021 18:03:53 GMT"}], "update_date": "2021-04-02", "authors_parsed": [["B\u00f6hle", "Moritz", ""], ["Fritz", "Mario", ""], ["Schiele", "Bernt", ""]]}, {"id": "2104.00035", "submitter": "Tamer Olmez", "authors": "Tamer \\\"Olmez and Z\\\"umray Dokur", "title": "Strengthening the Training of Convolutional Neural Networks By Using\n  Walsh Matrix", "comments": "Keyword: Deep neural networks, Convolutional neural network, Pattern\n  recognition, Training deep neural network, Classification. arXiv admin note:\n  substantial text overlap with arXiv:2103.10977", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  DNN structures are continuously developing and achieving high performances in\nclassification problems. Also, it is observed that success rates obtained with\nDNNs are higher than those obtained with traditional neural networks. In\naddition, one of the advantages of DNNs is that there is no need to spend an\nextra effort to determine the features; the CNN automatically extracts the\nfeatures from the dataset during the training. Besides their benefits, the DNNs\nhave the following three major drawbacks among the others: (i) Researchers have\nstruggled with over-fitting and under-fitting issues in the training of DNNs,\n(ii) determination of even a coarse structure for the DNN may take days, and\n(iii) most of the time, the proposed network structure is too large to be too\nbulky to be used in real time applications. We have modified the training and\nstructure of DNN to increase the classification performance, to decrease the\nnumber of nodes in the structure, and to be used with less number of hyper\nparameters. A minimum distance network (MDN) following the last layer of the\nconvolutional neural network (CNN) is used as the classifier instead of a fully\nconnected neural network (FCNN). In order to strengthen the training of the\nCNN, we suggest employing Walsh function. We tested the performances of the\nproposed DNN (named as DivFE) on the classification of ECG, EEG, heart sound,\ndetection pneumonia in X-ray chest images, detection of BGA solder defects, and\npatterns of benchmark datasets (MNIST, IRIS, CIFAR10 and CIFAR20). In different\nareas, it has been observed that a higher classification performance was\nobtained by using the DivFE with less number of nodes.\n", "versions": [{"version": "v1", "created": "Wed, 31 Mar 2021 18:06:11 GMT"}], "update_date": "2021-04-02", "authors_parsed": [["\u00d6lmez", "Tamer", ""], ["Dokur", "Z\u00fcmray", ""]]}, {"id": "2104.00038", "submitter": "Jason Hoffman", "authors": "Jason S. Hoffman, Varun Viswanath, Xinyi Ding, Matthew J. Thompson,\n  Eric C. Larson, Shwetak N. Patel and Edward Wang", "title": "Smartphone Camera Oximetry in an Induced Hypoxemia Study", "comments": "26 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.HC", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Hypoxemia, a medical condition that occurs when the blood is not carrying\nenough oxygen to adequately supply the tissues, is a leading indicator for\ndangerous complications of respiratory diseases like asthma, COPD, and\nCOVID-19. While purpose-built pulse oximeters can provide accurate blood-oxygen\nsaturation (SpO$_2$) readings that allow for diagnosis of hypoxemia, enabling\nthis capability in unmodified smartphone cameras via a software update could\ngive more people access to important information about their health, as well as\nimprove physicians' ability to remotely diagnose and treat respiratory\nconditions. In this work, we take a step towards this goal by performing the\nfirst clinical development validation on a smartphone-based SpO$_2$ sensing\nsystem using a varied fraction of inspired oxygen (FiO$_2$) protocol, creating\na clinically relevant validation dataset for solely smartphone-based methods on\na wide range of SpO$_2$ values (70%-100%) for the first time. This contrasts\nwith previous studies, which evaluated performance on a far smaller range\n(85%-100%). We build a deep learning model using this data to demonstrate\naccurate reporting of SpO$_2$ level with an overall MAE=5.00% SpO$_2$ and\nidentifying positive cases of low SpO$_2$<90% with 81% sensitivity and 79%\nspecificity. We ground our analysis with a summary of recent literature in\nsmartphone-based SpO2 monitoring, and we provide the data from the FiO$_2$\nstudy in open-source format, so that others may build on this work.\n", "versions": [{"version": "v1", "created": "Wed, 31 Mar 2021 18:10:10 GMT"}], "update_date": "2021-04-02", "authors_parsed": [["Hoffman", "Jason S.", ""], ["Viswanath", "Varun", ""], ["Ding", "Xinyi", ""], ["Thompson", "Matthew J.", ""], ["Larson", "Eric C.", ""], ["Patel", "Shwetak N.", ""], ["Wang", "Edward", ""]]}, {"id": "2104.00055", "submitter": "Amit Roy", "authors": "Amit Roy, Kashob Kumar Roy, Amin Ahsan Ali, M Ashraful Amin, and A K M\n  Mahbubur Rahman", "title": "SST-GNN: Simplified Spatio-temporal Traffic forecasting model using\n  Graph Neural Network", "comments": "Accepted for publication in 25th Pacific-Asia Conference on Knowledge\n  Discovery and Data Mining (PAKDD-2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To capture spatial relationships and temporal dynamics in traffic data,\nspatio-temporal models for traffic forecasting have drawn significant attention\nin recent years. Most of the recent works employed graph neural networks(GNN)\nwith multiple layers to capture the spatial dependency. However, road junctions\nwith different hop-distance can carry distinct traffic information which should\nbe exploited separately but existing multi-layer GNNs are incompetent to\ndiscriminate between their impact. Again, to capture the temporal\ninterrelationship, recurrent neural networks are common in state-of-the-art\napproaches that often fail to capture long-range dependencies. Furthermore,\ntraffic data shows repeated patterns in a daily or weekly period which should\nbe addressed explicitly. To address these limitations, we have designed a\nSimplified Spatio-temporal Traffic forecasting GNN(SST-GNN) that effectively\nencodes the spatial dependency by separately aggregating different neighborhood\nrepresentations rather than with multiple layers and capture the temporal\ndependency with a simple yet effective weighted spatio-temporal aggregation\nmechanism. We capture the periodic traffic patterns by using a novel position\nencoding scheme with historical and current data in two different models. With\nextensive experimental analysis, we have shown that our model has significantly\noutperformed the state-of-the-art models on three real-world traffic datasets\nfrom the Performance Measurement System (PeMS).\n", "versions": [{"version": "v1", "created": "Wed, 31 Mar 2021 18:28:44 GMT"}], "update_date": "2021-04-02", "authors_parsed": [["Roy", "Amit", ""], ["Roy", "Kashob Kumar", ""], ["Ali", "Amin Ahsan", ""], ["Amin", "M Ashraful", ""], ["Rahman", "A K M Mahbubur", ""]]}, {"id": "2104.00075", "submitter": "Mehdi Naderi Soorki", "authors": "Mehdi Naderi Soorki, Walid Saad, Mehdi Bennis, Choong Seon Hong", "title": "Ultra-Reliable Indoor Millimeter Wave Communications using Multiple\n  Artificial Intelligence-Powered Intelligent Surfaces", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, a novel framework for guaranteeing ultra-reliable millimeter\nwave (mmW) communications using multiple artificial intelligence (AI)-enabled\nreconfigurable intelligent surfaces (RISs) is proposed. The use of multiple\nAI-powered RISs allows changing the propagation direction of the signals\ntransmitted from a mmW access point (AP) thereby improving coverage\nparticularly for non-line-of-sight (NLoS) areas. However, due to the\npossibility of highly stochastic blockage over mmW links, designing an\nintelligent controller to jointly optimize the mmW AP beam and RIS phase shifts\nis a daunting task. In this regard, first, a parametric risk-sensitive episodic\nreturn is proposed to maximize the expected bit rate and mitigate the risk of\nmmW link blockage. Then, a closed-form approximation of the policy gradient of\nthe risk-sensitive episodic return is analytically derived. Next, the problem\nof joint beamforming for mmW AP and phase shift control for mmW RISs is modeled\nas an identical payoff stochastic game within a cooperative multi-agent\nenvironment, in which the agents are the mmW AP and the RISs. Two centralized\nand distributed controllers are proposed to control the policies of the mmW AP\nand RISs. To directly find an optimal solution, the parametric functional-form\npolicies for these controllers are modeled using deep recurrent neural networks\n(RNNs). Simulation results show that the error between policies of the optimal\nand the RNN-based controllers is less than 1.5%. Moreover, the variance of the\nachievable rates resulting from the deep RNN-based controllers is 60% less than\nthe variance of the risk-averse baseline.\n", "versions": [{"version": "v1", "created": "Wed, 31 Mar 2021 19:15:49 GMT"}], "update_date": "2021-04-02", "authors_parsed": [["Soorki", "Mehdi Naderi", ""], ["Saad", "Walid", ""], ["Bennis", "Mehdi", ""], ["Hong", "Choong Seon", ""]]}, {"id": "2104.00084", "submitter": "Timo Rehfeld", "authors": "Li Zhang, Faezeh Tafazzoli, Gunther Krehl, Runsheng Xu, Timo Rehfeld,\n  Manuel Schier, Arunava Seal", "title": "Hierarchical Road Topology Learning for Urban Map-less Driving", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The majority of current approaches in autonomous driving rely on\nHigh-Definition (HD) maps which detail the road geometry and surrounding area.\nYet, this reliance is one of the obstacles to mass deployment of autonomous\nvehicles due to poor scalability of such prior maps. In this paper, we tackle\nthe problem of online road map extraction via leveraging the sensory system\naboard the vehicle itself. To this end, we design a structured model where a\ngraph representation of the road network is generated in a hierarchical fashion\nwithin a fully convolutional network. The method is able to handle complex road\ntopology and does not require a user in the loop.\n", "versions": [{"version": "v1", "created": "Wed, 31 Mar 2021 19:51:25 GMT"}], "update_date": "2021-04-02", "authors_parsed": [["Zhang", "Li", ""], ["Tafazzoli", "Faezeh", ""], ["Krehl", "Gunther", ""], ["Xu", "Runsheng", ""], ["Rehfeld", "Timo", ""], ["Schier", "Manuel", ""], ["Seal", "Arunava", ""]]}, {"id": "2104.00088", "submitter": "Sebastian Me\\v{z}nar", "authors": "Sebastian Me\\v{z}nar, Nada Lavra\\v{c}, Bla\\v{z} \\v{S}krlj", "title": "Transfer Learning for Node Regression Applied to Spreading Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding how information propagates in real-life complex networks yields\na better understanding of dynamic processes such as misinformation or epidemic\nspreading. The recently introduced branch of machine learning methods for\nlearning node representations offers many novel applications, one of them being\nthe task of spreading prediction addressed in this paper. We explore the\nutility of the state-of-the-art node representation learners when used to\nassess the effects of spreading from a given node, estimated via extensive\nsimulations. Further, as many real-life networks are topologically similar, we\nsystematically investigate whether the learned models generalize to previously\nunseen networks, showing that in some cases very good model transfer can be\nobtained. This work is one of the first to explore transferability of the\nlearned representations for the task of node regression; we show there exist\npairs of networks with similar structure between which the trained models can\nbe transferred (zero-shot), and demonstrate their competitive performance. To\nour knowledge, this is one of the first attempts to evaluate the utility of\nzero-shot transfer for the task of node regression.\n", "versions": [{"version": "v1", "created": "Wed, 31 Mar 2021 20:09:09 GMT"}, {"version": "v2", "created": "Mon, 3 May 2021 15:42:38 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Me\u017enar", "Sebastian", ""], ["Lavra\u010d", "Nada", ""], ["\u0160krlj", "Bla\u017e", ""]]}, {"id": "2104.00102", "submitter": "Farzad Pourbabaee", "authors": "Farzad Pourbabaee", "title": "Robust Experimentation in the Continuous Time Bandit Problem", "comments": null, "journal-ref": "Economic Theory, pp. 1-31, 2000, Springer", "doi": "10.1007/s00199-020-01328-3", "report-no": null, "categories": "econ.TH cs.GT cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the experimentation dynamics of a decision maker (DM) in a two-armed\nbandit setup (Bolton and Harris (1999)), where the agent holds ambiguous\nbeliefs regarding the distribution of the return process of one arm and is\ncertain about the other one. The DM entertains Multiplier preferences a la\nHansen and Sargent (2001), thus we frame the decision making environment as a\ntwo-player differential game against nature in continuous time. We characterize\nthe DM value function and her optimal experimentation strategy that turns out\nto follow a cut-off rule with respect to her belief process. The belief\nthreshold for exploring the ambiguous arm is found in closed form and is shown\nto be increasing with respect to the ambiguity aversion index. We then study\nthe effect of provision of an unambiguous information source about the\nambiguous arm. Interestingly, we show that the exploration threshold rises\nunambiguously as a result of this new information source, thereby leading to\nmore conservatism. This analysis also sheds light on the efficient time to\nreach for an expert opinion.\n", "versions": [{"version": "v1", "created": "Wed, 31 Mar 2021 20:42:39 GMT"}], "update_date": "2021-04-02", "authors_parsed": [["Pourbabaee", "Farzad", ""]]}, {"id": "2104.00106", "submitter": "Aviral Joshi", "authors": "Aviral Joshi, Chengzhi Huang, Har Simrat Singh", "title": "Zero-Shot Language Transfer vs Iterative Back Translation for\n  Unsupervised Machine Translation", "comments": "7 pages, 2 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This work focuses on comparing different solutions for machine translation on\nlow resource language pairs, namely, with zero-shot transfer learning and\nunsupervised machine translation. We discuss how the data size affects the\nperformance of both unsupervised MT and transfer learning. Additionally we also\nlook at how the domain of the data affects the result of unsupervised MT. The\ncode to all the experiments performed in this project are accessible on Github.\n", "versions": [{"version": "v1", "created": "Wed, 31 Mar 2021 20:47:19 GMT"}], "update_date": "2021-04-02", "authors_parsed": [["Joshi", "Aviral", ""], ["Huang", "Chengzhi", ""], ["Singh", "Har Simrat", ""]]}, {"id": "2104.00107", "submitter": "Aviral Joshi", "authors": "Abhinav Khattar, Aviral Joshi, Har Simrat Singh, Pulkit Goel, Rohit\n  Prakash Barnwal", "title": "Analysis on Image Set Visual Question Answering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We tackle the challenge of Visual Question Answering in multi-image setting\nfor the ISVQA dataset. Traditional VQA tasks have focused on a single-image\nsetting where the target answer is generated from a single image. Image set\nVQA, however, comprises of a set of images and requires finding connection\nbetween images, relate the objects across images based on these connections and\ngenerate a unified answer. In this report, we work with 4 approaches in a bid\nto improve the performance on the task. We analyse and compare our results with\nthree baseline models - LXMERT, HME-VideoQA and VisualBERT - and show that our\napproaches can provide a slight improvement over the baselines. In specific, we\ntry to improve on the spatial awareness of the model and help the model\nidentify color using enhanced pre-training, reduce language dependence using\nadversarial regularization, and improve counting using regression loss and\ngraph based deduplication. We further delve into an in-depth analysis on the\nlanguage bias in the ISVQA dataset and show how models trained on ISVQA\nimplicitly learn to associate language more strongly with the final answer.\n", "versions": [{"version": "v1", "created": "Wed, 31 Mar 2021 20:47:32 GMT"}], "update_date": "2021-04-02", "authors_parsed": [["Khattar", "Abhinav", ""], ["Joshi", "Aviral", ""], ["Singh", "Har Simrat", ""], ["Goel", "Pulkit", ""], ["Barnwal", "Rohit Prakash", ""]]}, {"id": "2104.00120", "submitter": "Timo Lohrenz", "authors": "Timo Lohrenz, Zhengyang Li, Tim Fingscheidt", "title": "Multi-Encoder Learning and Stream Fusion for Transformer-Based\n  End-to-End Automatic Speech Recognition", "comments": "accepted at INTERSPEECH 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stream fusion, also known as system combination, is a common technique in\nautomatic speech recognition for traditional hybrid hidden Markov model\napproaches, yet mostly unexplored for modern deep neural network end-to-end\nmodel architectures. Here, we investigate various fusion techniques for the\nall-attention-based encoder-decoder architecture known as the transformer,\nstriving to achieve optimal fusion by investigating different fusion levels in\nan example single-microphone setting with fusion of standard magnitude and\nphase features. We introduce a novel multi-encoder learning method that\nperforms a weighted combination of two encoder-decoder multi-head attention\noutputs only during training. Employing then only the magnitude feature encoder\nin inference, we are able to show consistent improvement on Wall Street Journal\n(WSJ) with language model and on Librispeech, without increase in runtime or\nparameters. Combining two such multi-encoder trained models by a simple late\nfusion in inference, we achieve state-of-the-art performance for\ntransformer-based models on WSJ with a significant WER reduction of 19%\nrelative compared to the current benchmark approach.\n", "versions": [{"version": "v1", "created": "Wed, 31 Mar 2021 21:07:43 GMT"}, {"version": "v2", "created": "Wed, 14 Jul 2021 14:10:01 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Lohrenz", "Timo", ""], ["Li", "Zhengyang", ""], ["Fingscheidt", "Tim", ""]]}, {"id": "2104.00137", "submitter": "Chien-Lun Chen", "authors": "Chien-Lun Chen, Leana Golubchik, Ranjan Pal", "title": "Achieving Transparency Report Privacy in Linear Time", "comments": "56 pages, 5 figures, accepted in ACM Journal of Data and Information\n  Quality (JDIQ), Special Issue on Data Transparency", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  An accountable algorithmic transparency report (ATR) should ideally\ninvestigate the (a) transparency of the underlying algorithm, and (b) fairness\nof the algorithmic decisions, and at the same time preserve data subjects'\nprivacy. However, a provably formal study of the impact to data subjects'\nprivacy caused by the utility of releasing an ATR (that investigates\ntransparency and fairness), is yet to be addressed in the literature. The\nfar-fetched benefit of such a study lies in the methodical characterization of\nprivacy-utility trade-offs for release of ATRs in public, and their\nconsequential application-specific impact on the dimensions of society,\npolitics, and economics. In this paper, we first investigate and demonstrate\npotential privacy hazards brought on by the deployment of transparency and\nfairness measures in released ATRs. To preserve data subjects' privacy, we then\npropose a linear-time optimal-privacy scheme, built upon standard linear\nfractional programming (LFP) theory, for announcing ATRs, subject to\nconstraints controlling the tolerance of privacy perturbation on the utility of\ntransparency schemes. Subsequently, we quantify the privacy-utility trade-offs\ninduced by our scheme, and analyze the impact of privacy perturbation on\nfairness measures in ATRs. To the best of our knowledge, this is the first\nanalytical work that simultaneously addresses trade-offs between the triad of\nprivacy, utility, and fairness, applicable to algorithmic transparency reports.\n", "versions": [{"version": "v1", "created": "Wed, 31 Mar 2021 22:05:10 GMT"}, {"version": "v2", "created": "Fri, 9 Apr 2021 20:35:51 GMT"}, {"version": "v3", "created": "Thu, 15 Apr 2021 20:58:03 GMT"}], "update_date": "2021-04-19", "authors_parsed": [["Chen", "Chien-Lun", ""], ["Golubchik", "Leana", ""], ["Pal", "Ranjan", ""]]}, {"id": "2104.00138", "submitter": "Piotr Slomka", "authors": "Kajetan Grodecki, Aditya Killekar, Andrew Lin, Sebastien Cadet,\n  Priscilla McElhinney, Aryabod Razipour, Cato Chan, Barry D. Pressman, Peter\n  Julien, Judit Simon, Pal Maurovich-Horvat, Nicola Gaibazzi, Udit Thakur,\n  Elisabetta Mancini, Cecilia Agalbato, Jiro Munechika, Hidenari Matsumoto,\n  Roberto Men\\`e, Gianfranco Parati, Franco Cernigliaro, Nitesh Nerlekar,\n  Camilla Torlasco, Gianluca Pontone, Damini Dey, Piotr J. Slomka", "title": "Rapid quantification of COVID-19 pneumonia burden from computed\n  tomography with convolutional LSTM networks", "comments": "Fixed some typing mistakes in v2. No other results changed", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Quantitative lung measures derived from computed tomography (CT) have been\ndemonstrated to improve prognostication in coronavirus disease (COVID-19)\npatients, but are not part of the clinical routine since required manual\nsegmentation of lung lesions is prohibitively time-consuming. We propose a new\nfully automated deep learning framework for rapid quantification and\ndifferentiation between lung lesions in COVID-19 pneumonia from both contrast\nand non-contrast CT images using convolutional Long Short-Term Memory\n(ConvLSTM) networks. Utilizing the expert annotations, model training was\nperformed 5 times with separate hold-out sets using 5-fold cross-validation to\nsegment ground-glass opacity and high opacity (including consolidation and\npleural effusion). The performance of the method was evaluated on CT data sets\nfrom 197 patients with positive reverse transcription polymerase chain reaction\ntest result for SARS-CoV-2. Strong agreement between expert manual and\nautomatic segmentation was obtained for lung lesions with a Dice score\ncoefficient of 0.876 $\\pm$ 0.005; excellent correlations of 0.978 and 0.981 for\nground-glass opacity and high opacity volumes. In the external validation set\nof 67 patients, there was dice score coefficient of 0.767 $\\pm$ 0.009 as well\nas excellent correlations of 0.989 and 0.996 for ground-glass opacity and high\nopacity volumes. Computations for a CT scan comprising 120 slices were\nperformed under 2 seconds on a personal computer equipped with NVIDIA Titan RTX\ngraphics processing unit. Therefore, our deep learning-based method allows\nrapid fully-automated quantitative measurement of pneumonia burden from CT and\nmay generate results with an accuracy similar to the expert readers.\n", "versions": [{"version": "v1", "created": "Wed, 31 Mar 2021 22:09:14 GMT"}, {"version": "v2", "created": "Tue, 13 Jul 2021 17:38:07 GMT"}, {"version": "v3", "created": "Sat, 17 Jul 2021 00:14:16 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Grodecki", "Kajetan", ""], ["Killekar", "Aditya", ""], ["Lin", "Andrew", ""], ["Cadet", "Sebastien", ""], ["McElhinney", "Priscilla", ""], ["Razipour", "Aryabod", ""], ["Chan", "Cato", ""], ["Pressman", "Barry D.", ""], ["Julien", "Peter", ""], ["Simon", "Judit", ""], ["Maurovich-Horvat", "Pal", ""], ["Gaibazzi", "Nicola", ""], ["Thakur", "Udit", ""], ["Mancini", "Elisabetta", ""], ["Agalbato", "Cecilia", ""], ["Munechika", "Jiro", ""], ["Matsumoto", "Hidenari", ""], ["Men\u00e8", "Roberto", ""], ["Parati", "Gianfranco", ""], ["Cernigliaro", "Franco", ""], ["Nerlekar", "Nitesh", ""], ["Torlasco", "Camilla", ""], ["Pontone", "Gianluca", ""], ["Dey", "Damini", ""], ["Slomka", "Piotr J.", ""]]}, {"id": "2104.00158", "submitter": "Nikos Katzouris", "authors": "Nikos Katzouris, Alexander Artikis and Georgios Paliouras", "title": "Online Learning Probabilistic Event Calculus Theories in Answer Set\n  Programming", "comments": "Under consideration in Theory and Practice of Logic Programming\n  (TPLP)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Complex Event Recognition (CER) systems detect event occurrences in streaming\ntime-stamped input using predefined event patterns. Logic-based approaches are\nof special interest in CER, since, via Statistical Relational AI, they combine\nuncertainty-resilient reasoning with time and change, with machine learning,\nthus alleviating the cost of manual event pattern authoring. We present a\nsystem based on Answer Set Programming (ASP), capable of probabilistic\nreasoning with complex event patterns in the form of weighted rules in the\nEvent Calculus, whose structure and weights are learnt online. We compare our\nASP-based implementation with a Markov Logic-based one and with a number of\nstate-of-the-art batch learning algorithms on CER datasets for activity\nrecognition, maritime surveillance and fleet management. Our results\ndemonstrate the superiority of our novel approach, both in terms of efficiency\nand predictive performance. This paper is under consideration for publication\nin Theory and Practice of Logic Programming (TPLP).\n", "versions": [{"version": "v1", "created": "Wed, 31 Mar 2021 23:16:29 GMT"}], "update_date": "2021-04-02", "authors_parsed": [["Katzouris", "Nikos", ""], ["Artikis", "Alexander", ""], ["Paliouras", "Georgios", ""]]}, {"id": "2104.00159", "submitter": "Daniel Reusche", "authors": "Daniel Reusche, Nicol\\'as Della Penna", "title": "Towards Prior-Free Approximately Truthful One-Shot Auction Learning via\n  Differential Privacy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Designing truthful, revenue maximizing auctions is a core problem of auction\ndesign. Multi-item settings have long been elusive. Recent work\n(arXiv:1706.03459) introduces effective deep learning techniques to find such\nauctions for the prior-dependent setting, in which distributions about bidder\npreferences are known. One remaining problem is to obtain priors in a way that\nexcludes the possibility of manipulating the resulting auctions. Using\ntechniques from differential privacy for the construction of approximately\ntruthful mechanisms, we modify the RegretNet approach to be applicable to the\nprior-free setting. In this more general setting, no distributional information\nis assumed, but we trade this property for worse performance. We present\npreliminary empirical results and qualitative analysis for this work in\nprogress.\n", "versions": [{"version": "v1", "created": "Wed, 31 Mar 2021 23:22:55 GMT"}], "update_date": "2021-04-02", "authors_parsed": [["Reusche", "Daniel", ""], ["Della Penna", "Nicol\u00e1s", ""]]}, {"id": "2104.00163", "submitter": "Faraz Torabi", "authors": "Faraz Torabi, Garrett Warnell and Peter Stone", "title": "DEALIO: Data-Efficient Adversarial Learning for Imitation from\n  Observation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In imitation learning from observation IfO, a learning agent seeks to imitate\na demonstrating agent using only observations of the demonstrated behavior\nwithout access to the control signals generated by the demonstrator. Recent\nmethods based on adversarial imitation learning have led to state-of-the-art\nperformance on IfO problems, but they typically suffer from high sample\ncomplexity due to a reliance on data-inefficient, model-free reinforcement\nlearning algorithms. This issue makes them impractical to deploy in real-world\nsettings, where gathering samples can incur high costs in terms of time,\nenergy, and risk. In this work, we hypothesize that we can incorporate ideas\nfrom model-based reinforcement learning with adversarial methods for IfO in\norder to increase the data efficiency of these methods without sacrificing\nperformance. Specifically, we consider time-varying linear Gaussian policies,\nand propose a method that integrates the linear-quadratic regulator with path\nintegral policy improvement into an existing adversarial IfO framework. The\nresult is a more data-efficient IfO algorithm with better performance, which we\nshow empirically in four simulation domains: using far fewer interactions with\nthe environment, the proposed method exhibits similar or better performance\nthan the existing technique.\n", "versions": [{"version": "v1", "created": "Wed, 31 Mar 2021 23:46:32 GMT"}], "update_date": "2021-04-02", "authors_parsed": [["Torabi", "Faraz", ""], ["Warnell", "Garrett", ""], ["Stone", "Peter", ""]]}, {"id": "2104.00164", "submitter": "Christine Sinoquet Ms", "authors": "Fatoumata Dama, Christine Sinoquet", "title": "Analysis and modeling to forecast in time series: a systematic review", "comments": "65 pages (including 9 pages with bibliographic references), 14\n  figures, 6 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  This paper surveys state-of-the-art methods and models dedicated to time\nseries analysis and modeling, with the final aim of prediction. This review\naims to offer a structured and comprehensive view of the full process flow, and\nencompasses time series decomposition, stationary tests, modeling and\nforecasting. Besides, to meet didactic purposes, a unified presentation has\nbeen adopted throughout this survey, to present decomposition frameworks on the\none hand and linear and nonlinear time series models on the other hand. First,\nwe decrypt the relationships between stationarity and linearity, and further\nexamine the main classes of methods used to test for weak stationarity. Next,\nthe main frameworks for time series decomposition are presented in a unified\nway: depending on the time series, a more or less complex decomposition scheme\nseeks to obtain nonstationary effects (the deterministic components) and a\nremaining stochastic component. An appropriate modeling of the latter is a\ncritical step to guarantee prediction accuracy. We then present three popular\nlinear models, together with two more flexible variants of the latter. A step\nfurther in model complexity, and still in a unified way, we present five major\nnonlinear models used for time series. Amongst nonlinear models, artificial\nneural networks hold a place apart as deep learning has recently gained\nconsiderable attention. A whole section is therefore dedicated to time series\nforecasting relying on deep learning approaches. A final section provides a\nlist of R and Python implementations for the methods, models and tests\npresented throughout this review. In this document, our intention is to bring\nsufficient in-depth knowledge, while covering a broad range of models and\nforecasting methods: this compilation spans from well-established conventional\napproaches to more recent adaptations of deep learning to time series\nforecasting.\n", "versions": [{"version": "v1", "created": "Wed, 31 Mar 2021 23:48:46 GMT"}], "update_date": "2021-04-02", "authors_parsed": [["Dama", "Fatoumata", ""], ["Sinoquet", "Christine", ""]]}, {"id": "2104.00165", "submitter": "Kenneth Stewart", "authors": "Kenneth Stewart, Andreea Danielescu, Lazar Supic, Timothy Shea, Emre\n  Neftci", "title": "Gesture Similarity Analysis on Event Data Using a Hybrid Guided\n  Variational Auto Encoder", "comments": "Submitted to ICCV 2021 for review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While commercial mid-air gesture recognition systems have existed for at\nleast a decade, they have not become a widespread method of interacting with\nmachines. This is primarily due to the fact that these systems require rigid,\ndramatic gestures to be performed for accurate recognition that can be\nfatiguing and unnatural. The global pandemic has seen a resurgence of interest\nin touchless interfaces, so new methods that allow for natural mid-air gestural\ninteractions are even more important. To address the limitations of recognition\nsystems, we propose a neuromorphic gesture analysis system which naturally\ndeclutters the background and analyzes gestures at high temporal resolution.\nOur novel model consists of an event-based guided Variational Autoencoder (VAE)\nwhich encodes event-based data sensed by a Dynamic Vision Sensor (DVS) into a\nlatent space representation suitable to analyze and compute the similarity of\nmid-air gesture data. Our results show that the features learned by the VAE\nprovides a similarity measure capable of clustering and pseudo labeling of new\ngestures. Furthermore, we argue that the resulting event-based encoder and\npseudo-labeling system are suitable for implementation in neuromorphic hardware\nfor online adaptation and learning of natural mid-air gestures.\n", "versions": [{"version": "v1", "created": "Wed, 31 Mar 2021 23:58:34 GMT"}], "update_date": "2021-04-02", "authors_parsed": [["Stewart", "Kenneth", ""], ["Danielescu", "Andreea", ""], ["Supic", "Lazar", ""], ["Shea", "Timothy", ""], ["Neftci", "Emre", ""]]}, {"id": "2104.00170", "submitter": "Robik Shrestha", "authors": "Robik Shrestha, Kushal Kafle and Christopher Kanan", "title": "An Investigation of Critical Issues in Bias Mitigation Techniques", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A critical problem in deep learning is that systems learn inappropriate\nbiases, resulting in their inability to perform well on minority groups. This\nhas led to the creation of multiple algorithms that endeavor to mitigate bias.\nHowever, it is not clear how effective these methods are. This is because study\nprotocols differ among papers, systems are tested on datasets that fail to test\nmany forms of bias, and systems have access to hidden knowledge or are tuned\nspecifically to the test set. To address this, we introduce an improved\nevaluation protocol, sensible metrics, and a new dataset, which enables us to\nask and answer critical questions about bias mitigation algorithms. We evaluate\nseven state-of-the-art algorithms using the same network architecture and\nhyperparameter selection policy across three benchmark datasets. We introduce a\nnew dataset called Biased MNIST that enables assessment of robustness to\nmultiple bias sources. We use Biased MNIST and a visual question answering\n(VQA) benchmark to assess robustness to hidden biases. Rather than only tuning\nto the test set distribution, we study robustness across different tuning\ndistributions, which is critical because for many applications the test\ndistribution may not be known during development. We find that algorithms\nexploit hidden biases, are unable to scale to multiple forms of bias, and are\nhighly sensitive to the choice of tuning set. Based on our findings, we implore\nthe community to adopt more rigorous assessment of future bias mitigation\nmethods. All data, code, and results are publicly available at:\nhttps://github.com/erobic/bias-mitigators.\n", "versions": [{"version": "v1", "created": "Thu, 1 Apr 2021 00:14:45 GMT"}], "update_date": "2021-04-02", "authors_parsed": [["Shrestha", "Robik", ""], ["Kafle", "Kushal", ""], ["Kanan", "Christopher", ""]]}, {"id": "2104.00186", "submitter": "Zixun Lan", "authors": "Zixun Lan, Limin Yu, Linglong Yuan, Zili Wu, Qiang Niu, Fei Ma", "title": "Sub-GMN: The Subgraph Matching Network Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As one of the most fundamental tasks in graph theory, subgraph matching is a\ncrucial task in many fields, ranging from information retrieval, computer\nvision, biology, chemistry and natural language processing. Yet subgraph\nmatching problem remains to be an NP-complete problem. This study proposes an\nend-to-end learning-based approximate method for subgraph matching task, called\nsubgraph matching network (Sub-GMN). The proposed Sub-GMN firstly uses graph\nrepresentation learning to map nodes to node-level embedding. It then combines\nmetric learning and attention mechanisms to model the relationship between\nmatched nodes in the data graph and query graph. To test the performance of the\nproposed method, we applied our method on two databases. We used two existing\nmethods, GNN and FGNN as baseline for comparison. Our experiment shows that, on\ndataset 1, on average the accuracy of Sub-GMN are 12.21\\% and 3.2\\% higher than\nthat of GNN and FGNN respectively. On average running time Sub-GMN runs 20-40\ntimes faster than FGNN. In addition, the average F1-score of Sub-GMN on all\nexperiments with dataset 2 reached 0.95, which demonstrates that Sub-GMN\noutputs more correct node-to-node matches.\n  Comparing with the previous GNNs-based methods for subgraph matching task,\nour proposed Sub-GMN allows varying query and data graphes in the\ntest/application stage, while most previous GNNs-based methods can only find a\nmatched subgraph in the data graph during the test/application for the same\nquery graph used in the training stage. Another advantage of our proposed\nSub-GMN is that it can output a list of node-to-node matches, while most\nexisting end-to-end GNNs based methods cannot provide the matched node pairs.\n", "versions": [{"version": "v1", "created": "Thu, 1 Apr 2021 01:31:40 GMT"}, {"version": "v2", "created": "Fri, 2 Apr 2021 11:52:02 GMT"}, {"version": "v3", "created": "Fri, 30 Apr 2021 07:01:32 GMT"}], "update_date": "2021-05-03", "authors_parsed": [["Lan", "Zixun", ""], ["Yu", "Limin", ""], ["Yuan", "Linglong", ""], ["Wu", "Zili", ""], ["Niu", "Qiang", ""], ["Ma", "Fei", ""]]}, {"id": "2104.00190", "submitter": "Wail Gueaieb", "authors": "Mohammed Abouheaf, Wail Gueaieb, Md. Suruz Miah, Davide Spinello", "title": "Trajectory Tracking of Underactuated Sea Vessels With Uncertain\n  Dynamics: An Integral Reinforcement Learning Approach", "comments": null, "journal-ref": "IEEE International Conference on Systems, Man, and Cybernetics\n  (SMC), Toronto, ON, Canada, 2020, pp. 1866-1871", "doi": "10.1109/SMC42975.2020.9283399", "report-no": null, "categories": "eess.SY cs.AI cs.LG cs.RO cs.SY", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Underactuated systems like sea vessels have degrees of motion that are\ninsufficiently matched by a set of independent actuation forces. In addition,\nthe underlying trajectory-tracking control problems grow in complexity in order\nto decide the optimal rudder and thrust control signals. This enforces several\ndifficult-to-solve constraints that are associated with the error dynamical\nequations using classical optimal tracking and adaptive control approaches. An\nonline machine learning mechanism based on integral reinforcement learning is\nproposed to find a solution for a class of nonlinear tracking problems with\npartial prior knowledge of the system dynamics. The actuation forces are\ndecided using innovative forms of temporal difference equations relevant to the\nvessel's surge and angular velocities. The solution is implemented using an\nonline value iteration process which is realized by employing means of the\nadaptive critics and gradient descent approaches. The adaptive learning\nmechanism exhibited well-functioning and interactive features in react to\ndifferent desired reference-tracking scenarios.\n", "versions": [{"version": "v1", "created": "Thu, 1 Apr 2021 01:41:49 GMT"}], "update_date": "2021-04-02", "authors_parsed": [["Abouheaf", "Mohammed", ""], ["Gueaieb", "Wail", ""], ["Miah", "Md. Suruz", ""], ["Spinello", "Davide", ""]]}, {"id": "2104.00199", "submitter": "Wail Gueaieb", "authors": "Ning Wang, Mohammed Abouheaf, Wail Gueaieb", "title": "Data-Driven Optimized Tracking Control Heuristic for MIMO Structures: A\n  Balance System Case Study", "comments": null, "journal-ref": "IEEE International Conference on Systems, Man, and Cybernetics\n  (SMC), Toronto, ON, Canada, 2020, pp. 2365-2370", "doi": "10.1109/SMC42975.2020.9283038", "report-no": null, "categories": "eess.SY cs.AI cs.LG cs.SY", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  A data-driven computational heuristic is proposed to control MIMO systems\nwithout prior knowledge of their dynamics. The heuristic is illustrated on a\ntwo-input two-output balance system. It integrates a self-adjusting nonlinear\nthreshold accepting heuristic with a neural network to compromise between the\ndesired transient and steady state characteristics of the system while\noptimizing a dynamic cost function. The heuristic decides on the control gains\nof multiple interacting PID control loops. The neural network is trained upon\noptimizing a weighted-derivative like objective cost function. The performance\nof the developed mechanism is compared with another controller that employs a\ncombined PID-Riccati approach. One of the salient features of the proposed\ncontrol schemes is that they do not require prior knowledge of the system\ndynamics. However, they depend on a known region of stability for the control\ngains to be used as a search space by the optimization algorithm. The control\nmechanism is validated using different optimization criteria which address\ndifferent design requirements.\n", "versions": [{"version": "v1", "created": "Thu, 1 Apr 2021 02:00:20 GMT"}], "update_date": "2021-04-02", "authors_parsed": [["Wang", "Ning", ""], ["Abouheaf", "Mohammed", ""], ["Gueaieb", "Wail", ""]]}, {"id": "2104.00219", "submitter": "Randall Balestriero", "authors": "Randall Balestriero, Richard Baraniuk", "title": "Fast Jacobian-Vector Product for Deep Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Jacobian-vector products (JVPs) form the backbone of many recent developments\nin Deep Networks (DNs), with applications including faster constrained\noptimization, regularization with generalization guarantees, and adversarial\nexample sensitivity assessments. Unfortunately, JVPs are computationally\nexpensive for real world DN architectures and require the use of automatic\ndifferentiation to avoid manually adapting the JVP program when changing the DN\narchitecture. We propose a novel method to quickly compute JVPs for any DN that\nemploy Continuous Piecewise Affine (e.g., leaky-ReLU, max-pooling, maxout,\netc.) nonlinearities. We show that our technique is on average $2\\times$ faster\nthan the fastest alternative over $13$ DN architectures and across various\nhardware. In addition, our solution does not require automatic differentiation\nand is thus easy to deploy in software, requiring only the modification of a\nfew lines of codes that do not depend on the DN architecture.\n", "versions": [{"version": "v1", "created": "Thu, 1 Apr 2021 03:04:40 GMT"}], "update_date": "2021-04-02", "authors_parsed": [["Balestriero", "Randall", ""], ["Baraniuk", "Richard", ""]]}, {"id": "2104.00222", "submitter": "Yujing Ma", "authors": "Qi Zhao, Yujing Ma, Shuchang Lyu, Lijiang Chen", "title": "Embedded Self-Distillation in Compact Multi-Branch Ensemble Network for\n  Remote Sensing Scene Classification", "comments": "14 pages,9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Remote sensing (RS) image scene classification task faces many challenges due\nto the interference from different characteristics of different geographical\nelements. To solve this problem, we propose a multi-branch ensemble network to\nenhance the feature representation ability by fusing features in final output\nlogits and intermediate feature maps. However, simply adding branches will\nincrease the complexity of models and decline the inference efficiency. On this\nissue, we embed self-distillation (SD) method to transfer knowledge from\nensemble network to main-branch in it. Through optimizing with SD, main-branch\nwill have close performance as ensemble network. During inference, we can cut\nother branches to simplify the whole model. In this paper, we first design\ncompact multi-branch ensemble network, which can be trained in an end-to-end\nmanner. Then, we insert SD method on output logits and feature maps. Compared\nto previous methods, our proposed architecture (ESD-MBENet) performs strongly\non classification accuracy with compact design. Extensive experiments are\napplied on three benchmark RS datasets AID, NWPU-RESISC45 and UC-Merced with\nthree classic baseline models, VGG16, ResNet50 and DenseNet121. Results prove\nthat our proposed ESD-MBENet can achieve better accuracy than previous\nstate-of-the-art (SOTA) complex models. Moreover, abundant visualization\nanalysis make our method more convincing and interpretable.\n", "versions": [{"version": "v1", "created": "Thu, 1 Apr 2021 03:08:52 GMT"}], "update_date": "2021-04-02", "authors_parsed": [["Zhao", "Qi", ""], ["Ma", "Yujing", ""], ["Lyu", "Shuchang", ""], ["Chen", "Lijiang", ""]]}, {"id": "2104.00237", "submitter": "Zixuan Jiang", "authors": "Zixuan Jiang, Jiaqi Gu, Mingjie Liu, Keren Zhu, David Z. Pan", "title": "Optimizer Fusion: Efficient Training with Better Locality and\n  Parallelism", "comments": "It is published as a paper at the Hardware Aware Efficient Training\n  (HAET) workshop of ICLR 2021. There are 4 pages excluding references and\n  appendices", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning frameworks adopt iterative optimizers to train neural\nnetworks. Conventional eager execution separates the updating of trainable\nparameters from forward and backward computations. However, this approach\nintroduces nontrivial training time overhead due to the lack of data locality\nand computation parallelism. In this work, we propose to fuse the optimizer\nwith forward or backward computation to better leverage locality and\nparallelism during training. By reordering the forward computation, gradient\ncalculation, and parameter updating, our proposed method improves the\nefficiency of iterative optimizers. Experimental results demonstrate that we\ncan achieve an up to 20% training time reduction on various configurations.\nSince our methods do not alter the optimizer algorithm, they can be used as a\ngeneral \"plug-in\" technique to the training process.\n", "versions": [{"version": "v1", "created": "Thu, 1 Apr 2021 03:44:13 GMT"}], "update_date": "2021-04-02", "authors_parsed": [["Jiang", "Zixuan", ""], ["Gu", "Jiaqi", ""], ["Liu", "Mingjie", ""], ["Zhu", "Keren", ""], ["Pan", "David Z.", ""]]}, {"id": "2104.00241", "submitter": "Ziyi Wang", "authors": "Ziyi Wang, Oswin So, Jason Gibson, Bogdan Vlahov, Manan S. Gandhi,\n  Guan-Horng Liu and Evangelos A. Theodorou", "title": "Variational Inference MPC using Tsallis Divergence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we provide a generalized framework for Variational\nInference-Stochastic Optimal Control by using thenon-extensive Tsallis\ndivergence. By incorporating the deformed exponential function into the\noptimality likelihood function, a novel Tsallis Variational Inference-Model\nPredictive Control algorithm is derived, which includes prior works such as\nVariational Inference-Model Predictive Control, Model Predictive PathIntegral\nControl, Cross Entropy Method, and Stein VariationalInference Model Predictive\nControl as special cases. The proposed algorithm allows for effective control\nof the cost/reward transform and is characterized by superior performance in\nterms of mean and variance reduction of the associated cost. The aforementioned\nfeatures are supported by a theoretical and numerical analysis on the level of\nrisk sensitivity of the proposed algorithm as well as simulation experiments on\n5 different robotic systems with 3 different policy parameterizations.\n", "versions": [{"version": "v1", "created": "Thu, 1 Apr 2021 04:00:49 GMT"}], "update_date": "2021-04-02", "authors_parsed": [["Wang", "Ziyi", ""], ["So", "Oswin", ""], ["Gibson", "Jason", ""], ["Vlahov", "Bogdan", ""], ["Gandhi", "Manan S.", ""], ["Liu", "Guan-Horng", ""], ["Theodorou", "Evangelos A.", ""]]}, {"id": "2104.00245", "submitter": "Zhe Zhang", "authors": "Zhe Zhang and Linjun Zhang", "title": "High-Dimensional Differentially-Private EM Algorithm: Methods and\n  Near-Optimal Statistical Guarantees", "comments": "45 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CR cs.LG math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we develop a general framework to design differentially\nprivate expectation-maximization (EM) algorithms in high-dimensional latent\nvariable models, based on the noisy iterative hard-thresholding. We derive the\nstatistical guarantees of the proposed framework and apply it to three specific\nmodels: Gaussian mixture, mixture of regression, and regression with missing\ncovariates. In each model, we establish the near-optimal rate of convergence\nwith differential privacy constraints, and show the proposed algorithm is\nminimax rate optimal up to logarithm factors. The technical tools developed for\nthe high-dimensional setting are then extended to the classic low-dimensional\nlatent variable models, and we propose a near rate-optimal EM algorithm with\ndifferential privacy guarantees in this setting. Simulation studies and real\ndata analysis are conducted to support our results.\n", "versions": [{"version": "v1", "created": "Thu, 1 Apr 2021 04:08:34 GMT"}], "update_date": "2021-04-02", "authors_parsed": [["Zhang", "Zhe", ""], ["Zhang", "Linjun", ""]]}, {"id": "2104.00249", "submitter": "Seong Hyeon Park", "authors": "ByeoungDo Kim, Seong Hyeon Park, Seokhwan Lee, Elbek Khoshimjonov,\n  Dongsuk Kum, Junsoo Kim, Jeong Soo Kim, Jun Won Choi", "title": "LaPred: Lane-Aware Prediction of Multi-Modal Future Trajectories of\n  Dynamic Agents", "comments": "13 pages, 2 figures, 7 tables, CVPR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we address the problem of predicting the future motion of a\ndynamic agent (called a target agent) given its current and past states as well\nas the information on its environment. It is paramount to develop a prediction\nmodel that can exploit the contextual information in both static and dynamic\nenvironments surrounding the target agent and generate diverse trajectory\nsamples that are meaningful in a traffic context. We propose a novel prediction\nmodel, referred to as the lane-aware prediction (LaPred) network, which uses\nthe instance-level lane entities extracted from a semantic map to predict the\nmulti-modal future trajectories. For each lane candidate found in the\nneighborhood of the target agent, LaPred extracts the joint features relating\nthe lane and the trajectories of the neighboring agents. Then, the features for\nall lane candidates are fused with the attention weights learned through a\nself-supervised learning task that identifies the lane candidate likely to be\nfollowed by the target agent. Using the instance-level lane information, LaPred\ncan produce the trajectories compliant with the surroundings better than 2D\nraster image-based methods and generate the diverse future trajectories given\nmultiple lane candidates. The experiments conducted on the public nuScenes\ndataset and Argoverse dataset demonstrate that the proposed LaPred method\nsignificantly outperforms the existing prediction models, achieving\nstate-of-the-art performance in the benchmarks.\n", "versions": [{"version": "v1", "created": "Thu, 1 Apr 2021 04:33:36 GMT"}], "update_date": "2021-04-02", "authors_parsed": [["Kim", "ByeoungDo", ""], ["Park", "Seong Hyeon", ""], ["Lee", "Seokhwan", ""], ["Khoshimjonov", "Elbek", ""], ["Kum", "Dongsuk", ""], ["Kim", "Junsoo", ""], ["Kim", "Jeong Soo", ""], ["Choi", "Jun Won", ""]]}, {"id": "2104.00253", "submitter": "Yi Wang", "authors": "Yunhao Yang, Yuhan Zheng, Yi Wang and Chandrajit Bajaj", "title": "Learning Deep Latent Subspaces for Image Denoising", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Heterogeneity exists in most camera images. This heterogeneity manifests\nitself across the image space as varied Moire ringing, motion-blur,\ncolor-bleaching or lens based projection distortions. Moreover, combinations of\nthese image artifacts can be present in small or large pixel neighborhoods,\nwithin an acquired image. Current camera image processing pipelines, including\ndeep trained versions, tend to rectify the issue applying a single filter that\nis homogeneously applied to the entire image. This is also particularly true\nwhen an encoder-decoder type deep architecture is trained for the task. In this\npaper, we present a structured deep learning model that solves the\nheterogeneous image artifact filtering problem. We call our deep trained model\nthe Patch Subspace Variational Autoencoder (PS-VAE) for Camera ISP. PS-VAE does\nnot necessarily assume uniform image distortion levels nor similar artifact\ntypes within the image. Rather, our model attempts to learn to cluster\ndifferent patches extracted from images into artifact type and distortion\nlevels, within multiple latent subspaces (e.g. Moire ringing artifacts are\noften a higher dimensional latent distortion than a Gaussian motion blur\nartifact). Each image's patches are encoded into soft-clusters in their\nappropriate latent sub-space, using a prior mixture model. The decoders of the\nPS-VAE are also trained in an unsupervised manner for each of the image patches\nin each soft-cluster. Our experimental results demonstrates the flexibility and\nperformance that one can achieve through improved heterogeneous filtering. We\ncompare our results to a conventional one-encoder-one-decoder architecture.\n", "versions": [{"version": "v1", "created": "Thu, 1 Apr 2021 04:40:22 GMT"}, {"version": "v2", "created": "Thu, 22 Apr 2021 14:29:47 GMT"}], "update_date": "2021-04-23", "authors_parsed": [["Yang", "Yunhao", ""], ["Zheng", "Yuhan", ""], ["Wang", "Yi", ""], ["Bajaj", "Chandrajit", ""]]}, {"id": "2104.00254", "submitter": "Zachary DeVito", "authors": "Zachary DeVito, Jason Ansel, Will Constable, Michael Suo, Ailing\n  Zhang, Kim Hazelwood", "title": "Using Python for Model Inference in Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Python has become the de-facto language for training deep neural networks,\ncoupling a large suite of scientific computing libraries with efficient\nlibraries for tensor computation such as PyTorch or TensorFlow. However, when\nmodels are used for inference they are typically extracted from Python as\nTensorFlow graphs or TorchScript programs in order to meet performance and\npackaging constraints. The extraction process can be time consuming, impeding\nfast prototyping. We show how it is possible to meet these performance and\npackaging constraints while performing inference in Python. In particular, we\npresent a way of using multiple Python interpreters within a single process to\nachieve scalable inference and describe a new container format for models that\ncontains both native Python code and data. This approach simplifies the model\ndeployment story by eliminating the model extraction step, and makes it easier\nto integrate existing performance-enhancing Python libraries. We evaluate our\ndesign on a suite of popular PyTorch models on Github, showing how they can be\npackaged in our inference format, and comparing their performance to\nTorchScript. For larger models, our packaged Python models perform the same as\nTorchScript, and for smaller models where there is some Python overhead, our\nmulti-interpreter approach ensures inference is still scalable.\n", "versions": [{"version": "v1", "created": "Thu, 1 Apr 2021 04:48:52 GMT"}], "update_date": "2021-04-02", "authors_parsed": [["DeVito", "Zachary", ""], ["Ansel", "Jason", ""], ["Constable", "Will", ""], ["Suo", "Michael", ""], ["Zhang", "Ailing", ""], ["Hazelwood", "Kim", ""]]}, {"id": "2104.00258", "submitter": "Jiansong Li", "authors": "Jiansong Li, Xiao Dong, Guangli Li, Peng Zhao, Xueying Wang, Xiaobing\n  Chen, Xianzhi Yu, Yongxin Yang, Zihan Jiang, Wei Cao, Lei Liu, Xiaobing Feng", "title": "Pinpointing the Memory Behaviors of DNN Training", "comments": "Submitted to ISPASS'21 poster", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The training of deep neural networks (DNNs) is usually memory-hungry due to\nthe limited device memory capacity of DNN accelerators. Characterizing the\nmemory behaviors of DNN training is critical to optimize the device memory\npressures. In this work, we pinpoint the memory behaviors of each device memory\nblock of GPU during training by instrumenting the memory allocators of the\nruntime system. Our results show that the memory access patterns of device\nmemory blocks are stable and follow an iterative fashion. These observations\nare useful for the future optimization of memory-efficient training from the\nperspective of raw memory access patterns.\n", "versions": [{"version": "v1", "created": "Thu, 1 Apr 2021 05:30:03 GMT"}], "update_date": "2021-04-02", "authors_parsed": [["Li", "Jiansong", ""], ["Dong", "Xiao", ""], ["Li", "Guangli", ""], ["Zhao", "Peng", ""], ["Wang", "Xueying", ""], ["Chen", "Xiaobing", ""], ["Yu", "Xianzhi", ""], ["Yang", "Yongxin", ""], ["Jiang", "Zihan", ""], ["Cao", "Wei", ""], ["Liu", "Lei", ""], ["Feng", "Xiaobing", ""]]}, {"id": "2104.00267", "submitter": "Prabhakar Gupta", "authors": "Prabhakar Gupta, Ridha Juneja, Anil Nelakanti, Tamojit Chatterjee", "title": "Detecting over/under-translation errors for determining adequacy in\n  human translations", "comments": "6 pages, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present a novel approach to detecting over and under translations (OT/UT)\nas part of adequacy error checks in translation evaluation. We do not restrict\nourselves to machine translation (MT) outputs and specifically target\napplications with human generated translation pipeline. The goal of our system\nis to identify OT/UT errors from human translated video subtitles with high\nerror recall. We achieve this without reference translations by learning a\nmodel on synthesized training data. We compare various classification networks\nthat we trained on embeddings from pre-trained language model with our best\nhybrid network of GRU + CNN achieving 89.3% accuracy on high-quality\nhuman-annotated evaluation data in 8 languages.\n", "versions": [{"version": "v1", "created": "Thu, 1 Apr 2021 06:06:36 GMT"}], "update_date": "2021-04-02", "authors_parsed": [["Gupta", "Prabhakar", ""], ["Juneja", "Ridha", ""], ["Nelakanti", "Anil", ""], ["Chatterjee", "Tamojit", ""]]}, {"id": "2104.00269", "submitter": "Adrian Barbu", "authors": "Adrian Barbu, Hongyu Mou", "title": "The Compact Support Neural Network", "comments": "8 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Neural networks are popular and useful in many fields, but they have the\nproblem of giving high confidence responses for examples that are away from the\ntraining data. This makes the neural networks very confident in their\nprediction while making gross mistakes, thus limiting their reliability for\nsafety-critical applications such as autonomous driving, space exploration,\netc. In this paper, we present a neuron generalization that has the standard\ndot-product-based neuron and the RBF neuron as two extreme cases of a shape\nparameter. Using ReLU as the activation function we obtain a novel neuron that\nhas compact support, which means its output is zero outside a bounded domain.\nWe show how to avoid difficulties in training a neural network with such\nneurons, by starting with a trained standard neural network and gradually\nincreasing the shape parameter to the desired value. Through experiments on\nstandard benchmark datasets, we show the promise of the proposed approach, in\nthat it can have good prediction accuracy on in-distribution samples while\nbeing able to consistently detect and have low confidence on\nout-of-distribution samples.\n", "versions": [{"version": "v1", "created": "Thu, 1 Apr 2021 06:08:09 GMT"}], "update_date": "2021-04-02", "authors_parsed": [["Barbu", "Adrian", ""], ["Mou", "Hongyu", ""]]}, {"id": "2104.00277", "submitter": "Adrian Riekert", "authors": "Arnulf Jentzen, Adrian Riekert", "title": "A proof of convergence for stochastic gradient descent in the training\n  of artificial neural networks with ReLU activation for constant target\n  functions", "comments": "29 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.LG cs.NA math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article we study the stochastic gradient descent (SGD) optimization\nmethod in the training of fully-connected feedforward artificial neural\nnetworks with ReLU activation. The main result of this work proves that the\nrisk of the SGD process converges to zero if the target function under\nconsideration is constant. In the established convergence result the considered\nartificial neural networks consist of one input layer, one hidden layer, and\none output layer (with $d \\in \\mathbb{N}$ neurons on the input layer, $H \\in\n\\mathbb{N}$ neurons on the hidden layer, and one neuron on the output layer).\nThe learning rates of the SGD process are assumed to be sufficiently small and\nthe input data used in the SGD process to train the artificial neural networks\nis assumed to be independent and identically distributed.\n", "versions": [{"version": "v1", "created": "Thu, 1 Apr 2021 06:28:30 GMT"}], "update_date": "2021-04-02", "authors_parsed": [["Jentzen", "Arnulf", ""], ["Riekert", "Adrian", ""]]}, {"id": "2104.00290", "submitter": "Thamme Gowda", "authors": "Thamme Gowda, Zhao Zhang, Chris A Mattmann, Jonathan May", "title": "Many-to-English Machine Translation Tools, Data, and Pretrained Models", "comments": "To-appear: ACL 2021 System Demonstrations", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  While there are more than 7000 languages in the world, most translation\nresearch efforts have targeted a few high-resource languages. Commercial\ntranslation systems support only one hundred languages or fewer, and do not\nmake these models available for transfer to low resource languages. In this\nwork, we present useful tools for machine translation research: MTData,\nNLCodec, and RTG. We demonstrate their usefulness by creating a multilingual\nneural machine translation model capable of translating from 500 source\nlanguages to English. We make this multilingual model readily downloadable and\nusable as a service, or as a parent model for transfer-learning to even\nlower-resource languages.\n", "versions": [{"version": "v1", "created": "Thu, 1 Apr 2021 06:55:12 GMT"}, {"version": "v2", "created": "Thu, 1 Jul 2021 19:40:00 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Gowda", "Thamme", ""], ["Zhang", "Zhao", ""], ["Mattmann", "Chris A", ""], ["May", "Jonathan", ""]]}, {"id": "2104.00299", "submitter": "Hojung Lee", "authors": "Hojung Lee, Jong-Seok Lee", "title": "Students are the Best Teacher: Exit-Ensemble Distillation with\n  Multi-Exits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper proposes a novel knowledge distillation-based learning method to\nimprove the classification performance of convolutional neural networks (CNNs)\nwithout a pre-trained teacher network, called exit-ensemble distillation. Our\nmethod exploits the multi-exit architecture that adds auxiliary classifiers\n(called exits) in the middle of a conventional CNN, through which early\ninference results can be obtained. The idea of our method is to train the\nnetwork using the ensemble of the exits as the distillation target, which\ngreatly improves the classification performance of the overall network. Our\nmethod suggests a new paradigm of knowledge distillation; unlike the\nconventional notion of distillation where teachers only teach students, we show\nthat students can also help other students and even the teacher to learn\nbetter. Experimental results demonstrate that our method achieves significant\nimprovement of classification performance on various popular CNN architectures\n(VGG, ResNet, ResNeXt, WideResNet, etc.). Furthermore, the proposed method can\nexpedite the convergence of learning with improved stability. Our code will be\navailable on Github.\n", "versions": [{"version": "v1", "created": "Thu, 1 Apr 2021 07:10:36 GMT"}, {"version": "v2", "created": "Mon, 5 Apr 2021 01:13:20 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Lee", "Hojung", ""], ["Lee", "Jong-Seok", ""]]}, {"id": "2104.00303", "submitter": "Jennifer Jang", "authors": "Jennifer Jang, Heinrich Jiang", "title": "MeanShift++: Extremely Fast Mode-Seeking With Applications to\n  Segmentation and Object Tracking", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  MeanShift is a popular mode-seeking clustering algorithm used in a wide range\nof applications in machine learning. However, it is known to be prohibitively\nslow, with quadratic runtime per iteration. We propose MeanShift++, an\nextremely fast mode-seeking algorithm based on MeanShift that uses a grid-based\napproach to speed up the mean shift step, replacing the computationally\nexpensive neighbors search with a density-weighted mean of adjacent grid cells.\nIn addition, we show that this grid-based technique for density estimation\ncomes with theoretical guarantees. The runtime is linear in the number of\npoints and exponential in dimension, which makes MeanShift++ ideal on\nlow-dimensional applications such as image segmentation and object tracking. We\nprovide extensive experimental analysis showing that MeanShift++ can be more\nthan 10,000x faster than MeanShift with competitive clustering results on\nbenchmark datasets and nearly identical image segmentations as MeanShift.\nFinally, we show promising results for object tracking.\n", "versions": [{"version": "v1", "created": "Thu, 1 Apr 2021 07:14:11 GMT"}], "update_date": "2021-04-02", "authors_parsed": [["Jang", "Jennifer", ""], ["Jiang", "Heinrich", ""]]}, {"id": "2104.00322", "submitter": "Matan Levi", "authors": "Matan Levi, Idan Attias, Aryeh Kontorovich", "title": "Domain Invariant Adversarial Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The phenomenon of adversarial examples illustrates one of the most basic\nvulnerabilities of deep neural networks. Among the variety of techniques\nintroduced to surmount this inherent weakness, adversarial training has emerged\nas the most common and efficient strategy to achieve robustness. Typically,\nthis is achieved by balancing robust and natural objectives. In this work, we\naim to achieve better trade-off between robust and natural performances by\nenforcing a domain-invariant feature representation. We present a new\nadversarial training method, Domain Invariant Adversarial Learning (DIAL),\nwhich learns a feature representation which is both robust and domain\ninvariant. DIAL uses a variant of Domain Adversarial Neural Network (DANN) on\nthe natural domain and its corresponding adversarial domain. In a case where\nthe source domain consists of natural examples and the target domain is the\nadversarially perturbed examples, our method learns a feature representation\nconstrained not to discriminate between the natural and adversarial examples,\nand can therefore achieve a more robust representation. Our experiments\nindicate that our method improves both robustness and natural accuracy, when\ncompared to current state-of-the-art adversarial training methods.\n", "versions": [{"version": "v1", "created": "Thu, 1 Apr 2021 08:04:10 GMT"}, {"version": "v2", "created": "Sun, 20 Jun 2021 14:23:20 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Levi", "Matan", ""], ["Attias", "Idan", ""], ["Kontorovich", "Aryeh", ""]]}, {"id": "2104.00331", "submitter": "Francesco Pase", "authors": "Francesco Pase, Marco Giordani, Michele Zorzi", "title": "On the Convergence Time of Federated Learning Over Wireless Networks\n  Under Imperfect CSI", "comments": "IEEE International Conference on Communications Workshops (ICC\n  WKSHPS), Virtual/Montreal, Canada, 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning (FL) has recently emerged as an attractive decentralized\nsolution for wireless networks to collaboratively train a shared model while\nkeeping data localized. As a general approach, existing FL methods tend to\nassume perfect knowledge of the Channel State Information (CSI) during the\ntraining phase, which may not be easy to acquire in case of fast fading\nchannels. Moreover, literature analyses either consider a fixed number of\nclients participating in the training of the federated model, or simply assume\nthat all clients operate at the maximum achievable rate to transmit model data.\nIn this paper, we fill these gaps by proposing a training process that takes\nchannel statistics as a bias to minimize the convergence time under imperfect\nCSI. Numerical experiments demonstrate that it is possible to reduce the\ntraining time by neglecting model updates from clients that cannot sustain a\nminimum predefined transmission rate. We also examine the trade-off between\nnumber of clients involved in the training process and model accuracy as a\nfunction of different fading regimes.\n", "versions": [{"version": "v1", "created": "Thu, 1 Apr 2021 08:30:45 GMT"}], "update_date": "2021-04-02", "authors_parsed": [["Pase", "Francesco", ""], ["Giordani", "Marco", ""], ["Zorzi", "Michele", ""]]}, {"id": "2104.00341", "submitter": "Tanmay Chakraborty", "authors": "Tanmay Chakraborty and Utkarsh Trehan", "title": "SpectralNET: Exploring Spatial-Spectral WaveletCNN for Hyperspectral\n  Image Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Hyperspectral Image (HSI) classification using Convolutional Neural Networks\n(CNN) is widely found in the current literature. Approaches vary from using\nSVMs to 2D CNNs, 3D CNNs, 3D-2D CNNs. Besides 3D-2D CNNs and FuSENet, the other\napproaches do not consider both the spectral and spatial features together for\nHSI classification task, thereby resulting in poor performances. 3D CNNs are\ncomputationally heavy and are not widely used, while 2D CNNs do not consider\nmulti-resolution processing of images, and only limits itself to the spatial\nfeatures. Even though 3D-2D CNNs try to model the spectral and spatial features\ntheir performance seems limited when applied over multiple dataset. In this\narticle, we propose SpectralNET, a wavelet CNN, which is a variation of 2D CNN\nfor multi-resolution HSI classification. A wavelet CNN uses layers of wavelet\ntransform to bring out spectral features. Computing a wavelet transform is\nlighter than computing 3D CNN. The spectral features extracted are then\nconnected to the 2D CNN which bring out the spatial features, thereby creating\na spatial-spectral feature vector for classification. Overall a better model is\nachieved that can classify multi-resolution HSI data with high accuracy.\nExperiments performed with SpectralNET on benchmark dataset, i.e. Indian Pines,\nUniversity of Pavia, and Salinas Scenes confirm the superiority of proposed\nSpectralNET with respect to the state-of-the-art methods. The code is publicly\navailable in https://github.com/tanmay-ty/SpectralNET.\n", "versions": [{"version": "v1", "created": "Thu, 1 Apr 2021 08:45:15 GMT"}], "update_date": "2021-04-02", "authors_parsed": [["Chakraborty", "Tanmay", ""], ["Trehan", "Utkarsh", ""]]}, {"id": "2104.00352", "submitter": "Akihito Taya", "authors": "Akihito Taya, Takayuki Nishio, Masahiro Morikura, Koji Yamamoto", "title": "Decentralized and Model-Free Federated Learning: Consensus-Based\n  Distillation in Function Space", "comments": "submitted to IEEE TSIPN", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a decentralized FL scheme for IoE devices connected via\nmulti-hop networks. FL has gained attention as an enabler of privacy-preserving\nalgorithms, but it is not guaranteed that FL algorithms converge to the optimal\npoint because of non-convexity when using decentralized parameter averaging\nschemes. Therefore, a distributed algorithm that converges to the optimal\nsolution should be developed. The key idea of the proposed algorithm is to\naggregate the local prediction functions, not in a parameter space but in a\nfunction space. Since machine learning tasks can be regarded as convex\nfunctional optimization problems, a consensus-based optimization algorithm\nachieves the global optimum if it is tailored to work in a function space. This\npaper at first analyzes the convergence of the proposed algorithm in a function\nspace, which is referred to as a meta-algorithm. It is shown that spectral\ngraph theory can be applied to the function space in a similar manner as that\nof numerical vectors. Then, a CMFD is developed for NN as an implementation of\nthe meta-algorithm. CMFD leverages knowledge distillation to realize function\naggregation among adjacent devices without parameter averaging. One of the\nadvantages of CMFD is that it works even when NN models are different among the\ndistributed learners. This paper shows that CMFD achieves higher accuracy than\nparameter aggregation under weakly-connected networks. The stability of CMFD is\nalso higher than that of parameter aggregation methods.\n", "versions": [{"version": "v1", "created": "Thu, 1 Apr 2021 09:17:20 GMT"}, {"version": "v2", "created": "Fri, 2 Apr 2021 09:32:12 GMT"}], "update_date": "2021-04-05", "authors_parsed": [["Taya", "Akihito", ""], ["Nishio", "Takayuki", ""], ["Morikura", "Masahiro", ""], ["Yamamoto", "Koji", ""]]}, {"id": "2104.00353", "submitter": "Cesare Campagnano", "authors": "Giorgio Barnab\\`o, Giovanni Trappolini, Lorenzo Lastilla, Cesare\n  Campagnano, Angela Fan, Fabio Petroni and Fabrizio Silvestri", "title": "CycleDRUMS: Automatic Drum Arrangement For Bass Lines Using CycleGAN", "comments": "9 pages, 5 figures, submitted to IEEE Transactions on Multimedia, the\n  authors contributed equally to this work", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The two main research threads in computer-based music generation are: the\nconstruction of autonomous music-making systems, and the design of\ncomputer-based environments to assist musicians. In the symbolic domain, the\nkey problem of automatically arranging a piece music was extensively studied,\nwhile relatively fewer systems tackled this challenge in the audio domain. In\nthis contribution, we propose CycleDRUMS, a novel method for generating drums\ngiven a bass line. After converting the waveform of the bass into a\nmel-spectrogram, we are able to automatically generate original drums that\nfollow the beat, sound credible and can be directly mixed with the input bass.\nWe formulated this task as an unpaired image-to-image translation problem, and\nwe addressed it with CycleGAN, a well-established unsupervised style transfer\nframework, originally designed for treating images. The choice to deploy raw\naudio and mel-spectrograms enabled us to better represent how humans perceive\nmusic, and to potentially draw sounds for new arrangements from the vast\ncollection of music recordings accumulated in the last century. In absence of\nan objective way of evaluating the output of both generative adversarial\nnetworks and music generative systems, we further defined a possible metric for\nthe proposed task, partially based on human (and expert) judgement. Finally, as\na comparison, we replicated our results with Pix2Pix, a paired image-to-image\ntranslation network, and we showed that our approach outperforms it.\n", "versions": [{"version": "v1", "created": "Thu, 1 Apr 2021 09:17:48 GMT"}, {"version": "v2", "created": "Fri, 9 Apr 2021 10:43:12 GMT"}], "update_date": "2021-04-12", "authors_parsed": [["Barnab\u00f2", "Giorgio", ""], ["Trappolini", "Giovanni", ""], ["Lastilla", "Lorenzo", ""], ["Campagnano", "Cesare", ""], ["Fan", "Angela", ""], ["Petroni", "Fabio", ""], ["Silvestri", "Fabrizio", ""]]}, {"id": "2104.00355", "submitter": "Yossi Adi", "authors": "Adam Polyak, Yossi Adi, Jade Copet, Eugene Kharitonov, Kushal\n  Lakhotia, Wei-Ning Hsu, Abdelrahman Mohamed, Emmanuel Dupoux", "title": "Speech Resynthesis from Discrete Disentangled Self-Supervised\n  Representations", "comments": "In Proceedings of Interspeech 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose using self-supervised discrete representations for the task of\nspeech resynthesis. To generate disentangled representation, we separately\nextract low-bitrate representations for speech content, prosodic information,\nand speaker identity. This allows to synthesize speech in a controllable\nmanner. We analyze various state-of-the-art, self-supervised representation\nlearning methods and shed light on the advantages of each method while\nconsidering reconstruction quality and disentanglement properties.\nSpecifically, we evaluate the F0 reconstruction, speaker identification\nperformance (for both resynthesis and voice conversion), recordings'\nintelligibility, and overall quality using subjective human evaluation. Lastly,\nwe demonstrate how these representations can be used for an ultra-lightweight\nspeech codec. Using the obtained representations, we can get to a rate of 365\nbits per second while providing better speech quality than the baseline\nmethods. Audio samples can be found under the following link:\nspeechbot.github.io/resynthesis.\n", "versions": [{"version": "v1", "created": "Thu, 1 Apr 2021 09:20:33 GMT"}, {"version": "v2", "created": "Fri, 2 Apr 2021 09:48:31 GMT"}, {"version": "v3", "created": "Tue, 27 Jul 2021 14:27:27 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Polyak", "Adam", ""], ["Adi", "Yossi", ""], ["Copet", "Jade", ""], ["Kharitonov", "Eugene", ""], ["Lakhotia", "Kushal", ""], ["Hsu", "Wei-Ning", ""], ["Mohamed", "Abdelrahman", ""], ["Dupoux", "Emmanuel", ""]]}, {"id": "2104.00365", "submitter": "Chenyou Fan", "authors": "Chenyou Fan and Jianwei Huang", "title": "Federated Few-Shot Learning with Adversarial Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We are interested in developing a unified machine learning model over many\nmobile devices for practical learning tasks, where each device only has very\nfew training data. This is a commonly encountered situation in mobile computing\nscenarios, where data is scarce and distributed while the tasks are distinct.\nIn this paper, we propose a federated few-shot learning (FedFSL) framework to\nlearn a few-shot classification model that can classify unseen data classes\nwith only a few labeled samples. With the federated learning strategy, FedFSL\ncan utilize many data sources while keeping data privacy and communication\nefficiency. There are two technical challenges: 1) directly using the existing\nfederated learning approach may lead to misaligned decision boundaries produced\nby client models, and 2) constraining the decision boundaries to be similar\nover clients would overfit to training tasks but not adapt well to unseen\ntasks. To address these issues, we propose to regularize local updates by\nminimizing the divergence of client models. We also formulate the training in\nan adversarial fashion and optimize the client models to produce a\ndiscriminative feature space that can better represent unseen data samples. We\ndemonstrate the intuitions and conduct experiments to show our approaches\noutperform baselines by more than 10% in learning vision tasks and 5% in\nlanguage tasks.\n", "versions": [{"version": "v1", "created": "Thu, 1 Apr 2021 09:44:57 GMT"}], "update_date": "2021-04-02", "authors_parsed": [["Fan", "Chenyou", ""], ["Huang", "Jianwei", ""]]}, {"id": "2104.00366", "submitter": "Evander Nyoni", "authors": "Evander Nyoni and Bruce A. Bassett", "title": "Low-Resource Neural Machine Translation for Southern African Languages", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Low-resource African languages have not fully benefited from the progress in\nneural machine translation because of a lack of data. Motivated by this\nchallenge we compare zero-shot learning, transfer learning and multilingual\nlearning on three Bantu languages (Shona, isiXhosa and isiZulu) and English.\nOur main target is English-to-isiZulu translation for which we have just 30,000\nsentence pairs, 28% of the average size of our other corpora. We show the\nimportance of language similarity on the performance of English-to-isiZulu\ntransfer learning based on English-to-isiXhosa and English-to-Shona parent\nmodels whose BLEU scores differ by 5.2. We then demonstrate that multilingual\nlearning surpasses both transfer learning and zero-shot learning on our\ndataset, with BLEU score improvements relative to the baseline\nEnglish-to-isiZulu model of 9.9, 6.1 and 2.0 respectively. Our best model also\nimproves the previous SOTA BLEU score by more than 10.\n", "versions": [{"version": "v1", "created": "Thu, 1 Apr 2021 09:48:13 GMT"}, {"version": "v2", "created": "Sat, 3 Apr 2021 18:49:49 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Nyoni", "Evander", ""], ["Bassett", "Bruce A.", ""]]}, {"id": "2104.00385", "submitter": "Taisuke Kobayashi", "authors": "Taisuke Kobayashi, Kenta Yoshizawa", "title": "Optimization Algorithm for Feedback and Feedforward Policies towards\n  Robot Control Robust to Sensing Failures", "comments": "23 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model-free or learning-based control, in particular, reinforcement learning\n(RL), is expected to be applied for complex robotic tasks. Traditional RL\nrequires a policy to be optimized is state-dependent, that means, the policy is\na kind of feedback (FB) controllers. Due to the necessity of correct state\nobservation in such a FB controller, it is sensitive to sensing failures. To\nalleviate this drawback of the FB controllers, feedback error learning\nintegrates one of them with a feedforward (FF) controller. RL can be improved\nby dealing with the FB/FF policies, but to the best of our knowledge, a\nmethodology for learning them in a unified manner has not been developed. In\nthis paper, we propose a new optimization problem for optimizing both the FB/FF\npolicies simultaneously. Inspired by control as inference, the optimization\nproblem considers minimization/maximization of divergences between trajectory,\npredicted by the composed policy and a stochastic dynamics model, and\noptimal/non-optimal trajectories. By approximating the stochastic dynamics\nmodel using variational method, we naturally derive a regularization between\nthe FB/FF policies. In numerical simulations and a robot experiment, we\nverified that the proposed method can stably optimize the composed policy even\nwith the different learning law from the traditional RL. In addition, we\ndemonstrated that the FF policy is robust to the sensing failures and can hold\nthe optimal motion. Attached video is also uploaded on youtube:\nhttps://youtu.be/zLL4uXIRmrE\n", "versions": [{"version": "v1", "created": "Thu, 1 Apr 2021 10:41:42 GMT"}], "update_date": "2021-04-02", "authors_parsed": [["Kobayashi", "Taisuke", ""], ["Yoshizawa", "Kenta", ""]]}, {"id": "2104.00399", "submitter": "Mohammadreza Doostmohammadian", "authors": "Mohammadreza Doostmohammadian, Alireza Aghasi, Themistoklis\n  Charalambous, and Usman A. Khan", "title": "Distributed support-vector-machine over dynamic balanced directed\n  networks", "comments": "submitted to CDC21", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.LG cs.SI cs.SY eess.SP math.OC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we consider the binary classification problem via distributed\nSupport-Vector-Machines (SVM), where the idea is to train a network of agents,\nwith limited share of data, to cooperatively learn the SVM classifier for the\nglobal database. Agents only share processed information regarding the\nclassifier parameters and the gradient of the local loss functions instead of\ntheir raw data. In contrast to the existing work, we propose a continuous-time\nalgorithm that incorporates network topology changes in discrete jumps. This\nhybrid nature allows us to remove chattering that arises because of the\ndiscretization of the underlying CT process. We show that the proposed\nalgorithm converges to the SVM classifier over time-varying weight balanced\ndirected graphs by using arguments from the matrix perturbation theory.\n", "versions": [{"version": "v1", "created": "Thu, 1 Apr 2021 11:02:10 GMT"}], "update_date": "2021-04-02", "authors_parsed": [["Doostmohammadian", "Mohammadreza", ""], ["Aghasi", "Alireza", ""], ["Charalambous", "Themistoklis", ""], ["Khan", "Usman A.", ""]]}, {"id": "2104.00405", "submitter": "Vincenzo Lomonaco PhD", "authors": "Vincenzo Lomonaco, Lorenzo Pellegrini, Andrea Cossu, Antonio Carta,\n  Gabriele Graffieti, Tyler L. Hayes, Matthias De Lange, Marc Masana, Jary\n  Pomponi, Gido van de Ven, Martin Mundt, Qi She, Keiland Cooper, Jeremy\n  Forest, Eden Belouadah, Simone Calderara, German I. Parisi, Fabio Cuzzolin,\n  Andreas Tolias, Simone Scardapane, Luca Antiga, Subutai Amhad, Adrian\n  Popescu, Christopher Kanan, Joost van de Weijer, Tinne Tuytelaars, Davide\n  Bacciu, Davide Maltoni", "title": "Avalanche: an End-to-End Library for Continual Learning", "comments": "Official Website: https://avalanche.continualai.org", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning continually from non-stationary data streams is a long-standing goal\nand a challenging problem in machine learning. Recently, we have witnessed a\nrenewed and fast-growing interest in continual learning, especially within the\ndeep learning community. However, algorithmic solutions are often difficult to\nre-implement, evaluate and port across different settings, where even results\non standard benchmarks are hard to reproduce. In this work, we propose\nAvalanche, an open-source end-to-end library for continual learning research\nbased on PyTorch. Avalanche is designed to provide a shared and collaborative\ncodebase for fast prototyping, training, and reproducible evaluation of\ncontinual learning algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 1 Apr 2021 11:31:46 GMT"}], "update_date": "2021-04-02", "authors_parsed": [["Lomonaco", "Vincenzo", ""], ["Pellegrini", "Lorenzo", ""], ["Cossu", "Andrea", ""], ["Carta", "Antonio", ""], ["Graffieti", "Gabriele", ""], ["Hayes", "Tyler L.", ""], ["De Lange", "Matthias", ""], ["Masana", "Marc", ""], ["Pomponi", "Jary", ""], ["van de Ven", "Gido", ""], ["Mundt", "Martin", ""], ["She", "Qi", ""], ["Cooper", "Keiland", ""], ["Forest", "Jeremy", ""], ["Belouadah", "Eden", ""], ["Calderara", "Simone", ""], ["Parisi", "German I.", ""], ["Cuzzolin", "Fabio", ""], ["Tolias", "Andreas", ""], ["Scardapane", "Simone", ""], ["Antiga", "Luca", ""], ["Amhad", "Subutai", ""], ["Popescu", "Adrian", ""], ["Kanan", "Christopher", ""], ["van de Weijer", "Joost", ""], ["Tuytelaars", "Tinne", ""], ["Bacciu", "Davide", ""], ["Maltoni", "Davide", ""]]}, {"id": "2104.00409", "submitter": "Parfait Atchade", "authors": "Parfait Atchade-Adelomou, Daniel Casado-Fauli, Elisabet\n  Golobardes-Ribe and Xavier Vilasis-Cardona", "title": "quantum Case-Based Reasoning (qCBR)", "comments": "14 pages, 17 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.ET cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Case-Based Reasoning (CBR) is an artificial intelligence approach to\nproblem-solving with a good record of success. This article proposes using\nQuantum Computing to improve some of the key processes of CBR defining so a\nQuantum Case-Based Reasoning (qCBR) paradigm. The focus is set on designing and\nimplementing a qCBR based on the variational principle that improves its\nclassical counterpart in terms of average accuracy, scalability and tolerance\nto overlapping. A comparative study of the proposed qCBR with a classic CBR is\nperformed for the case of the Social Workers' Problem as a sample of a\ncombinatorial optimization problem with overlapping. The algorithm's quantum\nfeasibility is modelled with docplex and tested on IBMQ computers, and\nexperimented on the Qibo framework.\n", "versions": [{"version": "v1", "created": "Thu, 1 Apr 2021 11:34:22 GMT"}], "update_date": "2021-04-02", "authors_parsed": [["Atchade-Adelomou", "Parfait", ""], ["Casado-Fauli", "Daniel", ""], ["Golobardes-Ribe", "Elisabet", ""], ["Vilasis-Cardona", "Xavier", ""]]}, {"id": "2104.00411", "submitter": "Ashkan Khakzar", "authors": "Ashkan Khakzar, Yang Zhang, Wejdene Mansour, Yuezhi Cai, Yawei Li,\n  Yucheng Zhang, Seong Tae Kim, Nassir Navab", "title": "Explaining COVID-19 and Thoracic Pathology Model Predictions by\n  Identifying Informative Input Features", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks have demonstrated remarkable performance in classification\nand regression tasks on chest X-rays. In order to establish trust in the\nclinical routine, the networks' prediction mechanism needs to be interpretable.\nOne principal approach to interpretation is feature attribution. Feature\nattribution methods identify the importance of input features for the output\nprediction. Building on Information Bottleneck Attribution (IBA) method, for\neach prediction we identify the chest X-ray regions that have high mutual\ninformation with the network's output. Original IBA identifies input regions\nthat have sufficient predictive information. We propose Inverse IBA to identify\nall informative regions. Thus all predictive cues for pathologies are\nhighlighted on the X-rays, a desirable property for chest X-ray diagnosis.\nMoreover, we propose Regression IBA for explaining regression models. Using\nRegression IBA we observe that a model trained on cumulative severity score\nlabels implicitly learns the severity of different X-ray regions. Finally, we\npropose Multi-layer IBA to generate higher resolution and more detailed\nattribution/saliency maps. We evaluate our methods using both human-centric\n(ground-truth-based) interpretability metrics, and human-independent feature\nimportance metrics on NIH Chest X-ray8 and BrixIA datasets. The Code is\npublicly available.\n", "versions": [{"version": "v1", "created": "Thu, 1 Apr 2021 11:42:39 GMT"}], "update_date": "2021-04-02", "authors_parsed": [["Khakzar", "Ashkan", ""], ["Zhang", "Yang", ""], ["Mansour", "Wejdene", ""], ["Cai", "Yuezhi", ""], ["Li", "Yawei", ""], ["Zhang", "Yucheng", ""], ["Kim", "Seong Tae", ""], ["Navab", "Nassir", ""]]}, {"id": "2104.00415", "submitter": "Amir Zandieh", "authors": "Amir Zandieh", "title": "Learning with Neural Tangent Kernels in Near Input Sparsity Time", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Neural Tangent Kernel (NTK) characterizes the behavior of infinitely wide\nneural nets trained under least squares loss by gradient descent. However,\ndespite its importance, the super-quadratic runtime of kernel methods limits\nthe use of NTK in large-scale learning tasks. To accelerate kernel machines\nwith NTK, we propose a near input sparsity time algorithm that maps the input\ndata to a randomized low-dimensional feature space so that the inner product of\nthe transformed data approximates their NTK evaluation. Our transformation\nworks by sketching the polynomial expansions of arc-cosine kernels.\nFurthermore, we propose a feature map for approximating the convolutional\ncounterpart of the NTK, which can transform any image using a runtime that is\nonly linear in the number of pixels. We show that in standard large-scale\nregression and classification tasks a linear regressor trained on our features\noutperforms trained Neural Nets and Nystrom approximation of NTK kernel.\n", "versions": [{"version": "v1", "created": "Thu, 1 Apr 2021 11:56:58 GMT"}, {"version": "v2", "created": "Tue, 27 Jul 2021 07:04:09 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Zandieh", "Amir", ""]]}, {"id": "2104.00428", "submitter": "Emile van Krieken", "authors": "Emile van Krieken, Jakub M. Tomczak, Annette ten Teije", "title": "Storchastic: A Framework for General Stochastic Automatic\n  Differentiation", "comments": "28 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modelers use automatic differentiation (AD) of computation graphs to\nimplement complex Deep Learning models without defining gradient computations.\nStochastic AD extends AD to stochastic computation graphs with sampling steps,\nwhich arise when modelers handle the intractable expectations common in\nReinforcement Learning and Variational Inference. However, current methods for\nstochastic AD are limited: They are either only applicable to continuous random\nvariables and differentiable functions, or can only use simple but high\nvariance score-function estimators. To overcome these limitations, we introduce\nStorchastic, a new framework for AD of stochastic computation graphs.\nStorchastic allows the modeler to choose from a wide variety of gradient\nestimation methods at each sampling step, to optimally reduce the variance of\nthe gradient estimates. Furthermore, Storchastic is provably unbiased for\nestimation of any-order gradients, and generalizes variance reduction\ntechniques to higher-order gradient estimates. Finally, we implement\nStorchastic as a PyTorch library.\n", "versions": [{"version": "v1", "created": "Thu, 1 Apr 2021 12:19:54 GMT"}, {"version": "v2", "created": "Fri, 28 May 2021 14:13:16 GMT"}], "update_date": "2021-05-31", "authors_parsed": [["van Krieken", "Emile", ""], ["Tomczak", "Jakub M.", ""], ["Teije", "Annette ten", ""]]}, {"id": "2104.00430", "submitter": "Mathis Peyron", "authors": "Mathis Peyron, Anthony Fillion, Selime G\\\"urol, Victor Marchais, Serge\n  Gratton, Pierre Boudier and Gael Goret", "title": "Latent Space Data Assimilation by using Deep Learning", "comments": "15 pages, 7 figures and 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA math.NA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Performing Data Assimilation (DA) at a low cost is of prime concern in Earth\nsystem modeling, particularly at the time of big data where huge quantities of\nobservations are available. Capitalizing on the ability of Neural Networks\ntechniques for approximating the solution of PDE's, we incorporate Deep\nLearning (DL) methods into a DA framework. More precisely, we exploit the\nlatent structure provided by autoencoders (AEs) to design an Ensemble Transform\nKalman Filter with model error (ETKF-Q) in the latent space. Model dynamics are\nalso propagated within the latent space via a surrogate neural network. This\nnovel ETKF-Q-Latent (thereafter referred to as ETKF-Q-L) algorithm is tested on\na tailored instructional version of Lorenz 96 equations, named the augmented\nLorenz 96 system: it possesses a latent structure that accurately represents\nthe observed dynamics. Numerical experiments based on this particular system\nevidence that the ETKF-Q-L approach both reduces the computational cost and\nprovides better accuracy than state of the art algorithms, such as the ETKF-Q.\n", "versions": [{"version": "v1", "created": "Thu, 1 Apr 2021 12:25:55 GMT"}], "update_date": "2021-04-02", "authors_parsed": [["Peyron", "Mathis", ""], ["Fillion", "Anthony", ""], ["G\u00fcrol", "Selime", ""], ["Marchais", "Victor", ""], ["Gratton", "Serge", ""], ["Boudier", "Pierre", ""], ["Goret", "Gael", ""]]}, {"id": "2104.00442", "submitter": "Sai Rajeswar Mudumba", "authors": "Sai Rajeswar, Cyril Ibrahim, Nitin Surya, Florian Golemo, David\n  Vazquez, Aaron Courville, Pedro O. Pinheiro", "title": "Touch-based Curiosity for Sparse-Reward Tasks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.RO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Robots in many real-world settings have access to force/torque sensors in\ntheir gripper and tactile sensing is often necessary in tasks that involve\ncontact-rich motion. In this work, we leverage surprise from mismatches in\ntouch feedback to guide exploration in hard sparse-reward reinforcement\nlearning tasks. Our approach, Touch-based Curiosity (ToC), learns what visible\nobjects interactions are supposed to \"feel\" like. We encourage exploration by\nrewarding interactions where the expectation and the experience don't match. In\nour proposed method, an initial task-independent exploration phase is followed\nby an on-task learning phase, in which the original interactions are relabeled\nwith on-task rewards. We test our approach on a range of touch-intensive robot\narm tasks (e.g. pushing objects, opening doors), which we also release as part\nof this work. Across multiple experiments in a simulated setting, we\ndemonstrate that our method is able to learn these difficult tasks through\nsparse reward and curiosity alone. We compare our cross-modal approach to\nsingle-modality (touch- or vision-only) approaches as well as other\ncuriosity-based methods and find that our method performs better and is more\nsample-efficient.\n", "versions": [{"version": "v1", "created": "Thu, 1 Apr 2021 12:49:29 GMT"}, {"version": "v2", "created": "Sat, 26 Jun 2021 04:55:32 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Rajeswar", "Sai", ""], ["Ibrahim", "Cyril", ""], ["Surya", "Nitin", ""], ["Golemo", "Florian", ""], ["Vazquez", "David", ""], ["Courville", "Aaron", ""], ["Pinheiro", "Pedro O.", ""]]}, {"id": "2104.00447", "submitter": "Zhaoyang Lyu", "authors": "Zhaoyang Lyu, Minghao Guo, Tong Wu, Guodong Xu, Kehuan Zhang, Dahua\n  Lin", "title": "Towards Evaluating and Training Verifiably Robust Neural Networks", "comments": "Accepted to CVPR 2021 (Oral)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recent works have shown that interval bound propagation (IBP) can be used to\ntrain verifiably robust neural networks. Reseachers observe an intriguing\nphenomenon on these IBP trained networks: CROWN, a bounding method based on\ntight linear relaxation, often gives very loose bounds on these networks. We\nalso observe that most neurons become dead during the IBP training process,\nwhich could hurt the representation capability of the network. In this paper,\nwe study the relationship between IBP and CROWN, and prove that CROWN is always\ntighter than IBP when choosing appropriate bounding lines. We further propose a\nrelaxed version of CROWN, linear bound propagation (LBP), that can be used to\nverify large networks to obtain lower verified errors than IBP. We also design\na new activation function, parameterized ramp function (ParamRamp), which has\nmore diversity of neuron status than ReLU. We conduct extensive experiments on\nMNIST, CIFAR-10 and Tiny-ImageNet with ParamRamp activation and achieve\nstate-of-the-art verified robustness. Code and the appendix are available at\nhttps://github.com/ZhaoyangLyu/VerifiablyRobustNN.\n", "versions": [{"version": "v1", "created": "Thu, 1 Apr 2021 13:03:48 GMT"}, {"version": "v2", "created": "Mon, 5 Apr 2021 02:31:33 GMT"}, {"version": "v3", "created": "Wed, 16 Jun 2021 07:11:50 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Lyu", "Zhaoyang", ""], ["Guo", "Minghao", ""], ["Wu", "Tong", ""], ["Xu", "Guodong", ""], ["Zhang", "Kehuan", ""], ["Lin", "Dahua", ""]]}, {"id": "2104.00453", "submitter": "Haizhang Zhang", "authors": "Jie Gui and Haizhang Zhang", "title": "Learning Rates for Multi-task Regularization Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.FA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-task learning is an important trend of machine learning in facing the\nera of artificial intelligence and big data. Despite a large amount of\nresearches on learning rate estimates of various single-task machine learning\nalgorithms, there is little parallel work for multi-task learning. We present\nmathematical analysis on the learning rate estimate of multi-task learning\nbased on the theory of vector-valued reproducing kernel Hilbert spaces and\nmatrix-valued reproducing kernels. For the typical multi-task regularization\nnetworks, an explicit learning rate dependent both on the number of sample data\nand the number of tasks is obtained. It reveals that the generalization ability\nof multi-task learning algorithms is indeed affected as the number of tasks\nincreases.\n", "versions": [{"version": "v1", "created": "Thu, 1 Apr 2021 13:10:29 GMT"}, {"version": "v2", "created": "Tue, 20 Apr 2021 10:39:04 GMT"}], "update_date": "2021-04-21", "authors_parsed": [["Gui", "Jie", ""], ["Zhang", "Haizhang", ""]]}, {"id": "2104.00479", "submitter": "Celia Cintas", "authors": "Celia Cintas, Payel Das, Brian Quanz, Skyler Speakman, Victor\n  Akinwande, Pin-Yu Chen", "title": "Towards creativity characterization of generative models via group-based\n  subset scanning", "comments": "Synthetic Data Generation Workshop at ICLR'21", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deep generative models, such as Variational Autoencoders (VAEs), have been\nemployed widely in computational creativity research. However, such models\ndiscourage out-of-distribution generation to avoid spurious sample generation,\nlimiting their creativity. Thus, incorporating research on human creativity\ninto generative deep learning techniques presents an opportunity to make their\noutputs more compelling and human-like. As we see the emergence of generative\nmodels directed to creativity research, a need for machine learning-based\nsurrogate metrics to characterize creative output from these models is\nimperative. We propose group-based subset scanning to quantify, detect, and\ncharacterize creative processes by detecting a subset of anomalous\nnode-activations in the hidden layers of generative models. Our experiments on\noriginal, typically decoded, and \"creatively decoded\" (Das et al 2020) image\ndatasets reveal that the proposed subset scores distribution is more useful for\ndetecting creative processes in the activation space rather than the pixel\nspace. Further, we found that creative samples generate larger subsets of\nanomalies than normal or non-creative samples across datasets. The node\nactivations highlighted during the creative decoding process are different from\nthose responsible for normal sample generation.\n", "versions": [{"version": "v1", "created": "Thu, 1 Apr 2021 14:07:49 GMT"}, {"version": "v2", "created": "Wed, 26 May 2021 11:49:07 GMT"}], "update_date": "2021-05-27", "authors_parsed": [["Cintas", "Celia", ""], ["Das", "Payel", ""], ["Quanz", "Brian", ""], ["Speakman", "Skyler", ""], ["Akinwande", "Victor", ""], ["Chen", "Pin-Yu", ""]]}, {"id": "2104.00488", "submitter": "Jun Fu", "authors": "Jun Fu, Wei Zhou, Zhibo Chen", "title": "Bayesian Graph Convolutional Network for Traffic Prediction", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, adaptive graph convolutional network based traffic prediction\nmethods, learning a latent graph structure from traffic data via various\nattention-based mechanisms, have achieved impressive performance. However, they\nare still limited to find a better description of spatial relationships between\ntraffic conditions due to: (1) ignoring the prior of the observed topology of\nthe road network; (2) neglecting the presence of negative spatial\nrelationships; and (3) lacking investigation on uncertainty of the graph\nstructure. In this paper, we propose a Bayesian Graph Convolutional Network\n(BGCN) framework to alleviate these issues. Under this framework, the graph\nstructure is viewed as a random realization from a parametric generative model,\nand its posterior is inferred using the observed topology of the road network\nand traffic data. Specifically, the parametric generative model is comprised of\ntwo parts: (1) a constant adjacency matrix which discovers potential spatial\nrelationships from the observed physical connections between roads using a\nBayesian approach; (2) a learnable adjacency matrix that learns a global shared\nspatial correlations from traffic data in an end-to-end fashion and can model\nnegative spatial correlations. The posterior of the graph structure is then\napproximated by performing Monte Carlo dropout on the parametric graph\nstructure. We verify the effectiveness of our method on five real-world\ndatasets, and the experimental results demonstrate that BGCN attains superior\nperformance compared with state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Thu, 1 Apr 2021 14:19:37 GMT"}], "update_date": "2021-04-02", "authors_parsed": [["Fu", "Jun", ""], ["Zhou", "Wei", ""], ["Chen", "Zhibo", ""]]}, {"id": "2104.00489", "submitter": "Pavlos Papadopoulos", "authors": "Daniele Romanini, Adam James Hall, Pavlos Papadopoulos, Tom Titcombe,\n  Abbas Ismail, Tudor Cebere, Robert Sandmann, Robin Roehm, Michael A. Hoeh", "title": "PyVertical: A Vertical Federated Learning Framework for Multi-headed\n  SplitNN", "comments": "ICLR 2021 Workshop on Distributed and Private Machine Learning (DPML\n  2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.DC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We introduce PyVertical, a framework supporting vertical federated learning\nusing split neural networks. The proposed framework allows a data scientist to\ntrain neural networks on data features vertically partitioned across multiple\nowners while keeping raw data on an owner's device. To link entities shared\nacross different datasets' partitions, we use Private Set Intersection on IDs\nassociated with data points. To demonstrate the validity of the proposed\nframework, we present the training of a simple dual-headed split neural network\nfor a MNIST classification task, with data samples vertically distributed\nacross two data owners and a data scientist.\n", "versions": [{"version": "v1", "created": "Thu, 1 Apr 2021 14:21:33 GMT"}, {"version": "v2", "created": "Mon, 12 Apr 2021 18:15:08 GMT"}, {"version": "v3", "created": "Wed, 14 Apr 2021 08:05:04 GMT"}], "update_date": "2021-04-15", "authors_parsed": [["Romanini", "Daniele", ""], ["Hall", "Adam James", ""], ["Papadopoulos", "Pavlos", ""], ["Titcombe", "Tom", ""], ["Ismail", "Abbas", ""], ["Cebere", "Tudor", ""], ["Sandmann", "Robert", ""], ["Roehm", "Robin", ""], ["Hoeh", "Michael A.", ""]]}, {"id": "2104.00496", "submitter": "Tadhg Garton", "authors": "Tadhg M. Garton, Caitriona M. Jackman, Andy W. Smith, Kiley L. Yeakel,\n  Shane A. Maloney and Jon Vandegriff", "title": "Machine Learning Applications to Kronian Magnetospheric Reconnection\n  Classification", "comments": "21 pages, 9 figures", "journal-ref": "Frontiers in Astronomy and Space Science, 2021", "doi": "10.3389/fspas.2020.600031", "report-no": null, "categories": "astro-ph.EP cs.LG physics.space-ph", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  The products of magnetic reconnection in Saturn's magnetotail are identified\nin magnetometer observations primarily through characteristic deviations in the\nnorth-south component of the magnetic field. These magnetic deflections are\ncaused by travelling plasma structures created during reconnection rapidly\npassing over the observing spacecraft. Identification of these signatures have\nlong been performed by eye, and more recently through semi-automated methods,\nhowever these methods are often limited through a required human verification\nstep. Here, we present a fully automated, supervised learning, feed forward\nneural network model to identify evidence of reconnection in the Kronian\nmagnetosphere with the three magnetic field components observed by the Cassini\nspacecraft in Kronocentric radial-theta-phi (KRTP) coordinates as input. This\nmodel is constructed from a catalogue of reconnection events which covers three\nyears of observations with a total of 2093 classified events, categorized into\nplasmoids, travelling compression regions and dipolarizations. This neural\nnetwork model is capable of rapidly identifying reconnection events in large\ntime-span Cassini datasets, tested against the full year 2010 with a high level\nof accuracy (87%), true skill score (0.76), and Heidke skill score (0.73). From\nthis model, a full cataloguing and examination of magnetic reconnection events\nin the Kronian magnetosphere across Cassini's near Saturn lifetime is now\npossible.\n", "versions": [{"version": "v1", "created": "Thu, 1 Apr 2021 14:46:16 GMT"}], "update_date": "2021-04-02", "authors_parsed": [["Garton", "Tadhg M.", ""], ["Jackman", "Caitriona M.", ""], ["Smith", "Andy W.", ""], ["Yeakel", "Kiley L.", ""], ["Maloney", "Shane A.", ""], ["Vandegriff", "Jon", ""]]}, {"id": "2104.00501", "submitter": "Alexander Renz-Wieland", "authors": "Alexander Renz-Wieland, Rainer Gemulla, Zoi Kaoudi, Volker Markl", "title": "Replicate or Relocate? Non-Uniform Access in Parameter Servers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.DC cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Parameter servers (PSs) facilitate the implementation of distributed training\nfor large machine learning tasks. A key challenge for PS performance is that\nparameter access is non-uniform in many real-world machine learning tasks,\ni.e., different parameters exhibit drastically different access patterns. We\nidentify skew and nondeterminism as two major sources for non-uniformity.\nExisting PSs are ill-suited for managing such non-uniform access because they\nuniformly apply the same parameter management technique to all parameters. As\nconsequence, the performance of existing PSs is negatively affected and may\neven fall behind that of single node baselines. In this paper, we explore how\nPSs can manage non-uniform access efficiently. We find that it is key for PSs\nto support multiple management techniques and to leverage a well-suited\nmanagement technique for each parameter. We present Lapse2, a PS that\nreplicates hot spot parameters, relocates less frequently accessed parameters,\nand employs specialized techniques to manage nondeterminism that arises from\nrandom sampling. In our experimental study, Lapse2 outperformed existing,\nsingle-technique PSs by up to one order of magnitude and provided near-linear\nscalability across multiple machine learning tasks.\n", "versions": [{"version": "v1", "created": "Thu, 1 Apr 2021 14:52:32 GMT"}], "update_date": "2021-04-02", "authors_parsed": [["Renz-Wieland", "Alexander", ""], ["Gemulla", "Rainer", ""], ["Kaoudi", "Zoi", ""], ["Markl", "Volker", ""]]}, {"id": "2104.00507", "submitter": "Przemyslaw Biecek", "authors": "Jakub Wi\\'sniewski, Przemys{\\l}aw Biecek", "title": "fairmodels: A Flexible Tool For Bias Detection, Visualization, And\n  Mitigation", "comments": "15 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.MS stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning decision systems are getting omnipresent in our lives. From\ndating apps to rating loan seekers, algorithms affect both our well-being and\nfuture. Typically, however, these systems are not infallible. Moreover, complex\npredictive models are really eager to learn social biases present in historical\ndata that can lead to increasing discrimination. If we want to create models\nresponsibly then we need tools for in-depth validation of models also from the\nperspective of potential discrimination. This article introduces an R package\nfairmodels that helps to validate fairness and eliminate bias in classification\nmodels in an easy and flexible fashion. The fairmodels package offers a\nmodel-agnostic approach to bias detection, visualization and mitigation. The\nimplemented set of functions and fairness metrics enables model fairness\nvalidation from different perspectives. The package includes a series of\nmethods for bias mitigation that aim to diminish the discrimination in the\nmodel. The package is designed not only to examine a single model, but also to\nfacilitate comparisons between multiple models.\n", "versions": [{"version": "v1", "created": "Thu, 1 Apr 2021 15:06:13 GMT"}], "update_date": "2021-04-02", "authors_parsed": [["Wi\u015bniewski", "Jakub", ""], ["Biecek", "Przemys\u0142aw", ""]]}, {"id": "2104.00512", "submitter": "Xin Liang", "authors": "Xin Liang", "title": "On the Optimality of the Oja's Algorithm for Online PCA", "comments": "24 pages. arXiv admin note: text overlap with arXiv:1711.06644", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we analyze the behavior of the Oja's algorithm for\nonline/streaming principal component subspace estimation. It is proved that\nwith high probability it performs an efficient, gap-free, global convergence\nrate to approximate an principal component subspace for any sub-Gaussian\ndistribution. Moreover, it is the first time to show that the convergence rate,\nnamely the upper bound of the approximation, exactly matches the lower bound of\nan approximation obtained by the offline/classical PCA up to a constant factor.\n", "versions": [{"version": "v1", "created": "Wed, 31 Mar 2021 15:02:54 GMT"}], "update_date": "2021-04-02", "authors_parsed": [["Liang", "Xin", ""]]}, {"id": "2104.00514", "submitter": "Luc Moschella", "authors": "Luca Moschella, Simone Melzi, Luca Cosmo, Filippo Maggioli, Or Litany,\n  Maks Ovsjanikov, Leonidas Guibas, Emanuele Rodol\\`a", "title": "Spectral Unions of Partial Deformable 3D Shapes", "comments": "17 pages, 20 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GR cs.CG cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spectral geometric methods have brought revolutionary changes to the field of\ngeometry processing -- however, when the data to be processed exhibits severe\npartiality, such methods fail to generalize. As a result, there exists a big\nperformance gap between methods dealing with complete shapes, and methods that\naddress missing geometry. In this paper, we propose a possible way to fill this\ngap. We introduce the first method to compute compositions of non-rigidly\ndeforming shapes, without requiring to solve first for a dense correspondence\nbetween the given partial shapes. We do so by operating in a purely spectral\ndomain, where we define a union operation between short sequences of\neigenvalues. Working with eigenvalues allows to deal with unknown\ncorrespondence, different sampling, and different discretization (point clouds\nand meshes alike), making this operation especially robust and general. Our\napproach is data-driven, and can generalize to isometric and non-isometric\ndeformations of the surface, as long as these stay within the same semantic\nclass (e.g., human bodies), as well as to partiality artifacts not seen at\ntraining time.\n", "versions": [{"version": "v1", "created": "Wed, 31 Mar 2021 14:19:18 GMT"}], "update_date": "2021-04-02", "authors_parsed": [["Moschella", "Luca", ""], ["Melzi", "Simone", ""], ["Cosmo", "Luca", ""], ["Maggioli", "Filippo", ""], ["Litany", "Or", ""], ["Ovsjanikov", "Maks", ""], ["Guibas", "Leonidas", ""], ["Rodol\u00e0", "Emanuele", ""]]}, {"id": "2104.00520", "submitter": "Betul Guvenc Paltun", "authors": "Bet\\\"ul G\\\"uven\\c{c} Paltun, Samuel Kaski and Hiroshi Mamitsuka", "title": "DIVERSE: Bayesian Data IntegratiVE learning for precise drug ResponSE\n  prediction", "comments": null, "journal-ref": "Guvencpaltun, B., Kaski, S., & Mamitsuka, H. (2021). DIVERSE:\n  Bayesian Data IntegratiVE learning for precise drug ResponSE prediction.\n  IEEE/ACM Transactions on Computational Biology and Bioinformatics, (01), 1-1", "doi": "10.1109/TCBB.2021.3065535", "report-no": null, "categories": "q-bio.QM cs.LG q-bio.GN", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Detecting predictive biomarkers from multi-omics data is important for\nprecision medicine, to improve diagnostics of complex diseases and for better\ntreatments. This needs substantial experimental efforts that are made difficult\nby the heterogeneity of cell lines and huge cost. An effective solution is to\nbuild a computational model over the diverse omics data, including genomic,\nmolecular, and environmental information. However, choosing informative and\nreliable data sources from among the different types of data is a challenging\nproblem. We propose DIVERSE, a framework of Bayesian importance-weighted tri-\nand bi-matrix factorization(DIVERSE3 or DIVERSE2) to predict drug responses\nfrom data of cell lines, drugs, and gene interactions. DIVERSE integrates the\ndata sources systematically, in a step-wise manner, examining the importance of\neach added data set in turn. More specifically, we sequentially integrate five\ndifferent data sets, which have not all been combined in earlier bioinformatic\nmethods for predicting drug responses. Empirical experiments show that DIVERSE\nclearly outperformed five other methods including three state-of-the-art\napproaches, under cross-validation, particularly in out-of-matrix prediction,\nwhich is closer to the setting of real use cases and more challenging than\nsimpler in-matrix prediction. Additionally, case studies for discovering new\ndrugs further confirmed the performance advantage of DIVERSE.\n", "versions": [{"version": "v1", "created": "Wed, 31 Mar 2021 12:40:00 GMT"}, {"version": "v2", "created": "Mon, 7 Jun 2021 14:26:59 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Paltun", "Bet\u00fcl G\u00fcven\u00e7", ""], ["Kaski", "Samuel", ""], ["Mamitsuka", "Hiroshi", ""]]}, {"id": "2104.00525", "submitter": "Aydogan Ozcan", "authors": "Yi Luo, Yichen Wu, Liqiao Li, Yuening Guo, Ege Cetintas, Yifang Zhu,\n  Aydogan Ozcan", "title": "Dynamic imaging and characterization of volatile aerosols in e-cigarette\n  emissions using deep learning-based holographic microscopy", "comments": "23 Pages, 4 Figures", "journal-ref": "ACS Sensors (2021)", "doi": "10.1021/acssensors.1c00628", "report-no": null, "categories": "cs.LG physics.app-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Various volatile aerosols have been associated with adverse health effects;\nhowever, characterization of these aerosols is challenging due to their dynamic\nnature. Here we present a method that directly measures the volatility of\nparticulate matter (PM) using computational microscopy and deep learning. This\nmethod was applied to aerosols generated by electronic cigarettes (e-cigs),\nwhich vaporize a liquid mixture (e-liquid) that mainly consists of propylene\nglycol (PG), vegetable glycerin (VG), nicotine, and flavoring compounds. E-cig\ngenerated aerosols were recorded by a field-portable computational microscope,\nusing an impaction-based air sampler. A lensless digital holographic microscope\ninside this mobile device continuously records the inline holograms of the\ncollected particles. A deep learning-based algorithm is used to automatically\nreconstruct the microscopic images of e-cig generated particles from their\nholograms, and rapidly quantify their volatility. To evaluate the effects of\ne-liquid composition on aerosol dynamics, we measured the volatility of the\nparticles generated by flavorless, nicotine-free e-liquids with various PG/VG\nvolumetric ratios, revealing a negative correlation between the particles'\nvolatility and the volumetric ratio of VG in the e-liquid. For a given PG/VG\ncomposition, the addition of nicotine dominated the evaporation dynamics of the\ne-cig aerosol and the aforementioned negative correlation was no longer\nobserved. We also revealed that flavoring additives in e-liquids significantly\ndecrease the volatility of e-cig aerosol. The presented holographic volatility\nmeasurement technique and the associated mobile device might provide new\ninsights on the volatility of e-cig generated particles and can be applied to\ncharacterize various volatile PM.\n", "versions": [{"version": "v1", "created": "Wed, 31 Mar 2021 06:29:29 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["Luo", "Yi", ""], ["Wu", "Yichen", ""], ["Li", "Liqiao", ""], ["Guo", "Yuening", ""], ["Cetintas", "Ege", ""], ["Zhu", "Yifang", ""], ["Ozcan", "Aydogan", ""]]}, {"id": "2104.00526", "submitter": "Partha Mitra", "authors": "Partha P Mitra", "title": "Fitting Elephants", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI q-bio.NC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Textbook wisdom advocates for smooth function fits and implies that\ninterpolation of noisy data should lead to poor generalization. A related\nheuristic is that fitting parameters should be fewer than measurements (Occam's\nRazor). Surprisingly, contemporary machine learning (ML) approaches, cf. deep\nnets (DNNs), generalize well despite interpolating noisy data. This may be\nunderstood via Statistically Consistent Interpolation (SCI), i.e. data\ninterpolation techniques that generalize optimally for big data. In this\narticle we elucidate SCI using the weighted interpolating nearest neighbors\n(wiNN) algorithm, which adds singular weight functions to kNN (k-nearest\nneighbors). This shows that data interpolation can be a valid ML strategy for\nbig data. SCI clarifies the relation between two ways of modeling natural\nphenomena: the rationalist approach (strong priors) of theoretical physics with\nfew parameters and the empiricist (weak priors) approach of modern ML with more\nparameters than data. SCI shows that the purely empirical approach can\nsuccessfully predict. However data interpolation does not provide theoretical\ninsights, and the training data requirements may be prohibitive. Complex animal\nbrains are between these extremes, with many parameters, but modest training\ndata, and with prior structure encoded in species-specific mesoscale circuitry.\nThus, modern ML provides a distinct epistemological approach different both\nfrom physical theories and animal brains.\n", "versions": [{"version": "v1", "created": "Wed, 31 Mar 2021 05:50:39 GMT"}], "update_date": "2021-04-02", "authors_parsed": [["Mitra", "Partha P", ""]]}, {"id": "2104.00527", "submitter": "Yusuf Nasir", "authors": "Yusuf Nasir, Jincong He, Chaoshun Hu, Shusei Tanaka, Kainan Wang and\n  XianHuan Wen", "title": "Deep Reinforcement Learning for Constrained Field Development\n  Optimization in Subsurface Two-phase Flow", "comments": "Journal paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present a deep reinforcement learning-based artificial intelligence agent\nthat could provide optimized development plans given a basic description of the\nreservoir and rock/fluid properties with minimal computational cost. This\nartificial intelligence agent, comprising of a convolutional neural network,\nprovides a mapping from a given state of the reservoir model, constraints, and\neconomic condition to the optimal decision (drill/do not drill and well\nlocation) to be taken in the next stage of the defined sequential field\ndevelopment planning process. The state of the reservoir model is defined using\nparameters that appear in the governing equations of the two-phase flow. A\nfeedback loop training process referred to as deep reinforcement learning is\nused to train an artificial intelligence agent with such a capability. The\ntraining entails millions of flow simulations with varying reservoir model\ndescriptions (structural, rock and fluid properties), operational constraints,\nand economic conditions. The parameters that define the reservoir model,\noperational constraints, and economic conditions are randomly sampled from a\ndefined range of applicability. Several algorithmic treatments are introduced\nto enhance the training of the artificial intelligence agent. After appropriate\ntraining, the artificial intelligence agent provides an optimized field\ndevelopment plan instantly for new scenarios within the defined range of\napplicability. This approach has advantages over traditional optimization\nalgorithms (e.g., particle swarm optimization, genetic algorithm) that are\ngenerally used to find a solution for a specific field development scenario and\ntypically not generalizable to different scenarios.\n", "versions": [{"version": "v1", "created": "Wed, 31 Mar 2021 07:08:24 GMT"}], "update_date": "2021-04-02", "authors_parsed": [["Nasir", "Yusuf", ""], ["He", "Jincong", ""], ["Hu", "Chaoshun", ""], ["Tanaka", "Shusei", ""], ["Wang", "Kainan", ""], ["Wen", "XianHuan", ""]]}, {"id": "2104.00528", "submitter": "Alexander Wong", "authors": "Saad Abbasi, Mahmoud Famouri, Mohammad Javad Shafiee, and Alexander\n  Wong", "title": "OutlierNets: Highly Compact Deep Autoencoder Network Architectures for\n  On-Device Acoustic Anomaly Detection", "comments": "7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human operators often diagnose industrial machinery via anomalous sounds.\nAutomated acoustic anomaly detection can lead to reliable maintenance of\nmachinery. However, deep learning-driven anomaly detection methods often\nrequire an extensive amount of computational resources which prohibits their\ndeployment in factories. Here we explore a machine-driven design exploration\nstrategy to create OutlierNets, a family of highly compact deep convolutional\nautoencoder network architectures featuring as few as 686 parameters, model\nsizes as small as 2.7 KB, and as low as 2.8 million FLOPs, with a detection\naccuracy matching or exceeding published architectures with as many as 4\nmillion parameters. Furthermore, CPU-accelerated latency experiments show that\nthe OutlierNet architectures can achieve as much as 21x lower latency than\npublished networks.\n", "versions": [{"version": "v1", "created": "Wed, 31 Mar 2021 04:09:30 GMT"}, {"version": "v2", "created": "Mon, 19 Apr 2021 03:25:50 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Abbasi", "Saad", ""], ["Famouri", "Mahmoud", ""], ["Shafiee", "Mohammad Javad", ""], ["Wong", "Alexander", ""]]}, {"id": "2104.00530", "submitter": "Andrew Song", "authors": "Andrew H. Song, Bahareh Tolooshams, Demba Ba", "title": "Gaussian Process Convolutional Dictionary Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional dictionary learning (CDL), the problem of estimating\nshift-invariant templates from data, is typically conducted in the absence of a\nprior/structure on the templates. In data-scarce or low signal-to-noise ratio\n(SNR) regimes, which have received little attention from the community, learned\ntemplates overfit the data and lack smoothness, which can affect the predictive\nperformance of downstream tasks. To address this limitation, we propose GPCDL,\na convolutional dictionary learning framework that enforces priors on templates\nusing Gaussian Processes (GPs). With the focus on smoothness, we show\ntheoretically that imposing a GP prior is equivalent to Wiener filtering the\nlearned templates, thereby suppressing high-frequency components and promoting\nsmoothness. We show that the algorithm is a simple extension of the classical\niteratively reweighted least squares, which allows the flexibility to\nexperiment with different smoothness assumptions. Through simulation, we show\nthat GPCDL learns smooth dictionaries with better accuracy than the\nunregularized alternative across a range of SNRs. Through an application to\nneural spiking data from rats, we show that learning templates by GPCDL results\nin a more accurate and visually-interpretable smooth dictionary, leading to\nsuperior predictive performance compared to non-regularized CDL, as well as\nparametric alternatives.\n", "versions": [{"version": "v1", "created": "Sun, 28 Mar 2021 21:40:03 GMT"}], "update_date": "2021-04-02", "authors_parsed": [["Song", "Andrew H.", ""], ["Tolooshams", "Bahareh", ""], ["Ba", "Demba", ""]]}, {"id": "2104.00531", "submitter": "Reza Pourreza", "authors": "Reza Pourreza and Taco S Cohen", "title": "Extending Neural P-frame Codecs for B-frame Coding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  While most neural video codecs address P-frame coding (predicting each frame\nfrom past ones), in this paper we address B-frame compression (predicting\nframes using both past and future reference frames). Our B-frame solution is\nbased on the existing P-frame methods. As a result, B-frame coding capability\ncan easily be added to an existing neural codec. The basic idea of our B-frame\ncoding method is to interpolate the two reference frames to generate a single\nreference frame and then use it together with an existing P-frame codec to\nencode the input B-frame. Our studies show that the interpolated frame is a\nmuch better reference for the P-frame codec compared to using the previous\nframe as is usually done. Our results show that using the proposed method with\nan existing P-frame codec can lead to 28.5%saving in bit-rate on the UVG\ndataset compared to the P-frame codec while generating the same video quality.\n", "versions": [{"version": "v1", "created": "Tue, 30 Mar 2021 21:25:35 GMT"}], "update_date": "2021-04-02", "authors_parsed": [["Pourreza", "Reza", ""], ["Cohen", "Taco S", ""]]}, {"id": "2104.00535", "submitter": "Shixiang Zhu", "authors": "Shixiang Zhu, He Wang, Yao Xie", "title": "Data-Driven Optimization for Police Zone Design", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  We present a data-driven optimization framework for redesigning police patrol\nzones in an urban environment. The objectives are to rebalance police workload\namong geographical areas and to reduce response time to emergency calls. We\ndevelop a stochastic model for police emergency response by integrating\nmultiple data sources, including police incidents reports, demographic surveys,\nand traffic data. Using this stochastic model, we optimize zone redesign plans\nusing mixed-integer linear programming. Our proposed design was implemented by\nthe Atlanta Police Department in March 2019. By analyzing data before and after\nthe zone redesign, we show that the new design has reduced the response time to\nhigh priority 911 calls by 5.8\\% and the imbalance of police workload among\ndifferent zones by 43\\%.\n", "versions": [{"version": "v1", "created": "Tue, 30 Mar 2021 20:16:01 GMT"}], "update_date": "2021-04-02", "authors_parsed": [["Zhu", "Shixiang", ""], ["Wang", "He", ""], ["Xie", "Yao", ""]]}, {"id": "2104.00538", "submitter": "Timur \\.Inan", "authors": "Inan Timur, Baba Ahmet Fevzi", "title": "Prediction of Wind Speed Using Artificial Neural Networks and ANFIS\n  Methods (Observation Buoy Example)", "comments": "5 pages, in Turkish language", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Estimation of the wind speed plays an important role in many issues such as\nroute determination of ships, efficient use of wind roses, and correct planning\nof agricultural activities. In this study, wind velocity estimation is\ncalculated using artificial neural networks (ANN) and adaptive artificial\nneural fuzzy inference system (ANFIS) methods. The data required for estimation\nwas obtained from the float named E1M3A, which is a float inside the POSEIDON\nfloat system. The proposed ANN is a Nonlinear Auto Regressive with External\nInput (NARX) type of artificial neural network with 3 layers, 50 neurons, 6\ninputs and 1 output. The ANFIS system introduced is a fuzzy inference system\nwith 6 inputs, 1 output, and 3 membership functions (MF) per input. The\nproposed systems were trained to make wind speed estimates after 3 hours and\nthe data obtained were obtained and the successes of the systems were revealed\nby comparing the obtained values with real measurements. Mean Squarred Error\n(MSE) and the regression between the predictions and expected values (R) were\nused to evaluate the success of the estimation values obtained from the\nsystems. According to estimation results, ANN achieved 2.19 MSE and 0.897 R\nvalues in training, 2.88 MSE and 0.866 R values in validation, and 2.93 MSE and\n0.857 R values in testing. ANFIS method has obtained 0.31634 MSE and 0.99 R\nvalues\n", "versions": [{"version": "v1", "created": "Mon, 29 Mar 2021 19:01:43 GMT"}], "update_date": "2021-04-02", "authors_parsed": [["Timur", "Inan", ""], ["Fevzi", "Baba Ahmet", ""]]}, {"id": "2104.00540", "submitter": "Bhaskar Ramasubramanian", "authors": "Bhaskar Ramasubramanian, Luyao Niu, Andrew Clark, Radha Poovendran", "title": "Reinforcement Learning Beyond Expectation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.SY eess.SY math.OC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The inputs and preferences of human users are important considerations in\nsituations where these users interact with autonomous cyber or cyber-physical\nsystems. In these scenarios, one is often interested in aligning behaviors of\nthe system with the preferences of one or more human users. Cumulative prospect\ntheory (CPT) is a paradigm that has been empirically shown to model a tendency\nof humans to view gains and losses differently. In this paper, we consider a\nsetting where an autonomous agent has to learn behaviors in an unknown\nenvironment. In traditional reinforcement learning, these behaviors are learned\nthrough repeated interactions with the environment by optimizing an expected\nutility. In order to endow the agent with the ability to closely mimic the\nbehavior of human users, we optimize a CPT-based cost. We introduce the notion\nof the CPT-value of an action taken in a state, and establish the convergence\nof an iterative dynamic programming-based approach to estimate this quantity.\nWe develop two algorithms to enable agents to learn policies to optimize the\nCPT-vale, and evaluate these algorithms in environments where a target state\nhas to be reached while avoiding obstacles. We demonstrate that behaviors of\nthe agent learned using these algorithms are better aligned with that of a\nhuman user who might be placed in the same environment, and is significantly\nimproved over a baseline that optimizes an expected utility.\n", "versions": [{"version": "v1", "created": "Mon, 29 Mar 2021 20:35:25 GMT"}], "update_date": "2021-04-02", "authors_parsed": [["Ramasubramanian", "Bhaskar", ""], ["Niu", "Luyao", ""], ["Clark", "Andrew", ""], ["Poovendran", "Radha", ""]]}, {"id": "2104.00541", "submitter": "Kamil \\.Zbikowski", "authors": "Kamil \\.Zbikowski, Micha{\\l} Ostapowicz, Piotr Gawrysiak", "title": "Deep Reinforcement Learning for Resource Allocation in Business\n  Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.HC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Assigning resources in business processes execution is a repetitive task that\ncan be effectively automated. However, different automation methods may give\nvarying results that may not be optimal. Proper resource allocation is crucial\nas it may lead to significant cost reductions or increased effectiveness that\nresults in increased revenues.\n  In this work, we first propose a novel representation that allows modeling of\na multi-process environment with different process-based rewards. These\nprocesses can share resources that differ in their eligibility. Then, we use\ndouble deep reinforcement learning to look for optimal resource allocation\npolicy. We compare those results with two popular strategies that are widely\nused in the industry. Learning optimal policy through reinforcement learning\nrequires frequent interactions with the environment, so we also designed and\ndeveloped a simulation engine that can mimic real-world processes.\n  The results obtained are promising. Deep reinforcement learning based\nresource allocation achieved significantly better results compared to two\ncommonly used techniques.\n", "versions": [{"version": "v1", "created": "Mon, 29 Mar 2021 11:20:25 GMT"}], "update_date": "2021-04-02", "authors_parsed": [["\u017bbikowski", "Kamil", ""], ["Ostapowicz", "Micha\u0142", ""], ["Gawrysiak", "Piotr", ""]]}, {"id": "2104.00543", "submitter": "Tong Wu", "authors": "Tong Wu and Jorge Ortiz", "title": "RLAD: Time Series Anomaly Detection through Reinforcement Learning and\n  Active Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new semi-supervised, time series anomaly detection algorithm\nthat uses deep reinforcement learning (DRL) and active learning to efficiently\nlearn and adapt to anomalies in real-world time series data. Our model - called\nRLAD - makes no assumption about the underlying mechanism that produces the\nobservation sequence and continuously adapts the detection model based on\nexperience with anomalous patterns. In addition, it requires no manual tuning\nof parameters and outperforms all state-of-art methods we compare with, both\nunsupervised and semi-supervised, across several figures of merit. More\nspecifically, we outperform the best unsupervised approach by a factor of 1.58\non the F1 score, with only 1% of labels and up to around 4.4x on another\nreal-world dataset with only 0.1% of labels. We compare RLAD with seven\ndeep-learning based algorithms across two common anomaly detection datasets\nwith up to around 3M data points and between 0.28% to 2.65% anomalies.We\noutperform all of them across several important performance metrics.\n", "versions": [{"version": "v1", "created": "Wed, 31 Mar 2021 15:21:15 GMT"}], "update_date": "2021-04-02", "authors_parsed": [["Wu", "Tong", ""], ["Ortiz", "Jorge", ""]]}, {"id": "2104.00563", "submitter": "Roger Girgis", "authors": "Roger Girgis, Florian Golemo, Felipe Codevilla, Jim Aldon D'Souza,\n  Martin Weiss, Samira Ebrahimi Kahou, Felix Heide, Christopher Pal", "title": "Autobots: Latent Variable Sequential Set Transformers", "comments": "21 pages, 15 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CV cs.LG cs.MA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Robust multi-agent trajectory prediction is essential for the safe control of\nrobots and vehicles that interact with humans. Many existing methods treat\nsocial and temporal information separately and therefore fall short of\nmodelling the joint future trajectories of all agents in a socially consistent\nway. To address this, we propose a new class of Latent Variable Sequential Set\nTransformers which autoregressively model multi-agent trajectories. We refer to\nthese architectures as \"AutoBots\". AutoBots model the contents of sets (e.g.\nrepresenting the properties of agents in a scene) over time and employ\nmulti-head self-attention blocks over these sequences of sets to encode the\nsociotemporal relationships between the different actors of a scene. This\nproduces either the trajectory of one ego-agent or a distribution over the\nfuture trajectories for all agents under consideration. Our approach works for\ngeneral sequences of sets and we provide illustrative experiments modelling the\nsequential structure of the multiple strokes that make up symbols in the\nOmniglot data. For the single-agent prediction case, we validate our model on\nthe NuScenes motion prediction task and achieve competitive results on the\nglobal leaderboard. In the multi-agent forecasting setting, we validate our\nmodel on TrajNet. We find that our method outperforms physical extrapolation\nand recurrent network baselines and generates scene-consistent trajectories.\n", "versions": [{"version": "v1", "created": "Fri, 19 Feb 2021 18:53:26 GMT"}, {"version": "v2", "created": "Wed, 16 Jun 2021 19:06:13 GMT"}], "update_date": "2021-06-18", "authors_parsed": [["Girgis", "Roger", ""], ["Golemo", "Florian", ""], ["Codevilla", "Felipe", ""], ["D'Souza", "Jim Aldon", ""], ["Weiss", "Martin", ""], ["Kahou", "Samira Ebrahimi", ""], ["Heide", "Felix", ""], ["Pal", "Christopher", ""]]}, {"id": "2104.00567", "submitter": "Wentong Liao", "authors": "Kai Hu, Wentong Liao, Michael Ying Yang, Bodo Rosenhahn", "title": "Text to Image Generation with Semantic-Spatial Aware GAN", "comments": "code available", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A text to image generation (T2I) model aims to generate photo-realistic\nimages which are semantically consistent with the text descriptions. Built upon\nthe recent advances in generative adversarial networks (GANs), existing T2I\nmodels have made great progress. However, a close inspection of their generated\nimages reveals two major limitations: (1) The condition batch normalization\nmethods are applied on the whole image feature maps equally, ignoring the local\nsemantics; (2) The text encoder is fixed during training, which should be\ntrained with the image generator jointly to learn better text representations\nfor image generation. To address these limitations, we propose a novel\nframework Semantic-Spatial Aware GAN, which is trained in an end-to-end fashion\nso that the text encoder can exploit better text information. Concretely, we\nintroduce a novel Semantic-Spatial Aware Convolution Network, which (1) learns\nsemantic-adaptive transformation conditioned on text to effectively fuse text\nfeatures and image features, and (2) learns a mask map in a weakly-supervised\nway that depends on the current text-image fusion process in order to guide the\ntransformation spatially. Experiments on the challenging COCO and CUB bird\ndatasets demonstrate the advantage of our method over the recent\nstate-of-the-art approaches, regarding both visual fidelity and alignment with\ninput text description. Code is available at\nhttps://github.com/wtliao/text2image.\n", "versions": [{"version": "v1", "created": "Thu, 1 Apr 2021 15:48:01 GMT"}, {"version": "v2", "created": "Wed, 14 Apr 2021 14:36:40 GMT"}, {"version": "v3", "created": "Sat, 24 Apr 2021 20:24:38 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Hu", "Kai", ""], ["Liao", "Wentong", ""], ["Yang", "Michael Ying", ""], ["Rosenhahn", "Bodo", ""]]}, {"id": "2104.00584", "submitter": "Vitor Cerqueira", "authors": "Vitor Cerqueira, Luis Torgo, Carlos Soares", "title": "Model Selection for Time Series Forecasting: Empirical Analysis of\n  Different Estimators", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Evaluating predictive models is a crucial task in predictive analytics. This\nprocess is especially challenging with time series data where the observations\nshow temporal dependencies. Several studies have analysed how different\nperformance estimation methods compare with each other for approximating the\ntrue loss incurred by a given forecasting model. However, these studies do not\naddress how the estimators behave for model selection: the ability to select\nthe best solution among a set of alternatives. We address this issue and\ncompare a set of estimation methods for model selection in time series\nforecasting tasks. We attempt to answer two main questions: (i) how often is\nthe best possible model selected by the estimators; and (ii) what is the\nperformance loss when it does not. We empirically found that the accuracy of\nthe estimators for selecting the best solution is low, and the overall\nforecasting performance loss associated with the model selection process ranges\nfrom 1.2% to 2.3%. We also discovered that some factors, such as the sample\nsize, are important in the relative performance of the estimators.\n", "versions": [{"version": "v1", "created": "Thu, 1 Apr 2021 16:08:25 GMT"}], "update_date": "2021-04-02", "authors_parsed": [["Cerqueira", "Vitor", ""], ["Torgo", "Luis", ""], ["Soares", "Carlos", ""]]}, {"id": "2104.00587", "submitter": "Heiko Strathmann", "authors": "Adam R. Kosiorek, Heiko Strathmann, Daniel Zoran, Pol Moreno, Rosalia\n  Schneider, So\\v{n}a Mokr\\'a, Danilo J. Rezende", "title": "NeRF-VAE: A Geometry Aware 3D Scene Generative Model", "comments": "17 pages, 15 figures, under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose NeRF-VAE, a 3D scene generative model that incorporates geometric\nstructure via NeRF and differentiable volume rendering. In contrast to NeRF,\nour model takes into account shared structure across scenes, and is able to\ninfer the structure of a novel scene -- without the need to re-train -- using\namortized inference. NeRF-VAE's explicit 3D rendering process further contrasts\nprevious generative models with convolution-based rendering which lacks\ngeometric structure. Our model is a VAE that learns a distribution over\nradiance fields by conditioning them on a latent scene representation. We show\nthat, once trained, NeRF-VAE is able to infer and render\ngeometrically-consistent scenes from previously unseen 3D environments using\nvery few input images. We further demonstrate that NeRF-VAE generalizes well to\nout-of-distribution cameras, while convolutional models do not. Finally, we\nintroduce and study an attention-based conditioning mechanism of NeRF-VAE's\ndecoder, which improves model performance.\n", "versions": [{"version": "v1", "created": "Thu, 1 Apr 2021 16:16:31 GMT"}], "update_date": "2021-04-02", "authors_parsed": [["Kosiorek", "Adam R.", ""], ["Strathmann", "Heiko", ""], ["Zoran", "Daniel", ""], ["Moreno", "Pol", ""], ["Schneider", "Rosalia", ""], ["Mokr\u00e1", "So\u0148a", ""], ["Rezende", "Danilo J.", ""]]}, {"id": "2104.00606", "submitter": "Jessica Zosa Forde", "authors": "Jessica Zosa Forde, A. Feder Cooper, Kweku Kwegyir-Aggrey, Chris De Sa\n  and Michael Littman", "title": "Model Selection's Disparate Impact in Real-World Deep Learning\n  Applications", "comments": "Accepted to the Science and Engineering of Deep Learning Workshop,\n  ICLR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Algorithmic fairness has emphasized the role of biased data in automated\ndecision outcomes. Recently, there has been a shift in attention to sources of\nbias that implicate fairness in other stages in the ML pipeline. We contend\nthat one source of such bias, human preferences in model selection, remains\nunder-explored in terms of its role in disparate impact across demographic\ngroups. Using a deep learning model trained on real-world medical imaging data,\nwe verify our claim empirically and argue that choice of metric for model\ncomparison can significantly bias model selection outcomes.\n", "versions": [{"version": "v1", "created": "Thu, 1 Apr 2021 16:37:01 GMT"}], "update_date": "2021-04-02", "authors_parsed": [["Forde", "Jessica Zosa", ""], ["Cooper", "A. Feder", ""], ["Kwegyir-Aggrey", "Kweku", ""], ["De Sa", "Chris", ""], ["Littman", "Michael", ""]]}, {"id": "2104.00615", "submitter": "Roman Popovych", "authors": "Alex Bihlo and Roman O. Popovych", "title": "Physics-informed neural networks for the shallow-water equations on the\n  sphere", "comments": "20 pages, 7 figures, 3 tables, minor corrections", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.comp-ph cs.AI cs.LG cs.NA math.NA physics.ao-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose the use of physics-informed neural networks for solving the\nshallow-water equations on the sphere. Physics-informed neural networks are\ntrained to satisfy the differential equations along with the prescribed initial\nand boundary data, and thus can be seen as an alternative approach to solving\ndifferential equations compared to traditional numerical approaches such as\nfinite difference, finite volume or spectral methods. We discuss the training\ndifficulties of physics-informed neural networks for the shallow-water\nequations on the sphere and propose a simple multi-model approach to tackle\ntest cases of comparatively long time intervals. We illustrate the abilities of\nthe method by solving the most prominent test cases proposed by Williamson et\nal. [J. Comput. Phys. 102, 211-224, 1992].\n", "versions": [{"version": "v1", "created": "Thu, 1 Apr 2021 16:47:40 GMT"}, {"version": "v2", "created": "Tue, 20 Apr 2021 07:31:22 GMT"}], "update_date": "2021-04-21", "authors_parsed": [["Bihlo", "Alex", ""], ["Popovych", "Roman O.", ""]]}, {"id": "2104.00620", "submitter": "Karush Suri", "authors": "Karush Suri, Xiao Qi Shi, Konstantinos Plataniotis, Yuri Lawryshyn", "title": "TradeR: Practical Deep Hierarchical Reinforcement Learning for Trade\n  Execution", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.TR cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Advances in Reinforcement Learning (RL) span a wide variety of applications\nwhich motivate development in this area. While application tasks serve as\nsuitable benchmarks for real world problems, RL is seldomly used in practical\nscenarios consisting of abrupt dynamics. This allows one to rethink the problem\nsetup in light of practical challenges. We present Trade Execution using\nReinforcement Learning (TradeR) which aims to address two such practical\nchallenges of catastrophy and surprise minimization by formulating trading as a\nreal-world hierarchical RL problem. Through this lens, TradeR makes use of\nhierarchical RL to execute trade bids on high frequency real market experiences\ncomprising of abrupt price variations during the 2019 fiscal year COVID19 stock\nmarket crash. The framework utilizes an energy-based scheme in conjunction with\nsurprise value function for estimating and minimizing surprise. In a\nlarge-scale study of 35 stock symbols from the S&P500 index, TradeR\ndemonstrates robustness to abrupt price changes and catastrophic losses while\nmaintaining profitable outcomes. We hope that our work serves as a motivating\nexample for application of RL to practical problems.\n", "versions": [{"version": "v1", "created": "Tue, 16 Feb 2021 19:52:52 GMT"}], "update_date": "2021-04-02", "authors_parsed": [["Suri", "Karush", ""], ["Shi", "Xiao Qi", ""], ["Plataniotis", "Konstantinos", ""], ["Lawryshyn", "Yuri", ""]]}, {"id": "2104.00624", "submitter": "Minsu Kang", "authors": "Minsu Kang, Jihyun Lee, Simin Kim and Injung Kim", "title": "Fast DCTTS: Efficient Deep Convolutional Text-to-Speech", "comments": "5 pages, 1 figure, to be published in IEEE International Conference\n  on Acoustics, Speech and Signal Processing (ICASSP) 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose an end-to-end speech synthesizer, Fast DCTTS, that synthesizes\nspeech in real time on a single CPU thread. The proposed model is composed of a\ncarefully-tuned lightweight network designed by applying multiple network\nreduction and fidelity improvement techniques. In addition, we propose a novel\ngroup highway activation that can compromise between computational efficiency\nand the regularization effect of the gating mechanism. As well, we introduce a\nnew metric called Elastic mel-cepstral distortion (EMCD) to measure the\nfidelity of the output mel-spectrogram. In experiments, we analyze the effect\nof the acceleration techniques on speed and speech quality. Compared with the\nbaseline model, the proposed model exhibits improved MOS from 2.62 to 2.74 with\nonly 1.76% computation and 2.75% parameters. The speed on a single CPU thread\nwas improved by 7.45 times, which is fast enough to produce mel-spectrogram in\nreal time without GPU.\n", "versions": [{"version": "v1", "created": "Thu, 1 Apr 2021 17:08:01 GMT"}], "update_date": "2021-04-02", "authors_parsed": [["Kang", "Minsu", ""], ["Lee", "Jihyun", ""], ["Kim", "Simin", ""], ["Kim", "Injung", ""]]}, {"id": "2104.00629", "submitter": "Florian Pargent", "authors": "Florian Pargent, Florian Pfisterer, Janek Thomas, Bernd Bischl", "title": "Regularized target encoding outperforms traditional methods in\n  supervised machine learning with high cardinality features", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Because most machine learning (ML) algorithms are designed for numerical\ninputs, efficiently encoding categorical variables is a crucial aspect during\ndata analysis. An often encountered problem are high cardinality features, i.e.\nunordered categorical predictor variables with a high number of levels. We\nstudy techniques that yield numeric representations of categorical variables\nwhich can then be used in subsequent ML applications. We focus on the impact of\nthose techniques on a subsequent algorithm's predictive performance, and -- if\npossible -- derive best practices on when to use which technique. We conducted\na large-scale benchmark experiment, where we compared different encoding\nstrategies together with five ML algorithms (lasso, random forest, gradient\nboosting, k-nearest neighbours, support vector machine) using datasets from\nregression, binary- and multiclass- classification settings. Throughout our\nstudy, regularized versions of target encoding (i.e. using target predictions\nbased on the feature levels in the training set as a new numerical feature)\nconsistently provided the best results. Traditional encodings that make\nunreasonable assumptions to map levels to integers (e.g. integer encoding) or\nto reduce the number of levels (possibly based on target information, e.g. leaf\nencoding) before creating binary indicator variables (one-hot or dummy\nencoding) were not as effective.\n", "versions": [{"version": "v1", "created": "Thu, 1 Apr 2021 17:21:42 GMT"}], "update_date": "2021-04-02", "authors_parsed": [["Pargent", "Florian", ""], ["Pfisterer", "Florian", ""], ["Thomas", "Janek", ""], ["Bischl", "Bernd", ""]]}, {"id": "2104.00631", "submitter": "Joshua Gruenstein", "authors": "Joshua Gruenstein, Tao Chen, Neel Doshi, Pulkit Agrawal", "title": "Residual Model Learning for Microrobot Control", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG cs.SY eess.SY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A majority of microrobots are constructed using compliant materials that are\ndifficult to model analytically, limiting the utility of traditional\nmodel-based controllers. Challenges in data collection on microrobots and large\nerrors between simulated models and real robots make current model-based\nlearning and sim-to-real transfer methods difficult to apply. We propose a\nnovel framework residual model learning (RML) that leverages approximate models\nto substantially reduce the sample complexity associated with learning an\naccurate robot model. We show that using RML, we can learn a model of the\nHarvard Ambulatory MicroRobot (HAMR) using just 12 seconds of passively\ncollected interaction data. The learned model is accurate enough to be\nleveraged as \"proxy-simulator\" for learning walking and turning behaviors using\nmodel-free reinforcement learning algorithms. RML provides a general framework\nfor learning from extremely small amounts of interaction data, and our\nexperiments with HAMR clearly demonstrate that RML substantially outperforms\nexisting techniques.\n", "versions": [{"version": "v1", "created": "Thu, 1 Apr 2021 17:22:50 GMT"}], "update_date": "2021-04-02", "authors_parsed": [["Gruenstein", "Joshua", ""], ["Chen", "Tao", ""], ["Doshi", "Neel", ""], ["Agrawal", "Pulkit", ""]]}, {"id": "2104.00635", "submitter": "Michael Platzer", "authors": "Michael Platzer and Thomas Reutterer", "title": "Holdout-Based Fidelity and Privacy Assessment of Mixed-Type Synthetic\n  Data", "comments": "12 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  AI-based data synthesis has seen rapid progress over the last several years,\nand is increasingly recognized for its promise to enable privacy-respecting\nhigh-fidelity data sharing. However, adequately evaluating the quality of\ngenerated synthetic datasets is still an open challenge. We introduce and\ndemonstrate a holdout-based empirical assessment framework for quantifying the\nfidelity as well as the privacy risk of synthetic data solutions for mixed-type\ntabular data. Measuring fidelity is based on statistical distances of\nlower-dimensional marginal distributions, which provide a model-free and\neasy-to-communicate empirical metric for the representativeness of a synthetic\ndataset. Privacy risk is assessed by calculating the individual-level distances\nto closest record with respect to the training data. By showing that the\nsynthetic samples are just as close to the training as to the holdout data, we\nyield strong evidence that the synthesizer indeed learned to generalize\npatterns and is independent of individual training records. We demonstrate the\npresented framework for seven distinct synthetic data solutions across four\nmixed-type datasets and compare these to more traditional statistical\ndisclosure techniques. The results highlight the need to systematically assess\nthe fidelity just as well as the privacy of these emerging class of synthetic\ndata generators.\n", "versions": [{"version": "v1", "created": "Thu, 1 Apr 2021 17:30:23 GMT"}], "update_date": "2021-04-02", "authors_parsed": [["Platzer", "Michael", ""], ["Reutterer", "Thomas", ""]]}, {"id": "2104.00641", "submitter": "Youngser Park", "authors": "Jonathan Larson, Tiona Zuzul, Emily Cox Pahnke, Neha Parikh Shah,\n  Patrick Bourke, Nicholas Caurvina, Fereshteh Amini, Youngser Park, Joshua\n  Vogelstein, Jeffrey Weston, Christopher White, and Carey E. Priebe", "title": "Dynamic Silos: Modularity in intra-organizational communication networks\n  during the Covid-19 pandemic", "comments": "19 pages, 15 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Workplace communications around the world were drastically altered by\nCovid-19, work-from-home orders, and the rise of remote work. We analyze\naggregated, anonymized metadata from over 360 billion emails within over 4000\norganizations worldwide to examine changes in network community structures from\n2019 through 2020. We find that, during 2020, organizations around the world\nbecame more siloed, evidenced by increased modularity. This shift was\nconcurrent with decreased stability, indicating that organizational siloes had\nless stable membership. We provide initial insights into the implications of\nthese network changes -- which we term dynamic silos -- for organizational\nperformance and innovation.\n", "versions": [{"version": "v1", "created": "Thu, 1 Apr 2021 17:40:21 GMT"}, {"version": "v2", "created": "Wed, 7 Apr 2021 17:41:35 GMT"}, {"version": "v3", "created": "Sat, 1 May 2021 19:54:47 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Larson", "Jonathan", ""], ["Zuzul", "Tiona", ""], ["Pahnke", "Emily Cox", ""], ["Shah", "Neha Parikh", ""], ["Bourke", "Patrick", ""], ["Caurvina", "Nicholas", ""], ["Amini", "Fereshteh", ""], ["Park", "Youngser", ""], ["Vogelstein", "Joshua", ""], ["Weston", "Jeffrey", ""], ["White", "Christopher", ""], ["Priebe", "Carey E.", ""]]}, {"id": "2104.00664", "submitter": "Vil\\'em Zouhar", "authors": "Vil\\'em Zouhar", "title": "Sampling and Filtering of Neural Machine Translation Distillation Data", "comments": "6 pages (without references); to be published in NAACL-SRW", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In most of neural machine translation distillation or stealing scenarios, the\ngoal is to preserve the performance of the target model (teacher). The\nhighest-scoring hypothesis of the teacher model is commonly used to train a new\nmodel (student). If reference translations are also available, then better\nhypotheses (with respect to the references) can be upsampled and poor\nhypotheses either removed or undersampled.\n  This paper explores the importance sampling method landscape (pruning,\nhypothesis upsampling and undersampling, deduplication and their combination)\nwith English to Czech and English to German MT models using standard MT\nevaluation metrics. We show that careful upsampling and combination with the\noriginal data leads to better performance when compared to training only on the\noriginal or synthesized data or their direct combination.\n", "versions": [{"version": "v1", "created": "Thu, 1 Apr 2021 17:54:52 GMT"}], "update_date": "2021-04-02", "authors_parsed": [["Zouhar", "Vil\u00e9m", ""]]}, {"id": "2104.00669", "submitter": "Nima Hatami", "authors": "Nima Hatami and Mohsin Bilal and Nasir Rajpoot", "title": "Deep Multi-Resolution Dictionary Learning for Histopathology Image\n  Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The problem of recognizing various types of tissues present in\nmulti-gigapixel histology images is an important fundamental pre-requisite for\ndownstream analysis of the tumor microenvironment in a bottom-up analysis\nparadigm for computational pathology. In this paper, we propose a deep\ndictionary learning approach to solve the problem of tissue phenotyping in\nhistology images. We propose deep Multi-Resolution Dictionary Learning\n(deepMRDL) in order to benefit from deep texture descriptors at multiple\ndifferent spatial resolutions. We show the efficacy of the proposed approach\nthrough extensive experiments on four benchmark histology image datasets from\ndifferent organs (colorectal cancer, breast cancer and breast lymphnodes) and\ntasks (namely, cancer grading, tissue phenotyping, tumor detection and tissue\ntype classification). We also show that the proposed framework can employ most\noff-the-shelf CNNs models to generate effective deep texture descriptors.\n", "versions": [{"version": "v1", "created": "Thu, 1 Apr 2021 17:58:18 GMT"}], "update_date": "2021-04-02", "authors_parsed": [["Hatami", "Nima", ""], ["Bilal", "Mohsin", ""], ["Rajpoot", "Nasir", ""]]}, {"id": "2104.00670", "submitter": "Miguel \\'Angel Bautista Martin", "authors": "Terrance DeVries, Miguel Angel Bautista, Nitish Srivastava, Graham W.\n  Taylor, Joshua M. Susskind", "title": "Unconstrained Scene Generation with Locally Conditioned Radiance Fields", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We tackle the challenge of learning a distribution over complex, realistic,\nindoor scenes. In this paper, we introduce Generative Scene Networks (GSN),\nwhich learns to decompose scenes into a collection of many local radiance\nfields that can be rendered from a free moving camera. Our model can be used as\na prior to generate new scenes, or to complete a scene given only sparse 2D\nobservations. Recent work has shown that generative models of radiance fields\ncan capture properties such as multi-view consistency and view-dependent\nlighting. However, these models are specialized for constrained viewing of\nsingle objects, such as cars or faces. Due to the size and complexity of\nrealistic indoor environments, existing models lack the representational\ncapacity to adequately capture them. Our decomposition scheme scales to larger\nand more complex scenes while preserving details and diversity, and the learned\nprior enables high-quality rendering from viewpoints that are significantly\ndifferent from observed viewpoints. When compared to existing models, GSN\nproduces quantitatively higher-quality scene renderings across several\ndifferent scene datasets.\n", "versions": [{"version": "v1", "created": "Thu, 1 Apr 2021 17:58:26 GMT"}], "update_date": "2021-04-02", "authors_parsed": [["DeVries", "Terrance", ""], ["Bautista", "Miguel Angel", ""], ["Srivastava", "Nitish", ""], ["Taylor", "Graham W.", ""], ["Susskind", "Joshua M.", ""]]}, {"id": "2104.00671", "submitter": "Zhuolin Yang", "authors": "Zhuolin Yang, Linyi Li, Xiaojun Xu, Shiliang Zuo, Qian Chen, Benjamin\n  Rubinstein, Ce Zhang, Bo Li", "title": "TRS: Transferability Reduced Ensemble via Encouraging Gradient Diversity\n  and Model Smoothness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial Transferability is an intriguing property of adversarial examples\n-- a perturbation that is crafted against one model is also effective against\nanother model, which may arise from a different model family or training\nprocess. To better protect ML systems against adversarial attacks, several\nquestions are raised: what are the sufficient conditions for adversarial\ntransferability? Is it possible to bound such transferability? Is there a way\nto reduce the transferability in order to improve the robustness of an ensemble\nML model? To answer these questions, we first theoretically analyze sufficient\nconditions for transferability between models and propose a practical algorithm\nto reduce transferability within an ensemble to improve its robustness. Our\ntheoretical analysis shows only the orthogonality between gradients of\ndifferent models is not enough to ensure low adversarial transferability: the\nmodel smoothness is also an important factor. In particular, we provide a\nlower/upper bound of adversarial transferability based on model gradient\nsimilarity for low risk classifiers based on gradient orthogonality and model\nsmoothness. We demonstrate that under the condition of gradient orthogonality,\nsmoother classifiers will guarantee lower adversarial transferability.\nFurthermore, we propose an effective Transferability Reduced\nSmooth-ensemble(TRS) training strategy to train a robust ensemble with low\ntransferability by enforcing model smoothness and gradient orthogonality\nbetween base models. We conduct extensive experiments on TRS by comparing with\nother state-of-the-art baselines on different datasets, showing that the\nproposed TRS outperforms all baselines significantly. We believe our analysis\non adversarial transferability will inspire future research towards developing\nrobust ML models taking these adversarial transferability properties into\naccount.\n", "versions": [{"version": "v1", "created": "Thu, 1 Apr 2021 17:58:35 GMT"}], "update_date": "2021-04-02", "authors_parsed": [["Yang", "Zhuolin", ""], ["Li", "Linyi", ""], ["Xu", "Xiaojun", ""], ["Zuo", "Shiliang", ""], ["Chen", "Qian", ""], ["Rubinstein", "Benjamin", ""], ["Zhang", "Ce", ""], ["Li", "Bo", ""]]}, {"id": "2104.00676", "submitter": "Zhiqiang Shen", "authors": "Zhiqiang Shen and Zechun Liu and Dejia Xu and Zitian Chen and\n  Kwang-Ting Cheng and Marios Savvides", "title": "Is Label Smoothing Truly Incompatible with Knowledge Distillation: An\n  Empirical Study", "comments": "ICLR 2021. Project page:\n  http://zhiqiangshen.com/projects/LS_and_KD/index.html", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work aims to empirically clarify a recently discovered perspective that\nlabel smoothing is incompatible with knowledge distillation. We begin by\nintroducing the motivation behind on how this incompatibility is raised, i.e.,\nlabel smoothing erases relative information between teacher logits. We provide\na novel connection on how label smoothing affects distributions of semantically\nsimilar and dissimilar classes. Then we propose a metric to quantitatively\nmeasure the degree of erased information in sample's representation. After\nthat, we study its one-sidedness and imperfection of the incompatibility view\nthrough massive analyses, visualizations and comprehensive experiments on Image\nClassification, Binary Networks, and Neural Machine Translation. Finally, we\nbroadly discuss several circumstances wherein label smoothing will indeed lose\nits effectiveness. Project page:\nhttp://zhiqiangshen.com/projects/LS_and_KD/index.html.\n", "versions": [{"version": "v1", "created": "Thu, 1 Apr 2021 17:59:12 GMT"}], "update_date": "2021-04-02", "authors_parsed": [["Shen", "Zhiqiang", ""], ["Liu", "Zechun", ""], ["Xu", "Dejia", ""], ["Chen", "Zitian", ""], ["Cheng", "Kwang-Ting", ""], ["Savvides", "Marios", ""]]}, {"id": "2104.00677", "submitter": "Ajay Jain", "authors": "Ajay Jain and Matthew Tancik and Pieter Abbeel", "title": "Putting NeRF on a Diet: Semantically Consistent Few-Shot View Synthesis", "comments": "Project website: https://www.ajayj.com/dietnerf", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.GR cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  We present DietNeRF, a 3D neural scene representation estimated from a few\nimages. Neural Radiance Fields (NeRF) learn a continuous volumetric\nrepresentation of a scene through multi-view consistency, and can be rendered\nfrom novel viewpoints by ray casting. While NeRF has an impressive ability to\nreconstruct geometry and fine details given many images, up to 100 for\nchallenging 360{\\deg} scenes, it often finds a degenerate solution to its image\nreconstruction objective when only a few input views are available. To improve\nfew-shot quality, we propose DietNeRF. We introduce an auxiliary semantic\nconsistency loss that encourages realistic renderings at novel poses. DietNeRF\nis trained on individual scenes to (1) correctly render given input views from\nthe same pose, and (2) match high-level semantic attributes across different,\nrandom poses. Our semantic loss allows us to supervise DietNeRF from arbitrary\nposes. We extract these semantics using a pre-trained visual encoder such as\nCLIP, a Vision Transformer trained on hundreds of millions of diverse\nsingle-view, 2D photographs mined from the web with natural language\nsupervision. In experiments, DietNeRF improves the perceptual quality of\nfew-shot view synthesis when learned from scratch, can render novel views with\nas few as one observed image when pre-trained on a multi-view dataset, and\nproduces plausible completions of completely unobserved regions.\n", "versions": [{"version": "v1", "created": "Thu, 1 Apr 2021 17:59:31 GMT"}], "update_date": "2021-04-02", "authors_parsed": [["Jain", "Ajay", ""], ["Tancik", "Matthew", ""], ["Abbeel", "Pieter", ""]]}, {"id": "2104.00679", "submitter": "Jong-Chyi Su", "authors": "Jong-Chyi Su and Zezhou Cheng and Subhransu Maji", "title": "A Realistic Evaluation of Semi-Supervised Learning for Fine-Grained\n  Classification", "comments": "CVPR 2021 (oral)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We evaluate the effectiveness of semi-supervised learning (SSL) on a\nrealistic benchmark where data exhibits considerable class imbalance and\ncontains images from novel classes. Our benchmark consists of two fine-grained\nclassification datasets obtained by sampling classes from the Aves and Fungi\ntaxonomy. We find that recently proposed SSL methods provide significant\nbenefits, and can effectively use out-of-class data to improve performance when\ndeep networks are trained from scratch. Yet their performance pales in\ncomparison to a transfer learning baseline, an alternative approach for\nlearning from a few examples. Furthermore, in the transfer setting, while\nexisting SSL methods provide improvements, the presence of out-of-class is\noften detrimental. In this setting, standard fine-tuning followed by\ndistillation-based self-training is the most robust. Our work suggests that\nsemi-supervised learning with experts on realistic datasets may require\ndifferent strategies than those currently prevalent in the literature.\n", "versions": [{"version": "v1", "created": "Thu, 1 Apr 2021 17:59:41 GMT"}], "update_date": "2021-04-02", "authors_parsed": [["Su", "Jong-Chyi", ""], ["Cheng", "Zezhou", ""], ["Maji", "Subhransu", ""]]}, {"id": "2104.00682", "submitter": "Christoph Feichtenhofer", "authors": "Bo Xiong, Haoqi Fan, Kristen Grauman, Christoph Feichtenhofer", "title": "Multiview Pseudo-Labeling for Semi-supervised Learning from Video", "comments": "Technical report", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a multiview pseudo-labeling approach to video learning, a novel\nframework that uses complementary views in the form of appearance and motion\ninformation for semi-supervised learning in video. The complementary views help\nobtain more reliable pseudo-labels on unlabeled video, to learn stronger video\nrepresentations than from purely supervised data. Though our method capitalizes\non multiple views, it nonetheless trains a model that is shared across\nappearance and motion input and thus, by design, incurs no additional\ncomputation overhead at inference time. On multiple video recognition datasets,\nour method substantially outperforms its supervised counterpart, and compares\nfavorably to previous work on standard benchmarks in self-supervised video\nrepresentation learning.\n", "versions": [{"version": "v1", "created": "Thu, 1 Apr 2021 17:59:48 GMT"}], "update_date": "2021-04-02", "authors_parsed": [["Xiong", "Bo", ""], ["Fan", "Haoqi", ""], ["Grauman", "Kristen", ""], ["Feichtenhofer", "Christoph", ""]]}, {"id": "2104.00683", "submitter": "Ye Yuan", "authors": "Ye Yuan, Shih-En Wei, Tomas Simon, Kris Kitani, Jason Saragih", "title": "SimPoE: Simulated Character Control for 3D Human Pose Estimation", "comments": "CVPR 2021 (Oral). Project page: https://www.ye-yuan.com/simpoe/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurate estimation of 3D human motion from monocular video requires modeling\nboth kinematics (body motion without physical forces) and dynamics (motion with\nphysical forces). To demonstrate this, we present SimPoE, a Simulation-based\napproach for 3D human Pose Estimation, which integrates image-based kinematic\ninference and physics-based dynamics modeling. SimPoE learns a policy that\ntakes as input the current-frame pose estimate and the next image frame to\ncontrol a physically-simulated character to output the next-frame pose\nestimate. The policy contains a learnable kinematic pose refinement unit that\nuses 2D keypoints to iteratively refine its kinematic pose estimate of the next\nframe. Based on this refined kinematic pose, the policy learns to compute\ndynamics-based control (e.g., joint torques) of the character to advance the\ncurrent-frame pose estimate to the pose estimate of the next frame. This design\ncouples the kinematic pose refinement unit with the dynamics-based control\ngeneration unit, which are learned jointly with reinforcement learning to\nachieve accurate and physically-plausible pose estimation. Furthermore, we\npropose a meta-control mechanism that dynamically adjusts the character's\ndynamics parameters based on the character state to attain more accurate pose\nestimates. Experiments on large-scale motion datasets demonstrate that our\napproach establishes the new state of the art in pose accuracy while ensuring\nphysical plausibility.\n", "versions": [{"version": "v1", "created": "Thu, 1 Apr 2021 17:59:50 GMT"}], "update_date": "2021-04-02", "authors_parsed": [["Yuan", "Ye", ""], ["Wei", "Shih-En", ""], ["Simon", "Tomas", ""], ["Kitani", "Kris", ""], ["Saragih", "Jason", ""]]}, {"id": "2104.00706", "submitter": "Joseph Lambourne", "authors": "Joseph G. Lambourne, Karl D.D. Willis, Pradeep Kumar Jayaraman, Aditya\n  Sanghi, Peter Meltzer, Hooman Shayani", "title": "BRepNet: A topological message passing system for solid models", "comments": "CVPR 2021 Oral", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Boundary representation (B-rep) models are the standard way 3D shapes are\ndescribed in Computer-Aided Design (CAD) applications. They combine lightweight\nparametric curves and surfaces with topological information which connects the\ngeometric entities to describe manifolds. In this paper we introduce BRepNet, a\nneural network architecture designed to operate directly on B-rep data\nstructures, avoiding the need to approximate the model as meshes or point\nclouds. BRepNet defines convolutional kernels with respect to oriented coedges\nin the data structure. In the neighborhood of each coedge, a small collection\nof faces, edges and coedges can be identified and patterns in the feature\nvectors from these entities detected by specific learnable parameters. In\naddition, to encourage further deep learning research with B-reps, we publish\nthe Fusion 360 Gallery segmentation dataset. A collection of over 35,000 B-rep\nmodels annotated with information about the modeling operations which created\neach face. We demonstrate that BRepNet can segment these models with higher\naccuracy than methods working on meshes, and point clouds.\n", "versions": [{"version": "v1", "created": "Thu, 1 Apr 2021 18:16:03 GMT"}, {"version": "v2", "created": "Thu, 8 Apr 2021 14:46:06 GMT"}], "update_date": "2021-04-09", "authors_parsed": [["Lambourne", "Joseph G.", ""], ["Willis", "Karl D. D.", ""], ["Jayaraman", "Pradeep Kumar", ""], ["Sanghi", "Aditya", ""], ["Meltzer", "Peter", ""], ["Shayani", "Hooman", ""]]}, {"id": "2104.00721", "submitter": "Zaharah A. Bukhsh", "authors": "Zaharah A. Bukhsh, Aaqib Saeed, Remco M. Dijkman", "title": "ProcessTransformer: Predictive Business Process Monitoring with\n  Transformer Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Predictive business process monitoring focuses on predicting future\ncharacteristics of a running process using event logs. The foresight into\nprocess execution promises great potentials for efficient operations, better\nresource management, and effective customer services. Deep learning-based\napproaches have been widely adopted in process mining to address the\nlimitations of classical algorithms for solving multiple problems, especially\nthe next event and remaining-time prediction tasks. Nevertheless, designing a\ndeep neural architecture that performs competitively across various tasks is\nchallenging as existing methods fail to capture long-range dependencies in the\ninput sequences and perform poorly for lengthy process traces. In this paper,\nwe propose ProcessTransformer, an approach for learning high-level\nrepresentations from event logs with an attention-based network. Our model\nincorporates long-range memory and relies on a self-attention mechanism to\nestablish dependencies between a multitude of event sequences and corresponding\noutputs. We evaluate the applicability of our technique on nine real event\nlogs. We demonstrate that the transformer-based model outperforms several\nbaselines of prior techniques by obtaining on average above 80% accuracy for\nthe task of predicting the next activity. Our method also perform\ncompetitively, compared to baselines, for the tasks of predicting event time\nand remaining time of a running case\n", "versions": [{"version": "v1", "created": "Thu, 1 Apr 2021 18:58:46 GMT"}], "update_date": "2021-04-05", "authors_parsed": [["Bukhsh", "Zaharah A.", ""], ["Saeed", "Aaqib", ""], ["Dijkman", "Remco M.", ""]]}, {"id": "2104.00722", "submitter": "Avoy Datta", "authors": "Heejung W. Chung, Avoy Datta, Chris Waites", "title": "GABO: Graph Augmentations with Bi-level Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Data augmentation refers to a wide range of techniques for improving model\ngeneralization by augmenting training examples. Oftentimes such methods require\ndomain knowledge about the dataset at hand, spawning a plethora of recent\nliterature surrounding automated techniques for data augmentation. In this work\nwe apply one such method, bilevel optimization, to tackle the problem of graph\nclassification on the ogbg-molhiv dataset. Our best performing augmentation\nachieved a test ROCAUC score of 77.77 % with a GIN+virtual classifier, which\nmakes it the most effective augmenter for this classifier on the leaderboard.\nThis framework combines a GIN layer augmentation generator with a bias\ntransformation and outperforms the same classifier augmented using the\nstate-of-the-art FLAG augmentation.\n", "versions": [{"version": "v1", "created": "Thu, 1 Apr 2021 19:00:17 GMT"}], "update_date": "2021-04-05", "authors_parsed": [["Chung", "Heejung W.", ""], ["Datta", "Avoy", ""], ["Waites", "Chris", ""]]}, {"id": "2104.00732", "submitter": "Niko Br\\\"ummer", "authors": "Niko Br\\\"ummer and Luciana Ferrer and Albert Swart", "title": "Out of a hundred trials, how many errors does your speaker verifier\n  make?", "comments": "Submitted to Interspeech 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Out of a hundred trials, how many errors does your speaker verifier make? For\nthe user this is an important, practical question, but researchers and vendors\ntypically sidestep it and supply instead the conditional error-rates that are\ngiven by the ROC/DET curve. We posit that the user's question is answered by\nthe Bayes error-rate. We present a tutorial to show how to compute the\nerror-rate that results when making Bayes decisions with calibrated likelihood\nratios, supplied by the verifier, and an hypothesis prior, supplied by the\nuser. For perfect calibration, the Bayes error-rate is upper bounded by\nmin(EER,P,1-P), where EER is the equal-error-rate and P, 1-P are the prior\nprobabilities of the competing hypotheses. The EER represents the accuracy of\nthe verifier, while min(P,1-P) represents the hardness of the classification\nproblem. We further show how the Bayes error-rate can be computed also for\nnon-perfect calibration and how to generalize from error-rate to expected cost.\nWe offer some criticism of decisions made by direct score thresholding.\nFinally, we demonstrate by analyzing error-rates of the recently published\nDCA-PLDA speaker verifier.\n", "versions": [{"version": "v1", "created": "Thu, 1 Apr 2021 19:10:48 GMT"}], "update_date": "2021-04-05", "authors_parsed": [["Br\u00fcmmer", "Niko", ""], ["Ferrer", "Luciana", ""], ["Swart", "Albert", ""]]}, {"id": "2104.00734", "submitter": "Juliano Tusi Amaral Lagana Pinto", "authors": "Juliano Pinto, Georg Hess, William Ljungbergh, Yuxuan Xia, Lennart\n  Svensson, Henk Wymeersch", "title": "Next Generation Multitarget Trackers: Random Finite Set Methods vs\n  Transformer-based Deep Learning", "comments": "8 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multitarget Tracking (MTT) is the problem of tracking the states of an\nunknown number of objects using noisy measurements, with important applications\nto autonomous driving, surveillance, robotics, and others. In the model-based\nBayesian setting, there are conjugate priors that enable us to express the\nmulti-object posterior in closed form, which could theoretically provide\nBayes-optimal estimates. However, the posterior involves a super-exponential\ngrowth of the number of hypotheses over time, forcing state-of-the-art methods\nto resort to approximations for remaining tractable, which can impact their\nperformance in complex scenarios. Model-free methods based on deep-learning\nprovide an attractive alternative, as they can, in principle, learn the optimal\nfilter from data, but to the best of our knowledge were never compared to\ncurrent state-of-the-art Bayesian filters, specially not in contexts where\naccurate models are available. In this paper, we propose a high-performing\ndeep-learning method for MTT based on the Transformer architecture and compare\nit to two state-of-the-art Bayesian filters, in a setting where we assume the\ncorrect model is provided. Although this gives an edge to the model-based\nfilters, it also allows us to generate unlimited training data. We show that\nthe proposed model outperforms state-of-the-art Bayesian filters in complex\nscenarios, while matching their performance in simpler cases, which validates\nthe applicability of deep-learning also in the model-based regime. The code for\nall our implementations is made available at\nhttps://github.com/JulianoLagana/MT3 .\n", "versions": [{"version": "v1", "created": "Thu, 1 Apr 2021 19:14:55 GMT"}, {"version": "v2", "created": "Fri, 9 Apr 2021 12:43:46 GMT"}, {"version": "v3", "created": "Fri, 4 Jun 2021 08:48:19 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["Pinto", "Juliano", ""], ["Hess", "Georg", ""], ["Ljungbergh", "William", ""], ["Xia", "Yuxuan", ""], ["Svensson", "Lennart", ""], ["Wymeersch", "Henk", ""]]}, {"id": "2104.00735", "submitter": "K\\\"ur\\c{s}at Tekb{\\i}y{\\i}k", "authors": "K\\\"ur\\c{s}at Tekb{\\i}y{\\i}k, G\\\"une\\c{s} Karabulut Kurt, Ali R{\\i}za\n  Ekti, Halim Yanikomeroglu", "title": "Graph Attention Networks for Channel Estimation in RIS-assisted\n  Satellite IoT Communications", "comments": "9 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG eess.SP", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Direct-to-satellite (DtS) communication has gained importance recently to\nsupport globally connected Internet of things (IoT) networks. However,\nrelatively long distances of densely deployed satellite networks around the\nEarth cause a high path loss. In addition, since high complexity operations\nsuch as beamforming, tracking and equalization have to be performed in IoT\ndevices partially, both the hardware complexity and the need for high-capacity\nbatteries of IoT devices increase. The reconfigurable intelligent surfaces\n(RISs) have the potential to increase the energy-efficiency and to perform\ncomplex signal processing over the transmission environment instead of IoT\ndevices. But, RISs need the information of the cascaded channel in order to\nchange the phase of the incident signal. This study proposes graph attention\nnetworks (GATs) for the challenging channel estimation problem and examines the\nperformance of DtS IoT networks for different RIS configurations under GAT\nchannel estimation.\n", "versions": [{"version": "v1", "created": "Thu, 1 Apr 2021 19:15:04 GMT"}], "update_date": "2021-04-05", "authors_parsed": [["Tekb\u0131y\u0131k", "K\u00fcr\u015fat", ""], ["Kurt", "G\u00fcne\u015f Karabulut", ""], ["Ekti", "Ali R\u0131za", ""], ["Yanikomeroglu", "Halim", ""]]}, {"id": "2104.00739", "submitter": "Gopal P. Sarma", "authors": "Gopal Sarma, James Koppel, Gregory Malecha, Patrick Schultz, Eric\n  Drexler, Ramana Kumar, Cody Roux, and Philip Zucker", "title": "Formal Methods for the Informal Engineer: Workshop Recommendations", "comments": "6 pages", "journal-ref": null, "doi": "10.31219/osf.io/t4qs8", "report-no": null, "categories": "cs.SE cs.AI cs.LG cs.PL q-bio.OT", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Formal Methods for the Informal Engineer (FMIE) was a workshop held at the\nBroad Institute of MIT and Harvard in 2021 to explore the potential role of\nverified software in the biomedical software ecosystem. The motivation for\norganizing FMIE was the recognition that the life sciences and medicine are\nundergoing a transition from being passive consumers of software and AI/ML\ntechnologies to fundamental drivers of new platforms, including those which\nwill need to be mission and safety-critical. Drawing on conversations leading\nup to and during the workshop, we make five concrete recommendations to help\nsoftware leaders organically incorporate tools, techniques, and perspectives\nfrom formal methods into their project planning and development trajectories.\n", "versions": [{"version": "v1", "created": "Thu, 1 Apr 2021 19:22:42 GMT"}], "update_date": "2021-04-05", "authors_parsed": [["Sarma", "Gopal", ""], ["Koppel", "James", ""], ["Malecha", "Gregory", ""], ["Schultz", "Patrick", ""], ["Drexler", "Eric", ""], ["Kumar", "Ramana", ""], ["Roux", "Cody", ""], ["Zucker", "Philip", ""]]}, {"id": "2104.00742", "submitter": "Yunye Gong", "authors": "Yunye Gong, Xiao Lin, Yi Yao, Thomas G. Dietterich, Ajay Divakaran,\n  Melinda Gervasio", "title": "Confidence Calibration for Domain Generalization under Covariate Shift", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing calibration algorithms address the problem of covariate shift via\nunsupervised domain adaptation. However, these methods suffer from the\nfollowing limitations: 1) they require unlabeled data from the target domain,\nwhich may not be available at the stage of calibration in real-world\napplications and 2) their performances heavily depend on the disparity between\nthe distributions of the source and target domains. To address these two\nlimitations, we present novel calibration solutions via domain generalization\nwhich, to the best of our knowledge, are the first of their kind. Our core idea\nis to leverage multiple calibration domains to reduce the effective\ndistribution disparity between the target and calibration domains for improved\ncalibration transfer without needing any data from the target domain. We\nprovide theoretical justification and empirical experimental results to\ndemonstrate the effectiveness of our proposed algorithms. Compared against the\nstate-of-the-art calibration methods designed for domain adaptation, we observe\na decrease of 8.86 percentage points in expected calibration error,\nequivalently an increase of 35 percentage points in improvement ratio, for\nmulti-class classification on the Office-Home dataset.\n", "versions": [{"version": "v1", "created": "Thu, 1 Apr 2021 19:31:54 GMT"}], "update_date": "2021-04-05", "authors_parsed": [["Gong", "Yunye", ""], ["Lin", "Xiao", ""], ["Yao", "Yi", ""], ["Dietterich", "Thomas G.", ""], ["Divakaran", "Ajay", ""], ["Gervasio", "Melinda", ""]]}, {"id": "2104.00743", "submitter": "Tanmay Gupta", "authors": "Tanmay Gupta, Amita Kamath, Aniruddha Kembhavi and Derek Hoiem", "title": "Towards General Purpose Vision Systems", "comments": "Project page: https://prior.allenai.org/projects/gpv", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A special purpose learning system assumes knowledge of admissible tasks at\ndesign time. Adapting such a system to unforeseen tasks requires architecture\nmanipulation such as adding an output head for each new task or dataset. In\nthis work, we propose a task-agnostic vision-language system that accepts an\nimage and a natural language task description and outputs bounding boxes,\nconfidences, and text. The system supports a wide range of vision tasks such as\nclassification, localization, question answering, captioning, and more. We\nevaluate the system's ability to learn multiple skills simultaneously, to\nperform tasks with novel skill-concept combinations, and to learn new skills\nefficiently and without forgetting.\n", "versions": [{"version": "v1", "created": "Thu, 1 Apr 2021 19:35:21 GMT"}], "update_date": "2021-04-05", "authors_parsed": [["Gupta", "Tanmay", ""], ["Kamath", "Amita", ""], ["Kembhavi", "Aniruddha", ""], ["Hoiem", "Derek", ""]]}, {"id": "2104.00746", "submitter": "Junde Li", "authors": "Junde Li, Mahabubul Alam, Congzhou M Sha, Jian Wang, Nikolay V.\n  Dokholyan, Swaroop Ghosh", "title": "Drug Discovery Approaches using Quantum Machine Learning", "comments": "Li and Alam contributed equally to this work. arXiv admin note: text\n  overlap with arXiv:2101.03438", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.ET cs.LG quant-ph", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Traditional drug discovery pipeline takes several years and cost billions of\ndollars. Deep generative and predictive models are widely adopted to assist in\ndrug development. Classical machines cannot efficiently produce atypical\npatterns of quantum computers which might improve the training quality of\nlearning tasks. We propose a suite of quantum machine learning techniques e.g.,\ngenerative adversarial network (GAN), convolutional neural network (CNN) and\nvariational auto-encoder (VAE) to generate small drug molecules, classify\nbinding pockets in proteins, and generate large drug molecules, respectively.\n", "versions": [{"version": "v1", "created": "Thu, 1 Apr 2021 19:53:06 GMT"}], "update_date": "2021-04-05", "authors_parsed": [["Li", "Junde", ""], ["Alam", "Mahabubul", ""], ["Sha", "Congzhou M", ""], ["Wang", "Jian", ""], ["Dokholyan", "Nikolay V.", ""], ["Ghosh", "Swaroop", ""]]}, {"id": "2104.00749", "submitter": "Zhuang Liu", "authors": "Zhuang Liu, Trevor Darrell, Evan Shelhamer", "title": "Confidence Adaptive Anytime Pixel-Level Recognition", "comments": "16 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Anytime inference requires a model to make a progression of predictions which\nmight be halted at any time. Prior research on anytime visual recognition has\nmostly focused on image classification. We propose the first unified and\nend-to-end model approach for anytime pixel-level recognition. A cascade of\n\"exits\" is attached to the model to make multiple predictions and direct\nfurther computation. We redesign the exits to account for the depth and spatial\nresolution of the features for each exit. To reduce total computation, and make\nfull use of prior predictions, we develop a novel spatially adaptive approach\nto avoid further computation on regions where early predictions are already\nsufficiently confident. Our full model with redesigned exit architecture and\nspatial adaptivity enables anytime inference, achieves the same level of final\naccuracy, and even significantly reduces total computation. We evaluate our\napproach on semantic segmentation and human pose estimation. On Cityscapes\nsemantic segmentation and MPII human pose estimation, our approach enables\nanytime inference while also reducing the total FLOPs of its base models by\n44.4% and 59.1% without sacrificing accuracy. As a new anytime baseline, we\nmeasure the anytime capability of deep equilibrium networks, a recent class of\nmodel that is intrinsically iterative, and we show that the\naccuracy-computation curve of our architecture strictly dominates it.\n", "versions": [{"version": "v1", "created": "Thu, 1 Apr 2021 20:01:57 GMT"}], "update_date": "2021-04-05", "authors_parsed": [["Liu", "Zhuang", ""], ["Darrell", "Trevor", ""], ["Shelhamer", "Evan", ""]]}, {"id": "2104.00751", "submitter": "Silvija Kokalj-Filipovic", "authors": "Silvija Kokalj-Filipovic, Paul Toliver, William Johnson, Rob Miller", "title": "Reservoir-Based Distributed Machine Learning for Edge Operation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE eess.SP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We introduce a novel design for in-situ training of machine learning\nalgorithms built into smart sensors, and illustrate distributed training\nscenarios using radio frequency (RF) spectrum sensors. Current RF sensors at\nthe Edge lack the computational resources to support practical, in-situ\ntraining for intelligent signal classification. We propose a solution using\nDeepdelay Loop Reservoir Computing (DLR), a processing architecture that\nsupports machine learning algorithms on resource-constrained edge-devices by\nleveraging delayloop reservoir computing in combination with innovative\nhardware. DLR delivers reductions in form factor, hardware complexity and\nlatency, compared to the State-ofthe- Art (SoA) neural nets. We demonstrate DLR\nfor two applications: RF Specific Emitter Identification (SEI) and wireless\nprotocol recognition. DLR enables mobile edge platforms to authenticate and\nthen track emitters with fast SEI retraining. Once delay loops separate the\ndata classes, traditionally complex, power-hungry classification models are no\nlonger needed for the learning process. Yet, even with simple classifiers such\nas Ridge Regression (RR), the complexity grows at least quadratically with the\ninput size. DLR with a RR classifier exceeds the SoA accuracy, while further\nreducing power consumption by leveraging the architecture of parallel (split)\nloops. To authenticate mobile devices across large regions, DLR can be trained\nin a distributed fashion with very little additional processing and a small\ncommunication cost, all while maintaining accuracy. We illustrate how to merge\nlocally trained DLR classifiers in use cases of interest.\n", "versions": [{"version": "v1", "created": "Thu, 1 Apr 2021 20:06:40 GMT"}], "update_date": "2021-04-05", "authors_parsed": [["Kokalj-Filipovic", "Silvija", ""], ["Toliver", "Paul", ""], ["Johnson", "William", ""], ["Miller", "Rob", ""]]}, {"id": "2104.00755", "submitter": "Andre Martins", "authors": "Andr\\'e F. T. Martins", "title": "Reconciling the Discrete-Continuous Divide: Towards a Mathematical\n  Theory of Sparse Communication", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks and other machine learning models compute continuous\nrepresentations, while humans communicate with discrete symbols. Reconciling\nthese two forms of communication is desirable to generate human-readable\ninterpretations or to learn discrete latent variable models, while maintaining\nend-to-end differentiability. Some existing approaches (such as the\nGumbel-softmax transformation) build continuous relaxations that are discrete\napproximations in the zero-temperature limit, while others (such as sparsemax\ntransformations and the hard concrete distribution) produce discrete/continuous\nhybrids. In this paper, we build rigorous theoretical foundations for these\nhybrids. Our starting point is a new \"direct sum\" base measure defined on the\nface lattice of the probability simplex. From this measure, we introduce a new\nentropy function that includes the discrete and differential entropies as\nparticular cases, and has an interpretation in terms of code optimality, as\nwell as two other information-theoretic counterparts that generalize the mutual\ninformation and Kullback-Leibler divergences. Finally, we introduce \"mixed\nlanguages\" as strings of hybrid symbols and a new mixed weighted finite state\nautomaton that recognizes a class of regular mixed languages, generalizing\nclosure properties of regular languages.\n", "versions": [{"version": "v1", "created": "Thu, 1 Apr 2021 20:31:13 GMT"}], "update_date": "2021-04-05", "authors_parsed": [["Martins", "Andr\u00e9 F. T.", ""]]}, {"id": "2104.00765", "submitter": "Julien Aligon", "authors": "Gabriel Ferrettini (1), Elodie Escriva (2), Julien Aligon (1),\n  Jean-Baptiste Excoffier (2), Chantal Soul\\'e-Dupuy (1) ((1) Universit\\'e de\n  Toulouse-Capitole, IRIT CNRS/UMR 5505, (2) Kaduceo)", "title": "Coalitional strategies for efficient individual prediction explanation", "comments": "Paper submitted to Information Systems Frontiers (Special Issue of\n  the ADBIS 2020 conference)", "journal-ref": "Information Systems Frontiers (2021)", "doi": "10.1007/s10796-021-10141-9", "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  As Machine Learning (ML) is now widely applied in many domains, in both\nresearch and industry, an understanding of what is happening inside the black\nbox is becoming a growing demand, especially by non-experts of these models.\nSeveral approaches had thus been developed to provide clear insights of a model\nprediction for a particular observation but at the cost of long computation\ntime or restrictive hypothesis that does not fully take into account\ninteraction between attributes. This paper provides methods based on the\ndetection of relevant groups of attributes -- named coalitions -- influencing a\nprediction and compares them with the literature. Our results show that these\ncoalitional methods are more efficient than existing ones such as SHapley\nAdditive exPlanation (SHAP). Computation time is shortened while preserving an\nacceptable accuracy of individual prediction explanations. Therefore, this\nenables wider practical use of explanation methods to increase trust between\ndeveloped ML models, end-users, and whoever impacted by any decision where\nthese models played a role.\n", "versions": [{"version": "v1", "created": "Thu, 1 Apr 2021 21:00:23 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Ferrettini", "Gabriel", ""], ["Escriva", "Elodie", ""], ["Aligon", "Julien", ""], ["Excoffier", "Jean-Baptiste", ""], ["Soul\u00e9-Dupuy", "Chantal", ""]]}, {"id": "2104.00769", "submitter": "Axel Berg", "authors": "Axel Berg, Mark O'Connor, Miguel Tairum Cruz", "title": "Keyword Transformer: A Self-Attention Model for Keyword Spotting", "comments": "Proceedings of INTERSPEECH", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Transformer architecture has been successful across many domains,\nincluding natural language processing, computer vision and speech recognition.\nIn keyword spotting, self-attention has primarily been used on top of\nconvolutional or recurrent encoders. We investigate a range of ways to adapt\nthe Transformer architecture to keyword spotting and introduce the Keyword\nTransformer (KWT), a fully self-attentional architecture that exceeds\nstate-of-the-art performance across multiple tasks without any pre-training or\nadditional data. Surprisingly, this simple architecture outperforms more\ncomplex models that mix convolutional, recurrent and attentive layers. KWT can\nbe used as a drop-in replacement for these models, setting two new benchmark\nrecords on the Google Speech Commands dataset with 98.6% and 97.7% accuracy on\nthe 12 and 35-command tasks respectively.\n", "versions": [{"version": "v1", "created": "Thu, 1 Apr 2021 21:15:30 GMT"}, {"version": "v2", "created": "Thu, 15 Apr 2021 14:28:41 GMT"}, {"version": "v3", "created": "Tue, 15 Jun 2021 13:06:01 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Berg", "Axel", ""], ["O'Connor", "Mark", ""], ["Cruz", "Miguel Tairum", ""]]}, {"id": "2104.00776", "submitter": "Xibai Lou", "authors": "Xibai Lou, Yang Yang and Changhyun Choi", "title": "Collision-Aware Target-Driven Object Grasping in Constrained\n  Environments", "comments": "Accepted for publication in proceedings of 2021 International\n  Conference on Robotics and Automation (ICRA 2021). Link to Video:\n  https://youtu.be/QLTM6UkZ-Dw", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Grasping a novel target object in constrained environments (e.g., walls,\nbins, and shelves) requires intensive reasoning about grasp pose reachability\nto avoid collisions with the surrounding structures. Typical 6-DoF robotic\ngrasping systems rely on the prior knowledge about the environment and\nintensive planning computation, which is ungeneralizable and inefficient. In\ncontrast, we propose a novel Collision-Aware Reachability Predictor (CARP) for\n6-DoF grasping systems. The CARP learns to estimate the collision-free\nprobabilities for grasp poses and significantly improves grasping in\nchallenging environments. The deep neural networks in our approach are trained\nfully by self-supervision in simulation. The experiments in both simulation and\nthe real world show that our approach achieves more than 75% grasping rate on\nnovel objects in various surrounding structures. The ablation study\ndemonstrates the effectiveness of the CARP, which improves the 6-DoF grasping\nrate by 95.7%.\n", "versions": [{"version": "v1", "created": "Thu, 1 Apr 2021 21:44:07 GMT"}], "update_date": "2021-04-05", "authors_parsed": [["Lou", "Xibai", ""], ["Yang", "Yang", ""], ["Choi", "Changhyun", ""]]}, {"id": "2104.00788", "submitter": "Kiran Mantripragada", "authors": "Kiran Mantripragada, Phuong D. Dao, Yuhong He, Faisal Z. Qureshi", "title": "A study on the effects of compression on hyperspectral image\n  classification", "comments": "15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper presents a systematic study the effects of compression on\nhyperspectral pixel classification task. We use five dimensionality reduction\nmethods -- PCA, KPCA, ICA, AE, and DAE -- to compress 301-dimensional\nhyperspectral pixels. Compressed pixels are subsequently used to perform\npixel-based classifications. Pixel classification accuracies together with\ncompression method, compression rates, and reconstruction errors provide a new\nlens to study the suitability of a compression method for the task of\npixel-based classification. We use three high-resolution hyperspectral image\ndatasets, representing three common landscape units (i.e. urban, transitional\nsuburban, and forests) collected by the Remote Sensing and Spatial Ecosystem\nModeling laboratory of the University of Toronto. We found that PCA, KPCA, and\nICA post greater signal reconstruction capability; however, when compression\nrate is more than 90\\% those methods showed lower classification scores. AE and\nDAE methods post better classification accuracy at 95\\% compression rate,\nhowever decreasing again at 97\\%, suggesting a sweet-spot at the 95\\% mark. Our\nresults demonstrate that the choice of a compression method with the\ncompression rate are important considerations when designing a hyperspectral\nimage classification pipeline.\n", "versions": [{"version": "v1", "created": "Thu, 1 Apr 2021 22:22:47 GMT"}], "update_date": "2021-04-05", "authors_parsed": [["Mantripragada", "Kiran", ""], ["Dao", "Phuong D.", ""], ["He", "Yuhong", ""], ["Qureshi", "Faisal Z.", ""]]}, {"id": "2104.00793", "submitter": "Saahil Jain", "authors": "Saahil Jain, Akshay Smit, Andrew Y. Ng, Pranav Rajpurkar", "title": "Effect of Radiology Report Labeler Quality on Deep Learning Models for\n  Chest X-Ray Interpretation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although deep learning models for chest X-ray interpretation are commonly\ntrained on labels generated by automatic radiology report labelers, the impact\nof improvements in report labeling on the performance of chest X-ray\nclassification models has not been systematically investigated. We first\ncompare the CheXpert, CheXbert, and VisualCheXbert labelers on the task of\nextracting accurate chest X-ray image labels from radiology reports, reporting\nthat the VisualCheXbert labeler outperforms the CheXpert and CheXbert labelers.\nNext, after training image classification models using labels generated from\nthe different radiology report labelers on one of the largest datasets of chest\nX-rays, we show that an image classification model trained on labels from the\nVisualCheXbert labeler outperforms image classification models trained on\nlabels from the CheXpert and CheXbert labelers. Our work suggests that recent\nimprovements in radiology report labeling can translate to the development of\nhigher performing chest X-ray classification models.\n", "versions": [{"version": "v1", "created": "Thu, 1 Apr 2021 22:37:29 GMT"}], "update_date": "2021-04-05", "authors_parsed": [["Jain", "Saahil", ""], ["Smit", "Akshay", ""], ["Ng", "Andrew Y.", ""], ["Rajpurkar", "Pranav", ""]]}, {"id": "2104.00795", "submitter": "Shyamgopal Karthik", "authors": "Shyamgopal Karthik, Ameya Prabhu, Puneet K. Dokania, Vineet Gandhi", "title": "No Cost Likelihood Manipulation at Test Time for Making Better Mistakes\n  in Deep Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  There has been increasing interest in building deep hierarchy-aware\nclassifiers that aim to quantify and reduce the severity of mistakes, and not\njust reduce the number of errors. The idea is to exploit the label hierarchy\n(e.g., the WordNet ontology) and consider graph distances as a proxy for\nmistake severity. Surprisingly, on examining mistake-severity distributions of\nthe top-1 prediction, we find that current state-of-the-art hierarchy-aware\ndeep classifiers do not always show practical improvement over the standard\ncross-entropy baseline in making better mistakes. The reason for the reduction\nin average mistake-severity can be attributed to the increase in low-severity\nmistakes, which may also explain the noticeable drop in their accuracy. To this\nend, we use the classical Conditional Risk Minimization (CRM) framework for\nhierarchy-aware classification. Given a cost matrix and a reliable estimate of\nlikelihoods (obtained from a trained network), CRM simply amends mistakes at\ninference time; it needs no extra hyperparameters and requires adding just a\nfew lines of code to the standard cross-entropy baseline. It significantly\noutperforms the state-of-the-art and consistently obtains large reductions in\nthe average hierarchical distance of top-$k$ predictions across datasets, with\nvery little loss in accuracy. CRM, because of its simplicity, can be used with\nany off-the-shelf trained model that provides reliable likelihood estimates.\n", "versions": [{"version": "v1", "created": "Thu, 1 Apr 2021 22:40:25 GMT"}], "update_date": "2021-04-05", "authors_parsed": [["Karthik", "Shyamgopal", ""], ["Prabhu", "Ameya", ""], ["Dokania", "Puneet K.", ""], ["Gandhi", "Vineet", ""]]}, {"id": "2104.00801", "submitter": "Saketh Reddy Karra", "authors": "Saketh Reddy Karra and Theja Tulabandhula", "title": "Choice-Aware User Engagement Modeling andOptimization on Social Media", "comments": "11 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We address the problem of maximizing user engagement with content (in the\nform of like, reply, retweet, and retweet with comments)on the Twitter\nplatform. We formulate the engagement forecasting task as a multi-label\nclassification problem that captures choice behavior on an unsupervised\nclustering of tweet-topics. We propose a neural network architecture that\nincorporates user engagement history and predicts choice conditional on this\ncontext. We study the impact of recommend-ing tweets on engagement outcomes by\nsolving an appropriately defined sweet optimization problem based on the\nproposed model using a large dataset obtained from Twitter.\n", "versions": [{"version": "v1", "created": "Thu, 1 Apr 2021 23:31:01 GMT"}], "update_date": "2021-04-05", "authors_parsed": [["Karra", "Saketh Reddy", ""], ["Tulabandhula", "Theja", ""]]}, {"id": "2104.00807", "submitter": "Hilmi Enes Egilmez", "authors": "Ankitesh K. Singh, Hilmi E. Egilmez, Reza Pourreza, Muhammed Coban,\n  Marta Karczewicz, Taco S. Cohen", "title": "A Combined Deep Learning based End-to-End Video Coding Architecture for\n  YUV Color Space", "comments": "5 pages, submitted to as a conference paper. arXiv admin note: text\n  overlap with arXiv:2103.01760", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most of the existing deep learning based end-to-end video coding (DLEC)\narchitectures are designed specifically for RGB color format, yet the video\ncoding standards, including H.264/AVC, H.265/HEVC and H.266/VVC developed over\npast few decades, have been designed primarily for YUV 4:2:0 format, where the\nchrominance (U and V) components are subsampled to achieve superior compression\nperformances considering the human visual system. While a broad number of\npapers on DLEC compare these two distinct coding schemes in RGB domain, it is\nideal to have a common evaluation framework in YUV 4:2:0 domain for a more fair\ncomparison. This paper introduces a new DLEC architecture for video coding to\neffectively support YUV 4:2:0 and compares its performance against the HEVC\nstandard under a common evaluation framework. The experimental results on YUV\n4:2:0 video sequences show that the proposed architecture can outperform HEVC\nin intra-frame coding, however inter-frame coding is not as efficient on\ncontrary to the RGB coding results reported in recent papers.\n", "versions": [{"version": "v1", "created": "Thu, 1 Apr 2021 23:41:06 GMT"}], "update_date": "2021-04-05", "authors_parsed": [["Singh", "Ankitesh K.", ""], ["Egilmez", "Hilmi E.", ""], ["Pourreza", "Reza", ""], ["Coban", "Muhammed", ""], ["Karczewicz", "Marta", ""], ["Cohen", "Taco S.", ""]]}, {"id": "2104.00816", "submitter": "Ali Sadeghian", "authors": "Mohammadreza Armandpour, Ali Sadeghian, Chunyuan Li, Mingyuan Zhou", "title": "Partition-Guided GANs", "comments": "Accepted for publication at CVPR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Despite the success of Generative Adversarial Networks (GANs), their training\nsuffers from several well-known problems, including mode collapse and\ndifficulties learning a disconnected set of manifolds. In this paper, we break\ndown the challenging task of learning complex high dimensional distributions,\nsupporting diverse data samples, to simpler sub-tasks. Our solution relies on\ndesigning a partitioner that breaks the space into smaller regions, each having\na simpler distribution, and training a different generator for each partition.\nThis is done in an unsupervised manner without requiring any labels.\n  We formulate two desired criteria for the space partitioner that aid the\ntraining of our mixture of generators: 1) to produce connected partitions and\n2) provide a proxy of distance between partitions and data samples, along with\na direction for reducing that distance. These criteria are developed to avoid\nproducing samples from places with non-existent data density, and also\nfacilitate training by providing additional direction to the generators. We\ndevelop theoretical constraints for a space partitioner to satisfy the above\ncriteria. Guided by our theoretical analysis, we design an effective neural\narchitecture for the space partitioner that empirically assures these\nconditions. Experimental results on various standard benchmarks show that the\nproposed unsupervised model outperforms several recent methods.\n", "versions": [{"version": "v1", "created": "Fri, 2 Apr 2021 00:06:53 GMT"}, {"version": "v2", "created": "Fri, 18 Jun 2021 00:53:26 GMT"}], "update_date": "2021-06-21", "authors_parsed": [["Armandpour", "Mohammadreza", ""], ["Sadeghian", "Ali", ""], ["Li", "Chunyuan", ""], ["Zhou", "Mingyuan", ""]]}, {"id": "2104.00820", "submitter": "Enis Simsar", "authors": "O\\u{g}uz Kaan Y\\\"uksel, Enis Simsar, Ezgi G\\\"ulperi Er, Pinar Yanardag", "title": "LatentCLR: A Contrastive Learning Approach for Unsupervised Discovery of\n  Interpretable Directions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent research has shown great potential for finding interpretable\ndirections in the latent spaces of pre-trained Generative Adversarial Networks\n(GANs). These directions provide controllable generation and support a wide\nrange of semantic editing operations such as zoom or rotation. The discovery of\nsuch directions is often performed in a supervised or semi-supervised fashion\nand requires manual annotations, limiting their applications in practice. In\ncomparison, unsupervised discovery enables finding subtle directions a priori\nhard to recognize. In this work, we propose a contrastive-learning-based\napproach for discovering semantic directions in the latent space of pretrained\nGANs in a self-supervised manner. Our approach finds semantically meaningful\ndimensions compatible with state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Fri, 2 Apr 2021 00:11:22 GMT"}], "update_date": "2021-04-05", "authors_parsed": [["Y\u00fcksel", "O\u011fuz Kaan", ""], ["Simsar", "Enis", ""], ["Er", "Ezgi G\u00fclperi", ""], ["Yanardag", "Pinar", ""]]}, {"id": "2104.00827", "submitter": "Jingxi Xu", "authors": "Jingxi Xu, Bruce Lee, Nikolai Matni, Dinesh Jayaraman", "title": "How Are Learned Perception-Based Controllers Impacted by the Limits of\n  Robust Control?", "comments": "Accepted to L4DC 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The difficulty of optimal control problems has classically been characterized\nin terms of system properties such as minimum eigenvalues of\ncontrollability/observability gramians. We revisit these characterizations in\nthe context of the increasing popularity of data-driven techniques like\nreinforcement learning (RL), and in control settings where input observations\nare high-dimensional images and transition dynamics are unknown. Specifically,\nwe ask: to what extent are quantifiable control and perceptual difficulty\nmetrics of a task predictive of the performance and sample complexity of\ndata-driven controllers? We modulate two different types of partial\nobservability in a cartpole \"stick-balancing\" problem -- (i) the height of one\nvisible fixation point on the cartpole, which can be used to tune fundamental\nlimits of performance achievable by any controller, and by (ii) the level of\nperception noise in the fixation point position inferred from depth or RGB\nimages of the cartpole. In these settings, we empirically study two popular\nfamilies of controllers: RL and system identification-based $H_\\infty$ control,\nusing visually estimated system state. Our results show that the fundamental\nlimits of robust control have corresponding implications for the\nsample-efficiency and performance of learned perception-based controllers.\nVisit our project website https://jxu.ai/rl-vs-control-web for more\ninformation.\n", "versions": [{"version": "v1", "created": "Fri, 2 Apr 2021 00:31:31 GMT"}], "update_date": "2021-04-05", "authors_parsed": [["Xu", "Jingxi", ""], ["Lee", "Bruce", ""], ["Matni", "Nikolai", ""], ["Jayaraman", "Dinesh", ""]]}, {"id": "2104.00837", "submitter": "Pingchuan Ma", "authors": "Pingchuan Ma, Tao Du, John Z. Zhang, Kui Wu, Andrew Spielberg, Robert\n  K. Katzschmann, Wojciech Matusik", "title": "DiffAqua: A Differentiable Computational Design Pipeline for Soft\n  Underwater Swimmers with Shape Interpolation", "comments": "ACM SIGGRAPH 2021. Homepage: http://diffaqua.csail.mit.edu/", "journal-ref": null, "doi": "10.1145/3450626.3459832", "report-no": null, "categories": "cs.LG cs.GR cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The computational design of soft underwater swimmers is challenging because\nof the high degrees of freedom in soft-body modeling. In this paper, we present\na differentiable pipeline for co-designing a soft swimmer's geometry and\ncontroller. Our pipeline unlocks gradient-based algorithms for discovering\nnovel swimmer designs more efficiently than traditional gradient-free\nsolutions. We propose Wasserstein barycenters as a basis for the geometric\ndesign of soft underwater swimmers since it is differentiable and can naturally\ninterpolate between bio-inspired base shapes via optimal transport. By\ncombining this design space with differentiable simulation and control, we can\nefficiently optimize a soft underwater swimmer's performance with fewer\nsimulations than baseline methods. We demonstrate the efficacy of our method on\nvarious design problems such as fast, stable, and energy-efficient swimming and\ndemonstrate applicability to multi-objective design.\n", "versions": [{"version": "v1", "created": "Fri, 2 Apr 2021 01:18:15 GMT"}, {"version": "v2", "created": "Wed, 5 May 2021 18:58:41 GMT"}], "update_date": "2021-05-07", "authors_parsed": [["Ma", "Pingchuan", ""], ["Du", "Tao", ""], ["Zhang", "John Z.", ""], ["Wu", "Kui", ""], ["Spielberg", "Andrew", ""], ["Katzschmann", "Robert K.", ""], ["Matusik", "Wojciech", ""]]}, {"id": "2104.00842", "submitter": "Aviral Joshi", "authors": "A Vinay, Aviral Joshi, Hardik Mahipal Surana, Harsh Garg, K N\n  BalasubramanyaMurthy, S Natarajan", "title": "Unconstrained Face Recognition using ASURF and Cloud-Forest Classifier\n  optimized with VLAD", "comments": "8 Pages, 3 Figures", "journal-ref": "Procedia computer science, 143, 570-578 (2018)", "doi": "10.1016/j.procs.2018.10.433", "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The paper posits a computationally-efficient algorithm for multi-class facial\nimage classification in which images are constrained with translation,\nrotation, scale, color, illumination and affine distortion. The proposed method\nis divided into five main building blocks including Haar-Cascade for face\ndetection, Bilateral Filter for image preprocessing to remove unwanted noise,\nAffine Speeded-Up Robust Features (ASURF) for keypoint detection and\ndescription, Vector of Locally Aggregated Descriptors (VLAD) for feature\nquantization and Cloud Forest for image classification. The proposed method\naims at improving the accuracy and the time taken for face recognition systems.\nThe usage of the Cloud Forest algorithm as a classifier on three benchmark\ndatasets, namely the FACES95, FACES96 and ORL facial datasets, showed promising\nresults. The proposed methodology using Cloud Forest algorithm successfully\nimproves the recognition model by 2-12\\% when differentiated against other\nensemble techniques like the Random Forest classifier depending upon the\ndataset used.\n", "versions": [{"version": "v1", "created": "Fri, 2 Apr 2021 01:26:26 GMT"}], "update_date": "2021-04-05", "authors_parsed": [["Vinay", "A", ""], ["Joshi", "Aviral", ""], ["Surana", "Hardik Mahipal", ""], ["Garg", "Harsh", ""], ["BalasubramanyaMurthy", "K N", ""], ["Natarajan", "S", ""]]}, {"id": "2104.00853", "submitter": "Hao Peng", "authors": "Hao Peng, Jianxin Li, Yangqiu Song, Renyu Yang, Rajiv Ranjan, Philip\n  S. Yu, Lifang He", "title": "Streaming Social Event Detection and Evolution Discovery in\n  Heterogeneous Information Networks", "comments": "Accepted by TKDD 2021. arXiv admin note: text overlap with\n  arXiv:1906.04580", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Events are happening in real-world and real-time, which can be planned and\norganized for occasions, such as social gatherings, festival celebrations,\ninfluential meetings or sports activities. Social media platforms generate a\nlot of real-time text information regarding public events with different\ntopics. However, mining social events is challenging because events typically\nexhibit heterogeneous texture and metadata are often ambiguous. In this paper,\nwe first design a novel event-based meta-schema to characterize the semantic\nrelatedness of social events and then build an event-based heterogeneous\ninformation network (HIN) integrating information from external knowledge base.\nSecond, we propose a novel Pairwise Popularity Graph Convolutional Network,\nnamed as PP-GCN, based on weighted meta-path instance similarity and textual\nsemantic representation as inputs, to perform fine-grained social event\ncategorization and learn the optimal weights of meta-paths in different tasks.\nThird, we propose a streaming social event detection and evolution discovery\nframework for HINs based on meta-path similarity search, historical information\nabout meta-paths, and heterogeneous DBSCAN clustering method. Comprehensive\nexperiments on real-world streaming social text data are conducted to compare\nvarious social event detection and evolution discovery algorithms. Experimental\nresults demonstrate that our proposed framework outperforms other alternative\nsocial event detection and evolution discovery techniques.\n", "versions": [{"version": "v1", "created": "Fri, 2 Apr 2021 02:13:10 GMT"}], "update_date": "2021-04-05", "authors_parsed": [["Peng", "Hao", ""], ["Li", "Jianxin", ""], ["Song", "Yangqiu", ""], ["Yang", "Renyu", ""], ["Ranjan", "Rajiv", ""], ["Yu", "Philip S.", ""], ["He", "Lifang", ""]]}, {"id": "2104.00863", "submitter": "Philip Derbeko", "authors": "Philip Derbeko and Shlomi Dolev", "title": "PolyDNN: Polynomial Representation of NN for Communication-less SMPC\n  Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The structure and weights of Deep Neural Networks (DNN) typically encode and\ncontain very valuable information about the dataset that was used to train the\nnetwork.\n  One way to protect this information when DNN is published is to perform an\ninterference of the network using secure multi-party computations (MPC).\n  In this paper, we suggest a translation of deep neural networks to\npolynomials, which are easier to calculate efficiently with MPC techniques.\n  We show a way to translate complete networks into a single polynomial and how\nto calculate the polynomial with an efficient and information-secure MPC\nalgorithm.\n  The calculation is done without intermediate communication between the\nparticipating parties, which is beneficial in several cases, as explained in\nthe paper.\n", "versions": [{"version": "v1", "created": "Fri, 2 Apr 2021 02:59:37 GMT"}, {"version": "v2", "created": "Wed, 28 Apr 2021 03:24:20 GMT"}], "update_date": "2021-04-29", "authors_parsed": [["Derbeko", "Philip", ""], ["Dolev", "Shlomi", ""]]}, {"id": "2104.00864", "submitter": "Daniel Olds", "authors": "Phillip M. Maffettone, Aidan C. Daly, Daniel Olds", "title": "Constrained non-negative matrix factorization enabling real-time\n  insights of $\\textit{in situ}$ and high-throughput experiments", "comments": "This article has been submitted to Applied Physics Reviews. After it\n  is published, it will be found at https://aip.scitation.org/journal/are.\n  Copyright (2021) Phillip M. Maffettone, Aiden C. Daly, Daniel Olds", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.app-ph cond-mat.mtrl-sci cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Non-negative Matrix Factorization (NMF) methods offer an appealing\nunsupervised learning method for real-time analysis of streaming spectral data\nin time-sensitive data collection, such as $\\textit{in situ}$ characterization\nof materials. However, canonical NMF methods are optimized to reconstruct a\nfull dataset as closely as possible, with no underlying requirement that the\nreconstruction produces components or weights representative of the true\nphysical processes. In this work, we demonstrate how constraining NMF weights\nor components, provided as known or assumed priors, can provide significant\nimprovement in revealing true underlying phenomena. We present a PyTorch based\nmethod for efficiently applying constrained NMF and demonstrate this on several\nsynthetic examples. When applied to streaming experimentally measured spectral\ndata, an expert researcher-in-the-loop can provide and dynamically adjust the\nconstraints. This set of interactive priors to the NMF model can, for example,\ncontain known or identified independent components, as well as functional\nexpectations about the mixing of components. We demonstrate this application on\nmeasured X-ray diffraction and pair distribution function data from $\\textit{in\nsitu}$ beamline experiments. Details of the method are described, and general\nguidance provided to employ constrained NMF in extraction of critical\ninformation and insights during $\\textit{in situ}$ and high-throughput\nexperiments.\n", "versions": [{"version": "v1", "created": "Fri, 2 Apr 2021 03:04:24 GMT"}], "update_date": "2021-04-05", "authors_parsed": [["Maffettone", "Phillip M.", ""], ["Daly", "Aidan C.", ""], ["Olds", "Daniel", ""]]}, {"id": "2104.00871", "submitter": "Jay Kumar", "authors": "Khwaja Mutahir Ahmad, Gang He, Wenxin Yu, Xiaochuan Xu, Jay Kumar,\n  Muhammad Asim Saleem", "title": "A Survey on Semi-parametric Machine Learning Technique for Time Series\n  Forecasting", "comments": "44 pages, 8 figures, journal paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial Intelligence (AI) has recently shown its capabilities for almost\nevery field of life. Machine Learning, which is a subset of AI, is a `HOT'\ntopic for researchers. Machine Learning outperforms other classical forecasting\ntechniques in almost all-natural applications. It is a crucial part of modern\nresearch. As per this statement, Modern Machine Learning algorithms are hungry\nfor big data. Due to the small datasets, the researchers may not prefer to use\nMachine Learning algorithms. To tackle this issue, the main purpose of this\nsurvey is to illustrate, demonstrate related studies for significance of a\nsemi-parametric Machine Learning framework called Grey Machine Learning (GML).\nThis kind of framework is capable of handling large datasets as well as small\ndatasets for time series forecasting likely outcomes. This survey presents a\ncomprehensive overview of the existing semi-parametric machine learning\ntechniques for time series forecasting. In this paper, a primer survey on the\nGML framework is provided for researchers. To allow an in-depth understanding\nfor the readers, a brief description of Machine Learning, as well as various\nforms of conventional grey forecasting models are discussed. Moreover, a brief\ndescription on the importance of GML framework is presented.\n", "versions": [{"version": "v1", "created": "Fri, 2 Apr 2021 03:26:20 GMT"}], "update_date": "2021-04-05", "authors_parsed": [["Ahmad", "Khwaja Mutahir", ""], ["He", "Gang", ""], ["Yu", "Wenxin", ""], ["Xu", "Xiaochuan", ""], ["Kumar", "Jay", ""], ["Saleem", "Muhammad Asim", ""]]}, {"id": "2104.00878", "submitter": "Yantian Zha", "authors": "Yantian Zha, Siddhant Bhambri and Lin Guan", "title": "Contrastively Learning Visual Attention as Affordance Cues from\n  Demonstrations for Robotic Grasping", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Conventional works that learn grasping affordance from demonstrations need to\nexplicitly predict grasping configurations, such as gripper approaching angles\nor grasping preshapes. Classic motion planners could then sample trajectories\nby using such predicted configurations. In this work, our goal is instead to\nintegrate the two objectives of affordance discovery and affordance-aware\npolicy learning in an end-to-end imitation learning framework based on deep\nneural networks. From a psychological perspective, there is a close association\nbetween attention and affordance. Therefore, with an end-to-end neural network,\nwe propose to learn affordance cues as visual attention that serves as a useful\nindicating signal of how a demonstrator accomplishes tasks. To achieve this, we\npropose a contrastive learning framework that consists of a Siamese encoder and\na trajectory decoder. We further introduce a coupled triplet loss to encourage\nthe discovered affordance cues to be more affordance-relevant. Our experimental\nresults demonstrate that our model with the coupled triplet loss achieves the\nhighest grasping success rate.\n", "versions": [{"version": "v1", "created": "Fri, 2 Apr 2021 04:18:53 GMT"}, {"version": "v2", "created": "Sun, 11 Apr 2021 15:27:52 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Zha", "Yantian", ""], ["Bhambri", "Siddhant", ""], ["Guan", "Lin", ""]]}, {"id": "2104.00896", "submitter": "Vineeth Rakesh", "authors": "Vineeth Rakesh, Swayambhoo Jain", "title": "Efficacy of Bayesian Neural Networks in Active Learning", "comments": "Published at CVPR Workshop on Learning From Limited or Imperfect Data\n  (LLID) 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Obtaining labeled data for machine learning tasks can be prohibitively\nexpensive. Active learning mitigates this issue by exploring the unlabeled data\nspace and prioritizing the selection of data that can best improve the model\nperformance. A common approach to active learning is to pick a small sample of\ndata for which the model is most uncertain. In this paper, we explore the\nefficacy of Bayesian neural networks for active learning, which naturally\nmodels uncertainty by learning distribution over the weights of neural\nnetworks. By performing a comprehensive set of experiments, we show that\nBayesian neural networks are more efficient than ensemble based techniques in\ncapturing uncertainty. Our findings also reveal some key drawbacks of the\nensemble techniques, which was recently shown to be more effective than Monte\nCarlo dropouts.\n", "versions": [{"version": "v1", "created": "Fri, 2 Apr 2021 06:02:11 GMT"}, {"version": "v2", "created": "Mon, 19 Apr 2021 22:19:53 GMT"}], "update_date": "2021-04-21", "authors_parsed": [["Rakesh", "Vineeth", ""], ["Jain", "Swayambhoo", ""]]}, {"id": "2104.00931", "submitter": "Seung-Won Park", "authors": "Kang-wook Kim, Seung-won Park and Myun-chul Joe", "title": "Assem-VC: Realistic Voice Conversion by Assembling Modern Speech\n  Synthesis Techniques", "comments": "Submitted to Interspeech 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we pose the current state-of-the-art voice conversion (VC)\nsystems as two-encoder-one-decoder models. After comparing these models, we\ncombine the best features and propose Assem-VC, a new state-of-the-art\nany-to-many non-parallel VC system. This paper also introduces the GTA\nfinetuning in VC, which significantly improves the quality and the speaker\nsimilarity of the outputs. Assem-VC outperforms the previous state-of-the-art\napproaches in both the naturalness and the speaker similarity on the VCTK\ndataset. As an objective result, the degree of speaker disentanglement of\nfeatures such as phonetic posteriorgrams (PPG) is also explored. Our\ninvestigation indicates that many-to-many VC results are no longer distinct\nfrom human speech and similar quality can be achieved with any-to-many models.\nAudio samples are available at https://mindslab-ai.github.io/assem-vc/\n", "versions": [{"version": "v1", "created": "Fri, 2 Apr 2021 08:18:05 GMT"}], "update_date": "2021-04-05", "authors_parsed": [["Kim", "Kang-wook", ""], ["Park", "Seung-won", ""], ["Joe", "Myun-chul", ""]]}, {"id": "2104.00941", "submitter": "Dongha Lee", "authors": "Dongha Lee, Sehun Yu, Hwanjo Yu", "title": "Multi-Class Data Description for Out-of-distribution Detection", "comments": "9 pages, 7 figures, published in SIGKDD 20", "journal-ref": "In Proceedings of the 26th ACM SIGKDD International Conference on\n  Knowledge Discovery & Data Mining (pp. 1362-1370) 2020", "doi": "10.1145/3394486.3403189", "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The capability of reliably detecting out-of-distribution samples is one of\nthe key factors in deploying a good classifier, as the test distribution always\ndoes not match with the training distribution in most real-world applications.\nIn this work, we present a deep multi-class data description, termed as\nDeep-MCDD, which is effective to detect out-of-distribution (OOD) samples as\nwell as classify in-distribution (ID) samples. Unlike the softmax classifier\nthat only focuses on the linear decision boundary partitioning its latent space\ninto multiple regions, our Deep-MCDD aims to find a spherical decision boundary\nfor each class which determines whether a test sample belongs to the class or\nnot. By integrating the concept of Gaussian discriminant analysis into deep\nneural networks, we propose a deep learning objective to learn\nclass-conditional distributions that are explicitly modeled as separable\nGaussian distributions. Thereby, we can define the confidence score by the\ndistance of a test sample from each class-conditional distribution, and utilize\nit for identifying OOD samples. Our empirical evaluation on multi-class tabular\nand image datasets demonstrates that Deep-MCDD achieves the best performances\nin distinguishing OOD samples while showing the classification accuracy as high\nas the other competitors.\n", "versions": [{"version": "v1", "created": "Fri, 2 Apr 2021 08:41:51 GMT"}], "update_date": "2021-04-05", "authors_parsed": [["Lee", "Dongha", ""], ["Yu", "Sehun", ""], ["Yu", "Hwanjo", ""]]}, {"id": "2104.00950", "submitter": "Thomas Rojat", "authors": "Thomas Rojat, Rapha\\\"el Puget, David Filliat, Javier Del Ser, Rodolphe\n  Gelin, and Natalia D\\'iaz-Rodr\\'iguez", "title": "Explainable Artificial Intelligence (XAI) on TimeSeries Data: A Survey", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Most of state of the art methods applied on time series consist of deep\nlearning methods that are too complex to be interpreted. This lack of\ninterpretability is a major drawback, as several applications in the real world\nare critical tasks, such as the medical field or the autonomous driving field.\nThe explainability of models applied on time series has not gather much\nattention compared to the computer vision or the natural language processing\nfields. In this paper, we present an overview of existing explainable AI (XAI)\nmethods applied on time series and illustrate the type of explanations they\nproduce. We also provide a reflection on the impact of these explanation\nmethods to provide confidence and trust in the AI systems.\n", "versions": [{"version": "v1", "created": "Fri, 2 Apr 2021 09:14:00 GMT"}], "update_date": "2021-04-05", "authors_parsed": [["Rojat", "Thomas", ""], ["Puget", "Rapha\u00ebl", ""], ["Filliat", "David", ""], ["Del Ser", "Javier", ""], ["Gelin", "Rodolphe", ""], ["D\u00edaz-Rodr\u00edguez", "Natalia", ""]]}, {"id": "2104.00954", "submitter": "Suman Ravuri", "authors": "Suman Ravuri, Karel Lenc, Matthew Willson, Dmitry Kangin, Remi Lam,\n  Piotr Mirowski, Megan Fitzsimons, Maria Athanassiadou, Sheleem Kashem, Sam\n  Madge, Rachel Prudden, Amol Mandhane, Aidan Clark, Andrew Brock, Karen\n  Simonyan, Raia Hadsell, Niall Robinson, Ellen Clancy, Alberto Arribas, Shakir\n  Mohamed", "title": "Skillful Precipitation Nowcasting using Deep Generative Models of Radar", "comments": "46 pages, 17 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Precipitation nowcasting, the high-resolution forecasting of precipitation up\nto two hours ahead, supports the real-world socio-economic needs of many\nsectors reliant on weather-dependent decision-making. State-of-the-art\noperational nowcasting methods typically advect precipitation fields with\nradar-based wind estimates, and struggle to capture important non-linear events\nsuch as convective initiations. Recently introduced deep learning methods use\nradar to directly predict future rain rates, free of physical constraints.\nWhile they accurately predict low-intensity rainfall, their operational utility\nis limited because their lack of constraints produces blurry nowcasts at longer\nlead times, yielding poor performance on more rare medium-to-heavy rain events.\nTo address these challenges, we present a Deep Generative Model for the\nprobabilistic nowcasting of precipitation from radar. Our model produces\nrealistic and spatio-temporally consistent predictions over regions up to 1536\nkm x 1280 km and with lead times from 5-90 min ahead. In a systematic\nevaluation by more than fifty expert forecasters from the Met Office, our\ngenerative model ranked first for its accuracy and usefulness in 88% of cases\nagainst two competitive methods, demonstrating its decision-making value and\nability to provide physical insight to real-world experts. When verified\nquantitatively, these nowcasts are skillful without resorting to blurring. We\nshow that generative nowcasting can provide probabilistic predictions that\nimprove forecast value and support operational utility, and at resolutions and\nlead times where alternative methods struggle.\n", "versions": [{"version": "v1", "created": "Fri, 2 Apr 2021 09:29:03 GMT"}], "update_date": "2021-04-05", "authors_parsed": [["Ravuri", "Suman", ""], ["Lenc", "Karel", ""], ["Willson", "Matthew", ""], ["Kangin", "Dmitry", ""], ["Lam", "Remi", ""], ["Mirowski", "Piotr", ""], ["Fitzsimons", "Megan", ""], ["Athanassiadou", "Maria", ""], ["Kashem", "Sheleem", ""], ["Madge", "Sam", ""], ["Prudden", "Rachel", ""], ["Mandhane", "Amol", ""], ["Clark", "Aidan", ""], ["Brock", "Andrew", ""], ["Simonyan", "Karen", ""], ["Hadsell", "Raia", ""], ["Robinson", "Niall", ""], ["Clancy", "Ellen", ""], ["Arribas", "Alberto", ""], ["Mohamed", "Shakir", ""]]}, {"id": "2104.00972", "submitter": "Bla\\v{z} Bertalani\\v{c}", "authors": "Blaz Bertalanic, Marko Meza and Carolina Fortuna", "title": "Time Series Imaging for Link Layer Anomaly Classification in Wireless\n  Networks", "comments": "10 pages, 3 figures, 18 subfigures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The number of end devices that use the last mile wireless connectivity is\ndramatically increasing with the rise of smart infrastructures and require\nreliable functioning to support smooth and efficient business processes. To\nefficiently manage such massive wireless networks, more advanced and accurate\nnetwork monitoring and malfunction detection solutions are required. In this\npaper, we perform a first time analysis of image-based representation\ntechniques for wireless anomaly detection using recurrence plots and Gramian\nangular fields and propose a new deep learning architecture enabling accurate\nanomaly detection. We examine the relative performance of the proposed model\nand show that the image transformation of time series improves the performance\nof anomaly detection by up to 29% for binary classification and by up to 27%\nfor multiclass classification. At the same time, the best performing model\nbased on recurrence plot transformation leads to up to 55% increase compared to\nthe state of the art where classical machine learning techniques are used. We\nalso provide insights for the decisions of the classifier using an instance\nbased approach enabled by insights into guided back-propagation. Our results\ndemonstrate the potential of transformation of time series signals to images to\nimprove classification performance compared to classification on raw time\nseries data.\n", "versions": [{"version": "v1", "created": "Fri, 2 Apr 2021 10:23:06 GMT"}], "update_date": "2021-04-05", "authors_parsed": [["Bertalanic", "Blaz", ""], ["Meza", "Marko", ""], ["Fortuna", "Carolina", ""]]}, {"id": "2104.00980", "submitter": "Mobarakol Islam", "authors": "Mobarakol Islam, V Jeya Maria Jose, Hongliang Ren", "title": "Glioma Prognosis: Segmentation of the Tumor and Survival Prediction\n  using Shape, Geometric and Clinical Information", "comments": "MICCAI-BrainLes Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Segmentation of brain tumor from magnetic resonance imaging (MRI) is a vital\nprocess to improve diagnosis, treatment planning and to study the difference\nbetween subjects with tumor and healthy subjects. In this paper, we exploit a\nconvolutional neural network (CNN) with hypercolumn technique to segment tumor\nfrom healthy brain tissue. Hypercolumn is the concatenation of a set of vectors\nwhich form by extracting convolutional features from multiple layers. Proposed\nmodel integrates batch normalization (BN) approach with hypercolumn. BN layers\nhelp to alleviate the internal covariate shift during stochastic gradient\ndescent (SGD) training by zero-mean and unit variance of each mini-batch.\nSurvival Prediction is done by first extracting features(Geometric, Fractal,\nand Histogram) from the segmented brain tumor data. Then, the number of days of\noverall survival is predicted by implementing regression on the extracted\nfeatures using an artificial neural network (ANN). Our model achieves a mean\ndice score of 89.78%, 82.53% and 76.54% for the whole tumor, tumor core and\nenhancing tumor respectively in segmentation task and 67.90% in overall\nsurvival prediction task with the validation set of BraTS 2018 challenge. It\nobtains a mean dice accuracy of 87.315%, 77.04% and 70.22% for the whole tumor,\ntumor core and enhancing tumor respectively in the segmentation task and a\n46.80% in overall survival prediction task in the BraTS 2018 test data set.\n", "versions": [{"version": "v1", "created": "Fri, 2 Apr 2021 10:49:05 GMT"}], "update_date": "2021-04-05", "authors_parsed": [["Islam", "Mobarakol", ""], ["Jose", "V Jeya Maria", ""], ["Ren", "Hongliang", ""]]}, {"id": "2104.00984", "submitter": "Umair Qudus", "authors": "Umair Qudus, Muhammad Saleem, Axel-Cyrille Ngonga Ngomo, Young-koo Lee", "title": "An Empirical Evaluation of Cost-based Federated SPARQL Query Processing\n  Engines", "comments": "24 pages, Semantic Web, 2020, #article", "journal-ref": "Semantic Web 2020", "doi": null, "report-no": null, "categories": "cs.DB cs.LG cs.PF", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Finding a good query plan is key to the optimization of query runtime. This\nholds in particular for cost-based federation engines, which make use of\ncardinality estimations to achieve this goal. A number of studies compare\nSPARQL federation engines across different performance metrics, including query\nruntime, result set completeness and correctness, number of sources selected\nand number of requests sent. Albeit informative, these metrics are generic and\nunable to quantify and evaluate the accuracy of the cardinality estimators of\ncost-based federation engines. To thoroughly evaluate cost-based federation\nengines, the effect of estimated cardinality errors on the overall query\nruntime performance must be measured. In this paper, we address this challenge\nby presenting novel evaluation metrics targeted at a fine-grained benchmarking\nof cost-based federated SPARQL query engines. We evaluate five cost-based\nfederated SPARQL query engines using existing as well as novel evaluation\nmetrics by using LargeRDFBench queries. Our results provide a detailed analysis\nof the experimental outcomes that reveal novel insights, useful for the\ndevelopment of future cost-based federated SPARQL query processing engines.\n", "versions": [{"version": "v1", "created": "Fri, 2 Apr 2021 11:01:25 GMT"}], "update_date": "2021-04-05", "authors_parsed": [["Qudus", "Umair", ""], ["Saleem", "Muhammad", ""], ["Ngomo", "Axel-Cyrille Ngonga", ""], ["Lee", "Young-koo", ""]]}, {"id": "2104.00987", "submitter": "Nicolas Olivain", "authors": "Nicolas Olivain, Philipp Tiefenbacher and Jens Kohl", "title": "Bayesian Structural Learning for an Improved Diagnosis of Cyber-Physical\n  Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The diagnosis of cyber-physical systems (CPS) is based on a representation of\nfunctional and faulty behaviour which is combined with system observations\ntaken at runtime to detect faulty behaviour and reason for its root cause. In\nthis paper we propose a scalable algorithm for an automated learning of a\nstructured diagnosis model which -- although having a reduced size -- offers\nequal performance to comparable algorithms while giving better\ninterpretability. This allows tackling challenges of diagnosing CPS:\nautomatically learning a diagnosis model even with hugely imbalanced data,\nreducing the state-explosion problem when searching for a root cause, and an\neasy interpretability of the results. Our approach differs from existing\nmethods in two aspects: firstly, we aim to learn a holistic global\nrepresentation which is then transformed to a smaller, label-specific\nrepresentation. Secondly, we focus on providing a highly interpretable model\nfor an easy verification of the model and to facilitate repairs. We evaluated\nour approach on data sets relevant for our problem domain. The evaluation shows\nthat the algorithm overcomes the mentioned problems while returning a\ncomparable performance.\n", "versions": [{"version": "v1", "created": "Fri, 2 Apr 2021 11:14:05 GMT"}], "update_date": "2021-04-05", "authors_parsed": [["Olivain", "Nicolas", ""], ["Tiefenbacher", "Philipp", ""], ["Kohl", "Jens", ""]]}, {"id": "2104.00995", "submitter": "Arkopal Dutt", "authors": "Arkopal Dutt, Andrey Y. Lokhov, Marc Vuffray, Sidhant Misra", "title": "Exponential Reduction in Sample Complexity with Learning of Ising Model\n  Dynamics", "comments": "Accepted to ICML 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cond-mat.stat-mech physics.data-an stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The usual setting for learning the structure and parameters of a graphical\nmodel assumes the availability of independent samples produced from the\ncorresponding multivariate probability distribution. However, for many models\nthe mixing time of the respective Markov chain can be very large and i.i.d.\nsamples may not be obtained. We study the problem of reconstructing binary\ngraphical models from correlated samples produced by a dynamical process, which\nis natural in many applications. We analyze the sample complexity of two\nestimators that are based on the interaction screening objective and the\nconditional likelihood loss. We observe that for samples coming from a\ndynamical process far from equilibrium, the sample complexity reduces\nexponentially compared to a dynamical process that mixes quickly.\n", "versions": [{"version": "v1", "created": "Fri, 2 Apr 2021 11:44:13 GMT"}, {"version": "v2", "created": "Mon, 14 Jun 2021 20:22:33 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Dutt", "Arkopal", ""], ["Lokhov", "Andrey Y.", ""], ["Vuffray", "Marc", ""], ["Misra", "Sidhant", ""]]}, {"id": "2104.01002", "submitter": "Xuye Liu", "authors": "Xuye Liu, Dakuo Wang, April Wang, Lingfei Wu", "title": "HAConvGNN: Hierarchical Attention Based Convolutional Graph Neural\n  Network for Code Documentation Generation in Jupyter Notebooks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many data scientists use Jupyter notebook to experiment code, visualize\nresults, and document rationales or interpretations. The code documentation\ngeneration CDG task in notebooks is related but different from the code\nsummarization task in software engineering, as one documentation (markdown\ncell) may consist of a text (informative summary or indicative rationale) for\nmultiple code cells. Our work aims to solve the CDG task by encoding the\nmultiple code cells as separated AST graph structures, for which we propose a\nhierarchical attention-based ConvGNN component to augment the Seq2Seq network.\nWe build a dataset with publicly available Kaggle notebooks and evaluate our\nmodel (HAConvGNN) against baseline models (e.g., Code2Seq or Graph2Seq).\n", "versions": [{"version": "v1", "created": "Wed, 31 Mar 2021 22:36:41 GMT"}], "update_date": "2021-04-05", "authors_parsed": [["Liu", "Xuye", ""], ["Wang", "Dakuo", ""], ["Wang", "April", ""], ["Wu", "Lingfei", ""]]}, {"id": "2104.01021", "submitter": "Matthew Schmittle", "authors": "Matthew Schmittle, Sanjiban Choudhury, Siddhartha S. Srinivasa", "title": "Learning Online from Corrective Feedback: A Meta-Algorithm for Robotics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A key challenge in Imitation Learning (IL) is that optimal state actions\ndemonstrations are difficult for the teacher to provide. For example in\nrobotics, providing kinesthetic demonstrations on a robotic manipulator\nrequires the teacher to control multiple degrees of freedom at once. The\ndifficulty of requiring optimal state action demonstrations limits the space of\nproblems where the teacher can provide quality feedback. As an alternative to\nstate action demonstrations, the teacher can provide corrective feedback such\nas their preferences or rewards. Prior work has created algorithms designed to\nlearn from specific types of noisy feedback, but across teachers and tasks\ndifferent forms of feedback may be required. Instead we propose that in order\nto learn from a diversity of scenarios we need to learn from a variety of\nfeedback. To learn from a variety of feedback we make the following insight:\nthe teacher's cost function is latent and we can model a stream of feedback as\na stream of loss functions. We then use any online learning algorithm to\nminimize the sum of these losses. With this insight we can learn from a\ndiversity of feedback that is weakly correlated with the teacher's true cost\nfunction. We unify prior work into a general corrective feedback meta-algorithm\nand show that regardless of feedback we can obtain the same regret bounds. We\ndemonstrate our approach by learning to perform a household navigation task on\na robotic racecar platform. Our results show that our approach can learn\nquickly from a variety of noisy feedback.\n", "versions": [{"version": "v1", "created": "Fri, 2 Apr 2021 12:42:12 GMT"}], "update_date": "2021-04-05", "authors_parsed": [["Schmittle", "Matthew", ""], ["Choudhury", "Sanjiban", ""], ["Srinivasa", "Siddhartha S.", ""]]}, {"id": "2104.01024", "submitter": "Burak Turhan", "authors": "Seyedrebvar Hosseini and Burak Turhan", "title": "A Comparison of Similarity Based Instance Selection Methods for Cross\n  Project Defect Prediction", "comments": "The 36th ACM/SIGAPP Symposium on Applied Computing (SAC'21), 10 pages", "journal-ref": null, "doi": "10.1145/3412841.3442020", "report-no": null, "categories": "cs.LG cs.AI cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Context: Previous studies have shown that training data instance selection\nbased on nearest neighborhood (NN) information can lead to better performance\nin cross project defect prediction (CPDP) by reducing heterogeneity in training\ndatasets. However, neighborhood calculation is computationally expensive and\napproximate methods such as Locality Sensitive Hashing (LSH) can be as\neffective as exact methods. Aim: We aim at comparing instance selection methods\nfor CPDP, namely LSH, NN-filter, and Genetic Instance Selection (GIS). Method:\nWe conduct experiments with five base learners, optimizing their hyper\nparameters, on 13 datasets from PROMISE repository in order to compare the\nperformance of LSH with benchmark instance selection methods NN-Filter and GIS.\nResults: The statistical tests show six distinct groups for F-measure\nperformance. The top two group contains only LSH and GIS benchmarks whereas the\nbottom two groups contain only NN-Filter variants. LSH and GIS favor recall\nmore than precision. In fact, for precision performance only three\nsignificantly distinct groups are detected by the tests where the top group is\ncomprised of NN-Filter variants only. Recall wise, 16 different groups are\nidentified where the top three groups contain only LSH methods, four of the\nnext six are GIS only and the bottom five contain only NN-Filter. Finally,\nNN-Filter benchmarks never outperform the LSH counterparts with the same base\nlearner, tuned or non-tuned. Further, they never even belong to the same rank\ngroup, meaning that LSH is always significantly better than NN-Filter with the\nsame learner and settings. Conclusions: The increase in performance and the\ndecrease in computational overhead and runtime make LSH a promising approach.\nHowever, the performance of LSH is based on high recall and in environments\nwhere precision is considered more important NN-Filter should be considered.\n", "versions": [{"version": "v1", "created": "Fri, 2 Apr 2021 12:50:44 GMT"}], "update_date": "2021-04-05", "authors_parsed": [["Hosseini", "Seyedrebvar", ""], ["Turhan", "Burak", ""]]}, {"id": "2104.01027", "submitter": "Wei-Ning Hsu", "authors": "Wei-Ning Hsu, Anuroop Sriram, Alexei Baevski, Tatiana Likhomanenko,\n  Qiantong Xu, Vineel Pratap, Jacob Kahn, Ann Lee, Ronan Collobert, Gabriel\n  Synnaeve, Michael Auli", "title": "Robust wav2vec 2.0: Analyzing Domain Shift in Self-Supervised\n  Pre-Training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.CL cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Self-supervised learning of speech representations has been a very active\nresearch area but most work is focused on a single domain such as read audio\nbooks for which there exist large quantities of labeled and unlabeled data. In\nthis paper, we explore more general setups where the domain of the unlabeled\ndata for pre-training data differs from the domain of the labeled data for\nfine-tuning, which in turn may differ from the test data domain. Our\nexperiments show that using target domain data during pre-training leads to\nlarge performance improvements across a variety of setups. On a large-scale\ncompetitive setup, we show that pre-training on unlabeled in-domain data\nreduces the gap between models trained on in-domain and out-of-domain labeled\ndata by 66%-73%. This has obvious practical implications since it is much\neasier to obtain unlabeled target domain data than labeled data. Moreover, we\nfind that pre-training on multiple domains improves generalization performance\non domains not seen during training. Code and models will be made available at\nhttps://github.com/pytorch/fairseq.\n", "versions": [{"version": "v1", "created": "Fri, 2 Apr 2021 12:53:15 GMT"}], "update_date": "2021-04-05", "authors_parsed": [["Hsu", "Wei-Ning", ""], ["Sriram", "Anuroop", ""], ["Baevski", "Alexei", ""], ["Likhomanenko", "Tatiana", ""], ["Xu", "Qiantong", ""], ["Pratap", "Vineel", ""], ["Kahn", "Jacob", ""], ["Lee", "Ann", ""], ["Collobert", "Ronan", ""], ["Synnaeve", "Gabriel", ""], ["Auli", "Michael", ""]]}, {"id": "2104.01029", "submitter": "Tiago Santos", "authors": "Tiago Santos, Florian Lemmerich, Denis Helic", "title": "Surfacing Estimation Uncertainty in the Decay Parameters of Hawkes\n  Processes with Exponential Kernels", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  As a tool for capturing irregular temporal dependencies (rather than\nresorting to binning temporal observations to construct time series), Hawkes\nprocesses with exponential decay have seen widespread adoption across many\napplication domains, such as predicting the occurrence time of the next\nearthquake or stock market spike. However, practical applications of Hawkes\nprocesses face a noteworthy challenge: There is substantial and often\nunquantified variance in decay parameter estimations, especially in the case of\na small number of observations or when the dynamics behind the observed data\nsuddenly change. We empirically study the cause of these practical challenges\nand we develop an approach to surface and thereby mitigate them. In particular,\nour inspections of the Hawkes process likelihood function uncover the\nproperties of the uncertainty when fitting the decay parameter. We thus propose\nto explicitly capture this uncertainty within a Bayesian framework. With a\nseries of experiments with synthetic and real-world data from domains such as\n\"classical\" earthquake modeling or the manifestation of collective emotions on\nTwitter, we demonstrate that our proposed approach helps to quantify\nuncertainty and thereby to understand and fit Hawkes processes in practice.\n", "versions": [{"version": "v1", "created": "Fri, 2 Apr 2021 12:58:56 GMT"}], "update_date": "2021-04-05", "authors_parsed": [["Santos", "Tiago", ""], ["Lemmerich", "Florian", ""], ["Helic", "Denis", ""]]}, {"id": "2104.01033", "submitter": "Bas Vroling", "authors": "Bas Vroling and Stephan Heijl", "title": "White paper: The Helix Pathogenicity Prediction Platform", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.GN cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this white paper we introduce Helix, an AI based solution for missense\npathogenicity prediction. With recent advances in the sequencing of human\ngenomes, massive amounts of genetic data have become available. This has\nshifted the burden of labor for genetic diagnostics and research from the\ngathering of data to its interpretation. Helix presents a state of the art\nplatform for the prediction of pathogenicity in human missense variants. In\naddition to offering best-in-class predictive performance, Helix offers a\nplatform that allows researchers to analyze and interpret variants in depth\nthat can be accessed at helixlabs.ai.\n", "versions": [{"version": "v1", "created": "Fri, 2 Apr 2021 13:09:11 GMT"}, {"version": "v2", "created": "Mon, 3 May 2021 10:05:54 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Vroling", "Bas", ""], ["Heijl", "Stephan", ""]]}, {"id": "2104.01036", "submitter": "Chong Zheng", "authors": "Chong Zheng and Shengheng Liu and Yongming Huang and Luxi Yang", "title": "Hybrid Policy Learning for Energy-Latency Tradeoff in MEC-Assisted VR\n  Video Service", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Virtual reality (VR) is promising to fundamentally transform a broad spectrum\nof industry sectors and the way humans interact with virtual content. However,\ndespite unprecedented progress, current networking and computing\ninfrastructures are incompetent to unlock VR's full potential. In this paper,\nwe consider delivering the wireless multi-tile VR video service over a mobile\nedge computing (MEC) network. The primary goal is to minimize the system\nlatency/energy consumption and to arrive at a tradeoff thereof. To this end, we\nfirst cast the time-varying view popularity as a model-free Markov chain to\neffectively capture its dynamic characteristics. After jointly assessing the\ncaching and computing capacities on both the MEC server and the VR playback\ndevice, a hybrid policy is then implemented to coordinate the dynamic caching\nreplacement and the deterministic offloading, so as to fully utilize the system\nresources. The underlying multi-objective problem is reformulated as a\npartially observable Markov decision process, and a deep deterministic policy\ngradient algorithm is proposed to iteratively learn its solution, where a long\nshort-term memory neural network is embedded to continuously predict the\ndynamics of the unobservable popularity. Simulation results demonstrate the\nsuperiority of the proposed scheme in achieving a trade-off between the energy\nefficiency and the latency reduction over the baseline methods.\n", "versions": [{"version": "v1", "created": "Fri, 2 Apr 2021 13:17:11 GMT"}], "update_date": "2021-04-05", "authors_parsed": [["Zheng", "Chong", ""], ["Liu", "Shengheng", ""], ["Huang", "Yongming", ""], ["Yang", "Luxi", ""]]}, {"id": "2104.01037", "submitter": "Perceval Wajsburt", "authors": "Perceval Wajsburt, Yoann Taill\\'e, Xavier Tannier", "title": "Effect of depth order on iterative nested named entity recognition\n  models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper studies the effect of the order of depth of mention on nested\nnamed entity recognition (NER) models. NER is an essential task in the\nextraction of biomedical information, and nested entities are common since\nmedical concepts can assemble to form larger entities. Conventional NER systems\nonly predict disjointed entities. Thus, iterative models for nested NER use\nmultiple predictions to enumerate all entities, imposing a predefined order\nfrom largest to smallest or smallest to largest. We design an order-agnostic\niterative model and a procedure to choose a custom order during training and\nprediction. To accommodate for this task, we propose a modification of the\nTransformer architecture to take into account the entities predicted in the\nprevious steps. We provide a set of experiments to study the model's\ncapabilities and the effects of the order on performance. Finally, we show that\nthe smallest to largest order gives the best results.\n", "versions": [{"version": "v1", "created": "Fri, 2 Apr 2021 13:18:52 GMT"}], "update_date": "2021-04-05", "authors_parsed": [["Wajsburt", "Perceval", ""], ["Taill\u00e9", "Yoann", ""], ["Tannier", "Xavier", ""]]}, {"id": "2104.01040", "submitter": "Igor Halperin", "authors": "Igor Halperin", "title": "Distributional Offline Continuous-Time Reinforcement Learning with\n  Neural Physics-Informed PDEs (SciPhy RL for DOCTR-L)", "comments": "24 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI physics.comp-ph q-fin.CP", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This paper addresses distributional offline continuous-time reinforcement\nlearning (DOCTR-L) with stochastic policies for high-dimensional optimal\ncontrol. A soft distributional version of the classical Hamilton-Jacobi-Bellman\n(HJB) equation is given by a semilinear partial differential equation (PDE).\nThis `soft HJB equation' can be learned from offline data without assuming that\nthe latter correspond to a previous optimal or near-optimal policy. A\ndata-driven solution of the soft HJB equation uses methods of Neural PDEs and\nPhysics-Informed Neural Networks developed in the field of Scientific Machine\nLearning (SciML). The suggested approach, dubbed `SciPhy RL', thus reduces\nDOCTR-L to solving neural PDEs from data. Our algorithm called Deep DOCTR-L\nconverts offline high-dimensional data into an optimal policy in one step by\nreducing it to supervised learning, instead of relying on value iteration or\npolicy iteration methods. The method enables a computable approach to the\nquality control of obtained policies in terms of both their expected returns\nand uncertainties about their values.\n", "versions": [{"version": "v1", "created": "Fri, 2 Apr 2021 13:22:14 GMT"}], "update_date": "2021-04-05", "authors_parsed": [["Halperin", "Igor", ""]]}, {"id": "2104.01042", "submitter": "Lorenzo Campoli", "authors": "Lorenzo Campoli, Elena Kustova, Polina Maltseva", "title": "Assessment of machine learning methods for state-to-state approaches", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.flu-dyn cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  It is well known that numerical simulations of high-speed reacting flows, in\nthe framework of state-to-state formulations, are the most detailed but also\noften prohibitively computationally expensive. In this work, we start to\ninvestigate the possibilities offered by the use of machine learning methods\nfor state-to-state approaches to alleviate such burden.\n  In this regard, several tasks have been identified. Firstly, we assessed the\npotential of state-of-the-art data-driven regression models based on machine\nlearning to predict the relaxation source terms which appear in the right-hand\nside of the state-to-state Euler system of equations for a one-dimensional\nreacting flow of a N$_2$/N binary mixture behind a plane shock wave. It is\nfound that, by appropriately choosing the regressor and opportunely tuning its\nhyperparameters, it is possible to achieve accurate predictions compared to the\nfull-scale state-to-state simulation in significantly shorter times.\n  Secondly, we investigated different strategies to speed-up our in-house\nstate-to-state solver by coupling it with the best-performing pre-trained\nmachine learning algorithm. The embedding of machine learning methods into\nordinary differential equations solvers may offer a speed-up of several orders\nof magnitude but some care should be paid for how and where such coupling is\nrealized. Performances are found to be strongly dependent on the mutual nature\nof the interfaced codes.\n  Finally, we aimed at inferring the full solution of the state-to-state Euler\nsystem of equations by means of a deep neural network completely by-passing the\nuse of the state-to-state solver while relying only on data. Promising results\nsuggest that deep neural networks appear to be a viable technology also for\nthese tasks.\n", "versions": [{"version": "v1", "created": "Fri, 2 Apr 2021 13:27:23 GMT"}], "update_date": "2021-04-05", "authors_parsed": [["Campoli", "Lorenzo", ""], ["Kustova", "Elena", ""], ["Maltseva", "Polina", ""]]}, {"id": "2104.01061", "submitter": "Kumar Vijay Mishra", "authors": "Kumar Vijay Mishra and M. Ashok Kumar", "title": "Information Geometry and Classical Cram\\'{e}r-Rao Type Inequalities", "comments": "34 pages, 2 figures, 1 table. arXiv admin note: text overlap with\n  arXiv:2001.04769", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG eess.SP math.DG math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We examine the role of information geometry in the context of classical\nCram\\'er-Rao (CR) type inequalities. In particular, we focus on Eguchi's theory\nof obtaining dualistic geometric structures from a divergence function and then\napplying Amari-Nagoaka's theory to obtain a CR type inequality. The classical\ndeterministic CR inequality is derived from Kullback-Leibler (KL)-divergence.\nWe show that this framework could be generalized to other CR type inequalities\nthrough four examples: $\\alpha$-version of CR inequality, generalized CR\ninequality, Bayesian CR inequality, and Bayesian $\\alpha$-CR inequality. These\nare obtained from, respectively, $I_\\alpha$-divergence (or relative\n$\\alpha$-entropy), generalized Csisz\\'ar divergence, Bayesian KL divergence,\nand Bayesian $I_\\alpha$-divergence.\n", "versions": [{"version": "v1", "created": "Fri, 2 Apr 2021 14:21:49 GMT"}, {"version": "v2", "created": "Thu, 1 Jul 2021 11:58:09 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Mishra", "Kumar Vijay", ""], ["Kumar", "M. Ashok", ""]]}, {"id": "2104.01063", "submitter": "Raghvendra Mall", "authors": "Raghvendra Mall, Shameem A. Parambath, Han Yufei, Ting Yu and Sanjay\n  Chawla", "title": "Permutation-Invariant Subgraph Discovery", "comments": "8 pages, 4 Figures, 2 Tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We introduce Permutation and Structured Perturbation Inference (PSPI), a new\nproblem formulation that abstracts many graph matching tasks that arise in\nsystems biology. PSPI can be viewed as a robust formulation of the permutation\ninference or graph matching, where the objective is to find a permutation\nbetween two graphs under the assumption that a set of edges may have undergone\na perturbation due to an underlying cause. For example, suppose there are two\ngene regulatory networks X and Y from a diseased and normal tissue\nrespectively. Then, the PSPI problem can be used to detect if there has been a\nstructural change between the two networks which can serve as a signature of\nthe disease. Besides the new problem formulation, we propose an ADMM algorithm\n(STEPD) to solve a relaxed version of the PSPI problem. An extensive case study\non comparative gene regulatory networks (GRNs) is used to demonstrate that\nSTEPD is able to accurately infer structured perturbations and thus provides a\ntool for computational biologists to identify novel prognostic signatures. A\nspectral analysis confirms that STEPD can recover small clique-like\nperturbations making it a useful tool for detecting permutation-invariant\nchanges in graphs.\n", "versions": [{"version": "v1", "created": "Fri, 2 Apr 2021 14:28:21 GMT"}], "update_date": "2021-04-05", "authors_parsed": [["Mall", "Raghvendra", ""], ["Parambath", "Shameem A.", ""], ["Yufei", "Han", ""], ["Yu", "Ting", ""], ["Chawla", "Sanjay", ""]]}, {"id": "2104.01078", "submitter": "Noyan Sevuktekin", "authors": "Noyan C. Sevuktekin and Andrew C. Singer", "title": "Blind Exploration and Exploitation of Stochastic Experts", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present blind exploration and exploitation (BEE) algorithms for\nidentifying the most reliable stochastic expert based on formulations that\nemploy posterior sampling, upper-confidence bounds, empirical Kullback-Leibler\ndivergence, and minmax methods for the stochastic multi-armed bandit problem.\nJoint sampling and consultation of experts whose opinions depend on the hidden\nand random state of the world becomes challenging in the unsupervised, or\nblind, framework as feedback from the true state is not available. We propose\nan empirically realizable measure of expert competence that can be inferred\ninstantaneously using only the opinions of other experts. This measure\npreserves the ordering of true competences and thus enables joint sampling and\nconsultation of stochastic experts based on their opinions on dynamically\nchanging tasks. Statistics derived from the proposed measure is instantaneously\navailable allowing both blind exploration-exploitation and unsupervised opinion\naggregation. We discuss how the lack of supervision affects the asymptotic\nregret of BEE architectures that rely on UCB1, KL-UCB, MOSS, IMED, and Thompson\nsampling. We demonstrate the performance of different BEE algorithms\nempirically and compare them to their standard, or supervised, counterparts.\n", "versions": [{"version": "v1", "created": "Fri, 2 Apr 2021 15:02:02 GMT"}], "update_date": "2021-04-05", "authors_parsed": [["Sevuktekin", "Noyan C.", ""], ["Singer", "Andrew C.", ""]]}, {"id": "2104.01086", "submitter": "Dan Andrei Calian", "authors": "Dan A. Calian, Florian Stimberg, Olivia Wiles, Sylvestre-Alvise\n  Rebuffi, Andras Gyorgy, Timothy Mann, Sven Gowal", "title": "Defending Against Image Corruptions Through Adversarial Augmentations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern neural networks excel at image classification, yet they remain\nvulnerable to common image corruptions such as blur, speckle noise or fog.\nRecent methods that focus on this problem, such as AugMix and DeepAugment,\nintroduce defenses that operate in expectation over a distribution of image\ncorruptions. In contrast, the literature on $\\ell_p$-norm bounded perturbations\nfocuses on defenses against worst-case corruptions. In this work, we reconcile\nboth approaches by proposing AdversarialAugment, a technique which optimizes\nthe parameters of image-to-image models to generate adversarially corrupted\naugmented images. We theoretically motivate our method and give sufficient\nconditions for the consistency of its idealized version as well as that of\nDeepAugment. Our classifiers improve upon the state-of-the-art on common image\ncorruption benchmarks conducted in expectation on CIFAR-10-C and improve\nworst-case performance against $\\ell_p$-norm bounded perturbations on both\nCIFAR-10 and ImageNet.\n", "versions": [{"version": "v1", "created": "Fri, 2 Apr 2021 15:16:39 GMT"}, {"version": "v2", "created": "Tue, 20 Apr 2021 18:30:13 GMT"}], "update_date": "2021-04-22", "authors_parsed": [["Calian", "Dan A.", ""], ["Stimberg", "Florian", ""], ["Wiles", "Olivia", ""], ["Rebuffi", "Sylvestre-Alvise", ""], ["Gyorgy", "Andras", ""], ["Mann", "Timothy", ""], ["Gowal", "Sven", ""]]}, {"id": "2104.01101", "submitter": "Linjian Ma", "authors": "Linjian Ma and Edgar Solomonik", "title": "Fast and Accurate Randomized Algorithms for Low-rank Tensor\n  Decompositions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.DS cs.LG cs.NA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Low-rank Tucker and CP tensor decompositions are powerful tools in data\nanalytics. The widely used alternating least squares (ALS) method, which solves\na sequence of over-determined least squares subproblems, is inefficient for\nlarge and sparse tensors. We propose a fast and accurate sketched ALS algorithm\nfor Tucker decomposition, which solves a sequence of sketched rank-constrained\nlinear least squares subproblems. Theoretical sketch size upper bounds are\nprovided to achieve $O(\\epsilon)$-relative error for each subproblem with two\nsketching techniques, TensorSketch and leverage score sampling. Experimental\nresults show that this new ALS algorithm, combined with a new initialization\nscheme based on randomized range finder, yields up to $22.0\\%$ relative\ndecomposition residual improvement compared to the state-of-the-art sketched\nrandomized algorithm for Tucker decomposition of various synthetic datasets.\nThis Tucker-ALS algorithm is further used to accelerate CP decomposition, by\nusing randomized Tucker compression followed by CP decomposition of the Tucker\ncore tensor. Experimental results show that this algorithm not only converges\nfaster, but also yields more accurate CP decompositions.\n", "versions": [{"version": "v1", "created": "Fri, 2 Apr 2021 15:55:02 GMT"}], "update_date": "2021-04-05", "authors_parsed": [["Ma", "Linjian", ""], ["Solomonik", "Edgar", ""]]}, {"id": "2104.01109", "submitter": "Philippe Burlina", "authors": "Neil Joshi and Phil Burlina", "title": "AI Fairness via Domain Adaptation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  While deep learning (DL) approaches are reaching human-level performance for\nmany tasks, including for diagnostics AI, the focus is now on challenges\npossibly affecting DL deployment, including AI privacy, domain generalization,\nand fairness. This last challenge is addressed in this study. Here we look at a\nnovel method for ensuring AI fairness with respect to protected or sensitive\nfactors. This method uses domain adaptation via training set enhancement to\ntackle bias-causing training data imbalance. More specifically, it uses\ngenerative models that allow the generation of more synthetic training samples\nfor underrepresented populations. This paper applies this method to the use\ncase of detection of age related macular degeneration (AMD). Our experiments\nshow that starting with an originally biased AMD diagnostics model the method\nhas the ability to improve fairness.\n", "versions": [{"version": "v1", "created": "Mon, 15 Mar 2021 22:55:51 GMT"}], "update_date": "2021-04-05", "authors_parsed": [["Joshi", "Neil", ""], ["Burlina", "Phil", ""]]}, {"id": "2104.01112", "submitter": "Sean Welleck", "authors": "Sean Welleck, Jiacheng Liu, Ronan Le Bras, Hannaneh Hajishirzi, Yejin\n  Choi, Kyunghyun Cho", "title": "NaturalProofs: Mathematical Theorem Proving in Natural Language", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding and creating mathematics using natural mathematical language -\nthe mixture of symbolic and natural language used by humans - is a challenging\nand important problem for driving progress in machine learning. As a step in\nthis direction, we develop NaturalProofs, a multi-domain corpus of mathematical\nstatements and their proofs, written in natural mathematical language.\nNaturalProofs unifies broad coverage, deep coverage, and low-resource\nmathematical sources, allowing for evaluating both in-distribution and\nzero-shot generalization. Using NaturalProofs, we benchmark strong neural\nmethods on mathematical reference retrieval and generation tasks which test a\nsystem's ability to determine key results that appear in a proof. Large-scale\nsequence models show promise compared to classical information retrieval\nmethods, yet their performance and out-of-domain generalization leave\nsubstantial room for improvement. NaturalProofs opens many avenues for research\non challenging mathematical tasks.\n", "versions": [{"version": "v1", "created": "Wed, 24 Mar 2021 03:14:48 GMT"}, {"version": "v2", "created": "Mon, 7 Jun 2021 21:58:06 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Welleck", "Sean", ""], ["Liu", "Jiacheng", ""], ["Bras", "Ronan Le", ""], ["Hajishirzi", "Hannaneh", ""], ["Choi", "Yejin", ""], ["Cho", "Kyunghyun", ""]]}, {"id": "2104.01113", "submitter": "Satvik Garg", "authors": "Satvik Garg", "title": "Drug Recommendation System based on Sentiment Analysis of Drug Reviews\n  using Machine Learning", "comments": "7 pages, 8 figures, 2021 11th International Conference on Cloud\n  Computing, Data Science & Engineering (Confluence)", "journal-ref": null, "doi": "10.1109/Confluence51648.2021.9377188", "report-no": null, "categories": "cs.IR cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Since coronavirus has shown up, inaccessibility of legitimate clinical\nresources is at its peak, like the shortage of specialists, healthcare workers,\nlack of proper equipment and medicines. The entire medical fraternity is in\ndistress, which results in numerous individuals demise. Due to unavailability,\npeople started taking medication independently without appropriate\nconsultation, making the health condition worse than usual. As of late, machine\nlearning has been valuable in numerous applications, and there is an increase\nin innovative work for automation. This paper intends to present a drug\nrecommender system that can drastically reduce specialists heap. In this\nresearch, we build a medicine recommendation system that uses patient reviews\nto predict the sentiment using various vectorization processes like Bow, TFIDF,\nWord2Vec, and Manual Feature Analysis, which can help recommend the top drug\nfor a given disease by different classification algorithms. The predicted\nsentiments were evaluated by precision, recall, f1score, accuracy, and AUC\nscore. The results show that classifier LinearSVC using TFIDF vectorization\noutperforms all other models with 93% accuracy.\n", "versions": [{"version": "v1", "created": "Wed, 24 Mar 2021 10:11:18 GMT"}, {"version": "v2", "created": "Mon, 5 Apr 2021 03:19:32 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Garg", "Satvik", ""]]}, {"id": "2104.01117", "submitter": "Sami Diaf", "authors": "Sami Diaf and Ulrich Fritsche", "title": "Topic Scaling: A Joint Document Scaling -- Topic Model Approach To Learn\n  Time-Specific Topics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper proposes a new methodology to study sequential corpora by\nimplementing a two-stage algorithm that learns time-based topics with respect\nto a scale of document positions and introduces the concept of Topic Scaling\nwhich ranks learned topics within the same document scale. The first stage\nranks documents using Wordfish, a Poisson-based document scaling method, to\nestimate document positions that serve, in the second stage, as a dependent\nvariable to learn relevant topics via a supervised Latent Dirichlet Allocation.\nThis novelty brings two innovations in text mining as it explains document\npositions, whose scale is a latent variable, and ranks the inferred topics on\nthe document scale to match their occurrences within the corpus and track their\nevolution. Tested on the U.S. State Of The Union two-party addresses, this\ninductive approach reveals that each party dominates one end of the learned\nscale with interchangeable transitions that follow the parties' term of office.\nBesides a demonstrated high accuracy in predicting in-sample documents'\npositions from topic scores, this method reveals further hidden topics that\ndifferentiate similar documents by increasing the number of learned topics to\nunfold potential nested hierarchical topic structures. Compared to other\npopular topic models, Topic Scaling learns topics with respect to document\nsimilarities without specifying a time frequency to learn topic evolution, thus\ncapturing broader topic patterns than dynamic topic models and yielding more\ninterpretable outputs than a plain latent Dirichlet allocation.\n", "versions": [{"version": "v1", "created": "Wed, 31 Mar 2021 12:35:36 GMT"}], "update_date": "2021-04-05", "authors_parsed": [["Diaf", "Sami", ""], ["Fritsche", "Ulrich", ""]]}, {"id": "2104.01120", "submitter": "Anastasios Tsiamis", "authors": "Anastasios Tsiamis and George J. Pappas", "title": "Linear Systems can be Hard to Learn", "comments": "Under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.LG cs.SY math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we investigate when system identification is statistically\neasy or hard, in the finite sample regime. Statistically easy to learn linear\nsystem classes have sample complexity that is polynomial with the system\ndimension. Most prior research in the finite sample regime falls in this\ncategory, focusing on systems that are directly excited by process noise.\nStatistically hard to learn linear system classes have worst-case sample\ncomplexity that is at least exponential with the system dimension, regardless\nof the identification algorithm. Using tools from minimax theory, we show that\nclasses of linear systems can be hard to learn. Such classes include, for\nexample, under-actuated or under-excited systems with weak coupling among the\nstates. Having classified some systems as easy or hard to learn, a natural\nquestion arises as to what system properties fundamentally affect the hardness\nof system identifiability. Towards this direction, we characterize how the\ncontrollability index of linear systems affects the sample complexity of\nidentification. More specifically, we show that the sample complexity of\nrobustly controllable linear systems is upper bounded by an exponential\nfunction of the controllability index. This implies that identification is easy\nfor classes of linear systems with small controllability index and potentially\nhard if the controllability index is large. Our analysis is based on recent\nstatistical tools for finite sample analysis of system identification as well\nas a novel lower bound that relates controllability index with the least\nsingular value of the controllability Gramian.\n", "versions": [{"version": "v1", "created": "Fri, 2 Apr 2021 15:58:30 GMT"}], "update_date": "2021-04-05", "authors_parsed": [["Tsiamis", "Anastasios", ""], ["Pappas", "George J.", ""]]}, {"id": "2104.01126", "submitter": "Yiqiu Wang", "authors": "Yiqiu Wang, Shangdi Yu, Yan Gu, Julian Shun", "title": "Fast Parallel Algorithms for Euclidean Minimum Spanning Tree and\n  Hierarchical Spatial Clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DB cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents new parallel algorithms for generating Euclidean minimum\nspanning trees and spatial clustering hierarchies (known as HDBSCAN$^*$). Our\napproach is based on generating a well-separated pair decomposition followed by\nusing Kruskal's minimum spanning tree algorithm and bichromatic closest pair\ncomputations. We introduce a new notion of well-separation to reduce the work\nand space of our algorithm for HDBSCAN$^*$. We also present a parallel\napproximate algorithm for OPTICS based on a recent sequential algorithm by Gan\nand Tao. Finally, we give a new parallel divide-and-conquer algorithm for\ncomputing the dendrogram and reachability plots, which are used in visualizing\nclusters of different scale that arise for both EMST and HDBSCAN$^*$. We show\nthat our algorithms are theoretically efficient: they have work (number of\noperations) matching their sequential counterparts, and polylogarithmic depth\n(parallel time).\n  We implement our algorithms and propose a memory optimization that requires\nonly a subset of well-separated pairs to be computed and materialized, leading\nto savings in both space (up to 10x) and time (up to 8x). Our experiments on\nlarge real-world and synthetic data sets using a 48-core machine show that our\nfastest algorithms outperform the best serial algorithms for the problems by\n11.13--55.89x, and existing parallel algorithms by at least an order of\nmagnitude.\n", "versions": [{"version": "v1", "created": "Fri, 2 Apr 2021 16:05:00 GMT"}], "update_date": "2021-04-05", "authors_parsed": [["Wang", "Yiqiu", ""], ["Yu", "Shangdi", ""], ["Gu", "Yan", ""], ["Shun", "Julian", ""]]}, {"id": "2104.01129", "submitter": "Yu Zhang", "authors": "Yu Zhang and Martijn Tennekes and Tim de Jong and Lyana Curier and Bob\n  Coecke and Min Chen", "title": "Using Simulation to Aid the Design and Optimization of Intelligent User\n  Interfaces for Quality Assurance Processes in Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Many mission-critical applications of machine learning (ML) in the real-world\nrequire a quality assurance (QA) process before the decisions or predictions of\nan ML model can be deployed. Because QA4ML users have to view a non-trivial\namount of data and perform many input actions to correct errors made by the ML\nmodel, an optimally-designed user interface (UI) can reduce the cost of\ninteractions significantly. A UI's effectiveness can be affected by many\nfactors, such as the number of data objects processed concurrently, the types\nof commands for correcting errors, and the availability of algorithms for\nassisting users. We propose using simulation to aid the design and optimization\nof intelligent user interfaces for QA4ML processes. In particular, we focus on\nsimulating the combined effects of human intelligence in selecting appropriate\ncommands and algorithms, and machine intelligence in providing a collection of\ngeneral-purpose algorithms for reordering data objects to be quality-assured.\n", "versions": [{"version": "v1", "created": "Fri, 2 Apr 2021 16:10:24 GMT"}], "update_date": "2021-04-05", "authors_parsed": [["Zhang", "Yu", ""], ["Tennekes", "Martijn", ""], ["de Jong", "Tim", ""], ["Curier", "Lyana", ""], ["Coecke", "Bob", ""], ["Chen", "Min", ""]]}, {"id": "2104.01137", "submitter": "Spencer He", "authors": "Spencer He and Ryan Liu", "title": "Developing a New Autism Diagnosis Process Based on a Hybrid Deep\n  Learning Architecture Through Analyzing Home Videos", "comments": "11 pages, 3 figures, 4 tables Accepted by International Conference on\n  Artificial Intelligence and Machine Learning for Healthcare Applications\n  (ICAIMLHA 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Currently, every 1 in 54 children have been diagnosed with Autism Spectrum\nDisorder (ASD), which is 178% higher than it was in 2000. An early diagnosis\nand treatment can significantly increase the chances of going off the spectrum\nand making a full recovery. With a multitude of physical and behavioral tests\nfor neurological and communication skills, diagnosing ASD is very complex,\nsubjective, time-consuming, and expensive. We hypothesize that the use of\nmachine learning analysis on facial features and social behavior can speed up\nthe diagnosis of ASD without compromising real-world performance. We propose to\ndevelop a hybrid architecture using both categorical data and image data to\nautomate traditional ASD pre-screening, which makes diagnosis a quicker and\neasier process. We created and tested a Logistic Regression model and a Linear\nSupport Vector Machine for Module 1, which classifies ADOS categorical data. A\nConvolutional Neural Network and a DenseNet network are used for module 2,\nwhich classifies video data. Finally, we combined the best performing models, a\nLinear SVM and DenseNet, using three data averaging strategies. We used a\nstandard average, weighted based on number of training data, and weighted based\non the number of ASD patients in the training data to average the results,\nthereby increasing accuracy in clinical applications. The results we obtained\nsupport our hypothesis. Our novel architecture is able to effectively automate\nASD pre-screening with a maximum weighted accuracy of 84%.\n", "versions": [{"version": "v1", "created": "Fri, 2 Apr 2021 17:30:35 GMT"}], "update_date": "2021-04-05", "authors_parsed": [["He", "Spencer", ""], ["Liu", "Ryan", ""]]}, {"id": "2104.01148", "submitter": "Karl Stelzner", "authors": "Karl Stelzner, Kristian Kersting, Adam R. Kosiorek", "title": "Decomposing 3D Scenes into Objects via Unsupervised Volume Segmentation", "comments": "15 pages, 3 figures. For project page with videos, see\n  http://stelzner.github.io/obsurf/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present ObSuRF, a method which turns a single image of a scene into a 3D\nmodel represented as a set of Neural Radiance Fields (NeRFs), with each NeRF\ncorresponding to a different object. A single forward pass of an encoder\nnetwork outputs a set of latent vectors describing the objects in the scene.\nThese vectors are used independently to condition a NeRF decoder, defining the\ngeometry and appearance of each object. We make learning more computationally\nefficient by deriving a novel loss, which allows training NeRFs on RGB-D inputs\nwithout explicit ray marching. After confirming that the model performs equal\nor better than state of the art on three 2D image segmentation benchmarks, we\napply it to two multi-object 3D datasets: A multiview version of CLEVR, and a\nnovel dataset in which scenes are populated by ShapeNet models. We find that\nafter training ObSuRF on RGB-D views of training scenes, it is capable of not\nonly recovering the 3D geometry of a scene depicted in a single input image,\nbut also to segment it into objects, despite receiving no supervision in that\nregard.\n", "versions": [{"version": "v1", "created": "Fri, 2 Apr 2021 16:59:29 GMT"}], "update_date": "2021-04-05", "authors_parsed": [["Stelzner", "Karl", ""], ["Kersting", "Kristian", ""], ["Kosiorek", "Adam R.", ""]]}, {"id": "2104.01156", "submitter": "Debanjan Datta", "authors": "Debanjan Datta, Sathappan Muthiah and Naren Ramakrishnan", "title": "Detecting Anomalies Through Contrast in Heterogeneous Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Detecting anomalies has been a fundamental approach in detecting potentially\nfraudulent activities. Tasked with detection of illegal timber trade that\nthreatens ecosystems and economies and association with other illegal\nactivities, we formulate our problem as one of anomaly detection. Among other\nchallenges annotations are unavailable for our large-scale trade data with\nheterogeneous features (categorical and continuous), that can assist in\nbuilding automated systems to detect fraudulent transactions. Modelling the\ntask as unsupervised anomaly detection, we propose a novel model Contrastive\nLearning based Heterogeneous Anomaly Detector to address shortcomings of prior\nmodels. Our model uses an asymmetric autoencoder that can effectively handle\nlarge arity categorical variables, but avoids assumptions about structure of\ndata in low-dimensional latent space and is robust to changes to\nhyper-parameters. The likelihood of data is approximated through an estimator\nnetwork, which is jointly trained with the autoencoder,using negative sampling.\nFurther the details and intuition for an effective negative sample generation\napproach for heterogeneous data are outlined. We provide a qualitative study to\nshowcase the effectiveness of our model in detecting anomalies in timber trade.\n", "versions": [{"version": "v1", "created": "Fri, 2 Apr 2021 17:21:12 GMT"}], "update_date": "2021-04-05", "authors_parsed": [["Datta", "Debanjan", ""], ["Muthiah", "Sathappan", ""], ["Ramakrishnan", "Naren", ""]]}, {"id": "2104.01177", "submitter": "Colin White", "authors": "Colin White, Arber Zela, Binxin Ru, Yang Liu, Frank Hutter", "title": "How Powerful are Performance Predictors in Neural Architecture Search?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Early methods in the rapidly developing field of neural architecture search\n(NAS) required fully training thousands of neural networks. To reduce this\nextreme computational cost, dozens of techniques have since been proposed to\npredict the final performance of neural architectures. Despite the success of\nsuch performance prediction methods, it is not well-understood how different\nfamilies of techniques compare to one another, due to the lack of an\nagreed-upon evaluation metric and optimization for different constraints on the\ninitialization time and query time. In this work, we give the first large-scale\nstudy of performance predictors by analyzing 31 techniques ranging from\nlearning curve extrapolation, to weight-sharing, to supervised learning, to\n\"zero-cost\" proxies. We test a number of correlation- and rank-based\nperformance measures in a variety of settings, as well as the ability of each\ntechnique to speed up predictor-based NAS frameworks. Our results act as\nrecommendations for the best predictors to use in different settings, and we\nshow that certain families of predictors can be combined to achieve even better\npredictive power, opening up promising research directions. Our code, featuring\na library of 31 performance predictors, is available at\nhttps://github.com/automl/naslib.\n", "versions": [{"version": "v1", "created": "Fri, 2 Apr 2021 17:57:16 GMT"}], "update_date": "2021-04-05", "authors_parsed": [["White", "Colin", ""], ["Zela", "Arber", ""], ["Ru", "Binxin", ""], ["Liu", "Yang", ""], ["Hutter", "Frank", ""]]}, {"id": "2104.01188", "submitter": "Yamin Arefeen", "authors": "Yamin Arefeen (1), Onur Beker (2), Jaejin Cho (3), Heng Yu (4), Elfar\n  Adalsteinsson (1 and 5 and 6), Berkin Bilgic (3 and 5 and 7) ((1)\n  Massachusetts Institute of Technology, (2) \\'Ecole Polytechnique F\\'ed\\'erale\n  de Lausanne, (3) Athinoula A. Martinos Center for Biomedical Imaging (4)\n  Tsinghua University, (5) Harvard-MIT Health Sciences and Technology, (6)\n  Institute for Medical Engineering and Science, (7) Harvard Medical School)", "title": "Scan Specific Artifact Reduction in K-space (SPARK) Neural Networks\n  Synergize with Physics-based Reconstruction to Accelerate MRI", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG physics.med-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Purpose: To develop a scan-specific model that estimates and corrects k-space\nerrors made when reconstructing accelerated Magnetic Resonance Imaging (MRI)\ndata.\n  Methods: Scan-Specific Artifact Reduction in k-space (SPARK) trains a\nconvolutional-neural-network to estimate and correct k-space errors made by an\ninput reconstruction technique by back-propagating from the mean-squared-error\nloss between an auto-calibration signal (ACS) and the input technique's\nreconstructed ACS. First, SPARK is applied to GRAPPA and demonstrates improved\nrobustness over other scan-specific models, such as RAKI and residual-RAKI.\nSubsequent experiments demonstrate that SPARK synergizes with residual-RAKI to\nimprove reconstruction performance. SPARK also improves reconstruction quality\nwhen applied to advanced acquisition and reconstruction techniques like 2D\nvirtual coil (VC-) GRAPPA, 2D LORAKS, 3D GRAPPA without an integrated ACS\nregion, and 2D/3D wave-encoded images.\n  Results: SPARK yields 1.5x - 2x RMSE reduction when applied to GRAPPA and\nimproves robustness to ACS size for various acceleration rates in comparison to\nother scan-specific techniques. When applied to advanced reconstruction\ntechniques such as residual-RAKI, 2D VC-GRAPPA and LORAKS, SPARK achieves up to\n20% RMSE improvement. SPARK with 3D GRAPPA also improves performance by ~2x and\nperceived image quality without a fully sampled ACS region. Finally, SPARK\nsynergizes with non-cartesian 2D and 3D wave-encoding imaging by reducing RMSE\nbetween 20-25% and providing qualitative improvements.\n  Conclusion: SPARK synergizes with physics-based acquisition and\nreconstruction techniques to improve accelerated MRI by training scan-specific\nmodels to estimate and correct reconstruction errors in k-space.\n", "versions": [{"version": "v1", "created": "Fri, 2 Apr 2021 18:11:06 GMT"}, {"version": "v2", "created": "Mon, 19 Jul 2021 20:05:56 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Arefeen", "Yamin", "", "1 and 5 and 6"], ["Beker", "Onur", "", "1 and 5 and 6"], ["Cho", "Jaejin", "", "1 and 5 and 6"], ["Yu", "Heng", "", "1 and 5 and 6"], ["Adalsteinsson", "Elfar", "", "1 and 5 and 6"], ["Bilgic", "Berkin", "", "3 and 5 and 7"]]}, {"id": "2104.01193", "submitter": "Ana Ozaki", "authors": "Ana Ozaki", "title": "Learning Description Logic Ontologies. Five Approaches. Where Do They\n  Stand?", "comments": null, "journal-ref": "KI Kunstliche Intelligenz (2020) 34 317-327", "doi": "10.1007/s13218-020-00656-9", "report-no": null, "categories": "cs.AI cs.LG cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The quest for acquiring a formal representation of the knowledge of a domain\nof interest has attracted researchers with various backgrounds into a diverse\nfield called ontology learning. We highlight classical machine learning and\ndata mining approaches that have been proposed for (semi-)automating the\ncreation of description logic (DL) ontologies. These are based on association\nrule mining, formal concept analysis, inductive logic programming,\ncomputational learning theory, and neural networks. We provide an overview of\neach approach and how it has been adapted for dealing with DL ontologies.\nFinally, we discuss the benefits and limitations of each of them for learning\nDL ontologies.\n", "versions": [{"version": "v1", "created": "Fri, 2 Apr 2021 18:36:45 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Ozaki", "Ana", ""]]}, {"id": "2104.01194", "submitter": "Amanpreet Singh", "authors": "Amanpreet Singh, Martin Bauer, Sarang Joshi", "title": "Physics Informed Convex Artificial Neural Networks (PICANNs) for Optimal\n  Transport based Density Estimation", "comments": "15 page, 6 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Optimal Mass Transport (OMT) is a well studied problem with a variety of\napplications in a diverse set of fields ranging from Physics to Computer Vision\nand in particular Statistics and Data Science. Since the original formulation\nof Monge in 1781 significant theoretical progress been made on the existence,\nuniqueness and properties of the optimal transport maps. The actual numerical\ncomputation of the transport maps, particularly in high dimensions, remains a\nchallenging problem. By Brenier's theorem, the continuous OMT problem can be\nreduced to that of solving a non-linear PDE of Monge-Ampere type whose solution\nis a convex function. In this paper, building on recent developments of input\nconvex neural networks and physics informed neural networks for solving PDE's,\nwe propose a Deep Learning approach to solve the continuous OMT problem.\n  To demonstrate the versatility of our framework we focus on the ubiquitous\ndensity estimation and generative modeling tasks in statistics and machine\nlearning. Finally as an example we show how our framework can be incorporated\nwith an autoencoder to estimate an effective probabilistic generative model.\n", "versions": [{"version": "v1", "created": "Fri, 2 Apr 2021 18:44:11 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Singh", "Amanpreet", ""], ["Bauer", "Martin", ""], ["Joshi", "Sarang", ""]]}, {"id": "2104.01207", "submitter": "Sarthak Dash", "authors": "Sarthak Dash, Nandana Mihindukulasooriya, Alfio Gliozzo, Mustafa Canim", "title": "Type Prediction Systems", "comments": "5 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Inferring semantic types for entity mentions within text documents is an\nimportant asset for many downstream NLP tasks, such as Semantic Role Labelling,\nEntity Disambiguation, Knowledge Base Question Answering, etc. Prior works have\nmostly focused on supervised solutions that generally operate on relatively\nsmall-to-medium-sized type systems. In this work, we describe two systems aimed\nat predicting type information for the following two tasks, namely, a\nTypeSuggest module, an unsupervised system designed to predict types for a set\nof user-entered query terms, and an Answer Type prediction module, that\nprovides a solution for the task of determining the correct type of the answer\nexpected to a given query. Our systems generalize to arbitrary type systems of\nany sizes, thereby making it a highly appealing solution to extract type\ninformation at any granularity.\n", "versions": [{"version": "v1", "created": "Fri, 2 Apr 2021 19:16:42 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Dash", "Sarthak", ""], ["Mihindukulasooriya", "Nandana", ""], ["Gliozzo", "Alfio", ""], ["Canim", "Mustafa", ""]]}, {"id": "2104.01214", "submitter": "Inon Peled", "authors": "Inon Peled, Filipe Rodrigues, Francisco C. Pereira", "title": "Modeling Censored Mobility Demand through Quantile Regression Neural\n  Networks", "comments": "13 pages, 7 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Shared mobility services require accurate demand models for effective service\nplanning. On one hand, modeling the full probability distribution of demand is\nadvantageous, because the full uncertainty structure preserves valuable\ninformation for decision making. On the other hand, demand is often observed\nthrough usage of the service itself, so that the observations are censored, as\nthey are inherently limited by available supply. Since the 1980s, various works\non Censored Quantile Regression models have shown them to perform well under\nsuch conditions, and in the last two decades, several works have proposed to\nimplement them flexibly through Neural Networks (CQRNN). However, apparently no\nworks have yet applied CQRNN in the Transport domain. We address this gap by\napplying CQRNN to datasets from two shared mobility providers in the Copenhagen\nmetropolitan area in Denmark, as well as common synthetic baseline datasets.\nThe results show that CQRNN can estimate the intended distributions better than\nboth censorship-unaware models and parametric censored models.\n", "versions": [{"version": "v1", "created": "Fri, 2 Apr 2021 19:24:15 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Peled", "Inon", ""], ["Rodrigues", "Filipe", ""], ["Pereira", "Francisco C.", ""]]}, {"id": "2104.01231", "submitter": "Theodoros Tsiligkaridis", "authors": "Athanasios Tsiligkaridis, Theodoros Tsiligkaridis", "title": "Misclassification-Aware Gaussian Smoothing improves Robustness against\n  Domain Shifts", "comments": "16 pages, submitted", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deep neural networks achieve high prediction accuracy when the train and test\ndistributions coincide. However, in practice various types of corruptions can\ndeviate from this setup and performance can be heavily degraded. There have\nbeen only a few methods to address generalization in presence of unexpected\ndomain shifts observed during deployment. In this paper, a\nmisclassification-aware Gaussian smoothing approach is presented to improve the\nrobustness of image classifiers against a variety of corruptions while\nmaintaining clean accuracy. The intuition behind our proposed\nmisclassification-aware objective is revealed through bounds on the local loss\ndeviation in the small-noise regime. When our method is coupled with additional\ndata augmentations, it is empirically shown to improve upon the\nstate-of-the-art in robustness and uncertainty calibration on several image\nclassification tasks.\n", "versions": [{"version": "v1", "created": "Fri, 2 Apr 2021 20:25:53 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Tsiligkaridis", "Athanasios", ""], ["Tsiligkaridis", "Theodoros", ""]]}, {"id": "2104.01233", "submitter": "Ravikiran Mane", "authors": "Ravikiran Mane, Effie Chew, Karen Chua, Kai Keng Ang, Neethu Robinson,\n  A. P. Vinod, Seong-Whan Lee, Cuntai Guan", "title": "FBCNet: A Multi-view Convolutional Neural Network for Brain-Computer\n  Interface", "comments": "This work has been submitted to the IEEE for possible publication.\n  Copyright may be transferred without notice, after which this version may no\n  longer be accessible", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.OH cs.AI cs.LG eess.SP", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Lack of adequate training samples and noisy high-dimensional features are key\nchallenges faced by Motor Imagery (MI) decoding algorithms for\nelectroencephalogram (EEG) based Brain-Computer Interface (BCI). To address\nthese challenges, inspired from neuro-physiological signatures of MI, this\npaper proposes a novel Filter-Bank Convolutional Network (FBCNet) for MI\nclassification. FBCNet employs a multi-view data representation followed by\nspatial filtering to extract spectro-spatially discriminative features. This\nmultistage approach enables efficient training of the network even when limited\ntraining data is available. More significantly, in FBCNet, we propose a novel\nVariance layer that effectively aggregates the EEG time-domain information.\nWith this design, we compare FBCNet with state-of-the-art (SOTA) BCI algorithm\non four MI datasets: The BCI competition IV dataset 2a (BCIC-IV-2a), the\nOpenBMI dataset, and two large datasets from chronic stroke patients. The\nresults show that, by achieving 76.20% 4-class classification accuracy, FBCNet\nsets a new SOTA for BCIC-IV-2a dataset. On the other three datasets, FBCNet\nyields up to 8% higher binary classification accuracies. Additionally, using\nexplainable AI techniques we present one of the first reports about the\ndifferences in discriminative EEG features between healthy subjects and stroke\npatients. Also, the FBCNet source code is available at\nhttps://github.com/ravikiran-mane/FBCNet.\n", "versions": [{"version": "v1", "created": "Wed, 17 Mar 2021 08:27:01 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Mane", "Ravikiran", ""], ["Chew", "Effie", ""], ["Chua", "Karen", ""], ["Ang", "Kai Keng", ""], ["Robinson", "Neethu", ""], ["Vinod", "A. P.", ""], ["Lee", "Seong-Whan", ""], ["Guan", "Cuntai", ""]]}, {"id": "2104.01264", "submitter": "Qingyun Dou", "authors": "Qingyun Dou, Yiting Lu, Potsawee Manakul, Xixin Wu, Mark J. F. Gales", "title": "Attention Forcing for Machine Translation", "comments": "arXiv admin note: text overlap with arXiv:1909.12289", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Auto-regressive sequence-to-sequence models with attention mechanisms have\nachieved state-of-the-art performance in various tasks including Text-To-Speech\n(TTS) and Neural Machine Translation (NMT). The standard training approach,\nteacher forcing, guides a model with the reference output history. At inference\nstage, the generated output history must be used. This mismatch can impact\nperformance. However, it is highly challenging to train the model using the\ngenerated output. Several approaches have been proposed to address this\nproblem, normally by selectively using the generated output history. To make\ntraining stable, these approaches often require a heuristic schedule or an\nauxiliary classifier. This paper introduces attention forcing for NMT. This\napproach guides the model with the generated output history and reference\nattention, and can reduce the training-inference mismatch without a schedule or\na classifier. Attention forcing has been successful in TTS, but its application\nto NMT is more challenging, due to the discrete and multi-modal nature of the\noutput space. To tackle this problem, this paper adds a selection scheme to\nvanilla attention forcing, which automatically selects a suitable training\napproach for each pair of training data. Experiments show that attention\nforcing can improve the overall translation quality and the diversity of the\ntranslations.\n", "versions": [{"version": "v1", "created": "Fri, 2 Apr 2021 22:33:42 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Dou", "Qingyun", ""], ["Lu", "Yiting", ""], ["Manakul", "Potsawee", ""], ["Wu", "Xixin", ""], ["Gales", "Mark J. F.", ""]]}, {"id": "2104.01271", "submitter": "C.-H. Huck Yang", "authors": "Chao-Han Huck Yang, Sabato Marco Siniscalchi, Chin-Hui Lee", "title": "PATE-AAE: Incorporating Adversarial Autoencoder into Private Aggregation\n  of Teacher Ensembles for Spoken Command Classification", "comments": "Accepted to Interspeech 2021", "journal-ref": "Proc. Interspeech 2021", "doi": null, "report-no": null, "categories": "cs.SD cs.AI cs.LG cs.NE eess.AS", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We propose using an adversarial autoencoder (AAE) to replace generative\nadversarial network (GAN) in the private aggregation of teacher ensembles\n(PATE), a solution for ensuring differential privacy in speech applications.\nThe AAE architecture allows us to obtain good synthetic speech leveraging upon\na discriminative training of latent vectors. Such synthetic speech is used to\nbuild a privacy-preserving classifier when non-sensitive data is not\nsufficiently available in the public domain. This classifier follows the PATE\nscheme that uses an ensemble of noisy outputs to label the synthetic samples\nand guarantee $\\varepsilon$-differential privacy (DP) on its derived\nclassifiers. Our proposed framework thus consists of an AAE-based generator and\na PATE-based classifier (PATE-AAE). Evaluated on the Google Speech Commands\nDataset Version II, the proposed PATE-AAE improves the average classification\naccuracy by +$2.11\\%$ and +$6.60\\%$, respectively, when compared with\nalternative privacy-preserving solutions, namely PATE-GAN and DP-GAN, while\nmaintaining a strong level of privacy target at $\\varepsilon$=0.01 with a fixed\n$\\delta$=10$^{-5}$.\n", "versions": [{"version": "v1", "created": "Fri, 2 Apr 2021 23:10:57 GMT"}, {"version": "v2", "created": "Tue, 15 Jun 2021 06:09:42 GMT"}], "update_date": "2021-06-25", "authors_parsed": [["Yang", "Chao-Han Huck", ""], ["Siniscalchi", "Sabato Marco", ""], ["Lee", "Chin-Hui", ""]]}, {"id": "2104.01282", "submitter": "Neelay Fruitwala", "authors": "Neelay Fruitwala and Alex B Walter and John I Bailey III and Rupert\n  Dodkins and Benjamin A Mazin", "title": "End-to-end Deep Learning Pipeline for Microwave Kinetic Inductance\n  Detector (MKID) Resonator Identification and Tuning", "comments": "28 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "astro-ph.IM cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the development of a machine learning based pipeline to fully\nautomate the calibration of the frequency comb used to read out optical/IR\nMicrowave Kinetic Inductance Detector (MKID) arrays. This process involves\ndetermining the resonant frequency and optimal drive power of every pixel (i.e.\nresonator) in the array, which is typically done manually. Modern optical/IR\nMKID arrays, such as DARKNESS (DARK-speckle Near-infrared Energy-resolving\nSuperconducting Spectrophotometer) and MEC (MKID Exoplanet Camera), contain\n10-20,000 pixels, making the calibration process extremely time consuming; each\n2000 pixel feedline requires 4-6 hours of manual tuning. Here we present a\npipeline which uses a single convolutional neural network (CNN) to perform both\nresonator identification and tuning simultaneously. We find that our pipeline\nhas performance equal to that of the manual tuning process, and requires just\ntwelve minutes of computational time per feedline.\n", "versions": [{"version": "v1", "created": "Sat, 3 Apr 2021 00:04:39 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Fruitwala", "Neelay", ""], ["Walter", "Alex B", ""], ["Bailey", "John I", "III"], ["Dodkins", "Rupert", ""], ["Mazin", "Benjamin A", ""]]}, {"id": "2104.01293", "submitter": "Daniel Shea", "authors": "Daniel E. Shea, Rajiv Giridharagopal, David S. Ginger, Steven L.\n  Brunton, J. Nathan Kutz", "title": "Extraction of instantaneous frequencies and amplitudes in nonstationary\n  time-series data", "comments": null, "journal-ref": "IEEE Access, vol. 9, pp. 83453-83466, 2021", "doi": "10.1109/ACCESS.2021.3087595", "report-no": null, "categories": "eess.SP cs.LG cs.NA math.NA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Time-series analysis is critical for a diversity of applications in science\nand engineering. By leveraging the strengths of modern gradient descent\nalgorithms, the Fourier transform, multi-resolution analysis, and Bayesian\nspectral analysis, we propose a data-driven approach to time-frequency analysis\nthat circumvents many of the shortcomings of classic approaches, including the\nextraction of nonstationary signals with discontinuities in their behavior. The\nmethod introduced is equivalent to a {\\em nonstationary Fourier mode\ndecomposition} (NFMD) for nonstationary and nonlinear temporal signals,\nallowing for the accurate identification of instantaneous frequencies and their\namplitudes. The method is demonstrated on a diversity of time-series data,\nincluding on data from cantilever-based electrostatic force microscopy to\nquantify the time-dependent evolution of charging dynamics at the nanoscale.\n", "versions": [{"version": "v1", "created": "Sat, 3 Apr 2021 02:19:07 GMT"}], "update_date": "2021-06-23", "authors_parsed": [["Shea", "Daniel E.", ""], ["Giridharagopal", "Rajiv", ""], ["Ginger", "David S.", ""], ["Brunton", "Steven L.", ""], ["Kutz", "J. Nathan", ""]]}, {"id": "2104.01303", "submitter": "Xizi Chen", "authors": "Xizi Chen, Jingyang Zhu, Jingbo Jiang, Chi-Ying Tsui", "title": "Tight Compression: Compressing CNN Through Fine-Grained Pruning and\n  Weight Permutation for Efficient Implementation", "comments": "Previous Conference Version: 2020 57th ACM/IEEE Design Automation\n  Conference (DAC)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The unstructured sparsity after pruning poses a challenge to the efficient\nimplementation of deep learning models in existing regular architectures like\nsystolic arrays. On the other hand, coarse-grained structured pruning is\nsuitable for implementation in regular architectures but tends to have higher\naccuracy loss than unstructured pruning when the pruned models are of the same\nsize. In this work, we propose a model compression method based on a novel\nweight permutation scheme to fully exploit the fine-grained weight sparsity in\nthe hardware design. Through permutation, the optimal arrangement of the weight\nmatrix is obtained, and the sparse weight matrix is further compressed to a\nsmall and dense format to make full use of the hardware resources. Two pruning\ngranularities are explored. In addition to the unstructured weight pruning, we\nalso propose a more fine-grained subword-level pruning to further improve the\ncompression performance. Compared to the state-of-the-art works, the matrix\ncompression rate is significantly improved from 5.88x to 14.13x. As a result,\nthe throughput and energy efficiency are improved by 2.75 and 1.86 times,\nrespectively.\n", "versions": [{"version": "v1", "created": "Sat, 3 Apr 2021 03:24:52 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Chen", "Xizi", ""], ["Zhu", "Jingyang", ""], ["Jiang", "Jingbo", ""], ["Tsui", "Chi-Ying", ""]]}, {"id": "2104.01328", "submitter": "Niko S\\\"underhauf", "authors": "Dimity Miller, Niko S\\\"underhauf, Michael Milford and Feras Dayoub", "title": "Uncertainty for Identifying Open-Set Errors in Visual Object Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deployed into an open world, object detectors are prone to a type of false\npositive detection termed open-set errors. We propose GMM-Det, a real-time\nmethod for extracting epistemic uncertainty from object detectors to identify\nand reject open-set errors. GMM-Det trains the detector to produce a structured\nlogit space that is modelled with class-specific Gaussian Mixture Models. At\ntest time, open-set errors are identified by their low log-probability under\nall Gaussian Mixture Models. We test two common detector architectures, Faster\nR-CNN and RetinaNet, across three varied datasets spanning robotics and\ncomputer vision. Our results show that GMM-Det consistently outperforms\nexisting uncertainty techniques for identifying and rejecting open-set\ndetections, especially at the low-error-rate operating point required for\nsafety-critical applications. GMM-Det maintains object detection performance,\nand introduces only minimal computational overhead. We also introduce a\nmethodology for converting existing object detection datasets into specific\nopen-set datasets to consistently evaluate open-set performance in object\ndetection. Code for GMM-Det and the dataset methodology will be made publicly\navailable.\n", "versions": [{"version": "v1", "created": "Sat, 3 Apr 2021 07:12:31 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Miller", "Dimity", ""], ["S\u00fcnderhauf", "Niko", ""], ["Milford", "Michael", ""], ["Dayoub", "Feras", ""]]}, {"id": "2104.01331", "submitter": "Ahmad Mousavi", "authors": "Hossein Moosaei, Ahmad Mousavi, Milan Hlad\\'ik, Zheming Gao", "title": "Sparse Universum Quadratic Surface Support Vector Machine Models for\n  Binary Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In binary classification, kernel-free linear or quadratic support vector\nmachines are proposed to avoid dealing with difficulties such as finding\nappropriate kernel functions or tuning their hyper-parameters. Furthermore,\nUniversum data points, which do not belong to any class, can be exploited to\nembed prior knowledge into the corresponding models so that the generalization\nperformance is improved. In this paper, we design novel kernel-free Universum\nquadratic surface support vector machine models. Further, we propose the L1\nnorm regularized version that is beneficial for detecting potential sparsity\npatterns in the Hessian of the quadratic surface and reducing to the standard\nlinear models if the data points are (almost) linearly separable. The proposed\nmodels are convex such that standard numerical solvers can be utilized for\nsolving them. Nonetheless, we formulate a least squares version of the L1 norm\nregularized model and next, design an effective tailored algorithm that only\nrequires solving one linear system. Several theoretical properties of these\nmodels are then reported/proved as well. We finally conduct numerical\nexperiments on both artificial and public benchmark data sets to demonstrate\nthe feasibility and effectiveness of the proposed models.\n", "versions": [{"version": "v1", "created": "Sat, 3 Apr 2021 07:40:30 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Moosaei", "Hossein", ""], ["Mousavi", "Ahmad", ""], ["Hlad\u00edk", "Milan", ""], ["Gao", "Zheming", ""]]}, {"id": "2104.01351", "submitter": "Insu Han", "authors": "Insu Han, Haim Avron, Neta Shoham, Chaewon Kim, Jinwoo Shin", "title": "Random Features for the Neural Tangent Kernel", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The Neural Tangent Kernel (NTK) has discovered connections between deep\nneural networks and kernel methods with insights of optimization and\ngeneralization. Motivated by this, recent works report that NTK can achieve\nbetter performances compared to training neural networks on small-scale\ndatasets. However, results under large-scale settings are hardly studied due to\nthe computational limitation of kernel methods. In this work, we propose an\nefficient feature map construction of the NTK of fully-connected ReLU network\nwhich enables us to apply it to large-scale datasets. We combine random\nfeatures of the arc-cosine kernels with a sketching-based algorithm which can\nrun in linear with respect to both the number of data points and input\ndimension. We show that dimension of the resulting features is much smaller\nthan other baseline feature map constructions to achieve comparable error\nbounds both in theory and practice. We additionally utilize the leverage score\nbased sampling for improved bounds of arc-cosine random features and prove a\nspectral approximation guarantee of the proposed feature map to the NTK matrix\nof two-layer neural network. We benchmark a variety of machine learning tasks\nto demonstrate the superiority of the proposed scheme. In particular, our\nalgorithm can run tens of magnitude faster than the exact kernel methods for\nlarge-scale settings without performance loss.\n", "versions": [{"version": "v1", "created": "Sat, 3 Apr 2021 09:08:12 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Han", "Insu", ""], ["Avron", "Haim", ""], ["Shoham", "Neta", ""], ["Kim", "Chaewon", ""], ["Shin", "Jinwoo", ""]]}, {"id": "2104.01374", "submitter": "Florian Jug", "authors": "Mangal Prakash, Mauricio Delbracio, Peyman Milanfar, Florian Jug", "title": "Removing Pixel Noises and Spatial Artifacts with Generative Diversity\n  Denoising Methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG q-bio.QM", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Image denoising and artefact removal are complex inverse problems admitting\nmany potential solutions. Variational Autoencoders (VAEs) can be used to learn\na whole distribution of sensible solutions, from which one can sample\nefficiently. However, such a generative approach to image restoration is only\nstudied in the context of pixel-wise noise removal (e.g. Poisson or Gaussian\nnoise). While important, a plethora of application domains suffer from imaging\nartefacts (structured noises) that alter groups of pixels in correlated ways.\nIn this work we show, for the first time, that generative diversity denoising\n(GDD) approaches can learn to remove structured noises without supervision. To\nthis end, we investigate two existing GDD architectures, introduce a new one\nbased on hierarchical VAEs, and compare their performances against a total of\nseven state-of-the-art baseline methods on five sources of structured noise\n(including tomography reconstruction artefacts and microscopy artefacts). We\nfind that GDD methods outperform all unsupervised baselines and in many cases\nnot lagging far behind supervised results (in some occasions even superseding\nthem). In addition to structured noise removal, we also show that our new GDD\nmethod produces new state-of-the-art (SOTA) results on seven out of eight\nbenchmark datasets for pixel-noise removal. Finally, we offer insights into the\ndaunting question of how GDD methods distinguish structured noise, which we\nlike to see removed, from image signals, which we want to see retained.\n", "versions": [{"version": "v1", "created": "Sat, 3 Apr 2021 11:00:21 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Prakash", "Mangal", ""], ["Delbracio", "Mauricio", ""], ["Milanfar", "Peyman", ""], ["Jug", "Florian", ""]]}, {"id": "2104.01375", "submitter": "Ioannis Kakogeorgiou", "authors": "Ioannis Kakogeorgiou and Konstantinos Karantzalos", "title": "Evaluating Explainable Artificial Intelligence Methods for Multi-label\n  Deep Learning Classification Tasks in Remote Sensing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Although deep neural networks hold the state-of-the-art in several remote\nsensing tasks, their black-box operation hinders the understanding of their\ndecisions, concealing any bias and other shortcomings in datasets and model\nperformance. To this end, we have applied explainable artificial intelligence\n(XAI) methods in remote sensing multi-label classification tasks towards\nproducing human-interpretable explanations and improve transparency. In\nparticular, we developed deep learning models with state-of-the-art performance\nin the benchmark BigEarthNet and SEN12MS datasets. Ten XAI methods were\nemployed towards understanding and interpreting models' predictions, along with\nquantitative metrics to assess and compare their performance. Numerous\nexperiments were performed to assess the overall performance of XAI methods for\nstraightforward prediction cases, competing multiple labels, as well as\nmisclassification cases. According to our findings, Occlusion, Grad-CAM and\nLime were the most interpretable and reliable XAI methods. However, none\ndelivers high-resolution outputs, while apart from Grad-CAM, both Lime and\nOcclusion are computationally expensive. We also highlight different aspects of\nXAI performance and elaborate with insights on black-box decisions in order to\nimprove transparency, understand their behavior and reveal, as well, datasets'\nparticularities.\n", "versions": [{"version": "v1", "created": "Sat, 3 Apr 2021 11:13:14 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Kakogeorgiou", "Ioannis", ""], ["Karantzalos", "Konstantinos", ""]]}, {"id": "2104.01381", "submitter": "Tsubasa Murate", "authors": "Tsubasa Murate, Takashi Watanabe, Masaki Yamada", "title": "Learning Mobile CNN Feature Extraction Toward Fast Computation of Visual\n  Object Tracking", "comments": "9 pages, 17 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.GR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we construct a lightweight, high-precision and high-speed\nobject tracking using a trained CNN. Conventional methods with trained CNNs use\nVGG16 network which requires powerful computational resources. Therefore, there\nis a problem that it is difficult to apply in low computation resources\nenvironments. To solve this problem, we use MobileNetV3, which is a CNN for\nmobile terminals.Based on Feature Map Selection Tracking, we propose a new\narchitecture that extracts effective features of MobileNet for object tracking.\nThe architecture requires no online learning but only offline learning. In\naddition, by using features of objects other than tracking target, the features\nof tracking target are extracted more efficiently. We measure the tracking\naccuracy with Visual Tracker Benchmark and confirm that the proposed method can\nperform high-precision and high-speed calculation even in low computation\nresource environments.\n", "versions": [{"version": "v1", "created": "Sat, 3 Apr 2021 11:49:54 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Murate", "Tsubasa", ""], ["Watanabe", "Takashi", ""], ["Yamada", "Masaki", ""]]}, {"id": "2104.01390", "submitter": "HaoChih Lin", "authors": "HaoChih Lin, Baopu Li, Xin Zhou, Jiankun Wang, Max Q.-H. Meng", "title": "No Need for Interactions: Robust Model-Based Imitation Learning using\n  Neural ODE", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interactions with either environments or expert policies during training are\nneeded for most of the current imitation learning (IL) algorithms. For IL\nproblems with no interactions, a typical approach is Behavior Cloning (BC).\nHowever, BC-like methods tend to be affected by distribution shift. To mitigate\nthis problem, we come up with a Robust Model-Based Imitation Learning (RMBIL)\nframework that casts imitation learning as an end-to-end differentiable\nnonlinear closed-loop tracking problem. RMBIL applies Neural ODE to learn a\nprecise multi-step dynamics and a robust tracking controller via Nonlinear\nDynamics Inversion (NDI) algorithm. Then, the learned NDI controller will be\ncombined with a trajectory generator, a conditional VAE, to imitate an expert's\nbehavior. Theoretical derivation shows that the controller network can\napproximate an NDI when minimizing the training loss of Neural ODE. Experiments\non Mujoco tasks also demonstrate that RMBIL is competitive to the\nstate-of-the-art generative adversarial method (GAIL) and achieves at least 30%\nperformance gain over BC in uneven surfaces.\n", "versions": [{"version": "v1", "created": "Sat, 3 Apr 2021 12:52:22 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Lin", "HaoChih", ""], ["Li", "Baopu", ""], ["Zhou", "Xin", ""], ["Wang", "Jiankun", ""], ["Meng", "Max Q. -H.", ""]]}, {"id": "2104.01394", "submitter": "Viraj Bagal", "authors": "Yash Khare, Viraj Bagal, Minesh Mathew, Adithi Devi, U Deva\n  Priyakumar, CV Jawahar", "title": "MMBERT: Multimodal BERT Pretraining for Improved Medical VQA", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Images in the medical domain are fundamentally different from the general\ndomain images. Consequently, it is infeasible to directly employ general domain\nVisual Question Answering (VQA) models for the medical domain. Additionally,\nmedical images annotation is a costly and time-consuming process. To overcome\nthese limitations, we propose a solution inspired by self-supervised\npretraining of Transformer-style architectures for NLP, Vision and Language\ntasks. Our method involves learning richer medical image and text semantic\nrepresentations using Masked Language Modeling (MLM) with image features as the\npretext task on a large medical image+caption dataset. The proposed solution\nachieves new state-of-the-art performance on two VQA datasets for radiology\nimages -- VQA-Med 2019 and VQA-RAD, outperforming even the ensemble models of\nprevious best solutions. Moreover, our solution provides attention maps which\nhelp in model interpretability. The code is available at\nhttps://github.com/VirajBagal/MMBERT\n", "versions": [{"version": "v1", "created": "Sat, 3 Apr 2021 13:01:19 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Khare", "Yash", ""], ["Bagal", "Viraj", ""], ["Mathew", "Minesh", ""], ["Devi", "Adithi", ""], ["Priyakumar", "U Deva", ""], ["Jawahar", "CV", ""]]}, {"id": "2104.01395", "submitter": "Omer Bobrowski", "authors": "Lior Aloni, Omer Bobrowski, Ronen Talmon", "title": "Joint Geometric and Topological Analysis of Hierarchical Datasets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a world abundant with diverse data arising from complex acquisition\ntechniques, there is a growing need for new data analysis methods. In this\npaper we focus on high-dimensional data that are organized into several\nhierarchical datasets. We assume that each dataset consists of complex samples,\nand every sample has a distinct irregular structure modeled by a graph. The\nmain novelty in this work lies in the combination of two complementing powerful\ndata-analytic approaches: topological data analysis (TDA) and geometric\nmanifold learning. Geometry primarily contains local information, while\ntopology inherently provides global descriptors. Based on this combination, we\npresent a method for building an informative representation of hierarchical\ndatasets. At the finer (sample) level, we devise a new metric between samples\nbased on manifold learning that facilitates quantitative structural analysis.\nAt the coarser (dataset) level, we employ TDA to extract qualitative structural\ninformation from the datasets. We showcase the applicability and advantages of\nour method on simulated data and on a corpus of hyper-spectral images. We show\nthat an ensemble of hyper-spectral images exhibits a hierarchical structure\nthat fits well the considered setting. In addition, we show that our new method\ngives rise to superior classification results compared to state-of-the-art\nmethods.\n", "versions": [{"version": "v1", "created": "Sat, 3 Apr 2021 13:02:00 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Aloni", "Lior", ""], ["Bobrowski", "Omer", ""], ["Talmon", "Ronen", ""]]}, {"id": "2104.01396", "submitter": "Ekaterina Komendantskaya Dr", "authors": "Marco Casadio, Matthew Daggitt, Ekaterina Komendantskaya, Wen Kokke,\n  Daniel Kienitz, Rob Stewart", "title": "Property-driven Training: All You (N)Ever Wanted to Know About", "comments": "10 pages, under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks are known for their ability to detect general patterns in\nnoisy data. This makes them a popular tool for perception components in complex\nAI systems. Paradoxically, they are also known for being vulnerable to\nadversarial attacks. In response, various methods such as adversarial training,\ndata-augmentation and Lipschitz robustness training have been proposed as means\nof improving their robustness. However, as this paper explores, these training\nmethods each optimise for a different definition of robustness. We perform an\nin-depth comparison of these different definitions, including their\nrelationship, assumptions, interpretability and verifiability after training.\nWe also look at constraint-driven training, a general approach designed to\nencode arbitrary constraints, and show that not all of these definitions are\ndirectly encodable. Finally we perform experiments to compare the applicability\nand efficacy of the training methods at ensuring the network obeys these\ndifferent definitions. These results highlight that even the encoding of such a\nsimple piece of knowledge such as robustness in neural network training is\nfraught with difficult choices and pitfalls.\n", "versions": [{"version": "v1", "created": "Sat, 3 Apr 2021 13:06:06 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Casadio", "Marco", ""], ["Daggitt", "Matthew", ""], ["Komendantskaya", "Ekaterina", ""], ["Kokke", "Wen", ""], ["Kienitz", "Daniel", ""], ["Stewart", "Rob", ""]]}, {"id": "2104.01404", "submitter": "Derek Lim", "authors": "Derek Lim, Xiuyu Li, Felix Hohne, Ser-Nam Lim", "title": "New Benchmarks for Learning on Non-Homophilous Graphs", "comments": "In Workshop on Graph Learning Benchmarks (GLB 2021) at WWW 2021. 10\n  pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Much data with graph structures satisfy the principle of homophily, meaning\nthat connected nodes tend to be similar with respect to a specific attribute.\nAs such, ubiquitous datasets for graph machine learning tasks have generally\nbeen highly homophilous, rewarding methods that leverage homophily as an\ninductive bias. Recent work has pointed out this particular focus, as new\nnon-homophilous datasets have been introduced and graph representation learning\nmodels better suited for low-homophily settings have been developed. However,\nthese datasets are small and poorly suited to truly testing the effectiveness\nof new methods in non-homophilous settings. We present a series of improved\ngraph datasets with node label relationships that do not satisfy the homophily\nprinciple. Along with this, we introduce a new measure of the presence or\nabsence of homophily that is better suited than existing measures in different\nregimes. We benchmark a range of simple methods and graph neural networks\nacross our proposed datasets, drawing new insights for further research. Data\nand codes can be found at https://github.com/CUAI/Non-Homophily-Benchmarks.\n", "versions": [{"version": "v1", "created": "Sat, 3 Apr 2021 13:45:06 GMT"}, {"version": "v2", "created": "Mon, 5 Jul 2021 23:22:02 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Lim", "Derek", ""], ["Li", "Xiuyu", ""], ["Hohne", "Felix", ""], ["Lim", "Ser-Nam", ""]]}, {"id": "2104.01414", "submitter": "Tamer Khattab Dr.", "authors": "Muhammad Shehab, Bekir S. Ciftler, Tamer Khattab, Mohamed Abdallah,\n  and Daniele Trinchero", "title": "Deep Reinforcement Learning Powered IRS-Assisted Downlink NOMA", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG math.IT", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this work, we examine an intelligent reflecting surface (IRS) assisted\ndownlink non-orthogonal multiple access (NOMA) scenario with the aim of\nmaximizing the sum rate of users. The optimization problem at the IRS is quite\ncomplicated, and non-convex, since it requires the tuning of the phase shift\nreflection matrix. Driven by the rising deployment of deep reinforcement\nlearning (DRL) techniques that are capable of coping with solving non-convex\noptimization problems, we employ DRL to predict and optimally tune the IRS\nphase shift matrices. Simulation results reveal that IRS assisted NOMA based on\nour utilized DRL scheme achieves high sum rate compared to OMA based one, and\nas the transmit power increases, the capability of serving more users\nincreases. Furthermore, results show that imperfect successive interference\ncancellation (SIC) has a deleterious impact on the data rate of users\nperforming SIC. As the imperfection increases by ten times, the rate decreases\nby more than 10%.\n", "versions": [{"version": "v1", "created": "Sat, 3 Apr 2021 14:10:40 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Shehab", "Muhammad", ""], ["Ciftler", "Bekir S.", ""], ["Khattab", "Tamer", ""], ["Abdallah", "Mohamed", ""], ["Trinchero", "Daniele", ""]]}, {"id": "2104.01422", "submitter": "Martin Q. Ma", "authors": "Martin Q. Ma, Yue Zhao, Xiaorong Zhang, Leman Akoglu", "title": "A Large-scale Study on Unsupervised Outlier Model Selection: Do Internal\n  Strategies Suffice?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Given an unsupervised outlier detection task, how should one select a\ndetection algorithm as well as its hyperparameters (jointly called a model)?\nUnsupervised model selection is notoriously difficult, in the absence of\nhold-out validation data with ground-truth labels. Therefore, the problem is\nvastly understudied. In this work, we study the feasibility of employing\ninternal model evaluation strategies for selecting a model for outlier\ndetection. These so-called internal strategies solely rely on the input data\n(without labels) and the output (outlier scores) of the candidate models. We\nsetup (and open-source) a large testbed with 39 detection tasks and 297\ncandidate models comprised of 8 detectors and various hyperparameter\nconfigurations. We evaluate 7 different strategies on their ability to\ndiscriminate between models w.r.t. detection performance, without using any\nlabels. Our study reveals room for progress -- we find that none would be\npractically useful, as they select models only comparable to a state-of-the-art\ndetector (with random configuration).\n", "versions": [{"version": "v1", "created": "Sat, 3 Apr 2021 14:56:29 GMT"}, {"version": "v2", "created": "Mon, 12 Apr 2021 19:24:44 GMT"}], "update_date": "2021-04-14", "authors_parsed": [["Ma", "Martin Q.", ""], ["Zhao", "Yue", ""], ["Zhang", "Xiaorong", ""], ["Akoglu", "Leman", ""]]}, {"id": "2104.01436", "submitter": "Samujjwal Ghosh", "authors": "Samujjwal Ghosh, Subhadeep Maji, Maunendra Sankar Desarkar", "title": "Unsupervised Domain Adaptation with Global and Local Graph Neural\n  Networks in Limited Labeled Data Scenario: Application to Disaster Management", "comments": "This work has been submitted to the IEEE for possible publication.\n  Copyright may be transferred without notice, after which this version may no\n  longer be accessible", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Identification and categorization of social media posts generated during\ndisasters are crucial to reduce the sufferings of the affected people. However,\nlack of labeled data is a significant bottleneck in learning an effective\ncategorization system for a disaster. This motivates us to study the problem as\nunsupervised domain adaptation (UDA) between a previous disaster with labeled\ndata (source) and a current disaster (target). However, if the amount of\nlabeled data available is limited, it restricts the learning capabilities of\nthe model. To handle this challenge, we utilize limited labeled data along with\nabundantly available unlabeled data, generated during a source disaster to\npropose a novel two-part graph neural network. The first-part extracts\ndomain-agnostic global information by constructing a token level graph across\ndomains and the second-part preserves local instance-level semantics. In our\nexperiments, we show that the proposed method outperforms state-of-the-art\ntechniques by $2.74\\%$ weighted F$_1$ score on average on two standard public\ndataset in the area of disaster management. We also report experimental results\nfor granular actionable multi-label classification datasets in disaster domain\nfor the first time, on which we outperform BERT by $3.00\\%$ on average w.r.t\nweighted F$_1$. Additionally, we show that our approach can retain performance\nwhen very limited labeled data is available.\n", "versions": [{"version": "v1", "created": "Sat, 3 Apr 2021 16:01:03 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Ghosh", "Samujjwal", ""], ["Maji", "Subhadeep", ""], ["Desarkar", "Maunendra Sankar", ""]]}, {"id": "2104.01437", "submitter": "Jorino Van Rhijn", "authors": "Jorino van Rhijn, Cornelis W. Oosterlee, Lech A. Grzelak, Shuaiqiang\n  Liu", "title": "Monte Carlo Simulation of SDEs using GANs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA math.NA q-fin.CP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Generative adversarial networks (GANs) have shown promising results when\napplied on partial differential equations and financial time series generation.\nWe investigate if GANs can also be used to approximate one-dimensional Ito\nstochastic differential equations (SDEs). We propose a scheme that approximates\nthe path-wise conditional distribution of SDEs for large time steps. Standard\nGANs are only able to approximate processes in distribution, yielding a weak\napproximation to the SDE. A conditional GAN architecture is proposed that\nenables strong approximation. We inform the discriminator of this GAN with the\nmap between the prior input to the generator and the corresponding output\nsamples, i.e. we introduce a `supervised GAN'. We compare the input-output map\nobtained with the standard GAN and supervised GAN and show experimentally that\nthe standard GAN may fail to provide a path-wise approximation. The GAN is\ntrained on a dataset obtained with exact simulation. The architecture was\ntested on geometric Brownian motion (GBM) and the Cox-Ingersoll-Ross (CIR)\nprocess. The supervised GAN outperformed the Euler and Milstein schemes in\nstrong error on a discretisation with large time steps. It also outperformed\nthe standard conditional GAN when approximating the conditional distribution.\nWe also demonstrate how standard GANs may give rise to non-parsimonious\ninput-output maps that are sensitive to perturbations, which motivates the need\nfor constraints and regularisation on GAN generators.\n", "versions": [{"version": "v1", "created": "Sat, 3 Apr 2021 16:06:30 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["van Rhijn", "Jorino", ""], ["Oosterlee", "Cornelis W.", ""], ["Grzelak", "Lech A.", ""], ["Liu", "Shuaiqiang", ""]]}, {"id": "2104.01440", "submitter": "Rodrigo Rivera-Castro", "authors": "Vladislav Zhuzhel, Rodrigo Rivera-Castro, Nina Kaploukhaya, Liliya\n  Mironova, Alexey Zaytsev, Evgeny Burnaev", "title": "COHORTNEY: Non-Parametric Clustering of Event Sequences", "comments": "18 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cohort analysis is a pervasive activity in web analytics. One divides users\ninto groups according to specific criteria and tracks their behavior over time.\nDespite its extensive use, academic circles do not discuss cohort analysis to\nevaluate user behavior online. This work introduces an unsupervised\nnon-parametric approach to group Internet users based on their activities. In\ncomparison, canonical methods in marketing and engineering-based techniques\nunderperform. COHORTNEY is the first machine learning-based cohort analysis\nalgorithm with a robust theoretical explanation.\n", "versions": [{"version": "v1", "created": "Sat, 3 Apr 2021 16:12:21 GMT"}, {"version": "v2", "created": "Sat, 12 Jun 2021 10:14:46 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Zhuzhel", "Vladislav", ""], ["Rivera-Castro", "Rodrigo", ""], ["Kaploukhaya", "Nina", ""], ["Mironova", "Liliya", ""], ["Zaytsev", "Alexey", ""], ["Burnaev", "Evgeny", ""]]}, {"id": "2104.01459", "submitter": "Namgil Lee", "authors": "Namgil Lee, Heejung Yang, Hojin Yoo", "title": "A surrogate loss function for optimization of $F_\\beta$ score in binary\n  classification with imbalanced data", "comments": "17 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The $F_\\beta$ score is a commonly used measure of classification performance,\nwhich plays crucial roles in classification tasks with imbalanced data sets.\nHowever, the $F_\\beta$ score cannot be used as a loss function by\ngradient-based learning algorithms for optimizing neural network parameters due\nto its non-differentiability. On the other hand, commonly used loss functions\nsuch as the binary cross-entropy (BCE) loss are not directly related to\nperformance measures such as the $F_\\beta$ score, so that neural networks\noptimized by using the loss functions may not yield optimal performance\nmeasures. In this study, we investigate a relationship between classification\nperformance measures and loss functions in terms of the gradients with respect\nto the model parameters. Then, we propose a differentiable surrogate loss\nfunction for the optimization of the $F_\\beta$ score. We show that the gradient\npaths of the proposed surrogate $F_\\beta$ loss function approximate the\ngradient paths of the large sample limit of the $F_\\beta$ score. Through\nnumerical experiments using ResNets and benchmark image data sets, it is\ndemonstrated that the proposed surrogate $F_\\beta$ loss function is effective\nfor optimizing $F_\\beta$ scores under class imbalances in binary classification\ntasks compared with other loss functions.\n", "versions": [{"version": "v1", "created": "Sat, 3 Apr 2021 18:36:23 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Lee", "Namgil", ""], ["Yang", "Heejung", ""], ["Yoo", "Hojin", ""]]}, {"id": "2104.01481", "submitter": "Shyam Tailor", "authors": "Shyam A. Tailor, Felix L. Opolka, Pietro Li\\`o, Nicholas D. Lane", "title": "Adaptive Filters and Aggregator Fusion for Efficient Graph Convolutions", "comments": "Short versions to appear at the GNNSys Workshop at MLSys 2021 and the\n  Hardware-Aware Efficient Training Workshop at ICLR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Training and deploying graph neural networks (GNNs) remains difficult due to\ntheir high memory consumption and inference latency. In this work we present a\nnew type of GNN architecture that achieves state-of-the-art performance with\nlower memory consumption and latency, along with characteristics suited to\naccelerator implementation. Our proposal uses memory proportional to the number\nof vertices in the graph, in contrast to competing methods which require memory\nproportional to the number of edges; we find our efficient approach actually\nachieves higher accuracy than competing approaches across 5 large and varied\ndatasets against strong baselines. We achieve our results by using a novel\nadaptive filtering approach inspired by signal processing; it can be\ninterpreted as enabling each vertex to have its own weight matrix, and is not\nrelated to attention. Following our focus on efficient hardware usage, we\npropose aggregator fusion, a technique to enable GNNs to significantly boost\ntheir representational power, with only a small increase in latency of 19% over\nstandard sparse matrix multiplication. Code and pretrained models can be found\nat this URL: https://github.com/shyam196/egc.\n", "versions": [{"version": "v1", "created": "Sat, 3 Apr 2021 20:54:36 GMT"}, {"version": "v2", "created": "Sat, 10 Apr 2021 17:31:25 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Tailor", "Shyam A.", ""], ["Opolka", "Felix L.", ""], ["Li\u00f2", "Pietro", ""], ["Lane", "Nicholas D.", ""]]}, {"id": "2104.01482", "submitter": "Edgar A. Bernal", "authors": "Edgar A. Bernal", "title": "Training Deep Normalizing Flow Models in Highly Incomplete Data\n  Scenarios with Prior Regularization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep generative frameworks including GANs and normalizing flow models have\nproven successful at filling in missing values in partially observed data\nsamples by effectively learning -- either explicitly or implicitly -- complex,\nhigh-dimensional statistical distributions. In tasks where the data available\nfor learning is only partially observed, however, their performance decays\nmonotonically as a function of the data missingness rate. In high missing data\nrate regimes (e.g., 60% and above), it has been observed that state-of-the-art\nmodels tend to break down and produce unrealistic and/or semantically\ninaccurate data. We propose a novel framework to facilitate the learning of\ndata distributions in high paucity scenarios that is inspired by traditional\nformulations of solutions to ill-posed problems. The proposed framework\nnaturally stems from posing the process of learning from incomplete data as a\njoint optimization task of the parameters of the model being learned and the\nmissing data values. The method involves enforcing a prior regularization term\nthat seamlessly integrates with objectives used to train explicit and tractable\ndeep generative frameworks such as deep normalizing flow models. We demonstrate\nvia extensive experimental validation that the proposed framework outperforms\ncompeting techniques, particularly as the rate of data paucity approaches\nunity.\n", "versions": [{"version": "v1", "created": "Sat, 3 Apr 2021 20:57:57 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Bernal", "Edgar A.", ""]]}, {"id": "2104.01493", "submitter": "Negin Majidi", "authors": "Negin Majidi, Ehsan Amid, Hossein Talebi, and Manfred K. Warmuth", "title": "Exponentiated Gradient Reweighting for Robust Training Under Label Noise\n  and Beyond", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Many learning tasks in machine learning can be viewed as taking a gradient\nstep towards minimizing the average loss of a batch of examples in each\ntraining iteration. When noise is prevalent in the data, this uniform treatment\nof examples can lead to overfitting to noisy examples with larger loss values\nand result in poor generalization. Inspired by the expert setting in on-line\nlearning, we present a flexible approach to learning from noisy examples.\nSpecifically, we treat each training example as an expert and maintain a\ndistribution over all examples. We alternate between updating the parameters of\nthe model using gradient descent and updating the example weights using the\nexponentiated gradient update. Unlike other related methods, our approach\nhandles a general class of loss functions and can be applied to a wide range of\nnoise types and applications. We show the efficacy of our approach for multiple\nlearning settings, namely noisy principal component analysis and a variety of\nnoisy classification problems.\n", "versions": [{"version": "v1", "created": "Sat, 3 Apr 2021 22:54:49 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Majidi", "Negin", ""], ["Amid", "Ehsan", ""], ["Talebi", "Hossein", ""], ["Warmuth", "Manfred K.", ""]]}, {"id": "2104.01494", "submitter": "Aly El Gamal", "authors": "Rehana Mahfuz, Rajeev Sahay, Aly El Gamal", "title": "Mitigating Gradient-based Adversarial Attacks via Denoising and\n  Compression", "comments": "13 pages, 2 figures, 9 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gradient-based adversarial attacks on deep neural networks pose a serious\nthreat, since they can be deployed by adding imperceptible perturbations to the\ntest data of any network, and the risk they introduce cannot be assessed\nthrough the network's original training performance. Denoising and\ndimensionality reduction are two distinct methods that have been independently\ninvestigated to combat such attacks. While denoising offers the ability to\ntailor the defense to the specific nature of the attack, dimensionality\nreduction offers the advantage of potentially removing previously unseen\nperturbations, along with reducing the training time of the network being\ndefended. We propose strategies to combine the advantages of these two defense\nmechanisms. First, we propose the cascaded defense, which involves denoising\nfollowed by dimensionality reduction. To reduce the training time of the\ndefense for a small trade-off in performance, we propose the hidden layer\ndefense, which involves feeding the output of the encoder of a denoising\nautoencoder into the network. Further, we discuss how adaptive attacks against\nthese defenses could become significantly weak when an alternative defense is\nused, or when no defense is used. In this light, we propose a new metric to\nevaluate a defense which measures the sensitivity of the adaptive attack to\nmodifications in the defense. Finally, we present a guideline for building an\nordered repertoire of defenses, a.k.a. a defense infrastructure, that adjusts\nto limited computational resources in presence of uncertainty about the attack\nstrategy.\n", "versions": [{"version": "v1", "created": "Sat, 3 Apr 2021 22:57:01 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Mahfuz", "Rehana", ""], ["Sahay", "Rajeev", ""], ["Gamal", "Aly El", ""]]}, {"id": "2104.01495", "submitter": "Yang Gao", "authors": "Yang Gao, Yi-Fan Li, Swarup Chandra, Latifur Khan, Bhavani\n  Thuraisingham", "title": "Towards Self-Adaptive Metric Learning On the Fly", "comments": "Accepted by WWW 2019 (Long Paper, Oral)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.IR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Good quality similarity metrics can significantly facilitate the performance\nof many large-scale, real-world applications. Existing studies have proposed\nvarious solutions to learn a Mahalanobis or bilinear metric in an online\nfashion by either restricting distances between similar (dissimilar) pairs to\nbe smaller (larger) than a given lower (upper) bound or requiring similar\ninstances to be separated from dissimilar instances with a given margin.\nHowever, these linear metrics learned by leveraging fixed bounds or margins may\nnot perform well in real-world applications, especially when data distributions\nare complex. We aim to address the open challenge of \"Online Adaptive Metric\nLearning\" (OAML) for learning adaptive metric functions on the fly. Unlike\ntraditional online metric learning methods, OAML is significantly more\nchallenging since the learned metric could be non-linear and the model has to\nbe self-adaptive as more instances are observed. In this paper, we present a\nnew online metric learning framework that attempts to tackle the challenge by\nlearning an ANN-based metric with adaptive model complexity from a stream of\nconstraints. In particular, we propose a novel Adaptive-Bound Triplet Loss\n(ABTL) to effectively utilize the input constraints and present a novel\nAdaptive Hedge Update (AHU) method for online updating the model parameters. We\nempirically validate the effectiveness and efficacy of our framework on various\napplications such as real-world image classification, facial verification, and\nimage retrieval.\n", "versions": [{"version": "v1", "created": "Sat, 3 Apr 2021 23:11:52 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Gao", "Yang", ""], ["Li", "Yi-Fan", ""], ["Chandra", "Swarup", ""], ["Khan", "Latifur", ""], ["Thuraisingham", "Bhavani", ""]]}, {"id": "2104.01503", "submitter": "Lars Lindemann", "authors": "Lars Lindemann, Nikolai Matni, and George J. Pappas", "title": "STL Robustness Risk over Discrete-Time Stochastic Processes", "comments": "Submitted to the Conference on Decision and Control 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.FL cs.LG cs.SY math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a framework to interpret signal temporal logic (STL) formulas over\ndiscrete-time stochastic processes in terms of the induced risk. Each\nrealization of a stochastic process either satisfies or violates an STL\nformula. In fact, we can assign a robustness value to each realization that\nindicates how robustly this realization satisfies an STL formula. We then\ndefine the risk of a stochastic process not satisfying an STL formula robustly,\nreferred to as the \"STL robustness risk\". In our definition, we permit general\nclasses of risk measures such as, but not limited to, the value-at-risk. While\nin general hard to compute, we propose an approximation of the STL robustness\nrisk. This approximation has the desirable property of being an upper bound of\nthe STL robustness risk when the chosen risk measure is monotone, a property\nsatisfied by most risk measures. Motivated by the interest in data-driven\napproaches, we present a sampling-based method for calculating an upper bound\nof the approximate STL robustness risk for the value-at-risk that holds with\nhigh probability. While we consider the case of the value-at-risk, we highlight\nthat such sampling-based methods are viable for other risk measures.\n", "versions": [{"version": "v1", "created": "Sat, 3 Apr 2021 23:44:04 GMT"}, {"version": "v2", "created": "Thu, 22 Apr 2021 20:30:15 GMT"}], "update_date": "2021-04-26", "authors_parsed": [["Lindemann", "Lars", ""], ["Matni", "Nikolai", ""], ["Pappas", "George J.", ""]]}, {"id": "2104.01506", "submitter": "Tasmia Tasrin", "authors": "Tasmia Tasrin, Md Sultan Al Nahian, Habarakadage Perera and Brent\n  Harrison", "title": "Influencing Reinforcement Learning through Natural Language Guidance", "comments": "7 pages, 6 figures, The 34th International FLAIRS Conference, 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interactive reinforcement learning agents use human feedback or instruction\nto help them learn in complex environments. Often, this feedback comes in the\nform of a discrete signal that is either positive or negative. While\ninformative, this information can be difficult to generalize on its own. In\nthis work, we explore how natural language advice can be used to provide a\nricher feedback signal to a reinforcement learning agent by extending policy\nshaping, a well-known Interactive reinforcement learning technique. Usually\npolicy shaping employs a human feedback policy to help an agent to learn more\nabout how to achieve its goal. In our case, we replace this human feedback\npolicy with policy generated based on natural language advice. We aim to\ninspect if the generated natural language reasoning provides support to a deep\nreinforcement learning agent to decide its actions successfully in any given\nenvironment. So, we design our model with three networks: first one is the\nexperience driven, next is the advice generator and third one is the advice\ndriven. While the experience driven reinforcement learning agent chooses its\nactions being influenced by the environmental reward, the advice driven neural\nnetwork with generated feedback by the advice generator for any new state\nselects its actions to assist the reinforcement learning agent to better policy\nshaping.\n", "versions": [{"version": "v1", "created": "Sun, 4 Apr 2021 00:23:39 GMT"}, {"version": "v2", "created": "Sun, 11 Apr 2021 02:21:32 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Tasrin", "Tasmia", ""], ["Nahian", "Md Sultan Al", ""], ["Perera", "Habarakadage", ""], ["Harrison", "Brent", ""]]}, {"id": "2104.01511", "submitter": "Ayse Cakmak", "authors": "Ayse S. Cakmak, Samuel Densen, Gabriel Najarro, Pratik Rout,\n  Christopher J. Rozell, Omer T. Inan, Amit J. Shah, Gari D. Clifford", "title": "Late fusion of machine learning models using passively captured\n  interpersonal social interactions and motion from smartphones predicts\n  decompensation in heart failure", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Objective: Worldwide, heart failure (HF) is a major cause of morbidity and\nmortality and one of the leading causes of hospitalization. Early detection of\nHF symptoms and pro-active management may reduce adverse events. Approach:\nTwenty-eight participants were monitored using a smartphone app after discharge\nfrom hospitals, and each clinical event during the enrollment (N=110 clinical\nevents) was recorded. Motion, social, location, and clinical survey data\ncollected via the smartphone-based monitoring system were used to develop and\nvalidate an algorithm for predicting or classifying HF decompensation events\n(hospitalizations or clinic visit) versus clinic monitoring visits in which\nthey were determined to be compensated or stable. Models based on single\nmodality as well as early and late fusion approaches combining patient-reported\noutcomes and passive smartphone data were evaluated. Results: The highest AUCPr\nfor classifying decompensation with a late fusion approach was 0.80 using leave\none subject out cross-validation. Significance: Passively collected data from\nsmartphones, especially when combined with weekly patient-reported outcomes,\nmay reflect behavioral and physiological changes due to HF and thus could\nenable prediction of HF decompensation.\n", "versions": [{"version": "v1", "created": "Sun, 4 Apr 2021 01:04:29 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Cakmak", "Ayse S.", ""], ["Densen", "Samuel", ""], ["Najarro", "Gabriel", ""], ["Rout", "Pratik", ""], ["Rozell", "Christopher J.", ""], ["Inan", "Omer T.", ""], ["Shah", "Amit J.", ""], ["Clifford", "Gari D.", ""]]}, {"id": "2104.01520", "submitter": "Gabriele Farina", "authors": "Gabriele Farina, Andrea Celli, Alberto Marchesi, Nicola Gatti", "title": "Simple Uncoupled No-Regret Learning Dynamics for Extensive-Form\n  Correlated Equilibrium", "comments": "Extended version of our NeurIPS 2020 paper. Compared to the\n  conference version, this preprint gives finer, in-high-probability regret\n  bounds. We also better connected our work to the phi-regret minimization\n  framework", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.LG cs.MA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The existence of simple uncoupled no-regret learning dynamics that converge\nto correlated equilibria in normal-form games is a celebrated result in the\ntheory of multi-agent systems. Specifically, it has been known for more than 20\nyears that when all players seek to minimize their internal regret in a\nrepeated normal-form game, the empirical frequency of play converges to a\nnormal-form correlated equilibrium. Extensive-form games generalize normal-form\ngames by modeling both sequential and simultaneous moves, as well as imperfect\ninformation. Because of the sequential nature and presence of private\ninformation in the game, correlation in extensive-form games possesses\nsignificantly different properties than its counterpart in normal-form games,\nmany of which are still open research directions. Extensive-form correlated\nequilibrium (EFCE) has been proposed as the natural extensive-form counterpart\nto the classical notion of correlated equilibrium in normal-form games.\nCompared to the latter, the constraints that define the set of EFCEs are\nsignificantly more complex, as the correlation device must keep into account\nthe evolution of beliefs of each player as they make observations throughout\nthe game. Due to that significant added complexity, the existence of uncoupled\nlearning dynamics leading to an EFCE has remained a challenging open research\nquestion for a long time. In this article, we settle that question by giving\nthe first uncoupled no-regret dynamics that converge to the set of EFCEs in\nn-player general-sum extensive-form games with perfect recall. We show that\neach iterate can be computed in time polynomial in the size of the game tree,\nand that, when all players play repeatedly according to our learning dynamics,\nthe empirical frequency of play is proven to be a O(T^-0.5)-approximate EFCE\nwith high probability after T game repetitions, and an EFCE almost surely in\nthe limit.\n", "versions": [{"version": "v1", "created": "Sun, 4 Apr 2021 02:26:26 GMT"}, {"version": "v2", "created": "Thu, 27 May 2021 06:03:22 GMT"}], "update_date": "2021-05-28", "authors_parsed": [["Farina", "Gabriele", ""], ["Celli", "Andrea", ""], ["Marchesi", "Alberto", ""], ["Gatti", "Nicola", ""]]}, {"id": "2104.01521", "submitter": "Omid Tarkhaneh", "authors": "Omid Tarkhaneh, Neda Alipour, Amirahmad Chapnevis, Haifeng Shen", "title": "Golden Tortoise Beetle Optimizer: A Novel Nature-Inspired Meta-heuristic\n  Algorithm for Engineering Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.LG cs.NA math.NA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper proposes a novel nature-inspired meta-heuristic algorithm called\nthe Golden Tortoise Beetle Optimizer (GTBO) to solve optimization problems. It\nmimics golden tortoise beetle's behavior of changing colors to attract opposite\nsex for mating and its protective strategy that uses a kind of anal fork to\ndeter predators. The algorithm is modeled based on the beetle's dual\nattractiveness and survival strategy to generate new solutions for optimization\nproblems. To measure its performance, the proposed GTBO is compared with five\nother nature-inspired evolutionary algorithms on 24 well-known benchmark\nfunctions investigating the trade-off between exploration and exploitation,\nlocal optima avoidance, and convergence towards the global optima is\nstatistically significant. We particularly applied GTBO to two well-known\nengineering problems including the welded beam design problem and the gear\ntrain design problem. The results demonstrate that the new algorithm is more\nefficient than the five baseline algorithms for both problems. A sensitivity\nanalysis is also performed to reveal different impacts of the algorithm's key\ncontrol parameters and operators on GTBO's performance.\n", "versions": [{"version": "v1", "created": "Sun, 4 Apr 2021 02:29:47 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Tarkhaneh", "Omid", ""], ["Alipour", "Neda", ""], ["Chapnevis", "Amirahmad", ""], ["Shen", "Haifeng", ""]]}, {"id": "2104.01525", "submitter": "Benyamin Ghojogh", "authors": "Benyamin Ghojogh, Ali Ghodsi, Fakhri Karray, Mark Crowley", "title": "Generative Locally Linear Embedding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Locally Linear Embedding (LLE) is a nonlinear spectral dimensionality\nreduction and manifold learning method. It has two main steps which are linear\nreconstruction and linear embedding of points in the input space and embedding\nspace, respectively. In this work, we propose two novel generative versions of\nLLE, named Generative LLE (GLLE), whose linear reconstruction steps are\nstochastic rather than deterministic. GLLE assumes that every data point is\ncaused by its linear reconstruction weights as latent factors. The proposed\nGLLE algorithms can generate various LLE embeddings stochastically while all\nthe generated embeddings relate to the original LLE embedding. We propose two\nversions for stochastic linear reconstruction, one using expectation\nmaximization and another with direct sampling from a derived distribution by\noptimization. The proposed GLLE methods are closely related to and inspired by\nvariational inference, factor analysis, and probabilistic principal component\nanalysis. Our simulations show that the proposed GLLE methods work effectively\nin unfolding and generating submanifolds of data.\n", "versions": [{"version": "v1", "created": "Sun, 4 Apr 2021 02:59:39 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Ghojogh", "Benyamin", ""], ["Ghodsi", "Ali", ""], ["Karray", "Fakhri", ""], ["Crowley", "Mark", ""]]}, {"id": "2104.01527", "submitter": "Sihua Wang", "authors": "Sihua Wang, Mingzhe Chen, Zhaohui Yang, Changchuan Yin, Walid Saad,\n  Shuguang Cui, H. Vincent Poor", "title": "Reinforcement Learning for Minimizing Age of Information in Real-time\n  Internet of Things Systems with Realistic Physical Dynamics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, the problem of minimizing the weighted sum of age of\ninformation (AoI) and total energy consumption of Internet of Things (IoT)\ndevices is studied. In the considered model, each IoT device monitors a\nphysical process that follows nonlinear dynamics. As the dynamics of the\nphysical process vary over time, each device must find an optimal sampling\nfrequency to sample the real-time dynamics of the physical system and send\nsampled information to a base station (BS). Due to limited wireless resources,\nthe BS can only select a subset of devices to transmit their sampled\ninformation. Meanwhile, changing the sampling frequency will also impact the\nenergy used by each device for sampling and information transmission. Thus, it\nis necessary to jointly optimize the sampling policy of each device and the\ndevice selection scheme of the BS so as to accurately monitor the dynamics of\nthe physical process using minimum energy. This problem is formulated as an\noptimization problem whose goal is to minimize the weighted sum of AoI cost and\nenergy consumption. To solve this problem, a distributed reinforcement learning\napproach is proposed to optimize the sampling policy. The proposed learning\nmethod enables the IoT devices to find the optimal sampling policy using their\nlocal observations. Given the sampling policy, the device selection scheme can\nbe optimized so as to minimize the weighted sum of AoI and energy consumption\nof all devices. Simulations with real data of PM 2.5 pollution show that the\nproposed algorithm can reduce the sum of AoI by up to 17.8% and 33.9% and the\ntotal energy consumption by up to 13.2% and 35.1%, compared to a conventional\ndeep Q network method and a uniform sampling policy.\n", "versions": [{"version": "v1", "created": "Sun, 4 Apr 2021 03:17:26 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Wang", "Sihua", ""], ["Chen", "Mingzhe", ""], ["Yang", "Zhaohui", ""], ["Yin", "Changchuan", ""], ["Saad", "Walid", ""], ["Cui", "Shuguang", ""], ["Poor", "H. Vincent", ""]]}, {"id": "2104.01536", "submitter": "Jiashu He", "authors": "Jiashu He", "title": "Performance analysis of facial recognition: A critical review through\n  glass factor", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  COVID-19 pandemic and social distancing urge a reliable human face\nrecognition system in different abnormal situations. However, there is no\nresearch which studies the influence of glass factor in facial recognition\nsystem. This paper provides a comprehensive review of glass factor. The study\ncontains two steps: data collection and accuracy test. Data collection includes\ncollecting human face images through different situations, such as clear\nglasses, glass with water and glass with mist. Based on the collected data, an\nexisting state-of-the-art face detection and recognition system built upon\nMTCNN and Inception V1 deep nets is tested for further analysis. Experimental\ndata supports that 1) the system is robust for classification when comparing\nreal-time images and 2) it fails at determining if two images are of same\nperson by comparing real-time disturbed image with the frontal ones.\n", "versions": [{"version": "v1", "created": "Sun, 4 Apr 2021 05:02:04 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["He", "Jiashu", ""]]}, {"id": "2104.01539", "submitter": "Jian Liang", "authors": "Jian Liang and Dapeng Hu and Ran He and Jiashi Feng", "title": "Distill and Fine-tune: Effective Adaptation from a Black-box Source\n  Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To alleviate the burden of labeling, unsupervised domain adaptation (UDA)\naims to transfer knowledge in previous related labeled datasets (source) to a\nnew unlabeled dataset (target). Despite impressive progress, prior methods\nalways need to access the raw source data and develop data-dependent alignment\napproaches to recognize the target samples in a transductive learning manner,\nwhich may raise privacy concerns from source individuals. Several recent\nstudies resort to an alternative solution by exploiting the well-trained\nwhite-box model instead of the raw data from the source domain, however, it may\nleak the raw data through generative adversarial training. This paper studies a\npractical and interesting setting for UDA, where only a black-box source model\n(i.e., only network predictions are available) is provided during adaptation in\nthe target domain. Besides, different neural networks are even allowed to be\nemployed for different domains. For this new problem, we propose a novel\ntwo-step adaptation framework called Distill and Fine-tune (Dis-tune).\nSpecifically, Dis-tune first structurally distills the knowledge from the\nsource model to a customized target model, then unsupervisedly fine-tunes the\ndistilled model to fit the target domain. To verify the effectiveness, we\nconsider two UDA scenarios (\\ie, closed-set and partial-set), and discover that\nDis-tune achieves highly competitive performance to state-of-the-art\napproaches.\n", "versions": [{"version": "v1", "created": "Sun, 4 Apr 2021 05:29:05 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Liang", "Jian", ""], ["Hu", "Dapeng", ""], ["He", "Ran", ""], ["Feng", "Jiashi", ""]]}, {"id": "2104.01555", "submitter": "He Wang", "authors": "He Wang, Yifei Shen, Ziyuan Wang, Dongsheng Li, Jun Zhang, Khaled B.\n  Letaief and Jie Lu", "title": "Decentralized Statistical Inference with Unrolled Graph Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we investigate the decentralized statistical inference\nproblem, where a network of agents cooperatively recover a (structured) vector\nfrom private noisy samples without centralized coordination. Existing\noptimization-based algorithms suffer from issues of model mismatch and poor\nconvergence speed, and thus their performance would be degraded, provided that\nthe number of communication rounds is limited. This motivates us to propose a\nlearning-based framework, which unrolls well-noted decentralized optimization\nalgorithms (e.g., Prox-DGD and PG-EXTRA) into graph neural networks (GNNs). By\nminimizing the recovery error via end-to-end training, this learning-based\nframework resolves the model mismatch issue. Our convergence analysis (with\nPG-EXTRA as the base algorithm) reveals that the learned model parameters may\naccelerate the convergence and reduce the recovery error to a large extent. The\nsimulation results demonstrate that the proposed GNN-based learning methods\nprominently outperform several state-of-the-art optimization-based algorithms\nin convergence speed and recovery error.\n", "versions": [{"version": "v1", "created": "Sun, 4 Apr 2021 07:52:34 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Wang", "He", ""], ["Shen", "Yifei", ""], ["Wang", "Ziyuan", ""], ["Li", "Dongsheng", ""], ["Zhang", "Jun", ""], ["Letaief", "Khaled B.", ""], ["Lu", "Jie", ""]]}, {"id": "2104.01560", "submitter": "Marco Visca", "authors": "Marco Visca, Arthur Bouton, Roger Powell, Yang Gao, Saber Fallah", "title": "Conv1D Energy-Aware Path Planner for Mobile Robots in Unstructured\n  Environments", "comments": "To be published in IEEE International Conference on Robotics and\n  Automation (ICRA) 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Driving energy consumption plays a major role in the navigation of mobile\nrobots in challenging environments, especially if they are left to operate\nunattended under limited on-board power. This paper reports on first results of\nan energy-aware path planner, which can provide estimates of the driving energy\nconsumption and energy recovery of a robot traversing complex uneven terrains.\nEnergy is estimated over trajectories making use of a self-supervised learning\napproach, in which the robot autonomously learns how to correlate perceived\nterrain point clouds to energy consumption and recovery. A novel feature of the\nmethod is the use of 1D convolutional neural network to analyse the terrain\nsequentially in the same temporal order as it would be experienced by the robot\nwhen moving. The performance of the proposed approach is assessed in simulation\nover several digital terrain models collected from real natural scenarios, and\nis compared with a heuristic inclination-based energy model. We show evidence\nof the benefit of our method to increase the overall prediction r2 score by\n66.8% and to reduce the driving energy consumption over planned paths by 5.5%.\n", "versions": [{"version": "v1", "created": "Sun, 4 Apr 2021 08:13:54 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Visca", "Marco", ""], ["Bouton", "Arthur", ""], ["Powell", "Roger", ""], ["Gao", "Yang", ""], ["Fallah", "Saber", ""]]}, {"id": "2104.01563", "submitter": "Abhishek Mittal", "authors": "Abhishek Mittal, Ashutosh Modi", "title": "ReCAM@IITK at SemEval-2021 Task 4: BERT and ALBERT based Ensemble for\n  Abstract Word Prediction", "comments": "Accepted at SemEval 2021 Task 4, 8 Pages (7 Pages main content + 1\n  pages for references)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This paper describes our system for Task 4 of SemEval-2021: Reading\nComprehension of Abstract Meaning (ReCAM). We participated in all subtasks\nwhere the main goal was to predict an abstract word missing from a statement.\nWe fine-tuned the pre-trained masked language models namely BERT and ALBERT and\nused an Ensemble of these as our submitted system on Subtask 1\n(ReCAM-Imperceptibility) and Subtask 2 (ReCAM-Nonspecificity). For Subtask 3\n(ReCAM-Intersection), we submitted the ALBERT model as it gives the best\nresults. We tried multiple approaches and found that Masked Language\nModeling(MLM) based approach works the best.\n", "versions": [{"version": "v1", "created": "Sun, 4 Apr 2021 08:22:19 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Mittal", "Abhishek", ""], ["Modi", "Ashutosh", ""]]}, {"id": "2104.01568", "submitter": "Geon Yeong Park", "authors": "Geon Yeong Park, Sang Wan Lee", "title": "Information-theoretic regularization for Multi-source Domain Adaptation", "comments": "17 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Adversarial learning strategy has demonstrated remarkable performance in\ndealing with single-source Domain Adaptation (DA) problems, and it has recently\nbeen applied to Multi-source DA (MDA) problems. Although most existing MDA\nstrategies rely on a multiple domain discriminator setting, its effect on the\nlatent space representations has been poorly understood. Here we adopt an\ninformation-theoretic approach to identify and resolve the potential adverse\neffect of the multiple domain discriminators on MDA: disintegration of\ndomain-discriminative information, limited computational scalability, and a\nlarge variance in the gradient of the loss during training. We examine the\nabove issues by situating adversarial DA in the context of information\nregularization. This also provides a theoretical justification for using a\nsingle and unified domain discriminator. Based on this idea, we implement a\nnovel neural architecture called a Multi-source Information-regularized\nAdaptation Networks (MIAN). Large-scale experiments demonstrate that MIAN,\ndespite its structural simplicity, reliably and significantly outperforms other\nstate-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Sun, 4 Apr 2021 09:11:35 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Park", "Geon Yeong", ""], ["Lee", "Sang Wan", ""]]}, {"id": "2104.01575", "submitter": "Geon Yeong Park", "authors": "Geon Yeong Park, Sang Wan Lee", "title": "Reliably fast adversarial training via latent adversarial perturbation", "comments": "ICLR 2021 Workshop on Security and Safety in Machine Learning Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  While multi-step adversarial training is widely popular as an effective\ndefense method against strong adversarial attacks, its computational cost is\nnotoriously expensive, compared to standard training. Several single-step\nadversarial training methods have been proposed to mitigate the above-mentioned\noverhead cost; however, their performance is not sufficiently reliable\ndepending on the optimization setting. To overcome such limitations, we deviate\nfrom the existing input-space-based adversarial training regime and propose a\nsingle-step latent adversarial training method (SLAT), which leverages the\ngradients of latent representation as the latent adversarial perturbation. We\ndemonstrate that the L1 norm of feature gradients is implicitly regularized\nthrough the adopted latent perturbation, thereby recovering local linearity and\nensuring reliable performance, compared to the existing single-step adversarial\ntraining methods. Because latent perturbation is based on the gradients of the\nlatent representations which can be obtained for free in the process of input\ngradients computation, the proposed method costs roughly the same time as the\nfast gradient sign method. Experiment results demonstrate that the proposed\nmethod, despite its structural simplicity, outperforms state-of-the-art\naccelerated adversarial training methods.\n", "versions": [{"version": "v1", "created": "Sun, 4 Apr 2021 09:47:38 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Park", "Geon Yeong", ""], ["Lee", "Sang Wan", ""]]}, {"id": "2104.01577", "submitter": "Sobirdzhon Bobiev", "authors": "Sobirdzhon Bobiev, Adil Khan, Syed Muhammad Ahsan Raza Kazmi", "title": "Class-incremental Learning using a Sequence of Partial Implicitly\n  Regularized Classifiers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In class-incremental learning, the objective is to learn a number of classes\nsequentially without having access to the whole training data. However, due to\na problem known as catastrophic forgetting, neural networks suffer substantial\nperformance drop in such settings. The problem is often approached by\nexperience replay, a method which stores a limited number of samples to be\nreplayed in future steps to reduce forgetting of the learned classes. When\nusing a pretrained network as a feature extractor, we show that instead of\ntraining a single classifier incrementally, it is better to train a number of\nspecialized classifiers which do not interfere with each other yet can\ncooperatively predict a single class. Our experiments on CIFAR100 dataset show\nthat the proposed method improves the performance over SOTA by a large margin.\n", "versions": [{"version": "v1", "created": "Sun, 4 Apr 2021 10:02:45 GMT"}, {"version": "v2", "created": "Tue, 6 Apr 2021 05:47:21 GMT"}, {"version": "v3", "created": "Sun, 30 May 2021 13:16:51 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Bobiev", "Sobirdzhon", ""], ["Khan", "Adil", ""], ["Kazmi", "Syed Muhammad Ahsan Raza", ""]]}, {"id": "2104.01600", "submitter": "Shreya Ghosh Ms.", "authors": "Shreya Ghosh, Anwesha Mukherjee, Soumya K Ghosh, Rajkumar Buyya", "title": "STOPPAGE: Spatio-temporal Data Driven Cloud-Fog-Edge Computing Framework\n  for Pandemic Monitoring and Management", "comments": "16 pages, 11 figures, pre-print submitted to journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Several researches and evidence show the increasing likelihood of pandemics\n(large-scale outbreaks of infectious disease) which has far reaching sequels in\nall aspects of human lives ranging from rapid mortality rates to economic and\nsocial disruption across the world. In the recent time, COVID-19 (Coronavirus\nDisease 2019) pandemic disrupted normal human lives, and motivated by the\nurgent need of combating COVID-19, researchers have put significant efforts in\nmodelling and analysing the disease spread patterns for effective preventive\nmeasures (in addition to developing pharmaceutical solutions, like vaccine). In\nthis regards, it is absolutely necessary to develop an analytics framework by\nextracting and incorporating the knowledge of heterogeneous datasources to\ndeliver insights in improving administrative policy and enhance the\npreparedness to combat the pandemic. Specifically, human mobility, travel\nhistory and other transport statistics have significant impacts on the spread\nof any infectious disease. In this direction, this paper proposes a\nspatio-temporal knowledge mining framework, named STOPPAGE to model the impact\nof human mobility and other contextual information over large geographic area\nin different temporal scales. The framework has two major modules: (i)\nSpatio-temporal data and computing infrastructure using fog/edge based\narchitecture; and (ii) Spatio-temporal data analytics module to efficiently\nextract knowledge from heterogeneous data sources. Typically, we develop a\nPandemic-knowledge graph to discover correlations among mobility information\nand disease spread, a deep learning architecture to predict the next hot-spot\nzones; and provide necessary support in home-health monitoring utilizing\nFemtolet and fog/edge based solutions. The experimental evaluations on\nreal-life datasets related to COVID-19 in India illustrate the efficacy of the\nproposed methods.\n", "versions": [{"version": "v1", "created": "Sun, 4 Apr 2021 12:29:31 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Ghosh", "Shreya", ""], ["Mukherjee", "Anwesha", ""], ["Ghosh", "Soumya K", ""], ["Buyya", "Rajkumar", ""]]}, {"id": "2104.01618", "submitter": "Haijin Wang", "authors": "Haijin Wang, Caomingzhe Si, Junhua Zhao", "title": "A Federated Learning Framework for Non-Intrusive Load Monitoring", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Non-intrusive load monitoring (NILM) aims at decomposing the total reading of\nthe household power consumption into appliance-wise ones, which is beneficial\nfor consumer behavior analysis as well as energy conservation. NILM based on\ndeep learning has been a focus of research. To train a better neural network,\nit is necessary for the network to be fed with massive data containing various\nappliances and reflecting consumer behavior habits. Therefore, data cooperation\namong utilities and DNOs (distributed network operators) who own the NILM data\nhas been increasingly significant. During the cooperation, however, risks of\nconsumer privacy leakage and losses of data control rights arise. To deal with\nthe problems above, a framework to improve the performance of NILM with\nfederated learning (FL) has been set up. In the framework, model weights\ninstead of the local data are shared among utilities. The global model is\ngenerated by weighted averaging the locally-trained model weights to gather the\nlocally-trained model information. Optimal model selection help choose the\nmodel which adapts to the data from different domains best. Experiments show\nthat this proposal improves the performance of local NILM runners. The\nperformance of this framework is close to that of the centrally-trained model\nobtained by the convergent data without privacy protection.\n", "versions": [{"version": "v1", "created": "Sun, 4 Apr 2021 14:24:50 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Wang", "Haijin", ""], ["Si", "Caomingzhe", ""], ["Zhao", "Junhua", ""]]}, {"id": "2104.01627", "submitter": "Thinh Doan", "authors": "Thinh T. Doan", "title": "Finite-Time Convergence Rates of Nonlinear Two-Time-Scale Stochastic\n  Approximation under Markovian Noise", "comments": "arXiv admin note: text overlap with arXiv:2011.01868", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the so-called two-time-scale stochastic approximation, a\nsimulation-based approach for finding the roots of two coupled nonlinear\noperators. Our focus is to characterize its finite-time performance in a Markov\nsetting, which often arises in stochastic control and reinforcement learning\nproblems. In particular, we consider the scenario where the data in the method\nare generated by Markov processes, therefore, they are dependent. Such\ndependent data result to biased observations of the underlying operators. Under\nsome fairly standard assumptions on the operators and the Markov processes, we\nprovide a formula that characterizes the convergence rate of the mean square\nerrors generated by the method to zero. Our result shows that the method\nachieves a convergence in expectation at a rate $\\mathcal{O}(1/k^{2/3})$, where\n$k$ is the number of iterations. Our analysis is mainly motivated by the\nclassic singular perturbation theory for studying the asymptotic convergence of\ntwo-time-scale systems, that is, we consider a Lyapunov function that carefully\ncharacterizes the coupling between the two iterates. In addition, we utilize\nthe geometric mixing time of the underlying Markov process to handle the bias\nand dependence in the data. Our theoretical result complements for the existing\nliterature, where the rate of nonlinear two-time-scale stochastic approximation\nunder Markovian noise is unknown.\n", "versions": [{"version": "v1", "created": "Sun, 4 Apr 2021 15:19:19 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Doan", "Thinh T.", ""]]}, {"id": "2104.01632", "submitter": "Rui Liu", "authors": "Rui Liu, Siddharth Bhatia, Bryan Hooi", "title": "Isconna: Streaming Anomaly Detection with Frequency and Patterns", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  An edge stream is a common form of presentation of dynamic networks. It can\nevolve with time, with new types of nodes or edges being continuously added.\nExisting methods for anomaly detection rely on edge occurrence counts or\ncompare pattern snippets found in historical records. In this work, we propose\nIsconna, which focuses on both the frequency and the pattern of edge records.\nThe burst detection component targets anomalies between individual timestamps,\nwhile the pattern detection component highlights anomalies across segments of\ntimestamps. These two components together produce three intermediate scores,\nwhich are aggregated into the final anomaly score. Isconna does not actively\nexplore or maintain pattern snippets; it instead measures the consecutive\npresence and absence of edge records. Isconna is an online algorithm, it does\nnot keep the original information of edge records; only statistical values are\nmaintained in a few count-min sketches (CMS). Isconna's space complexity\n$O(rc)$ is determined by two user-specific parameters, the size of CMSs. In\nworst case, Isconna's time complexity can be up to $O(rc)$, but it can be\namortized in practice. Experiments show that Isconna outperforms five\nstate-of-the-art frequency- and/or pattern-based baselines on six real-world\ndatasets with up to 20 million edge records.\n", "versions": [{"version": "v1", "created": "Sun, 4 Apr 2021 15:42:14 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Liu", "Rui", ""], ["Bhatia", "Siddharth", ""], ["Hooi", "Bryan", ""]]}, {"id": "2104.01634", "submitter": "Mohammad Mahdi Kamani", "authors": "Mohammad Mahdi Kamani, Rana Forsati, James Z. Wang, Mehrdad Mahdavi", "title": "Pareto Efficient Fairness in Supervised Learning: From Extraction to\n  Tracing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  As algorithmic decision-making systems are becoming more pervasive, it is\ncrucial to ensure such systems do not become mechanisms of unfair\ndiscrimination on the basis of gender, race, ethnicity, religion, etc.\nMoreover, due to the inherent trade-off between fairness measures and accuracy,\nit is desirable to learn fairness-enhanced models without significantly\ncompromising the accuracy. In this paper, we propose Pareto efficient Fairness\n(PEF) as a suitable fairness notion for supervised learning, that can ensure\nthe optimal trade-off between overall loss and other fairness criteria. The\nproposed PEF notion is definition-agnostic, meaning that any well-defined\nnotion of fairness can be reduced to the PEF notion. To efficiently find a PEF\nclassifier, we cast the fairness-enhanced classification as a bilevel\noptimization problem and propose a gradient-based method that can guarantee the\nsolution belongs to the Pareto frontier with provable guarantees for convex and\nnon-convex objectives. We also generalize the proposed algorithmic solution to\nextract and trace arbitrary solutions from the Pareto frontier for a given\npreference over accuracy and fairness measures. This approach is generic and\ncan be generalized to any multicriteria optimization problem to trace points on\nthe Pareto frontier curve, which is interesting by its own right. We\nempirically demonstrate the effectiveness of the PEF solution and the extracted\nPareto frontier on real-world datasets compared to state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Sun, 4 Apr 2021 15:49:35 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Kamani", "Mohammad Mahdi", ""], ["Forsati", "Rana", ""], ["Wang", "James Z.", ""], ["Mahdavi", "Mehrdad", ""]]}, {"id": "2104.01646", "submitter": "Ayal Taitler", "authors": "Joel Oren, Chana Ross, Maksym Lefarov, Felix Richter, Ayal Taitler,\n  Zohar Feldman, Christian Daniel, Dotan Di Castro", "title": "SOLO: Search Online, Learn Offline for Combinatorial Optimization\n  Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study combinatorial problems with real world applications such as machine\nscheduling, routing, and assignment. We propose a method that combines\nReinforcement Learning (RL) and planning. This method can equally be applied to\nboth the offline, as well as online, variants of the combinatorial problem, in\nwhich the problem components (e.g., jobs in scheduling problems) are not known\nin advance, but rather arrive during the decision-making process. Our solution\nis quite generic, scalable, and leverages distributional knowledge of the\nproblem parameters. We frame the solution process as an MDP, and take a Deep\nQ-Learning approach wherein states are represented as graphs, thereby allowing\nour trained policies to deal with arbitrary changes in a principled manner.\nThough learned policies work well in expectation, small deviations can have\nsubstantial negative effects in combinatorial settings. We mitigate these\ndrawbacks by employing our graph-convolutional policies as non-optimal\nheuristics in a compatible search algorithm, Monte Carlo Tree Search, to\nsignificantly improve overall performance. We demonstrate our method on two\nproblems: Machine Scheduling and Capacitated Vehicle Routing. We show that our\nmethod outperforms custom-tailored mathematical solvers, state of the art\nlearning-based algorithms, and common heuristics, both in computation time and\nperformance.\n", "versions": [{"version": "v1", "created": "Sun, 4 Apr 2021 17:12:24 GMT"}, {"version": "v2", "created": "Thu, 8 Apr 2021 12:48:09 GMT"}, {"version": "v3", "created": "Tue, 18 May 2021 13:06:22 GMT"}], "update_date": "2021-05-19", "authors_parsed": [["Oren", "Joel", ""], ["Ross", "Chana", ""], ["Lefarov", "Maksym", ""], ["Richter", "Felix", ""], ["Taitler", "Ayal", ""], ["Feldman", "Zohar", ""], ["Daniel", "Christian", ""], ["Di Castro", "Dotan", ""]]}, {"id": "2104.01648", "submitter": "Martin Molina-Fructuoso", "authors": "Martin Molina-Fructuoso and Ryan Murray", "title": "Tukey Depths and Hamilton-Jacobi Differential Equations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG math.AP stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The widespread application of modern machine learning has increased the need\nfor robust statistical algorithms. This work studies one such fundamental\nstatistical measure known as the Tukey depth. We study the problem in the\ncontinuum (population) limit. In particular, we derive the associated necessary\nconditions, which take the form of a first-order partial differential equation.\nWe discuss the classical interpretation of this necessary condition as the\nviscosity solution of a Hamilton-Jacobi equation, but with a non-classical\nHamiltonian with discontinuous dependence on the gradient at zero. We prove\nthat this equation possesses a unique viscosity solution and that this solution\nalways bounds the Tukey depth from below. In certain cases, we prove that the\nTukey depth is equal to the viscosity solution, and we give some illustrations\nof standard numerical methods from the optimal control community which deal\ndirectly with the partial differential equation. We conclude by outlining\nseveral promising research directions both in terms of new numerical algorithms\nand theoretical challenges.\n", "versions": [{"version": "v1", "created": "Sun, 4 Apr 2021 17:13:50 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Molina-Fructuoso", "Martin", ""], ["Murray", "Ryan", ""]]}, {"id": "2104.01655", "submitter": "Emilio Parisotto", "authors": "Emilio Parisotto, Ruslan Salakhutdinov", "title": "Efficient Transformers in Reinforcement Learning using Actor-Learner\n  Distillation", "comments": "Published at ICLR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many real-world applications such as robotics provide hard constraints on\npower and compute that limit the viable model complexity of Reinforcement\nLearning (RL) agents. Similarly, in many distributed RL settings, acting is\ndone on un-accelerated hardware such as CPUs, which likewise restricts model\nsize to prevent intractable experiment run times. These \"actor-latency\"\nconstrained settings present a major obstruction to the scaling up of model\ncomplexity that has recently been extremely successful in supervised learning.\nTo be able to utilize large model capacity while still operating within the\nlimits imposed by the system during acting, we develop an \"Actor-Learner\nDistillation\" (ALD) procedure that leverages a continual form of distillation\nthat transfers learning progress from a large capacity learner model to a small\ncapacity actor model. As a case study, we develop this procedure in the context\nof partially-observable environments, where transformer models have had large\nimprovements over LSTMs recently, at the cost of significantly higher\ncomputational complexity. With transformer models as the learner and LSTMs as\nthe actor, we demonstrate in several challenging memory environments that using\nActor-Learner Distillation recovers the clear sample-efficiency gains of the\ntransformer learner model while maintaining the fast inference and reduced\ntotal training time of the LSTM actor model.\n", "versions": [{"version": "v1", "created": "Sun, 4 Apr 2021 17:56:34 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Parisotto", "Emilio", ""], ["Salakhutdinov", "Ruslan", ""]]}, {"id": "2104.01662", "submitter": "Lokesh Krishna", "authors": "Lokesh Krishna, Utkarsh A. Mishra, Guillermo A. Castillo, Ayonga\n  Hereid, Shishir Kolathaya", "title": "Learning Linear Policies for Robust Bipedal Locomotion on Terrains with\n  Varying Slopes", "comments": "7 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG cs.SY eess.SY", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  In this paper, with a view toward deployment of light-weight control\nframeworks for bipedal walking robots, we realize end-foot trajectories that\nare shaped by a single linear feedback policy. We learn this policy via a\nmodel-free and a gradient-free learning algorithm, Augmented Random Search\n(ARS), in the two robot platforms Rabbit and Digit. Our contributions are\ntwo-fold: a) By using torso and support plane orientation as inputs, we achieve\nrobust walking on slopes of up to 20 degrees in simulation. b) We demonstrate\nadditional behaviors like walking backwards, stepping-in-place, and recovery\nfrom external pushes of up to 120 N. The end result is a robust and a fast\nfeedback control law for bipedal walking on terrains with varying slopes.\nTowards the end, we also provide preliminary results of hardware transfer to\nDigit.\n", "versions": [{"version": "v1", "created": "Sun, 4 Apr 2021 18:50:58 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Krishna", "Lokesh", ""], ["Mishra", "Utkarsh A.", ""], ["Castillo", "Guillermo A.", ""], ["Hereid", "Ayonga", ""], ["Kolathaya", "Shishir", ""]]}, {"id": "2104.01672", "submitter": "Anthea Monod", "authors": "Athanasios Vlontzos, Yueqi Cao, Luca Schmidtke, Bernhard Kainz, and\n  Anthea Monod", "title": "Topological Data Analysis of Database Representations for Information\n  Retrieval", "comments": "15 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.AT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Appropriately representing elements in a database so that queries may be\naccurately matched is a central task in information retrieval. This recently\nhas been achieved by embedding the graphical structure of the database into a\nmanifold so that the hierarchy is preserved. Persistent homology provides a\nrigorous characterization for the database topology in terms of both its\nhierarchy and connectivity structure. We compute persistent homology on a\nvariety of datasets and show that some commonly used embeddings fail to\npreserve the connectivity. Moreover, we show that embeddings which successfully\nretain the database topology coincide in persistent homology. We introduce the\ndilation-invariant bottleneck distance to capture this effect, which addresses\nmetric distortion on manifolds. We use it to show that distances between\ntopology-preserving embeddings of databases are small.\n", "versions": [{"version": "v1", "created": "Sun, 4 Apr 2021 19:29:47 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Vlontzos", "Athanasios", ""], ["Cao", "Yueqi", ""], ["Schmidtke", "Luca", ""], ["Kainz", "Bernhard", ""], ["Monod", "Anthea", ""]]}, {"id": "2104.01677", "submitter": "Jo\\~ao Sacramento", "authors": "Nicolas Zucchet and Simon Schug and Johannes von Oswald and Dominic\n  Zhao and Jo\\~ao Sacramento", "title": "A contrastive rule for meta-learning", "comments": "29 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Meta-learning algorithms leverage regularities that are present on a set of\ntasks to speed up and improve the performance of a subsidiary learning process.\nRecent work on deep neural networks has shown that prior gradient-based\nlearning of meta-parameters can greatly improve the efficiency of subsequent\nlearning. Here, we present a biologically plausible meta-learning algorithm\nbased on equilibrium propagation. Instead of explicitly differentiating the\nlearning process, our contrastive meta-learning rule estimates meta-parameter\ngradients by executing the subsidiary process more than once. This avoids\nreversing the learning dynamics in time and computing second-order derivatives.\nIn spite of this, and unlike previous first-order methods, our rule recovers an\narbitrarily accurate meta-parameter update given enough compute. We establish\ntheoretical bounds on its performance and present experiments on a set of\nstandard benchmarks and neural network architectures.\n", "versions": [{"version": "v1", "created": "Sun, 4 Apr 2021 19:45:41 GMT"}, {"version": "v2", "created": "Mon, 19 Apr 2021 21:04:58 GMT"}], "update_date": "2021-04-21", "authors_parsed": [["Zucchet", "Nicolas", ""], ["Schug", "Simon", ""], ["von Oswald", "Johannes", ""], ["Zhao", "Dominic", ""], ["Sacramento", "Jo\u00e3o", ""]]}, {"id": "2104.01678", "submitter": "Timoth\\'ee Lesort", "authors": "Timoth\\'ee Lesort, Massimo Caccia, Irina Rish", "title": "Understanding Continual Learning Settings with Data Distribution Drift\n  Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Classical machine learning algorithms often assume that the data are drawn\ni.i.d. from a stationary probability distribution. Recently, continual learning\nemerged as a rapidly growing area of machine learning where this assumption is\nrelaxed, namely, where the data distribution is non-stationary, i.e., changes\nover time. However, data distribution drifts may interfere with the learning\nprocess and erase previously learned knowledge; thus, continual learning\nalgorithms must include specialized mechanisms to deal with such distribution\ndrifts. A distribution drift may change the class labels distribution, the\ninput distribution, or both. Moreover, distribution drifts might be abrupt or\ngradual. In this paper, we aim to identify and categorize different types of\ndata distribution drifts and potential assumptions about them, to better\ncharacterize various continual-learning scenarios. Moreover, we propose to use\nthe distribution drift framework to provide more precise definitions of several\nterms commonly used in the continual learning field.\n", "versions": [{"version": "v1", "created": "Sun, 4 Apr 2021 19:48:16 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Lesort", "Timoth\u00e9e", ""], ["Caccia", "Massimo", ""], ["Rish", "Irina", ""]]}, {"id": "2104.01681", "submitter": "Grigor Gatchev", "authors": "Grigor Gatchev, Valentin Mollov", "title": "Faster Convolution Inference Through Using Pre-Calculated Lookup Tables", "comments": "11 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Low-cardinality activations permit an algorithm based on fetching the\ninference values from pre-calculated lookup tables instead of calculating them\nevery time. This algorithm can have extensions, some of which offer abilities\nbeyond those of the currently used algorithms. It also allows for a simpler and\nmore effective CNN-specialized hardware.\n", "versions": [{"version": "v1", "created": "Sun, 4 Apr 2021 20:09:20 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Gatchev", "Grigor", ""], ["Mollov", "Valentin", ""]]}, {"id": "2104.01699", "submitter": "Ankit Wagle", "authors": "Ankit Wagle and Sunil Khatri and Sarma Vrudhula", "title": "A Configurable BNN ASIC using a Network of Programmable Threshold Logic\n  Standard Cells", "comments": null, "journal-ref": null, "doi": "10.1109/ICCD50377.2020.00079", "report-no": null, "categories": "cs.AR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper presents TULIP, a new architecture for a binary neural network\n(BNN) that uses an optimal schedule for executing the operations of an\narbitrary BNN. It was constructed with the goal of maximizing energy efficiency\nper classification. At the top-level, TULIP consists of a collection of unique\nprocessing elements (TULIP-PEs) that are organized in a SIMD fashion. Each\nTULIP-PE consists of a small network of binary neurons, and a small amount of\nlocal memory per neuron. The unique aspect of the binary neuron is that it is\nimplemented as a mixed-signal circuit that natively performs the inner-product\nand thresholding operation of an artificial binary neuron. Moreover, the binary\nneuron, which is implemented as a single CMOS standard cell, is reconfigurable,\nand with a change in a single parameter, can implement all standard operations\ninvolved in a BNN. We present novel algorithms for mapping arbitrary nodes of a\nBNN onto the TULIP-PEs. TULIP was implemented as an ASIC in TSMC 40nm-LP\ntechnology. To provide a fair comparison, a recently reported BNN that employs\na conventional MAC-based arithmetic processor was also implemented in the same\ntechnology. The results show that TULIP is consistently 3X more\nenergy-efficient than the conventional design, without any penalty in\nperformance, area, or accuracy.\n", "versions": [{"version": "v1", "created": "Sun, 4 Apr 2021 21:28:11 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Wagle", "Ankit", ""], ["Khatri", "Sunil", ""], ["Vrudhula", "Sarma", ""]]}, {"id": "2104.01708", "submitter": "Stephen Zhang", "authors": "Stephen Y. Zhang", "title": "A unified framework for non-negative matrix and tensor factorisations\n  with a smoothed Wasserstein loss", "comments": "14 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Non-negative matrix and tensor factorisations are a classical tool for\nfinding low-dimensional representations of high-dimensional datasets. In\napplications such as imaging, datasets can be regarded as distributions\nsupported on a space with metric structure. In such a setting, a loss function\nbased on the Wasserstein distance of optimal transportation theory is a natural\nchoice since it incorporates the underlying geometry of the data. We introduce\na general mathematical framework for computing non-negative factorisations of\nboth matrices and tensors with respect to an optimal transport loss. We derive\nan efficient computational method for its solution using a convex dual\nformulation, and demonstrate the applicability of this approach with several\nnumerical illustrations with both matrix and tensor-valued data.\n", "versions": [{"version": "v1", "created": "Sun, 4 Apr 2021 22:42:21 GMT"}, {"version": "v2", "created": "Thu, 15 Jul 2021 03:32:32 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Zhang", "Stephen Y.", ""]]}, {"id": "2104.01711", "submitter": "Rocky Chen", "authors": "Tong Chen, Hongzhi Yin, Jie Ren, Zi Huang, Xiangliang Zhang, Hao Wang", "title": "Uniting Heterogeneity, Inductiveness, and Efficiency for Graph\n  Representation Learning", "comments": "Manuscript is under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the ubiquitous graph-structured data in various applications, models\nthat can learn compact but expressive vector representations of nodes have\nbecome highly desirable. Recently, bearing the message passing paradigm, graph\nneural networks (GNNs) have greatly advanced the performance of node\nrepresentation learning on graphs. However, a majority class of GNNs are only\ndesigned for homogeneous graphs, leading to inferior adaptivity to the more\ninformative heterogeneous graphs with various types of nodes and edges. Also,\ndespite the necessity of inductively producing representations for completely\nnew nodes (e.g., in streaming scenarios), few heterogeneous GNNs can bypass the\ntransductive learning scheme where all nodes must be known during training.\nFurthermore, the training efficiency of most heterogeneous GNNs has been\nhindered by their sophisticated designs for extracting the semantics associated\nwith each meta path or relation. In this paper, we propose WIde and DEep\nmessage passing Network (WIDEN) to cope with the aforementioned problems about\nheterogeneity, inductiveness, and efficiency that are rarely investigated\ntogether in graph representation learning. In WIDEN, we propose a novel\ninductive, meta path-free message passing scheme that packs up heterogeneous\nnode features with their associated edges from both low- and high-order\nneighbor nodes. To further improve the training efficiency, we innovatively\npresent an active downsampling strategy that drops unimportant neighbor nodes\nto facilitate faster information propagation. Experiments on three real-world\nheterogeneous graphs have further validated the efficacy of WIDEN on both\ntransductive and inductive node representation learning, as well as the\nsuperior training efficiency against state-of-the-art baselines.\n", "versions": [{"version": "v1", "created": "Sun, 4 Apr 2021 23:31:39 GMT"}, {"version": "v2", "created": "Sun, 11 Apr 2021 07:47:41 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Chen", "Tong", ""], ["Yin", "Hongzhi", ""], ["Ren", "Jie", ""], ["Huang", "Zi", ""], ["Zhang", "Xiangliang", ""], ["Wang", "Hao", ""]]}, {"id": "2104.01713", "submitter": "Erkan Kayacan", "authors": "Erkan Kayacan, Erdal Kayacan and Mojtaba Ahmadieh Khanesar", "title": "Identification of Nonlinear Dynamic Systems Using Type-2 Fuzzy Neural\n  Networks -- A Novel Learning Algorithm and a Comparative Study", "comments": null, "journal-ref": "IEEE Transactions on Industrial Electronics, vol. 62, no. 3, pp.\n  1716-1724, March 2015", "doi": "10.1109/TIE.2014.2345353", "report-no": null, "categories": "eess.SY cs.LG cs.SY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In order to achieve faster and more robust convergence (especially under\nnoisy working environments), a sliding mode theory-based learning algorithm has\nbeen proposed to tune both the premise and consequent parts of type-2 fuzzy\nneural networks in this paper. Differently from recent studies, where sliding\nmode control theory-based rules are proposed for only the consequent part of\nthe network, the developed algorithm applies fully sliding mode parameter\nupdate rules for both the premise and consequent parts of the type-2 fuzzy\nneural networks. In addition, the responsible parameter for sharing the\ncontributions of the lower and upper parts of the type-2 fuzzy membership\nfunctions is also tuned. Moreover, the learning rate of the network is updated\nduring the online training. The stability of the proposed learning algorithm\nhas been proved by using an appropriate Lyapunov function. Several comparisons\nhave been realized and shown that the proposed algorithm has faster convergence\nspeed than the existing methods such as gradient-based and swarm\nintelligence-based methods. Moreover, the proposed learning algorithm has a\nclosed form, and it is easier to implement than the other existing methods.\n", "versions": [{"version": "v1", "created": "Sun, 4 Apr 2021 23:44:59 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Kayacan", "Erkan", ""], ["Kayacan", "Erdal", ""], ["Khanesar", "Mojtaba Ahmadieh", ""]]}, {"id": "2104.01714", "submitter": "Michael Poluektov", "authors": "Andrew Polar, Michael Poluektov", "title": "Urysohn Forest for Aleatoric Uncertainty Quantification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The terms tree and forest are normally associated with an ensemble of\nclassifiers. In this article Urysohn tree is a regression model representing\nmultiple discrete Urysohn operators connected as a tree, where the inputs of\none operator are outputs of the others. This structure, referred as Urysohn\ntree, is not completely new. One example of such tree is known for more than\nhalf a century. It is Kolmogorov-Arnold representation. The authors of this\npaper in their recently published research offered the new computational\ntechnique for generating of Kolmogorov-Arnold representation as a deep machine\nlearning process. This article is two steps further into this research. First\nis a Urysohn tree with multiple hidden layers which is generalization of\nKolmogorov-Arnold model and second is a boosting algorithm for building of the\nforest of such trees for modeling of aleatoric uncertainty of the data.\n", "versions": [{"version": "v1", "created": "Sun, 4 Apr 2021 23:49:15 GMT"}, {"version": "v2", "created": "Mon, 14 Jun 2021 10:22:03 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Polar", "Andrew", ""], ["Poluektov", "Michael", ""]]}, {"id": "2104.01716", "submitter": "Rocky Chen", "authors": "Tong Chen, Hongzhi Yin, Xiangliang Zhang, Zi Huang, Yang Wang, Meng\n  Wang", "title": "Quaternion Factorization Machines: A Lightweight Solution to Intricate\n  Feature Interaction Modelling", "comments": "Manuscript is under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As a well-established approach, factorization machine (FM) is capable of\nautomatically learning high-order interactions among features to make\npredictions without the need for manual feature engineering. With the prominent\ndevelopment of deep neural networks (DNNs), there is a recent and ongoing trend\nof enhancing the expressiveness of FM-based models with DNNs. However, though\nbetter results are obtained with DNN-based FM variants, such performance gain\nis paid off by an enormous amount (usually millions) of excessive model\nparameters on top of the plain FM. Consequently, the heavy parameterization\nimpedes the real-life practicality of those deep models, especially efficient\ndeployment on resource-constrained IoT and edge devices. In this paper, we move\nbeyond the traditional real space where most deep FM-based models are defined,\nand seek solutions from quaternion representations within the hypercomplex\nspace. Specifically, we propose the quaternion factorization machine (QFM) and\nquaternion neural factorization machine (QNFM), which are two novel lightweight\nand memory-efficient quaternion-valued models for sparse predictive analytics.\nBy introducing a brand new take on FM-based models with the notion of\nquaternion algebra, our models not only enable expressive inter-component\nfeature interactions, but also significantly reduce the parameter size due to\nlower degrees of freedom in the hypercomplex Hamilton product compared with\nreal-valued matrix multiplication. Extensive experimental results on three\nlarge-scale datasets demonstrate that QFM achieves 4.36% performance\nimprovement over the plain FM without introducing any extra parameters, while\nQNFM outperforms all baselines with up to two magnitudes' parameter size\nreduction in comparison to state-of-the-art peer methods.\n", "versions": [{"version": "v1", "created": "Mon, 5 Apr 2021 00:02:36 GMT"}, {"version": "v2", "created": "Sun, 11 Apr 2021 07:30:29 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Chen", "Tong", ""], ["Yin", "Hongzhi", ""], ["Zhang", "Xiangliang", ""], ["Huang", "Zi", ""], ["Wang", "Yang", ""], ["Wang", "Meng", ""]]}, {"id": "2104.01720", "submitter": "Eduardo Ogasawara", "authors": "Lucas Giusti, Leonardo Carvalho, Antonio Tadeu Gomes, Rafaelli\n  Coutinho, Jorge Soares, Eduardo Ogasawara", "title": "Analyzing Flight Delay Prediction Under Concept Drift", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Flight delays impose challenges that impact any flight transportation system.\nPredicting when they are going to occur is an important way to mitigate this\nissue. However, the behavior of the flight delay system varies through time.\nThis phenomenon is known in predictive analytics as concept drift. This paper\ninvestigates the prediction performance of different drift handling strategies\nin aviation under different scales (models trained from flights related to a\nsingle airport or the entire flight system). Specifically, two research\nquestions were proposed and answered: (i) How do drift handling strategies\ninfluence the prediction performance of delays? (ii) Do different scales change\nthe results of drift handling strategies? In our analysis, drift handling\nstrategies are relevant, and their impacts vary according to scale and machine\nlearning models used.\n", "versions": [{"version": "v1", "created": "Mon, 5 Apr 2021 00:16:08 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Giusti", "Lucas", ""], ["Carvalho", "Leonardo", ""], ["Gomes", "Antonio Tadeu", ""], ["Coutinho", "Rafaelli", ""], ["Soares", "Jorge", ""], ["Ogasawara", "Eduardo", ""]]}, {"id": "2104.01725", "submitter": "Ali Hariri", "authors": "Ali Hariri, Darya Dyachkova and Sergei Gleyzer", "title": "Graph Generative Models for Fast Detector Simulations in High Energy\n  Physics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "hep-ex cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Accurate and fast simulation of particle physics processes is crucial for the\nhigh-energy physics community. Simulating particle interactions with detectors\nis both time consuming and computationally expensive. With the proton-proton\ncollision energy of 13 TeV, the Large Hadron Collider is uniquely positioned to\ndetect and measure the rare phenomena that can shape our knowledge of new\ninteractions. The High-Luminosity Large Hadron Collider (HL-LHC) upgrade will\nput a significant strain on the computing infrastructure due to increased event\nrate and levels of pile-up. Simulation of high-energy physics collisions needs\nto be significantly faster without sacrificing the physics accuracy. Machine\nlearning approaches can offer faster solutions, while maintaining a high level\nof fidelity. We discuss a graph generative model that provides effective\nreconstruction of LHC events, paving the way for full detector level fast\nsimulation for HL-LHC.\n", "versions": [{"version": "v1", "created": "Mon, 5 Apr 2021 00:27:43 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Hariri", "Ali", ""], ["Dyachkova", "Darya", ""], ["Gleyzer", "Sergei", ""]]}, {"id": "2104.01742", "submitter": "Robin M. Schmidt", "authors": "Robin M. Schmidt", "title": "Explainability-aided Domain Generalization for Image Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Traditionally, for most machine learning settings, gaining some degree of\nexplainability that tries to give users more insights into how and why the\nnetwork arrives at its predictions, restricts the underlying model and hinders\nperformance to a certain degree. For example, decision trees are thought of as\nbeing more explainable than deep neural networks but they lack performance on\nvisual tasks. In this work, we empirically demonstrate that applying methods\nand architectures from the explainability literature can, in fact, achieve\nstate-of-the-art performance for the challenging task of domain generalization\nwhile offering a framework for more insights into the prediction and training\nprocess. For that, we develop a set of novel algorithms including DivCAM, an\napproach where the network receives guidance during training via gradient based\nclass activation maps to focus on a diverse set of discriminative features, as\nwell as ProDrop and D-Transformers which apply prototypical networks to the\ndomain generalization task, either with self-challenging or attention\nalignment. Since these methods offer competitive performance on top of\nexplainability, we argue that the proposed methods can be used as a tool to\nimprove the robustness of deep neural network architectures.\n", "versions": [{"version": "v1", "created": "Mon, 5 Apr 2021 02:27:01 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Schmidt", "Robin M.", ""]]}, {"id": "2104.01747", "submitter": "Sanjai Narain", "authors": "Sanjai Narain, Emily Mak, Dana Chee, Brendan Englot, Kishore\n  Pochiraju, Niraj K. Jha, Karthik Narayan", "title": "Fast Design Space Exploration of Nonlinear Systems: Part I", "comments": "14 pages, 26 figures. arXiv admin note: text overlap with\n  arXiv:2010.09842", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  System design tools are often only available as blackboxes with complex\nnonlinear relationships between inputs and outputs. Blackboxes typically run in\nthe forward direction: for a given design as input they compute an output\nrepresenting system behavior. Most cannot be run in reverse to produce an input\nfrom requirements on output. Thus, finding a design satisfying a requirement is\noften a trial-and-error process without assurance of optimality. Finding\ndesigns concurrently satisfying multiple requirements is harder because designs\nsatisfying individual requirements may conflict with each other. Compounding\nthe hardness are the facts that blackbox evaluations can be expensive and\nsometimes fail to produce an output due to non-convergence of underlying\nnumerical algorithms. This paper presents CNMA (Constrained optimization with\nNeural networks, MILP solvers and Active Learning), a new optimization method\nfor blackboxes. It is conservative in the number of blackbox evaluations. Any\ndesigns it finds are guaranteed to satisfy all requirements. It is resilient to\nthe failure of blackboxes to compute outputs. It tries to sample only the part\nof the design space relevant to solving the design problem, leveraging the\npower of neural networks, MILPs, and a new learning-from-failure feedback loop.\nThe paper also presents parallel CNMA that improves the efficiency and quality\nof solutions over the sequential version, and tries to steer it away from local\noptima. CNMA's performance is evaluated for seven nonlinear design problems of\n8 (2 problems), 10, 15, 36 and 60 real-valued dimensions and one with 186\nbinary dimensions. It is shown that CNMA improves the performance of stable,\noff-the-shelf implementations of Bayesian Optimization and Nelder Mead and\nRandom Search by 1%-87% for a given fixed time and function evaluation budget.\nNote, that these implementations did not always return solutions.\n", "versions": [{"version": "v1", "created": "Mon, 5 Apr 2021 02:59:45 GMT"}, {"version": "v2", "created": "Sun, 11 Apr 2021 04:04:23 GMT"}, {"version": "v3", "created": "Thu, 27 May 2021 20:09:36 GMT"}], "update_date": "2021-05-31", "authors_parsed": [["Narain", "Sanjai", ""], ["Mak", "Emily", ""], ["Chee", "Dana", ""], ["Englot", "Brendan", ""], ["Pochiraju", "Kishore", ""], ["Jha", "Niraj K.", ""], ["Narayan", "Karthik", ""]]}, {"id": "2104.01750", "submitter": "Shaojie Tang", "authors": "Shaojie Tang, Jing Yuan", "title": "Optimal Sampling Gaps for Adaptive Submodular Maximization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Running machine learning algorithms on large and rapidly growing volumes of\ndata are often computationally expensive, one common trick to reduce the size\nof a data set, and thus reduce the computational cost of machine learning\nalgorithms, is \\emph{probability sampling}. It creates a sampled data set by\nincluding each data point from the original data set with a known probability.\nAlthough the benefit of running machine learning algorithms on the reduced data\nset is obvious, one major concern is that the performance of the solution\nobtained from samples might be much worse than that of the optimal solution\nwhen using the full data set. In this paper, we examine the performance loss\ncaused by probability sampling in the context of adaptive submodular\nmaximization. We consider a easiest probability sampling method which selects\neach data point independently with probability $r\\in[0,1]$. We define sampling\ngap as the largest ratio of the optimal solution obtained from the full data\nset and the optimal solution obtained from the samples, over independence\nsystems. Our main contribution is to show that if the utility function is\npolicywise submodular, then for a given sampling rate $r$, the sampling gap is\nboth upper bounded and lower bounded by $1/r$. One immediate implication of our\nresult is that if we can find an $\\alpha$-approximation solution based on a\nsampled data set (which is sampled at sampling rate $r$), then this solution\nachieves an $\\alpha r$ approximation ratio for the original problem when using\nthe full data set. We also show that the property of policywise submodular can\nbe found in a wide range of real-world applications, including pool-based\nactive learning and adaptive viral marketing.\n", "versions": [{"version": "v1", "created": "Mon, 5 Apr 2021 03:21:32 GMT"}, {"version": "v2", "created": "Tue, 13 Apr 2021 02:34:04 GMT"}], "update_date": "2021-04-14", "authors_parsed": [["Tang", "Shaojie", ""], ["Yuan", "Jing", ""]]}, {"id": "2104.01757", "submitter": "Keenan Venuti", "authors": "Keenan Venuti", "title": "Predicting Mergers and Acquisitions using Graph-based Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The graph data structure is a staple in mathematics, yet graph-based machine\nlearning is a relatively green field within the domain of data science. Recent\nadvances in graph-based ML and open source implementations of relevant\nalgorithms are allowing researchers to apply methods created in academia to\nreal-world datasets. The goal of this project was to utilize a popular graph\nmachine learning framework, GraphSAGE, to predict mergers and acquisitions\n(M&A) of enterprise companies. The results were promising, as the model\npredicted with 81.79% accuracy on a validation dataset. Given the abundance of\ndata sources and algorithmic decision making within financial data science,\ngraph-based machine learning offers a performant, yet non-traditional approach\nto generating alpha.\n", "versions": [{"version": "v1", "created": "Mon, 5 Apr 2021 03:49:45 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Venuti", "Keenan", ""]]}, {"id": "2104.01769", "submitter": "Wei-Lun Chao", "authors": "Han-Jia Ye, De-Chuan Zhan, Wei-Lun Chao", "title": "Procrustean Training for Imbalanced Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Neural networks trained with class-imbalanced data are known to perform\npoorly on minor classes of scarce training data. Several recent works attribute\nthis to over-fitting to minor classes. In this paper, we provide a novel\nexplanation of this issue. We found that a neural network tends to first\nunder-fit the minor classes by classifying most of their data into the major\nclasses in early training epochs. To correct these wrong predictions, the\nneural network then must focus on pushing features of minor class data across\nthe decision boundaries between major and minor classes, leading to much larger\ngradients for features of minor classes. We argue that such an under-fitting\nphase over-emphasizes the competition between major and minor classes, hinders\nthe neural network from learning the discriminative knowledge that can be\ngeneralized to test data, and eventually results in over-fitting. To address\nthis issue, we propose a novel learning strategy to equalize the training\nprogress across classes. We mix features of the major class data with those of\nother data in a mini-batch, intentionally weakening their features to prevent a\nneural network from fitting them first. We show that this strategy can largely\nbalance the training accuracy and feature gradients across classes, effectively\nmitigating the under-fitting then over-fitting problem for minor class data. On\nseveral benchmark datasets, our approach achieves the state-of-the-art\naccuracy, especially for the challenging step-imbalanced cases.\n", "versions": [{"version": "v1", "created": "Mon, 5 Apr 2021 04:44:01 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Ye", "Han-Jia", ""], ["Zhan", "De-Chuan", ""], ["Chao", "Wei-Lun", ""]]}, {"id": "2104.01774", "submitter": "Jinwei Lu", "authors": "Jinwei Lu, Ningrui Zhao", "title": "Application of Neural Network Algorithm in Propylene Distillation", "comments": "16 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.chem-ph cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Artificial neural network modeling does not need to consider the mechanism.\nIt can map the implicit relationship between input and output and predict the\nperformance of the system well. At the same time, it has the advantages of\nself-learning ability and high fault tolerance. The gas-liquid two phases in\nthe rectification tower conduct interphase heat and mass transfer through\ncountercurrent contact. The functional relationship between the product\nconcentration at the top and bottom of the tower and the process parameters is\nextremely complex. The functional relationship can be accurately controlled by\nartificial neural network algorithms. The key components of the propylene\ndistillation tower are the propane concentration at the top of the tower and\nthe propylene concentration at the bottom of the tower. Accurate measurement of\nthem plays a key role in increasing propylene yield in ethylene production\nenterprises. This article mainly introduces the neural network model and its\napplication in the propylene distillation tower.\n", "versions": [{"version": "v1", "created": "Mon, 5 Apr 2021 05:06:29 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Lu", "Jinwei", ""], ["Zhao", "Ningrui", ""]]}, {"id": "2104.01781", "submitter": "Astuti Sharma", "authors": "Apoorva Gokhale, Astuti Sharma, Kaustav Datta, Savyasachi", "title": "Reducing Racial Bias in Facial Age Prediction using Unsupervised Domain\n  Adaptation in Regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  We propose an approach for unsupervised domain adaptation for the task of\nestimating someone's age from a given face image. In order to avoid the\npropagation of racial bias in most publicly available face image datasets into\nthe inefficacy of models trained on them, we perform domain adaptation to\nmotivate the predictor to learn features that are invariant to ethnicity,\nenhancing the generalization performance across faces of people from different\nethnic backgrounds. Exploiting the ordinality of age, we also impose ranking\nconstraints on the prediction of the model and design our model such that it\ntakes as input a pair of images, and outputs both the relative age difference\nand the rank of the first identity with respect to the other in terms of their\nages. Furthermore, we implement Multi-Dimensional Scaling to retrieve absolute\nages from the predicted age differences from as few as two labeled images from\nthe domain to be adapted to. We experiment with a publicly available dataset\nwith age labels, dividing it into subsets based on the ethnicity labels, and\nevaluating the performance of our approach on the data from an ethnicity\ndifferent from the one that the model is trained on. Additionally, we impose a\nconstraint to preserve the sanity of the predictions with respect to relative\nand absolute ages, and another to ensure the smoothness of the predictions with\nrespect to the input. We experiment extensively and compare various domain\nadaptation approaches for the task of regression.\n", "versions": [{"version": "v1", "created": "Mon, 5 Apr 2021 05:31:12 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Gokhale", "Apoorva", ""], ["Sharma", "Astuti", ""], ["Datta", "Kaustav", ""], ["Savyasachi", "", ""]]}, {"id": "2104.01787", "submitter": "Jeong Min Lee", "authors": "Jeong Min Lee and Milos Hauskrecht", "title": "Neural Clinical Event Sequence Prediction through Personalized Online\n  Adaptive Learning", "comments": "Accepted at 19th International Conference on Artificial Intelligence\n  in Medicine (AIME 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Clinical event sequences consist of thousands of clinical events that\nrepresent records of patient care in time. Developing accurate prediction\nmodels for such sequences is of a great importance for defining representations\nof a patient state and for improving patient care. One important challenge of\nlearning a good predictive model of clinical sequences is patient-specific\nvariability. Based on underlying clinical complications, each patient's\nsequence may consist of different sets of clinical events. However,\npopulation-based models learned from such sequences may not accurately predict\npatient-specific dynamics of event sequences. To address the problem, we\ndevelop a new adaptive event sequence prediction framework that learns to\nadjust its prediction for individual patients through an online model update.\n", "versions": [{"version": "v1", "created": "Mon, 5 Apr 2021 06:22:56 GMT"}, {"version": "v2", "created": "Tue, 6 Apr 2021 03:02:09 GMT"}], "update_date": "2021-04-07", "authors_parsed": [["Lee", "Jeong Min", ""], ["Hauskrecht", "Milos", ""]]}, {"id": "2104.01789", "submitter": "Guannan Lou", "authors": "Yao Deng, Tiehua Zhang, Guannan Lou, Xi Zheng, Jiong Jin, Qing-Long\n  Han", "title": "Deep Learning-Based Autonomous Driving Systems: A Survey of Attacks and\n  Defenses", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The rapid development of artificial intelligence, especially deep learning\ntechnology, has advanced autonomous driving systems (ADSs) by providing precise\ncontrol decisions to counterpart almost any driving event, spanning from\nanti-fatigue safe driving to intelligent route planning. However, ADSs are\nstill plagued by increasing threats from different attacks, which could be\ncategorized into physical attacks, cyberattacks and learning-based adversarial\nattacks. Inevitably, the safety and security of deep learning-based autonomous\ndriving are severely challenged by these attacks, from which the\ncountermeasures should be analyzed and studied comprehensively to mitigate all\npotential risks. This survey provides a thorough analysis of different attacks\nthat may jeopardize ADSs, as well as the corresponding state-of-the-art defense\nmechanisms. The analysis is unrolled by taking an in-depth overview of each\nstep in the ADS workflow, covering adversarial attacks for various deep\nlearning models and attacks in both physical and cyber context. Furthermore,\nsome promising research directions are suggested in order to improve deep\nlearning-based autonomous driving safety, including model robustness training,\nmodel testing and verification, and anomaly detection based on cloud/edge\nservers.\n", "versions": [{"version": "v1", "created": "Mon, 5 Apr 2021 06:31:47 GMT"}, {"version": "v2", "created": "Sat, 10 Apr 2021 02:28:02 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Deng", "Yao", ""], ["Zhang", "Tiehua", ""], ["Lou", "Guannan", ""], ["Zheng", "Xi", ""], ["Jin", "Jiong", ""], ["Han", "Qing-Long", ""]]}, {"id": "2104.01795", "submitter": "Gege Wen", "authors": "Gege Wen, Catherine Hay, Sally M. Benson", "title": "CCSNet: a deep learning modeling suite for CO$_2$ storage", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.flu-dyn cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Numerical simulation is an essential tool for many applications involving\nsubsurface flow and transport, yet often suffers from computational challenges\ndue to the multi-physics nature, highly non-linear governing equations,\ninherent parameter uncertainties, and the need for high spatial resolutions to\ncapture multi-scale heterogeneity. We developed CCSNet, a general-purpose\ndeep-learning modeling suite that can act as an alternative to conventional\nnumerical simulators for carbon capture and storage (CCS) problems where CO$_2$\nis injected into saline aquifers in 2d-radial systems. CCSNet consists of a\nsequence of deep learning models producing all the outputs that a numerical\nsimulator typically provides, including saturation distributions, pressure\nbuildup, dry-out, fluid densities, mass balance, solubility trapping, and sweep\nefficiency. The results are 10$^3$ to 10$^4$ times faster than conventional\nnumerical simulators. As an application of CCSNet illustrating the value of its\nhigh computational efficiency, we developed rigorous estimation techniques for\nthe sweep efficiency and solubility trapping.\n", "versions": [{"version": "v1", "created": "Mon, 5 Apr 2021 06:56:25 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Wen", "Gege", ""], ["Hay", "Catherine", ""], ["Benson", "Sally M.", ""]]}, {"id": "2104.01808", "submitter": "Ziyue Huang", "authors": "Ziyue Huang, Yuan Qiu, Ke Yi, Graham Cormode", "title": "Frequency Estimation Under Multiparty Differential Privacy: One-shot and\n  Streaming", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the fundamental problem of frequency estimation under both privacy\nand communication constraints, where the data is distributed among $k$ parties.\nWe consider two application scenarios: (1) one-shot, where the data is static\nand the aggregator conducts a one-time computation; and (2) streaming, where\neach party receives a stream of items over time and the aggregator continuously\nmonitors the frequencies. We adopt the model of multiparty differential privacy\n(MDP), which is more general than local differential privacy (LDP) and\n(centralized) differential privacy. Our protocols achieve optimality (up to\nlogarithmic factors) permissible by the more stringent of the two constraints.\nIn particular, when specialized to the $\\varepsilon$-LDP model, our protocol\nachieves an error of $\\sqrt{k}/(e^{\\Theta(\\varepsilon)}-1)$ using $O(k\\max\\{\n\\varepsilon, \\frac{1}{\\varepsilon} \\})$ bits of communication and $O(k \\log u)$\nbits of public randomness, where $u$ is the size of the domain.\n", "versions": [{"version": "v1", "created": "Mon, 5 Apr 2021 08:15:20 GMT"}, {"version": "v2", "created": "Sat, 29 May 2021 13:24:01 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Huang", "Ziyue", ""], ["Qiu", "Yuan", ""], ["Yi", "Ke", ""], ["Cormode", "Graham", ""]]}, {"id": "2104.01812", "submitter": "Aneesh Balakrishnan", "authors": "Aneesh Balakrishnan, Thomas Lange, Maximilien Glorieux, Dan\n  Alexandrescu and Maksim Jenihhin", "title": "Modeling Gate-Level Abstraction Hierarchy Using Graph Convolutional\n  Neural Networks to Predict Functional De-Rating Factors", "comments": "13 Figures, 7 pages for conference ( 1 extra page (page number 1) is\n  added for arxive about license agreement), Conference: 2019 NASA/ESA\n  Conference on Adaptive Hardware and Systems (AHS)", "journal-ref": null, "doi": "10.1109/AHS.2019.00007", "report-no": null, "categories": "cs.AR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper is proposing a methodology for modeling a gate-level netlist using\na Graph Convolutional Network (GCN). The model predicts the overall functional\nde-rating factors of sequential elements of a given circuit. In the preliminary\nphase of the work, the important goal is making a GCN which able to take a\ngate-level netlist as input information after transforming it into the\nProbabilistic Bayesian Graph in the form of Graph Modeling Language (GML). This\npart enables the GCN to learn the structural information of netlist in graph\ndomains. In the second phase of the work, the modeled GCN trained with the a\nfunctional de-rating factor of a very low number of individual sequential\nelements (flip-flops). The third phase includes understanding of GCN models\naccuracy to model an arbitrary circuit netlist. The designed model was\nvalidated for two circuits. One is the IEEE 754 standard double precision\nfloating point adder and the second one is the 10-Gigabit Ethernet MAC\nIEEE802.3 standard. The predicted results compared to the standard fault\ninjection campaign results of the error called Single EventUpset (SEU). The\nvalidated results are graphically pictured in the form of the histogram and\nsorted probabilities and evaluated with the Confidence Interval (CI) metric\nbetween the predicted and simulated fault injection results.\n", "versions": [{"version": "v1", "created": "Mon, 5 Apr 2021 08:38:16 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Balakrishnan", "Aneesh", ""], ["Lange", "Thomas", ""], ["Glorieux", "Maximilien", ""], ["Alexandrescu", "Dan", ""], ["Jenihhin", "Maksim", ""]]}, {"id": "2104.01830", "submitter": "Vitor Cerqueira", "authors": "Vitor Cerqueira, Luis Torgo, Carlos Soares, Albert Bifet", "title": "Model Compression for Dynamic Forecast Combination", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The predictive advantage of combining several different predictive models is\nwidely accepted. Particularly in time series forecasting problems, this\ncombination is often dynamic to cope with potential non-stationary sources of\nvariation present in the data. Despite their superior predictive performance,\nensemble methods entail two main limitations: high computational costs and lack\nof transparency. These issues often preclude the deployment of such approaches,\nin favour of simpler yet more efficient and reliable ones. In this paper, we\nleverage the idea of model compression to address this problem in time series\nforecasting tasks. Model compression approaches have been mostly unexplored for\nforecasting. Their application in time series is challenging due to the\nevolving nature of the data. Further, while the literature focuses on neural\nnetworks, we apply model compression to distinct types of methods. In an\nextensive set of experiments, we show that compressing dynamic forecasting\nensembles into an individual model leads to a comparable predictive performance\nand a drastic reduction in computational costs. Further, the compressed\nindividual model with best average rank is a rule-based regression model. Thus,\nmodel compression also leads to benefits in terms of model interpretability.\nThe experiments carried in this paper are fully reproducible.\n", "versions": [{"version": "v1", "created": "Mon, 5 Apr 2021 09:55:35 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Cerqueira", "Vitor", ""], ["Torgo", "Luis", ""], ["Soares", "Carlos", ""], ["Bifet", "Albert", ""]]}, {"id": "2104.01836", "submitter": "Hideaki Ishibashi Ph.D", "authors": "Hideaki Ishibashi and Hideitsu Hino", "title": "Stopping Criterion for Active Learning Based on Error Stability", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Active learning is a framework for supervised learning to improve the\npredictive performance by adaptively annotating a small number of samples. To\nrealize efficient active learning, both an acquisition function that determines\nthe next datum and a stopping criterion that determines when to stop learning\nshould be considered. In this study, we propose a stopping criterion based on\nerror stability, which guarantees that the change in generalization error upon\nadding a new sample is bounded by the annotation cost and can be applied to any\nBayesian active learning. We demonstrate that the proposed criterion stops\nactive learning at the appropriate timing for various learning models and real\ndatasets.\n", "versions": [{"version": "v1", "created": "Mon, 5 Apr 2021 10:15:50 GMT"}, {"version": "v2", "created": "Fri, 9 Apr 2021 01:20:21 GMT"}], "update_date": "2021-04-12", "authors_parsed": [["Ishibashi", "Hideaki", ""], ["Hino", "Hideitsu", ""]]}, {"id": "2104.01845", "submitter": "Sk Miraj Ahmed", "authors": "Sk Miraj Ahmed, Dripta S. Raychaudhuri, Sujoy Paul, Samet Oymak, Amit\n  K. Roy-Chowdhury", "title": "Unsupervised Multi-source Domain Adaptation Without Access to Source\n  Data", "comments": "This paper will appear at CVPR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Unsupervised Domain Adaptation (UDA) aims to learn a predictor model for an\nunlabeled domain by transferring knowledge from a separate labeled source\ndomain. However, most of these conventional UDA approaches make the strong\nassumption of having access to the source data during training, which may not\nbe very practical due to privacy, security and storage concerns. A recent line\nof work addressed this problem and proposed an algorithm that transfers\nknowledge to the unlabeled target domain from a single source model without\nrequiring access to the source data. However, for adaptation purposes, if there\nare multiple trained source models available to choose from, this method has to\ngo through adapting each and every model individually, to check for the best\nsource. Thus, we ask the question: can we find the optimal combination of\nsource models, with no source data and without target labels, whose performance\nis no worse than the single best source? To answer this, we propose a novel and\nefficient algorithm which automatically combines the source models with\nsuitable weights in such a way that it performs at least as good as the best\nsource model. We provide intuitive theoretical insights to justify our claim.\nFurthermore, extensive experiments are conducted on several benchmark datasets\nto show the effectiveness of our algorithm, where in most cases, our method not\nonly reaches best source accuracy but also outperforms it.\n", "versions": [{"version": "v1", "created": "Mon, 5 Apr 2021 10:45:12 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Ahmed", "Sk Miraj", ""], ["Raychaudhuri", "Dripta S.", ""], ["Paul", "Sujoy", ""], ["Oymak", "Samet", ""], ["Roy-Chowdhury", "Amit K.", ""]]}, {"id": "2104.01848", "submitter": "Alan JiaXiang Guo", "authors": "Alan J.X. Guo, Qing-Hu Hou, Ou Wu", "title": "Improving the Expressive Power of Graph Neural Network with Tinhofer\n  Algorithm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, Graph Neural Network (GNN) has bloomly progressed for its\npower in processing graph-based data. Most GNNs follow a message passing\nscheme, and their expressive power is mathematically limited by the\ndiscriminative ability of the Weisfeiler-Lehman (WL) test. Following Tinhofer's\nresearch on compact graphs, we propose a variation of the message passing\nscheme, called the Weisfeiler-Lehman-Tinhofer GNN (WLT-GNN), that theoretically\nbreaks through the limitation of the WL test. In addition, we conduct\ncomparative experiments and ablation studies on several well-known datasets.\nThe results show that the proposed methods have comparable performances and\nbetter expressive power on these datasets.\n", "versions": [{"version": "v1", "created": "Mon, 5 Apr 2021 10:54:22 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Guo", "Alan J. X.", ""], ["Hou", "Qing-Hu", ""], ["Wu", "Ou", ""]]}, {"id": "2104.01853", "submitter": "Sho Takase", "authors": "Sho Takase and Shun Kiyono", "title": "Rethinking Perturbations in Encoder-Decoders for Fast Training", "comments": "Accepted at NAACL-HLT 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We often use perturbations to regularize neural models. For neural\nencoder-decoders, previous studies applied the scheduled sampling (Bengio et\nal., 2015) and adversarial perturbations (Sato et al., 2019) as perturbations\nbut these methods require considerable computational time. Thus, this study\naddresses the question of whether these approaches are efficient enough for\ntraining time. We compare several perturbations in sequence-to-sequence\nproblems with respect to computational time. Experimental results show that the\nsimple techniques such as word dropout (Gal and Ghahramani, 2016) and random\nreplacement of input tokens achieve comparable (or better) scores to the\nrecently proposed perturbations, even though these simple methods are faster.\nOur code is publicly available at\nhttps://github.com/takase/rethink_perturbations.\n", "versions": [{"version": "v1", "created": "Mon, 5 Apr 2021 11:06:54 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Takase", "Sho", ""], ["Kiyono", "Shun", ""]]}, {"id": "2104.01864", "submitter": "Rakshit Naidu", "authors": "Aman Priyanshu, Rakshit Naidu", "title": "FedPandemic: A Cross-Device Federated Learning Approach Towards\n  Elementary Prognosis of Diseases During a Pandemic", "comments": "4+10 pages. To be presented at the DPML and MLPCP workshops at\n  ICLR'21", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The amount of data, manpower and capital required to understand, evaluate and\nagree on a group of symptoms for the elementary prognosis of pandemic diseases\nis enormous. In this paper, we present FedPandemic, a novel noise\nimplementation algorithm integrated with cross-device Federated learning for\nElementary symptom prognosis during a pandemic, taking COVID-19 as a case\nstudy. Our results display consistency and enhance robustness in recovering the\ncommon symptoms displayed by the disease, paving a faster and cheaper path\ntowards symptom retrieval while also preserving the privacy of patient's\nsymptoms via Federated learning.\n", "versions": [{"version": "v1", "created": "Mon, 5 Apr 2021 12:01:18 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Priyanshu", "Aman", ""], ["Naidu", "Rakshit", ""]]}, {"id": "2104.01874", "submitter": "Jason Bramburger", "authors": "Jason J. Bramburger, Steven L. Brunton, J. Nathan Kutz", "title": "Deep Learning of Conjugate Mappings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite many of the most common chaotic dynamical systems being continuous in\ntime, it is through discrete time mappings that much of the understanding of\nchaos is formed. Henri Poincar\\'e first made this connection by tracking\nconsecutive iterations of the continuous flow with a lower-dimensional,\ntransverse subspace. The mapping that iterates the dynamics through consecutive\nintersections of the flow with the subspace is now referred to as a Poincar\\'e\nmap, and it is the primary method available for interpreting and classifying\nchaotic dynamics. Unfortunately, in all but the simplest systems, an explicit\nform for such a mapping remains outstanding. This work proposes a method for\nobtaining explicit Poincar\\'e mappings by using deep learning to construct an\ninvertible coordinate transformation into a conjugate representation where the\ndynamics are governed by a relatively simple chaotic mapping. The invertible\nchange of variable is based on an autoencoder, which allows for dimensionality\nreduction, and has the advantage of classifying chaotic systems using the\nequivalence relation of topological conjugacies. Indeed, the enforcement of\ntopological conjugacies is the critical neural network regularization for\nlearning the coordinate and dynamics pairing. We provide expository\napplications of the method to low-dimensional systems such as the R\\\"ossler and\nLorenz systems, while also demonstrating the utility of the method on\ninfinite-dimensional systems, such as the Kuramoto--Sivashinsky equation.\n", "versions": [{"version": "v1", "created": "Thu, 1 Apr 2021 16:29:41 GMT"}, {"version": "v2", "created": "Tue, 13 Jul 2021 17:04:53 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Bramburger", "Jason J.", ""], ["Brunton", "Steven L.", ""], ["Kutz", "J. Nathan", ""]]}, {"id": "2104.01885", "submitter": "Vladimir Vovk", "authors": "Vladimir Vovk", "title": "Conformal testing in a binary model situation", "comments": "8 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conformal testing is a way of testing the IID assumption based on conformal\nprediction. The topic of this note is computational evaluation of the\nperformance of conformal testing in a model situation in which IID binary\nobservations generated from a Bernoulli distribution are followed by IID binary\nobservations generated from another Bernoulli distribution, with the parameters\nof the distributions and changepoint unknown. Existing conformal test\nmartingales can be used for this task and work well in simple cases, but their\nefficiency can be improved greatly.\n", "versions": [{"version": "v1", "created": "Mon, 5 Apr 2021 12:51:39 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Vovk", "Vladimir", ""]]}, {"id": "2104.01894", "submitter": "Ramon Sanabria", "authors": "Ramon Sanabria, Austin Waters, Jason Baldridge", "title": "Talk, Don't Write: A Study of Direct Speech-Based Image Retrieval", "comments": "Accepted to INTERSPEECH 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CV cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Speech-based image retrieval has been studied as a proxy for joint\nrepresentation learning, usually without emphasis on retrieval itself. As such,\nit is unclear how well speech-based retrieval can work in practice -- both in\nan absolute sense and versus alternative strategies that combine automatic\nspeech recognition (ASR) with strong text encoders. In this work, we\nextensively study and expand choices of encoder architectures, training\nmethodology (including unimodal and multimodal pretraining), and other factors.\nOur experiments cover different types of speech in three datasets: Flickr\nAudio, Places Audio, and Localized Narratives. Our best model configuration\nachieves large gains over state of the art, e.g., pushing recall-at-one from\n21.8% to 33.2% for Flickr Audio and 27.6% to 53.4% for Places Audio. We also\nshow our best speech-based models can match or exceed cascaded ASR-to-text\nencoding when speech is spontaneous, accented, or otherwise hard to\nautomatically transcribe.\n", "versions": [{"version": "v1", "created": "Mon, 5 Apr 2021 13:11:40 GMT"}, {"version": "v2", "created": "Thu, 8 Apr 2021 10:16:17 GMT"}, {"version": "v3", "created": "Tue, 15 Jun 2021 17:03:38 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Sanabria", "Ramon", ""], ["Waters", "Austin", ""], ["Baldridge", "Jason", ""]]}, {"id": "2104.01896", "submitter": "Cheng Xue", "authors": "Cheng Xue, Lei Zhu, Huazhu Fu, Xiaowei Hu, Xiaomeng Li, Hai Zhang,\n  Pheng Ann Heng", "title": "Global Guidance Network for Breast Lesion Segmentation in Ultrasound\n  Images", "comments": "16page,10 figures. Accepted by medical image analysis", "journal-ref": null, "doi": "10.1016/j.media.2021.101989", "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Automatic breast lesion segmentation in ultrasound helps to diagnose breast\ncancer, which is one of the dreadful diseases that affect women globally.\nSegmenting breast regions accurately from ultrasound image is a challenging\ntask due to the inherent speckle artifacts, blurry breast lesion boundaries,\nand inhomogeneous intensity distributions inside the breast lesion regions.\nRecently, convolutional neural networks (CNNs) have demonstrated remarkable\nresults in medical image segmentation tasks. However, the convolutional\noperations in a CNN often focus on local regions, which suffer from limited\ncapabilities in capturing long-range dependencies of the input ultrasound\nimage, resulting in degraded breast lesion segmentation accuracy. In this\npaper, we develop a deep convolutional neural network equipped with a global\nguidance block (GGB) and breast lesion boundary detection (BD) modules for\nboosting the breast ultrasound lesion segmentation. The GGB utilizes the\nmulti-layer integrated feature map as a guidance information to learn the\nlong-range non-local dependencies from both spatial and channel domains. The BD\nmodules learn additional breast lesion boundary map to enhance the boundary\nquality of a segmentation result refinement. Experimental results on a public\ndataset and a collected dataset show that our network outperforms other medical\nimage segmentation methods and the recent semantic segmentation methods on\nbreast ultrasound lesion segmentation. Moreover, we also show the application\nof our network on the ultrasound prostate segmentation, in which our method\nbetter identifies prostate regions than state-of-the-art networks.\n", "versions": [{"version": "v1", "created": "Mon, 5 Apr 2021 13:15:22 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Xue", "Cheng", ""], ["Zhu", "Lei", ""], ["Fu", "Huazhu", ""], ["Hu", "Xiaowei", ""], ["Li", "Xiaomeng", ""], ["Zhang", "Hai", ""], ["Heng", "Pheng Ann", ""]]}, {"id": "2104.01914", "submitter": "Thomas Brown", "authors": "Thomas S. Brown, Harbir Antil, Rainald L\\\"ohner, Fumiya Togashi,\n  Deepanshu Verma", "title": "Novel DNNs for Stiff ODEs with Applications to Chemically Reacting Flows", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Chemically reacting flows are common in engineering, such as hypersonic flow,\ncombustion, explosions, manufacturing processes and environmental assessments.\nFor combustion, the number of reactions can be significant (over 100) and due\nto the very large CPU requirements of chemical reactions (over 99%) a large\nnumber of flow and combustion problems are presently beyond the capabilities of\neven the largest supercomputers. Motivated by this, novel Deep Neural Networks\n(DNNs) are introduced to approximate stiff ODEs. Two approaches are compared,\ni.e., either learn the solution or the derivative of the solution to these\nODEs. These DNNs are applied to multiple species and reactions common in\nchemically reacting flows. Experimental results show that it is helpful to\naccount for the physical properties of species while designing DNNs. The\nproposed approach is shown to generalize well.\n", "versions": [{"version": "v1", "created": "Thu, 1 Apr 2021 22:54:22 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Brown", "Thomas S.", ""], ["Antil", "Harbir", ""], ["L\u00f6hner", "Rainald", ""], ["Togashi", "Fumiya", ""], ["Verma", "Deepanshu", ""]]}, {"id": "2104.01924", "submitter": "Ling Chen", "authors": "Ling Chen, Hongyu Shi", "title": "DexDeepFM: Ensemble Diversity Enhanced Extreme Deep Factorization\n  Machine Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predicting user positive response (e.g., purchases and clicks) probability is\na critical task in Web applications. To identify predictive features from raw\ndata, the state-of-the-art extreme deep factorization machine (xDeepFM) model\nintroduces a compressed interaction network (CIN) to leverage feature\ninteractions at the vector-wise level explicitly. However, since each hidden\nlayer in CIN is a collection of feature maps, it can be viewed essentially as\nan ensemble of different feature maps. In this case, only using a single\nobjective to minimize the prediction loss may lead to overfitting. In this\npaper, an ensemble diversity enhanced extreme deep factorization machine model\n(DexDeepFM) is proposed, which introduces the ensemble diversity measure in CIN\nand considers both ensemble diversity and prediction accuracy in the objective\nfunction. In addition, the attention mechanism is introduced to discriminate\nthe importance of ensemble diversity measures with different feature\ninteraction orders. Extensive experiments on two public real-world datasets\nshow the superiority of the proposed model.\n", "versions": [{"version": "v1", "created": "Mon, 5 Apr 2021 14:06:32 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Chen", "Ling", ""], ["Shi", "Hongyu", ""]]}, {"id": "2104.01926", "submitter": "Wei Tang", "authors": "Wei Tang, Chien-Ju Ho, Yang Liu", "title": "Optimal Query Complexity of Secure Stochastic Convex Optimization", "comments": "add more discussions about adversary definition", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the secure stochastic convex optimization problem. A learner aims to\nlearn the optimal point of a convex function through sequentially querying a\n(stochastic) gradient oracle. In the meantime, there exists an adversary who\naims to free-ride and infer the learning outcome of the learner from observing\nthe learner's queries. The adversary observes only the points of the queries\nbut not the feedback from the oracle. The goal of the learner is to optimize\nthe accuracy, i.e., obtaining an accurate estimate of the optimal point, while\nsecuring her privacy, i.e., making it difficult for the adversary to infer the\noptimal point. We formally quantify this tradeoff between learner's accuracy\nand privacy and characterize the lower and upper bounds on the learner's query\ncomplexity as a function of desired levels of accuracy and privacy. For the\nanalysis of lower bounds, we provide a general template based on information\ntheoretical analysis and then tailor the template to several families of\nproblems, including stochastic convex optimization and (noisy) binary search.\nWe also present a generic secure learning protocol that achieves the matching\nupper bound up to logarithmic factors.\n", "versions": [{"version": "v1", "created": "Mon, 5 Apr 2021 14:10:26 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Tang", "Wei", ""], ["Ho", "Chien-Ju", ""], ["Liu", "Yang", ""]]}, {"id": "2104.01945", "submitter": "Terrence Alsup", "authors": "Terrence Alsup and Luca Venturi and Benjamin Peherstorfer", "title": "Multilevel Stein variational gradient descent with applications to\n  Bayesian inverse problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.LG cs.NA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This work presents a multilevel variant of Stein variational gradient descent\nto more efficiently sample from target distributions. The key ingredient is a\nsequence of distributions with growing fidelity and costs that converges to the\ntarget distribution of interest. For example, such a sequence of distributions\nis given by a hierarchy of ever finer discretization levels of the forward\nmodel in Bayesian inverse problems. The proposed multilevel Stein variational\ngradient descent moves most of the iterations to lower, cheaper levels with the\naim of requiring only a few iterations on the higher, more expensive levels\nwhen compared to the traditional, single-level Stein variational gradient\ndescent variant that uses the highest-level distribution only. Under certain\nassumptions, in the mean-field limit, the error of the proposed multilevel\nStein method decays by a log factor faster than the error of the single-level\ncounterpart with respect to computational costs. Numerical experiments with\nBayesian inverse problems show speedups of more than one order of magnitude of\nthe proposed multilevel Stein method compared to the single-level variant that\nuses the highest level only.\n", "versions": [{"version": "v1", "created": "Mon, 5 Apr 2021 15:07:16 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Alsup", "Terrence", ""], ["Venturi", "Luca", ""], ["Peherstorfer", "Benjamin", ""]]}, {"id": "2104.01946", "submitter": "Ke Liang", "authors": "Ke Liang and Mitchel Myers", "title": "Machine Learning Applications in the Routing in Computer Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Development of routing algorithms is of clear importance as the volume of\nInternet traffic continues to increase. In this survey, there is much research\ninto how Machine Learning techniques can be employed to improve the performance\nand scalability of routing algorithms. We surveyed both centralized and\ndecentralized ML routing architectures and using a variety of ML techniques\nbroadly divided into supervised learning and reinforcement learning. Many of\nthe papers showed promise in their ability to optimize some aspect of network\nrouting. We also implemented two routing protocols within 14 surveyed routing\nalgorithms and verified the efficacy of their results. While the results of\nmost of the papers showed promise, many of them are based on simulations of\npotentially unrealistic network configurations. To provide further efficacy to\nthe results, more real-world results are necessary.\n", "versions": [{"version": "v1", "created": "Mon, 5 Apr 2021 15:08:35 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Liang", "Ke", ""], ["Myers", "Mitchel", ""]]}, {"id": "2104.01963", "submitter": "Lama Alsulaiman", "authors": "Lama Alsulaiman and Saad Al-Ahmadi", "title": "Performance Evaluation of Machine Learning Techniques for DoS Detection\n  in Wireless Sensor Network", "comments": null, "journal-ref": "International Journal of Network Security & Its Applications\n  (IJNSA) Vol.13, No.2, March 2021", "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The nature of Wireless Sensor Networks (WSN) and the widespread of using WSN\nintroduce many security threats and attacks. An effective Intrusion Detection\nSystem (IDS) should be used to detect attacks. Detecting such an attack is\nchallenging, especially the detection of Denial of Service (DoS) attacks.\nMachine learning classification techniques have been used as an approach for\nDoS detection. This paper conducted an experiment using Waikato Environment for\nKnowledge Analysis (WEKA)to evaluate the efficiency of five machine learning\nalgorithms for detecting flooding, grayhole, blackhole, and scheduling at DoS\nattacks in WSNs. The evaluation is based on a dataset, called WSN-DS. The\nresults showed that the random forest classifier outperforms the other\nclassifiers with an accuracy of 99.72%.\n", "versions": [{"version": "v1", "created": "Mon, 5 Apr 2021 15:31:27 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Alsulaiman", "Lama", ""], ["Al-Ahmadi", "Saad", ""]]}, {"id": "2104.01981", "submitter": "Jack Kosaian", "authors": "Kaige Liu, Jack Kosaian, K. V. Rashmi", "title": "ECRM: Efficient Fault Tolerance for Recommendation Model Training via\n  Erasure Coding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep-learning-based recommendation models (DLRMs) are widely deployed to\nserve personalized content to users. DLRMs are large in size due to their use\nof large embedding tables, and are trained by distributing the model across the\nmemory of tens or hundreds of servers. Server failures are common in such large\ndistributed systems and must be mitigated to enable training to progress.\nCheckpointing is the primary approach used for fault tolerance in these\nsystems, but incurs significant training-time overhead both during normal\noperation and when recovering from failures. As these overheads increase with\nDLRM size, checkpointing is slated to become an even larger overhead for future\nDLRMs, which are expected to grow in size. This calls for rethinking fault\ntolerance in DLRM training.\n  We present ECRM, a DLRM training system that achieves efficient fault\ntolerance using erasure coding. ECRM chooses which DLRM parameters to encode,\ncorrectly and efficiently updates parities, and enables training to proceed\nwithout any pauses, while maintaining consistency of the recovered parameters.\nWe implement ECRM atop XDL, an open-source, industrial-scale DLRM training\nsystem. Compared to checkpointing, ECRM reduces training-time overhead for\nlarge DLRMs by up to 88%, recovers from failures up to 10.3$\\times$ faster, and\nallows training to proceed during recovery. These results show the promise of\nerasure coding in imparting efficient fault tolerance to training current and\nfuture DLRMs.\n", "versions": [{"version": "v1", "created": "Mon, 5 Apr 2021 16:16:19 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Liu", "Kaige", ""], ["Kosaian", "Jack", ""], ["Rashmi", "K. V.", ""]]}, {"id": "2104.01987", "submitter": "Weijie J. Su", "authors": "Jinshuo Dong, Aaron Roth, Weijie J. Su", "title": "Rejoinder: Gaussian Differential Privacy", "comments": "Updated the references. Rejoinder to discussions on Gaussian\n  Differential Privacy, read to the Royal Statistical Society in December 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG math.ST stat.ML stat.TH", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this rejoinder, we aim to address two broad issues that cover most\ncomments made in the discussion. First, we discuss some theoretical aspects of\nour work and comment on how this work might impact the theoretical foundation\nof privacy-preserving data analysis. Taking a practical viewpoint, we next\ndiscuss how f-differential privacy (f-DP) and Gaussian differential privacy\n(GDP) can make a difference in a range of applications.\n", "versions": [{"version": "v1", "created": "Mon, 5 Apr 2021 16:27:56 GMT"}, {"version": "v2", "created": "Sat, 26 Jun 2021 02:40:17 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Dong", "Jinshuo", ""], ["Roth", "Aaron", ""], ["Su", "Weijie J.", ""]]}, {"id": "2104.01989", "submitter": "Jason Pelecanos", "authors": "Jason Pelecanos and Quan Wang and Ignacio Lopez Moreno", "title": "Dr-Vectors: Decision Residual Networks and an Improved Loss for Speaker\n  Recognition", "comments": "To appear in Interspeech 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many neural network speaker recognition systems model each speaker using a\nfixed-dimensional embedding vector. These embeddings are generally compared\nusing either linear or 2nd-order scoring and, until recently, do not handle\nutterance-specific uncertainty. In this work we propose scoring these\nrepresentations in a way that can capture uncertainty, enroll/test asymmetry\nand additional non-linear information. This is achieved by incorporating a\n2nd-stage neural network (known as a decision network) as part of an end-to-end\ntraining regimen. In particular, we propose the concept of decision residual\nnetworks which involves the use of a compact decision network to leverage\ncosine scores and to model the residual signal that's needed. Additionally, we\npresent a modification to the generalized end-to-end softmax loss function to\ntarget the separation of same/different speaker scores. We observed significant\nperformance gains for the two techniques.\n", "versions": [{"version": "v1", "created": "Mon, 5 Apr 2021 16:31:04 GMT"}, {"version": "v2", "created": "Wed, 16 Jun 2021 15:41:38 GMT"}], "update_date": "2021-06-18", "authors_parsed": [["Pelecanos", "Jason", ""], ["Wang", "Quan", ""], ["Moreno", "Ignacio Lopez", ""]]}, {"id": "2104.01992", "submitter": "Utkarsh Azad", "authors": "Animesh Sinha, Utkarsh Azad and Harjinder Singh", "title": "Qubit Routing using Graph Neural Network aided Monte Carlo Tree Search", "comments": "10 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Near-term quantum hardware can support two-qubit operations only on the\nqubits that can interact with each other. Therefore, to execute an arbitrary\nquantum circuit on the hardware, compilers have to first perform the task of\nqubit routing, i.e., to transform the quantum circuit either by inserting\nadditional SWAP gates or by reversing existing CNOT gates to satisfy the\nconnectivity constraints of the target topology. We propose a procedure for\nqubit routing that is architecture agnostic and that outperforms other\navailable routing implementations on various circuit benchmarks. The depth of\nthe transformed quantum circuits is minimised by utilizing the Monte Carlo tree\nsearch to perform qubit routing, aided by a Graph neural network that evaluates\nthe value function and action probabilities for each state.\n", "versions": [{"version": "v1", "created": "Thu, 1 Apr 2021 17:08:28 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Sinha", "Animesh", ""], ["Azad", "Utkarsh", ""], ["Singh", "Harjinder", ""]]}, {"id": "2104.01996", "submitter": "Rishikesh Ranade", "authors": "Rishikesh Ranade, Kevin Gitushi, Tarek Echekki", "title": "Generalized Joint Probability Density Function Formulation inTurbulent\n  Combustion using DeepONet", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.flu-dyn cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Joint probability density function (PDF)-based models in turbulent combustion\nprovide direct closure for turbulence-chemistry interactions. The joint PDFs\ncapture the turbulent flame dynamics at different spatial locations and hence\nit is crucial to represent them accurately. The jointPDFs are parameterized on\nthe unconditional means of thermo-chemical state variables, which can be high\ndimensional. Thus, accurate construction of joint PDFs at various spatial\nlocations may require an exorbitant amount of data. In a previous work, we\nintroduced a framework that alleviated data requirements by constructing joint\nPDFs in a lower dimensional space using principal component analysis (PCA) in\nconjunction with Kernel Density Estimation (KDE). However, constructing the\nprincipal component (PC) joint PDFs is still computationally expensive as they\nare required to be calculated at each spatial location in the turbulent flame.\nIn this work, we propose the concept of a generalized joint PDF model using the\nDeep Operator Network (DeepONet). The DeepONet is a machine learning model that\nis parameterized on the unconditional means of PCs at a given spatial location\nand discrete PC coordinates and predicts the joint probability density value\nfor the corresponding PC coordinate. We demonstrate the accuracy and\ngeneralizability of the DeepONet on the Sandia flames, D, E and F. The DeepONet\nis trained based on the PC joint PDFs observed inflame E and yields excellent\npredictions of joint PDFs shapes at different spatial locations of flamesD and\nF, which are not seen during training\n", "versions": [{"version": "v1", "created": "Mon, 5 Apr 2021 16:40:56 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Ranade", "Rishikesh", ""], ["Gitushi", "Kevin", ""], ["Echekki", "Tarek", ""]]}, {"id": "2104.02005", "submitter": "Tong Xia", "authors": "Tong Xia, Jing Han, Lorena Qendro, Ting Dang, Cecilia Mascolo", "title": "Uncertainty-Aware COVID-19 Detection from Imbalanced Sound Data", "comments": "Accepted by INTERSPEECH 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, sound-based COVID-19 detection studies have shown great promise to\nachieve scalable and prompt digital pre-screening. However, there are still two\nunsolved issues hindering the practice. First, collected datasets for model\ntraining are often imbalanced, with a considerably smaller proportion of users\ntested positive, making it harder to learn representative and robust features.\nSecond, deep learning models are generally overconfident in their predictions.\nClinically, false predictions aggravate healthcare costs. Estimation of the\nuncertainty of screening would aid this. To handle these issues, we propose an\nensemble framework where multiple deep learning models for sound-based COVID-19\ndetection are developed from different but balanced subsets from original data.\nAs such, data are utilized more effectively compared to traditional up-sampling\nand down-sampling approaches: an AUC of 0.74 with a sensitivity of 0.68 and a\nspecificity of 0.69 is achieved. Simultaneously, we estimate uncertainty from\nthe disagreement across multiple models. It is shown that false predictions\noften yield higher uncertainty, enabling us to suggest the users with certainty\nhigher than a threshold to repeat the audio test on their phones or to take\nclinical tests if digital diagnosis still fails. This study paves the way for a\nmore robust sound-based COVID-19 automated screening system.\n", "versions": [{"version": "v1", "created": "Mon, 5 Apr 2021 16:54:03 GMT"}, {"version": "v2", "created": "Fri, 18 Jun 2021 21:10:52 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Xia", "Tong", ""], ["Han", "Jing", ""], ["Qendro", "Lorena", ""], ["Dang", "Ting", ""], ["Mascolo", "Cecilia", ""]]}, {"id": "2104.02008", "submitter": "Kaiyang Zhou", "authors": "Kaiyang Zhou and Yongxin Yang and Yu Qiao and Tao Xiang", "title": "Domain Generalization with MixStyle", "comments": "ICLR 2021; Code is available at\n  https://github.com/KaiyangZhou/mixstyle-release", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Though convolutional neural networks (CNNs) have demonstrated remarkable\nability in learning discriminative features, they often generalize poorly to\nunseen domains. Domain generalization aims to address this problem by learning\nfrom a set of source domains a model that is generalizable to any unseen\ndomain. In this paper, a novel approach is proposed based on probabilistically\nmixing instance-level feature statistics of training samples across source\ndomains. Our method, termed MixStyle, is motivated by the observation that\nvisual domain is closely related to image style (e.g., photo vs.~sketch\nimages). Such style information is captured by the bottom layers of a CNN where\nour proposed style-mixing takes place. Mixing styles of training instances\nresults in novel domains being synthesized implicitly, which increase the\ndomain diversity of the source domains, and hence the generalizability of the\ntrained model. MixStyle fits into mini-batch training perfectly and is\nextremely easy to implement. The effectiveness of MixStyle is demonstrated on a\nwide range of tasks including category classification, instance retrieval and\nreinforcement learning.\n", "versions": [{"version": "v1", "created": "Mon, 5 Apr 2021 16:58:09 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Zhou", "Kaiyang", ""], ["Yang", "Yongxin", ""], ["Qiao", "Yu", ""], ["Xiang", "Tao", ""]]}, {"id": "2104.02013", "submitter": "Samir Chowdhury", "authors": "Samir Chowdhury, David Miller, Tom Needham", "title": "Quantized Gromov-Wasserstein", "comments": "Small updates made to clarify related literature", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Gromov-Wasserstein (GW) framework adapts ideas from optimal transport to\nallow for the comparison of probability distributions defined on different\nmetric spaces. Scalable computation of GW distances and associated matchings on\ngraphs and point clouds have recently been made possible by state-of-the-art\nalgorithms such as S-GWL and MREC. Each of these algorithmic breakthroughs\nrelies on decomposing the underlying spaces into parts and performing matchings\non these parts, adding recursion as needed. While very successful in practice,\ntheoretical guarantees on such methods are limited. Inspired by recent advances\nin the theory of quantization for metric measure spaces, we define Quantized\nGromov Wasserstein (qGW): a metric that treats parts as fundamental objects and\nfits into a hierarchy of theoretical upper bounds for the GW problem. This\nformulation motivates a new algorithm for approximating optimal GW matchings\nwhich yields algorithmic speedups and reductions in memory complexity.\nConsequently, we are able to go beyond outperforming state-of-the-art and apply\nGW matching at scales that are an order of magnitude larger than in the\nexisting literature, including datasets containing over 1M points.\n", "versions": [{"version": "v1", "created": "Mon, 5 Apr 2021 17:03:20 GMT"}, {"version": "v2", "created": "Tue, 4 May 2021 09:51:50 GMT"}], "update_date": "2021-05-05", "authors_parsed": [["Chowdhury", "Samir", ""], ["Miller", "David", ""], ["Needham", "Tom", ""]]}, {"id": "2104.02017", "submitter": "Aswin Sivaraman", "authors": "Aswin Sivaraman, Minje Kim", "title": "Self-Supervised Learning for Personalized Speech Enhancement", "comments": "10 pages, 5 figures, under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Speech enhancement systems can show improved performance by adapting the\nmodel towards a single test-time speaker. In this personalization context, the\ntest-time user might only provide a small amount of noise-free speech data,\nlikely insufficient for traditional fully-supervised learning. One way to\novercome the lack of personal data is to transfer the model parameters from a\nspeaker-agnostic model to initialize the personalized model, and then to\nfinetune the model using the small amount of personal speech data. This\nbaseline marginally adapts over the scarce clean speech data. Alternatively, we\npropose self-supervised methods that are designed specifically to learn\npersonalized and discriminative features from abundant in-the-wild noisy, but\nstill personal speech recordings. Our experiment shows that the proposed\nself-supervised learning methods initialize personalized speech enhancement\nmodels better than the baseline fully-supervised methods, yielding superior\nspeech enhancement performance. The proposed methods also result in a more\nrobust feature set under the real-world conditions: compressed model sizes and\nfewness of the labeled data.\n", "versions": [{"version": "v1", "created": "Mon, 5 Apr 2021 17:12:51 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Sivaraman", "Aswin", ""], ["Kim", "Minje", ""]]}, {"id": "2104.02018", "submitter": "Aswin Sivaraman", "authors": "Aswin Sivaraman, Sunwoo Kim, Minje Kim", "title": "Personalized Speech Enhancement through Self-Supervised Data\n  Augmentation and Purification", "comments": "5 pages, 3 figures, under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Training personalized speech enhancement models is innately a no-shot\nlearning problem due to privacy constraints and limited access to noise-free\nspeech from the target user. If there is an abundance of unlabeled noisy speech\nfrom the test-time user, a personalized speech enhancement model can be trained\nusing self-supervised learning. One straightforward approach to model\npersonalization is to use the target speaker's noisy recordings as\npseudo-sources. Then, a pseudo denoising model learns to remove injected\ntraining noises and recover the pseudo-sources. However, this approach is\nvolatile as it depends on the quality of the pseudo-sources, which may be too\nnoisy. As a remedy, we propose an improvement to the self-supervised approach\nthrough data purification. We first train an SNR predictor model to estimate\nthe frame-by-frame SNR of the pseudo-sources. Then, the predictor's estimates\nare converted into weights which adjust the frame-by-frame contribution of the\npseudo-sources towards training the personalized model. We empirically show\nthat the proposed data purification step improves the usability of the\nspeaker-specific noisy data in the context of personalized speech enhancement.\nWithout relying on any clean speech recordings or speaker embeddings, our\napproach may be seen as privacy-preserving.\n", "versions": [{"version": "v1", "created": "Mon, 5 Apr 2021 17:17:55 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Sivaraman", "Aswin", ""], ["Kim", "Sunwoo", ""], ["Kim", "Minje", ""]]}, {"id": "2104.02032", "submitter": "Kolawole Ogunsina", "authors": "Kolawole Ogunsina and Wendy A. Okolo", "title": "Artificial Neural Network Modeling for Airline Disruption Management", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Since the 1970s, most airlines have incorporated computerized support for\nmanaging disruptions during flight schedule execution. However, existing\nplatforms for airline disruption management (ADM) employ monolithic system\ndesign methods that rely on the creation of specific rules and requirements\nthrough explicit optimization routines, before a system that meets the\nspecifications is designed. Thus, current platforms for ADM are unable to\nreadily accommodate additional system complexities resulting from the\nintroduction of new capabilities, such as the introduction of unmanned aerial\nsystems (UAS), operations and infrastructure, to the system. To this end, we\nuse historical data on airline scheduling and operations recovery to develop a\nsystem of artificial neural networks (ANNs), which describe a predictive\ntransfer function model (PTFM) for promptly estimating the recovery impact of\ndisruption resolutions at separate phases of flight schedule execution during\nADM. Furthermore, we provide a modular approach for assessing and executing the\nPTFM by employing a parallel ensemble method to develop generative routines\nthat amalgamate the system of ANNs. Our modular approach ensures that current\nindustry standards for tardiness in flight schedule execution during ADM are\nsatisfied, while accurately estimating appropriate time-based performance\nmetrics for the separate phases of flight schedule execution.\n", "versions": [{"version": "v1", "created": "Mon, 5 Apr 2021 17:37:24 GMT"}, {"version": "v2", "created": "Mon, 3 May 2021 13:24:05 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Ogunsina", "Kolawole", ""], ["Okolo", "Wendy A.", ""]]}, {"id": "2104.02040", "submitter": "Ekaterina Trofimova", "authors": "Vladislav Belavin, Ekaterina Trofimova, Andrey Ustyuzhanin", "title": "Segmentation of EM showers for neutrino experiments with deep graph\n  neural networks", "comments": "14 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG hep-ex", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We introduce a novel method for showers reconstruction from the data\ncollected with electromagnetic (EM) sampling calorimeters. Such detectors are\nwidely used in High Energy Physics to measure the energy and kinematics of\nin-going particles. In this work, we consider the case when a large number of\nparticles pass through an Emulsion Cloud Chamber (ECC) brick, generating\nelectromagnetic showers. This situation can be observed with long exposure\ntimes or large input particle flux. For example, SHiP experiment is planning to\nuse emulsion detectors for dark matter search and neutrino physics\ninvestigation. The expected full flux of SHiP experiment is about $10^{20}$\nparticles over five years. Because of the high amount of in-going particles, we\nwill observe a lot of overlapping showers. It makes EM showers reconstruction a\nchallenging segmentation problem. Our reconstruction pipeline consists of a\nGraph Neural Network that predicts an adjacency matrix for the clustering\nalgorithm. To improve Graph Neural Network's performance, we propose a new\nlayer type (EmulsionConv) that takes into account geometrical properties of\nshower development in ECC brick. For the clustering of overlapping showers, we\nuse a modified hierarchical density-based clustering algorithm. Our method does\nnot use any prior information about the incoming particles and identifies up to\n82% of electromagnetic showers in emulsion detectors. The mean energy\nresolution over $17,715$ showers is 27%. The main test bench for the algorithm\nfor reconstructing electromagnetic showers is going to be SND@LHC.\n", "versions": [{"version": "v1", "created": "Mon, 5 Apr 2021 17:45:21 GMT"}, {"version": "v2", "created": "Tue, 6 Apr 2021 10:12:29 GMT"}, {"version": "v3", "created": "Mon, 12 Apr 2021 21:38:40 GMT"}, {"version": "v4", "created": "Fri, 16 Apr 2021 13:35:26 GMT"}], "update_date": "2021-04-19", "authors_parsed": [["Belavin", "Vladislav", ""], ["Trofimova", "Ekaterina", ""], ["Ustyuzhanin", "Andrey", ""]]}, {"id": "2104.02052", "submitter": "Utkarsh Ojha", "authors": "Utkarsh Ojha, Krishna Kumar Singh, Yong Jae Lee", "title": "Generating Furry Cars: Disentangling Object Shape & Appearance across\n  Multiple Domains", "comments": "Camera ready version for ICLR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.GR cs.LG", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  We consider the novel task of learning disentangled representations of object\nshape and appearance across multiple domains (e.g., dogs and cars). The goal is\nto learn a generative model that learns an intermediate distribution, which\nborrows a subset of properties from each domain, enabling the generation of\nimages that did not exist in any domain exclusively. This challenging problem\nrequires an accurate disentanglement of object shape, appearance, and\nbackground from each domain, so that the appearance and shape factors from the\ntwo domains can be interchanged. We augment an existing approach that can\ndisentangle factors within a single domain but struggles to do so across\ndomains. Our key technical contribution is to represent object appearance with\na differentiable histogram of visual features, and to optimize the generator so\nthat two images with the same latent appearance factor but different latent\nshape factors produce similar histograms. On multiple multi-domain datasets, we\ndemonstrate our method leads to accurate and consistent appearance and shape\ntransfer across domains.\n", "versions": [{"version": "v1", "created": "Mon, 5 Apr 2021 17:59:15 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Ojha", "Utkarsh", ""], ["Singh", "Krishna Kumar", ""], ["Lee", "Yong Jae", ""]]}, {"id": "2104.02054", "submitter": "Girmaw Abebe Tadesse", "authors": "Girmaw Abebe Tadesse, Hamza Javed, Yong Liu, Jin Liu, Jiyan Chen,\n  Komminist Weldemariam, and Tingting Zhu", "title": "DeepMI: Deep Multi-lead ECG Fusion for Identifying Myocardial Infarction\n  and its Occurrence-time", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Myocardial Infarction (MI) has the highest mortality of all cardiovascular\ndiseases (CVDs). Detection of MI and information regarding its occurrence-time\nin particular, would enable timely interventions that may improve patient\noutcomes, thereby reducing the global rise in CVD deaths. Electrocardiogram\n(ECG) recordings are currently used to screen MI patients. However, manual\ninspection of ECGs is time-consuming and prone to subjective bias. Machine\nlearning methods have been adopted for automated ECG diagnosis, but most\napproaches require extraction of ECG beats or consider leads independently of\none another. We propose an end-to-end deep learning approach, DeepMI, to\nclassify MI from normal cases as well as identifying the time-occurrence of MI\n(defined as acute, recent and old), using a collection of fusion strategies on\n12 ECG leads at data-, feature-, and decision-level. In order to minimise\ncomputational overhead, we employ transfer learning using existing computer\nvision networks. Moreover, we use recurrent neural networks to encode the\nlongitudinal information inherent in ECGs. We validated DeepMI on a dataset\ncollected from 17,381 patients, in which over 323,000 samples were extracted\nper ECG lead. We were able to classify normal cases as well as acute, recent\nand old onset cases of MI, with AUROCs of 96.7%, 82.9%, 68.6% and 73.8%,\nrespectively. We have demonstrated a multi-lead fusion approach to detect the\npresence and occurrence-time of MI. Our end-to-end framework provides\nflexibility for different levels of multi-lead ECG fusion and performs feature\nextraction via transfer learning.\n", "versions": [{"version": "v1", "created": "Wed, 31 Mar 2021 19:46:19 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Tadesse", "Girmaw Abebe", ""], ["Javed", "Hamza", ""], ["Liu", "Yong", ""], ["Liu", "Jin", ""], ["Chen", "Jiyan", ""], ["Weldemariam", "Komminist", ""], ["Zhu", "Tingting", ""]]}, {"id": "2104.02055", "submitter": "Tai Le Quy", "authors": "Tai Le Quy, Sergej Zerr, Eirini Ntoutsi and Wolfgang Nejdl", "title": "Data augmentation for dealing with low sampling rates in NILM", "comments": "10 pages, 3 figures, 6 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Data have an important role in evaluating the performance of NILM algorithms.\nThe best performance of NILM algorithms is achieved with high-quality\nevaluation data. However, many existing real-world data sets come with a low\nsampling quality, and often with gaps, lacking data for some recording periods.\nAs a result, in such data, NILM algorithms can hardly recognize devices and\nestimate their power consumption properly. An important step towards improving\nthe performance of these energy disaggregation methods is to improve the\nquality of the data sets. In this paper, we carry out experiments using several\nmethods to increase the sampling rate of low sampling rate data. Our results\nshow that augmentation of low-frequency data can support the considered NILM\nalgorithms in estimating appliances' consumption with a higher F-score\nmeasurement.\n", "versions": [{"version": "v1", "created": "Tue, 30 Mar 2021 22:43:34 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Quy", "Tai Le", ""], ["Zerr", "Sergej", ""], ["Ntoutsi", "Eirini", ""], ["Nejdl", "Wolfgang", ""]]}, {"id": "2104.02056", "submitter": "Yizheng Liao", "authors": "Yizheng Liao, Yang Weng, Chin-woo Tan, Ram Rajagopal", "title": "Quick Line Outage Identification in Urban Distribution Grids via Smart\n  Meters", "comments": "12 pages, 12 figures. arXiv admin note: substantial text overlap with\n  arXiv:1811.05646", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG cs.SY eess.SY stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The growing integration of distributed energy resources (DERs) in\ndistribution grids raises various reliability issues due to DER's uncertain and\ncomplex behaviors. With a large-scale DER penetration in distribution grids,\ntraditional outage detection methods, which rely on customers report and smart\nmeters' last gasp signals, will have poor performance, because the renewable\ngenerators and storages and the mesh structure in urban distribution grids can\ncontinue supplying power after line outages. To address these challenges, we\npropose a data-driven outage monitoring approach based on the stochastic time\nseries analysis with a theoretical guarantee. Specifically, we prove via power\nflow analysis that the dependency of time-series voltage measurements exhibits\nsignificant statistical changes after line outages. This makes the theory on\noptimal change-point detection suitable to identify line outages. However,\nexisting change point detection methods require post-outage voltage\ndistribution, which is unknown in distribution systems. Therefore, we design a\nmaximum likelihood estimator to directly learn the distribution parameters from\nvoltage data. We prove that the estimated parameters-based detection also\nachieves the optimal performance, making it extremely useful for fast\ndistribution grid outage identifications. Furthermore, since smart meters have\nbeen widely installed in distribution grids and advanced infrastructure (e.g.,\nPMU) has not widely been available, our approach only requires voltage\nmagnitude for quick outage identification. Simulation results show highly\naccurate outage identification in eight distribution grids with 14\nconfigurations with and without DERs using smart meter data.\n", "versions": [{"version": "v1", "created": "Thu, 1 Apr 2021 07:10:34 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Liao", "Yizheng", ""], ["Weng", "Yang", ""], ["Tan", "Chin-woo", ""], ["Rajagopal", "Ram", ""]]}, {"id": "2104.02057", "submitter": "Xinlei Chen", "authors": "Xinlei Chen and Saining Xie and Kaiming He", "title": "An Empirical Study of Training Self-Supervised Vision Transformers", "comments": "Technical report, 10 pages. v2: corrected \"Visual Transformer\" to\n  \"Vision Transformer\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper does not describe a novel method. Instead, it studies a\nstraightforward, incremental, yet must-know baseline given the recent progress\nin computer vision: self-supervised learning for Vision Transformers (ViT).\nWhile the training recipes for standard convolutional networks have been highly\nmature and robust, the recipes for ViT are yet to be built, especially in the\nself-supervised scenarios where training becomes more challenging. In this\nwork, we go back to basics and investigate the effects of several fundamental\ncomponents for training self-supervised ViT. We observe that instability is a\nmajor issue that degrades accuracy, and it can be hidden by apparently good\nresults. We reveal that these results are indeed partial failure, and they can\nbe improved when training is made more stable. We benchmark ViT results in MoCo\nv3 and several other self-supervised frameworks, with ablations in various\naspects. We discuss the currently positive evidence as well as challenges and\nopen questions. We hope that this work will provide useful data points and\nexperience for future research.\n", "versions": [{"version": "v1", "created": "Mon, 5 Apr 2021 17:59:40 GMT"}, {"version": "v2", "created": "Thu, 8 Apr 2021 20:16:36 GMT"}, {"version": "v3", "created": "Wed, 5 May 2021 06:35:38 GMT"}], "update_date": "2021-05-06", "authors_parsed": [["Chen", "Xinlei", ""], ["Xie", "Saining", ""], ["He", "Kaiming", ""]]}, {"id": "2104.02058", "submitter": "Mehrad Jaloli", "authors": "Mehrad Jaloli, Divya Choudhary and Marzia Cescon", "title": "Neurological Status Classification Using Convolutional Neural Network", "comments": "6 pages, 4 figures, \\c{opyright} 2020 the authors. This work has been\n  accepted to IFAC for publication under a Creative Commons Licence CC-BY-NC-ND", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG cs.SY eess.SY", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  In this study we show that a Convolutional Neural Network (CNN) model is able\nto accuratelydiscriminate between 4 different phases of neurological status in\na non-Electroencephalogram(EEG) dataset recorded in an experiment in which\nsubjects are exposed to physical, cognitiveand emotional stress. We demonstrate\nthat the proposed model is able to obtain 99.99% AreaUnder the Curve (AUC) of\nReceiver Operation characteristic (ROC) and 99.82% classificationaccuracy on\nthe test dataset. Furthermore, for comparison, we show that our models\noutperformstraditional classification methods such as SVM, and RF. Finally, we\nshow the advantage of CNN models, in comparison to other methods, in robustness\nto noise by 97.46% accuracy on a noisy dataset.\n", "versions": [{"version": "v1", "created": "Thu, 1 Apr 2021 22:40:28 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Jaloli", "Mehrad", ""], ["Choudhary", "Divya", ""], ["Cescon", "Marzia", ""]]}, {"id": "2104.02059", "submitter": "Pranav M Pawar Dr", "authors": "Pranav M. Pawar, Amir Leshem", "title": "Distributed Deep Reinforcement Learning for Collaborative Spectrum\n  Sharing", "comments": "7 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.IT cs.LG math.IT", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Spectrum sharing among users is a fundamental problem in the management of\nany wireless network. In this paper, we discuss the problem of distributed\nspectrum collaboration without central management under general unknown\nchannels. Since the cost of communication, coordination and control is rapidly\nincreasing with the number of devices and the expanding bandwidth used there is\nan obvious need to develop distributed techniques for spectrum collaboration\nwhere no explicit signaling is used. In this paper, we combine game-theoretic\ninsights with deep Q-learning to provide a novel asymptotically optimal\nsolution to the spectrum collaboration problem. We propose a deterministic\ndistributed deep reinforcement learning(D3RL) mechanism using a deep Q-network\n(DQN). It chooses the channels using the Q-values and the channel loads while\nlimiting the options available to the user to a few channels with the highest\nQ-values and among those, it selects the least loaded channel. Using insights\nfrom both game theory and combinatorial optimization we show that this\ntechnique is asymptotically optimal for large overloaded networks. The selected\nchannel and the outcome of the successful transmission are fed back into the\nlearning of the deep Q-network to incorporate it into the learning of the\nQ-values. We also analyzed performance to understand the behavior of D3RL in\ndiffer\n", "versions": [{"version": "v1", "created": "Tue, 6 Apr 2021 04:33:06 GMT"}], "update_date": "2021-04-07", "authors_parsed": [["Pawar", "Pranav M.", ""], ["Leshem", "Amir", ""]]}, {"id": "2104.02060", "submitter": "Jayalakshmi Mangalagiri", "authors": "Jayalakshmi Mangalagiri, David Chapman, Aryya Gangopadhyay, Yaacov\n  Yesha, Joshua Galita, Sumeet Menon, Yelena Yesha, Babak Saboury, Michael\n  Morris, Phuong Nguyen", "title": "Toward Generating Synthetic CT Volumes using a 3D-Conditional Generative\n  Adversarial Network", "comments": "It is a short paper accepted in CSCI 2020 conference and is accepted\n  to publication in the IEEE CPS proceedings", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel conditional Generative Adversarial Network (cGAN)\narchitecture that is capable of generating 3D Computed Tomography scans in\nvoxels from noisy and/or pixelated approximations and with the potential to\ngenerate full synthetic 3D scan volumes. We believe conditional cGAN to be a\ntractable approach to generate 3D CT volumes, even though the problem of\ngenerating full resolution deep fakes is presently impractical due to GPU\nmemory limitations. We present results for autoencoder, denoising, and\ndepixelating tasks which are trained and tested on two novel COVID19 CT\ndatasets. Our evaluation metrics, Peak Signal to Noise ratio (PSNR) range from\n12.53 - 46.46 dB, and the Structural Similarity index ( SSIM) range from 0.89\nto 1.\n", "versions": [{"version": "v1", "created": "Fri, 2 Apr 2021 12:25:37 GMT"}], "update_date": "2021-04-07", "authors_parsed": [["Mangalagiri", "Jayalakshmi", ""], ["Chapman", "David", ""], ["Gangopadhyay", "Aryya", ""], ["Yesha", "Yaacov", ""], ["Galita", "Joshua", ""], ["Menon", "Sumeet", ""], ["Yesha", "Yelena", ""], ["Saboury", "Babak", ""], ["Morris", "Michael", ""], ["Nguyen", "Phuong", ""]]}, {"id": "2104.02061", "submitter": "Bingqing Yu", "authors": "Federico Bianchi, Jacopo Tagliabue and Bingqing Yu", "title": "Query2Prod2Vec Grounded Word Embeddings for eCommerce", "comments": "Published as a conference paper at NAACL2021 - Industry Track", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present Query2Prod2Vec, a model that grounds lexical representations for\nproduct search in product embeddings: in our model, meaning is a mapping\nbetween words and a latent space of products in a digital shop. We leverage\nshopping sessions to learn the underlying space and use merchandising\nannotations to build lexical analogies for evaluation: our experiments show\nthat our model is more accurate than known techniques from the NLP and IR\nliterature. Finally, we stress the importance of data efficiency for product\nsearch outside of retail giants, and highlight how Query2Prod2Vec fits with\npractical constraints faced by most practitioners.\n", "versions": [{"version": "v1", "created": "Fri, 2 Apr 2021 21:32:43 GMT"}], "update_date": "2021-04-07", "authors_parsed": [["Bianchi", "Federico", ""], ["Tagliabue", "Jacopo", ""], ["Yu", "Bingqing", ""]]}, {"id": "2104.02066", "submitter": "Jun-En Ding", "authors": "Jun-En Ding, Chi-Hsiang Chu, Mong-Na Lo Huang, Chien-Ching Hsu", "title": "Dopamine Transporter SPECT Image Classification for Neurodegenerative\n  Parkinsonism via Diffusion Maps and Machine Learning Classifiers", "comments": null, "journal-ref": "24th Annual Conference, MIUA 2021, Oxford, UK, July 12-14, 2021,\n  Proceedings", "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Neurodegenerative parkinsonism can be assessed by dopamine transporter single\nphoton emission computed tomography (DaT-SPECT). Although generating images is\ntime consuming, these images can show interobserver variability and they have\nbeen visually interpreted by nuclear medicine physicians to date. Accordingly,\nthis study aims to provide an automatic and robust method based on Diffusion\nMaps and machine learning classifiers to classify the SPECT images into two\ntypes, namely Normal and Abnormal DaT-SPECT image groups. In the proposed\nmethod, the 3D images of N patients are mapped to an N by N pairwise distance\nmatrix and are visualized in Diffusion Maps coordinates. The images of the\ntraining set are embedded into a low-dimensional space by using diffusion maps.\nMoreover, we use Nystr\\\"om's out-of-sample extension, which embeds new sample\npoints as the testing set in the reduced space. Testing samples in the embedded\nspace are then classified into two types through the ensemble classifier with\nLinear Discriminant Analysis (LDA) and voting procedure through\ntwenty-five-fold cross-validation results. The feasibility of the method is\ndemonstrated via Parkinsonism Progression Markers Initiative (PPMI) dataset of\n1097 subjects and a clinical cohort from Kaohsiung Chang Gung Memorial Hospital\n(KCGMH-TW) of 630 patients. We compare performances using Diffusion Maps with\nthose of three alternative manifold methods for dimension reduction, namely\nLocally Linear Embedding (LLE), Isomorphic Mapping Algorithm (Isomap), and\nKernel Principal Component Analysis (Kernel PCA). We also compare results using\n2D and 3D CNN methods. The diffusion maps method has an average accuracy of 98%\nfor the PPMI and 90% for the KCGMH-TW dataset with twenty-five fold\ncross-validation results. It outperforms the other three methods concerning the\noverall accuracy and the robustness in the training and testing samples.\n", "versions": [{"version": "v1", "created": "Tue, 6 Apr 2021 06:30:15 GMT"}, {"version": "v2", "created": "Fri, 7 May 2021 15:47:56 GMT"}], "update_date": "2021-05-10", "authors_parsed": [["Ding", "Jun-En", ""], ["Chu", "Chi-Hsiang", ""], ["Huang", "Mong-Na Lo", ""], ["Hsu", "Chien-Ching", ""]]}, {"id": "2104.02095", "submitter": "Aleksandr Beknazaryan", "authors": "Aleksandr Beknazaryan", "title": "Analytic function approximation by path norm regularized deep networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We provide an entropy bound for the spaces of path norm regularized neural\nnetworks with piecewise linear activation functions, such as the ReLU and the\nabsolute value functions. This bound generalizes the known entropy bound for\nthe spaces of linear functions on $\\mathbb{R}^d$. Keeping the path norm\ntogether with the depth, width and the weights of networks to have logarithmic\ndependence on $1/\\varepsilon$, we $\\varepsilon$-approximate functions that are\nanalytic on certain regions of $\\mathbb{C}^d$.\n", "versions": [{"version": "v1", "created": "Mon, 5 Apr 2021 18:02:04 GMT"}, {"version": "v2", "created": "Thu, 3 Jun 2021 13:01:53 GMT"}, {"version": "v3", "created": "Tue, 15 Jun 2021 10:54:53 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Beknazaryan", "Aleksandr", ""]]}, {"id": "2104.02102", "submitter": "Ali Sedaghatbaf", "authors": "Ali Sedaghatbaf, Mahshid Helali Moghadam and Mehrdad Saadatmand", "title": "Automated Performance Testing Based on Active Deep Learning", "comments": "9 pages, 7 figures, 2nd ACM/IEEE conference on automation of software\n  test", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Generating tests that can reveal performance issues in large and complex\nsoftware systems within a reasonable amount of time is a challenging task. On\none hand, there are numerous combinations of input data values to explore. On\nthe other hand, we have a limited test budget to execute tests. What makes this\ntask even more difficult is the lack of access to source code and the internal\ndetails of these systems. In this paper, we present an automated test\ngeneration method called ACTA for black-box performance testing. ACTA is based\non active learning, which means that it does not require a large set of\nhistorical test data to learn about the performance characteristics of the\nsystem under test. Instead, it dynamically chooses the tests to execute using\nuncertainty sampling. ACTA relies on a conditional variant of generative\nadversarial networks,and facilitates specifying performance requirements in\nterms of conditions and generating tests that address those conditions.We have\nevaluated ACTA on a benchmark web application, and the experimental results\nindicate that this method is comparable with random testing, and two other\nmachine learning methods,i.e. PerfXRL and DN.\n", "versions": [{"version": "v1", "created": "Mon, 5 Apr 2021 18:19:12 GMT"}], "update_date": "2021-04-07", "authors_parsed": [["Sedaghatbaf", "Ali", ""], ["Moghadam", "Mahshid Helali", ""], ["Saadatmand", "Mehrdad", ""]]}, {"id": "2104.02107", "submitter": "Neal Mangaokar", "authors": "Neal Mangaokar, Jiameng Pu, Parantapa Bhattacharya, Chandan K. Reddy,\n  Bimal Viswanath", "title": "Jekyll: Attacking Medical Image Diagnostics using Deep Generative Models", "comments": "Published in proceedings of the 5th European Symposium on Security\n  and Privacy (EuroS&P '20)", "journal-ref": null, "doi": "10.1109/EuroSP48549.2020.00017", "report-no": null, "categories": "cs.CR cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Advances in deep neural networks (DNNs) have shown tremendous promise in the\nmedical domain. However, the deep learning tools that are helping the domain,\ncan also be used against it. Given the prevalence of fraud in the healthcare\ndomain, it is important to consider the adversarial use of DNNs in manipulating\nsensitive data that is crucial to patient healthcare. In this work, we present\nthe design and implementation of a DNN-based image translation attack on\nbiomedical imagery. More specifically, we propose Jekyll, a neural style\ntransfer framework that takes as input a biomedical image of a patient and\ntranslates it to a new image that indicates an attacker-chosen disease\ncondition. The potential for fraudulent claims based on such generated 'fake'\nmedical images is significant, and we demonstrate successful attacks on both\nX-rays and retinal fundus image modalities. We show that these attacks manage\nto mislead both medical professionals and algorithmic detection schemes.\nLastly, we also investigate defensive measures based on machine learning to\ndetect images generated by Jekyll.\n", "versions": [{"version": "v1", "created": "Mon, 5 Apr 2021 18:23:36 GMT"}], "update_date": "2021-04-07", "authors_parsed": [["Mangaokar", "Neal", ""], ["Pu", "Jiameng", ""], ["Bhattacharya", "Parantapa", ""], ["Reddy", "Chandan K.", ""], ["Viswanath", "Bimal", ""]]}, {"id": "2104.02120", "submitter": "Felix Xiaofeng Ye", "authors": "Felix X.-F. Ye, Sichen Yang, Mauro Maggioni", "title": "Nonlinear model reduction for slow-fast stochastic systems near\n  manifolds", "comments": "45 pages, 9 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a nonlinear stochastic model reduction technique for\nhigh-dimensional stochastic dynamical systems that have a low-dimensional\ninvariant effective manifold with slow dynamics, and high-dimensional, large\nfast modes. Given only access to a black box simulator from which short bursts\nof simulation can be obtained, we estimate the invariant manifold, a process of\nthe effective (stochastic) dynamics on it, and construct an efficient simulator\nthereof. These estimation steps can be performed on-the-fly, leading to\nefficient exploration of the effective state space, without losing consistency\nwith the underlying dynamics. This construction enables fast and efficient\nsimulation of paths of the effective dynamics, together with estimation of\ncrucial features and observables of such dynamics, including the stationary\ndistribution, identification of metastable states, and residence times and\ntransition rates between them.\n", "versions": [{"version": "v1", "created": "Mon, 5 Apr 2021 19:29:46 GMT"}], "update_date": "2021-04-07", "authors_parsed": [["Ye", "Felix X. -F.", ""], ["Yang", "Sichen", ""], ["Maggioni", "Mauro", ""]]}, {"id": "2104.02125", "submitter": "Quan Wang", "authors": "Roza Chojnacka, Jason Pelecanos, Quan Wang, Ignacio Lopez Moreno", "title": "SpeakerStew: Scaling to Many Languages with a Triaged Multilingual\n  Text-Dependent and Text-Independent Speaker Verification System", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we describe SpeakerStew - a hybrid system to perform speaker\nverification on 46 languages. Two core ideas were explored in this system: (1)\nPooling training data of different languages together for multilingual\ngeneralization and reducing development cycles; (2) A novel triage mechanism\nbetween text-dependent and text-independent models to reduce runtime cost and\nexpected latency. To the best of our knowledge, this is the first study of\nspeaker verification systems at the scale of 46 languages. The problem is\nframed from the perspective of using a smart speaker device with interactions\nconsisting of a wake-up keyword (text-dependent) followed by a speech query\n(text-independent). Experimental evidence suggests that training on multiple\nlanguages can generalize to unseen varieties while maintaining performance on\nseen varieties. We also found that it can reduce computational requirements for\ntraining models by an order of magnitude. Furthermore, during model inference\non English data, we observe that leveraging a triage framework can reduce the\nnumber of calls to the more computationally expensive text-independent system\nby 73% (and reduce latency by 59%) while maintaining an EER no worse than the\ntext-independent setup.\n", "versions": [{"version": "v1", "created": "Mon, 5 Apr 2021 19:48:16 GMT"}, {"version": "v2", "created": "Mon, 26 Apr 2021 17:56:24 GMT"}, {"version": "v3", "created": "Tue, 15 Jun 2021 19:39:03 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Chojnacka", "Roza", ""], ["Pelecanos", "Jason", ""], ["Wang", "Quan", ""], ["Moreno", "Ignacio Lopez", ""]]}, {"id": "2104.02133", "submitter": "William Chan", "authors": "William Chan, Daniel Park, Chris Lee, Yu Zhang, Quoc Le, Mohammad\n  Norouzi", "title": "SpeechStew: Simply Mix All Available Speech Recognition Data to Train\n  One Large Neural Network", "comments": "submitted to INTERSPEECH", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present SpeechStew, a speech recognition model that is trained on a\ncombination of various publicly available speech recognition datasets: AMI,\nBroadcast News, Common Voice, LibriSpeech, Switchboard/Fisher, Tedlium, and\nWall Street Journal. SpeechStew simply mixes all of these datasets together,\nwithout any special re-weighting or re-balancing of the datasets. SpeechStew\nachieves SoTA or near SoTA results across a variety of tasks, without the use\nof an external language model. Our results include 9.0\\% WER on AMI-IHM, 4.7\\%\nWER on Switchboard, 8.3\\% WER on CallHome, and 1.3\\% on WSJ, which\nsignificantly outperforms prior work with strong external language models. We\nalso demonstrate that SpeechStew learns powerful transfer learning\nrepresentations. We fine-tune SpeechStew on a noisy low resource speech\ndataset, CHiME-6. We achieve 38.9\\% WER without a language model, which\ncompares to 38.6\\% WER to a strong HMM baseline with a language model.\n", "versions": [{"version": "v1", "created": "Mon, 5 Apr 2021 20:13:36 GMT"}, {"version": "v2", "created": "Mon, 12 Apr 2021 21:28:29 GMT"}, {"version": "v3", "created": "Tue, 27 Apr 2021 13:23:27 GMT"}], "update_date": "2021-04-28", "authors_parsed": [["Chan", "William", ""], ["Park", "Daniel", ""], ["Lee", "Chris", ""], ["Zhang", "Yu", ""], ["Le", "Quoc", ""], ["Norouzi", "Mohammad", ""]]}, {"id": "2104.02144", "submitter": "Abolfazl Farahani", "authors": "Abolfazl Farahani, Behrouz Pourshojae, Khaled Rasheed, Hamid R.\n  Arabnia", "title": "A Concise Review of Transfer Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  The availability of abundant labeled data in recent years led the researchers\nto introduce a methodology called transfer learning, which utilizes existing\ndata in situations where there are difficulties in collecting new annotated\ndata. Transfer learning aims to boost the performance of a target learner by\napplying another related source data. In contrast to the traditional machine\nlearning and data mining techniques, which assume that the training and testing\ndata lie from the same feature space and distribution, transfer learning can\nhandle situations where there is a discrepancy between domains and\ndistributions. These characteristics give the model the potential to utilize\nthe available related source data and extend the underlying knowledge to the\ntarget task achieving better performance. This survey paper aims to give a\nconcise review of traditional and current transfer learning settings, existing\nchallenges, and related approaches.\n", "versions": [{"version": "v1", "created": "Mon, 5 Apr 2021 20:34:55 GMT"}], "update_date": "2021-04-07", "authors_parsed": [["Farahani", "Abolfazl", ""], ["Pourshojae", "Behrouz", ""], ["Rasheed", "Khaled", ""], ["Arabnia", "Hamid R.", ""]]}, {"id": "2104.02146", "submitter": "Daniel Gribel", "authors": "Daniel Gribel, Michel Gendreau, Thibaut Vidal", "title": "Semi-Supervised Clustering with Inaccurate Pairwise Annotations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pairwise relational information is a useful way of providing partial\nsupervision in domains where class labels are difficult to acquire. This work\npresents a clustering model that incorporates pairwise annotations in the form\nof must-link and cannot-link relations and considers possible annotation\ninaccuracies (i.e., a common setting when experts provide pairwise\nsupervision). We propose a generative model that assumes Gaussian-distributed\ndata samples along with must-link and cannot-link relations generated by\nstochastic block models. We adopt a maximum-likelihood approach and demonstrate\nthat, even when supervision is weak and inaccurate, accounting for relational\ninformation significantly improves clustering performance. Relational\ninformation also helps to detect meaningful groups in real-world datasets that\ndo not fit the original data-distribution assumptions. Additionally, we extend\nthe model to integrate prior knowledge of experts' accuracy and discuss\ncircumstances in which the use of this knowledge is beneficial.\n", "versions": [{"version": "v1", "created": "Mon, 5 Apr 2021 20:37:00 GMT"}], "update_date": "2021-04-07", "authors_parsed": [["Gribel", "Daniel", ""], ["Gendreau", "Michel", ""], ["Vidal", "Thibaut", ""]]}, {"id": "2104.02150", "submitter": "Alexander D'Amour", "authors": "Alexander D'Amour", "title": "Revisiting Rashomon: A Comment on \"The Two Cultures\"", "comments": "Commentary to appear in a special issue of Observational Studies,\n  discussing Leo Breiman's paper \"Statistical Modeling: The Two Cultures\"\n  (https://doi.org/10.1214/ss/1009213726) and accompanying commentary", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Here, I provide some reflections on Prof. Leo Breiman's \"The Two Cultures\"\npaper. I focus specifically on the phenomenon that Breiman dubbed the \"Rashomon\nEffect\", describing the situation in which there are many models that satisfy\npredictive accuracy criteria equally well, but process information in the data\nin substantially different ways. This phenomenon can make it difficult to draw\nconclusions or automate decisions based on a model fit to data. I make\nconnections to recent work in the Machine Learning literature that explore the\nimplications of this issue, and note that grappling with it can be a fruitful\narea of collaboration between the algorithmic and data modeling cultures.\n", "versions": [{"version": "v1", "created": "Mon, 5 Apr 2021 20:51:58 GMT"}], "update_date": "2021-04-07", "authors_parsed": [["D'Amour", "Alexander", ""]]}, {"id": "2104.02151", "submitter": "Mingzhe Chen", "authors": "Mingzhe Chen, Deniz G\\\"und\\\"uz, Kaibin Huang, Walid Saad, Mehdi\n  Bennis, Aneta Vulgarakis Feljan, and H. Vincent Poor", "title": "Distributed Learning in Wireless Networks: Recent Progress and Future\n  Challenges", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The next-generation of wireless networks will enable many machine learning\n(ML) tools and applications to efficiently analyze various types of data\ncollected by edge devices for inference, autonomy, and decision making\npurposes. However, due to resource constraints, delay limitations, and privacy\nchallenges, edge devices cannot offload their entire collected datasets to a\ncloud server for centrally training their ML models or inference purposes. To\novercome these challenges, distributed learning and inference techniques have\nbeen proposed as a means to enable edge devices to collaboratively train ML\nmodels without raw data exchanges, thus reducing the communication overhead and\nlatency as well as improving data privacy. However, deploying distributed\nlearning over wireless networks faces several challenges including the\nuncertain wireless environment, limited wireless resources (e.g., transmit\npower and radio spectrum), and hardware resources. This paper provides a\ncomprehensive study of how distributed learning can be efficiently and\neffectively deployed over wireless edge networks. We present a detailed\noverview of several emerging distributed learning paradigms, including\nfederated learning, federated distillation, distributed inference, and\nmulti-agent reinforcement learning. For each learning framework, we first\nintroduce the motivation for deploying it over wireless networks. Then, we\npresent a detailed literature review on the use of communication techniques for\nits efficient deployment. We then introduce an illustrative example to show how\nto optimize wireless networks to improve its performance. Finally, we introduce\nfuture research opportunities. In a nutshell, this paper provides a holistic\nset of guidelines on how to deploy a broad range of distributed learning\nframeworks over real-world wireless communication networks.\n", "versions": [{"version": "v1", "created": "Mon, 5 Apr 2021 20:57:56 GMT"}], "update_date": "2021-04-07", "authors_parsed": [["Chen", "Mingzhe", ""], ["G\u00fcnd\u00fcz", "Deniz", ""], ["Huang", "Kaibin", ""], ["Saad", "Walid", ""], ["Bennis", "Mehdi", ""], ["Feljan", "Aneta Vulgarakis", ""], ["Poor", "H. Vincent", ""]]}, {"id": "2104.02153", "submitter": "Claudio Bellei", "authors": "Claudio Bellei, Hussain Alattas, and Nesrine Kaaniche", "title": "Label-GCN: An Effective Method for Adding Label Propagation to Graph\n  Convolutional Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that a modification of the first layer of a Graph Convolutional\nNetwork (GCN) can be used to effectively propagate label information across\nneighbor nodes, for binary and multi-class classification problems. This is\ndone by selectively eliminating self-loops for the label features during the\ntraining phase of a GCN. The GCN architecture is otherwise unchanged, without\nany extra hyper-parameters, and can be used in both a transductive and\ninductive setting. We show through several experiments that, depending on how\nmany labels are available during the inference phase, this strategy can lead to\na substantial improvement in the model performance compared to a standard GCN\napproach, including with imbalanced datasets.\n", "versions": [{"version": "v1", "created": "Mon, 5 Apr 2021 21:02:48 GMT"}], "update_date": "2021-04-07", "authors_parsed": [["Bellei", "Claudio", ""], ["Alattas", "Hussain", ""], ["Kaaniche", "Nesrine", ""]]}, {"id": "2104.02159", "submitter": "Vandad Davoodnia", "authors": "Vandad Davoodnia, Ali Etemad", "title": "Identity and Posture Recognition in Smart Beds with Deep Multitask\n  Learning", "comments": "\\c{opyright} 2019 IEEE. Personal use of this material is permitted.\n  Permission from IEEE must be obtained for all other uses, in any current or\n  future media, including reprinting/republishing this material for advertising\n  or promotional purposes, creating new collective works, for resale or\n  redistribution to servers or lists, or reuse of any copyrighted component of\n  this work in other works", "journal-ref": "2019 IEEE International Conference on Systems, Man and Cybernetics\n  (SMC)", "doi": "10.1109/SMC.2019.8914459", "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Sleep posture analysis is widely used for clinical patient monitoring and\nsleep studies. Earlier research has revealed that sleep posture highly\ninfluences symptoms of diseases such as apnea and pressure ulcers. In this\nstudy, we propose a robust deep learning model capable of accurately detecting\nsubjects and their sleeping postures using the publicly available data acquired\nfrom a commercial pressure mapping system. A combination of loss functions is\nused to discriminate subjects and their sleeping postures simultaneously. The\nexperimental results show that our proposed method can identify the patients\nand their in-bed posture with almost no errors in a 10-fold cross-validation\nscheme. Furthermore, we show that our network achieves an average accuracy of\nup to 99% when faced with new subjects in a leave-one-subject-out validation\nprocedure on the three most common sleeping posture categories. We demonstrate\nthe effects of the combined cost function over its parameter and show that\nlearning both tasks simultaneously improves performance significantly. Finally,\nwe evaluate our proposed pipeline by testing it over augmented images of our\ndataset. The proposed algorithm can ultimately be used in clinical and smart\nhome environments as a complementary tool with other available automated\npatient monitoring systems.\n", "versions": [{"version": "v1", "created": "Mon, 5 Apr 2021 21:21:54 GMT"}], "update_date": "2021-04-07", "authors_parsed": [["Davoodnia", "Vandad", ""], ["Etemad", "Ali", ""]]}, {"id": "2104.02164", "submitter": "Atousa Zarindast", "authors": "Atousa Zarindast, Jonathan Wood, Anuj Sharma", "title": "A data-driven personalized smart lighting recommender system", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recommender systems attempts to identify and recommend the most preferable\nitem (product-service) to an individual user. These systems predict user\ninterest in items based on related items, users, and the interactions between\nitems and users. We aim to build an auto-routine and color scheme recommender\nsystem that leverages a wealth of historical data and machine learning methods.\nWe introduce an unsupervised method to recommend a routine for lighting.\nMoreover, by analyzing users' daily logs, geographical location, temporal and\nusage information we understand user preference and predict their preferred\ncolor for lights. To do so, we cluster users based on their geographical\ninformation and usage distribution. We then build and train a predictive model\nwithin each cluster and aggregate the results. Results indicate that models\nbased on similar users increases the prediction accuracy, with and without\nprior knowledge about user preferences.\n", "versions": [{"version": "v1", "created": "Mon, 5 Apr 2021 21:32:43 GMT"}], "update_date": "2021-04-07", "authors_parsed": [["Zarindast", "Atousa", ""], ["Wood", "Jonathan", ""], ["Sharma", "Anuj", ""]]}, {"id": "2104.02173", "submitter": "AKM Bahalul Haque", "authors": "A K M Bahalul Haque, Tahmid Hasan Pranto, Abdulla All Noman and Atik\n  Mahmood", "title": "Insight about Detection, Prediction and Weather Impact of Coronavirus\n  (Covid-19) using Neural Network", "comments": "15 Pages, 13 Figures and 4 Tables", "journal-ref": "International Journal of Artificial Intelligence & Applications\n  11(4):67-81, July. 2020", "doi": "10.5121/ijaia.2020.11406", "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The world is facing a tough situation due to the catastrophic pandemic caused\nby novel coronavirus (COVID-19). The number people affected by this virus are\nincreasing exponentially day by day and the number has already crossed 6.4\nmillion. As no vaccine has been discovered yet, the early detection of patients\nand isolation is the only and most effective way to reduce the spread of the\nvirus. Detecting infected persons from chest X-Ray by using Deep Neural\nNetworks, can be applied as a time and laborsaving solution. In this study, we\ntried to detect Covid-19 by classification of Covid-19, pneumonia and normal\nchest X-Rays. We used five different Convolutional Pre-Trained Neural Network\nmodels (VGG16, VGG19, Xception, InceptionV3 and Resnet50) and compared their\nperformance. VGG16 and VGG19 shows precise performance in classification. Both\nmodels can classify between three kinds of X-Rays with an accuracy over 92%.\nAnother part of our study was to find the impact of weather factors\n(temperature, humidity, sun hour and wind speed) on this pandemic using\nDecision Tree Regressor. We found that temperature, humidity and sun-hour\njointly hold 85.88% impact on escalation of Covid-19 and 91.89% impact on death\ndue to Covid-19 where humidity has 8.09% impact on death. We also tried to\npredict the death of an individual based on age, gender, country, and location\ndue to COVID-19 using the LogisticRegression, which can predict death of an\nindividual with a model accuracy of 94.40%.\n", "versions": [{"version": "v1", "created": "Mon, 5 Apr 2021 22:18:57 GMT"}], "update_date": "2021-04-07", "authors_parsed": [["Haque", "A K M Bahalul", ""], ["Pranto", "Tahmid Hasan", ""], ["Noman", "Abdulla All", ""], ["Mahmood", "Atik", ""]]}, {"id": "2104.02180", "submitter": "Xue Bin Peng", "authors": "Xue Bin Peng, Ze Ma, Pieter Abbeel, Sergey Levine, Angjoo Kanazawa", "title": "AMP: Adversarial Motion Priors for Stylized Physics-Based Character\n  Control", "comments": null, "journal-ref": null, "doi": "10.1145/3450626.3459670", "report-no": null, "categories": "cs.GR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Synthesizing graceful and life-like behaviors for physically simulated\ncharacters has been a fundamental challenge in computer animation. Data-driven\nmethods that leverage motion tracking are a prominent class of techniques for\nproducing high fidelity motions for a wide range of behaviors. However, the\neffectiveness of these tracking-based methods often hinges on carefully\ndesigned objective functions, and when applied to large and diverse motion\ndatasets, these methods require significant additional machinery to select the\nappropriate motion for the character to track in a given scenario. In this\nwork, we propose to obviate the need to manually design imitation objectives\nand mechanisms for motion selection by utilizing a fully automated approach\nbased on adversarial imitation learning. High-level task objectives that the\ncharacter should perform can be specified by relatively simple reward\nfunctions, while the low-level style of the character's behaviors can be\nspecified by a dataset of unstructured motion clips, without any explicit clip\nselection or sequencing. These motion clips are used to train an adversarial\nmotion prior, which specifies style-rewards for training the character through\nreinforcement learning (RL). The adversarial RL procedure automatically selects\nwhich motion to perform, dynamically interpolating and generalizing from the\ndataset. Our system produces high-quality motions that are comparable to those\nachieved by state-of-the-art tracking-based techniques, while also being able\nto easily accommodate large datasets of unstructured motion clips. Composition\nof disparate skills emerges automatically from the motion prior, without\nrequiring a high-level motion planner or other task-specific annotations of the\nmotion clips. We demonstrate the effectiveness of our framework on a diverse\ncast of complex simulated characters and a challenging suite of motor control\ntasks.\n", "versions": [{"version": "v1", "created": "Mon, 5 Apr 2021 22:43:14 GMT"}], "update_date": "2021-04-07", "authors_parsed": [["Peng", "Xue Bin", ""], ["Ma", "Ze", ""], ["Abbeel", "Pieter", ""], ["Levine", "Sergey", ""], ["Kanazawa", "Angjoo", ""]]}, {"id": "2104.02184", "submitter": "Malte J. Rasch", "authors": "Malte J. Rasch, Diego Moreda, Tayfun Gokmen, Manuel Le Gallo, Fabio\n  Carta, Cindy Goldberg, Kaoutar El Maghraoui, Abu Sebastian, Vijay Narayanan", "title": "A flexible and fast PyTorch toolkit for simulating training and\n  inference on analog crossbar arrays", "comments": "Submitted to AICAS2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We introduce the IBM Analog Hardware Acceleration Kit, a new and first of a\nkind open source toolkit to simulate analog crossbar arrays in a convenient\nfashion from within PyTorch (freely available at\nhttps://github.com/IBM/aihwkit). The toolkit is under active development and is\ncentered around the concept of an \"analog tile\" which captures the computations\nperformed on a crossbar array. Analog tiles are building blocks that can be\nused to extend existing network modules with analog components and compose\narbitrary artificial neural networks (ANNs) using the flexibility of the\nPyTorch framework. Analog tiles can be conveniently configured to emulate a\nplethora of different analog hardware characteristics and their non-idealities,\nsuch as device-to-device and cycle-to-cycle variations, resistive device\nresponse curves, and weight and output noise. Additionally, the toolkit makes\nit possible to design custom unit cell configurations and to use advanced\nanalog optimization algorithms such as Tiki-Taka. Moreover, the backward and\nupdate behavior can be set to \"ideal\" to enable hardware-aware training\nfeatures for chips that target inference acceleration only. To evaluate the\ninference accuracy of such chips over time, we provide statistical programming\nnoise and drift models calibrated on phase-change memory hardware. Our new\ntoolkit is fully GPU accelerated and can be used to conveniently estimate the\nimpact of material properties and non-idealities of future analog technology on\nthe accuracy for arbitrary ANNs.\n", "versions": [{"version": "v1", "created": "Mon, 5 Apr 2021 22:59:35 GMT"}], "update_date": "2021-04-07", "authors_parsed": [["Rasch", "Malte J.", ""], ["Moreda", "Diego", ""], ["Gokmen", "Tayfun", ""], ["Gallo", "Manuel Le", ""], ["Carta", "Fabio", ""], ["Goldberg", "Cindy", ""], ["Maghraoui", "Kaoutar El", ""], ["Sebastian", "Abu", ""], ["Narayanan", "Vijay", ""]]}, {"id": "2104.02188", "submitter": "Yaosheng Fu", "authors": "Yaosheng Fu, Evgeny Bolotin, Niladrish Chatterjee, David Nellans,\n  Stephen W. Keckler", "title": "GPU Domain Specialization via Composable On-Package Architecture", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR cs.DC cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  As GPUs scale their low precision matrix math throughput to boost deep\nlearning (DL) performance, they upset the balance between math throughput and\nmemory system capabilities. We demonstrate that converged GPU design trying to\naddress diverging architectural requirements between FP32 (or larger) based HPC\nand FP16 (or smaller) based DL workloads results in sub-optimal configuration\nfor either of the application domains. We argue that a Composable On-PAckage\nGPU (COPAGPU) architecture to provide domain-specialized GPU products is the\nmost practical solution to these diverging requirements. A COPA-GPU leverages\nmulti-chip-module disaggregation to support maximal design reuse, along with\nmemory system specialization per application domain. We show how a COPA-GPU\nenables DL-specialized products by modular augmentation of the baseline GPU\narchitecture with up to 4x higher off-die bandwidth, 32x larger on-package\ncache, 2.3x higher DRAM bandwidth and capacity, while conveniently supporting\nscaled-down HPC-oriented designs. This work explores the microarchitectural\ndesign necessary to enable composable GPUs and evaluates the benefits\ncomposability can provide to HPC, DL training, and DL inference. We show that\nwhen compared to a converged GPU design, a DL-optimized COPA-GPU featuring a\ncombination of 16x larger cache capacity and 1.6x higher DRAM bandwidth scales\nper-GPU training and inference performance by 31% and 35% respectively and\nreduces the number of GPU instances by 50% in scale-out training scenarios.\n", "versions": [{"version": "v1", "created": "Mon, 5 Apr 2021 23:06:50 GMT"}], "update_date": "2021-04-07", "authors_parsed": [["Fu", "Yaosheng", ""], ["Bolotin", "Evgeny", ""], ["Chatterjee", "Niladrish", ""], ["Nellans", "David", ""], ["Keckler", "Stephen W.", ""]]}, {"id": "2104.02189", "submitter": "Payam Delgosha", "authors": "Payam Delgosha, Hamed Hassani, Ramtin Pedarsani", "title": "Robust Classification Under $\\ell_0$ Attack for the Gaussian Mixture\n  Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is well-known that machine learning models are vulnerable to small but\ncleverly-designed adversarial perturbations that can cause misclassification.\nWhile there has been major progress in designing attacks and defenses for\nvarious adversarial settings, many fundamental and theoretical problems are yet\nto be resolved. In this paper, we consider classification in the presence of\n$\\ell_0$-bounded adversarial perturbations, a.k.a. sparse attacks. This setting\nis significantly different from other $\\ell_p$-adversarial settings, with\n$p\\geq 1$, as the $\\ell_0$-ball is non-convex and highly non-smooth. Under the\nassumption that data is distributed according to the Gaussian mixture model,\nour goal is to characterize the optimal robust classifier and the corresponding\nrobust classification error as well as a variety of trade-offs between\nrobustness, accuracy, and the adversary's budget. To this end, we develop a\nnovel classification algorithm called FilTrun that has two main modules:\nFiltration and Truncation. The key idea of our method is to first filter out\nthe non-robust coordinates of the input and then apply a carefully-designed\ntruncated inner product for classification. By analyzing the performance of\nFilTrun, we derive an upper bound on the optimal robust classification error.\nWe also find a lower bound by designing a specific adversarial strategy that\nenables us to derive the corresponding robust classifier and its achieved\nerror. For the case that the covariance matrix of the Gaussian mixtures is\ndiagonal, we show that as the input's dimension gets large, the upper and lower\nbounds converge; i.e. we characterize the asymptotically-optimal robust\nclassifier. Throughout, we discuss several examples that illustrate interesting\nbehaviors such as the existence of a phase transition for adversary's budget\ndetermining whether the effect of adversarial perturbation can be fully\nneutralized.\n", "versions": [{"version": "v1", "created": "Mon, 5 Apr 2021 23:31:25 GMT"}], "update_date": "2021-04-07", "authors_parsed": [["Delgosha", "Payam", ""], ["Hassani", "Hamed", ""], ["Pedarsani", "Ramtin", ""]]}, {"id": "2104.02194", "submitter": "Duc Le", "authors": "Duc Le, Mahaveer Jain, Gil Keren, Suyoun Kim, Yangyang Shi, Jay\n  Mahadeokar, Julian Chan, Yuan Shangguan, Christian Fuegen, Ozlem Kalinli,\n  Yatharth Saraf, Michael L. Seltzer", "title": "Contextualized Streaming End-to-End Speech Recognition with Trie-Based\n  Deep Biasing and Shallow Fusion", "comments": "Accepted for presentation at INTERSPEECH 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How to leverage dynamic contextual information in end-to-end speech\nrecognition has remained an active research area. Previous solutions to this\nproblem were either designed for specialized use cases that did not generalize\nwell to open-domain scenarios, did not scale to large biasing lists, or\nunderperformed on rare long-tail words. We address these limitations by\nproposing a novel solution that combines shallow fusion, trie-based deep\nbiasing, and neural network language model contextualization. These techniques\nresult in significant 19.5% relative Word Error Rate improvement over existing\ncontextual biasing approaches and 5.4%-9.3% improvement compared to a strong\nhybrid baseline on both open-domain and constrained contextualization tasks,\nwhere the targets consist of mostly rare long-tail words. Our final system\nremains lightweight and modular, allowing for quick modification without model\nre-training.\n", "versions": [{"version": "v1", "created": "Mon, 5 Apr 2021 23:59:43 GMT"}, {"version": "v2", "created": "Fri, 11 Jun 2021 23:10:43 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Le", "Duc", ""], ["Jain", "Mahaveer", ""], ["Keren", "Gil", ""], ["Kim", "Suyoun", ""], ["Shi", "Yangyang", ""], ["Mahadeokar", "Jay", ""], ["Chan", "Julian", ""], ["Shangguan", "Yuan", ""], ["Fuegen", "Christian", ""], ["Kalinli", "Ozlem", ""], ["Saraf", "Yatharth", ""], ["Seltzer", "Michael L.", ""]]}, {"id": "2104.02214", "submitter": "Basheer Qolomany", "authors": "Ghezlane Halhoul Merabet, Mohamed Essaaidi, Mohamed Ben Haddou,\n  Basheer Qolomany, Junaid Qadir, Muhammad Anan, Ala Al-Fuqaha, Mohamed Riduan\n  Abid, Driss Benhaddou", "title": "Intelligent Building Control Systems for Thermal Comfort and\n  Energy-Efficiency: A Systematic Review of Artificial Intelligence-Assisted\n  Techniques", "comments": "arXiv admin note: text overlap with arXiv:2006.12559", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Building operations represent a significant percentage of the total primary\nenergy consumed in most countries due to the proliferation of Heating,\nVentilation and Air-Conditioning (HVAC) installations in response to the\ngrowing demand for improved thermal comfort. Reducing the associated energy\nconsumption while maintaining comfortable conditions in buildings are\nconflicting objectives and represent a typical optimization problem that\nrequires intelligent system design. Over the last decade, different\nmethodologies based on the Artificial Intelligence (AI) techniques have been\ndeployed to find the sweet spot between energy use in HVAC systems and suitable\nindoor comfort levels to the occupants. This paper performs a comprehensive and\nan in-depth systematic review of AI-based techniques used for building control\nsystems by assessing the outputs of these techniques, and their implementations\nin the reviewed works, as well as investigating their abilities to improve the\nenergy-efficiency, while maintaining thermal comfort conditions. This enables a\nholistic view of (1) the complexities of delivering thermal comfort to users\ninside buildings in an energy-efficient way, and (2) the associated\nbibliographic material to assist researchers and experts in the field in\ntackling such a challenge. Among the 20 AI tools developed for both energy\nconsumption and comfort control, functions such as identification and\nrecognition patterns, optimization, predictive control. Based on the findings\nof this work, the application of AI technology in building control is a\npromising area of research and still an ongoing, i.e., the performance of\nAI-based control is not yet completely satisfactory. This is mainly due in part\nto the fact that these algorithms usually need a large amount of high-quality\nreal-world data, which is lacking in the building or, more precisely, the\nenergy sector.\n", "versions": [{"version": "v1", "created": "Tue, 6 Apr 2021 01:04:28 GMT"}], "update_date": "2021-04-07", "authors_parsed": [["Merabet", "Ghezlane Halhoul", ""], ["Essaaidi", "Mohamed", ""], ["Haddou", "Mohamed Ben", ""], ["Qolomany", "Basheer", ""], ["Qadir", "Junaid", ""], ["Anan", "Muhammad", ""], ["Al-Fuqaha", "Ala", ""], ["Abid", "Mohamed Riduan", ""], ["Benhaddou", "Driss", ""]]}, {"id": "2104.02219", "submitter": "Izhak Shafran", "authors": "Hagen Soltau, Mingqiu Wang, Izhak Shafran, Laurent El Shafey", "title": "Understanding Medical Conversations: Rich Transcription, Confidence\n  Scores & Information Extraction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we describe novel components for extracting clinically\nrelevant information from medical conversations which will be available as\nGoogle APIs. We describe a transformer-based Recurrent Neural Network\nTransducer (RNN-T) model tailored for long-form audio, which can produce rich\ntranscriptions including speaker segmentation, speaker role labeling,\npunctuation and capitalization. On a representative test set, we compare\nperformance of RNN-T models with different encoders, units and streaming\nconstraints. Our transformer-based streaming model performs at about 20% WER on\nthe ASR task, 6% WDER on the diarization task, 43% SER on periods, 52% SER on\ncommas, 43% SER on question marks and 30% SER on capitalization. Our recognizer\nis paired with a confidence model that utilizes both acoustic and lexical\nfeatures from the recognizer. The model performs at about 0.37 NCE. Finally, we\ndescribe a RNN-T based tagging model. The performance of the model depends on\nthe ontologies, with F-scores of 0.90 for medications, 0.76 for symptoms, 0.75\nfor conditions, 0.76 for diagnosis, and 0.61 for treatments. While there is\nstill room for improvement, our results suggest that these models are\nsufficiently accurate for practical applications.\n", "versions": [{"version": "v1", "created": "Tue, 6 Apr 2021 01:16:59 GMT"}], "update_date": "2021-04-07", "authors_parsed": [["Soltau", "Hagen", ""], ["Wang", "Mingqiu", ""], ["Shafran", "Izhak", ""], ["Shafey", "Laurent El", ""]]}, {"id": "2104.02226", "submitter": "Boyuan Chen", "authors": "Boyuan Chen, Yu Li, Sunand Raghupathi, Hod Lipson", "title": "Beyond Categorical Label Representations for Image Classification", "comments": "International Conference on Learning Representations (ICLR 2021).\n  Project page is at\n  \\url{https://www.creativemachineslab.com/label-representation.html}", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We find that the way we choose to represent data labels can have a profound\neffect on the quality of trained models. For example, training an image\nclassifier to regress audio labels rather than traditional categorical\nprobabilities produces a more reliable classification. This result is\nsurprising, considering that audio labels are more complex than simpler\nnumerical probabilities or text. We hypothesize that high dimensional, high\nentropy label representations are generally more useful because they provide a\nstronger error signal. We support this hypothesis with evidence from various\nlabel representations including constant matrices, spectrograms, shuffled\nspectrograms, Gaussian mixtures, and uniform random matrices of various\ndimensionalities. Our experiments reveal that high dimensional, high entropy\nlabels achieve comparable accuracy to text (categorical) labels on the standard\nimage classification task, but features learned through our label\nrepresentations exhibit more robustness under various adversarial attacks and\nbetter effectiveness with a limited amount of training data. These results\nsuggest that label representation may play a more important role than\npreviously thought. The project website is at\n\\url{https://www.creativemachineslab.com/label-representation.html}.\n", "versions": [{"version": "v1", "created": "Tue, 6 Apr 2021 01:31:04 GMT"}], "update_date": "2021-04-07", "authors_parsed": [["Chen", "Boyuan", ""], ["Li", "Yu", ""], ["Raghupathi", "Sunand", ""], ["Lipson", "Hod", ""]]}, {"id": "2104.02228", "submitter": "Li Sun", "authors": "Li Sun, Zhongbao Zhang, Jiawei Zhang, Feiyang Wang, Hao Peng, Sen Su\n  and Philip S. Yu", "title": "Hyperbolic Variational Graph Neural Network for Modeling Dynamic Graphs", "comments": "9 pages, Accepted as a regular paper in AAAI Conference on Artificial\n  Intelligence 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Learning representations for graphs plays a critical role in a wide spectrum\nof downstream applications. In this paper, we summarize the limitations of the\nprior works in three folds: representation space, modeling dynamics and\nmodeling uncertainty. To bridge this gap, we propose to learn dynamic graph\nrepresentation in hyperbolic space, for the first time, which aims to infer\nstochastic node representations. Working with hyperbolic space, we present a\nnovel Hyperbolic Variational Graph Neural Network, referred to as HVGNN. In\nparticular, to model the dynamics, we introduce a Temporal GNN (TGNN) based on\na theoretically grounded time encoding approach. To model the uncertainty, we\ndevise a hyperbolic graph variational autoencoder built upon the proposed TGNN\nto generate stochastic node representations of hyperbolic normal distributions.\nFurthermore, we introduce a reparameterisable sampling algorithm for the\nhyperbolic normal distribution to enable the gradient-based learning of HVGNN.\nExtensive experiments show that HVGNN outperforms state-of-the-art baselines on\nreal-world datasets.\n", "versions": [{"version": "v1", "created": "Tue, 6 Apr 2021 01:44:15 GMT"}], "update_date": "2021-04-07", "authors_parsed": [["Sun", "Li", ""], ["Zhang", "Zhongbao", ""], ["Zhang", "Jiawei", ""], ["Wang", "Feiyang", ""], ["Peng", "Hao", ""], ["Su", "Sen", ""], ["Yu", "Philip S.", ""]]}, {"id": "2104.02231", "submitter": "Satish Pokhrel", "authors": "Satish Pokhrel, Robert Abbas, Bhulok Aryal", "title": "IoT Security: Botnet detection in IoT using Machine learning", "comments": "11 pages, 23 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  The acceptance of Internet of Things (IoT) applications and services has seen\nan enormous rise of interest in IoT. Organizations have begun to create various\nIoT based gadgets ranging from small personal devices such as a smart watch to\na whole network of smart grid, smart mining, smart manufacturing, and\nautonomous driver-less vehicles. The overwhelming amount and ubiquitous\npresence have attracted potential hackers for cyber-attacks and data theft.\nSecurity is considered as one of the prominent challenges in IoT. The key scope\nof this research work is to propose an innovative model using machine learning\nalgorithm to detect and mitigate botnet-based distributed denial of service\n(DDoS) attack in IoT network. Our proposed model tackles the security issue\nconcerning the threats from bots. Different machine learning algorithms such as\nK- Nearest Neighbour (KNN), Naive Bayes model and Multi-layer Perception\nArtificial Neural Network (MLP ANN) were used to develop a model where data are\ntrained by BoT-IoT dataset. The best algorithm was selected by a reference\npoint based on accuracy percentage and area under the receiver operating\ncharacteristics curve (ROC AUC) score. Feature engineering and Synthetic\nminority oversampling technique (SMOTE) were combined with machine learning\nalgorithms (MLAs). Performance comparison of three algorithms used was done in\nclass imbalance dataset and on the class balanced dataset.\n", "versions": [{"version": "v1", "created": "Tue, 6 Apr 2021 01:47:50 GMT"}], "update_date": "2021-04-07", "authors_parsed": [["Pokhrel", "Satish", ""], ["Abbas", "Robert", ""], ["Aryal", "Bhulok", ""]]}, {"id": "2104.02233", "submitter": "Seyed Hamed Fatemi Langroudi", "authors": "Hamed F. Langroudi, Vedant Karia, Tej Pandit, Dhireesha Kudithipudi", "title": "TENT: Efficient Quantization of Neural Networks on the tiny Edge with\n  Tapered FixEd PoiNT", "comments": "poster presented at the first tinyML Research Symposium, March 26,\n  2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this research, we propose a new low-precision framework, TENT, to leverage\nthe benefits of a tapered fixed-point numerical format in TinyML models. We\nintroduce a tapered fixed-point quantization algorithm that matches the\nnumerical format's dynamic range and distribution to that of the deep neural\nnetwork model's parameter distribution at each layer. An accelerator\narchitecture for the tapered fixed-point with TENT framework is proposed.\nResults show that the accuracy on classification tasks improves up to ~31 %\nwith an energy overhead of ~17-30 % as compared to fixed-point, for ConvNet and\nResNet-18 models.\n", "versions": [{"version": "v1", "created": "Tue, 6 Apr 2021 01:54:32 GMT"}], "update_date": "2021-04-07", "authors_parsed": [["Langroudi", "Hamed F.", ""], ["Karia", "Vedant", ""], ["Pandit", "Tej", ""], ["Kudithipudi", "Dhireesha", ""]]}, {"id": "2104.02238", "submitter": "Alexandrea Ramnarine", "authors": "Alexandrea K. Ramnarine", "title": "In-Line Image Transformations for Imbalanced, Multiclass Computer Vision\n  Classification of Lung Chest X-Rays", "comments": "8 article pages, 4 article figures, 1 article table. 14 supplemental\n  pages with figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Artificial intelligence (AI) is disrupting the medical field as advances in\nmodern technology allow common household computers to learn anatomical and\npathological features that distinguish between healthy and disease with the\naccuracy of highly specialized, trained physicians. Computer vision AI\napplications use medical imaging, such as lung chest X-Rays (LCXRs), to\nfacilitate diagnoses by providing second-opinions in addition to a physician's\nor radiologist's interpretation. Considering the advent of the current\nCoronavirus disease (COVID-19) pandemic, LCXRs may provide rapid insights to\nindirectly aid in infection containment, however generating a reliably labeled\nimage dataset for a novel disease is not an easy feat, nor is it of highest\npriority when combating a global pandemic. Deep learning techniques such as\nconvolutional neural networks (CNNs) are able to select features that\ndistinguish between healthy and disease states for other lung pathologies; this\nstudy aims to leverage that body of literature in order to apply image\ntransformations that would serve to balance the lack of COVID-19 LCXR data.\nFurthermore, this study utilizes a simple CNN architecture for high-performance\nmulticlass LCXR classification at 94 percent accuracy.\n", "versions": [{"version": "v1", "created": "Tue, 6 Apr 2021 02:01:43 GMT"}], "update_date": "2021-04-07", "authors_parsed": [["Ramnarine", "Alexandrea K.", ""]]}, {"id": "2104.02240", "submitter": "Nengfeng Zhou", "authors": "Lian Yu, Nengfeng Zhou", "title": "Survey of Imbalanced Data Methodologies", "comments": "7 pages, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Imbalanced data set is a problem often found and well-studied in financial\nindustry. In this paper, we reviewed and compared some popular methodologies\nhandling data imbalance. We then applied the under-sampling/over-sampling\nmethodologies to several modeling algorithms on UCI and Keel data sets. The\nperformance was analyzed for class-imbalance methods, modeling algorithms and\ngrid search criteria comparison.\n", "versions": [{"version": "v1", "created": "Tue, 6 Apr 2021 02:10:22 GMT"}], "update_date": "2021-04-07", "authors_parsed": [["Yu", "Lian", ""], ["Zhou", "Nengfeng", ""]]}, {"id": "2104.02259", "submitter": "Yeonjong Shin", "authors": "Yeonjong Shin, J\\'er\\^ome Darbon, George Em Karniadakis", "title": "A Caputo fractional derivative-based algorithm for optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG cs.NA math.NA", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  We propose a novel Caputo fractional derivative-based optimization algorithm.\nUpon defining the Caputo fractional gradient with respect to the Cartesian\ncoordinate, we present a generic Caputo fractional gradient descent (CFGD)\nmethod. We prove that the CFGD yields the steepest descent direction of a\nlocally smoothed objective function. The generic CFGD requires three parameters\nto be specified, and a choice of the parameters yields a version of CFGD. We\npropose three versions -- non-adaptive, adaptive terminal and adaptive order.\nBy focusing on quadratic objective functions, we provide a convergence\nanalysis. We prove that the non-adaptive CFGD converges to a Tikhonov\nregularized solution. For the two adaptive versions, we derive error bounds,\nwhich show convergence to integer-order stationary point under some conditions.\nWe derive an explicit formula of CFGD for quadratic functions. We\ncomputationally found that the adaptive terminal (AT) CFGD mitigates the\ndependence on the condition number in the rate of convergence and results in\nsignificant acceleration over gradient descent (GD). For non-quadratic\nfunctions, we develop an efficient implementation of CFGD using the\nGauss-Jacobi quadrature, whose computational cost is approximately proportional\nto the number of the quadrature points and the cost of GD. Our numerical\nexamples show that AT-CFGD results in acceleration over GD, even when a small\nnumber of the Gauss-Jacobi quadrature points (including a single point) is\nused.\n", "versions": [{"version": "v1", "created": "Tue, 6 Apr 2021 03:01:14 GMT"}], "update_date": "2021-04-07", "authors_parsed": [["Shin", "Yeonjong", ""], ["Darbon", "J\u00e9r\u00f4me", ""], ["Karniadakis", "George Em", ""]]}, {"id": "2104.02261", "submitter": "Sanjay Kariyappa", "authors": "Sanjay Kariyappa, Ousmane Dia and Moinuddin K Qureshi", "title": "Enabling Inference Privacy with Adaptive Noise Injection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  User-facing software services are becoming increasingly reliant on remote\nservers to host Deep Neural Network (DNN) models, which perform inference tasks\nfor the clients. Such services require the client to send input data to the\nservice provider, who processes it using a DNN and returns the output\npredictions to the client. Due to the rich nature of the inputs such as images\nand speech, the input often contains more information than what is necessary to\nperform the primary inference task. Consequently, in addition to the primary\ninference task, a malicious service provider could infer secondary (sensitive)\nattributes from the input, compromising the client's privacy. The goal of our\nwork is to improve inference privacy by injecting noise to the input to hide\nthe irrelevant features that are not conducive to the primary classification\ntask. To this end, we propose Adaptive Noise Injection (ANI), which uses a\nlight-weight DNN on the client-side to inject noise to each input, before\ntransmitting it to the service provider to perform inference. Our key insight\nis that by customizing the noise to each input, we can achieve state-of-the-art\ntrade-off between utility and privacy (up to 48.5% degradation in\nsensitive-task accuracy with <1% degradation in primary accuracy),\nsignificantly outperforming existing noise injection schemes. Our method does\nnot require prior knowledge of the sensitive attributes and incurs minimal\ncomputational overheads.\n", "versions": [{"version": "v1", "created": "Tue, 6 Apr 2021 03:06:21 GMT"}], "update_date": "2021-04-07", "authors_parsed": [["Kariyappa", "Sanjay", ""], ["Dia", "Ousmane", ""], ["Qureshi", "Moinuddin K", ""]]}, {"id": "2104.02276", "submitter": "Faxi Yuan", "authors": "Faxi Yuan, Yuanchang Xu, Qingchun Li, Ali Mostafavi", "title": "Spatio-Temporal Graph Convolutional Networks for Road Network Inundation\n  Status Prediction during Urban Flooding", "comments": "15 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The objective of this study is to predict the near-future flooding status of\nroad segments based on their own and adjacent road segments current status\nthrough the use of deep learning framework on fine-grained traffic data.\nPredictive flood monitoring for situational awareness of road network status\nplays a critical role to support crisis response activities such as evaluation\nof the loss of access to hospitals and shelters. Existing studies related to\nnear-future prediction of road network flooding status at road segment level\nare missing. Using fine-grained traffic speed data related to road sections,\nthis study designed and implemented three spatio-temporal graph convolutional\nnetwork (STGCN) models to predict road network status during flood events at\nthe road segment level in the context of the 2017 Hurricane Harvey in Harris\nCounty (Texas, USA). Model 1 consists of two spatio-temporal blocks considering\nthe adjacency and distance between road segments, while Model 2 contains an\nadditional elevation block to account for elevation difference between road\nsegments. Model 3 includes three blocks for considering the adjacency and the\nproduct of distance and elevation difference between road segments. The\nanalysis tested the STGCN models and evaluated their prediction performance.\nOur results indicated that Model 1 and Model 2 have reliable and accurate\nperformance for predicting road network flooding status in near future (e.g.,\n2-4 hours) with model precision and recall values larger than 98% and 96%,\nrespectively. With reliable road network status predictions in floods, the\nproposed model can benefit affected communities to avoid flooded roads and the\nemergency management agencies to implement evacuation and relief resource\ndelivery plans.\n", "versions": [{"version": "v1", "created": "Tue, 6 Apr 2021 04:03:34 GMT"}], "update_date": "2021-04-07", "authors_parsed": [["Yuan", "Faxi", ""], ["Xu", "Yuanchang", ""], ["Li", "Qingchun", ""], ["Mostafavi", "Ali", ""]]}, {"id": "2104.02278", "submitter": "The Danh Phan", "authors": "Danh T. Phan and Hai L. Vu", "title": "A novel activity pattern generation incorporating deep learning for\n  transport demand models", "comments": "21 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.MA", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Activity generation plays an important role in activity-based demand\nmodelling systems. While machine learning, especially deep learning, has been\nincreasingly used for mode choice and traffic flow prediction, much less\nresearch exploiting the advantage of deep learning for activity generation\ntasks. This paper proposes a novel activity pattern generation framework by\nincorporating deep learning with travel domain knowledge. We model each\nactivity schedule as one primary activity tour and several secondary activity\ntours. We then develop different deep neural networks with entity embedding and\nrandom forest models to classify activity type, as well as to predict activity\ntimes. The proposed framework can capture the activity patterns for individuals\nin both training and validation sets. Results show high accuracy for the start\ntime and end time of work and school activities. The framework also replicates\nthe start time patterns of stop-before and stop-after primary work activity\nwell. This provides a promising direction to deploy advanced machine learning\nmethods to generate more reliable activity-travel patterns for transport demand\nsystems and their applications.\n", "versions": [{"version": "v1", "created": "Tue, 6 Apr 2021 04:07:05 GMT"}], "update_date": "2021-04-07", "authors_parsed": [["Phan", "Danh T.", ""], ["Vu", "Hai L.", ""]]}, {"id": "2104.02293", "submitter": "Chenjun Xiao", "authors": "Chenjun Xiao, Yifan Wu, Tor Lattimore, Bo Dai, Jincheng Mei, Lihong\n  Li, Csaba Szepesvari, Dale Schuurmans", "title": "On the Optimality of Batch Policy Optimization Algorithms", "comments": "29 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Batch policy optimization considers leveraging existing data for policy\nconstruction before interacting with an environment. Although interest in this\nproblem has grown significantly in recent years, its theoretical foundations\nremain under-developed. To advance the understanding of this problem, we\nprovide three results that characterize the limits and possibilities of batch\npolicy optimization in the finite-armed stochastic bandit setting. First, we\nintroduce a class of confidence-adjusted index algorithms that unifies\noptimistic and pessimistic principles in a common framework, which enables a\ngeneral analysis. For this family, we show that any confidence-adjusted index\nalgorithm is minimax optimal, whether it be optimistic, pessimistic or neutral.\nOur analysis reveals that instance-dependent optimality, commonly used to\nestablish optimality of on-line stochastic bandit algorithms, cannot be\nachieved by any algorithm in the batch setting. In particular, for any\nalgorithm that performs optimally in some environment, there exists another\nenvironment where the same algorithm suffers arbitrarily larger regret.\nTherefore, to establish a framework for distinguishing algorithms, we introduce\na new weighted-minimax criterion that considers the inherent difficulty of\noptimal value prediction. We demonstrate how this criterion can be used to\njustify commonly used pessimistic principles for batch policy optimization.\n", "versions": [{"version": "v1", "created": "Tue, 6 Apr 2021 05:23:20 GMT"}], "update_date": "2021-04-07", "authors_parsed": [["Xiao", "Chenjun", ""], ["Wu", "Yifan", ""], ["Lattimore", "Tor", ""], ["Dai", "Bo", ""], ["Mei", "Jincheng", ""], ["Li", "Lihong", ""], ["Szepesvari", "Csaba", ""], ["Schuurmans", "Dale", ""]]}, {"id": "2104.02297", "submitter": "Rui Wang", "authors": "Rui Wang, Xiaoqian Wang, David I. Inouye", "title": "Shapley Explanation Networks", "comments": "26 pages, 11 figures, accepted to ICLR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Shapley values have become one of the most popular feature attribution\nexplanation methods. However, most prior work has focused on post-hoc Shapley\nexplanations, which can be computationally demanding due to its exponential\ntime complexity and preclude model regularization based on Shapley explanations\nduring training. Thus, we propose to incorporate Shapley values themselves as\nlatent representations in deep models thereby making Shapley explanations\nfirst-class citizens in the modeling paradigm. This intrinsic explanation\napproach enables layer-wise explanations, explanation regularization of the\nmodel during training, and fast explanation computation at test time. We define\nthe Shapley transform that transforms the input into a Shapley representation\ngiven a specific function. We operationalize the Shapley transform as a neural\nnetwork module and construct both shallow and deep networks, called ShapNets,\nby composing Shapley modules. We prove that our Shallow ShapNets compute the\nexact Shapley values and our Deep ShapNets maintain the missingness and\naccuracy properties of Shapley values. We demonstrate on synthetic and\nreal-world datasets that our ShapNets enable layer-wise Shapley explanations,\nnovel Shapley regularizations during training, and fast computation while\nmaintaining reasonable performance. Code is available at\nhttps://github.com/inouye-lab/ShapleyExplanationNetworks.\n", "versions": [{"version": "v1", "created": "Tue, 6 Apr 2021 05:42:12 GMT"}], "update_date": "2021-04-07", "authors_parsed": [["Wang", "Rui", ""], ["Wang", "Xiaoqian", ""], ["Inouye", "David I.", ""]]}, {"id": "2104.02306", "submitter": "Tinglong Zhu", "authors": "Tinglong Zhu, Xiaoyi Qin, Ming Li", "title": "Binary Neural Network for Speaker Verification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although deep neural networks are successful for many tasks in the speech\ndomain, the high computational and memory costs of deep neural networks make it\ndifficult to directly deploy highperformance Neural Network systems on\nlow-resource embedded devices. There are several mechanisms to reduce the size\nof the neural networks i.e. parameter pruning, parameter quantization, etc.\nThis paper focuses on how to apply binary neural networks to the task of\nspeaker verification. The proposed binarization of training parameters can\nlargely maintain the performance while significantly reducing storage space\nrequirements and computational costs. Experiment results show that, after\nbinarizing the Convolutional Neural Network, the ResNet34-based network\nachieves an EER of around 5% on the Voxceleb1 testing dataset and even\noutperforms the traditional real number network on the text-dependent dataset:\nXiaole while having a 32x memory saving.\n", "versions": [{"version": "v1", "created": "Tue, 6 Apr 2021 06:04:57 GMT"}], "update_date": "2021-04-07", "authors_parsed": [["Zhu", "Tinglong", ""], ["Qin", "Xiaoyi", ""], ["Li", "Ming", ""]]}, {"id": "2104.02307", "submitter": "Marek Pecha", "authors": "Marek Pecha", "title": "Balancing Predictive Relevance of Ligand Biochemical Activities", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we present a technique for balancing predictive relevance\nmodels related to supervised modelling ligand biochemical activities to\nbiological targets. We train uncalibrated models employing conventional\nsupervised machine learning technique, namely Support Vector Machines.\nUnfortunately, SVMs have a serious drawback. They are sensitive to imbalanced\ndatasets, outliers and high multicollinearity among training samples, which\ncould be a cause of preferencing one group over another. Thus, an additional\ncalibration could be required for balancing a predictive relevance of models.\nAs a technique for this balancing, we propose the Platt's scaling. The achieved\nresults were demonstrated on single-target models trained on datasets exported\nfrom the ExCAPE database. Unlike traditional used machine techniques, we focus\non decreasing uncertainty employing deterministic solvers.\n", "versions": [{"version": "v1", "created": "Tue, 6 Apr 2021 06:05:13 GMT"}], "update_date": "2021-04-07", "authors_parsed": [["Pecha", "Marek", ""]]}, {"id": "2104.02309", "submitter": "Kai Middlebrook", "authors": "Kai Middlebrook, Shyam Sudhakaran, David Guy Brizan", "title": "MuSLCAT: Multi-Scale Multi-Level Convolutional Attention Transformer for\n  Discriminative Music Modeling on Raw Waveforms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this work, we aim to improve the expressive capacity of waveform-based\ndiscriminative music networks by modeling both sequential (temporal) and\nhierarchical information in an efficient end-to-end architecture. We present\nMuSLCAT, or Multi-scale and Multi-level Convolutional Attention Transformer, a\nnovel architecture for learning robust representations of complex music tags\ndirectly from raw waveform recordings. We also introduce a lightweight variant\nof MuSLCAT called MuSLCAN, short for Multi-scale and Multi-level Convolutional\nAttention Network. Both MuSLCAT and MuSLCAN model features from multiple scales\nand levels by integrating a frontend-backend architecture. The frontend targets\ndifferent frequency ranges while modeling long-range dependencies and\nmulti-level interactions by using two convolutional attention networks with\nattention-augmented convolution (AAC) blocks. The backend dynamically\nrecalibrates multi-scale and level features extracted from the frontend by\nincorporating self-attention. The difference between MuSLCAT and MuSLCAN is\ntheir backend components. MuSLCAT's backend is a modified version of BERT.\nWhile MuSLCAN's is a simple AAC block. We validate the proposed MuSLCAT and\nMuSLCAN architectures by comparing them to state-of-the-art networks on four\nbenchmark datasets for music tagging and genre recognition. Our experiments\nshow that MuSLCAT and MuSLCAN consistently yield competitive results when\ncompared to state-of-the-art waveform-based models yet require considerably\nfewer parameters.\n", "versions": [{"version": "v1", "created": "Tue, 6 Apr 2021 06:17:22 GMT"}], "update_date": "2021-04-07", "authors_parsed": [["Middlebrook", "Kai", ""], ["Sudhakaran", "Shyam", ""], ["Brizan", "David Guy", ""]]}, {"id": "2104.02317", "submitter": "Yun Bai", "authors": "Yun Bai, Ganglin Tian, Yanfei Kang, Suling Jia", "title": "Enhancing the Diversity of Predictions Combination by Negative\n  Correlation Learning", "comments": "33 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predictions combination, as a combination model approach with adjustments in\nthe output space, has flourished in recent years in research and competitions.\nSimple average is intuitive and robust, and is often used as a benchmark in\npredictions combination. However, some poorly performing sub-models can reduce\nthe overall accuracy because the sub-models are not selected in advance. Even\nthough some studies have selected the top sub-models for the combination after\nranking them by mean square error, the covariance of them causes this approach\nto not yield much benefit. In this paper, we suggest to consider the diversity\nof sub-models in the predictions combination, which can be adopted to assist in\nselecting the most diverse model subset in the model pool using negative\ncorrelation learning. Three publicly available datasets are applied to evaluate\nthe approach. The experimental results not only show the diversity of\nsub-models in the predictions combination incorporating negative correlation\nlearning, but also produce predictions with accuracy far exceeding that of the\nsimple average benchmark and some weighted average methods. Furthermore, by\nadjusting the penalty strength for negative correlation, the predictions\ncombination also outperform the best sub-model. The value of this paper lies in\nits ease of use and effectiveness, allowing the predictions combination to\nembrace both diversity and accuracy.\n", "versions": [{"version": "v1", "created": "Tue, 6 Apr 2021 06:45:14 GMT"}], "update_date": "2021-04-07", "authors_parsed": [["Bai", "Yun", ""], ["Tian", "Ganglin", ""], ["Kang", "Yanfei", ""], ["Jia", "Suling", ""]]}, {"id": "2104.02321", "submitter": "Junhyeok Lee", "authors": "Junhyeok Lee and Seungu Han", "title": "NU-Wave: A Diffusion Probabilistic Model for Neural Audio Upsampling", "comments": "Accepted to Interspeech 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we introduce NU-Wave, the first neural audio upsampling model\nto produce waveforms of sampling rate 48kHz from coarse 16kHz or 24kHz inputs,\nwhile prior works could generate only up to 16kHz. NU-Wave is the first\ndiffusion probabilistic model for audio super-resolution which is engineered\nbased on neural vocoders. NU-Wave generates high-quality audio that achieves\nhigh performance in terms of signal-to-noise ratio (SNR), log-spectral distance\n(LSD), and accuracy of the ABX test. In all cases, NU-Wave outperforms the\nbaseline models despite the substantially smaller model capacity (3.0M\nparameters) than baselines (5.4-21%). The audio samples of our model are\navailable at https://mindslab-ai.github.io/nuwave, and the code will be made\navailable soon.\n", "versions": [{"version": "v1", "created": "Tue, 6 Apr 2021 06:52:53 GMT"}, {"version": "v2", "created": "Thu, 17 Jun 2021 04:36:40 GMT"}], "update_date": "2021-06-18", "authors_parsed": [["Lee", "Junhyeok", ""], ["Han", "Seungu", ""]]}, {"id": "2104.02322", "submitter": "Mehrdad Khani", "authors": "Mehrdad Khani, Vibhaalakshmi Sivaraman, Mohammad Alizadeh", "title": "Efficient Video Compression via Content-Adaptive Super-Resolution", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Video compression is a critical component of Internet video delivery. Recent\nwork has shown that deep learning techniques can rival or outperform\nhuman-designed algorithms, but these methods are significantly less compute and\npower-efficient than existing codecs. This paper presents a new approach that\naugments existing codecs with a small, content-adaptive super-resolution model\nthat significantly boosts video quality. Our method, SRVC, encodes video into\ntwo bitstreams: (i) a content stream, produced by compressing downsampled\nlow-resolution video with the existing codec, (ii) a model stream, which\nencodes periodic updates to a lightweight super-resolution neural network\ncustomized for short segments of the video. SRVC decodes the video by passing\nthe decompressed low-resolution video frames through the (time-varying)\nsuper-resolution model to reconstruct high-resolution video frames. Our results\nshow that to achieve the same PSNR, SRVC requires 16% of the bits-per-pixel of\nH.265 in slow mode, and 2% of the bits-per-pixel of DVC, a recent deep\nlearning-based video compression scheme. SRVC runs at 90 frames per second on a\nNVIDIA V100 GPU.\n", "versions": [{"version": "v1", "created": "Tue, 6 Apr 2021 07:01:06 GMT"}], "update_date": "2021-04-07", "authors_parsed": [["Khani", "Mehrdad", ""], ["Sivaraman", "Vibhaalakshmi", ""], ["Alizadeh", "Mohammad", ""]]}, {"id": "2104.02324", "submitter": "Tianning Yuan", "authors": "Tianning Yuan (1), Fang Wan (1), Mengying Fu (1), Jianzhuang Liu (2),\n  Songcen Xu (2), Xiangyang Ji (3), Qixiang Ye (1) ((1) University of Chinese\n  Academy of Sciences, Beijing, China, (2) Noah's Ark Lab, Huawei Technologies,\n  Shenzhen, China, (3) Tsinghua University, Beijing, China)", "title": "Multiple instance active learning for object detection", "comments": "10 pages, 7 figures, 5 tables. Code is available at\n  https://github.com/yuantn/MI-AOD", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the substantial progress of active learning for image recognition,\nthere still lacks an instance-level active learning method specified for object\ndetection. In this paper, we propose Multiple Instance Active Object Detection\n(MI-AOD), to select the most informative images for detector training by\nobserving instance-level uncertainty. MI-AOD defines an instance uncertainty\nlearning module, which leverages the discrepancy of two adversarial instance\nclassifiers trained on the labeled set to predict instance uncertainty of the\nunlabeled set. MI-AOD treats unlabeled images as instance bags and feature\nanchors in images as instances, and estimates the image uncertainty by\nre-weighting instances in a multiple instance learning (MIL) fashion. Iterative\ninstance uncertainty learning and re-weighting facilitate suppressing noisy\ninstances, toward bridging the gap between instance uncertainty and image-level\nuncertainty. Experiments validate that MI-AOD sets a solid baseline for\ninstance-level active learning. On commonly used object detection datasets,\nMI-AOD outperforms state-of-the-art methods with significant margins,\nparticularly when the labeled sets are small. Code is available at\nhttps://github.com/yuantn/MI-AOD.\n", "versions": [{"version": "v1", "created": "Tue, 6 Apr 2021 07:03:38 GMT"}], "update_date": "2021-04-07", "authors_parsed": [["Yuan", "Tianning", ""], ["Wan", "Fang", ""], ["Fu", "Mengying", ""], ["Liu", "Jianzhuang", ""], ["Xu", "Songcen", ""], ["Ji", "Xiangyang", ""], ["Ye", "Qixiang", ""]]}, {"id": "2104.02334", "submitter": "Abed AlRahman Al Makdah", "authors": "Abed AlRahman Al Makdah and Vaibhav Katewa and Fabio Pasqualetti", "title": "Taming Adversarial Robustness via Abstaining", "comments": "Submitted to CDC 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we consider a binary classification problem and cast it into a\nbinary hypothesis testing framework, where the observations can be perturbed by\nan adversary. To improve the adversarial robustness of a classifier, we include\nan abstaining option, where the classifier abstains from taking a decision when\nit has low confidence about the prediction. We propose metrics to quantify the\nnominal performance of a classifier with abstaining option and its robustness\nagainst adversarial perturbations. We show that there exist a tradeoff between\nthe two metrics regardless of what method is used to choose the abstaining\nregion. Our results imply that the robustness of a classifier with abstaining\ncan only be improved at the expense of its nominal performance. Further, we\nprovide necessary conditions to design the abstaining region for a\n1-dimensional binary classification problem. We validate our theoretical\nresults on the MNIST dataset, where we numerically show that the tradeoff\nbetween performance and robustness also exist for the general multi-class\nclassification problems.\n", "versions": [{"version": "v1", "created": "Tue, 6 Apr 2021 07:36:48 GMT"}], "update_date": "2021-04-07", "authors_parsed": [["Makdah", "Abed AlRahman Al", ""], ["Katewa", "Vaibhav", ""], ["Pasqualetti", "Fabio", ""]]}, {"id": "2104.02369", "submitter": "Axel Kroener", "authors": "Elisa Giesecke and Axel Kr\\\"oner", "title": "Point classification with Runge-Kutta networks and feature space\n  augmentation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we combine an approach based on Runge-Kutta Nets considered in\n[\\emph{Benning et al., J. Comput. Dynamics, 9, 2019}] and a technique on\naugmenting the input space in [\\emph{Dupont et al., NeurIPS}, 2019] to obtain\nnetwork architectures which show a better numerical performance for deep neural\nnetworks in point classification problems. The approach is illustrated with\nseveral examples implemented in PyTorch.\n", "versions": [{"version": "v1", "created": "Tue, 6 Apr 2021 08:54:30 GMT"}], "update_date": "2021-04-07", "authors_parsed": [["Giesecke", "Elisa", ""], ["Kr\u00f6ner", "Axel", ""]]}, {"id": "2104.02372", "submitter": "Ido Greenberg", "authors": "Ido Greenberg, Netanel Yannay, Shie Mannor", "title": "Noise Estimation Is Not Optimal: How to Use Kalman Filter the Right Way", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Determining the noise parameters of a Kalman Filter (KF) has been studied for\ndecades. A huge body of research focuses on the task of estimation of the noise\nunder various conditions, since precise noise estimation is considered\nequivalent to minimization of the filtering errors. However, we show that even\na small violation of the KF assumptions can significantly modify the effective\nnoise, breaking the equivalence between the tasks and making noise estimation\nan inferior strategy. We show that such violations are very common, and are\noften not trivial to handle or even notice. Consequentially, we argue that a\nrobust solution is needed - rather than choosing a dedicated model per problem.\nTo that end, we apply gradient-based optimization to the filtering errors\ndirectly, with relation to a simple and efficient parameterization of the\nsymmetric and positive-definite parameters of KF. In radar tracking and video\ntracking, we show that the optimization improves both the accuracy of KF and\nits robustness to design decisions. In addition, we demonstrate how an\noptimized neural network model can seem to reduce the errors significantly\ncompared to a KF - and how this reduction vanishes once the KF is optimized\nsimilarly. This indicates how complicated models can be wrongly identified as\nsuperior to KF, while in fact they were merely more optimized.\n", "versions": [{"version": "v1", "created": "Tue, 6 Apr 2021 08:59:15 GMT"}, {"version": "v2", "created": "Tue, 4 May 2021 00:05:58 GMT"}, {"version": "v3", "created": "Thu, 20 May 2021 16:54:57 GMT"}], "update_date": "2021-05-21", "authors_parsed": [["Greenberg", "Ido", ""], ["Yannay", "Netanel", ""], ["Mannor", "Shie", ""]]}, {"id": "2104.02373", "submitter": "Joachim Schreurs", "authors": "Joachim Schreurs, Hannes De Meulemeester, Micha\\\"el Fanuel, Bart De\n  Moor and Johan A.K. Suykens", "title": "Leverage Score Sampling for Complete Mode Coverage in Generative\n  Adversarial Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Commonly, machine learning models minimize an empirical expectation. As a\nresult, the trained models typically perform well for the majority of the data\nbut the performance may deteriorate in less dense regions of the dataset. This\nissue also arises in generative modeling. A generative model may overlook\nunderrepresented modes that are less frequent in the empirical data\ndistribution. This problem is known as complete mode coverage. We propose a\nsampling procedure based on ridge leverage scores which significantly improves\nmode coverage when compared to standard methods and can easily be combined with\nany GAN. Ridge leverage scores are computed by using an explicit feature map,\nassociated with the next-to-last layer of a GAN discriminator or of a\npre-trained network, or by using an implicit feature map corresponding to a\nGaussian kernel. Multiple evaluations against recent approaches of complete\nmode coverage show a clear improvement when using the proposed sampling\nstrategy.\n", "versions": [{"version": "v1", "created": "Tue, 6 Apr 2021 09:00:38 GMT"}, {"version": "v2", "created": "Tue, 27 Apr 2021 14:38:50 GMT"}, {"version": "v3", "created": "Wed, 21 Jul 2021 07:51:18 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Schreurs", "Joachim", ""], ["De Meulemeester", "Hannes", ""], ["Fanuel", "Micha\u00ebl", ""], ["De Moor", "Bart", ""], ["Suykens", "Johan A. K.", ""]]}, {"id": "2104.02381", "submitter": "Paridhi Maheshwari", "authors": "Paridhi Maheshwari, Ritwick Chaudhry, Vishwa Vinay", "title": "Scene Graph Embeddings Using Relative Similarity Supervision", "comments": "Accepted to AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Scene graphs are a powerful structured representation of the underlying\ncontent of images, and embeddings derived from them have been shown to be\nuseful in multiple downstream tasks. In this work, we employ a graph\nconvolutional network to exploit structure in scene graphs and produce image\nembeddings useful for semantic image retrieval. Different from\nclassification-centric supervision traditionally available for learning image\nrepresentations, we address the task of learning from relative similarity\nlabels in a ranking context. Rooted within the contrastive learning paradigm,\nwe propose a novel loss function that operates on pairs of similar and\ndissimilar images and imposes relative ordering between them in embedding\nspace. We demonstrate that this Ranking loss, coupled with an intuitive triple\nsampling strategy, leads to robust representations that outperform well-known\ncontrastive losses on the retrieval task. In addition, we provide qualitative\nevidence of how retrieved results that utilize structured scene information\ncapture the global context of the scene, different from visual similarity\nsearch.\n", "versions": [{"version": "v1", "created": "Tue, 6 Apr 2021 09:13:05 GMT"}], "update_date": "2021-04-07", "authors_parsed": [["Maheshwari", "Paridhi", ""], ["Chaudhry", "Ritwick", ""], ["Vinay", "Vishwa", ""]]}, {"id": "2104.02388", "submitter": "Khoat Than", "authors": "Khoat Than and Nghia Vu", "title": "Generalization of GANs under Lipschitz continuity and data augmentation", "comments": "25 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Generative adversarial networks (GANs) have been being widely used in various\napplications. Arguably, GANs are really complex, and little has been known\nabout their generalization. In this paper, we make a comprehensive analysis\nabout generalization of GANs. We decompose the generalization error into an\nexplicit composition: generator error + discriminator error + optimization\nerror. The first two errors show the capacity of the player's families, are\nirreducible and optimizer-independent. We then provide both uniform and\nnon-uniform generalization bounds in different scenarios, thanks to our new\nbridge between Lipschitz continuity and generalization. Our bounds overcome\nsome major limitations of existing ones. In particular, our bounds show that\npenalizing the zero- and first-order informations of the GAN loss will improve\ngeneralization, answering the long mystery of why imposing a Lipschitz\nconstraint can help GANs perform better in practice. Finally, we show why data\naugmentation penalizes the zero- and first-order informations of the loss,\nhelping the players generalize better, and hence explaining the highly\nsuccessful use of data augmentation for GANs.\n", "versions": [{"version": "v1", "created": "Tue, 6 Apr 2021 09:24:10 GMT"}], "update_date": "2021-04-07", "authors_parsed": [["Than", "Khoat", ""], ["Vu", "Nghia", ""]]}, {"id": "2104.02395", "submitter": "M Tanveer PhD", "authors": "M.A. Ganaie (1) and Minghui Hu (2) and M. Tanveer*(1) and P.N.\n  Suganthan*(2) (* Corresponding Author (1) Department of Mathematics, Indian\n  Institute of Technology Indore, Simrol, Indore, 453552, India (2) School of\n  Electrical & Electronic Engineering, Nanyang Technological University,\n  Singapore)", "title": "Ensemble deep learning: A review", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ensemble learning combines several individual models to obtain better\ngeneralization performance. Currently, deep learning models with multilayer\nprocessing architecture is showing better performance as compared to the\nshallow or traditional classification models. Deep ensemble learning models\ncombine the advantages of both the deep learning models as well as the ensemble\nlearning such that the final model has better generalization performance. This\npaper reviews the state-of-art deep ensemble models and hence serves as an\nextensive summary for the researchers. The ensemble models are broadly\ncategorised into ensemble models like bagging, boosting and stacking, negative\ncorrelation based deep ensemble models, explicit/implicit ensembles,\nhomogeneous /heterogeneous ensemble, decision fusion strategies, unsupervised,\nsemi-supervised, reinforcement learning and online/incremental, multilabel\nbased deep ensemble models. Application of deep ensemble models in different\ndomains is also briefly discussed. Finally, we conclude this paper with some\nfuture recommendations and research directions.\n", "versions": [{"version": "v1", "created": "Tue, 6 Apr 2021 09:56:29 GMT"}], "update_date": "2021-04-07", "authors_parsed": [["Ganaie", "M. A.", ""], ["Hu", "Minghui", ""], ["Tanveer*", "M.", ""], ["Suganthan*", "P. N.", ""]]}, {"id": "2104.02397", "submitter": "Branislav Gerazov", "authors": "Branislav Gerazov and Michael Wagner", "title": "ProsoBeast Prosody Annotation Tool", "comments": "Accepted at Interspeech 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The labelling of speech corpora is a laborious and time-consuming process.\nThe ProsoBeast Annotation Tool seeks to ease and accelerate this process by\nproviding an interactive 2D representation of the prosodic landscape of the\ndata, in which contours are distributed based on their similarity. This\ninteractive map allows the user to inspect and label the utterances. The tool\nintegrates several state-of-the-art methods for dimensionality reduction and\nfeature embedding, including variational autoencoders. The user can use these\nto find a good representation for their data. In addition, as most of these\nmethods are stochastic, each can be used to generate an unlimited number of\ndifferent prosodic maps. The web app then allows the user to seamlessly switch\nbetween these alternative representations in the annotation process.\nExperiments with a sample prosodically rich dataset have shown that the tool\nmanages to find good representations of varied data and is helpful both for\nannotation and label correction. The tool is released as free software for use\nby the community.\n", "versions": [{"version": "v1", "created": "Tue, 6 Apr 2021 10:04:48 GMT"}, {"version": "v2", "created": "Tue, 15 Jun 2021 07:40:36 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Gerazov", "Branislav", ""], ["Wagner", "Michael", ""]]}, {"id": "2104.02410", "submitter": "Alessio Ferrari", "authors": "Alessio Ferrari, Thaide Huichapa, Paola Spoletini, Nicole Novielli,\n  Davide Fucci, Daniela Girardi", "title": "Using Voice and Biofeedback to Predict User Engagement during\n  Requirements Interviews", "comments": "We discovered issues in the code used for the experiments, and we\n  need to run them again. While the method reported in the paper is correct,\n  the results are not", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Capturing users engagement is crucial for gathering feedback about the\nfeatures of a software product. In a market-driven context, current approaches\nto collect and analyze users feedback are based on techniques leveraging\ninformation extracted from product reviews and social media. These approaches\nare hardly applicable in bespoke software development, or in contexts in which\none needs to gather information from specific users. In such cases, companies\nneed to resort to face-to-face interviews to get feedback on their products. In\nthis paper, we propose to utilize biometric data, in terms of physiological and\nvoice features, to complement interviews with information about the engagement\nof the user on the discussed product-relevant topics. We evaluate our approach\nby interviewing users while gathering their physiological data (i.e.,\nbiofeedback) using an Empatica E4 wristband, and capturing their voice through\nthe default audio-recorder of a common laptop. Our results show that we can\npredict users' engagement by training supervised machine learning algorithms on\nbiometric data, and that voice features alone can be sufficiently effective.\nThe performance of the prediction algorithms is maximised when pre-processing\nthe training data with the synthetic minority oversampling technique (SMOTE).\nThe results of our work suggest that biofeedback and voice analysis can be used\nto facilitate prioritization of requirements oriented to product improvement,\nand to steer the interview based on users' engagement. Furthermore, the usage\nof voice features can be particularly helpful for emotion-aware requirements\nelicitation in remote communication, either performed by human analysts or\nvoice-based chatbots.\n", "versions": [{"version": "v1", "created": "Tue, 6 Apr 2021 10:34:36 GMT"}, {"version": "v2", "created": "Wed, 16 Jun 2021 16:28:52 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Ferrari", "Alessio", ""], ["Huichapa", "Thaide", ""], ["Spoletini", "Paola", ""], ["Novielli", "Nicole", ""], ["Fucci", "Davide", ""], ["Girardi", "Daniela", ""]]}, {"id": "2104.02411", "submitter": "Arash Bahari Kordabad", "authors": "Arash Bahari Kordabad, Wenqi Cai, Sebastien Gros", "title": "MPC-based Reinforcement Learning for Economic Problems with Application\n  to Battery Storage", "comments": "This paper has been accepted to ECC2021. 6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we are interested in optimal control problems with purely\neconomic costs, which often yield optimal policies having a (nearly) bang-bang\nstructure. We focus on policy approximations based on Model Predictive Control\n(MPC) and the use of the deterministic policy gradient method to optimize the\nMPC closed-loop performance in the presence of unmodelled stochasticity or\nmodel error. When the policy has a (nearly) bang-bang structure, we observe\nthat the policy gradient method can struggle to produce meaningful steps in the\npolicy parameters. To tackle this issue, we propose a homotopy strategy based\non the interior-point method, providing a relaxation of the policy during the\nlearning. We investigate a specific well-known battery storage problem, and\nshow that the proposed method delivers a homogeneous and faster learning than a\nclassical policy gradient approach.\n", "versions": [{"version": "v1", "created": "Tue, 6 Apr 2021 10:37:14 GMT"}], "update_date": "2021-04-07", "authors_parsed": [["Kordabad", "Arash Bahari", ""], ["Cai", "Wenqi", ""], ["Gros", "Sebastien", ""]]}, {"id": "2104.02416", "submitter": "Diego Martin Arroyo", "authors": "Diego Martin Arroyo, Janis Postels and Federico Tombari", "title": "Variational Transformer Networks for Layout Generation", "comments": "To be published in CVPR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative models able to synthesize layouts of different kinds (e.g.\ndocuments, user interfaces or furniture arrangements) are a useful tool to aid\ndesign processes and as a first step in the generation of synthetic data, among\nother tasks. We exploit the properties of self-attention layers to capture high\nlevel relationships between elements in a layout, and use these as the building\nblocks of the well-known Variational Autoencoder (VAE) formulation. Our\nproposed Variational Transformer Network (VTN) is capable of learning margins,\nalignments and other global design rules without explicit supervision. Layouts\nsampled from our model have a high degree of resemblance to the training data,\nwhile demonstrating appealing diversity. In an extensive evaluation on publicly\navailable benchmarks for different layout types VTNs achieve state-of-the-art\ndiversity and perceptual quality. Additionally, we show the capabilities of\nthis method as part of a document layout detection pipeline.\n", "versions": [{"version": "v1", "created": "Tue, 6 Apr 2021 10:45:53 GMT"}], "update_date": "2021-04-07", "authors_parsed": [["Arroyo", "Diego Martin", ""], ["Postels", "Janis", ""], ["Tombari", "Federico", ""]]}, {"id": "2104.02433", "submitter": "Xinyi Zhang", "authors": "Xinyi Zhang, Lihui Chen", "title": "mSHINE: A Multiple-meta-paths Simultaneous Learning Framework for\n  Heterogeneous Information Network Embedding", "comments": "Accpeted by TKDE, code is available at https://github.com/XinyiZ001", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Heterogeneous information networks(HINs) become popular in recent years for\nits strong capability of modelling objects with abundant information using\nexplicit network structure. Network embedding has been proved as an effective\nmethod to convert information networks into lower-dimensional space, whereas\nthe core information can be well preserved. However, traditional network\nembedding algorithms are sub-optimal in capturing rich while potentially\nincompatible semantics provided by HINs. To address this issue, a novel\nmeta-path-based HIN representation learning framework named mSHINE is designed\nto simultaneously learn multiple node representations for different meta-paths.\nMore specifically, one representation learning module inspired by the RNN\nstructure is developed and multiple node representations can be learned\nsimultaneously, where each representation is associated with one respective\nmeta-path. By measuring the relevance between nodes with the designed objective\nfunction, the learned module can be applied in downstream link prediction\ntasks. A set of criteria for selecting initial meta-paths is proposed as the\nother module in mSHINE which is important to reduce the optimal meta-path\nselection cost when no prior knowledge of suitable meta-paths is available. To\ncorroborate the effectiveness of mSHINE, extensive experimental studies\nincluding node classification and link prediction are conducted on five\nreal-world datasets. The results demonstrate that mSHINE outperforms other\nstate-of-the-art HIN embedding methods.\n", "versions": [{"version": "v1", "created": "Tue, 6 Apr 2021 11:35:56 GMT"}, {"version": "v2", "created": "Fri, 9 Apr 2021 06:40:05 GMT"}], "update_date": "2021-04-12", "authors_parsed": [["Zhang", "Xinyi", ""], ["Chen", "Lihui", ""]]}, {"id": "2104.02443", "submitter": "Ahmed Elnaggar", "authors": "Ahmed Elnaggar, Wei Ding, Llion Jones, Tom Gibbs, Tamas Feher,\n  Christoph Angerer, Silvia Severini, Florian Matthes and Burkhard Rost", "title": "CodeTrans: Towards Cracking the Language of Silicon's Code Through\n  Self-Supervised Deep Learning and High Performance Computing", "comments": "28 pages, 6 tables and 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.AI cs.CL cs.LG cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Currently, a growing number of mature natural language processing\napplications make people's life more convenient. Such applications are built by\nsource code - the language in software engineering. However, the applications\nfor understanding source code language to ease the software engineering process\nare under-researched. Simultaneously, the transformer model, especially its\ncombination with transfer learning, has been proven to be a powerful technique\nfor natural language processing tasks. These breakthroughs point out a\npromising direction for process source code and crack software engineering\ntasks. This paper describes CodeTrans - an encoder-decoder transformer model\nfor tasks in the software engineering domain, that explores the effectiveness\nof encoder-decoder transformer models for six software engineering tasks,\nincluding thirteen sub-tasks. Moreover, we have investigated the effect of\ndifferent training strategies, including single-task learning, transfer\nlearning, multi-task learning, and multi-task learning with fine-tuning.\nCodeTrans outperforms the state-of-the-art models on all the tasks. To expedite\nfuture works in the software engineering domain, we have published our\npre-trained models of CodeTrans. https://github.com/agemagician/CodeTrans\n", "versions": [{"version": "v1", "created": "Tue, 6 Apr 2021 11:57:12 GMT"}, {"version": "v2", "created": "Wed, 12 May 2021 06:51:32 GMT"}], "update_date": "2021-05-13", "authors_parsed": [["Elnaggar", "Ahmed", ""], ["Ding", "Wei", ""], ["Jones", "Llion", ""], ["Gibbs", "Tom", ""], ["Feher", "Tamas", ""], ["Angerer", "Christoph", ""], ["Severini", "Silvia", ""], ["Matthes", "Florian", ""], ["Rost", "Burkhard", ""]]}, {"id": "2104.02452", "submitter": "Rishikesh Ranade", "authors": "Rishikesh Ranade, Chris Hill, Haiyang He, Amir Maleki, Jay Pathak", "title": "A Latent space solver for PDE generalization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this work we propose a hybrid solver to solve partial differential\nequation (PDE)s in the latent space. The solver uses an iterative inferencing\nstrategy combined with solution initialization to improve generalization of PDE\nsolutions. The solver is tested on an engineering case and the results show\nthat it can generalize well to several PDE conditions.\n", "versions": [{"version": "v1", "created": "Tue, 6 Apr 2021 12:16:53 GMT"}], "update_date": "2021-04-07", "authors_parsed": [["Ranade", "Rishikesh", ""], ["Hill", "Chris", ""], ["He", "Haiyang", ""], ["Maleki", "Amir", ""], ["Pathak", "Jay", ""]]}, {"id": "2104.02459", "submitter": "Andr\\'e Artelt", "authors": "Andr\\'e Artelt, Fabian Hinder, Valerie Vaquet, Robert Feldhans,\n  Barbara Hammer", "title": "Contrastive Explanations for Explaining Model Adaptations", "comments": "Fix some typos", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many decision making systems deployed in the real world are not static - a\nphenomenon known as model adaptation takes place over time. The need for\ntransparency and interpretability of AI-based decision models is widely\naccepted and thus have been worked on extensively. Usually, explanation methods\nassume a static system that has to be explained. Explaining non-static systems\nis still an open research question, which poses the challenge how to explain\nmodel adaptations. In this contribution, we propose and (empirically) evaluate\na framework for explaining model adaptations by contrastive explanations. We\nalso propose a method for automatically finding regions in data space that are\naffected by a given model adaptation and thus should be explained.\n", "versions": [{"version": "v1", "created": "Tue, 6 Apr 2021 12:35:23 GMT"}, {"version": "v2", "created": "Wed, 7 Apr 2021 07:09:30 GMT"}], "update_date": "2021-04-08", "authors_parsed": [["Artelt", "Andr\u00e9", ""], ["Hinder", "Fabian", ""], ["Vaquet", "Valerie", ""], ["Feldhans", "Robert", ""], ["Hammer", "Barbara", ""]]}, {"id": "2104.02464", "submitter": "Prerit Terway", "authors": "Prerit Terway, Kenza Hamidouche, and Niraj K. Jha", "title": "Fast Design Space Exploration of Nonlinear Systems: Part II", "comments": "14 pages, 24 figures. arXiv admin note: substantial text overlap with\n  arXiv:2009.10214", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.AI cs.LG cs.NE cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nonlinear system design is often a multi-objective optimization problem\ninvolving search for a design that satisfies a number of predefined\nconstraints. The design space is typically very large since it includes all\npossible system architectures with different combinations of components\ncomposing each architecture. In this article, we address nonlinear system\ndesign space exploration through a two-step approach encapsulated in a\nframework called Fast Design Space Exploration of Nonlinear Systems (ASSENT).\nIn the first step, we use a genetic algorithm to search for system\narchitectures that allow discrete choices for component values or else only\ncomponent values for a fixed architecture. This step yields a coarse design\nsince the system may or may not meet the target specifications. In the second\nstep, we use an inverse design to search over a continuous space and fine-tune\nthe component values with the goal of improving the value of the objective\nfunction. We use a neural network to model the system response. The neural\nnetwork is converted into a mixed-integer linear program for active learning to\nsample component values efficiently. We illustrate the efficacy of ASSENT on\nproblems ranging from nonlinear system design to design of electrical circuits.\nExperimental results show that ASSENT achieves the same or better value of the\nobjective function compared to various other optimization techniques for\nnonlinear system design by up to 54%. We improve sample efficiency by 6-10x\ncompared to reinforcement learning based synthesis of electrical circuits.\n", "versions": [{"version": "v1", "created": "Mon, 5 Apr 2021 16:11:50 GMT"}, {"version": "v2", "created": "Thu, 8 Apr 2021 19:35:15 GMT"}], "update_date": "2021-04-12", "authors_parsed": [["Terway", "Prerit", ""], ["Hamidouche", "Kenza", ""], ["Jha", "Niraj K.", ""]]}, {"id": "2104.02466", "submitter": "Caterina Urban", "authors": "Caterina Urban and Antoine Min\\'e", "title": "A Review of Formal Methods applied to Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LG cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We review state-of-the-art formal methods applied to the emerging field of\nthe verification of machine learning systems. Formal methods can provide\nrigorous correctness guarantees on hardware and software systems. Thanks to the\navailability of mature tools, their use is well established in the industry,\nand in particular to check safety-critical applications as they undergo a\nstringent certification process. As machine learning is becoming more popular,\nmachine-learned components are now considered for inclusion in critical\nsystems. This raises the question of their safety and their verification. Yet,\nestablished formal methods are limited to classic, i.e. non machine-learned\nsoftware. Applying formal methods to verify systems that include machine\nlearning has only been considered recently and poses novel challenges in\nsoundness, precision, and scalability.\n  We first recall established formal methods and their current use in an\nexemplar safety-critical field, avionic software, with a focus on abstract\ninterpretation based techniques as they provide a high level of scalability.\nThis provides a golden standard and sets high expectations for machine learning\nverification. We then provide a comprehensive and detailed review of the formal\nmethods developed so far for machine learning, highlighting their strengths and\nlimitations. The large majority of them verify trained neural networks and\nemploy either SMT, optimization, or abstract interpretation techniques. We also\ndiscuss methods for support vector machines and decision tree ensembles, as\nwell as methods targeting training and data preparation, which are critical but\noften neglected aspects of machine learning. Finally, we offer perspectives for\nfuture research directions towards the formal verification of machine learning\nsystems.\n", "versions": [{"version": "v1", "created": "Tue, 6 Apr 2021 12:48:17 GMT"}, {"version": "v2", "created": "Wed, 21 Apr 2021 15:32:51 GMT"}], "update_date": "2021-04-22", "authors_parsed": [["Urban", "Caterina", ""], ["Min\u00e9", "Antoine", ""]]}, {"id": "2104.02468", "submitter": "Sanghoon Myung", "authors": "Sanghoon Myung, Hyunjae Jang, Byungseon Choi, Jisu Ryu, Hyuk Kim, Sang\n  Wuk Park, Changwook Jeong and Dae Sin Kim", "title": "A Novel Approach for Semiconductor Etching Process with Inductive Biases", "comments": "5 pages; accepted to NeurIPS 2020 Workshop on Interpretable Inductive\n  Biases and Physically Structured Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG physics.comp-ph physics.plasm-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The etching process is one of the most important processes in semiconductor\nmanufacturing. We have introduced the state-of-the-art deep learning model to\npredict the etching profiles. However, the significant problems violating\nphysics have been found through various techniques such as explainable\nartificial intelligence and representation of prediction uncertainty. To\naddress this problem, this paper presents a novel approach to apply the\ninductive biases for etching process. We demonstrate that our approach fits the\nmeasurement faster than physical simulator while following the physical\nbehavior. Our approach would bring a new opportunity for better etching process\nwith higher accuracy and lower cost.\n", "versions": [{"version": "v1", "created": "Tue, 6 Apr 2021 12:51:52 GMT"}], "update_date": "2021-04-07", "authors_parsed": [["Myung", "Sanghoon", ""], ["Jang", "Hyunjae", ""], ["Choi", "Byungseon", ""], ["Ryu", "Jisu", ""], ["Kim", "Hyuk", ""], ["Park", "Sang Wuk", ""], ["Jeong", "Changwook", ""], ["Kim", "Dae Sin", ""]]}, {"id": "2104.02469", "submitter": "Kiran Karra", "authors": "Kiran Karra, Alan McCree", "title": "Speaker Diarization using Two-pass Leave-One-Out Gaussian PLDA\n  Clustering of DNN Embeddings", "comments": "5 pages, 2 figures, accepted at INTERSPEECH 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many modern systems for speaker diarization, such as the recently-developed\nVBx approach, rely on clustering of DNN speaker embeddings followed by\nresegmentation. Two problems with this approach are that the DNN is not\ndirectly optimized for this task, and the parameters need significant retuning\nfor different applications. We have recently presented progress in this\ndirection with a Leave-One-Out Gaussian PLDA (LGP) clustering algorithm and an\napproach to training the DNN such that embeddings directly optimize performance\nof this scoring method. This paper presents a new two-pass version of this\nsystem, where the second pass uses finer time resolution to significantly\nimprove overall performance. For the Callhome corpus, we achieve the first\npublished error rate below 4% without any task-dependent parameter tuning. We\nalso show significant progress towards a robust single solution for multiple\ndiarization tasks.\n", "versions": [{"version": "v1", "created": "Tue, 6 Apr 2021 12:52:55 GMT"}, {"version": "v2", "created": "Wed, 7 Apr 2021 01:39:17 GMT"}, {"version": "v3", "created": "Mon, 14 Jun 2021 22:23:12 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Karra", "Kiran", ""], ["McCree", "Alan", ""]]}, {"id": "2104.02472", "submitter": "Yang Tao Dr.", "authors": "Tian Meng, Yang Tao, Ziqi Chen, Jorge R. Salas Avila, Qiaoye Ran,\n  Yuchun Shao, Ruochen Huang, Yuedong Xie, Qian Zhao, Zhijie Zhang, Hujun Yin,\n  Anthony J. Peyton, and Wuliang Yin", "title": "Depth Evaluation for Metal Surface Defects by Eddy Current Testing using\n  Deep Residual Convolutional Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.IV eess.SP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Eddy current testing (ECT) is an effective technique in the evaluation of the\ndepth of metal surface defects. However, in practice, the evaluation primarily\nrelies on the experience of an operator and is often carried out by manual\ninspection. In this paper, we address the challenges of automatic depth\nevaluation of metal surface defects by virtual of state-of-the-art deep\nlearning (DL) techniques. The main contributions are three-fold. Firstly, a\nhighly-integrated portable ECT device is developed, which takes advantage of an\nadvanced field programmable gate array (Zynq-7020 system on chip) and provides\nfast data acquisition and in-phase/quadrature demodulation. Secondly, a\ndataset, termed as MDDECT, is constructed using the ECT device by human\noperators and made openly available. It contains 48,000 scans from 18 defects\nof different depths and lift-offs. Thirdly, the depth evaluation problem is\nformulated as a time series classification problem, and various\nstate-of-the-art 1-d residual convolutional neural networks are trained and\nevaluated on the MDDECT dataset. A 38-layer 1-d ResNeXt achieves an accuracy of\n93.58% in discriminating the surface defects in a stainless steel sheet. The\ndepths of the defects vary from 0.3 mm to 2.0 mm in a resolution of 0.1 mm. In\naddition, results show that the trained ResNeXt1D-38 model is immune to\nlift-off signals.\n", "versions": [{"version": "v1", "created": "Mon, 8 Mar 2021 17:38:36 GMT"}], "update_date": "2021-04-07", "authors_parsed": [["Meng", "Tian", ""], ["Tao", "Yang", ""], ["Chen", "Ziqi", ""], ["Avila", "Jorge R. Salas", ""], ["Ran", "Qiaoye", ""], ["Shao", "Yuchun", ""], ["Huang", "Ruochen", ""], ["Xie", "Yuedong", ""], ["Zhao", "Qian", ""], ["Zhang", "Zhijie", ""], ["Yin", "Hujun", ""], ["Peyton", "Anthony J.", ""], ["Yin", "Wuliang", ""]]}, {"id": "2104.02475", "submitter": "Jirong Yi", "authors": "Jirong Yi", "title": "Solving Large Scale Quadratic Constrained Basis Pursuit", "comments": "5 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.IT cs.LG eess.SP math.IT", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Inspired by alternating direction method of multipliers and the idea of\noperator splitting, we propose a efficient algorithm for solving large-scale\nquadratically constrained basis pursuit. Experimental results show that the\nproposed algorithm can achieve 50~~100 times speedup when compared with the\nbaseline interior point algorithm implemented in CVX.\n", "versions": [{"version": "v1", "created": "Fri, 2 Apr 2021 18:26:18 GMT"}], "update_date": "2021-04-07", "authors_parsed": [["Yi", "Jirong", ""]]}, {"id": "2104.02477", "submitter": "Madhurananda Pahar", "authors": "Madhurananda Pahar, Thomas Niesler", "title": "Deep Transfer Learning based COVID-19 Detection in Cough, Breath and\n  Speech using Bottleneck Features", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present an experimental investigation into the automatic detection of\nCOVID-19 from coughs, breaths and speech as this type of screening is\nnon-contact, does not require specialist medical expertise or laboratory\nfacilities and can easily be deployed on inexpensive consumer hardware.\n  Smartphone recordings of cough, breath and speech from subjects around the\nglobe are used for classification by seven standard machine learning\nclassifiers using leave-$p$-out cross-validation to provide a promising\nbaseline performance.\n  Then, a diverse dataset of 10.29 hours of cough, sneeze, speech and noise\naudio recordings are used to pre-train a CNN, LSTM and Resnet50 classifier and\nfine tuned the model to enhance the performance even further.\n  We have also extracted the bottleneck features from these pre-trained models\nby removing the final-two layers and used them as an input to the LR, SVM, MLP\nand KNN classifiers to detect COVID-19 signature.\n  The highest AUC of 0.98 was achieved using a transfer learning based Resnet50\narchitecture on coughs from Coswara dataset.\n  The highest AUC of 0.94 and 0.92 was achieved from an SVM run on the\nbottleneck features extracted from the breaths from Coswara dataset and speech\nrecordings from ComParE dataset.\n  We conclude that among all vocal audio, coughs carry the strongest COVID-19\nsignature followed by breath and speech and using transfer learning improves\nthe classifier performance with higher AUC and lower variance across the\ncross-validation folds.\n  Although these signatures are not perceivable by human ear, machine learning\nbased COVID-19 detection is possible from vocal audio recorded via smartphone.\n", "versions": [{"version": "v1", "created": "Fri, 2 Apr 2021 23:21:24 GMT"}, {"version": "v2", "created": "Mon, 12 Apr 2021 22:14:59 GMT"}, {"version": "v3", "created": "Tue, 27 Jul 2021 15:03:56 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Pahar", "Madhurananda", ""], ["Niesler", "Thomas", ""]]}, {"id": "2104.02478", "submitter": "Rui Song", "authors": "Rui Song and Fausto Giunchiglia and Ke Zhao and Hao Xu", "title": "Topological Regularization for Graph Neural Networks Augmentation", "comments": "20 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The complexity and non-Euclidean structure of graph data hinder the\ndevelopment of data augmentation methods similar to those in computer vision.\nIn this paper, we propose a feature augmentation method for graph nodes based\non topological regularization, in which topological structure information is\nintroduced into end-to-end model. Specifically, we first obtain topology\nembedding of nodes through unsupervised representation learning method based on\nrandom walk. Then, the topological embedding as additional features and the\noriginal node features are input into a dual graph neural network for\npropagation, and two different high-order neighborhood representations of nodes\nare obtained. On this basis, we propose a regularization technique to bridge\nthe differences between the two different node representations, eliminate the\nadverse effects caused by the topological features of graphs directly used, and\ngreatly improve the performance. We have carried out extensive experiments on a\nlarge number of datasets to prove the effectiveness of our model.\n", "versions": [{"version": "v1", "created": "Sat, 3 Apr 2021 01:37:44 GMT"}], "update_date": "2021-04-07", "authors_parsed": [["Song", "Rui", ""], ["Giunchiglia", "Fausto", ""], ["Zhao", "Ke", ""], ["Xu", "Hao", ""]]}, {"id": "2104.02479", "submitter": "Bojing Feng", "authors": "Bojing Feng, Wenfang Xue", "title": "Adversarial Semi-supervised Learning for Corporate Credit Ratings", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Corporate credit rating is an analysis of credit risks within a corporation,\nwhich plays a vital role during the management of financial risk.\nTraditionally, the rating assessment process based on the historical profile of\ncorporation is usually expensive and complicated, which often takes months.\nTherefore, most of the corporations, which are lacking in money and time, can't\nget their own credit level. However, we believe that although these\ncorporations haven't their credit rating levels (unlabeled data), this big data\ncontains useful knowledge to improve credit system. In this work, its major\nchallenge lies in how to effectively learn the knowledge from unlabeled data\nand help improve the performance of the credit rating system. Specifically, we\nconsider the problem of adversarial semi-supervised learning (ASSL) for\ncorporate credit rating which has been rarely researched before. A novel\nframework adversarial semi-supervised learning for corporate credit rating\n(ASSL4CCR) which includes two phases is proposed to address these problems. In\nthe first phase, we train a normal rating system via a normal machine-learning\nalgorithm to give unlabeled data pseudo rating level. Then in the second phase,\nadversarial semi-supervised learning is applied uniting labeled data and\npseudo-labeled data. To demonstrate the effectiveness of the proposed ASSL4CCR,\nwe conduct extensive experiments on the Chinese public-listed corporate rating\ndataset, which proves that ASSL4CCR outperforms the state-of-the-art methods\nconsistently.\n", "versions": [{"version": "v1", "created": "Sun, 4 Apr 2021 09:05:53 GMT"}, {"version": "v2", "created": "Mon, 12 Apr 2021 02:45:03 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Feng", "Bojing", ""], ["Xue", "Wenfang", ""]]}, {"id": "2104.02481", "submitter": "Ashkan Khakzar", "authors": "Ashkan Khakzar, Sabrina Musatian, Jonas Buchberger, Icxel Valeriano\n  Quiroz, Nikolaus Pinger, Soroosh Baselizadeh, Seong Tae Kim, Nassir Navab", "title": "Towards Semantic Interpretation of Thoracic Disease and COVID-19\n  Diagnosis Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional neural networks are showing promise in the automatic diagnosis\nof thoracic pathologies on chest x-rays. Their black-box nature has sparked\nmany recent works to explain the prediction via input feature attribution\nmethods (aka saliency methods). However, input feature attribution methods\nmerely identify the importance of input regions for the prediction and lack\nsemantic interpretation of model behavior. In this work, we first identify the\nsemantics associated with internal units (feature maps) of the network. We\nproceed to investigate the following questions; Does a regression model that is\nonly trained with COVID-19 severity scores implicitly learn visual patterns\nassociated with thoracic pathologies? Does a network that is trained on weakly\nlabeled data (e.g. healthy, unhealthy) implicitly learn pathologies? Moreover,\nwe investigate the effect of pretraining and data imbalance on the\ninterpretability of learned features. In addition to the analysis, we propose\nsemantic attribution to semantically explain each prediction. We present our\nfindings using publicly available chest pathologies (CheXpert, NIH ChestX-ray8)\nand COVID-19 datasets (BrixIA, and COVID-19 chest X-ray segmentation dataset).\nThe Code is publicly available.\n", "versions": [{"version": "v1", "created": "Sun, 4 Apr 2021 17:35:13 GMT"}], "update_date": "2021-04-07", "authors_parsed": [["Khakzar", "Ashkan", ""], ["Musatian", "Sabrina", ""], ["Buchberger", "Jonas", ""], ["Quiroz", "Icxel Valeriano", ""], ["Pinger", "Nikolaus", ""], ["Baselizadeh", "Soroosh", ""], ["Kim", "Seong Tae", ""], ["Navab", "Nassir", ""]]}, {"id": "2104.02484", "submitter": "Petr Marek", "authors": "Petr Marek, Vishal Ishwar Naik, Vincent Auvray, Anuj Goyal", "title": "OodGAN: Generative Adversarial Network for Out-of-Domain Data Generation", "comments": "NAACL 2021 Industry track", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Detecting an Out-of-Domain (OOD) utterance is crucial for a robust dialog\nsystem. Most dialog systems are trained on a pool of annotated OOD data to\nachieve this goal. However, collecting the annotated OOD data for a given\ndomain is an expensive process. To mitigate this issue, previous works have\nproposed generative adversarial networks (GAN) based models to generate OOD\ndata for a given domain automatically. However, these proposed models do not\nwork directly with the text. They work with the text's latent space instead,\nenforcing these models to include components responsible for encoding text into\nlatent space and decoding it back, such as auto-encoder. These components\nincrease the model complexity, making it difficult to train. We propose OodGAN,\na sequential generative adversarial network (SeqGAN) based model for OOD data\ngeneration. Our proposed model works directly on the text and hence eliminates\nthe need to include an auto-encoder. OOD data generated using OodGAN model\noutperforms state-of-the-art in OOD detection metrics for ROSTD (67% relative\nimprovement in FPR 0.95) and OSQ datasets (28% relative improvement in FPR\n0.95) (Zheng et al., 2020).\n", "versions": [{"version": "v1", "created": "Tue, 6 Apr 2021 13:08:39 GMT"}], "update_date": "2021-04-07", "authors_parsed": [["Marek", "Petr", ""], ["Naik", "Vishal Ishwar", ""], ["Auvray", "Vincent", ""], ["Goyal", "Anuj", ""]]}, {"id": "2104.02487", "submitter": "Zhongkai Shangguan", "authors": "Zhongkai Shangguan and Lei Lin and Wencheng Wu and Beilei Xu", "title": "Neural Process for Black-Box Model Optimization Under Bayesian Framework", "comments": "This paper has been accepted to AAAI-MLPS 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SY", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  There are a large number of optimization problems in physical models where\nthe relationships between model parameters and outputs are unknown or hard to\ntrack. These models are named as black-box models in general because they can\nonly be viewed in terms of inputs and outputs, without knowledge of the\ninternal workings. Optimizing the black-box model parameters has become\nincreasingly expensive and time consuming as they have become more complex.\nHence, developing effective and efficient black-box model optimization\nalgorithms has become an important task. One powerful algorithm to solve such\nproblem is Bayesian optimization, which can effectively estimates the model\nparameters that lead to the best performance, and Gaussian Process (GP) has\nbeen one of the most widely used surrogate model in Bayesian optimization.\nHowever, the time complexity of GP scales cubically with respect to the number\nof observed model outputs, and GP does not scale well with large parameter\ndimension either. Consequently, it has been challenging for GP to optimize\nblack-box models that need to query many observations and/or have many\nparameters. To overcome the drawbacks of GP, in this study, we propose a\ngeneral Bayesian optimization algorithm that employs a Neural Process (NP) as\nthe surrogate model to perform black-box model optimization, namely, Neural\nProcess for Bayesian Optimization (NPBO). In order to validate the benefits of\nNPBO, we compare NPBO with four benchmark approaches on a power system\nparameter optimization problem and a series of seven benchmark Bayesian\noptimization problems. The results show that the proposed NPBO performs better\nthan the other four benchmark approaches on the power system parameter\noptimization problem and competitively on the seven benchmark problems.\n", "versions": [{"version": "v1", "created": "Sat, 3 Apr 2021 23:35:26 GMT"}], "update_date": "2021-04-07", "authors_parsed": [["Shangguan", "Zhongkai", ""], ["Lin", "Lei", ""], ["Wu", "Wencheng", ""], ["Xu", "Beilei", ""]]}, {"id": "2104.02493", "submitter": "Ole Schumann", "authors": "Ole Schumann, Markus Hahn, Nicolas Scheiner, Fabio Weishaupt, Julius\n  F. Tilly, J\\\"urgen Dickmann, Christian W\\\"ohler", "title": "RadarScenes: A Real-World Radar Point Cloud Data Set for Automotive\n  Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new automotive radar data set with measurements and point-wise annotations\nfrom more than four hours of driving is presented. Data provided by four series\nradar sensors mounted on one test vehicle were recorded and the individual\ndetections of dynamic objects were manually grouped to clusters and labeled\nafterwards. The purpose of this data set is to enable the development of novel\n(machine learning-based) radar perception algorithms with the focus on moving\nroad users. Images of the recorded sequences were captured using a documentary\ncamera. For the evaluation of future object detection and classification\nalgorithms, proposals for score calculation are made so that researchers can\nevaluate their algorithms on a common basis. Additional information as well as\ndownload instructions can be found on the website of the data set:\nwww.radar-scenes.com.\n", "versions": [{"version": "v1", "created": "Tue, 6 Apr 2021 13:22:23 GMT"}], "update_date": "2021-04-07", "authors_parsed": [["Schumann", "Ole", ""], ["Hahn", "Markus", ""], ["Scheiner", "Nicolas", ""], ["Weishaupt", "Fabio", ""], ["Tilly", "Julius F.", ""], ["Dickmann", "J\u00fcrgen", ""], ["W\u00f6hler", "Christian", ""]]}, {"id": "2104.02496", "submitter": "Matthias A{\\ss}enmacher", "authors": "P. Schulze, S. Wiegrebe, P. W. Thurner, C. Heumann, M. A{\\ss}enmacher,\n  S. Wankm\\\"uller", "title": "Exploring Topic-Metadata Relationships with the STM: A Bayesian Approach", "comments": "8 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Topic models such as the Structural Topic Model (STM) estimate latent topical\nclusters within text. An important step in many topic modeling applications is\nto explore relationships between the discovered topical structure and metadata\nassociated with the text documents. Methods used to estimate such relationships\nmust take into account that the topical structure is not directly observed, but\ninstead being estimated itself. The authors of the STM, for instance, perform\nrepeated OLS regressions of sampled topic proportions on metadata covariates by\nusing a Monte Carlo sampling technique known as the method of composition. In\nthis paper, we propose two improvements: first, we replace OLS with more\nappropriate Beta regression. Second, we suggest a fully Bayesian approach\ninstead of the current blending of frequentist and Bayesian methods. We\ndemonstrate our improved methodology by exploring relationships between Twitter\nposts by German members of parliament (MPs) and different metadata covariates.\n", "versions": [{"version": "v1", "created": "Tue, 6 Apr 2021 13:28:04 GMT"}], "update_date": "2021-04-07", "authors_parsed": [["Schulze", "P.", ""], ["Wiegrebe", "S.", ""], ["Thurner", "P. W.", ""], ["Heumann", "C.", ""], ["A\u00dfenmacher", "M.", ""], ["Wankm\u00fcller", "S.", ""]]}, {"id": "2104.02523", "submitter": "Anh Nguyen", "authors": "Anh Nguyen, Khoa Pham, Dat Ngo, Thanh Ngo, Lam Pham", "title": "An Analysis of State-of-the-art Activation Functions For Supervised Deep\n  Neural Network", "comments": "6 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper provides an analysis of state-of-the-art activation functions with\nrespect to supervised classification of deep neural network. These activation\nfunctions comprise of Rectified Linear Units (ReLU), Exponential Linear Unit\n(ELU), Scaled Exponential Linear Unit (SELU), Gaussian Error Linear Unit\n(GELU), and the Inverse Square Root Linear Unit (ISRLU). To evaluate,\nexperiments over two deep learning network architectures integrating these\nactivation functions are conducted. The first model, basing on Multilayer\nPerceptron (MLP), is evaluated with MNIST dataset to perform these activation\nfunctions. Meanwhile, the second model, likely VGGish-based architecture, is\napplied for Acoustic Scene Classification (ASC) Task 1A in DCASE 2018\nchallenge, thus evaluate whether these activation functions work well in\ndifferent datasets as well as different network architectures.\n", "versions": [{"version": "v1", "created": "Mon, 5 Apr 2021 16:50:31 GMT"}], "update_date": "2021-04-07", "authors_parsed": [["Nguyen", "Anh", ""], ["Pham", "Khoa", ""], ["Ngo", "Dat", ""], ["Ngo", "Thanh", ""], ["Pham", "Lam", ""]]}, {"id": "2104.02526", "submitter": "Anton Mitrofanov", "authors": "Anton Mitrofanov, Mariya Korenevskaya, Ivan Podluzhny, Yuri Khokhlov,\n  Aleksandr Laptev, Andrei Andrusenko, Aleksei Ilin, Maxim Korenevsky, Ivan\n  Medennikov, Aleksei Romanenko", "title": "LT-LM: a novel non-autoregressive language model for single-shot lattice\n  rescoring", "comments": "Submitted to InterSpeech 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural network-based language models are commonly used in rescoring\napproaches to improve the quality of modern automatic speech recognition (ASR)\nsystems. Most of the existing methods are computationally expensive since they\nuse autoregressive language models. We propose a novel rescoring approach,\nwhich processes the entire lattice in a single call to the model. The key\nfeature of our rescoring policy is a novel non-autoregressive Lattice\nTransformer Language Model (LT-LM). This model takes the whole lattice as an\ninput and predicts a new language score for each arc. Additionally, we propose\nthe artificial lattices generation approach to incorporate a large amount of\ntext data in the LT-LM training process. Our single-shot rescoring performs\norders of magnitude faster than other rescoring methods in our experiments. It\nis more than 300 times faster than pruned RNNLM lattice rescoring and N-best\nrescoring while slightly inferior in terms of WER.\n", "versions": [{"version": "v1", "created": "Tue, 6 Apr 2021 14:06:07 GMT"}], "update_date": "2021-04-07", "authors_parsed": [["Mitrofanov", "Anton", ""], ["Korenevskaya", "Mariya", ""], ["Podluzhny", "Ivan", ""], ["Khokhlov", "Yuri", ""], ["Laptev", "Aleksandr", ""], ["Andrusenko", "Andrei", ""], ["Ilin", "Aleksei", ""], ["Korenevsky", "Maxim", ""], ["Medennikov", "Ivan", ""], ["Romanenko", "Aleksei", ""]]}, {"id": "2104.02532", "submitter": "Tal Feldman", "authors": "Tal Feldman and Ashley Peake", "title": "End-To-End Bias Mitigation: Removing Gender Bias in Deep Learning", "comments": "9 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine Learning models have been deployed across many different aspects of\nsociety, often in situations that affect social welfare. Although these models\noffer streamlined solutions to large problems, they may contain biases and\ntreat groups or individuals unfairly based on protected attributes such as\ngender. In this paper, we introduce several examples of machine learning gender\nbias in practice followed by formalizations of fairness. We provide a survey of\nfairness research by detailing influential pre-processing, in-processing, and\npost-processing bias mitigation algorithms. We then propose an end-to-end bias\nmitigation framework, which employs a fusion of pre-, in-, and post-processing\nmethods to leverage the strengths of each individual technique. We test this\nmethod, along with the standard techniques we review, on a deep neural network\nto analyze bias mitigation in a deep learning setting. We find that our\nend-to-end bias mitigation framework outperforms the baselines with respect to\nseveral fairness metrics, suggesting its promise as a method for improving\nfairness. As society increasingly relies on artificial intelligence to help in\ndecision-making, addressing gender biases present in deep learning models is\nimperative. To provide readers with the tools to assess the fairness of machine\nlearning models and mitigate the biases present in them, we discuss multiple\nopen source packages for fairness in AI.\n", "versions": [{"version": "v1", "created": "Tue, 6 Apr 2021 14:11:16 GMT"}, {"version": "v2", "created": "Fri, 18 Jun 2021 02:32:06 GMT"}, {"version": "v3", "created": "Mon, 21 Jun 2021 01:48:24 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Feldman", "Tal", ""], ["Peake", "Ashley", ""]]}, {"id": "2104.02548", "submitter": "Meghna P Ayyar", "authors": "Meghna P Ayyar, Jenny Benois-Pineau, Akka Zemmari", "title": "White Box Methods for Explanations of Convolutional Neural Networks in\n  Image Classification Tasks", "comments": "Submitted to Journal of Electronic Imaging (JEI)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In recent years, deep learning has become prevalent to solve applications\nfrom multiple domains. Convolutional Neural Networks (CNNs) particularly have\ndemonstrated state of the art performance for the task of image classification.\nHowever, the decisions made by these networks are not transparent and cannot be\ndirectly interpreted by a human. Several approaches have been proposed to\nexplain to understand the reasoning behind a prediction made by a network. In\nthis paper, we propose a topology of grouping these methods based on their\nassumptions and implementations. We focus primarily on white box methods that\nleverage the information of the internal architecture of a network to explain\nits decision. Given the task of image classification and a trained CNN, this\nwork aims to provide a comprehensive and detailed overview of a set of methods\nthat can be used to create explanation maps for a particular image, that assign\nan importance score to each pixel of the image based on its contribution to the\ndecision of the network. We also propose a further classification of the white\nbox methods based on their implementations to enable better comparisons and\nhelp researchers find methods best suited for different scenarios.\n", "versions": [{"version": "v1", "created": "Tue, 6 Apr 2021 14:40:00 GMT"}], "update_date": "2021-04-07", "authors_parsed": [["Ayyar", "Meghna P", ""], ["Benois-Pineau", "Jenny", ""], ["Zemmari", "Akka", ""]]}, {"id": "2104.02550", "submitter": "Sergey Alyaev", "authors": "Kristian Fossum, Sergey Alyaev, Jan Tveranger, Ahmed Elsheikh", "title": "Deep learning for prediction of complex geology ahead of drilling", "comments": "Accepted to ICCS 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  During a geosteering operation the well path is intentionally adjusted in\nresponse to the new data acquired while drilling. To achieve consistent\nhigh-quality decisions, especially when drilling in complex environments,\ndecision support systems can help cope with high volumes of data and\ninterpretation complexities. They can assimilate the real-time measurements\ninto a probabilistic earth model and use the updated model for decision\nrecommendations.\n  Recently, machine learning (ML) techniques have enabled a wide range of\nmethods that redistribute computational cost from on-line to off-line\ncalculations. In this paper, we introduce two ML techniques into the\ngeosteering decision support framework. Firstly, a complex earth model\nrepresentation is generated using a Generative Adversarial Network (GAN).\nSecondly, a commercial extra-deep electromagnetic simulator is represented\nusing a Forward Deep Neural Network (FDNN).\n  The numerical experiments demonstrate that the combination of the GAN and the\nFDNN in an ensemble randomized maximum likelihood data assimilation scheme\nprovides real-time estimates of complex geological uncertainty. This yields\nreduction of geological uncertainty ahead of the drill-bit from the\nmeasurements gathered behind and around the well bore.\n", "versions": [{"version": "v1", "created": "Tue, 6 Apr 2021 14:42:33 GMT"}], "update_date": "2021-04-07", "authors_parsed": [["Fossum", "Kristian", ""], ["Alyaev", "Sergey", ""], ["Tveranger", "Jan", ""], ["Elsheikh", "Ahmed", ""]]}, {"id": "2104.02555", "submitter": "Tim-Oliver Buchholz", "authors": "Tim-Oliver Buchholz and Florian Jug", "title": "Fourier Image Transformer", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Transformer architectures show spectacular performance on NLP tasks and have\nrecently also been used for tasks such as image completion or image\nclassification. Here we propose to use a sequential image representation, where\neach prefix of the complete sequence describes the whole image at reduced\nresolution. Using such Fourier Domain Encodings (FDEs), an auto-regressive\nimage completion task is equivalent to predicting a higher resolution output\ngiven a low-resolution input. Additionally, we show that an encoder-decoder\nsetup can be used to query arbitrary Fourier coefficients given a set of\nFourier domain observations. We demonstrate the practicality of this approach\nin the context of computed tomography (CT) image reconstruction. In summary, we\nshow that Fourier Image Transformer (FIT) can be used to solve relevant image\nanalysis tasks in Fourier space, a domain inherently inaccessible to\nconvolutional architectures.\n", "versions": [{"version": "v1", "created": "Tue, 6 Apr 2021 14:48:57 GMT"}, {"version": "v2", "created": "Mon, 3 May 2021 10:29:54 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Buchholz", "Tim-Oliver", ""], ["Jug", "Florian", ""]]}, {"id": "2104.02556", "submitter": "Eric Antonelo", "authors": "Eric Aislan Antonelo, Eduardo Camponogara, Laio Oriel Seman, Eduardo\n  Rehbein de Souza, Jean P. Jordanou, Jomi F. Hubner", "title": "Physics-Informed Neural Nets-based Control", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Physics-informed neural networks (PINNs) impose known physical laws into the\nlearning of deep neural networks, making sure they respect the physics of the\nprocess while decreasing the demand of labeled data. For systems represented by\nOrdinary Differential Equations (ODEs), the conventional PINN has a continuous\ntime input variable and outputs the solution of the corresponding ODE. In their\noriginal form, PINNs do not allow control inputs neither can they simulate for\nlong-range intervals without serious degradation in their predictions. In this\ncontext, this work presents a new framework called Physics-Informed Neural\nNets-based Control (PINC), which proposes a novel PINN-based architecture that\nis amenable to control problems and able to simulate for longer-range time\nhorizons that are not fixed beforehand. First, the network is augmented with\nnew inputs to account for the initial state of the system and the control\naction. Then, the response over the complete time horizon is split such that\neach smaller interval constitutes a solution of the ODE conditioned on the\nfixed values of initial state and control action. The complete response is\nformed by setting the initial state of the next interval to the terminal state\nof the previous one. The new methodology enables the optimal control of dynamic\nsystems, making feasible to integrate a priori knowledge from experts and data\ncollected from plants in control applications. We showcase our method in the\ncontrol of two nonlinear dynamic systems: the Van der Pol oscillator and the\nfour-tank system.\n", "versions": [{"version": "v1", "created": "Tue, 6 Apr 2021 14:55:23 GMT"}], "update_date": "2021-04-07", "authors_parsed": [["Antonelo", "Eric Aislan", ""], ["Camponogara", "Eduardo", ""], ["Seman", "Laio Oriel", ""], ["de Souza", "Eduardo Rehbein", ""], ["Jordanou", "Jean P.", ""], ["Hubner", "Jomi F.", ""]]}, {"id": "2104.02558", "submitter": "Apoorv Vyas", "authors": "Apoorv Vyas, Srikanth Madikeri, Herv\\'e Bourlard", "title": "Comparing CTC and LFMMI for out-of-domain adaptation of wav2vec 2.0\n  acoustic model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we investigate if the wav2vec 2.0 self-supervised pretraining\nhelps mitigate the overfitting issues with connectionist temporal\nclassification (CTC) training to reduce its performance gap with flat-start\nlattice-free MMI (E2E-LFMMI) for automatic speech recognition with limited\ntraining data. Towards that objective, we use the pretrained wav2vec 2.0 BASE\nmodel and fine-tune it on three different datasets including out-of-domain\n(Switchboard) and cross-lingual (Babel) scenarios. Our results show that for\nsupervised adaptation of the wav2vec 2.0 model, both E2E-LFMMI and CTC achieve\nsimilar results; significantly outperforming the baselines trained only with\nsupervised data. Fine-tuning the wav2vec 2.0 model with E2E-LFMMI and CTC we\nobtain the following relative WER improvements over the supervised baseline\ntrained with E2E-LFMMI. We get relative improvements of 40% and 44% on the\nclean-set and 64% and 58% on the test set of Librispeech (100h) respectively.\nOn Switchboard (300h) we obtain relative improvements of 33% and 35%\nrespectively. Finally, for Babel languages, we obtain relative improvements of\n26% and 23% on Swahili (38h) and 18% and 17% on Tagalog (84h) respectively.\n", "versions": [{"version": "v1", "created": "Tue, 6 Apr 2021 14:56:04 GMT"}], "update_date": "2021-04-07", "authors_parsed": [["Vyas", "Apoorv", ""], ["Madikeri", "Srikanth", ""], ["Bourlard", "Herv\u00e9", ""]]}, {"id": "2104.02562", "submitter": "Daniel Cummings", "authors": "Daniel Cummings, Marcel Nassar", "title": "Structured Citation Trend Prediction Using Graph Neural Networks", "comments": "Appeared in IEEE International Conference on Acoustics, Speech and\n  Signal Processing (ICASSP) 2020. 5 pages, 5 figures", "journal-ref": null, "doi": "10.1109/ICASSP40776.2020.9054769", "report-no": null, "categories": "cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Academic citation graphs represent citation relationships between\npublications across the full range of academic fields. Top cited papers\ntypically reveal future trends in their corresponding domains which is of\nimportance to both researchers and practitioners. Prior citation prediction\nmethods often require initial citation trends to be established and do not take\nadvantage of the recent advancements in graph neural networks (GNNs). We\npresent GNN-based architecture that predicts the top set of papers at the time\nof publication. For experiments, we curate a set of academic citation graphs\nfor a variety of conferences and show that the proposed model outperforms other\nclassic machine learning models in terms of the F1-score.\n", "versions": [{"version": "v1", "created": "Tue, 6 Apr 2021 14:58:29 GMT"}], "update_date": "2021-04-07", "authors_parsed": [["Cummings", "Daniel", ""], ["Nassar", "Marcel", ""]]}, {"id": "2104.02570", "submitter": "Hao Yang", "authors": "Hao Yang, Youzhi Jin, Ziyin Li, Deng-Bao Wang, Lei Miao, Xin Geng,\n  Min-Ling Zhang", "title": "Learning from Noisy Labels via Dynamic Loss Thresholding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Numerous researches have proved that deep neural networks (DNNs) can fit\neverything in the end even given data with noisy labels, and result in poor\ngeneralization performance. However, recent studies suggest that DNNs tend to\ngradually memorize the data, moving from correct data to mislabeled data.\nInspired by this finding, we propose a novel method named Dynamic Loss\nThresholding (DLT). During the training process, DLT records the loss value of\neach sample and calculates dynamic loss thresholds. Specifically, DLT compares\nthe loss value of each sample with the current loss threshold. Samples with\nsmaller losses can be considered as clean samples with higher probability and\nvice versa. Then, DLT discards the potentially corrupted labels and further\nleverages supervised learning techniques. Experiments on CIFAR-10/100 and\nClothing1M demonstrate substantial improvements over recent state-of-the-art\nmethods.\n  In addition, we investigate two real-world problems for the first time.\nFirstly, we propose a novel approach to estimate the noise rates of datasets\nbased on the loss difference between the early and late training stages of\nDNNs. Secondly, we explore the effect of hard samples (which are difficult to\nbe distinguished) on the process of learning from noisy labels.\n", "versions": [{"version": "v1", "created": "Thu, 1 Apr 2021 07:59:03 GMT"}], "update_date": "2021-04-07", "authors_parsed": [["Yang", "Hao", ""], ["Jin", "Youzhi", ""], ["Li", "Ziyin", ""], ["Wang", "Deng-Bao", ""], ["Miao", "Lei", ""], ["Geng", "Xin", ""], ["Zhang", "Min-Ling", ""]]}, {"id": "2104.02573", "submitter": "AKM Bahalul Haque", "authors": "Shahriar Rahman, Shazzadur Rahman and A K M Bahalul Haque", "title": "Prediction of Solar Radiation Using Artificial Neural Network", "comments": "Published as open access, 12 pages, 13 images and 2 tables", "journal-ref": "Journal of Physics: Conference Series , 2021", "doi": "10.1088/1742-6596/1767/1/012041", "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Most solar applications and systems can be reliably used to generate\nelectricity and power in many homes and offices. Recently, there is an increase\nin many solar required systems that can be found not only in electricity\ngeneration but other applications such as solar distillation, water heating,\nheating of buildings, meteorology and producing solar conversion energy.\nPrediction of solar radiation is very significant in order to accomplish the\npreviously mentioned objectives. In this paper, the main target is to present\nan algorithm that can be used to predict an hourly activity of solar radiation.\nUsing a dataset that consists of temperature of air, time, humidity, wind\nspeed, atmospheric pressure, direction of wind and solar radiation data, an\nArtificial Neural Network (ANN) model is constructed to effectively forecast\nsolar radiation using the available weather forecast data. Two models are\ncreated to efficiently create a system capable of interpreting patterns through\nsupervised learning data and predict the correct amount of radiation present in\nthe atmosphere. The results of the two statistical indicators: Mean Absolute\nError (MAE) and Mean Squared Error (MSE) are performed and compared with\nobserved and predicted data. These two models were able to generate efficient\npredictions with sufficient performance accuracy.\n", "versions": [{"version": "v1", "created": "Thu, 1 Apr 2021 20:41:27 GMT"}], "update_date": "2021-04-07", "authors_parsed": [["Rahman", "Shahriar", ""], ["Rahman", "Shazzadur", ""], ["Haque", "A K M Bahalul", ""]]}, {"id": "2104.02577", "submitter": "Dongha Lee", "authors": "Dongha Lee, Seonghyeon Lee, Hwanjo Yu", "title": "Learnable Dynamic Temporal Pooling for Time Series Classification", "comments": "AAAI 2021. 7 pages + references (2 pages). 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  With the increase of available time series data, predicting their class\nlabels has been one of the most important challenges in a wide range of\ndisciplines. Recent studies on time series classification show that\nconvolutional neural networks (CNN) achieved the state-of-the-art performance\nas a single classifier. In this work, pointing out that the global pooling\nlayer that is usually adopted by existing CNN classifiers discards the temporal\ninformation of high-level features, we present a dynamic temporal pooling (DTP)\ntechnique that reduces the temporal size of hidden representations by\naggregating the features at the segment-level. For the partition of a whole\nseries into multiple segments, we utilize dynamic time warping (DTW) to align\neach time point in a temporal order with the prototypical features of the\nsegments, which can be optimized simultaneously with the network parameters of\nCNN classifiers. The DTP layer combined with a fully-connected layer helps to\nextract further discriminative features considering their temporal position\nwithin an input time series. Extensive experiments on both univariate and\nmultivariate time series datasets show that our proposed pooling significantly\nimproves the classification performance.\n", "versions": [{"version": "v1", "created": "Fri, 2 Apr 2021 08:58:44 GMT"}], "update_date": "2021-04-07", "authors_parsed": [["Lee", "Dongha", ""], ["Lee", "Seonghyeon", ""], ["Yu", "Hwanjo", ""]]}, {"id": "2104.02578", "submitter": "Ilona Kulikovskikh Dr.", "authors": "Ilona Kulikovskikh", "title": "Neurons learn slower than they think", "comments": "7 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent studies revealed complex convergence dynamics in gradient-based\nmethods, which has been little understood so far. Changing the step size to\nbalance between high convergence rate and small generalization error may not be\nsufficient: maximizing the test accuracy usually requires a larger learning\nrate than minimizing the training loss. To explore the dynamic bounds of\nconvergence rate, this study introduces \\textit{differential capability} into\nan optimization process, which measures whether the test accuracy increases as\nfast as a model approaches the decision boundary in a classification problem.\nThe convergence analysis showed that: 1) a higher convergence rate leads to\nslower capability growth; 2) a lower convergence rate results in faster\ncapability growth and decay; 3) regulating a convergence rate in either\ndirection reduces differential capability.\n", "versions": [{"version": "v1", "created": "Fri, 2 Apr 2021 09:09:52 GMT"}], "update_date": "2021-04-07", "authors_parsed": [["Kulikovskikh", "Ilona", ""]]}, {"id": "2104.02588", "submitter": "Giorgio Gnecco", "authors": "Giorgio Gnecco, Andrea Bacigalupo, Francesca Fantoni, and Daniela\n  Selvi", "title": "Principal Component Analysis Applied to Gradient Fields in Band Gap\n  Optimization Problems for Metamaterials", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.LG cs.SD eess.AS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A promising technique for the spectral design of acoustic metamaterials is\nbased on the formulation of suitable constrained nonlinear optimization\nproblems. Unfortunately, the straightforward application of classical\ngradient-based iterative optimization algorithms to the numerical solution of\nsuch problems is typically highly demanding, due to the complexity of the\nunderlying physical models. Nevertheless, supervised machine learning\ntechniques can reduce such a computational effort, e.g., by replacing the\noriginal objective functions of such optimization problems with more-easily\ncomputable approximations. In this framework, the present article describes the\napplication of a related unsupervised machine learning technique, namely,\nprincipal component analysis, to approximate the gradient of the objective\nfunction of a band gap optimization problem for an acoustic metamaterial, with\nthe aim of making the successive application of a gradient-based iterative\noptimization algorithm faster. Numerical results show the effectiveness of the\nproposed method.\n", "versions": [{"version": "v1", "created": "Sun, 4 Apr 2021 11:13:37 GMT"}, {"version": "v2", "created": "Fri, 16 Apr 2021 11:48:48 GMT"}, {"version": "v3", "created": "Mon, 19 Apr 2021 22:20:30 GMT"}, {"version": "v4", "created": "Sat, 24 Apr 2021 00:32:34 GMT"}, {"version": "v5", "created": "Mon, 10 May 2021 15:09:09 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Gnecco", "Giorgio", ""], ["Bacigalupo", "Andrea", ""], ["Fantoni", "Francesca", ""], ["Selvi", "Daniela", ""]]}, {"id": "2104.02596", "submitter": "Huan Li", "authors": "Huan Li and Zhouchen Lin", "title": "Accelerated Gradient Tracking over Time-varying Graphs for Decentralized\n  Optimization", "comments": "Correct the typos in equations (15b) and (16)", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Decentralized optimization over time-varying graphs has been increasingly\ncommon in modern machine learning with massive data stored on millions of\nmobile devices, such as in federated learning. This paper revisits the widely\nused accelerated gradient tracking and extends it to time-varying graphs. We\nprove the $O((\\frac{\\gamma}{1-\\sigma_{\\gamma}})^2\\sqrt{\\frac{L}{\\epsilon}})$\nand\n$O((\\frac{\\gamma}{1-\\sigma_{\\gamma}})^{1.5}\\sqrt{\\frac{L}{\\mu}}\\log\\frac{1}{\\epsilon})$\ncomplexities for the practical single loop accelerated gradient tracking over\ntime-varying graphs when the problems are nonstrongly convex and strongly\nconvex, respectively, where $\\gamma$ and $\\sigma_{\\gamma}$ are two common\nconstants charactering the network connectivity, $\\epsilon$ is the desired\nprecision, and $L$ and $\\mu$ are the smoothness and strong convexity constants,\nrespectively. Our complexities improve significantly over the ones of\n$O(\\frac{1}{\\epsilon^{5/7}})$ and\n$O((\\frac{L}{\\mu})^{5/7}\\frac{1}{(1-\\sigma)^{1.5}}\\log\\frac{1}{\\epsilon})$,\nrespectively, which were proved in the original literature only for static\ngraphs, where $\\frac{1}{1-\\sigma}$ equals $\\frac{\\gamma}{1-\\sigma_{\\gamma}}$\nwhen the network is time-invariant. When combining with a multiple consensus\nsubroutine, the dependence on the network connectivity constants can be further\nimproved to $O(1)$ and $O(\\frac{\\gamma}{1-\\sigma_{\\gamma}})$ for the\ncomputation and communication complexities, respectively. When the network is\nstatic, by employing the Chebyshev acceleration, our complexities exactly match\nthe lower bounds without hiding any poly-logarithmic factor for both\nnonstrongly convex and strongly convex problems.\n", "versions": [{"version": "v1", "created": "Tue, 6 Apr 2021 15:34:14 GMT"}, {"version": "v2", "created": "Wed, 5 May 2021 11:05:44 GMT"}, {"version": "v3", "created": "Wed, 26 May 2021 14:21:23 GMT"}], "update_date": "2021-05-27", "authors_parsed": [["Li", "Huan", ""], ["Lin", "Zhouchen", ""]]}, {"id": "2104.02600", "submitter": "Eliya Nachmani", "authors": "Robin San-Roman, Eliya Nachmani, Lior Wolf", "title": "Noise Estimation for Generative Diffusion Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Generative diffusion models have emerged as leading models in speech and\nimage generation. However, in order to perform well with a small number of\ndenoising steps, a costly tuning of the set of noise parameters is needed. In\nthis work, we present a simple and versatile learning scheme that can\nstep-by-step adjust those noise parameters, for any given number of steps,\nwhile the previous work needs to retune for each number separately.\nFurthermore, without modifying the weights of the diffusion model, we are able\nto significantly improve the synthesis results, for a small number of steps.\nOur approach comes at a negligible computation cost.\n", "versions": [{"version": "v1", "created": "Tue, 6 Apr 2021 15:46:16 GMT"}], "update_date": "2021-04-07", "authors_parsed": [["San-Roman", "Robin", ""], ["Nachmani", "Eliya", ""], ["Wolf", "Lior", ""]]}, {"id": "2104.02604", "submitter": "Mar\\'ia Virginia Sabando Miss", "authors": "Mar\\'ia Virginia Sabando, Ignacio Ponzoni, Evangelos E. Milios, Axel\n  J. Soto", "title": "Using Molecular Embeddings in QSAR Modeling: Does it Make a Difference?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.BM cs.LG q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the consolidation of deep learning in drug discovery, several novel\nalgorithms for learning molecular representations have been proposed. Despite\nthe interest of the community in developing new methods for learning molecular\nembeddings and their theoretical benefits, comparing molecular embeddings with\neach other and with traditional representations is not straightforward, which\nin turn hinders the process of choosing a suitable representation for QSAR\nmodeling. A reason behind this issue is the difficulty of conducting a fair and\nthorough comparison of the different existing embedding approaches, which\nrequires numerous experiments on various datasets and training scenarios. To\nclose this gap, we reviewed the literature on methods for molecular embeddings\nand reproduced three unsupervised and two supervised molecular embedding\ntechniques recently proposed in the literature. We compared these five methods\nconcerning their performance in QSAR scenarios using different classification\nand regression datasets. We also compared these representations to traditional\nmolecular representations, namely molecular descriptors and fingerprints. As\nopposed to the expected outcome, our experimental setup consisting of over\n25,000 trained models and statistical tests revealed that the predictive\nperformance using molecular embeddings did not significantly surpass that of\ntraditional representations. While supervised embeddings yielded competitive\nresults compared to those using traditional molecular representations,\nunsupervised embeddings tended to perform worse than traditional\nrepresentations. Our results highlight the need for conducting a careful\ncomparison and analysis of the different embedding techniques prior to using\nthem in drug design tasks, and motivate a discussion about the potential of\nmolecular embeddings in computer-aided drug design.\n", "versions": [{"version": "v1", "created": "Sat, 20 Mar 2021 21:45:22 GMT"}, {"version": "v2", "created": "Wed, 28 Jul 2021 15:30:22 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Sabando", "Mar\u00eda Virginia", ""], ["Ponzoni", "Ignacio", ""], ["Milios", "Evangelos E.", ""], ["Soto", "Axel J.", ""]]}, {"id": "2104.02610", "submitter": "Kaleel Mahmood", "authors": "Kaleel Mahmood, Rigel Mahmood, Marten van Dijk", "title": "On the Robustness of Vision Transformers to Adversarial Examples", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in attention-based networks have shown that Vision\nTransformers can achieve state-of-the-art or near state-of-the-art results on\nmany image classification tasks. This puts transformers in the unique position\nof being a promising alternative to traditional convolutional neural networks\n(CNNs). While CNNs have been carefully studied with respect to adversarial\nattacks, the same cannot be said of Vision Transformers. In this paper, we\nstudy the robustness of Vision Transformers to adversarial examples. Our\nanalyses of transformer security is divided into three parts. First, we test\nthe transformer under standard white-box and black-box attacks. Second, we\nstudy the transferability of adversarial examples between CNNs and\ntransformers. We show that adversarial examples do not readily transfer between\nCNNs and transformers. Based on this finding, we analyze the security of a\nsimple ensemble defense of CNNs and transformers. By creating a new attack, the\nself-attention blended gradient attack, we show that such an ensemble is not\nsecure under a white-box adversary. However, under a black-box adversary, we\nshow that an ensemble can achieve unprecedented robustness without sacrificing\nclean accuracy. Our analysis for this work is done using six types of white-box\nattacks and two types of black-box attacks. Our study encompasses multiple\nVision Transformers, Big Transfer Models and CNN architectures trained on\nCIFAR-10, CIFAR-100 and ImageNet.\n", "versions": [{"version": "v1", "created": "Wed, 31 Mar 2021 00:29:12 GMT"}, {"version": "v2", "created": "Sat, 5 Jun 2021 00:31:29 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Mahmood", "Kaleel", ""], ["Mahmood", "Rigel", ""], ["van Dijk", "Marten", ""]]}, {"id": "2104.02638", "submitter": "Neil Houlsby", "authors": "Vincent Dumoulin, Neil Houlsby, Utku Evci, Xiaohua Zhai, Ross\n  Goroshin, Sylvain Gelly, Hugo Larochelle", "title": "Comparing Transfer and Meta Learning Approaches on a Unified Few-Shot\n  Classification Benchmark", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Meta and transfer learning are two successful families of approaches to\nfew-shot learning. Despite highly related goals, state-of-the-art advances in\neach family are measured largely in isolation of each other. As a result of\ndiverging evaluation norms, a direct or thorough comparison of different\napproaches is challenging. To bridge this gap, we perform a cross-family study\nof the best transfer and meta learners on both a large-scale meta-learning\nbenchmark (Meta-Dataset, MD), and a transfer learning benchmark (Visual Task\nAdaptation Benchmark, VTAB). We find that, on average, large-scale transfer\nmethods (Big Transfer, BiT) outperform competing approaches on MD, even when\ntrained only on ImageNet. In contrast, meta-learning approaches struggle to\ncompete on VTAB when trained and validated on MD. However, BiT is not without\nlimitations, and pushing for scale does not improve performance on highly\nout-of-distribution MD tasks. In performing this study, we reveal a number of\ndiscrepancies in evaluation norms and study some of these in light of the\nperformance gap. We hope that this work facilitates sharing of insights from\neach community, and accelerates progress on few-shot learning.\n", "versions": [{"version": "v1", "created": "Tue, 6 Apr 2021 16:17:51 GMT"}], "update_date": "2021-04-07", "authors_parsed": [["Dumoulin", "Vincent", ""], ["Houlsby", "Neil", ""], ["Evci", "Utku", ""], ["Zhai", "Xiaohua", ""], ["Goroshin", "Ross", ""], ["Gelly", "Sylvain", ""], ["Larochelle", "Hugo", ""]]}, {"id": "2104.02640", "submitter": "TrungTin Nguyen", "authors": "TrungTin Nguyen, Hien Duy Nguyen, Faicel Chamroukhi and Florence\n  Forbes", "title": "A non-asymptotic penalization criterion for model selection in mixture\n  of experts models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.AI cs.LG stat.ME stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mixture of experts (MoE) is a popular class of models in statistics and\nmachine learning that has sustained attention over the years, due to its\nflexibility and effectiveness. We consider the Gaussian-gated localized MoE\n(GLoME) regression model for modeling heterogeneous data. This model poses\nchallenging questions with respect to the statistical estimation and model\nselection problems, including feature selection, both from the computational\nand theoretical points of view. We study the problem of estimating the number\nof components of the GLoME model, in a penalized maximum likelihood estimation\nframework. We provide a lower bound on the penalty that ensures a weak oracle\ninequality is satisfied by our estimator. To support our theoretical result, we\nperform numerical experiments on simulated and real data, which illustrate the\nperformance of our finite-sample oracle inequality.\n", "versions": [{"version": "v1", "created": "Tue, 6 Apr 2021 16:24:55 GMT"}], "update_date": "2021-04-07", "authors_parsed": [["Nguyen", "TrungTin", ""], ["Nguyen", "Hien Duy", ""], ["Chamroukhi", "Faicel", ""], ["Forbes", "Florence", ""]]}, {"id": "2104.02646", "submitter": "Krishna Murthy Jatavallabhula", "authors": "Krishna Murthy Jatavallabhula and Miles Macklin and Florian Golemo and\n  Vikram Voleti and Linda Petrini and Martin Weiss and Breandan Considine and\n  Jerome Parent-Levesque and Kevin Xie and Kenny Erleben and Liam Paull and\n  Florian Shkurti and Derek Nowrouzezahrai and Sanja Fidler", "title": "gradSim: Differentiable simulation for system identification and\n  visuomotor control", "comments": "ICLR 2021. Project page (and a dynamic web version of the article):\n  https://gradsim.github.io", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.RO", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We consider the problem of estimating an object's physical properties such as\nmass, friction, and elasticity directly from video sequences. Such a system\nidentification problem is fundamentally ill-posed due to the loss of\ninformation during image formation. Current solutions require precise 3D labels\nwhich are labor-intensive to gather, and infeasible to create for many systems\nsuch as deformable solids or cloth. We present gradSim, a framework that\novercomes the dependence on 3D supervision by leveraging differentiable\nmultiphysics simulation and differentiable rendering to jointly model the\nevolution of scene dynamics and image formation. This novel combination enables\nbackpropagation from pixels in a video sequence through to the underlying\nphysical attributes that generated them. Moreover, our unified computation\ngraph -- spanning from the dynamics and through the rendering process --\nenables learning in challenging visuomotor control tasks, without relying on\nstate-based (3D) supervision, while obtaining performance competitive to or\nbetter than techniques that rely on precise 3D labels.\n", "versions": [{"version": "v1", "created": "Tue, 6 Apr 2021 16:32:01 GMT"}], "update_date": "2021-04-07", "authors_parsed": [["Jatavallabhula", "Krishna Murthy", ""], ["Macklin", "Miles", ""], ["Golemo", "Florian", ""], ["Voleti", "Vikram", ""], ["Petrini", "Linda", ""], ["Weiss", "Martin", ""], ["Considine", "Breandan", ""], ["Parent-Levesque", "Jerome", ""], ["Xie", "Kevin", ""], ["Erleben", "Kenny", ""], ["Paull", "Liam", ""], ["Shkurti", "Florian", ""], ["Nowrouzezahrai", "Derek", ""], ["Fidler", "Sanja", ""]]}, {"id": "2104.02650", "submitter": "Jan N. Fuhg", "authors": "Jan Niklas Fuhg, Christoph Boehm, Nikolaos Bouklas, Amelie Fau, Peter\n  Wriggers, Michele Marino", "title": "Model-data-driven constitutive responses: application to a multiscale\n  computational framework", "comments": "43 pages, 28 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.AP", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Computational multiscale methods for analyzing and deriving constitutive\nresponses have been used as a tool in engineering problems because of their\nability to combine information at different length scales. However, their\napplication in a nonlinear framework can be limited by high computational\ncosts, numerical difficulties, and/or inaccuracies. In this paper, a hybrid\nmethodology is presented which combines classical constitutive laws\n(model-based), a data-driven correction component, and computational multiscale\napproaches. A model-based material representation is locally improved with data\nfrom lower scales obtained by means of a nonlinear numerical homogenization\nprocedure leading to a model-data-driven approach. Therefore, macroscale\nsimulations explicitly incorporate the true microscale response, maintaining\nthe same level of accuracy that would be obtained with online micro-macro\nsimulations but with a computational cost comparable to classical model-driven\napproaches. In the proposed approach, both model and data play a fundamental\nrole allowing for the synergistic integration between a physics-based response\nand a machine learning black-box. Numerical applications are implemented in two\ndimensions for different tests investigating both material and structural\nresponses in large deformation.\n", "versions": [{"version": "v1", "created": "Tue, 6 Apr 2021 16:34:46 GMT"}], "update_date": "2021-04-07", "authors_parsed": [["Fuhg", "Jan Niklas", ""], ["Boehm", "Christoph", ""], ["Bouklas", "Nikolaos", ""], ["Fau", "Amelie", ""], ["Wriggers", "Peter", ""], ["Marino", "Michele", ""]]}, {"id": "2104.02651", "submitter": "Erico Tjoa", "authors": "Erico Tjoa", "title": "A Modified Convolutional Network for Auto-encoding based on Pattern\n  Theory Growth Function", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This brief paper reports the shortcoming of a variant of convolutional neural\nnetwork whose components are developed based on the pattern theory framework.\n", "versions": [{"version": "v1", "created": "Sun, 4 Apr 2021 04:23:36 GMT"}], "update_date": "2021-04-07", "authors_parsed": [["Tjoa", "Erico", ""]]}, {"id": "2104.02652", "submitter": "Meng Xia", "authors": "Meng Xia, Meenal K. Kheterpal, Samantha C. Wong, Christine Park,\n  William Ratliff, Lawrence Carin, Ricardo Henao", "title": "Malignancy Prediction and Lesion Identification from Clinical\n  Dermatological Images", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider machine-learning-based malignancy prediction and lesion\nidentification from clinical dermatological images, which can be indistinctly\nacquired via smartphone or dermoscopy capture. Additionally, we do not assume\nthat images contain single lesions, thus the framework supports both focal or\nwide-field images. Specifically, we propose a two-stage approach in which we\nfirst identify all lesions present in the image regardless of sub-type or\nlikelihood of malignancy, then it estimates their likelihood of malignancy, and\nthrough aggregation, it also generates an image-level likelihood of malignancy\nthat can be used for high-level screening processes. Further, we consider\naugmenting the proposed approach with clinical covariates (from electronic\nhealth records) and publicly available data (the ISIC dataset). Comprehensive\nexperiments validated on an independent test dataset demonstrate that i) the\nproposed approach outperforms alternative model architectures; ii) the model\nbased on images outperforms a pure clinical model by a large margin, and the\ncombination of images and clinical data does not significantly improves over\nthe image-only model; and iii) the proposed framework offers comparable\nperformance in terms of malignancy classification relative to three board\ncertified dermatologists with different levels of experience.\n", "versions": [{"version": "v1", "created": "Fri, 2 Apr 2021 20:52:05 GMT"}], "update_date": "2021-04-07", "authors_parsed": [["Xia", "Meng", ""], ["Kheterpal", "Meenal K.", ""], ["Wong", "Samantha C.", ""], ["Park", "Christine", ""], ["Ratliff", "William", ""], ["Carin", "Lawrence", ""], ["Henao", "Ricardo", ""]]}, {"id": "2104.02653", "submitter": "Ad\\'in Ram\\'irez Rivera", "authors": "Miguel Rodr\\'iguez Santander, Juan Hern\\'andez Albarrac\\'in, Ad\\'in\n  Ram\\'irez Rivera", "title": "On the Pitfalls of Learning with Limited Data: A Facial Expression\n  Recognition Case Study", "comments": "To appear in Expert Systems with Applications", "journal-ref": "Expert Syst. Appl. 2021, 18 (1) 114991", "doi": "10.1016/j.eswa.2021.114991", "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Deep learning models need large amounts of data for training. In video\nrecognition and classification, significant advances were achieved with the\nintroduction of new large databases. However, the creation of large-databases\nfor training is infeasible in several scenarios. Thus, existing or small\ncollected databases are typically joined and amplified to train these models.\nNevertheless, training neural networks on limited data is not straightforward\nand comes with a set of problems. In this paper, we explore the effects of\nstacking databases, model initialization, and data amplification techniques\nwhen training with limited data on deep learning models' performance. We\nfocused on the problem of Facial Expression Recognition from videos. We\nperformed an extensive study with four databases at a different complexity and\nnine deep-learning architectures for video classification. We found that (i)\ncomplex training sets translate better to more stable test sets when trained\nwith transfer learning and synthetically generated data, but their performance\nyields a high variance; (ii) training with more detailed data translates to\nmore stable performance on novel scenarios (albeit with lower performance);\n(iii) merging heterogeneous data is not a straightforward improvement, as the\ntype of augmentation and initialization is crucial; (iv) classical data\naugmentation cannot fill the holes created by joining largely separated\ndatasets; and (v) inductive biases help to bridge the gap when paired with\nsynthetic data, but this data is not enough when working with standard\ninitialization techniques.\n", "versions": [{"version": "v1", "created": "Fri, 2 Apr 2021 18:53:41 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Santander", "Miguel Rodr\u00edguez", ""], ["Albarrac\u00edn", "Juan Hern\u00e1ndez", ""], ["Rivera", "Ad\u00edn Ram\u00edrez", ""]]}, {"id": "2104.02661", "submitter": "Tarindu Jayatilaka", "authors": "Haritha Jayasinghe, Tarindu Jayatilaka, Ravin Gunawardena,\n  Uthayasanker Thayasivam", "title": "Data-Driven Simulation of Ride-Hailing Services using Imitation and\n  Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The rapid growth of ride-hailing platforms has created a highly competitive\nmarket where businesses struggle to make profits, demanding the need for better\noperational strategies. However, real-world experiments are risky and expensive\nfor these platforms as they deal with millions of users daily. Thus, a need\narises for a simulated environment where they can predict users' reactions to\nchanges in the platform-specific parameters such as trip fares and incentives.\nBuilding such a simulation is challenging, as these platforms exist within\ndynamic environments where thousands of users regularly interact with one\nanother. This paper presents a framework to mimic and predict user,\nspecifically driver, behaviors in ride-hailing services. We use a data-driven\nhybrid reinforcement learning and imitation learning approach for this. First,\nthe agent utilizes behavioral cloning to mimic driver behavior using a\nreal-world data set. Next, reinforcement learning is applied on top of the\npre-trained agents in a simulated environment, to allow them to adapt to\nchanges in the platform. Our framework provides an ideal playground for\nride-hailing platforms to experiment with platform-specific parameters to\npredict drivers' behavioral patterns.\n", "versions": [{"version": "v1", "created": "Tue, 6 Apr 2021 16:49:26 GMT"}], "update_date": "2021-04-07", "authors_parsed": [["Jayasinghe", "Haritha", ""], ["Jayatilaka", "Tarindu", ""], ["Gunawardena", "Ravin", ""], ["Thayasivam", "Uthayasanker", ""]]}, {"id": "2104.02680", "submitter": "Benjamin McLaughlin", "authors": "Benjamin McLaughlin, Sung Ha Kang", "title": "A New Parallel Adaptive Clustering and its Application to Streaming Data", "comments": "This work was funded by NAVSEA. Distribution Statement A: Approved\n  for Public Release, Distribution is Unlimited", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a parallel adaptive clustering (PAC) algorithm to\nautomatically classify data while simultaneously choosing a suitable number of\nclasses. Clustering is an important tool for data analysis and understanding in\na broad set of areas including data reduction, pattern analysis, and\nclassification. However, the requirement to specify the number of clusters in\nadvance and the computational burden associated with clustering large sets of\ndata persist as challenges in clustering. We propose a new parallel adaptive\nclustering (PAC) algorithm that addresses these challenges by adaptively\ncomputing the number of clusters and leveraging the power of parallel\ncomputing. The algorithm clusters disjoint subsets of the data on parallel\ncomputation threads. We develop regularized set \\mi{k}-means to efficiently\ncluster the results from the parallel threads. A refinement step further\nimproves the clusters. The PAC algorithm offers the capability to adaptively\ncluster data sets which change over time by reusing the information from\nprevious time steps to decrease computation. We provide theoretical analysis\nand numerical experiments to characterize the performance of the method,\nvalidate its properties, and demonstrate the computational efficiency of the\nmethod.\n", "versions": [{"version": "v1", "created": "Tue, 6 Apr 2021 17:18:56 GMT"}], "update_date": "2021-04-07", "authors_parsed": [["McLaughlin", "Benjamin", ""], ["Kang", "Sung Ha", ""]]}, {"id": "2104.02689", "submitter": "Kun Qian", "authors": "Kun Qian, Wei Wei, Zhou Yu", "title": "A Student-Teacher Architecture for Dialog Domain Adaptation under the\n  Meta-Learning Setting", "comments": "Accepted by AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Numerous new dialog domains are being created every day while collecting data\nfor these domains is extremely costly since it involves human interactions.\nTherefore, it is essential to develop algorithms that can adapt to different\ndomains efficiently when building data-driven dialog models. The most recent\nresearches on domain adaption focus on giving the model a better\ninitialization, rather than optimizing the adaptation process. We propose an\nefficient domain adaptive task-oriented dialog system model, which incorporates\na meta-teacher model to emphasize the different impacts between generated\ntokens with respect to the context. We first train our base dialog model and\nmeta-teacher model adversarially in a meta-learning setting on rich-resource\ndomains. The meta-teacher learns to quantify the importance of tokens under\ndifferent contexts across different domains. During adaptation, the\nmeta-teacher guides the dialog model to focus on important tokens in order to\nachieve better adaptation efficiency. We evaluate our model on two multi-domain\ndatasets, MultiWOZ and Google Schema-Guided Dialogue, and achieve\nstate-of-the-art performance.\n", "versions": [{"version": "v1", "created": "Tue, 6 Apr 2021 17:31:28 GMT"}], "update_date": "2021-04-07", "authors_parsed": [["Qian", "Kun", ""], ["Wei", "Wei", ""], ["Yu", "Zhou", ""]]}, {"id": "2104.02705", "submitter": "David R\\\"ugamer", "authors": "David R\\\"ugamer, Ruolin Shen, Christina Bukas, Lisa Barros de Andrade\n  e Sousa, Dominik Thalmeier, Nadja Klein, Chris Kolb, Florian Pfisterer,\n  Philipp Kopper, Bernd Bischl, Christian L. M\\\"uller", "title": "deepregression: a Flexible Neural Network Framework for Semi-Structured\n  Deep Distributional Regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes the implementation of semi-structured deep\ndistributional regression, a flexible framework to learn distributions based on\na combination of additive regression models and deep neural networks.\ndeepregression is implemented in both R and Python, using the deep learning\nlibraries TensorFlow and PyTorch, respectively. The implementation consists of\n(1) a modular neural network building system for the combination of various\nstatistical and deep learning approaches, (2) an orthogonalization cell to\nallow for an interpretable combination of different subnetworks as well as (3)\npre-processing steps necessary to initialize such models. The software package\nallows to define models in a user-friendly manner using distribution\ndefinitions via a formula environment that is inspired by classical statistical\nmodel frameworks such as mgcv. The packages' modular design and functionality\nprovides a unique resource for rapid and reproducible prototyping of complex\nstatistical and deep learning models while simultaneously retaining the\nindispensable interpretability of classical statistical models.\n", "versions": [{"version": "v1", "created": "Tue, 6 Apr 2021 17:56:31 GMT"}], "update_date": "2021-04-07", "authors_parsed": [["R\u00fcgamer", "David", ""], ["Shen", "Ruolin", ""], ["Bukas", "Christina", ""], ["Sousa", "Lisa Barros de Andrade e", ""], ["Thalmeier", "Dominik", ""], ["Klein", "Nadja", ""], ["Kolb", "Chris", ""], ["Pfisterer", "Florian", ""], ["Kopper", "Philipp", ""], ["Bischl", "Bernd", ""], ["M\u00fcller", "Christian L.", ""]]}, {"id": "2104.02710", "submitter": "Jennifer J. Sun", "authors": "Jennifer J. Sun, Tomomi Karigo, Dipam Chakraborty, Sharada P. Mohanty,\n  Benjamin Wild, Quan Sun, Chen Chen, David J. Anderson, Pietro Perona, Yisong\n  Yue, Ann Kennedy", "title": "The Multi-Agent Behavior Dataset: Mouse Dyadic Social Interactions", "comments": "Dataset: https://data.caltech.edu/records/1991, Website:\n  https://sites.google.com/view/computational-behavior/calms21-dataset", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-agent behavior modeling aims to understand the interactions that occur\nbetween agents. We present a multi-agent dataset from behavioral neuroscience,\nthe Caltech Mouse Social Interactions (CalMS21) Dataset. Our dataset consists\nof trajectory data of social interactions, recorded from videos of freely\nbehaving mice in a standard resident-intruder assay. To help accelerate\nbehavioral studies, the CalMS21 dataset provides benchmarks to evaluate the\nperformance of automated behavior classification methods in three settings: (1)\nfor training on large behavioral datasets all annotated by a single annotator,\n(2) for style transfer to learn inter-annotator differences in behavior\ndefinitions, and (3) for learning of new behaviors of interest given limited\ntraining data. The dataset consists of 6 million frames of unlabeled tracked\nposes of interacting mice, as well as over 1 million frames with tracked poses\nand corresponding frame-level behavior annotations. The challenge of our\ndataset is to be able to classify behaviors accurately using both labeled and\nunlabeled tracking data, as well as being able to generalize to new settings.\n", "versions": [{"version": "v1", "created": "Tue, 6 Apr 2021 17:58:47 GMT"}, {"version": "v2", "created": "Wed, 7 Apr 2021 16:16:29 GMT"}, {"version": "v3", "created": "Thu, 10 Jun 2021 19:56:59 GMT"}], "update_date": "2021-06-14", "authors_parsed": [["Sun", "Jennifer J.", ""], ["Karigo", "Tomomi", ""], ["Chakraborty", "Dipam", ""], ["Mohanty", "Sharada P.", ""], ["Wild", "Benjamin", ""], ["Sun", "Quan", ""], ["Chen", "Chen", ""], ["Anderson", "David J.", ""], ["Perona", "Pietro", ""], ["Yue", "Yisong", ""], ["Kennedy", "Ann", ""]]}, {"id": "2104.02726", "submitter": "Giorgio Franceschelli", "authors": "Giorgio Franceschelli and Mirco Musolesi", "title": "Creativity and Machine Learning: A Survey", "comments": "25 pages, 3 figures, 2 tables; uppercase typos corrected; paragraph\n  about char-RNN and folk-RNN revised", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is a growing interest in the area of machine learning and creativity.\nThis survey presents an overview of the history and the state of the art of\ncomputational creativity theories, machine learning techniques, including\ngenerative deep learning, and corresponding automatic evaluation methods. After\npresenting a critical discussion of the key contributions in this area, we\noutline the current research challenges and emerging opportunities in this\nfield.\n", "versions": [{"version": "v1", "created": "Tue, 6 Apr 2021 18:00:06 GMT"}, {"version": "v2", "created": "Tue, 20 Apr 2021 18:00:03 GMT"}], "update_date": "2021-04-22", "authors_parsed": [["Franceschelli", "Giorgio", ""], ["Musolesi", "Mirco", ""]]}, {"id": "2104.02741", "submitter": "Thomas Schrefl", "authors": "Alexander Kovacs, Lukas Exl, Alexander Kornell, Johann Fischbacher,\n  Markus Hovorka, Markus Gusenbauer, Leoni Breth, Harald Oezelt, Masao Yano,\n  Noritsugu Sakuma, Akihito Kinoshita, Tetsuya Shoji, Akira Kato, Thomas\n  Schrefl", "title": "Conditional physics informed neural networks", "comments": "18 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cond-mat.mtrl-sci", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce conditional PINNs (physics informed neural networks) for\nestimating the solution of classes of eigenvalue problems. The concept of PINNs\nis expanded to learn not only the solution of one particular differential\nequation but the solutions to a class of problems. We demonstrate this idea by\nestimating the coercive field of permanent magnets which depends on the width\nand strength of local defects. When the neural network incorporates the physics\nof magnetization reversal, training can be achieved in an unsupervised way.\nThere is no need to generate labeled training data. The presented test cases\nhave been rigorously studied in the past. Thus, a detailed and easy comparison\nwith analytical solutions is made. We show that a single deep neural network\ncan learn the solution of partial differential equations for an entire class of\nproblems.\n", "versions": [{"version": "v1", "created": "Tue, 6 Apr 2021 18:29:14 GMT"}], "update_date": "2021-04-08", "authors_parsed": [["Kovacs", "Alexander", ""], ["Exl", "Lukas", ""], ["Kornell", "Alexander", ""], ["Fischbacher", "Johann", ""], ["Hovorka", "Markus", ""], ["Gusenbauer", "Markus", ""], ["Breth", "Leoni", ""], ["Oezelt", "Harald", ""], ["Yano", "Masao", ""], ["Sakuma", "Noritsugu", ""], ["Kinoshita", "Akihito", ""], ["Shoji", "Tetsuya", ""], ["Kato", "Akira", ""], ["Schrefl", "Thomas", ""]]}, {"id": "2104.02743", "submitter": "Hossein Nejatbakhsh Esfahani", "authors": "Hossein Nejatbakhsh Esfahani, Arash Bahari Kordabad, Sebastien Gros", "title": "Approximate Robust NMPC using Reinforcement Learning", "comments": "This paper has been accepted to 2021 European Control Conference\n  (ECC)", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.LG cs.RO cs.SY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present a Reinforcement Learning-based Robust Nonlinear Model Predictive\nControl (RL-RNMPC) framework for controlling nonlinear systems in the presence\nof disturbances and uncertainties. An approximate Robust Nonlinear Model\nPredictive Control (RNMPC) of low computational complexity is used in which the\nstate trajectory uncertainty is modelled via ellipsoids. Reinforcement Learning\nis then used in order to handle the ellipsoidal approximation and improve the\nclosed-loop performance of the scheme by adjusting the MPC parameters\ngenerating the ellipsoids. The approach is tested on a simulated Wheeled Mobile\nRobot (WMR) tracking a desired trajectory while avoiding static obstacles.\n", "versions": [{"version": "v1", "created": "Tue, 6 Apr 2021 18:34:58 GMT"}], "update_date": "2021-04-08", "authors_parsed": [["Esfahani", "Hossein Nejatbakhsh", ""], ["Kordabad", "Arash Bahari", ""], ["Gros", "Sebastien", ""]]}, {"id": "2104.02745", "submitter": "Shubhankar Mangesh Borse", "authors": "Shubhankar Borse, Ying Wang, Yizhe Zhang, Fatih Porikli", "title": "InverseForm: A Loss Function for Structured Boundary-Aware Segmentation", "comments": "Accepted to CVPR 2021 as an oral presentation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present a novel boundary-aware loss term for semantic segmentation using\nan inverse-transformation network, which efficiently learns the degree of\nparametric transformations between estimated and target boundaries. This\nplug-in loss term complements the cross-entropy loss in capturing boundary\ntransformations and allows consistent and significant performance improvement\non segmentation backbone models without increasing their size and computational\ncomplexity. We analyze the quantitative and qualitative effects of our loss\nfunction on three indoor and outdoor segmentation benchmarks, including\nCityscapes, NYU-Depth-v2, and PASCAL, integrating it into the training phase of\nseveral backbone networks in both single-task and multi-task settings. Our\nextensive experiments show that the proposed method consistently outperforms\nbaselines, and even sets the new state-of-the-art on two datasets.\n", "versions": [{"version": "v1", "created": "Tue, 6 Apr 2021 18:52:45 GMT"}, {"version": "v2", "created": "Thu, 8 Apr 2021 01:19:22 GMT"}], "update_date": "2021-04-09", "authors_parsed": [["Borse", "Shubhankar", ""], ["Wang", "Ying", ""], ["Zhang", "Yizhe", ""], ["Porikli", "Fatih", ""]]}, {"id": "2104.02746", "submitter": "Felix Voigtlaender", "authors": "Philipp Grohs, Felix Voigtlaender", "title": "Proof of the Theory-to-Practice Gap in Deep Learning via Sampling\n  Complexity bounds for Neural Network Approximation Spaces", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.FA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the computational complexity of (deterministic or randomized)\nalgorithms based on point samples for approximating or integrating functions\nthat can be well approximated by neural networks. Such algorithms (most\nprominently stochastic gradient descent and its variants) are used extensively\nin the field of deep learning. One of the most important problems in this field\nconcerns the question of whether it is possible to realize theoretically\nprovable neural network approximation rates by such algorithms. We answer this\nquestion in the negative by proving hardness results for the problems of\napproximation and integration on a novel class of neural network approximation\nspaces. In particular, our results confirm a conjectured and empirically\nobserved theory-to-practice gap in deep learning. We complement our hardness\nresults by showing that approximation rates of a comparable order of\nconvergence are (at least theoretically) achievable.\n", "versions": [{"version": "v1", "created": "Tue, 6 Apr 2021 18:55:20 GMT"}], "update_date": "2021-04-08", "authors_parsed": [["Grohs", "Philipp", ""], ["Voigtlaender", "Felix", ""]]}, {"id": "2104.02748", "submitter": "Jae Ro", "authors": "Jae Ro, Mingqing Chen, Rajiv Mathews, Mehryar Mohri, Ananda Theertha\n  Suresh", "title": "Communication-Efficient Agnostic Federated Averaging", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In distributed learning settings such as federated learning, the training\nalgorithm can be potentially biased towards different clients. Mohri et al.\n(2019) proposed a domain-agnostic learning algorithm, where the model is\noptimized for any target distribution formed by a mixture of the client\ndistributions in order to overcome this bias. They further proposed an\nalgorithm for the cross-silo federated learning setting, where the number of\nclients is small. We consider this problem in the cross-device setting, where\nthe number of clients is much larger. We propose a communication-efficient\ndistributed algorithm called Agnostic Federated Averaging (or AgnosticFedAvg)\nto minimize the domain-agnostic objective proposed in Mohri et al. (2019),\nwhich is amenable to other private mechanisms such as secure aggregation. We\nhighlight two types of naturally occurring domains in federated learning and\nargue that AgnosticFedAvg performs well on both. To demonstrate the practical\neffectiveness of AgnosticFedAvg, we report positive results for large-scale\nlanguage modeling tasks in both simulation and live experiments, where the\nlatter involves training language models for Spanish virtual keyboard for\nmillions of user devices.\n", "versions": [{"version": "v1", "created": "Tue, 6 Apr 2021 19:01:18 GMT"}, {"version": "v2", "created": "Wed, 16 Jun 2021 01:10:15 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Ro", "Jae", ""], ["Chen", "Mingqing", ""], ["Mathews", "Rajiv", ""], ["Mohri", "Mehryar", ""], ["Suresh", "Ananda Theertha", ""]]}, {"id": "2104.02754", "submitter": "Yinglun Li", "authors": "Yinglun Li, Nanpeng Yu, Wei Wang", "title": "Machine Learning-Driven Virtual Bidding with Electricity Market\n  Efficiency Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper develops a machine learning-driven portfolio optimization\nframework for virtual bidding in electricity markets considering both risk\nconstraint and price sensitivity. The algorithmic trading strategy is developed\nfrom the perspective of a proprietary trading firm to maximize profit. A\nrecurrent neural network-based Locational Marginal Price (LMP) spread forecast\nmodel is developed by leveraging the inter-hour dependencies of the market\nclearing algorithm. The LMP spread sensitivity with respect to net virtual bids\nis modeled as a monotonic function with the proposed constrained gradient\nboosting tree. We leverage the proposed algorithmic virtual bid trading\nstrategy to evaluate both the profitability of the virtual bid portfolio and\nthe efficiency of U.S. wholesale electricity markets. The comprehensive\nempirical analysis on PJM, ISO-NE, and CAISO indicates that the proposed\nvirtual bid portfolio optimization strategy considering the price sensitivity\nexplicitly outperforms the one that neglects the price sensitivity. The Sharpe\nratio of virtual bid portfolios for all three electricity markets are much\nhigher than that of the S&P 500 index. It was also shown that the efficiency of\nCAISO's two-settlement system is lower than that of PJM and ISO-NE.\n", "versions": [{"version": "v1", "created": "Tue, 6 Apr 2021 19:30:39 GMT"}], "update_date": "2021-04-08", "authors_parsed": [["Li", "Yinglun", ""], ["Yu", "Nanpeng", ""], ["Wang", "Wei", ""]]}, {"id": "2104.02756", "submitter": "Fran\\c{c}ois Mercier", "authors": "Fran\\c{c}ois Mercier", "title": "Efficient transfer learning for NLP with ELECTRA", "comments": "Submission for ML Reproducibility Challenge 2020", "journal-ref": "Machine Learning Reproducibility Challenge 2020", "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Clark et al. [2020] claims that the ELECTRA approach is highly efficient in\nNLP performances relative to computation budget. As such, this reproducibility\nstudy focus on this claim, summarized by the following question: Can we use\nELECTRA to achieve close to SOTA performances for NLP in low-resource settings,\nin term of compute cost?\n", "versions": [{"version": "v1", "created": "Tue, 6 Apr 2021 19:34:36 GMT"}], "update_date": "2021-04-09", "authors_parsed": [["Mercier", "Fran\u00e7ois", ""]]}, {"id": "2104.02757", "submitter": "Zhiyun Lu", "authors": "Zhiyun Lu, Wei Han, Yu Zhang, Liangliang Cao", "title": "Exploring Targeted Universal Adversarial Perturbations to End-to-end ASR\n  Models", "comments": "Submitted to INTERSPEECH 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although end-to-end automatic speech recognition (e2e ASR) models are widely\ndeployed in many applications, there have been very few studies to understand\nmodels' robustness against adversarial perturbations. In this paper, we explore\nwhether a targeted universal perturbation vector exists for e2e ASR models. Our\ngoal is to find perturbations that can mislead the models to predict the given\ntargeted transcript such as \"thank you\" or empty string on any input utterance.\nWe study two different attacks, namely additive and prepending perturbations,\nand their performances on the state-of-the-art LAS, CTC and RNN-T models. We\nfind that LAS is the most vulnerable to perturbations among the three models.\nRNN-T is more robust against additive perturbations, especially on long\nutterances. And CTC is robust against both additive and prepending\nperturbations. To attack RNN-T, we find prepending perturbation is more\neffective than the additive perturbation, and can mislead the models to predict\nthe same short target on utterances of arbitrary length.\n", "versions": [{"version": "v1", "created": "Tue, 6 Apr 2021 19:39:05 GMT"}], "update_date": "2021-04-08", "authors_parsed": [["Lu", "Zhiyun", ""], ["Han", "Wei", ""], ["Zhang", "Yu", ""], ["Cao", "Liangliang", ""]]}, {"id": "2104.02768", "submitter": "Jacob Pfau", "authors": "Jacob Pfau, Albert T. Young, Jerome Wei, Maria L. Wei, Michael J.\n  Keiser", "title": "Robust Semantic Interpretability: Revisiting Concept Activation Vectors", "comments": "ICML WHI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interpretability methods for image classification assess model\ntrustworthiness by attempting to expose whether the model is systematically\nbiased or attending to the same cues as a human would. Saliency methods for\nfeature attribution dominate the interpretability literature, but these methods\ndo not address semantic concepts such as the textures, colors, or genders of\nobjects within an image. Our proposed Robust Concept Activation Vectors (RCAV)\nquantifies the effects of semantic concepts on individual model predictions and\non model behavior as a whole. RCAV calculates a concept gradient and takes a\ngradient ascent step to assess model sensitivity to the given concept. By\ngeneralizing previous work on concept activation vectors to account for model\nnon-linearity, and by introducing stricter hypothesis testing, we show that\nRCAV yields interpretations which are both more accurate at the image level and\nrobust at the dataset level. RCAV, like saliency methods, supports the\ninterpretation of individual predictions. To evaluate the practical use of\ninterpretability methods as debugging tools, and the scientific use of\ninterpretability methods for identifying inductive biases (e.g. texture over\nshape), we construct two datasets and accompanying metrics for realistic\nbenchmarking of semantic interpretability methods. Our benchmarks expose the\nimportance of counterfactual augmentation and negative controls for quantifying\nthe practical usability of interpretability methods.\n", "versions": [{"version": "v1", "created": "Tue, 6 Apr 2021 20:14:59 GMT"}], "update_date": "2021-04-08", "authors_parsed": [["Pfau", "Jacob", ""], ["Young", "Albert T.", ""], ["Wei", "Jerome", ""], ["Wei", "Maria L.", ""], ["Keiser", "Michael J.", ""]]}, {"id": "2104.02772", "submitter": "Christopher Harshaw", "authors": "Christopher Harshaw, Ehsan Kazemi, Moran Feldman, Amin Karbasi", "title": "The Power of Subsampling in Submodular Maximization", "comments": "arXiv admin note: text overlap with arXiv:1802.07098", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG math.OC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose subsampling as a unified algorithmic technique for submodular\nmaximization in centralized and online settings. The idea is simple:\nindependently sample elements from the ground set, and use simple combinatorial\ntechniques (such as greedy or local search) on these sampled elements. We show\nthat this approach leads to optimal/state-of-the-art results despite being much\nsimpler than existing methods. In the usual offline setting, we present\nSampleGreedy, which obtains a $(p + 2 + o(1))$-approximation for maximizing a\nsubmodular function subject to a $p$-extendible system using $O(n + nk/p)$\nevaluation and feasibility queries, where $k$ is the size of the largest\nfeasible set. The approximation ratio improves to $p+1$ and $p$ for monotone\nsubmodular and linear objectives, respectively. In the streaming setting, we\npresent SampleStreaming, which obtains a $(4p +2 - o(1))$-approximation for\nmaximizing a submodular function subject to a $p$-matchoid using $O(k)$ memory\nand $O(km/p)$ evaluation and feasibility queries per element, where $m$ is the\nnumber of matroids defining the $p$-matchoid. The approximation ratio improves\nto $4p$ for monotone submodular objectives. We empirically demonstrate the\neffectiveness of our algorithms on video summarization, location summarization,\nand movie recommendation tasks.\n", "versions": [{"version": "v1", "created": "Tue, 6 Apr 2021 20:25:57 GMT"}], "update_date": "2021-04-08", "authors_parsed": [["Harshaw", "Christopher", ""], ["Kazemi", "Ehsan", ""], ["Feldman", "Moran", ""], ["Karbasi", "Amin", ""]]}, {"id": "2104.02774", "submitter": "Huadong Mo", "authors": "Jianyu Xu, Bin Liu, Huadong Mo, Daoyi Dong", "title": "Bayesian adversarial multi-node bandit for optimal smart grid protection\n  against cyber attacks", "comments": null, "journal-ref": "Automatica, 2021", "doi": null, "report-no": null, "categories": "cs.CR cs.LG cs.SY eess.SY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The cybersecurity of smart grids has become one of key problems in developing\nreliable modern power and energy systems. This paper introduces a\nnon-stationary adversarial cost with a variation constraint for smart grids and\nenables us to investigate the problem of optimal smart grid protection against\ncyber attacks in a relatively practical scenario. In particular, a Bayesian\nmulti-node bandit (MNB) model with adversarial costs is constructed and a new\nregret function is defined for this model. An algorithm called Thompson-Hedge\nalgorithm is presented to solve the problem and the superior performance of the\nproposed algorithm is proven in terms of the convergence rate of the regret\nfunction. The applicability of the algorithm to real smart grid scenarios is\nverified and the performance of the algorithm is also demonstrated by numerical\nexamples.\n", "versions": [{"version": "v1", "created": "Sat, 20 Feb 2021 10:45:21 GMT"}], "update_date": "2021-04-08", "authors_parsed": [["Xu", "Jianyu", ""], ["Liu", "Bin", ""], ["Mo", "Huadong", ""], ["Dong", "Daoyi", ""]]}, {"id": "2104.02784", "submitter": "Karl-Philipp Kortmann", "authors": "Karl-Philipp Kortmann, Moritz Fehsenfeld and Mark Wielitzka", "title": "Autoencoder-based Representation Learning from Heterogeneous\n  Multivariate Time Series Data of Mechatronic Systems", "comments": "A later version of this paper in German language was submitted to VDI\n  Mechatronic Tagung 2021 and will be published in the conference proceedings", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI eess.SP", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Sensor and control data of modern mechatronic systems are often available as\nheterogeneous time series with different sampling rates and value ranges.\nSuitable classification and regression methods from the field of supervised\nmachine learning already exist for predictive tasks, for example in the context\nof condition monitoring, but their performance scales strongly with the number\nof labeled training data. Their provision is often associated with high effort\nin the form of person-hours or additional sensors. In this paper, we present a\nmethod for unsupervised feature extraction using autoencoder networks that\nspecifically addresses the heterogeneous nature of the database and reduces the\namount of labeled training data required compared to existing methods. Three\npublic datasets of mechatronic systems from different application domains are\nused to validate the results.\n", "versions": [{"version": "v1", "created": "Tue, 6 Apr 2021 21:04:27 GMT"}, {"version": "v2", "created": "Thu, 8 Apr 2021 12:39:35 GMT"}], "update_date": "2021-04-09", "authors_parsed": [["Kortmann", "Karl-Philipp", ""], ["Fehsenfeld", "Moritz", ""], ["Wielitzka", "Mark", ""]]}, {"id": "2104.02788", "submitter": "James Ferlez", "authors": "Ulices Santa Cruz and James Ferlez and Yasser Shoukry", "title": "Safe-by-Repair: A Convex Optimization Approach for Repairing Unsafe\n  Two-Level Lattice Neural Network Controllers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SY math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider the problem of repairing a data-trained Rectified\nLinear Unit (ReLU) Neural Network (NN) controller for a discrete-time,\ninput-affine system. That is we assume that such a NN controller is available,\nand we seek to repair unsafe closed-loop behavior at one known \"counterexample\"\nstate while simultaneously preserving a notion of safe closed-loop behavior on\na separate, verified set of states. To this end, we further assume that the NN\ncontroller has a Two-Level Lattice (TLL) architecture, and exhibit an algorithm\nthat can systematically and efficiently repair such an network. Facilitated by\nthis choice, our approach uses the unique semantics of the TLL architecture to\ndivide the repair problem into two significantly decoupled sub-problems, one of\nwhich is concerned with repairing the un-safe counterexample -- and hence is\nessentially of local scope -- and the other of which ensures that the repairs\nare realized in the output of the network -- and hence is essentially of global\nscope. We then show that one set of sufficient conditions for solving each\nthese sub-problems can be cast as a convex feasibility problem, and this allows\nus to formulate the TLL repair problem as two separate, but significantly\ndecoupled, convex optimization problems. Finally, we evaluate our algorithm on\na TLL controller on a simple dynamical model of a four-wheel-car.\n", "versions": [{"version": "v1", "created": "Tue, 6 Apr 2021 21:21:24 GMT"}], "update_date": "2021-04-08", "authors_parsed": [["Cruz", "Ulices Santa", ""], ["Ferlez", "James", ""], ["Shoukry", "Yasser", ""]]}, {"id": "2104.02789", "submitter": "Alexandr Kuznetsov", "authors": "Alexandr Kuznetsov, Krishna Mullia, Zexiang Xu, Milo\\v{s} Ha\\v{s}an\n  and Ravi Ramamoorthi", "title": "NeuMIP: Multi-Resolution Neural Materials", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GR cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose NeuMIP, a neural method for representing and rendering a variety\nof material appearances at different scales. Classical prefiltering\n(mipmapping) methods work well on simple material properties such as diffuse\ncolor, but fail to generalize to normals, self-shadowing, fibers or more\ncomplex microstructures and reflectances. In this work, we generalize\ntraditional mipmap pyramids to pyramids of neural textures, combined with a\nfully connected network. We also introduce neural offsets, a novel method which\nallows rendering materials with intricate parallax effects without any\ntessellation. This generalizes classical parallax mapping, but is trained\nwithout supervision by any explicit heightfield. Neural materials within our\nsystem support a 7-dimensional query, including position, incoming and outgoing\ndirection, and the desired filter kernel size. The materials have small storage\n(on the order of standard mipmapping except with more texture channels), and\ncan be integrated within common Monte-Carlo path tracing systems. We\ndemonstrate our method on a variety of materials, resulting in complex\nappearance across levels of detail, with accurate parallax, self-shadowing, and\nother effects.\n", "versions": [{"version": "v1", "created": "Tue, 6 Apr 2021 21:22:22 GMT"}], "update_date": "2021-04-08", "authors_parsed": [["Kuznetsov", "Alexandr", ""], ["Mullia", "Krishna", ""], ["Xu", "Zexiang", ""], ["Ha\u0161an", "Milo\u0161", ""], ["Ramamoorthi", "Ravi", ""]]}, {"id": "2104.02810", "submitter": "Michael Weylandt", "authors": "Michael Weylandt and George Michailidis and T. Mitchell Roddenberry", "title": "Sparse Partial Least Squares for Coarse Noisy Graph Alignment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.SI eess.SP stat.ME", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Graph signal processing (GSP) provides a powerful framework for analyzing\nsignals arising in a variety of domains. In many applications of GSP, multiple\nnetwork structures are available, each of which captures different aspects of\nthe same underlying phenomenon. To integrate these different data sources,\ngraph alignment techniques attempt to find the best correspondence between\nvertices of two graphs. We consider a generalization of this problem, where\nthere is no natural one-to-one mapping between vertices, but where there is\ncorrespondence between the community structures of each graph. Because we seek\nto learn structure at this higher community level, we refer to this problem as\n\"coarse\" graph alignment. To this end, we propose a novel regularized partial\nleast squares method which both incorporates the observed graph structures and\nimposes sparsity in order to reflect the underlying block community structure.\nWe provide efficient algorithms for our method and demonstrate its\neffectiveness in simulations.\n", "versions": [{"version": "v1", "created": "Tue, 6 Apr 2021 21:52:15 GMT"}], "update_date": "2021-04-08", "authors_parsed": [["Weylandt", "Michael", ""], ["Michailidis", "George", ""], ["Roddenberry", "T. Mitchell", ""]]}, {"id": "2104.02811", "submitter": "Steven Grosz Mr.", "authors": "Steven A. Grosz, Joshua J. Engelsma, and Anil K. Jain", "title": "C2CL: Contact to Contactless Fingerprint Matching", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Matching contactless fingerprints or finger photos to contact-based\nfingerprint impressions has received increased attention in the wake of\nCOVID-19 due to the superior hygiene of the contactless acquisition and the\nwidespread availability of low cost mobile phones capable of capturing photos\nof fingerprints with sufficient resolution for verification purposes. This\npaper presents an end-to-end automated system, called C2CL, comprised of a\nmobile finger photo capture app, preprocessing, and matching algorithms to\nhandle the challenges inhibiting previous cross-matching methods; namely i) low\nridge-valley contrast of contactless fingerprints, ii) varying roll, pitch,\nyaw, and distance of the finger to the camera, iii) non-linear distortion of\ncontact-based fingerprints, and vi) different image qualities of smartphone\ncameras. Our preprocessing algorithm segments, enhances, scales, and unwarps\ncontactless fingerprints, while our matching algorithm extracts both minutiae\nand texture representations. A sequestered dataset of 9,888 contactless 2D\nfingerprints and corresponding contact-based fingerprints from 206 subjects (2\nthumbs and 2 index fingers for each subject) acquired using our mobile capture\napp is used to evaluate the cross-database performance of our proposed\nalgorithm. Furthermore, additional experimental results on 3 publicly available\ndatasets demonstrate, for the first time, contact to contactless fingerprint\nmatching accuracy that is comparable to existing contact to contact fingerprint\nmatching systems (TAR in the range of 96.67% to 98.15% at FAR=0.01%).\n", "versions": [{"version": "v1", "created": "Tue, 6 Apr 2021 21:52:46 GMT"}, {"version": "v2", "created": "Thu, 8 Apr 2021 20:43:51 GMT"}], "update_date": "2021-04-12", "authors_parsed": [["Grosz", "Steven A.", ""], ["Engelsma", "Joshua J.", ""], ["Jain", "Anil K.", ""]]}, {"id": "2104.02819", "submitter": "Samuele Cornell", "authors": "Samuele Cornell, Alessio Brutti, Marco Matassoni, Stefano Squartini", "title": "Learning to Rank Microphones for Distant Speech Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fully exploiting ad-hoc microphone networks for distant speech recognition is\nstill an open issue. Empirical evidence shows that being able to select the\nbest microphone leads to significant improvements in recognition without any\nadditional effort on front-end processing. Current channel selection techniques\neither rely on signal, decoder or posterior-based features. Signal-based\nfeatures are inexpensive to compute but do not always correlate with\nrecognition performance. Instead decoder and posterior-based features exhibit\nbetter correlation but require substantial computational resources. In this\nwork, we tackle the channel selection problem by proposing MicRank, a learning\nto rank framework where a neural network is trained to rank the available\nchannels using directly the recognition performance on the training set. The\nproposed approach is agnostic with respect to the array geometry and type of\nrecognition back-end. We investigate different learning to rank strategies\nusing a synthetic dataset developed on purpose and the CHiME-6 data. Results\nshow that the proposed approach is able to considerably improve over previous\nselection techniques, reaching comparable and in some instances better\nperformance than oracle signal-based measures.\n", "versions": [{"version": "v1", "created": "Tue, 6 Apr 2021 22:39:30 GMT"}, {"version": "v2", "created": "Tue, 13 Apr 2021 21:19:23 GMT"}], "update_date": "2021-04-15", "authors_parsed": [["Cornell", "Samuele", ""], ["Brutti", "Alessio", ""], ["Matassoni", "Marco", ""], ["Squartini", "Stefano", ""]]}, {"id": "2104.02821", "submitter": "Cristian Canton Ferrer", "authors": "Caner Hazirbas, Joanna Bitton, Brian Dolhansky, Jacqueline Pan, Albert\n  Gordo, Cristian Canton Ferrer", "title": "Towards measuring fairness in AI: the Casual Conversations dataset", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a novel dataset to help researchers evaluate their\ncomputer vision and audio models for accuracy across a diverse set of age,\ngenders, apparent skin tones and ambient lighting conditions. Our dataset is\ncomposed of 3,011 subjects and contains over 45,000 videos, with an average of\n15 videos per person. The videos were recorded in multiple U.S. states with a\ndiverse set of adults in various age, gender and apparent skin tone groups. A\nkey feature is that each subject agreed to participate for their likenesses to\nbe used. Additionally, our age and gender annotations are provided by the\nsubjects themselves. A group of trained annotators labeled the subjects'\napparent skin tone using the Fitzpatrick skin type scale. Moreover, annotations\nfor videos recorded in low ambient lighting are also provided. As an\napplication to measure robustness of predictions across certain attributes, we\nprovide a comprehensive study on the top five winners of the DeepFake Detection\nChallenge (DFDC). Experimental evaluation shows that the winning models are\nless performant on some specific groups of people, such as subjects with darker\nskin tones and thus may not generalize to all people. In addition, we also\nevaluate the state-of-the-art apparent age and gender classification methods.\nOur experiments provides a through analysis on these models in terms of fair\ntreatment of people from various backgrounds.\n", "versions": [{"version": "v1", "created": "Tue, 6 Apr 2021 22:48:22 GMT"}], "update_date": "2021-04-08", "authors_parsed": [["Hazirbas", "Caner", ""], ["Bitton", "Joanna", ""], ["Dolhansky", "Brian", ""], ["Pan", "Jacqueline", ""], ["Gordo", "Albert", ""], ["Ferrer", "Cristian Canton", ""]]}, {"id": "2104.02822", "submitter": "Cenk Baykal", "authors": "Cenk Baykal, Lucas Liebenwein, Dan Feldman, Daniela Rus", "title": "Low-Regret Active learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop an online learning algorithm for identifying unlabeled data points\nthat are most informative for training (i.e., active learning). By formulating\nthe active learning problem as the prediction with sleeping experts problem, we\nprovide a framework for identifying informative data with respect to any given\ndefinition of informativeness. At the core of our work is an efficient\nalgorithm for sleeping experts that is tailored to achieve low regret on\npredictable (easy) instances while remaining resilient to adversarial ones.\nThis stands in contrast to state-of-the-art active learning methods that are\noverwhelmingly based on greedy selection, and hence cannot ensure good\nperformance across varying problem instances. We present empirical results\ndemonstrating that our method (i) instantiated with an informativeness measure\nconsistently outperforms its greedy counterpart and (ii) reliably outperforms\nuniform sampling on real-world data sets and models.\n", "versions": [{"version": "v1", "created": "Tue, 6 Apr 2021 22:53:45 GMT"}, {"version": "v2", "created": "Sat, 5 Jun 2021 01:22:38 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Baykal", "Cenk", ""], ["Liebenwein", "Lucas", ""], ["Feldman", "Dan", ""], ["Rus", "Daniela", ""]]}, {"id": "2104.02828", "submitter": "Antoine Prouvost", "authors": "Antoine Prouvost, Justin Dumouchelle, Maxime Gasse, Didier Ch\\'etelat,\n  Andrea Lodi", "title": "Ecole: A Library for Learning Inside MILP Solvers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper we describe Ecole (Extensible Combinatorial Optimization\nLearning Environments), a library to facilitate integration of machine learning\nin combinatorial optimization solvers. It exposes sequential decision making\nthat must be performed in the process of solving as Markov decision processes.\nThis means that, rather than trying to predict solutions to combinatorial\noptimization problems directly, Ecole allows machine learning to work in\ncooperation with a state-of-the-art a mixed-integer linear programming solver\nthat acts as a controllable algorithm. Ecole provides a collection of\ncomputationally efficient, ready to use learning environments, which are also\neasy to extend to define novel training tasks. Documentation and code can be\nfound at https://www.ecole.ai.\n", "versions": [{"version": "v1", "created": "Tue, 6 Apr 2021 23:36:16 GMT"}], "update_date": "2021-04-08", "authors_parsed": [["Prouvost", "Antoine", ""], ["Dumouchelle", "Justin", ""], ["Gasse", "Maxime", ""], ["Ch\u00e9telat", "Didier", ""], ["Lodi", "Andrea", ""]]}, {"id": "2104.02830", "submitter": "Shivangi Aneja Ms", "authors": "Pranjal Singh Rajput, Shivangi Aneja", "title": "IndoFashion : Apparel Classification for Indian Ethnic Clothes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cloth categorization is an important research problem that is used by\ne-commerce websites for displaying correct products to the end-users. Indian\nclothes have a large number of clothing categories both for men and women. The\ntraditional Indian clothes like \"Saree\" and \"Dhoti\" are worn very differently\nfrom western clothes like t-shirts and jeans. Moreover, the style and patterns\nof ethnic clothes have a very different distribution from western outfits. Thus\nthe models trained on standard cloth datasets fail miserably on ethnic outfits.\nTo address these challenges, we introduce the first large-scale ethnic dataset\nof over 106k images with 15 different categories for fine-grained\nclassification of Indian ethnic clothes. We gathered a diverse dataset from a\nlarge number of Indian e-commerce websites. We then evaluate several baselines\nfor the cloth classification task on our dataset. In the end, we obtain 88.43%\nclassification accuracy. We hope that our dataset would foster research in the\ndevelopment of several algorithms such as cloth classification, landmark\ndetection, especially for ethnic clothes.\n", "versions": [{"version": "v1", "created": "Tue, 6 Apr 2021 23:59:23 GMT"}], "update_date": "2021-04-08", "authors_parsed": [["Rajput", "Pranjal Singh", ""], ["Aneja", "Shivangi", ""]]}, {"id": "2104.02836", "submitter": "Yue Wang", "authors": "Yue Wang, Shaofeng Zou, Yi Zhou", "title": "Finite-Sample Analysis for Two Time-scale Non-linear TDC with General\n  Smooth Function Approximation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Temporal-difference learning with gradient correction (TDC) is a two\ntime-scale algorithm for policy evaluation in reinforcement learning. This\nalgorithm was initially proposed with linear function approximation, and was\nlater extended to the one with general smooth function approximation. The\nasymptotic convergence for the on-policy setting with general smooth function\napproximation was established in [bhatnagar2009convergent], however, the\nfinite-sample analysis remains unsolved due to challenges in the non-linear and\ntwo-time-scale update structure, non-convex objective function and the\ntime-varying projection onto a tangent plane. In this paper, we develop novel\ntechniques to explicitly characterize the finite-sample error bound for the\ngeneral off-policy setting with i.i.d.\\ or Markovian samples, and show that it\nconverges as fast as $\\mathcal O(1/\\sqrt T)$ (up to a factor of $\\mathcal\nO(\\log T)$). Our approach can be applied to a wide range of value-based\nreinforcement learning algorithms with general smooth function approximation.\n", "versions": [{"version": "v1", "created": "Wed, 7 Apr 2021 00:34:11 GMT"}], "update_date": "2021-04-08", "authors_parsed": [["Wang", "Yue", ""], ["Zou", "Shaofeng", ""], ["Zhou", "Yi", ""]]}, {"id": "2104.02858", "submitter": "Niko Moritz", "authors": "Niko Moritz, Takaaki Hori, Jonathan Le Roux", "title": "Capturing Multi-Resolution Context by Dilated Self-Attention", "comments": "In Proc. ICASSP 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Self-attention has become an important and widely used neural network\ncomponent that helped to establish new state-of-the-art results for various\napplications, such as machine translation and automatic speech recognition\n(ASR). However, the computational complexity of self-attention grows\nquadratically with the input sequence length. This can be particularly\nproblematic for applications such as ASR, where an input sequence generated\nfrom an utterance can be relatively long. In this work, we propose a\ncombination of restricted self-attention and a dilation mechanism, which we\nrefer to as dilated self-attention. The restricted self-attention allows\nattention to neighboring frames of the query at a high resolution, and the\ndilation mechanism summarizes distant information to allow attending to it with\na lower resolution. Different methods for summarizing distant frames are\nstudied, such as subsampling, mean-pooling, and attention-based pooling. ASR\nresults demonstrate substantial improvements compared to restricted\nself-attention alone, achieving similar results compared to full-sequence based\nself-attention with a fraction of the computational costs.\n", "versions": [{"version": "v1", "created": "Wed, 7 Apr 2021 02:04:18 GMT"}], "update_date": "2021-04-08", "authors_parsed": [["Moritz", "Niko", ""], ["Hori", "Takaaki", ""], ["Roux", "Jonathan Le", ""]]}, {"id": "2104.02863", "submitter": "Nathan Hatch", "authors": "Nathan Hatch (1) and Byron Boots (1) ((1) University of Washington)", "title": "The Value of Planning for Infinite-Horizon Model Predictive Control", "comments": "7 pages, 8 figures. To appear in the proceedings of the International\n  Conference on Robotics and Automation (ICRA) 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Model Predictive Control (MPC) is a classic tool for optimal control of\ncomplex, real-world systems. Although it has been successfully applied to a\nwide range of challenging tasks in robotics, it is fundamentally limited by the\nprediction horizon, which, if too short, will result in myopic decisions.\nRecently, several papers have suggested using a learned value function as the\nterminal cost for MPC. If the value function is accurate, it effectively allows\nMPC to reason over an infinite horizon. Unfortunately, Reinforcement Learning\n(RL) solutions to value function approximation can be difficult to realize for\nrobotics tasks. In this paper, we suggest a more efficient method for value\nfunction approximation that applies to goal-directed problems, like reaching\nand navigation. In these problems, MPC is often formulated to track a path or\ntrajectory returned by a planner. However, this strategy is brittle in that\nunexpected perturbations to the robot will require replanning, which can be\ncostly at runtime. Instead, we show how the intermediate data structures used\nby modern planners can be interpreted as an approximate value function. We show\nthat that this value function can be used by MPC directly, resulting in more\nefficient and resilient behavior at runtime.\n", "versions": [{"version": "v1", "created": "Wed, 7 Apr 2021 02:21:55 GMT"}], "update_date": "2021-04-08", "authors_parsed": [["Hatch", "Nathan", "", "University of Washington"], ["Boots", "Byron", "", "University of Washington"]]}, {"id": "2104.02865", "submitter": "Art Owen", "authors": "Sifan Liu and Art B. Owen", "title": "Quasi-Newton Quasi-Monte Carlo for variational Bayes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA math.NA stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Many machine learning problems optimize an objective that must be measured\nwith noise. The primary method is a first order stochastic gradient descent\nusing one or more Monte Carlo (MC) samples at each step. There are settings\nwhere ill-conditioning makes second order methods such as L-BFGS more\neffective. We study the use of randomized quasi-Monte Carlo (RQMC) sampling for\nsuch problems. When MC sampling has a root mean squared error (RMSE) of\n$O(n^{-1/2})$ then RQMC has an RMSE of $o(n^{-1/2})$ that can be close to\n$O(n^{-3/2})$ in favorable settings. We prove that improved sampling accuracy\ntranslates directly to improved optimization. In our empirical investigations\nfor variational Bayes, using RQMC with stochastic L-BFGS greatly speeds up the\noptimization, and sometimes finds a better parameter value than MC does.\n", "versions": [{"version": "v1", "created": "Wed, 7 Apr 2021 02:34:03 GMT"}, {"version": "v2", "created": "Wed, 21 Apr 2021 00:58:02 GMT"}], "update_date": "2021-04-22", "authors_parsed": [["Liu", "Sifan", ""], ["Owen", "Art B.", ""]]}, {"id": "2104.02869", "submitter": "Ugur Demir", "authors": "Ugur Demir, Ismail Irmakci, Elif Keles, Ahmet Topcu, Ziyue Xu,\n  Concetto Spampinato, Sachin Jambawalikar, Evrim Turkbey, Baris Turkbey, Ulas\n  Bagci", "title": "Information Bottleneck Attribution for Visual Explanations of Diagnosis\n  and Prognosis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Visual explanation methods have an important role in the prognosis of the\npatients where the annotated data is limited or unavailable. There have been\nseveral attempts to use gradient-based attribution methods to localize\npathology from medical scans without using segmentation labels. This research\ndirection has been impeded by the lack of robustness and reliability. These\nmethods are highly sensitive to the network parameters. In this study, we\nintroduce a robust visual explanation method to address this problem for\nmedical applications. We provide an innovative visual explanation algorithm for\ngeneral purpose and as an example application, we demonstrate its effectiveness\nfor quantifying lesions in the lungs caused by the Covid-19 with high accuracy\nand robustness without using dense segmentation labels. This approach overcomes\nthe drawbacks of commonly used Grad-CAM and its extended versions. The premise\nbehind our proposed strategy is that the information flow is minimized while\nensuring the classifier prediction stays similar. Our findings indicate that\nthe bottleneck condition provides a more stable severity estimation than the\nsimilar attribution methods.\n", "versions": [{"version": "v1", "created": "Wed, 7 Apr 2021 02:43:52 GMT"}, {"version": "v2", "created": "Wed, 23 Jun 2021 01:13:39 GMT"}], "update_date": "2021-06-24", "authors_parsed": [["Demir", "Ugur", ""], ["Irmakci", "Ismail", ""], ["Keles", "Elif", ""], ["Topcu", "Ahmet", ""], ["Xu", "Ziyue", ""], ["Spampinato", "Concetto", ""], ["Jambawalikar", "Sachin", ""], ["Turkbey", "Evrim", ""], ["Turkbey", "Baris", ""], ["Bagci", "Ulas", ""]]}, {"id": "2104.02871", "submitter": "Andy Shih", "authors": "Andy Shih and Arjun Sawhney and Jovana Kondic and Stefano Ermon and\n  Dorsa Sadigh", "title": "On the Critical Role of Conventions in Adaptive Human-AI Collaboration", "comments": "9th International Conference on Learning Representations (ICLR 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humans can quickly adapt to new partners in collaborative tasks (e.g. playing\nbasketball), because they understand which fundamental skills of the task (e.g.\nhow to dribble, how to shoot) carry over across new partners. Humans can also\nquickly adapt to similar tasks with the same partners by carrying over\nconventions that they have developed (e.g. raising hand signals pass the ball),\nwithout learning to coordinate from scratch. To collaborate seamlessly with\nhumans, AI agents should adapt quickly to new partners and new tasks as well.\nHowever, current approaches have not attempted to distinguish between the\ncomplexities intrinsic to a task and the conventions used by a partner, and\nmore generally there has been little focus on leveraging conventions for\nadapting to new settings. In this work, we propose a learning framework that\nteases apart rule-dependent representation from convention-dependent\nrepresentation in a principled way. We show that, under some assumptions, our\nrule-dependent representation is a sufficient statistic of the distribution\nover best-response strategies across partners. Using this separation of\nrepresentations, our agents are able to adapt quickly to new partners, and to\ncoordinate with old partners on new tasks in a zero-shot manner. We\nexperimentally validate our approach on three collaborative tasks varying in\ncomplexity: a contextual multi-armed bandit, a block placing task, and the card\ngame Hanabi.\n", "versions": [{"version": "v1", "created": "Wed, 7 Apr 2021 02:46:19 GMT"}], "update_date": "2021-04-08", "authors_parsed": [["Shih", "Andy", ""], ["Sawhney", "Arjun", ""], ["Kondic", "Jovana", ""], ["Ermon", "Stefano", ""], ["Sadigh", "Dorsa", ""]]}, {"id": "2104.02872", "submitter": "Daniel Ahfock", "authors": "Daniel Ahfock and Geoffrey J. McLachlan", "title": "Harmless label noise and informative soft-labels in supervised\n  classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Manual labelling of training examples is common practice in supervised\nlearning. When the labelling task is of non-trivial difficulty, the supplied\nlabels may not be equal to the ground-truth labels, and label noise is\nintroduced into the training dataset. If the manual annotation is carried out\nby multiple experts, the same training example can be given different class\nassignments by different experts, which is indicative of label noise. In the\nframework of model-based classification, a simple, but key observation is that\nwhen the manual labels are sampled using the posterior probabilities of class\nmembership, the noisy labels are as valuable as the ground-truth labels in\nterms of statistical information. A relaxation of this process is a random\neffects model for imperfect labelling by a group that uses approximate\nposterior probabilities of class membership. The relative efficiency of\nlogistic regression using the noisy labels compared to logistic regression\nusing the ground-truth labels can then be derived. The main finding is that\nlogistic regression can be robust to label noise when label noise and\nclassification difficulty are positively correlated. In particular, when\nclassification difficulty is the only source of label errors, multiple sets of\nnoisy labels can supply more information for the estimation of a classification\nrule compared to the single set of ground-truth labels.\n", "versions": [{"version": "v1", "created": "Wed, 7 Apr 2021 02:56:11 GMT"}], "update_date": "2021-04-08", "authors_parsed": [["Ahfock", "Daniel", ""], ["McLachlan", "Geoffrey J.", ""]]}, {"id": "2104.02878", "submitter": "Jee-Weon Jung", "authors": "Jee-weon Jung, Hee-Soo Heo, Youngki Kwon, Joon Son Chung, Bong-Jin Lee", "title": "Three-class Overlapped Speech Detection using a Convolutional Recurrent\n  Neural Network", "comments": "5 pages, 2 figures, 4 tables, submitted to Interspeech as a\n  conference paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we propose an overlapped speech detection system trained as a\nthree-class classifier. Unlike conventional systems that perform binary\nclassification as to whether or not a frame contains overlapped speech, the\nproposed approach classifies into three classes: non-speech, single speaker\nspeech, and overlapped speech. By training a network with the more detailed\nlabel definition, the model can learn a better notion on deciding the number of\nspeakers included in a given frame. A convolutional recurrent neural network\narchitecture is explored to benefit from both convolutional layer's capability\nto model local patterns and recurrent layer's ability to model sequential\ninformation. The proposed overlapped speech detection model establishes a\nstate-of-the-art performance with a precision of 0.6648 and a recall of 0.3222\non the DIHARD II evaluation set, showing a 20% increase in recall along with\nhigher precision. In addition, we also introduce a simple approach to utilize\nthe proposed overlapped speech detection model for speaker diarization which\nranked third place in the Track 1 of the DIHARD III challenge.\n", "versions": [{"version": "v1", "created": "Wed, 7 Apr 2021 03:01:34 GMT"}], "update_date": "2021-04-08", "authors_parsed": [["Jung", "Jee-weon", ""], ["Heo", "Hee-Soo", ""], ["Kwon", "Youngki", ""], ["Chung", "Joon Son", ""], ["Lee", "Bong-Jin", ""]]}, {"id": "2104.02879", "submitter": "Jee-Weon Jung", "authors": "Youngki Kwon, Jee-weon Jung, Hee-Soo Heo, You Jin Kim, Bong-Jin Lee,\n  Joon Son Chung", "title": "Adapting Speaker Embeddings for Speaker Diarisation", "comments": "5 pages, 2 figures, 3 tables, submitted to Interspeech as a\n  conference paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of this paper is to adapt speaker embeddings for solving the problem\nof speaker diarisation. The quality of speaker embeddings is paramount to the\nperformance of speaker diarisation systems. Despite this, prior works in the\nfield have directly used embeddings designed only to be effective on the\nspeaker verification task. In this paper, we propose three techniques that can\nbe used to better adapt the speaker embeddings for diarisation: dimensionality\nreduction, attention-based embedding aggregation, and non-speech clustering. A\nwide range of experiments is performed on various challenging datasets. The\nresults demonstrate that all three techniques contribute positively to the\nperformance of the diarisation system achieving an average relative improvement\nof 25.07% in terms of diarisation error rate over the baseline.\n", "versions": [{"version": "v1", "created": "Wed, 7 Apr 2021 03:04:47 GMT"}], "update_date": "2021-04-08", "authors_parsed": [["Kwon", "Youngki", ""], ["Jung", "Jee-weon", ""], ["Heo", "Hee-Soo", ""], ["Kim", "You Jin", ""], ["Lee", "Bong-Jin", ""], ["Chung", "Joon Son", ""]]}, {"id": "2104.02883", "submitter": "Mingyuan Wang", "authors": "Mingyuan Wang, Adrian Barbu", "title": "Online Feature Screening for Data Streams with Concept Drift", "comments": "8 figures, 30 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Screening feature selection methods are often used as a preprocessing step\nfor reducing the number of variables before training step. Traditional\nscreening methods only focus on dealing with complete high dimensional\ndatasets. Modern datasets not only have higher dimension and larger sample\nsize, but also have properties such as streaming input, sparsity and concept\ndrift. Therefore a considerable number of online feature selection methods were\nintroduced to handle these kind of problems in recent years. Online screening\nmethods are one of the categories of online feature selection methods. The\nmethods that we proposed in this research are capable of handling all three\nsituations mentioned above. Our research study focuses on classification\ndatasets. Our experiments show proposed methods can generate the same feature\nimportance as their offline version with faster speed and less storage\nconsumption. Furthermore, the results show that online screening methods with\nintegrated model adaptation have a higher true feature detection rate than\nwithout model adaptation on data streams with the concept drift property. Among\nthe two large real datasets that potentially have the concept drift property,\nonline screening methods with model adaptation show advantages in either saving\ncomputing time and space, reducing model complexity, or improving prediction\naccuracy.\n", "versions": [{"version": "v1", "created": "Wed, 7 Apr 2021 03:16:15 GMT"}], "update_date": "2021-04-08", "authors_parsed": [["Wang", "Mingyuan", ""], ["Barbu", "Adrian", ""]]}, {"id": "2104.02895", "submitter": "Jong Chul Ye", "authors": "Byung-Hoon Kim, Joonyoung Song, Jong Chul Ye, JaeHyun Baek", "title": "PyNET-CA: Enhanced PyNET with Channel Attention for End-to-End Mobile\n  Image Signal Processing", "comments": "ECCV 2020 AIM workshop accepted version", "journal-ref": null, "doi": "10.1007/978-3-030-67070-2_12", "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reconstructing RGB image from RAW data obtained with a mobile device is\nrelated to a number of image signal processing (ISP) tasks, such as\ndemosaicing, denoising, etc. Deep neural networks have shown promising results\nover hand-crafted ISP algorithms on solving these tasks separately, or even\nreplacing the whole reconstruction process with one model. Here, we propose\nPyNET-CA, an end-to-end mobile ISP deep learning algorithm for RAW to RGB\nreconstruction. The model enhances PyNET, a recently proposed state-of-the-art\nmodel for mobile ISP, and improve its performance with channel attention and\nsubpixel reconstruction module. We demonstrate the performance of the proposed\nmethod with comparative experiments and results from the AIM 2020 learned\nsmartphone ISP challenge. The source code of our implementation is available at\nhttps://github.com/egyptdj/skyb-aim2020-public\n", "versions": [{"version": "v1", "created": "Wed, 7 Apr 2021 03:40:11 GMT"}], "update_date": "2021-04-08", "authors_parsed": [["Kim", "Byung-Hoon", ""], ["Song", "Joonyoung", ""], ["Ye", "Jong Chul", ""], ["Baek", "JaeHyun", ""]]}, {"id": "2104.02899", "submitter": "Alexander Ororbia", "authors": "Ankur Mali, Alexander Ororbia, Daniel Kifer, C. Lee Giles", "title": "Recognizing and Verifying Mathematical Equations using Multiplicative\n  Differential Neural Units", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automated mathematical reasoning is a challenging problem that requires an\nagent to learn algebraic patterns that contain long-range dependencies. Two\nparticular tasks that test this type of reasoning are (1) mathematical equation\nverification, which requires determining whether trigonometric and linear\nalgebraic statements are valid identities or not, and (2) equation completion,\nwhich entails filling in a blank within an expression to make it true. Solving\nthese tasks with deep learning requires that the neural model learn how to\nmanipulate and compose various algebraic symbols, carrying this ability over to\npreviously unseen expressions. Artificial neural networks, including recurrent\nnetworks and transformers, struggle to generalize on these kinds of difficult\ncompositional problems, often exhibiting poor extrapolation performance. In\ncontrast, recursive neural networks (recursive-NNs) are, theoretically, capable\nof achieving better extrapolation due to their tree-like design but are\ndifficult to optimize as the depth of their underlying tree structure\nincreases. To overcome this issue, we extend recursive-NNs to utilize\nmultiplicative, higher-order synaptic connections and, furthermore, to learn to\ndynamically control and manipulate an external memory. We argue that this key\nmodification gives the neural system the ability to capture powerful transition\nfunctions for each possible input. We demonstrate the effectiveness of our\nproposed higher-order, memory-augmented recursive-NN models on two challenging\nmathematical equation tasks, showing improved extrapolation, stable\nperformance, and faster convergence. Our models achieve a 1.53% average\nimprovement over current state-of-the-art methods in equation verification and\nachieve a 2.22% Top-1 average accuracy and 2.96% Top-5 average accuracy for\nequation completion.\n", "versions": [{"version": "v1", "created": "Wed, 7 Apr 2021 03:50:11 GMT"}], "update_date": "2021-04-08", "authors_parsed": [["Mali", "Ankur", ""], ["Ororbia", "Alexander", ""], ["Kifer", "Daniel", ""], ["Giles", "C. Lee", ""]]}, {"id": "2104.02912", "submitter": "Xiangyu Yang", "authors": "Hao Wang, Xiangyu Yang, and Wei Jiang", "title": "An Iteratively Reweighted Method for Sparse Optimization on Nonconvex\n  $\\ell_{p}$ Ball", "comments": "This work has been submitted and may be published. Copyright may be\n  transferred without notice, after which this version may no longer be\n  accessible", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is intended to solve the nonconvex $\\ell_{p}$-ball constrained\nnonlinear optimization problems. An iteratively reweighted method is proposed,\nwhich solves a sequence of weighted $\\ell_{1}$-ball projection subproblems. At\neach iteration, the next iterate is obtained by moving along the negative\ngradient with a stepsize and then projecting the resulted point onto the\nweighted $\\ell_{1}$ ball to approximate the $\\ell_{p}$ ball. Specifically, if\nthe current iterate is in the interior of the feasible set, then the weighted\n$\\ell_{1}$ ball is formed by linearizing the $\\ell_{p}$ norm at the current\niterate. If the current iterate is on the boundary of the feasible set, then\nthe weighted $\\ell_{1}$ ball is formed differently by keeping those zero\ncomponents in the current iterate still zero. In our analysis, we prove that\nthe generated iterates converge to a first-order stationary point. Numerical\nexperiments demonstrate the effectiveness of the proposed method.\n", "versions": [{"version": "v1", "created": "Wed, 7 Apr 2021 04:43:36 GMT"}], "update_date": "2021-04-08", "authors_parsed": [["Wang", "Hao", ""], ["Yang", "Xiangyu", ""], ["Jiang", "Wei", ""]]}, {"id": "2104.02922", "submitter": "Suryabhan Singh Hada", "authors": "Suryabhan Singh Hada and Miguel \\'A. Carreira-Perpi\\~n\\'an and Arman\n  Zharmagambetov", "title": "Sparse Oblique Decision Trees: A Tool to Understand and Manipulate\n  Neural Net Features", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The widespread deployment of deep nets in practical applications has lead to\na growing desire to understand how and why such black-box methods perform\nprediction. Much work has focused on understanding what part of the input\npattern (an image, say) is responsible for a particular class being predicted,\nand how the input may be manipulated to predict a different class. We focus\ninstead on understanding which of the internal features computed by the neural\nnet are responsible for a particular class. We achieve this by mimicking part\nof the neural net with an oblique decision tree having sparse weight vectors at\nthe decision nodes. Using the recently proposed Tree Alternating Optimization\n(TAO) algorithm, we are able to learn trees that are both highly accurate and\ninterpretable. Such trees can faithfully mimic the part of the neural net they\nreplaced, and hence they can provide insights into the deep net black box.\nFurther, we show we can easily manipulate the neural net features in order to\nmake the net predict, or not predict, a given class, thus showing that it is\npossible to carry out adversarial attacks at the level of the features. These\ninsights and manipulations apply globally to the entire training and test set,\nnot just at a local (single-instance) level. We demonstrate this robustly in\nthe MNIST and ImageNet datasets with LeNet5 and VGG networks.\n", "versions": [{"version": "v1", "created": "Wed, 7 Apr 2021 05:31:08 GMT"}], "update_date": "2021-04-08", "authors_parsed": [["Hada", "Suryabhan Singh", ""], ["Carreira-Perpi\u00f1\u00e1n", "Miguel \u00c1.", ""], ["Zharmagambetov", "Arman", ""]]}, {"id": "2104.02925", "submitter": "Alexandre Thiery", "authors": "Rahul Rahaman, Atin Ghosh and Alexandre H. Thiery", "title": "Pretrained equivariant features improve unsupervised landmark discovery", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Locating semantically meaningful landmark points is a crucial component of a\nlarge number of computer vision pipelines. Because of the small number of\navailable datasets with ground truth landmark annotations, it is important to\ndesign robust unsupervised and semi-supervised methods for landmark detection.\n  Many of the recent unsupervised learning methods rely on the equivariance\nproperties of landmarks to synthetic image deformations. Our work focuses on\nsuch widely used methods and sheds light on its core problem, its inability to\nproduce equivariant intermediate convolutional features. This finding leads us\nto formulate a two-step unsupervised approach that overcomes this challenge by\nfirst learning powerful pixel-based features and then use the pre-trained\nfeatures to learn a landmark detector by the traditional equivariance method.\nOur method produces state-of-the-art results in several challenging landmark\ndetection datasets such as the BBC Pose dataset and the Cat-Head dataset. It\nperforms comparably on a range of other benchmarks.\n", "versions": [{"version": "v1", "created": "Wed, 7 Apr 2021 05:42:11 GMT"}], "update_date": "2021-04-08", "authors_parsed": [["Rahaman", "Rahul", ""], ["Ghosh", "Atin", ""], ["Thiery", "Alexandre H.", ""]]}, {"id": "2104.02929", "submitter": "AmirEmad Ghassami", "authors": "AmirEmad Ghassami, Andrew Ying, Ilya Shpitser, Eric Tchetgen Tchetgen", "title": "Minimax Kernel Machine Learning for a Class of Doubly Robust Functionals", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG econ.EM math.ST stat.TH", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A moment function is called doubly robust if it is comprised of two nuisance\nfunctions and the estimator based on it is a consistent estimator of the target\nparameter even if one of the nuisance functions is misspecified. In this paper,\nwe consider a class of doubly robust moment functions originally introduced in\n(Robins et al., 2008). We demonstrate that this moment function can be used to\nconstruct estimating equations for the nuisance functions. The main idea is to\nchoose each nuisance function such that it minimizes the dependency of the\nexpected value of the moment function to the other nuisance function. We\nimplement this idea as a minimax optimization problem. We then provide\nconditions required for asymptotic linearity of the estimator of the parameter\nof interest, which are based on the convergence rate of the product of the\nerrors of the nuisance functions, as well as the local ill-posedness of a\nconditional expectation operator. The convergence rates of the nuisance\nfunctions are analyzed using the modern techniques in statistical learning\ntheory based on the Rademacher complexity of the function spaces. We\nspecifically focus on the case that the function spaces are reproducing kernel\nHilbert spaces, which enables us to use its spectral properties to analyze the\nconvergence rates. As an application of the proposed methodology, we consider\nthe parameter of average causal effect both in presence and absence of latent\nconfounders. For the case of presence of latent confounders, we use the\nrecently proposed proximal causal inference framework of (Miao et al., 2018;\nTchetgen Tchetgen et al., 2020), and hence our results lead to a robust\nnon-parametric estimator for average causal effect in this framework.\n", "versions": [{"version": "v1", "created": "Wed, 7 Apr 2021 05:52:15 GMT"}], "update_date": "2021-04-08", "authors_parsed": [["Ghassami", "AmirEmad", ""], ["Ying", "Andrew", ""], ["Shpitser", "Ilya", ""], ["Tchetgen", "Eric Tchetgen", ""]]}, {"id": "2104.02932", "submitter": "Tingyi Wanyan", "authors": "Tingyi Wanyan, Jing Zhang, Ying Ding, Ariful Azad, Zhangyang Wang,\n  Benjamin S Glicksberg", "title": "Bootstrapping Your Own Positive Sample: Contrastive Learning With\n  Electronic Health Record Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Electronic Health Record (EHR) data has been of tremendous utility in\nArtificial Intelligence (AI) for healthcare such as predicting future clinical\nevents. These tasks, however, often come with many challenges when using\nclassical machine learning models due to a myriad of factors including class\nimbalance and data heterogeneity (i.e., the complex intra-class variances). To\naddress some of these research gaps, this paper leverages the exciting\ncontrastive learning framework and proposes a novel contrastive regularized\nclinical classification model. The contrastive loss is found to substantially\naugment EHR-based prediction: it effectively characterizes the\nsimilar/dissimilar patterns (by its \"push-and-pull\" form), meanwhile mitigating\nthe highly skewed class distribution by learning more balanced feature spaces\n(as also echoed by recent findings). In particular, when naively exporting the\ncontrastive learning to the EHR data, one hurdle is in generating positive\nsamples, since EHR data is not as amendable to data augmentation as image data.\nTo this end, we have introduced two unique positive sampling strategies\nspecifically tailored for EHR data: a feature-based positive sampling that\nexploits the feature space neighborhood structure to reinforce the feature\nlearning; and an attribute-based positive sampling that incorporates\npre-generated patient similarity metrics to define the sample proximity. Both\nsampling approaches are designed with an awareness of unique high intra-class\nvariance in EHR data. Our overall framework yields highly competitive\nexperimental results in predicting the mortality risk on real-world COVID-19\nEHR data with a total of 5,712 patients admitted to a large, urban health\nsystem. Specifically, our method reaches a high AUROC prediction score of\n0.959, which outperforms other baselines and alternatives: cross-entropy(0.873)\nand focal loss(0.931).\n", "versions": [{"version": "v1", "created": "Wed, 7 Apr 2021 06:02:04 GMT"}], "update_date": "2021-04-08", "authors_parsed": [["Wanyan", "Tingyi", ""], ["Zhang", "Jing", ""], ["Ding", "Ying", ""], ["Azad", "Ariful", ""], ["Wang", "Zhangyang", ""], ["Glicksberg", "Benjamin S", ""]]}, {"id": "2104.02934", "submitter": "Jiayang Cheng", "authors": "Jiayang Cheng, Haiyun Jiang, Deqing Yang, Yanghua Xiao", "title": "A Question-answering Based Framework for Relation Extraction Validation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Relation extraction is an important task in knowledge acquisition and text\nunderstanding. Existing works mainly focus on improving relation extraction by\nextracting effective features or designing reasonable model structures.\nHowever, few works have focused on how to validate and correct the results\ngenerated by the existing relation extraction models. We argue that validation\nis an important and promising direction to further improve the performance of\nrelation extraction. In this paper, we explore the possibility of using\nquestion answering as validation. Specifically, we propose a novel\nquestion-answering based framework to validate the results from relation\nextraction models. Our proposed framework can be easily applied to existing\nrelation classifiers without any additional information. We conduct extensive\nexperiments on the popular NYT dataset to evaluate the proposed framework, and\nobserve consistent improvements over five strong baselines.\n", "versions": [{"version": "v1", "created": "Wed, 7 Apr 2021 06:08:36 GMT"}], "update_date": "2021-04-08", "authors_parsed": [["Cheng", "Jiayang", ""], ["Jiang", "Haiyun", ""], ["Yang", "Deqing", ""], ["Xiao", "Yanghua", ""]]}, {"id": "2104.02935", "submitter": "Yi Ding", "authors": "Yi Ding, Neethu Robinson, Qiuhao Zeng, Cuntai Guan", "title": "TSception: Capturing Temporal Dynamics and Spatial Asymmetry from EEG\n  for Emotion Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose TSception, a multi-scale convolutional neural\nnetwork, to learn temporal dynamics and spatial asymmetry from affective\nelectroencephalogram (EEG). TSception consists of dynamic temporal, asymmetric\nspatial, and high-level fusion Layers, which learn discriminative\nrepresentations in the time and channel dimensions simultaneously. The dynamic\ntemporal layer consists of multi-scale 1D convolutional kernels whose lengths\nare related to the sampling rate of the EEG signal, which learns its dynamic\ntemporal and frequency representations. The asymmetric spatial layer takes\nadvantage of the asymmetric neural activations underlying emotional responses,\nlearning the discriminative global and hemisphere representations. The learned\nspatial representations will be fused by a high-level fusion layer. With robust\nnested cross-validation settings, the proposed method is evaluated on two\npublicly available datasets DEAP and AMIGOS. And the performance is compared\nwith prior reported methods such as FBFgMDM, FBTSC, Unsupervised learning,\nDeepConvNet, ShallowConvNet, and EEGNet. The results indicate that the proposed\nmethod significantly (p<0.05) outperforms others in terms of classification\naccuracy. The proposed methods can be utilized in emotion regulation therapy\nfor emotion recognition in the future. The source code can be found at:\nhttps://github.com/deepBrains/TSception-New\n", "versions": [{"version": "v1", "created": "Wed, 7 Apr 2021 06:10:01 GMT"}], "update_date": "2021-04-08", "authors_parsed": [["Ding", "Yi", ""], ["Robinson", "Neethu", ""], ["Zeng", "Qiuhao", ""], ["Guan", "Cuntai", ""]]}, {"id": "2104.02938", "submitter": "Ini Oguntola", "authors": "Ini Oguntola, Dana Hughes, Katia Sycara", "title": "Deep Interpretable Models of Theory of Mind", "comments": "RO-MAN 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  When developing AI systems that interact with humans, it is essential to\ndesign both a system that can understand humans, and a system that humans can\nunderstand. Most deep network based agent-modeling approaches are 1) not\ninterpretable and 2) only model external behavior, ignoring internal mental\nstates, which potentially limits their capability for assistance,\ninterventions, discovering false beliefs, etc. To this end, we develop an\ninterpretable modular neural framework for modeling the intentions of other\nobserved entities. We demonstrate the efficacy of our approach with experiments\non data from human participants on a search and rescue task in Minecraft, and\nshow that incorporating interpretability can significantly increase predictive\nperformance under the right conditions.\n", "versions": [{"version": "v1", "created": "Wed, 7 Apr 2021 06:18:58 GMT"}, {"version": "v2", "created": "Mon, 12 Jul 2021 18:22:30 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Oguntola", "Ini", ""], ["Hughes", "Dana", ""], ["Sycara", "Katia", ""]]}, {"id": "2104.02947", "submitter": "Happy Mittal", "authors": "Happy Mittal, Aniket Chakrabarti, Belhassen Bayar, Animesh Anant\n  Sharma, Nikhil Rasiwasia", "title": "Distantly Supervised Transformers For E-Commerce Product QA", "comments": "NAACL 2021 (10 pages)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a practical instant question answering (QA) system on product\npages of ecommerce services, where for each user query, relevant community\nquestion answer (CQA) pairs are retrieved. User queries and CQA pairs differ\nsignificantly in language characteristics making relevance learning difficult.\nOur proposed transformer-based model learns a robust relevance function by\njointly learning unified syntactic and semantic representations without the\nneed for human labeled data. This is achieved by distantly supervising our\nmodel by distilling from predictions of a syntactic matching system on user\nqueries and simultaneously training with CQA pairs. Training with CQA pairs\nhelps our model learning semantic QA relevance and distant supervision enables\nlearning of syntactic features as well as the nuances of user querying\nlanguage. Additionally, our model encodes queries and candidate responses\nindependently allowing offline candidate embedding generation thereby\nminimizing the need for real-time transformer model execution. Consequently,\nour framework is able to scale to large e-commerce QA traffic. Extensive\nevaluation on user queries shows that our framework significantly outperforms\nboth syntactic and semantic baselines in offline as well as large scale online\nA/B setups of a popular e-commerce service.\n", "versions": [{"version": "v1", "created": "Wed, 7 Apr 2021 06:37:16 GMT"}], "update_date": "2021-04-08", "authors_parsed": [["Mittal", "Happy", ""], ["Chakrabarti", "Aniket", ""], ["Bayar", "Belhassen", ""], ["Sharma", "Animesh Anant", ""], ["Rasiwasia", "Nikhil", ""]]}, {"id": "2104.02951", "submitter": "Luis Larios-C\\'ardenas", "authors": "Luis \\'Angel Larios-C\\'ardenas and Frederic Gibou", "title": "A Hybrid Inference System for Improved Curvature Estimation in the\n  Level-Set Method Using Machine Learning", "comments": "Submitted", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA math.NA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present a novel hybrid strategy based on machine learning to improve\ncurvature estimation in the level-set method. The proposed inference system\ncouples enhanced neural networks with standard numerical schemes to compute\ncurvature more accurately. The core of our hybrid framework is a switching\nmechanism that relies on well established numerical techniques to gauge\ncurvature. If the curvature magnitude is larger than a resolution-dependent\nthreshold, it uses a neural network to yield a better approximation. Our\nnetworks are multilayer perceptrons fitted to synthetic data sets composed of\nsinusoidal- and circular-interface samples at various configurations. To reduce\ndata set size and training complexity, we leverage the problem's characteristic\nsymmetry and build our models on just half of the curvature spectrum. These\nsavings lead to a powerful inference system able to outperform any of its\nnumerical or neural component alone. Experiments with static, smooth interfaces\nshow that our hybrid solver is notably superior to conventional numerical\nmethods in coarse grids and along steep interface regions. Compared to prior\nresearch, we have observed outstanding gains in precision after training the\nregression model with data pairs from more than a single interface type and\ntransforming data with specialized input preprocessing. In particular, our\nfindings confirm that machine learning is a promising venue for reducing or\nremoving mass loss in the level-set method.\n", "versions": [{"version": "v1", "created": "Wed, 7 Apr 2021 06:51:52 GMT"}, {"version": "v2", "created": "Fri, 4 Jun 2021 18:36:50 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Larios-C\u00e1rdenas", "Luis \u00c1ngel", ""], ["Gibou", "Frederic", ""]]}, {"id": "2104.02959", "submitter": "Badr AlKhamissi", "authors": "Badr AlKhamissi, Muhammad ElNokrashy, Michael Spranger", "title": "The Emergence of Abstract and Episodic Neurons in Episodic Meta-RL", "comments": "This work was accepted at the Learning to Learn Workshop (ICLR 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  In this work, we analyze the reinstatement mechanism introduced by Ritter et\nal. (2018) to reveal two classes of neurons that emerge in the agent's working\nmemory (an epLSTM cell) when trained using episodic meta-RL on an episodic\nvariant of the Harlow visual fixation task. Specifically, Abstract neurons\nencode knowledge shared across tasks, while Episodic neurons carry information\nrelevant for a specific episode's task.\n", "versions": [{"version": "v1", "created": "Wed, 7 Apr 2021 07:25:52 GMT"}], "update_date": "2021-04-08", "authors_parsed": [["AlKhamissi", "Badr", ""], ["ElNokrashy", "Muhammad", ""], ["Spranger", "Michael", ""]]}, {"id": "2104.02962", "submitter": "Zeyu Cui", "authors": "Zeyu Cui, Zekun Li, Shu Wu, Xiaoyu Zhang, Qiang Liu, Liang Wang,\n  Mengmeng Ai", "title": "DyGCN: Dynamic Graph Embedding with Graph Convolutional Network", "comments": "21 pages, 5 figures, submitted to TOIS", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph embedding, aiming to learn low-dimensional representations (aka.\nembeddings) of nodes, has received significant attention recently. Recent years\nhave witnessed a surge of efforts made on static graphs, among which Graph\nConvolutional Network (GCN) has emerged as an effective class of models.\nHowever, these methods mainly focus on the static graph embedding. In this\nwork, we propose an efficient dynamic graph embedding approach, Dynamic Graph\nConvolutional Network (DyGCN), which is an extension of GCN-based methods. We\nnaturally generalizes the embedding propagation scheme of GCN to dynamic\nsetting in an efficient manner, which is to propagate the change along the\ngraph to update node embeddings. The most affected nodes are first updated, and\nthen their changes are propagated to the further nodes and leads to their\nupdate. Extensive experiments conducted on various dynamic graphs demonstrate\nthat our model can update the node embeddings in a time-saving and\nperformance-preserving way.\n", "versions": [{"version": "v1", "created": "Wed, 7 Apr 2021 07:28:44 GMT"}], "update_date": "2021-04-08", "authors_parsed": [["Cui", "Zeyu", ""], ["Li", "Zekun", ""], ["Wu", "Shu", ""], ["Zhang", "Xiaoyu", ""], ["Liu", "Qiang", ""], ["Wang", "Liang", ""], ["Ai", "Mengmeng", ""]]}, {"id": "2104.02963", "submitter": "Jinlai Zhang", "authors": "Jinlai Zhang, Binbin Liu, Lyvjie Chen, Bo Ouyang, Jihong Zhu, Minchi\n  Kuang, Houqing Wang, Yanmei Meng", "title": "The art of defense: letting networks fool the attacker", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Some deep neural networks are invariant to some input transformations, such\nas Pointnet is permutation invariant to the input point cloud. In this paper,\nwe demonstrated this property could be powerful in defense of gradient-based\nattacks. Specifically, we apply random input transformation which is invariant\nto the networks we want to defend. Extensive experiments demonstrate that the\nproposed scheme defeats various gradient-based attackers in the targeted attack\nsetting, and breaking the attack accuracy into nearly zero. Our code is\navailable at: {\\footnotesize{\\url{https://github.com/cuge1995/IT-Defense}}}.\n", "versions": [{"version": "v1", "created": "Wed, 7 Apr 2021 07:28:46 GMT"}, {"version": "v2", "created": "Mon, 31 May 2021 13:15:53 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Zhang", "Jinlai", ""], ["Liu", "Binbin", ""], ["Chen", "Lyvjie", ""], ["Ouyang", "Bo", ""], ["Zhu", "Jihong", ""], ["Kuang", "Minchi", ""], ["Wang", "Houqing", ""], ["Meng", "Yanmei", ""]]}, {"id": "2104.02980", "submitter": "Pierre Gutierrez", "authors": "Pierre Gutierrez, Maria Luschkova, Antoine Cordier, Mustafa Shukor,\n  Mona Schappert, and Tim Dahmen", "title": "Synthetic training data generation for deep learning based quality\n  inspection", "comments": "8 pages, 4 figures, to be published in QCAV 2021 conference,\n  proceedings will by published by SPIE", "journal-ref": null, "doi": "10.1117/12.2586824", "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Deep learning is now the gold standard in computer vision-based quality\ninspection systems. In order to detect defects, supervised learning is often\nutilized, but necessitates a large amount of annotated images, which can be\ncostly: collecting, cleaning, and annotating the data is tedious and limits the\nspeed at which a system can be deployed as everything the system must detect\nneeds to be observed first. This can impede the inspection of rare defects,\nsince very few samples can be collected by the manufacturer. In this work, we\nfocus on simulations to solve this issue. We first present a generic simulation\npipeline to render images of defective or healthy (non defective) parts. As\nmetallic parts can be highly textured with small defects like holes, we design\na texture scanning and generation method. We assess the quality of the\ngenerated images by training deep learning networks and by testing them on real\ndata from a manufacturer. We demonstrate that we can achieve encouraging\nresults on real defect detection using purely simulated data. Additionally, we\nare able to improve global performances by concatenating simulated and real\ndata, showing that simulations can complement real images to boost\nperformances. Lastly, using domain adaptation techniques helps improving\nslightly our final results.\n", "versions": [{"version": "v1", "created": "Wed, 7 Apr 2021 08:07:57 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Gutierrez", "Pierre", ""], ["Luschkova", "Maria", ""], ["Cordier", "Antoine", ""], ["Shukor", "Mustafa", ""], ["Schappert", "Mona", ""], ["Dahmen", "Tim", ""]]}, {"id": "2104.02981", "submitter": "Kai Wang", "authors": "Kai Wang, Zhene Zou, Qilin Deng, Runze Wu, Jianrong Tao, Changjie Fan,\n  Liang Chen, Peng Cui", "title": "Reinforcement Learning with a Disentangled Universal Value Function for\n  Item Recommendation", "comments": "9 pages, 4 figures, to be published in Proceedings of the AAAI\n  Conference on Artificial Intelligence 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, there are great interests as well as challenges in applying\nreinforcement learning (RL) to recommendation systems (RS). In this paper, we\nsummarize three key practical challenges of large-scale RL-based recommender\nsystems: massive state and action spaces, high-variance environment, and the\nunspecific reward setting in recommendation. All these problems remain largely\nunexplored in the existing literature and make the application of RL\nchallenging. We develop a model-based reinforcement learning framework, called\nGoalRec. Inspired by the ideas of world model (model-based), value function\nestimation (model-free), and goal-based RL, a novel disentangled universal\nvalue function designed for item recommendation is proposed. It can generalize\nto various goals that the recommender may have, and disentangle the stochastic\nenvironmental dynamics and high-variance reward signals accordingly. As a part\nof the value function, free from the sparse and high-variance reward signals, a\nhigh-capacity reward-independent world model is trained to simulate complex\nenvironmental dynamics under a certain goal. Based on the predicted\nenvironmental dynamics, the disentangled universal value function is related to\nthe user's future trajectory instead of a monolithic state and a scalar reward.\nWe demonstrate the superiority of GoalRec over previous approaches in terms of\nthe above three practical challenges in a series of simulations and a real\napplication.\n", "versions": [{"version": "v1", "created": "Wed, 7 Apr 2021 08:13:32 GMT"}, {"version": "v2", "created": "Sun, 11 Apr 2021 13:32:20 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Wang", "Kai", ""], ["Zou", "Zhene", ""], ["Deng", "Qilin", ""], ["Wu", "Runze", ""], ["Tao", "Jianrong", ""], ["Fan", "Changjie", ""], ["Chen", "Liang", ""], ["Cui", "Peng", ""]]}, {"id": "2104.02987", "submitter": "Peterson Yuhala", "authors": "Peterson Yuhala, Pascal Felber, Valerio Schiavoni, Alain Tchana", "title": "Plinius: Secure and Persistent Machine Learning Model Training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  With the increasing popularity of cloud based machine learning (ML)\ntechniques there comes a need for privacy and integrity guarantees for ML data.\nIn addition, the significant scalability challenges faced by DRAM coupled with\nthe high access-times of secondary storage represent a huge performance\nbottleneck for ML systems. While solutions exist to tackle the security aspect,\nperformance remains an issue. Persistent memory (PM) is resilient to power loss\n(unlike DRAM), provides fast and fine-granular access to memory (unlike disk\nstorage) and has latency and bandwidth close to DRAM (in the order of ns and\nGB/s, respectively). We present PLINIUS, a ML framework using Intel SGX\nenclaves for secure training of ML models and PM for fault tolerance\nguarantees. P LINIUS uses a novel mirroring mechanism to create and maintain\n(i) encrypted mirror copies of ML models on PM, and (ii) encrypted training\ndata in byte-addressable PM, for near-instantaneous data recovery after a\nsystem failure. Compared to disk-based checkpointing systems,PLINIUS is 3.2x\nand 3.7x faster respectively for saving and restoring models on real PM\nhardware, achieving robust and secure ML model training in SGX enclaves.\n", "versions": [{"version": "v1", "created": "Wed, 7 Apr 2021 08:35:59 GMT"}, {"version": "v2", "created": "Thu, 8 Apr 2021 06:03:57 GMT"}], "update_date": "2021-04-09", "authors_parsed": [["Yuhala", "Peterson", ""], ["Felber", "Pascal", ""], ["Schiavoni", "Valerio", ""], ["Tchana", "Alain", ""]]}, {"id": "2104.02988", "submitter": "Crist\\'obal Guzm\\'an", "authors": "Digvijay Boob and Crist\\'obal Guzm\\'an", "title": "Optimal Algorithms for Differentially Private Stochastic Monotone\n  Variational Inequalities and Saddle-Point Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this work, we conduct the first systematic study of stochastic variational\ninequality (SVI) and stochastic saddle point (SSP) problems under the\nconstraint of differential privacy-(DP). We propose two algorithms: Noisy\nStochastic Extragradient (NSEG) and Noisy Inexact Stochastic Proximal Point\n(NISPP). We show that sampling with replacement variants of these algorithms\nattain the optimal risk for DP-SVI and DP-SSP. Key to our analysis is the\ninvestigation of algorithmic stability bounds, both of which are new even in\nthe nonprivate case, together with a novel \"stability implies generalization\"\nresult for the gap functions for SVI and SSP problems. The dependence of the\nrunning time of these algorithms, with respect to the dataset size $n$, is\n$n^2$ for NSEG and $\\widetilde{O}(n^{3/2})$ for NISPP.\n", "versions": [{"version": "v1", "created": "Wed, 7 Apr 2021 08:37:07 GMT"}], "update_date": "2021-04-08", "authors_parsed": [["Boob", "Digvijay", ""], ["Guzm\u00e1n", "Crist\u00f3bal", ""]]}, {"id": "2104.02995", "submitter": "Qingqing Long", "authors": "Qingqing Long, Yilun Jin, Yi Wu, Guojie Song", "title": "Theoretically Improving Graph Neural Networks via Anonymous Walk Graph\n  Kernels", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph neural networks (GNNs) have achieved tremendous success in graph\nmining. However, the inability of GNNs to model substructures in graphs remains\na significant drawback. Specifically, message-passing GNNs (MPGNNs), as the\nprevailing type of GNNs, have been theoretically shown unable to distinguish,\ndetect or count many graph substructures. While efforts have been paid to\ncomplement the inability, existing works either rely on pre-defined\nsubstructure sets, thus being less flexible, or are lacking in theoretical\ninsights. In this paper, we propose GSKN, a GNN model with a theoretically\nstronger ability to distinguish graph structures. Specifically, we design GSKN\nbased on anonymous walks (AWs), flexible substructure units, and derive it upon\nfeature mappings of graph kernels (GKs). We theoretically show that GSKN\nprovably extends the 1-WL test, and hence the maximally powerful MPGNNs from\nboth graph-level and node-level viewpoints. Correspondingly, various\nexperiments are leveraged to evaluate GSKN, where GSKN outperforms a wide range\nof baselines, endorsing the analysis.\n", "versions": [{"version": "v1", "created": "Wed, 7 Apr 2021 08:50:34 GMT"}], "update_date": "2021-04-08", "authors_parsed": [["Long", "Qingqing", ""], ["Jin", "Yilun", ""], ["Wu", "Yi", ""], ["Song", "Guojie", ""]]}, {"id": "2104.03000", "submitter": "Philipp Benz", "authors": "Philipp Benz, Chaoning Zhang, Adil Karjauv, In So Kweon", "title": "Universal Adversarial Training with Class-Wise Perturbations", "comments": "Accepted to ICME 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite their overwhelming success on a wide range of applications,\nconvolutional neural networks (CNNs) are widely recognized to be vulnerable to\nadversarial examples. This intriguing phenomenon led to a competition between\nadversarial attacks and defense techniques. So far, adversarial training is the\nmost widely used method for defending against adversarial attacks. It has also\nbeen extended to defend against universal adversarial perturbations (UAPs). The\nSOTA universal adversarial training (UAT) method optimizes a single\nperturbation for all training samples in the mini-batch. In this work, we find\nthat a UAP does not attack all classes equally. Inspired by this observation,\nwe identify it as the source of the model having unbalanced robustness. To this\nend, we improve the SOTA UAT by proposing to utilize class-wise UAPs during\nadversarial training. On multiple benchmark datasets, our class-wise UAT leads\nsuperior performance for both clean accuracy and adversarial robustness against\nuniversal attack.\n", "versions": [{"version": "v1", "created": "Wed, 7 Apr 2021 09:05:49 GMT"}], "update_date": "2021-04-08", "authors_parsed": [["Benz", "Philipp", ""], ["Zhang", "Chaoning", ""], ["Karjauv", "Adil", ""], ["Kweon", "In So", ""]]}, {"id": "2104.03002", "submitter": "Luca Tomasetti", "authors": "Luca Tomasetti, Kjersti Engan, Mahdieh Khanmohammadi, and Kathinka\n  D{\\ae}hli Kurz", "title": "CNN Based Segmentation of Infarcted Regions in Acute Cerebral Stroke\n  Patients From Computed Tomography Perfusion Imaging", "comments": null, "journal-ref": null, "doi": "10.1145/3388440.3412470", "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  More than 13 million people suffer from ischemic cerebral stroke worldwide\neach year. Thrombolytic treatment can reduce brain damage but has a narrow\ntreatment window. Computed Tomography Perfusion imaging is a commonly used\nprimary assessment tool for stroke patients, and typically the radiologists\nwill evaluate resulting parametric maps to estimate the affected areas, dead\ntissue (core), and the surrounding tissue at risk (penumbra), to decide further\ntreatments. Different work has been reported, suggesting thresholds, and\nsemi-automated methods, and in later years deep neural networks, for segmenting\ninfarction areas based on the parametric maps. However, there is no consensus\nin terms of which thresholds to use, or how to combine the information from the\nparametric maps, and the presented methods all have limitations in terms of\nboth accuracy and reproducibility.\n  We propose a fully automated convolutional neural network based segmentation\nmethod that uses the full four-dimensional computed tomography perfusion\ndataset as input, rather than the pre-filtered parametric maps. The suggested\nnetwork is tested on an available dataset as a proof-of-concept, with very\nencouraging results. Cross-validated results show averaged Dice score of 0.78\nand 0.53, and an area under the receiver operating characteristic curve of 0.97\nand 0.94 for penumbra and core respectively\n", "versions": [{"version": "v1", "created": "Wed, 7 Apr 2021 09:09:13 GMT"}, {"version": "v2", "created": "Wed, 21 Apr 2021 14:25:34 GMT"}], "update_date": "2021-04-22", "authors_parsed": [["Tomasetti", "Luca", ""], ["Engan", "Kjersti", ""], ["Khanmohammadi", "Mahdieh", ""], ["Kurz", "Kathinka D\u00e6hli", ""]]}, {"id": "2104.03004", "submitter": "Yu Tsao", "authors": "Xugang Lu, Peng Shen, Yu Tsao, Hisashi Kawai", "title": "Siamese Neural Network with Joint Bayesian Model Structure for Speaker\n  Verification", "comments": "arXiv admin note: substantial text overlap with arXiv:2101.03329", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative probability models are widely used for speaker verification (SV).\nHowever, the generative models are lack of discriminative feature selection\nability. As a hypothesis test, the SV can be regarded as a binary\nclassification task which can be designed as a Siamese neural network (SiamNN)\nwith discriminative training. However, in most of the discriminative training\nfor SiamNN, only the distribution of pair-wised sample distances is considered,\nand the additional discriminative information in joint distribution of samples\nis ignored. In this paper, we propose a novel SiamNN with consideration of the\njoint distribution of samples. The joint distribution of samples is first\nformulated based on a joint Bayesian (JB) based generative model, then a SiamNN\nis designed with dense layers to approximate the factorized affine transforms\nas used in the JB model. By initializing the SiamNN with the learned model\nparameters of the JB model, we further train the model parameters with the\npair-wised samples as a binary discrimination task for SV. We carried out SV\nexperiments on data corpus of speakers in the wild (SITW) and VoxCeleb.\nExperimental results showed that our proposed model improved the performance\nwith a large margin compared with state of the art models for SV.\n", "versions": [{"version": "v1", "created": "Wed, 7 Apr 2021 09:17:29 GMT"}], "update_date": "2021-04-08", "authors_parsed": [["Lu", "Xugang", ""], ["Shen", "Peng", ""], ["Tsao", "Yu", ""], ["Kawai", "Hisashi", ""]]}, {"id": "2104.03007", "submitter": "Paul Tiwald", "authors": "Paul Tiwald, Alexandra Ebert, Daniel T. Soukup", "title": "Representative & Fair Synthetic Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Algorithms learn rules and associations based on the training data that they\nare exposed to. Yet, the very same data that teaches machines to understand and\npredict the world, contains societal and historic biases, resulting in biased\nalgorithms with the risk of further amplifying these once put into use for\ndecision support. Synthetic data, on the other hand, emerges with the promise\nto provide an unlimited amount of representative, realistic training samples,\nthat can be shared further without disclosing the privacy of individual\nsubjects. We present a framework to incorporate fairness constraints into the\nself-supervised learning process, that allows to then simulate an unlimited\namount of representative as well as fair synthetic data. This framework\nprovides a handle to govern and control for privacy as well as for bias within\nAI at its very source: the training data. We demonstrate the proposed approach\nby amending an existing generative model architecture and generating a\nrepresentative as well as fair version of the UCI Adult census data set. While\nthe relationships between attributes are faithfully retained, the gender and\nracial biases inherent in the original data are controlled for. This is further\nvalidated by comparing propensity scores of downstream predictive models that\nare trained on the original data versus the fair synthetic data. We consider\nrepresentative & fair synthetic data a promising future building block to teach\nalgorithms not on historic worlds, but rather on the worlds that we strive to\nlive in.\n", "versions": [{"version": "v1", "created": "Wed, 7 Apr 2021 09:19:46 GMT"}], "update_date": "2021-04-08", "authors_parsed": [["Tiwald", "Paul", ""], ["Ebert", "Alexandra", ""], ["Soukup", "Daniel T.", ""]]}, {"id": "2104.03009", "submitter": "Cheng-Hung Hu", "authors": "Cheng-Hung Hu, Yi-Chiao Wu, Wen-Chin Huang, Yu-Huai Peng, Yu-Wen Chen,\n  Pin-Jui Ku, Tomoki Toda, Yu Tsao, Hsin-Min Wang", "title": "The AS-NU System for the M2VoC Challenge", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes the AS-NU systems for two tracks in MultiSpeaker\nMulti-Style Voice Cloning Challenge (M2VoC). The first track focuses on using a\nsmall number of 100 target utterances for voice cloning, while the second track\nfocuses on using only 5 target utterances for voice cloning. Due to the serious\nlack of data in the second track, we selected the speaker most similar to the\ntarget speaker from the training data of the TTS system, and used the speaker's\nutterances and the given 5 target utterances to fine-tune our model. The\nevaluation results show that our systems on the two tracks perform similarly in\nterms of quality, but there is still a clear gap between the similarity score\nof the second track and the similarity score of the first track.\n", "versions": [{"version": "v1", "created": "Wed, 7 Apr 2021 09:26:20 GMT"}], "update_date": "2021-04-08", "authors_parsed": [["Hu", "Cheng-Hung", ""], ["Wu", "Yi-Chiao", ""], ["Huang", "Wen-Chin", ""], ["Peng", "Yu-Huai", ""], ["Chen", "Yu-Wen", ""], ["Ku", "Pin-Jui", ""], ["Toda", "Tomoki", ""], ["Tsao", "Yu", ""], ["Wang", "Hsin-Min", ""]]}, {"id": "2104.03017", "submitter": "Wei-Cheng Tseng", "authors": "Wei-Cheng Tseng, Chien-yu Huang, Wei-Tsung Kao, Yist Y. Lin, Hung-yi\n  Lee", "title": "Utilizing Self-supervised Representations for MOS Prediction", "comments": "Submitted to Interspeech 2021. We acknowledge the support of AWS\n  Machine Learning Research Awards program", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Speech quality assessment has been a critical issue in speech processing for\ndecades. Existing automatic evaluations usually require clean references or\nparallel ground truth data, which is infeasible when the amount of data soars.\nSubjective tests, on the other hand, do not need any additional clean or\nparallel data and correlates better to human perception. However, such a test\nis expensive and time-consuming because crowd work is necessary. It thus\nbecomes highly desired to develop an automatic evaluation approach that\ncorrelates well with human perception while not requiring ground truth data. In\nthis paper, we use self-supervised pre-trained models for MOS prediction. We\nshow their representations can distinguish between clean and noisy audios.\nThen, we fine-tune these pre-trained models followed by simple linear layers in\nan end-to-end manner. The experiment results showed that our framework\noutperforms the two previous state-of-the-art models by a significant\nimprovement on Voice Conversion Challenge 2018 and achieves comparable or\nsuperior performance on Voice Conversion Challenge 2016. We also conducted an\nablation study to further investigate how each module benefits the task. The\nexperiment results are implemented and reproducible with publicly available\ntoolkits.\n", "versions": [{"version": "v1", "created": "Wed, 7 Apr 2021 09:44:36 GMT"}, {"version": "v2", "created": "Wed, 21 Apr 2021 11:31:40 GMT"}], "update_date": "2021-04-22", "authors_parsed": [["Tseng", "Wei-Cheng", ""], ["Huang", "Chien-yu", ""], ["Kao", "Wei-Tsung", ""], ["Lin", "Yist Y.", ""], ["Lee", "Hung-yi", ""]]}, {"id": "2104.03020", "submitter": "Wenjie Yin", "authors": "Wenjie Yin, Hang Yin, Danica Kragic, M{\\aa}rten Bj\\\"orkman", "title": "Graph-based Normalizing Flow for Human Motion Generation and\n  Reconstruction", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data-driven approaches for modeling human skeletal motion have found various\napplications in interactive media and social robotics. Challenges remain in\nthese fields for generating high-fidelity samples and robustly reconstructing\nmotion from imperfect input data, due to e.g. missed marker detection. In this\npaper, we propose a probabilistic generative model to synthesize and\nreconstruct long horizon motion sequences conditioned on past information and\ncontrol signals, such as the path along which an individual is moving. Our\nmethod adapts the existing work MoGlow by introducing a new graph-based model.\nThe model leverages the spatial-temporal graph convolutional network (ST-GCN)\nto effectively capture the spatial structure and temporal correlation of\nskeletal motion data at multiple scales. We evaluate the models on a mixture of\nmotion capture datasets of human locomotion with foot-step and bone-length\nanalysis. The results demonstrate the advantages of our model in reconstructing\nmissing markers and achieving comparable results on generating realistic future\nposes. When the inputs are imperfect, our model shows improvements on\nrobustness of generation.\n", "versions": [{"version": "v1", "created": "Wed, 7 Apr 2021 09:51:15 GMT"}], "update_date": "2021-04-08", "authors_parsed": [["Yin", "Wenjie", ""], ["Yin", "Hang", ""], ["Kragic", "Danica", ""], ["Bj\u00f6rkman", "M\u00e5rten", ""]]}, {"id": "2104.03042", "submitter": "Akhil Mathur", "authors": "Akhil Mathur, Daniel J. Beutel, Pedro Porto Buarque de Gusm\\~ao,\n  Javier Fernandez-Marques, Taner Topal, Xinchi Qiu, Titouan Parcollet, Yan\n  Gao, Nicholas D. Lane", "title": "On-device Federated Learning with Flower", "comments": "Accepted at the 2nd On-device Intelligence Workshop @ MLSys 2021.\n  arXiv admin note: substantial text overlap with arXiv:2007.14390", "journal-ref": "On-device Intelligence Workshop at the Fourth Conference on\n  Machine Learning and Systems (MLSys), April 9, 2021", "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Federated Learning (FL) allows edge devices to collaboratively learn a shared\nprediction model while keeping their training data on the device, thereby\ndecoupling the ability to do machine learning from the need to store data in\nthe cloud. Despite the algorithmic advancements in FL, the support for\non-device training of FL algorithms on edge devices remains poor. In this\npaper, we present an exploration of on-device FL on various smartphones and\nembedded devices using the Flower framework. We also evaluate the system costs\nof on-device FL and discuss how this quantification could be used to design\nmore efficient FL algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 7 Apr 2021 10:42:14 GMT"}], "update_date": "2021-04-08", "authors_parsed": [["Mathur", "Akhil", ""], ["Beutel", "Daniel J.", ""], ["de Gusm\u00e3o", "Pedro Porto Buarque", ""], ["Fernandez-Marques", "Javier", ""], ["Topal", "Taner", ""], ["Qiu", "Xinchi", ""], ["Parcollet", "Titouan", ""], ["Gao", "Yan", ""], ["Lane", "Nicholas D.", ""]]}, {"id": "2104.03046", "submitter": "Ant\\'onio Farinhas", "authors": "Ant\\'onio Farinhas, Andr\\'e F. T. Martins, Pedro M. Q. Aguiar", "title": "Multimodal Continuous Visual Attention Mechanisms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Visual attention mechanisms are a key component of neural network models for\ncomputer vision. By focusing on a discrete set of objects or image regions,\nthese mechanisms identify the most relevant features and use them to build more\npowerful representations. Recently, continuous-domain alternatives to discrete\nattention models have been proposed, which exploit the continuity of images.\nThese approaches model attention as simple unimodal densities (e.g. a\nGaussian), making them less suitable to deal with images whose region of\ninterest has a complex shape or is composed of multiple non-contiguous patches.\nIn this paper, we introduce a new continuous attention mechanism that produces\nmultimodal densities, in the form of mixtures of Gaussians. We use the EM\nalgorithm to obtain a clustering of relevant regions in the image, and a\ndescription length penalty to select the number of components in the mixture.\nOur densities decompose as a linear combination of unimodal attention\nmechanisms, enabling closed-form Jacobians for the backpropagation step.\nExperiments on visual question answering in the VQA-v2 dataset show competitive\naccuracies and a selection of regions that mimics human attention more closely\nin VQA-HAT. We present several examples that suggest how multimodal attention\nmaps are naturally more interpretable than their unimodal counterparts, showing\nthe ability of our model to automatically segregate objects from ground in\ncomplex scenes.\n", "versions": [{"version": "v1", "created": "Wed, 7 Apr 2021 10:47:51 GMT"}], "update_date": "2021-04-08", "authors_parsed": [["Farinhas", "Ant\u00f3nio", ""], ["Martins", "Andr\u00e9 F. T.", ""], ["Aguiar", "Pedro M. Q.", ""]]}, {"id": "2104.03047", "submitter": "Chi Zhang", "authors": "Chi Zhang, Nan Song, Guosheng Lin, Yun Zheng, Pan Pan, Yinghui Xu", "title": "Few-Shot Incremental Learning with Continually Evolved Classifiers", "comments": "Accpeted to CVPR2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Few-shot class-incremental learning (FSCIL) aims to design machine learning\nalgorithms that can continually learn new concepts from a few data points,\nwithout forgetting knowledge of old classes. The difficulty lies in that\nlimited data from new classes not only lead to significant overfitting issues\nbut also exacerbate the notorious catastrophic forgetting problems. Moreover,\nas training data come in sequence in FSCIL, the learned classifier can only\nprovide discriminative information in individual sessions, while FSCIL requires\nall classes to be involved for evaluation. In this paper, we address the FSCIL\nproblem from two aspects. First, we adopt a simple but effective decoupled\nlearning strategy of representations and classifiers that only the classifiers\nare updated in each incremental session, which avoids knowledge forgetting in\nthe representations. By doing so, we demonstrate that a pre-trained backbone\nplus a non-parametric class mean classifier can beat state-of-the-art methods.\nSecond, to make the classifiers learned on individual sessions applicable to\nall classes, we propose a Continually Evolved Classifier (CEC) that employs a\ngraph model to propagate context information between classifiers for\nadaptation. To enable the learning of CEC, we design a pseudo incremental\nlearning paradigm that episodically constructs a pseudo incremental learning\ntask to optimize the graph parameters by sampling data from the base dataset.\nExperiments on three popular benchmark datasets, including CIFAR100,\nminiImageNet, and Caltech-USCD Birds-200-2011 (CUB200), show that our method\nsignificantly outperforms the baselines and sets new state-of-the-art results\nwith remarkable advantages.\n", "versions": [{"version": "v1", "created": "Wed, 7 Apr 2021 10:54:51 GMT"}], "update_date": "2021-04-08", "authors_parsed": [["Zhang", "Chi", ""], ["Song", "Nan", ""], ["Lin", "Guosheng", ""], ["Zheng", "Yun", ""], ["Pan", "Pan", ""], ["Xu", "Yinghui", ""]]}, {"id": "2104.03058", "submitter": "Jianlei Yang", "authors": "Ao Zhou, Jianlei Yang, Yeqi Gao, Tong Qiao, Yingjie Qi, Xiaoyi Wang,\n  Yunli Chen, Pengcheng Dai, Weisheng Zhao, Chunming Hu", "title": "Optimizing Memory Efficiency of Graph Neural Networks on Edge Computing\n  Platforms", "comments": "This paper has been accepted by RTAS 2021(brief industry track), with\n  link to publicly available code", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph neural networks (GNN) have achieved state-of-the-art performance on\nvarious industrial tasks. However, the poor efficiency of GNN inference and\nfrequent Out-Of-Memory (OOM) problem limit the successful application of GNN on\nedge computing platforms. To tackle these problems, a feature decomposition\napproach is proposed for memory efficiency optimization of GNN inference. The\nproposed approach could achieve outstanding optimization on various GNN models,\ncovering a wide range of datasets, which speeds up the inference by up to 3x.\nFurthermore, the proposed feature decomposition could significantly reduce the\npeak memory usage (up to 5x in memory efficiency improvement) and mitigate OOM\nproblems during GNN inference.\n", "versions": [{"version": "v1", "created": "Wed, 7 Apr 2021 11:15:12 GMT"}, {"version": "v2", "created": "Mon, 12 Apr 2021 11:02:19 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Zhou", "Ao", ""], ["Yang", "Jianlei", ""], ["Gao", "Yeqi", ""], ["Qiao", "Tong", ""], ["Qi", "Yingjie", ""], ["Wang", "Xiaoyi", ""], ["Chen", "Yunli", ""], ["Dai", "Pengcheng", ""], ["Zhao", "Weisheng", ""], ["Hu", "Chunming", ""]]}, {"id": "2104.03059", "submitter": "Thomas Unterthiner", "authors": "Jean-Baptiste Cordonnier, Aravindh Mahendran, Alexey Dosovitskiy, Dirk\n  Weissenborn, Jakob Uszkoreit, Thomas Unterthiner", "title": "Differentiable Patch Selection for Image Recognition", "comments": "Accepted to IEEE/CVF Conference on Computer Vision and Pattern\n  Recognition (CVPR) 2021. Code available at\n  https://github.com/google-research/google-research/tree/master/ptopk_patch_selection/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural Networks require large amounts of memory and compute to process high\nresolution images, even when only a small part of the image is actually\ninformative for the task at hand. We propose a method based on a differentiable\nTop-K operator to select the most relevant parts of the input to efficiently\nprocess high resolution images. Our method may be interfaced with any\ndownstream neural network, is able to aggregate information from different\npatches in a flexible way, and allows the whole model to be trained end-to-end\nusing backpropagation. We show results for traffic sign recognition,\ninter-patch relationship reasoning, and fine-grained recognition without using\nobject/part bounding box annotations during training.\n", "versions": [{"version": "v1", "created": "Wed, 7 Apr 2021 11:15:51 GMT"}], "update_date": "2021-04-08", "authors_parsed": [["Cordonnier", "Jean-Baptiste", ""], ["Mahendran", "Aravindh", ""], ["Dosovitskiy", "Alexey", ""], ["Weissenborn", "Dirk", ""], ["Uszkoreit", "Jakob", ""], ["Unterthiner", "Thomas", ""]]}, {"id": "2104.03065", "submitter": "Marcelo Medeiros", "authors": "Marcelo C. Medeiros, Henrique F. Pires", "title": "The Proper Use of Google Trends in Forecasting Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.EM cs.LG stat.AP stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  It is widely known that Google Trends have become one of the most popular\nfree tools used by forecasters both in academics and in the private and public\nsectors. There are many papers, from several different fields, concluding that\nGoogle Trends improve forecasts' accuracy. However, what seems to be widely\nunknown, is that each sample of Google search data is different from the other,\neven if you set the same search term, data and location. This means that it is\npossible to find arbitrary conclusions merely by chance. This paper aims to\nshow why and when it can become a problem and how to overcome this obstacle.\n", "versions": [{"version": "v1", "created": "Wed, 7 Apr 2021 11:33:51 GMT"}, {"version": "v2", "created": "Thu, 8 Apr 2021 14:15:57 GMT"}, {"version": "v3", "created": "Sat, 10 Apr 2021 13:09:44 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Medeiros", "Marcelo C.", ""], ["Pires", "Henrique F.", ""]]}, {"id": "2104.03066", "submitter": "Dvir Samuel", "authors": "Dvir Samuel and Gal Chechik", "title": "Distributional Robustness Loss for Long-tail Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Real-world data is often unbalanced and long-tailed, but deep models struggle\nto recognize rare classes in the presence of frequent classes. To address\nunbalanced data, most studies try balancing the data, the loss, or the\nclassifier to reduce classification bias towards head classes. Far less\nattention has been given to the latent representations learned with unbalanced\ndata. We show that the feature extractor part of deep networks suffers greatly\nfrom this bias. We propose a new loss based on robustness theory, which\nencourages the model to learn high-quality representations for both head and\ntail classes. While the general form of the robustness loss may be hard to\ncompute, we further derive an easy-to-compute upper bound that can be minimized\nefficiently. This procedure reduces representation bias towards head classes in\nthe feature space and achieves new SOTA results on CIFAR100-LT, ImageNet-LT,\nand iNaturalist long-tail benchmarks. We find that training with robustness\nincreases recognition accuracy of tail classes while largely maintaining the\naccuracy of head classes. The new robustness loss can be combined with various\nclassifier balancing techniques and can be applied to representations at\nseveral layers of the deep model.\n", "versions": [{"version": "v1", "created": "Wed, 7 Apr 2021 11:34:04 GMT"}], "update_date": "2021-04-08", "authors_parsed": [["Samuel", "Dvir", ""], ["Chechik", "Gal", ""]]}, {"id": "2104.03086", "submitter": "Bo Pang", "authors": "Bo Pang, Tianyang Zhao, Xu Xie, and Ying Nian Wu", "title": "Trajectory Prediction with Latent Belief Energy-Based Model", "comments": "13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human trajectory prediction is critical for autonomous platforms like\nself-driving cars or social robots. We present a latent belief energy-based\nmodel (LB-EBM) for diverse human trajectory forecast. LB-EBM is a probabilistic\nmodel with cost function defined in the latent space to account for the\nmovement history and social context. The low-dimensionality of the latent space\nand the high expressivity of the EBM make it easy for the model to capture the\nmultimodality of pedestrian trajectory distributions. LB-EBM is learned from\nexpert demonstrations (i.e., human trajectories) projected into the latent\nspace. Sampling from or optimizing the learned LB-EBM yields a belief vector\nwhich is used to make a path plan, which then in turn helps to predict a\nlong-range trajectory. The effectiveness of LB-EBM and the two-step approach\nare supported by strong empirical results. Our model is able to make accurate,\nmulti-modal, and social compliant trajectory predictions and improves over\nprior state-of-the-arts performance on the Stanford Drone trajectory prediction\nbenchmark by 10.9% and on the ETH-UCY benchmark by 27.6%.\n", "versions": [{"version": "v1", "created": "Wed, 7 Apr 2021 12:18:50 GMT"}], "update_date": "2021-04-08", "authors_parsed": [["Pang", "Bo", ""], ["Zhao", "Tianyang", ""], ["Xie", "Xu", ""], ["Wu", "Ying Nian", ""]]}, {"id": "2104.03088", "submitter": "Lewis Crawford Mr", "authors": "Stephane Doyen, Hugh Taylor, Peter Nicholas, Lewis Crawford, Isabella\n  Young, Michael Sughrue", "title": "Hollow-tree Super: a directional and scalable approach for feature\n  importance in boosted tree models", "comments": "28 pages, 1 table, 7 figures, PDF format - Submitted to PLOSONE\n  pending review", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Current limitations in boosted tree modelling prevent the effective scaling\nto datasets with a large feature number, particularly when investigating the\nmagnitude and directionality of various features on classification. We present\na novel methodology, Hollow-tree Super (HOTS), to resolve and visualize feature\nimportance in boosted tree models involving a large number of features.\nFurther, HOTS allows for investigation of the directionality and magnitude\nvarious features have on classification. Using the Iris dataset, we first\ncompare HOTS to Gini Importance, Partial Dependence Plots, and Permutation\nImportance, and demonstrate how HOTS resolves the weaknesses present in these\nmethods. We then show how HOTS can be utilized in high dimensional\nneuroscientific data, by taking 60 Schizophrenic subjects and applying the\nmethod to determine which brain regions were most important for classification\nof schizophrenia as determined by the PANSS. HOTS effectively replicated and\nsupported the findings of Gini importance, Partial Dependence Plots and\nPermutation importance within the Iris dataset. When applied to the\nschizophrenic brain dataset, HOTS was able to resolve the top 10 most important\nfeatures for classification, as well as their directionality for classification\nand magnitude compared to other features. Cross-validation supported that these\nsame 10 features were consistently used in the decision-making process across\nmultiple trees, and these features were localised primarily to the occipital\nand parietal cortices, commonly disturbed brain regions in those with\nSchizophrenia. It is imperative that a methodology is developed that is able to\nhandle the demands of working with large datasets that contain a large number\nof features. HOTS represents a unique way to investigate both the\ndirectionality and magnitude of feature importance when working at scale with\nboosted-tree modelling.\n", "versions": [{"version": "v1", "created": "Wed, 7 Apr 2021 12:24:56 GMT"}], "update_date": "2021-04-08", "authors_parsed": [["Doyen", "Stephane", ""], ["Taylor", "Hugh", ""], ["Nicholas", "Peter", ""], ["Crawford", "Lewis", ""], ["Young", "Isabella", ""], ["Sughrue", "Michael", ""]]}, {"id": "2104.03090", "submitter": "Firoj Alam", "authors": "Firoj Alam, Umair Qazi, Muhammad Imran, Ferda Ofli", "title": "HumAID: Human-Annotated Disaster Incidents Data from Twitter with Deep\n  Learning Benchmarks", "comments": "Accepted in ICWSM-2021, Twitter datasets, Textual content, Natural\n  disasters, Crisis Informatics, Benchmarks, Transformers", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CY cs.LG cs.SI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Social networks are widely used for information consumption and\ndissemination, especially during time-critical events such as natural\ndisasters. Despite its significantly large volume, social media content is\noften too noisy for direct use in any application. Therefore, it is important\nto filter, categorize, and concisely summarize the available content to\nfacilitate effective consumption and decision-making. To address such issues\nautomatic classification systems have been developed using supervised modeling\napproaches, thanks to the earlier efforts on creating labeled datasets.\nHowever, existing datasets are limited in different aspects (e.g., size,\ncontains duplicates) and less suitable to support more advanced and data-hungry\ndeep learning models. In this paper, we present a new large-scale dataset with\n~77K human-labeled tweets, sampled from a pool of ~24 million tweets across 19\ndisaster events that happened between 2016 and 2019. Moreover, we propose a\ndata collection and sampling pipeline, which is important for social media data\nsampling for human annotation. We report multiclass classification results\nusing classic and deep learning (fastText and transformer) based models to set\nthe ground for future studies. The dataset and associated resources are\npublicly available. https://crisisnlp.qcri.org/humaid_dataset.html\n", "versions": [{"version": "v1", "created": "Wed, 7 Apr 2021 12:29:36 GMT"}, {"version": "v2", "created": "Thu, 8 Apr 2021 09:12:11 GMT"}], "update_date": "2021-04-09", "authors_parsed": [["Alam", "Firoj", ""], ["Qazi", "Umair", ""], ["Imran", "Muhammad", ""], ["Ofli", "Ferda", ""]]}, {"id": "2104.03093", "submitter": "Yuval Belfer", "authors": "Yuval Belfer, Amnon Geifman, Meirav Galun, Ronen Basri", "title": "Spectral Analysis of the Neural Tangent Kernel for Deep Residual\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deep residual network architectures have been shown to achieve superior\naccuracy over classical feed-forward networks, yet their success is still not\nfully understood. Focusing on massively over-parameterized, fully connected\nresidual networks with ReLU activation through their respective neural tangent\nkernels (ResNTK), we provide here a spectral analysis of these kernels.\nSpecifically, we show that, much like NTK for fully connected networks\n(FC-NTK), for input distributed uniformly on the hypersphere\n$\\mathbb{S}^{d-1}$, the eigenfunctions of ResNTK are the spherical harmonics\nand the eigenvalues decay polynomially with frequency $k$ as $k^{-d}$. These in\nturn imply that the set of functions in their Reproducing Kernel Hilbert Space\nare identical to those of FC-NTK, and consequently also to those of the Laplace\nkernel. We further show, by drawing on the analogy to the Laplace kernel, that\ndepending on the choice of a hyper-parameter that balances between the skip and\nresidual connections ResNTK can either become spiky with depth, as with FC-NTK,\nor maintain a stable shape.\n", "versions": [{"version": "v1", "created": "Wed, 7 Apr 2021 12:35:19 GMT"}], "update_date": "2021-04-08", "authors_parsed": [["Belfer", "Yuval", ""], ["Geifman", "Amnon", ""], ["Galun", "Meirav", ""], ["Basri", "Ronen", ""]]}, {"id": "2104.03111", "submitter": "Christopher Dance", "authors": "Jinyoung Choi, Christopher R. Dance, Jung-eun Kim, Seulbin Hwang,\n  Kyung-sik Park", "title": "Risk-Conditioned Distributional Soft Actor-Critic for Risk-Sensitive\n  Navigation", "comments": "ICRA 2021. For associated videos, see https://europe.naverlabs.com/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern navigation algorithms based on deep reinforcement learning (RL) show\npromising efficiency and robustness. However, most deep RL algorithms operate\nin a risk-neutral manner, making no special attempt to shield users from\nrelatively rare but serious outcomes, even if such shielding might cause little\nloss of performance. Furthermore, such algorithms typically make no provisions\nto ensure safety in the presence of inaccuracies in the models on which they\nwere trained, beyond adding a cost-of-collision and some domain randomization\nwhile training, in spite of the formidable complexity of the environments in\nwhich they operate. In this paper, we present a novel distributional RL\nalgorithm that not only learns an uncertainty-aware policy, but can also change\nits risk measure without expensive fine-tuning or retraining. Our method shows\nsuperior performance and safety over baselines in partially-observed navigation\ntasks. We also demonstrate that agents trained using our method can adapt their\npolicies to a wide range of risk measures at run-time.\n", "versions": [{"version": "v1", "created": "Wed, 7 Apr 2021 13:23:53 GMT"}, {"version": "v2", "created": "Fri, 9 Apr 2021 11:18:10 GMT"}], "update_date": "2021-04-12", "authors_parsed": [["Choi", "Jinyoung", ""], ["Dance", "Christopher R.", ""], ["Kim", "Jung-eun", ""], ["Hwang", "Seulbin", ""], ["Park", "Kyung-sik", ""]]}, {"id": "2104.03113", "submitter": "Andy Jones", "authors": "Andy L. Jones", "title": "Scaling Scaling Laws with Board Games", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.MA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The largest experiments in machine learning now require resources far beyond\nthe budget of all but a few institutions. Fortunately, it has recently been\nshown that the results of these huge experiments can often be extrapolated from\nthe results of a sequence of far smaller, cheaper experiments. In this work, we\nshow that not only can the extrapolation be done based on the size of the\nmodel, but on the size of the problem as well. By conducting a sequence of\nexperiments using AlphaZero and Hex, we show that the performance achievable\nwith a fixed amount of compute degrades predictably as the game gets larger and\nharder. Along with our main result, we further show that the test-time and\ntrain-time compute available to an agent can be traded off while maintaining\nperformance.\n", "versions": [{"version": "v1", "created": "Wed, 7 Apr 2021 13:34:25 GMT"}, {"version": "v2", "created": "Thu, 15 Apr 2021 10:03:37 GMT"}], "update_date": "2021-04-16", "authors_parsed": [["Jones", "Andy L.", ""]]}, {"id": "2104.03115", "submitter": "Michael Chertkov", "authors": "Andrei Afonin and Michael Chertkov", "title": "Which Neural Network to Choose for Post-Fault Localization, Dynamic\n  State Estimation and Optimal Measurement Placement in Power Systems?", "comments": "12 pages, 8 figures, 10 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG physics.data-an physics.soc-ph", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We consider a power transmission system monitored with Phasor Measurement\nUnits (PMUs) placed at significant, but not all, nodes of the system. Assuming\nthat a sufficient number of distinct single-line faults, specifically pre-fault\nstate and (not cleared) post-fault state, are recorded by the PMUs and are\navailable for training, we, first, design a comprehensive sequence of Neural\nNetworks (NNs) locating the faulty line. Performance of different NNs in the\nsequence, including Linear Regression, Feed-Forward NN, AlexNet, Graphical\nConvolutional NN, Neural Linear ODE and Neural Graph-based ODE, ordered\naccording to the type and amount of the power flow physics involved, are\ncompared for different levels of observability. Second, we build a sequence of\nadvanced Power-System-Dynamics-Informed and Neural-ODE based Machine Learning\nschemes trained, given pre-fault state, to predict the post-fault state and\nalso, in parallel, to estimate system parameters. Finally, third, and\ncontinuing to work with the first (fault localization) setting we design a\n(NN-based) algorithm which discovers optimal PMU placement.\n", "versions": [{"version": "v1", "created": "Wed, 7 Apr 2021 13:35:55 GMT"}], "update_date": "2021-04-08", "authors_parsed": [["Afonin", "Andrei", ""], ["Chertkov", "Michael", ""]]}, {"id": "2104.03123", "submitter": "Wanying Ge", "authors": "Wanying Ge, Michele Panariello, Jose Patino, Massimiliano Todisco and\n  Nicholas Evans", "title": "Partially-Connected Differentiable Architecture Search for Deepfake and\n  Spoofing Detection", "comments": "Accepted to INTERSPEECH 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SD eess.AS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper reports the first successful application of a differentiable\narchitecture search (DARTS) approach to the deepfake and spoofing detection\nproblems. An example of neural architecture search, DARTS operates upon a\ncontinuous, differentiable search space which enables both the architecture and\nparameters to be optimised via gradient descent. Solutions based on\npartially-connected DARTS use random channel masking in the search space to\nreduce GPU time and automatically learn and optimise complex neural\narchitectures composed of convolutional operations and residual blocks. Despite\nbeing learned quickly with little human effort, the resulting networks are\ncompetitive with the best performing systems reported in the literature. Some\nare also far less complex, containing 85% fewer parameters than a Res2Net\ncompetitor.\n", "versions": [{"version": "v1", "created": "Wed, 7 Apr 2021 13:53:20 GMT"}, {"version": "v2", "created": "Wed, 30 Jun 2021 11:03:10 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Ge", "Wanying", ""], ["Panariello", "Michele", ""], ["Patino", "Jose", ""], ["Todisco", "Massimiliano", ""], ["Evans", "Nicholas", ""]]}, {"id": "2104.03130", "submitter": "Steven Guan", "authors": "Steven Guan, Ko-Tsung Hsu, Matthias Eyassu, and Parag V. Chitnis", "title": "Dense Dilated UNet: Deep Learning for 3D Photoacoustic Tomography Image\n  Reconstruction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In photoacoustic tomography (PAT), the acoustic pressure waves produced by\noptical excitation are measured by an array of detectors and used to\nreconstruct an image. Sparse spatial sampling and limited-view detection are\ntwo common challenges faced in PAT. Reconstructing from incomplete data using\nstandard methods results in severe streaking artifacts and blurring. We propose\na modified convolutional neural network (CNN) architecture termed Dense\nDilation UNet (DD-UNet) for correcting artifacts in 3D PAT. The DD-Net\nleverages the benefits of dense connectivity and dilated convolutions to\nimprove CNN performance. We compare the proposed CNN in terms of image quality\nas measured by the multiscale structural similarity index metric to the Fully\nDense UNet (FD-UNet). Results demonstrate that the DD-Net consistently\noutperforms the FD-UNet and is able to more reliably reconstruct smaller image\nfeatures.\n", "versions": [{"version": "v1", "created": "Wed, 7 Apr 2021 14:01:48 GMT"}], "update_date": "2021-04-08", "authors_parsed": [["Guan", "Steven", ""], ["Hsu", "Ko-Tsung", ""], ["Eyassu", "Matthias", ""], ["Chitnis", "Parag V.", ""]]}, {"id": "2104.03142", "submitter": "Jos\\'e Moreira", "authors": "Jos\\'e E. Moreira, Kit Barton, Steven Battle, Peter Bergner, Ramon\n  Bertran, Puneeth Bhat, Pedro Caldeira, David Edelsohn, Gordon Fossum, Brad\n  Frey, Nemanja Ivanovic, Chip Kerchner, Vincent Lim, Shakti Kapoor, Tulio\n  Machado Filho, Silvia Melitta Mueller, Brett Olsson, Satish Sadasivam,\n  Baptiste Saleil, Bill Schmidt, Rajalakshmi Srinivasaraghavan, Shricharan\n  Srivatsan, Brian Thompto, Andreas Wagner, Nelson Wu", "title": "A matrix math facility for Power ISA(TM) processors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR cs.LG cs.PF cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Power ISA(TM) Version 3.1 has introduced a new family of matrix math\ninstructions, collectively known as the Matrix-Multiply Assist (MMA) facility.\nThe instructions in this facility implement numerical linear algebra operations\non small matrices and are meant to accelerate computation-intensive kernels,\nsuch as matrix multiplication, convolution and discrete Fourier transform.\nThese instructions have led to a power- and area-efficient implementation of a\nhigh throughput math engine in the future POWER10 processor. Performance per\ncore is 4 times better, at constant frequency, than the previous generation\nPOWER9 processor. We also advocate the use of compiler built-ins as the\npreferred way of leveraging these instructions, which we illustrate through\ncase studies covering matrix multiplication and convolution.\n", "versions": [{"version": "v1", "created": "Wed, 7 Apr 2021 14:17:32 GMT"}], "update_date": "2021-04-08", "authors_parsed": [["Moreira", "Jos\u00e9 E.", ""], ["Barton", "Kit", ""], ["Battle", "Steven", ""], ["Bergner", "Peter", ""], ["Bertran", "Ramon", ""], ["Bhat", "Puneeth", ""], ["Caldeira", "Pedro", ""], ["Edelsohn", "David", ""], ["Fossum", "Gordon", ""], ["Frey", "Brad", ""], ["Ivanovic", "Nemanja", ""], ["Kerchner", "Chip", ""], ["Lim", "Vincent", ""], ["Kapoor", "Shakti", ""], ["Filho", "Tulio Machado", ""], ["Mueller", "Silvia Melitta", ""], ["Olsson", "Brett", ""], ["Sadasivam", "Satish", ""], ["Saleil", "Baptiste", ""], ["Schmidt", "Bill", ""], ["Srinivasaraghavan", "Rajalakshmi", ""], ["Srivatsan", "Shricharan", ""], ["Thompto", "Brian", ""], ["Wagner", "Andreas", ""], ["Wu", "Nelson", ""]]}, {"id": "2104.03152", "submitter": "Bogdan Cebere", "authors": "Ayoub Benaissa, Bilal Retiat, Bogdan Cebere, Alaa Eddine Belfedhal", "title": "TenSEAL: A Library for Encrypted Tensor Operations Using Homomorphic\n  Encryption", "comments": "ICLR 2021 Workshop on Distributed and Private Machine Learning (DPML\n  2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Machine learning algorithms have achieved remarkable results and are widely\napplied in a variety of domains. These algorithms often rely on sensitive and\nprivate data such as medical and financial records. Therefore, it is vital to\ndraw further attention regarding privacy threats and corresponding defensive\ntechniques applied to machine learning models. In this paper, we present\nTenSEAL, an open-source library for Privacy-Preserving Machine Learning using\nHomomorphic Encryption that can be easily integrated within popular machine\nlearning frameworks. We benchmark our implementation using MNIST and show that\nan encrypted convolutional neural network can be evaluated in less than a\nsecond, using less than half a megabyte of communication.\n", "versions": [{"version": "v1", "created": "Wed, 7 Apr 2021 14:32:38 GMT"}, {"version": "v2", "created": "Wed, 28 Apr 2021 04:44:18 GMT"}], "update_date": "2021-04-29", "authors_parsed": [["Benaissa", "Ayoub", ""], ["Retiat", "Bilal", ""], ["Cebere", "Bogdan", ""], ["Belfedhal", "Alaa Eddine", ""]]}, {"id": "2104.03154", "submitter": "Lucas Schott", "authors": "Lucas Schott, Manon C\\'esaire, Hatem Hajri, Sylvain Lamprier", "title": "Improving Robustness of Deep Reinforcement Learning Agents: Environment\n  Attacks based on Critic Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To improve policy robustness of deep reinforcement learning agents, a line of\nrecent works focus on producing disturbances of the environment. Existing\napproaches of the literature to generate meaningful disturbances of the\nenvironment are adversarial reinforcement learning methods. These methods set\nthe problem as a two-player game between the protagonist agent, which learns to\nperform a task in an environment, and the adversary agent, which learns to\ndisturb the protagonist via modifications of the considered environment. Both\nprotagonist and adversary are trained with deep reinforcement learning\nalgorithms. Alternatively, we propose in this paper to build on gradient-based\nadversarial attacks, usually used for classification tasks for instance, that\nwe apply on the critic network of the protagonist to identify efficient\ndisturbances of the environment. Rather than learning an attacker policy, which\nusually reveals as very complex and unstable, we leverage the knowledge of the\ncritic network of the protagonist, to dynamically complexify the task at each\nstep of the learning process. We show that our method, while being faster and\nlighter, leads to significantly better improvements in policy robustness than\nexisting methods of the literature.\n", "versions": [{"version": "v1", "created": "Wed, 7 Apr 2021 14:37:23 GMT"}], "update_date": "2021-04-08", "authors_parsed": [["Schott", "Lucas", ""], ["C\u00e9saire", "Manon", ""], ["Hajri", "Hatem", ""], ["Lamprier", "Sylvain", ""]]}, {"id": "2104.03158", "submitter": "Jean Pauphilet", "authors": "Dimitris Bertsimas, Arthur Delarue, Jean Pauphilet", "title": "Prediction with Missing Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Missing information is inevitable in real-world data sets. While imputation\nis well-suited and theoretically sound for statistical inference, its relevance\nand practical implementation for out-of-sample prediction remains unsettled. We\nprovide a theoretical analysis of widely used data imputation methods and\nhighlight their key deficiencies in making accurate predictions. Alternatively,\nwe propose adaptive linear regression, a new class of models that can be\ndirectly trained and evaluated on partially observed data, adapting to the set\nof available features. In particular, we show that certain adaptive regression\nmodels are equivalent to impute-then-regress methods where the imputation and\nthe regression models are learned simultaneously instead of sequentially. We\nvalidate our theoretical findings and adaptive regression approach with\nnumerical results with real-world data sets.\n", "versions": [{"version": "v1", "created": "Wed, 7 Apr 2021 14:45:14 GMT"}], "update_date": "2021-04-08", "authors_parsed": [["Bertsimas", "Dimitris", ""], ["Delarue", "Arthur", ""], ["Pauphilet", "Jean", ""]]}, {"id": "2104.03165", "submitter": "Alexander Wong", "authors": "Alexander Wong, James Ren Hou Lee, Hadi Rahmat-Khah, Ali Sabri, and\n  Amer Alaref", "title": "TB-Net: A Tailored, Self-Attention Deep Convolutional Neural Network\n  Design for Detection of Tuberculosis Cases from Chest X-ray Images", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tuberculosis (TB) remains a global health problem, and is the leading cause\nof death from an infectious disease. A crucial step in the treatment of\ntuberculosis is screening high risk populations and the early detection of the\ndisease, with chest x-ray (CXR) imaging being the most widely-used imaging\nmodality. As such, there has been significant recent interest in artificial\nintelligence-based TB screening solutions for use in resource-limited scenarios\nwhere there is a lack of trained healthcare workers with expertise in CXR\ninterpretation. Motivated by this pressing need and the recent recommendation\nby the World Health Organization (WHO) for the use of computer-aided diagnosis\nof TB, we introduce TB-Net, a self-attention deep convolutional neural network\ntailored for TB case screening. More specifically, we leveraged machine-driven\ndesign exploration to build a highly customized deep neural network\narchitecture with attention condensers. We conducted an explainability-driven\nperformance validation process to validate TB-Net's decision-making behaviour.\nExperiments on CXR data from a multi-national patient cohort showed that the\nproposed TB-Net is able to achieve accuracy/sensitivity/specificity of\n99.86%/100.0%/99.71%. Radiologist validation was conducted on select cases by\ntwo board-certified radiologists with over 10 and 19 years of experience,\nrespectively, and showed consistency between radiologist interpretation and\ncritical factors leveraged by TB-Net for TB case detection for the case where\nradiologists identified anomalies. While not a production-ready solution, we\nhope that the open-source release of TB-Net as part of the COVID-Net initiative\nwill support researchers, clinicians, and citizen data scientists in advancing\nthis field in the fight against this global public health crisis.\n", "versions": [{"version": "v1", "created": "Tue, 6 Apr 2021 14:09:05 GMT"}, {"version": "v2", "created": "Wed, 14 Apr 2021 00:09:11 GMT"}], "update_date": "2021-04-15", "authors_parsed": [["Wong", "Alexander", ""], ["Lee", "James Ren Hou", ""], ["Rahmat-Khah", "Hadi", ""], ["Sabri", "Ali", ""], ["Alaref", "Amer", ""]]}, {"id": "2104.03180", "submitter": "Andrea Patane", "authors": "Andrea Patane, Arno Blaas, Luca Laurenti, Luca Cardelli, Stephen\n  Roberts, Marta Kwiatkowska", "title": "Adversarial Robustness Guarantees for Gaussian Processes", "comments": "Submitted for publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Gaussian processes (GPs) enable principled computation of model uncertainty,\nmaking them attractive for safety-critical applications. Such scenarios demand\nthat GP decisions are not only accurate, but also robust to perturbations. In\nthis paper we present a framework to analyse adversarial robustness of GPs,\ndefined as invariance of the model's decision to bounded perturbations. Given a\ncompact subset of the input space $T\\subseteq \\mathbb{R}^d$, a point $x^*$ and\na GP, we provide provable guarantees of adversarial robustness of the GP by\ncomputing lower and upper bounds on its prediction range in $T$. We develop a\nbranch-and-bound scheme to refine the bounds and show, for any $\\epsilon > 0$,\nthat our algorithm is guaranteed to converge to values $\\epsilon$-close to the\nactual values in finitely many iterations. The algorithm is anytime and can\nhandle both regression and classification tasks, with analytical formulation\nfor most kernels used in practice. We evaluate our methods on a collection of\nsynthetic and standard benchmark datasets, including SPAM, MNIST and\nFashionMNIST. We study the effect of approximate inference techniques on\nrobustness and demonstrate how our method can be used for interpretability. Our\nempirical results suggest that the adversarial robustness of GPs increases with\naccurate posterior estimation.\n", "versions": [{"version": "v1", "created": "Wed, 7 Apr 2021 15:14:56 GMT"}], "update_date": "2021-04-08", "authors_parsed": [["Patane", "Andrea", ""], ["Blaas", "Arno", ""], ["Laurenti", "Luca", ""], ["Cardelli", "Luca", ""], ["Roberts", "Stephen", ""], ["Kwiatkowska", "Marta", ""]]}, {"id": "2104.03182", "submitter": "Lixuan Yang", "authors": "Lixuan Yang, Alessandro Finamore, Feng Jun, Dario Rossi", "title": "Deep Learning and Traffic Classification: Lessons learned from a\n  commercial-grade dataset with hundreds of encrypted and zero-day applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The increasing success of Machine Learning (ML) and Deep Learning (DL) has\nrecently re-sparked interest towards traffic classification. While\nclassification of known traffic is a well investigated subject with supervised\nclassification tools (such as ML and DL models) are known to provide\nsatisfactory performance, detection of unknown (or zero-day) traffic is more\nchallenging and typically handled by unsupervised techniques (such as\nclustering algorithms).\n  In this paper, we share our experience on a commercial-grade DL traffic\nclassification engine that is able to (i) identify known applications from\nencrypted traffic, as well as (ii) handle unknown zero-day applications. In\nparticular, our contribution for (i) is to perform a thorough assessment of\nstate of the art traffic classifiers in commercial-grade settings comprising\nfew thousands of very fine grained application labels, as opposite to the few\ntens of classes generally targeted in academic evaluations. Additionally, we\ncontribute to the problem of (ii) detection of zero-day applications by\nproposing a novel technique, tailored for DL models, that is significantly more\naccurate and light-weight than the state of the art.\n  Summarizing our main findings, we gather that (i) while ML and DL models are\nboth equally able to provide satisfactory solution for classification of known\ntraffic, however (ii) the non-linear feature extraction process of the DL\nbackbone provides sizeable advantages for the detection of unknown classes.\n", "versions": [{"version": "v1", "created": "Wed, 7 Apr 2021 15:21:22 GMT"}], "update_date": "2021-04-08", "authors_parsed": [["Yang", "Lixuan", ""], ["Finamore", "Alessandro", ""], ["Jun", "Feng", ""], ["Rossi", "Dario", ""]]}, {"id": "2104.03189", "submitter": "Tunazzina Islam", "authors": "Tunazzina Islam, Dan Goldwasser", "title": "Analysis of Twitter Users' Lifestyle Choices using Joint Embedding Model", "comments": "accepted at 15th International AAAI Conference on Web and Social\n  Media (ICWSM-2021), 12 pages. Minor changes for camera-ready version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CY cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multiview representation learning of data can help construct coherent and\ncontextualized users' representations on social media. This paper suggests a\njoint embedding model, incorporating users' social and textual information to\nlearn contextualized user representations used for understanding their\nlifestyle choices. We apply our model to tweets related to two lifestyle\nactivities, `Yoga' and `Keto diet' and use it to analyze users' activity type\nand motivation. We explain the data collection and annotation process in detail\nand provide an in-depth analysis of users from different classes based on their\nTwitter content. Our experiments show that our model results in performance\nimprovements in both domains.\n", "versions": [{"version": "v1", "created": "Wed, 7 Apr 2021 15:29:36 GMT"}, {"version": "v2", "created": "Fri, 16 Apr 2021 15:36:19 GMT"}, {"version": "v3", "created": "Tue, 4 May 2021 18:14:32 GMT"}], "update_date": "2021-05-06", "authors_parsed": [["Islam", "Tunazzina", ""], ["Goldwasser", "Dan", ""]]}, {"id": "2104.03207", "submitter": "Soheyla Amirian", "authors": "Soheyla Amirian, Abolfazl Farahani, Hamid R. Arabnia, Khaled Rasheed,\n  Thiab R. Taha", "title": "The Use of Video Captioning for Fostering Physical Activity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Video Captioning is considered to be one of the most challenging problems in\nthe field of computer vision. Video Captioning involves the combination of\ndifferent deep learning models to perform object detection, action detection,\nand localization by processing a sequence of image frames. It is crucial to\nconsider the sequence of actions in a video in order to generate a meaningful\ndescription of the overall action event. A reliable, accurate, and real-time\nvideo captioning method can be used in many applications. However, this paper\nfocuses on one application: video captioning for fostering and facilitating\nphysical activities. In broad terms, the work can be considered to be assistive\ntechnology. Lack of physical activity appears to be increasingly widespread in\nmany nations due to many factors, the most important being the convenience that\ntechnology has provided in workplaces. The adopted sedentary lifestyle is\nbecoming a significant public health issue. Therefore, it is essential to\nincorporate more physical movements into our daily lives. Tracking one's daily\nphysical activities would offer a base for comparison with activities performed\nin subsequent days. With the above in mind, this paper proposes a video\ncaptioning framework that aims to describe the activities in a video and\nestimate a person's daily physical activity level. This framework could\npotentially help people trace their daily movements to reduce an inactive\nlifestyle's health risks. The work presented in this paper is still in its\ninfancy. The initial steps of the application are outlined in this paper. Based\non our preliminary research, this project has great merit.\n", "versions": [{"version": "v1", "created": "Wed, 7 Apr 2021 15:52:48 GMT"}], "update_date": "2021-04-08", "authors_parsed": [["Amirian", "Soheyla", ""], ["Farahani", "Abolfazl", ""], ["Arabnia", "Hamid R.", ""], ["Rasheed", "Khaled", ""], ["Taha", "Thiab R.", ""]]}, {"id": "2104.03220", "submitter": "Malte S. Kurz", "authors": "Philipp Bach, Victor Chernozhukov, Malte S. Kurz, Martin Spindler", "title": "DoubleML -- An Object-Oriented Implementation of Double Machine Learning\n  in Python", "comments": "6 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG econ.EM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  DoubleML is an open-source Python library implementing the double machine\nlearning framework of Chernozhukov et al. (2018) for a variety of causal\nmodels. It contains functionalities for valid statistical inference on causal\nparameters when the estimation of nuisance parameters is based on machine\nlearning methods. The object-oriented implementation of DoubleML provides a\nhigh flexibility in terms of model specifications and makes it easily\nextendable. The package is distributed under the MIT license and relies on core\nlibraries from the scientific Python ecosystem: scikit-learn, numpy, pandas,\nscipy, statsmodels and joblib. Source code, documentation and an extensive user\nguide can be found at https://github.com/DoubleML/doubleml-for-py and\nhttps://docs.doubleml.org.\n", "versions": [{"version": "v1", "created": "Wed, 7 Apr 2021 16:16:39 GMT"}], "update_date": "2021-04-08", "authors_parsed": [["Bach", "Philipp", ""], ["Chernozhukov", "Victor", ""], ["Kurz", "Malte S.", ""], ["Spindler", "Martin", ""]]}, {"id": "2104.03224", "submitter": "Michael Kaufmann", "authors": "Michael Kaufmann, Gabriel Stechschulte, Anna Huber", "title": "Efficient and Accurate In-Database Machine Learning with SQL Code\n  Generation in Python", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Following an analysis of the advantages of SQL-based Machine Learning (ML)\nand a short literature survey of the field, we describe a novel method for\nIn-Database Machine Learning (IDBML). We contribute a process for SQL-code\ngeneration in Python using template macros in Jinja2 as well as the prototype\nimplementation of the process. We describe our implementation of the process to\ncompute multidimensional histogram (MDH) probability estimation in SQL. For\nthis, we contribute and implement a novel discretization method called equal\nquantized rank binning (EQRB) and equal-width binning (EWB). Based on this, we\nprovide data gathered in a benchmarking experiment for the quantitative\nempirical evaluation of our method and system using the Covertype dataset. We\nmeasured accuracy and computation time and compared it to Scikit Learn state of\nthe art classification algorithms. Using EWB, our multidimensional probability\nestimation was the fastest of all tested algorithms, while being only 1-2% less\naccurate than the best state of the art methods found (decision trees and\nrandom forests). Our method was significantly more accurate than Naive Bayes,\nwhich assumes independent one-dimensional probabilities and/or densities. Also,\nour method was significantly more accurate and faster than logistic regression.\nThis motivates for further research in accuracy improvement and in IDBML with\nSQL code generation for big data and larger-than-memory datasets.\n", "versions": [{"version": "v1", "created": "Wed, 7 Apr 2021 16:23:19 GMT"}, {"version": "v2", "created": "Mon, 31 May 2021 14:43:37 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Kaufmann", "Michael", ""], ["Stechschulte", "Gabriel", ""], ["Huber", "Anna", ""]]}, {"id": "2104.03226", "submitter": "Satvik Garg", "authors": "Satvik Garg and Himanshu Jindal", "title": "Evaluation of Time Series Forecasting Models for Estimation of PM2.5\n  Levels in Air", "comments": "8 pages, This paper is accepted and presented in the IEEE 6th I2CT\n  2021 conference. The final version of this paper will appear in the\n  conference proceedings", "journal-ref": null, "doi": "10.1109/I2CT51068.2021.9418215", "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Air contamination in urban areas has risen consistently over the past few\nyears. Due to expanding industrialization and increasing concentration of toxic\ngases in the climate, the air is getting more poisonous step by step at an\nalarming rate. Since the arrival of the Coronavirus pandemic, it is getting\nmore critical to lessen air contamination to reduce its impact. The specialists\nand environmentalists are making a valiant effort to gauge air contamination\nlevels. However, its genuinely unpredictable to mimic subatomic communication\nin the air, which brings about off base outcomes. There has been an ascent in\nusing machine learning and deep learning models to foresee the results on time\nseries data. This study adopts ARIMA, FBProphet, and deep learning models such\nas LSTM, 1D CNN, to estimate the concentration of PM2.5 in the environment. Our\npredicted results convey that all adopted methods give comparative outcomes in\nterms of average root mean squared error. However, the LSTM outperforms all\nother models with reference to mean absolute percentage error.\n", "versions": [{"version": "v1", "created": "Wed, 7 Apr 2021 16:24:39 GMT"}], "update_date": "2021-05-13", "authors_parsed": [["Garg", "Satvik", ""], ["Jindal", "Himanshu", ""]]}, {"id": "2104.03233", "submitter": "Ellie Simonson", "authors": "Ellie Simonson", "title": "Semi-Supervised Classification of Social Media Posts: Identifying\n  Sex-Industry Posts to Enable Better Support for Those Experiencing\n  Sex-Trafficking", "comments": "111 pages, Thesis Supervisor: Richard Fletcher", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Social media is both helpful and harmful to the work against sex trafficking.\nOn one hand, social workers carefully use social media to support people\nexperiencing sex trafficking. On the other hand, traffickers use social media\nto groom and recruit people into trafficking situations. There is the\nopportunity to use social media data to better provide support for people\nexperiencing trafficking.\n  While AI and Machine Learning (ML) have been used in work against sex\ntrafficking, they predominantly focus on detecting Child Sexual Abuse Material.\nWork using social media data has not been done with the intention to provide\ncommunity level support to people of all ages experiencing trafficking. Within\nthis context, this thesis explores the use of semi-supervised classification to\nidentify social media posts that are a part of the sex industry.\n  Several methods were explored for ML. However, the primary method used was\nsemi-supervised learning, which has the benefit of providing automated\nclassification with a limited set of labelled data. Social media posts were\nembedded into low-dimensional vectors using FastText and Doc2Vec models. The\ndata were then clustered using k-means clustering, and cross-validation was\nused to determine label propagation accuracy.\n  The results of the semi-supervised algorithm were encouraging. The FastText\nCBOW model provided 98.6% accuracy to over 12,000 posts in clusters where label\npropagation was applied. The results of this thesis suggest that further\nsemi-supervised learning, in conjunction with manual labeling, may allow for\nthe entire dataset containing over 50,000 posts to be accurately labeled.\n  A fully labeled dataset could be used to develop a tool to identify an\noverview of where and when social media is used within the sex industry. This\ncould be used to help determine better ways to provide support to people\nexperiencing trafficking.\n", "versions": [{"version": "v1", "created": "Wed, 7 Apr 2021 16:31:14 GMT"}], "update_date": "2021-04-08", "authors_parsed": [["Simonson", "Ellie", ""]]}, {"id": "2104.03279", "submitter": "Philipp Seidl", "authors": "Philipp Seidl, Philipp Renz, Natalia Dyubankova, Paulo Neves, Jonas\n  Verhoeven, Marwin Segler, J\\\"org K. Wegner, Sepp Hochreiter, G\\\"unter\n  Klambauer", "title": "Modern Hopfield Networks for Few- and Zero-Shot Reaction Template\n  Prediction", "comments": "14 pages + 12 pages appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI q-bio.BM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Finding synthesis routes for molecules of interest is an essential step in\nthe discovery of new drugs and materials. To find such routes,\ncomputer-assisted synthesis planning (CASP) methods are employed which rely on\na model of chemical reactivity. In this study, we model single-step\nretrosynthesis in a template-based approach using modern Hopfield networks\n(MHNs). We adapt MHNs to associate different modalities, reaction templates and\nmolecules, which allows the model to leverage structural information about\nreaction templates. This approach significantly improves the performance of\ntemplate relevance prediction, especially for templates with few or zero\ntraining examples. With inference speed several times faster than that of\nbaseline methods, we improve predictive performance for top-k exact match\naccuracy for $\\mathrm{k}\\geq5$ in the retrosynthesis benchmark USPTO-50k.\n", "versions": [{"version": "v1", "created": "Wed, 7 Apr 2021 17:35:00 GMT"}, {"version": "v2", "created": "Mon, 7 Jun 2021 15:57:01 GMT"}, {"version": "v3", "created": "Tue, 15 Jun 2021 13:24:02 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Seidl", "Philipp", ""], ["Renz", "Philipp", ""], ["Dyubankova", "Natalia", ""], ["Neves", "Paulo", ""], ["Verhoeven", "Jonas", ""], ["Segler", "Marwin", ""], ["Wegner", "J\u00f6rg K.", ""], ["Hochreiter", "Sepp", ""], ["Klambauer", "G\u00fcnter", ""]]}, {"id": "2104.03298", "submitter": "Changxiao Cai", "authors": "Gen Li, Changxiao Cai, Yuantao Gu, H. Vincent Poor, Yuxin Chen", "title": "Minimax Estimation of Linear Functions of Eigenvectors in the Face of\n  Small Eigen-Gaps", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.IT cs.LG math.IT stat.ML stat.TH", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Eigenvector perturbation analysis plays a vital role in various statistical\ndata science applications. A large body of prior works, however, focused on\nestablishing $\\ell_{2}$ eigenvector perturbation bounds, which are often highly\ninadequate in addressing tasks that rely on fine-grained behavior of an\neigenvector. This paper makes progress on this by studying the perturbation of\nlinear functions of an unknown eigenvector. Focusing on two fundamental\nproblems -- matrix denoising and principal component analysis -- in the\npresence of Gaussian noise, we develop a suite of statistical theory that\ncharacterizes the perturbation of arbitrary linear functions of an unknown\neigenvector. In order to mitigate a non-negligible bias issue inherent to the\nnatural \"plug-in\" estimator, we develop de-biased estimators that (1) achieve\nminimax lower bounds for a family of scenarios (modulo some logarithmic\nfactor), and (2) can be computed in a data-driven manner without sample\nsplitting. Noteworthily, the proposed estimators are nearly minimax optimal\neven when the associated eigen-gap is substantially smaller than what is\nrequired in prior theory.\n", "versions": [{"version": "v1", "created": "Wed, 7 Apr 2021 17:55:10 GMT"}], "update_date": "2021-04-08", "authors_parsed": [["Li", "Gen", ""], ["Cai", "Changxiao", ""], ["Gu", "Yuantao", ""], ["Poor", "H. Vincent", ""], ["Chen", "Yuxin", ""]]}, {"id": "2104.03305", "submitter": "Magda Gregorova", "authors": "Magda Gregorov\\'a, Marc Desaules, Alexandros Kalousis", "title": "Learned transform compression with optimized entropy encoding", "comments": "Published as a workshop paper at ICLR 2021 neural compression\n  workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We consider the problem of learned transform compression where we learn both,\nthe transform as well as the probability distribution over the discrete codes.\nWe utilize a soft relaxation of the quantization operation to allow for\nback-propagation of gradients and employ vector (rather than scalar)\nquantization of the latent codes. Furthermore, we apply similar relaxation in\nthe code probability assignments enabling direct optimization of the code\nentropy. To the best of our knowledge, this approach is completely novel. We\nconduct a set of proof-of concept experiments confirming the potency of our\napproaches.\n", "versions": [{"version": "v1", "created": "Wed, 7 Apr 2021 17:58:01 GMT"}, {"version": "v2", "created": "Tue, 4 May 2021 08:52:38 GMT"}], "update_date": "2021-05-05", "authors_parsed": [["Gregorov\u00e1", "Magda", ""], ["Desaules", "Marc", ""], ["Kalousis", "Alexandros", ""]]}, {"id": "2104.03309", "submitter": "Aayush Bansal", "authors": "Zhiqiu Lin and Deva Ramanan and Aayush Bansal", "title": "Streaming Self-Training via Domain-Agnostic Unlabeled Images", "comments": "Project Page: https://www.cs.cmu.edu/~aayushb/SST/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present streaming self-training (SST) that aims to democratize the process\nof learning visual recognition models such that a non-expert user can define a\nnew task depending on their needs via a few labeled examples and minimal domain\nknowledge. Key to SST are two crucial observations: (1) domain-agnostic\nunlabeled images enable us to learn better models with a few labeled examples\nwithout any additional knowledge or supervision; and (2) learning is a\ncontinuous process and can be done by constructing a schedule of learning\nupdates that iterates between pre-training on novel segments of the streams of\nunlabeled data, and fine-tuning on the small and fixed labeled dataset. This\nallows SST to overcome the need for a large number of domain-specific labeled\nand unlabeled examples, exorbitant computational resources, and\ndomain/task-specific knowledge. In this setting, classical semi-supervised\napproaches require a large amount of domain-specific labeled and unlabeled\nexamples, immense resources to process data, and expert knowledge of a\nparticular task. Due to these reasons, semi-supervised learning has been\nrestricted to a few places that can house required computational and human\nresources. In this work, we overcome these challenges and demonstrate our\nfindings for a wide range of visual recognition tasks including fine-grained\nimage classification, surface normal estimation, and semantic segmentation. We\nalso demonstrate our findings for diverse domains including medical, satellite,\nand agricultural imagery, where there does not exist a large amount of labeled\nor unlabeled data.\n", "versions": [{"version": "v1", "created": "Wed, 7 Apr 2021 17:58:39 GMT"}], "update_date": "2021-04-08", "authors_parsed": [["Lin", "Zhiqiu", ""], ["Ramanan", "Deva", ""], ["Bansal", "Aayush", ""]]}, {"id": "2104.03310", "submitter": "Hung-Yu Tseng", "authors": "Hung-Yu Tseng, Lu Jiang, Ce Liu, Ming-Hsuan Yang, Weilong Yang", "title": "Regularizing Generative Adversarial Networks under Limited Data", "comments": "CVPR 2021. Project Page: https://hytseng0509.github.io/lecam-gan\n  Code: https://github.com/google/lecam-gan", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent years have witnessed the rapid progress of generative adversarial\nnetworks (GANs). However, the success of the GAN models hinges on a large\namount of training data. This work proposes a regularization approach for\ntraining robust GAN models on limited data. We theoretically show a connection\nbetween the regularized loss and an f-divergence called LeCam-divergence, which\nwe find is more robust under limited training data. Extensive experiments on\nseveral benchmark datasets demonstrate that the proposed regularization scheme\n1) improves the generalization performance and stabilizes the learning dynamics\nof GAN models under limited training data, and 2) complements the recent data\naugmentation methods. These properties facilitate training GAN models to\nachieve state-of-the-art performance when only limited training data of the\nImageNet benchmark is available.\n", "versions": [{"version": "v1", "created": "Wed, 7 Apr 2021 17:59:06 GMT"}], "update_date": "2021-04-08", "authors_parsed": [["Tseng", "Hung-Yu", ""], ["Jiang", "Lu", ""], ["Liu", "Ce", ""], ["Yang", "Ming-Hsuan", ""], ["Yang", "Weilong", ""]]}, {"id": "2104.03311", "submitter": "Chuang Gan", "authors": "Zhiao Huang, Yuanming Hu, Tao Du, Siyuan Zhou, Hao Su, Joshua B.\n  Tenenbaum, Chuang Gan", "title": "PlasticineLab: A Soft-Body Manipulation Benchmark with Differentiable\n  Physics", "comments": "Accepted to ICLR 2021 as a spotlight presentation. Project page:\n  http://plasticinelab.csail.mit.edu/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.GR cs.RO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Simulated virtual environments serve as one of the main driving forces behind\ndeveloping and evaluating skill learning algorithms. However, existing\nenvironments typically only simulate rigid body physics. Additionally, the\nsimulation process usually does not provide gradients that might be useful for\nplanning and control optimizations. We introduce a new differentiable physics\nbenchmark called PasticineLab, which includes a diverse collection of soft body\nmanipulation tasks. In each task, the agent uses manipulators to deform the\nplasticine into the desired configuration. The underlying physics engine\nsupports differentiable elastic and plastic deformation using the DiffTaichi\nsystem, posing many under-explored challenges to robotic agents. We evaluate\nseveral existing reinforcement learning (RL) methods and gradient-based methods\non this benchmark. Experimental results suggest that 1) RL-based approaches\nstruggle to solve most of the tasks efficiently; 2) gradient-based approaches,\nby optimizing open-loop control sequences with the built-in differentiable\nphysics engine, can rapidly find a solution within tens of iterations, but\nstill fall short on multi-stage tasks that require long-term planning. We\nexpect that PlasticineLab will encourage the development of novel algorithms\nthat combine differentiable physics and RL for more complex physics-based skill\nlearning tasks.\n", "versions": [{"version": "v1", "created": "Wed, 7 Apr 2021 17:59:23 GMT"}], "update_date": "2021-04-08", "authors_parsed": [["Huang", "Zhiao", ""], ["Hu", "Yuanming", ""], ["Du", "Tao", ""], ["Zhou", "Siyuan", ""], ["Su", "Hao", ""], ["Tenenbaum", "Joshua B.", ""], ["Gan", "Chuang", ""]]}, {"id": "2104.03335", "submitter": "Jon Nelson", "authors": "Jon Nelson, Marc Vuffray, Andrey Y. Lokhov, Carleton Coffrin", "title": "Single-Qubit Fidelity Assessment of Quantum Annealing Hardware", "comments": null, "journal-ref": null, "doi": null, "report-no": "LA-UR-21-23013", "categories": "quant-ph cs.LG physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As a wide variety of quantum computing platforms become available, methods\nfor assessing and comparing the performance of these devices are of increasing\ninterest and importance. Inspired by the success of single-qubit error rate\ncomputations for tracking the progress of gate-based quantum computers, this\nwork proposes a Quantum Annealing Single-qubit Assessment (QASA) protocol for\nquantifying the performance of individual qubits in quantum annealing\ncomputers. The proposed protocol scales to large quantum annealers with\nthousands of qubits and provides unique insights into the distribution of qubit\nproperties within a particular hardware device. The efficacy of the QASA\nprotocol is demonstrated by analyzing the properties of a D-Wave 2000Q system,\nrevealing unanticipated correlations in the qubit performance of that device. A\nstudy repeating the QASA protocol at different annealing times highlights how\nthe method can be utilized to understand the impact of annealing parameters on\nqubit performance. Overall, the proposed QASA protocol provides a useful tool\nfor assessing the performance of current and emerging quantum annealing\ndevices.\n", "versions": [{"version": "v1", "created": "Wed, 7 Apr 2021 18:12:05 GMT"}], "update_date": "2021-04-09", "authors_parsed": [["Nelson", "Jon", ""], ["Vuffray", "Marc", ""], ["Lokhov", "Andrey Y.", ""], ["Coffrin", "Carleton", ""]]}, {"id": "2104.03337", "submitter": "Soheyla Amirian", "authors": "Soheyla Amirian, Khaled Rasheed, Thiab R. Taha, Hamid R. Arabnia", "title": "Automatic Generation of Descriptive Titles for Video Clips Using Deep\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Over the last decade, the use of Deep Learning in many applications produced\nresults that are comparable to and in some cases surpassing human expert\nperformance. The application domains include diagnosing diseases, finance,\nagriculture, search engines, robot vision, and many others. In this paper, we\nare proposing an architecture that utilizes image/video captioning methods and\nNatural Language Processing systems to generate a title and a concise abstract\nfor a video. Such a system can potentially be utilized in many application\ndomains, including, the cinema industry, video search engines, security\nsurveillance, video databases/warehouses, data centers, and others. The\nproposed system functions and operates as followed: it reads a video;\nrepresentative image frames are identified and selected; the image frames are\ncaptioned; NLP is applied to all generated captions together with text\nsummarization; and finally, a title and an abstract are generated for the\nvideo. All functions are performed automatically. Preliminary results are\nprovided in this paper using publicly available datasets. This paper is not\nconcerned about the efficiency of the system at the execution time. We hope to\nbe able to address execution efficiency issues in our subsequent publications.\n", "versions": [{"version": "v1", "created": "Wed, 7 Apr 2021 18:14:18 GMT"}], "update_date": "2021-04-09", "authors_parsed": [["Amirian", "Soheyla", ""], ["Rasheed", "Khaled", ""], ["Taha", "Thiab R.", ""], ["Arabnia", "Hamid R.", ""]]}, {"id": "2104.03338", "submitter": "Fabricio Murai", "authors": "Francisco Galuppo Azevedo and Fabricio Murai", "title": "Evaluating the state-of-the-art in mapping research spaces: a Brazilian\n  case study", "comments": "28 pages, 11 figures", "journal-ref": "PLoS ONE 16(3): e0248724 (2021)", "doi": "10.1371/journal.pone.0248724", "report-no": null, "categories": "cs.DL cs.LG cs.SI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Scientific knowledge cannot be seen as a set of isolated fields, but as a\nhighly connected network. Understanding how research areas are connected is of\nparamount importance for adequately allocating funding and human resources\n(e.g., assembling teams to tackle multidisciplinary problems). The relationship\nbetween disciplines can be drawn from data on the trajectory of individual\nscientists, as researchers often make contributions in a small set of\ninterrelated areas. Two recent works propose methods for creating research maps\nfrom scientists' publication records: by using a frequentist approach to create\na transition probability matrix; and by learning embeddings (vector\nrepresentations). Surprisingly, these models were evaluated on different\ndatasets and have never been compared in the literature. In this work, we\ncompare both models in a systematic way, using a large dataset of publication\nrecords from Brazilian researchers. We evaluate these models' ability to\npredict whether a given entity (scientist, institution or region) will enter a\nnew field w.r.t. the area under the ROC curve. Moreover, we analyze how\nsensitive each method is to the number of publications and the number of fields\nassociated to one entity. Last, we conduct a case study to showcase how these\nmodels can be used to characterize science dynamics in the context of Brazil.\n", "versions": [{"version": "v1", "created": "Wed, 7 Apr 2021 18:14:41 GMT"}], "update_date": "2021-04-09", "authors_parsed": [["Azevedo", "Francisco Galuppo", ""], ["Murai", "Fabricio", ""]]}, {"id": "2104.03354", "submitter": "Shantanu Sharma", "authors": "Yin Li, Dhrubajyoti Ghosh, Peeyush Gupta, Sharad Mehrotra, Nisha\n  Panwar, Shantanu Sharma", "title": "Prism: Private Verifiable Set Computation over Multi-Owner Outsourced\n  Databases", "comments": "This paper has been accepted in ACM SIGMOD 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.CR cs.DC cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes Prism, a secret sharing based approach to compute private\nset operations (i.e., intersection and union), as well as aggregates over\noutsourced databases belonging to multiple owners. Prism enables data owners to\npre-load the data onto non-colluding servers and exploits the additive and\nmultiplicative properties of secret-shares to compute the above-listed\noperations in (at most) two rounds of communication between the servers\n(storing the secret-shares) and the querier, resulting in a very efficient\nimplementation. Also, Prism does not require communication among the servers\nand supports result verification techniques for each operation to detect\nmalicious adversaries. Experimental results show that Prism scales both in\nterms of the number of data owners and database sizes, to which prior\napproaches do not scale.\n", "versions": [{"version": "v1", "created": "Wed, 7 Apr 2021 19:08:15 GMT"}], "update_date": "2021-04-09", "authors_parsed": [["Li", "Yin", ""], ["Ghosh", "Dhrubajyoti", ""], ["Gupta", "Peeyush", ""], ["Mehrotra", "Sharad", ""], ["Panwar", "Nisha", ""], ["Sharma", "Shantanu", ""]]}, {"id": "2104.03356", "submitter": "Arianna Rampini", "authors": "Arianna Rampini, Franco Pestarini, Luca Cosmo, Simone Melzi, Emanuele\n  Rodol\\`a", "title": "Universal Spectral Adversarial Attacks for Deformable Shapes", "comments": "Published at CVPR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning models are known to be vulnerable to adversarial attacks,\nnamely perturbations of the data that lead to wrong predictions despite being\nimperceptible. However, the existence of \"universal\" attacks (i.e., unique\nperturbations that transfer across different data points) has only been\ndemonstrated for images to date. Part of the reason lies in the lack of a\ncommon domain, for geometric data such as graphs, meshes, and point clouds,\nwhere a universal perturbation can be defined. In this paper, we offer a change\nin perspective and demonstrate the existence of universal attacks for geometric\ndata (shapes). We introduce a computational procedure that operates entirely in\nthe spectral domain, where the attacks take the form of small perturbations to\nshort eigenvalue sequences; the resulting geometry is then synthesized via\nshape-from-spectrum recovery. Our attacks are universal, in that they transfer\nacross different shapes, different representations (meshes and point clouds),\nand generalize to previously unseen data.\n", "versions": [{"version": "v1", "created": "Wed, 7 Apr 2021 19:08:24 GMT"}], "update_date": "2021-04-09", "authors_parsed": [["Rampini", "Arianna", ""], ["Pestarini", "Franco", ""], ["Cosmo", "Luca", ""], ["Melzi", "Simone", ""], ["Rodol\u00e0", "Emanuele", ""]]}, {"id": "2104.03361", "submitter": "Javier Gonzalez-Trejo", "authors": "Javier A. Gonz\\'alez-Trejo, Diego A. Mercado-Ravell", "title": "Monitoring Social-distance in Wide Areas during Pandemics: a Density Map\n  and Segmentation Approach", "comments": "Video: https://youtu.be/TwzBMKg7h_U", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the relaxation of the containment measurements around the globe,\nmonitoring the social distancing in crowded public places is of grate\nimportance to prevent a new massive wave of COVID-19 infections. Recent works\nin that matter have limited themselves by detecting social distancing in\ncorridors up to small crowds by detecting each person individually considering\nthe full body in the image. In this work, we propose a new framework for\nmonitoring the social-distance using end-to-end Deep Learning, to detect crowds\nviolating the social-distance in wide areas where important occlusions may be\npresent. Our framework consists in the creation of a new ground truth based on\nthe ground truth density maps and the proposal of two different solutions, a\ndensity-map-based and a segmentation-based, to detect the crowds violating the\nsocial-distance constrain. We assess the results of both approaches by using\nthe generated ground truth from the PET2009 and CityStreet datasets. We show\nthat our framework performs well at providing the zones where people are not\nfollowing the social-distance even when heavily occluded or far away from one\ncamera.\n", "versions": [{"version": "v1", "created": "Wed, 7 Apr 2021 19:26:26 GMT"}], "update_date": "2021-04-09", "authors_parsed": [["Gonz\u00e1lez-Trejo", "Javier A.", ""], ["Mercado-Ravell", "Diego A.", ""]]}, {"id": "2104.03403", "submitter": "Katarzyna P\\k{e}kala", "authors": "Katarzyna Pekala, Katarzyna Woznica, Przemyslaw Biecek", "title": "Triplot: model agnostic measures and visualisations for variable\n  importance in predictive models that take into account the hierarchical\n  correlation structure", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the key elements of explanatory analysis of a predictive model is to\nassess the importance of individual variables. Rapid development of the area of\npredictive model exploration (also called explainable artificial intelligence\nor interpretable machine learning) has led to the popularization of methods for\nlocal (instance level) and global (dataset level) methods, such as\nPermutational Variable Importance, Shapley Values (SHAP), Local Interpretable\nModel Explanations (LIME), Break Down and so on. However, these methods do not\nuse information about the correlation between features which significantly\nreduce the explainability of the model behaviour. In this work, we propose new\nmethods to support model analysis by exploiting the information about the\ncorrelation between variables. The dataset level aspect importance measure is\ninspired by the block permutations procedure, while the instance level aspect\nimportance measure is inspired by the LIME method. We show how to analyze\ngroups of variables (aspects) both when they are proposed by the user and when\nthey should be determined automatically based on the hierarchical structure of\ncorrelations between variables. Additionally, we present the new type of model\nvisualisation, triplot, which exploits a hierarchical structure of variable\ngrouping to produce a high information density model visualisation. This\nvisualisation provides a consistent illustration for either local or global\nmodel and data exploration. We also show an example of real-world data with 5k\ninstances and 37 features in which a significant correlation between variables\naffects the interpretation of the effect of variable importance. The proposed\nmethod is, to our knowledge, the first to allow direct use of the correlation\nbetween variables in exploratory model analysis.\n", "versions": [{"version": "v1", "created": "Wed, 7 Apr 2021 21:29:03 GMT"}], "update_date": "2021-04-09", "authors_parsed": [["Pekala", "Katarzyna", ""], ["Woznica", "Katarzyna", ""], ["Biecek", "Przemyslaw", ""]]}, {"id": "2104.03406", "submitter": "Nicholas Guttenberg", "authors": "Nicholas Guttenberg", "title": "Evolutionary rates of information gain and decay in fluctuating\n  environments", "comments": "7 pages, 4 figures, ALife 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.PE cs.IT cs.LG math.IT", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we wish to investigate the dynamics of information transfer in\nevolutionary dynamics. We use information theoretic tools to track how much\ninformation an evolving population has obtained and managed to retain about\ndifferent environments that it is exposed to. By understanding the dynamics of\ninformation gain and loss in a static environment, we predict how that same\nevolutionary system would behave when the environment is fluctuating.\nSpecifically, we anticipate a cross-over between the regime in which\nfluctuations improve the ability of the evolutionary system to capture\nenvironmental information and the regime in which the fluctuations inhibit it,\ngoverned by a cross-over in the timescales of information gain and decay.\n", "versions": [{"version": "v1", "created": "Wed, 7 Apr 2021 21:42:37 GMT"}], "update_date": "2021-04-09", "authors_parsed": [["Guttenberg", "Nicholas", ""]]}, {"id": "2104.03408", "submitter": "Tae Min Hong", "authors": "Tae Min Hong, Benjamin Carlson, Brandon Eubanks, Stephen Racz, Stephen\n  Roche, Joerg Stelzer, Daniel Stumpp", "title": "Nanosecond machine learning event classification with boosted decision\n  trees in FPGA for high energy physics", "comments": "65 pages, 27 figures, 13 tables", "journal-ref": null, "doi": null, "report-no": "PITT-PACC-2103", "categories": "hep-ex cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel implementation of classification using the machine\nlearning / artificial intelligence method called boosted decision trees (BDT)\non field programmable gate arrays (FPGA). The firmware implementation of binary\nclassification requiring 100 training trees with a maximum depth of 4 using\nfour input variables gives a latency value of about 10 ns, independent of the\nclock speed from 100 to 320 MHz in our setup. The low timing values are\nachieved by restructuring the BDT layout and reconfiguring its parameters. The\nFPGA resource utilization is also kept low at a range from 0.01% to 0.2% in our\nsetup. A software package called fwXmachina achieves this implementation. Our\nintended user is an expert of custom electronics-based trigger systems in high\nenergy physics experiments or anyone that needs decisions at the lowest latency\nvalues for real-time event classification. Two problems from high energy\nphysics are considered, in the separation of electrons vs. photons and in the\nselection of vector boson fusion-produced Higgs bosons vs. the rejection of the\nmultijet processes.\n", "versions": [{"version": "v1", "created": "Wed, 7 Apr 2021 21:46:42 GMT"}, {"version": "v2", "created": "Mon, 17 May 2021 21:52:58 GMT"}], "update_date": "2021-05-19", "authors_parsed": [["Hong", "Tae Min", ""], ["Carlson", "Benjamin", ""], ["Eubanks", "Brandon", ""], ["Racz", "Stephen", ""], ["Roche", "Stephen", ""], ["Stelzer", "Joerg", ""], ["Stumpp", "Daniel", ""]]}, {"id": "2104.03413", "submitter": "Yi Zeng", "authors": "Yi Zeng, Won Park, Z. Morley Mao and Ruoxi Jia", "title": "Rethinking the Backdoor Attacks' Triggers: A Frequency Perspective", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Backdoor attacks have been considered a severe security threat to deep\nlearning. Such attacks can make models perform abnormally on inputs with\npredefined triggers and still retain state-of-the-art performance on clean\ndata. While backdoor attacks have been thoroughly investigated in the image\ndomain from both attackers' and defenders' sides, an analysis in the frequency\ndomain has been missing thus far.\n  This paper first revisits existing backdoor triggers from a frequency\nperspective and performs a comprehensive analysis. Our results show that many\ncurrent backdoor attacks exhibit severe high-frequency artifacts, which persist\nacross different datasets and resolutions. We further demonstrate these\nhigh-frequency artifacts enable a simple way to detect existing backdoor\ntriggers at a detection rate of 98.50% without prior knowledge of the attack\ndetails and the target model. Acknowledging previous attacks' weaknesses, we\npropose a practical way to create smooth backdoor triggers without\nhigh-frequency artifacts and study their detectability. We show that existing\ndefense works can benefit by incorporating these smooth triggers into their\ndesign consideration. Moreover, we show that the detector tuned over stronger\nsmooth triggers can generalize well to unseen weak smooth triggers. In short,\nour work emphasizes the importance of considering frequency analysis when\ndesigning both backdoor attacks and defenses in deep learning.\n", "versions": [{"version": "v1", "created": "Wed, 7 Apr 2021 22:05:28 GMT"}, {"version": "v2", "created": "Fri, 9 Apr 2021 18:49:01 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Zeng", "Yi", ""], ["Park", "Won", ""], ["Mao", "Z. Morley", ""], ["Jia", "Ruoxi", ""]]}, {"id": "2104.03416", "submitter": "Edwin Ng", "authors": "Edwin G. Ng, Chung-Cheng Chiu, Yu Zhang, William Chan", "title": "Pushing the Limits of Non-Autoregressive Speech Recognition", "comments": "Accepted to Interspeech 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We combine recent advancements in end-to-end speech recognition to\nnon-autoregressive automatic speech recognition. We push the limits of\nnon-autoregressive state-of-the-art results for multiple datasets: LibriSpeech,\nFisher+Switchboard and Wall Street Journal. Key to our recipe, we leverage CTC\non giant Conformer neural network architectures with SpecAugment and wav2vec2\npre-training. We achieve 1.8%/3.6% WER on LibriSpeech test/test-other sets,\n5.1%/9.8% WER on Switchboard, and 3.4% on the Wall Street Journal, all without\na language model.\n", "versions": [{"version": "v1", "created": "Wed, 7 Apr 2021 22:17:20 GMT"}, {"version": "v2", "created": "Mon, 12 Apr 2021 15:09:29 GMT"}, {"version": "v3", "created": "Wed, 16 Jun 2021 19:17:11 GMT"}], "update_date": "2021-06-18", "authors_parsed": [["Ng", "Edwin G.", ""], ["Chiu", "Chung-Cheng", ""], ["Zhang", "Yu", ""], ["Chan", "William", ""]]}, {"id": "2104.03418", "submitter": "Parfait Atchade", "authors": "Parfait Atchade-Adelomou and Guillermo Alonso-Linaje", "title": "Quantum Enhanced Filter: QFilter", "comments": "8 pages, 10 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Convolutional Neural Networks (CNN) are used mainly to treat problems with\nmany images characteristic of Deep Learning. In this work, we propose a hybrid\nimage classification model to take advantage of quantum and classical\ncomputing. The method will use the potential that convolutional networks have\nshown in artificial intelligence by replacing classical filters with\nvariational quantum filters. Similarly, this work will compare with other\nclassification methods and the system's execution on different servers. The\nalgorithm's quantum feasibility is modelled and tested on Amazon Braket\nNotebook instances and experimented on the Pennylane's philosophy and\nframework.\n", "versions": [{"version": "v1", "created": "Wed, 7 Apr 2021 22:20:20 GMT"}], "update_date": "2021-04-10", "authors_parsed": [["Atchade-Adelomou", "Parfait", ""], ["Alonso-Linaje", "Guillermo", ""]]}, {"id": "2104.03428", "submitter": "Nima Salehi Sadghiani", "authors": "Lun Jiang, Nima Salehi Sadghiani, Zhuo Tao, Andrew Cohen", "title": "Generating Multi-type Temporal Sequences to Mitigate Class-imbalanced\n  Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  From the ad network standpoint, a user's activity is a multi-type sequence of\ntemporal events consisting of event types and time intervals. Understanding\nuser patterns in ad networks has received increasing attention from the machine\nlearning community. Particularly, the problems of fraud detection, Conversion\nRate (CVR), and Click-Through Rate (CTR) prediction are of interest. However,\nthe class imbalance between major and minor classes in these tasks can bias a\nmachine learning model leading to poor performance. This study proposes using\ntwo multi-type (continuous and discrete) training approaches for GANs to deal\nwith the limitations of traditional GANs in passing the gradient updates for\ndiscrete tokens. First, we used the Reinforcement Learning (RL)-based training\napproach and then, an approximation of the multinomial distribution\nparameterized in terms of the softmax function (Gumble-Softmax). Our extensive\nexperiments based on synthetic data have shown the trained generator can\ngenerate sequences with desired properties measured by multiple criteria.\n", "versions": [{"version": "v1", "created": "Wed, 7 Apr 2021 23:19:13 GMT"}, {"version": "v2", "created": "Thu, 22 Jul 2021 23:34:37 GMT"}], "update_date": "2021-07-26", "authors_parsed": [["Jiang", "Lun", ""], ["Sadghiani", "Nima Salehi", ""], ["Tao", "Zhuo", ""], ["Cohen", "Andrew", ""]]}, {"id": "2104.03438", "submitter": "Zi Wang", "authors": "Zi Wang, Chengcheng Li, Xiangyang Wang", "title": "Convolutional Neural Network Pruning with Structural Redundancy\n  Reduction", "comments": "Accepted to CVPR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Convolutional neural network (CNN) pruning has become one of the most\nsuccessful network compression approaches in recent years. Existing works on\nnetwork pruning usually focus on removing the least important filters in the\nnetwork to achieve compact architectures. In this study, we claim that\nidentifying structural redundancy plays a more essential role than finding\nunimportant filters, theoretically and empirically. We first statistically\nmodel the network pruning problem in a redundancy reduction perspective and\nfind that pruning in the layer(s) with the most structural redundancy\noutperforms pruning the least important filters across all layers. Based on\nthis finding, we then propose a network pruning approach that identifies\nstructural redundancy of a CNN and prunes filters in the selected layer(s) with\nthe most redundancy. Experiments on various benchmark network architectures and\ndatasets show that our proposed approach significantly outperforms the previous\nstate-of-the-art.\n", "versions": [{"version": "v1", "created": "Thu, 8 Apr 2021 00:16:24 GMT"}], "update_date": "2021-04-09", "authors_parsed": [["Wang", "Zi", ""], ["Li", "Chengcheng", ""], ["Wang", "Xiangyang", ""]]}, {"id": "2104.03439", "submitter": "Kshitij Bhardwaj", "authors": "Kshitij Bhardwaj and Maya Gokhale", "title": "Semi-supervised on-device neural network adaptation for remote and\n  portable laser-induced breakdown spectroscopy", "comments": "Accepted in On-Device Intelligence Workshop (held in conjunction with\n  MLSys Conference), 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP physics.optics", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Laser-induced breakdown spectroscopy (LIBS) is a popular, fast elemental\nanalysis technique used to determine the chemical composition of target\nsamples, such as in industrial analysis of metals or in space exploration.\nRecently, there has been a rise in the use of machine learning (ML) techniques\nfor LIBS data processing. However, ML for LIBS is challenging as: (i) the\npredictive models must be lightweight since they need to be deployed in highly\nresource-constrained and battery-operated portable LIBS systems; and (ii) since\nthese systems can be remote, the models must be able to self-adapt to any\ndomain shift in input distributions which could be due to the lack of different\ntypes of inputs in training data or dynamic environmental/sensor noise. This\non-device retraining of model should not only be fast but also unsupervised due\nto the absence of new labeled data in remote LIBS systems. We introduce a\nlightweight multi-layer perceptron (MLP) model for LIBS that can be adapted\non-device without requiring labels for new input data. It shows 89.3% average\naccuracy during data streaming, and up to 2.1% better accuracy compared to an\nMLP model that does not support adaptation. Finally, we also characterize the\ninference and retraining performance of our model on Google Pixel2 phone.\n", "versions": [{"version": "v1", "created": "Thu, 8 Apr 2021 00:20:36 GMT"}], "update_date": "2021-04-10", "authors_parsed": [["Bhardwaj", "Kshitij", ""], ["Gokhale", "Maya", ""]]}, {"id": "2104.03453", "submitter": "Chidera Biringa", "authors": "Chidera Biringa, Gokhan Kul", "title": "Automated User Experience Testing through Multi-Dimensional Performance\n  Impact Analysis", "comments": "4 pages, 2 figures, Proceedings of the ACM/IEEE 2nd International\n  Conference on Automation of Software Test", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Although there are many automated software testing suites, they usually focus\non unit, system, and interface testing. However, especially software updates\nsuch as new security features have the potential to diminish user experience.\nIn this paper, we propose a novel automated user experience testing methodology\nthat learns how code changes impact the time unit and system tests take, and\nextrapolate user experience changes based on this information. Such a tool can\nbe integrated into existing continuous integration pipelines, and it provides\nsoftware teams immediate user experience feedback. We construct a feature set\nfrom lexical, layout, and syntactic characteristics of the code, and using\nAbstract Syntax Tree-Based Embeddings, we can calculate the approximate\nsemantic distance to feed into a machine learning algorithm. In our\nexperiments, we use several regression methods to estimate the time impact of\nsoftware updates. Our open-source tool achieved 3.7% mean absolute error rate\nwith a random forest regressor.\n", "versions": [{"version": "v1", "created": "Thu, 8 Apr 2021 01:18:01 GMT"}], "update_date": "2021-04-09", "authors_parsed": [["Biringa", "Chidera", ""], ["Kul", "Gokhan", ""]]}, {"id": "2104.03466", "submitter": "Zekai Chen", "authors": "Zekai Chen, Dingshuo Chen, Xiao Zhang, Zixuan Yuan, Xiuzhen Cheng", "title": "Learning Graph Structures with Transformer for Multivariate Time Series\n  Anomaly Detection in IoT", "comments": "12 pages, 5 figures, Accepted by IEEE Internet of Things Journal 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many real-world IoT systems, which include a variety of internet-connected\nsensory devices, produce substantial amounts of multivariate time series data.\nMeanwhile, vital IoT infrastructures like smart power grids and water\ndistribution networks are frequently targeted by cyber-attacks, making anomaly\ndetection an important study topic. Modeling such relatedness is, nevertheless,\nunavoidable for any efficient and effective anomaly detection system, given the\nintricate topological and nonlinear connections that are originally unknown\namong sensors. Furthermore, detecting anomalies in multivariate time series is\ndifficult due to their temporal dependency and stochasticity. This paper\npresented GTA, a new framework for multivariate time series anomaly detection\nthat involves automatically learning a graph structure, graph convolution, and\nmodeling temporal dependency using a Transformer-based architecture. The\nconnection learning policy, which is based on the Gumbel-softmax sampling\napproach to learn bi-directed links among sensors directly, is at the heart of\nlearning graph structure. To describe the anomaly information flow between\nnetwork nodes, we introduced a new graph convolution called Influence\nPropagation convolution. In addition, to tackle the quadratic complexity\nbarrier, we suggested a multi-branch attention mechanism to replace the\noriginal multi-head self-attention method. Extensive experiments on four\npublicly available anomaly detection benchmarks further demonstrate the\nsuperiority of our approach over alternative state-of-the-arts.\n", "versions": [{"version": "v1", "created": "Thu, 8 Apr 2021 01:45:28 GMT"}, {"version": "v2", "created": "Fri, 23 Jul 2021 02:11:39 GMT"}], "update_date": "2021-07-26", "authors_parsed": [["Chen", "Zekai", ""], ["Chen", "Dingshuo", ""], ["Zhang", "Xiao", ""], ["Yuan", "Zixuan", ""], ["Cheng", "Xiuzhen", ""]]}, {"id": "2104.03469", "submitter": "Brian Quanz", "authors": "Yair Schiff, Brian Quanz, Payel Das, Pin-Yu Chen", "title": "Gi and Pal Scores: Deep Neural Network Generalization Statistics", "comments": "Accepted to RobustML Workshop at ICLR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The field of Deep Learning is rich with empirical evidence of human-like\nperformance on a variety of regression, classification, and control tasks.\nHowever, despite these successes, the field lacks strong theoretical error\nbounds and consistent measures of network generalization and learned\ninvariances. In this work, we introduce two new measures, the Gi-score and\nPal-score, that capture a deep neural network's generalization capabilities.\nInspired by the Gini coefficient and Palma ratio, measures of income\ninequality, our statistics are robust measures of a network's invariance to\nperturbations that accurately predict generalization gaps, i.e., the difference\nbetween accuracy on training and test sets.\n", "versions": [{"version": "v1", "created": "Thu, 8 Apr 2021 01:52:49 GMT"}, {"version": "v2", "created": "Thu, 10 Jun 2021 00:14:47 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["Schiff", "Yair", ""], ["Quanz", "Brian", ""], ["Das", "Payel", ""], ["Chen", "Pin-Yu", ""]]}, {"id": "2104.03490", "submitter": "Xin Fan", "authors": "Xin Fan, Yue Wang, Yan Huo, and Zhi Tian", "title": "Joint Optimization of Communications and Federated Learning Over the Air", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning (FL) is an attractive paradigm for making use of rich\ndistributed data while protecting data privacy. Nonetheless, nonideal\ncommunication links and limited transmission resources have become the\nbottleneck of the implementation of fast and accurate FL. In this paper, we\nstudy joint optimization of communications and FL based on analog aggregation\ntransmission in realistic wireless networks. We first derive a closed-form\nexpression for the expected convergence rate of FL over the air, which\ntheoretically quantifies the impact of analog aggregation on FL. Based on the\nanalytical result, we develop a joint optimization model for accurate FL\nimplementation, which allows a parameter server to select a subset of workers\nand determine an appropriate power scaling factor. Since the practical setting\nof FL over the air encounters unobservable parameters, we reformulate the joint\noptimization of worker selection and power allocation using controlled\napproximation. Finally, we efficiently solve the resulting mixed-integer\nprogramming problem via a simple yet optimal finite-set search method by\nreducing the search space. Simulation results show that the proposed solutions\ndeveloped for realistic wireless analog channels outperform a benchmark method,\nand achieve comparable performance of the ideal case where FL is implemented\nover noise-free wireless channels.\n", "versions": [{"version": "v1", "created": "Thu, 8 Apr 2021 03:38:31 GMT"}], "update_date": "2021-04-09", "authors_parsed": [["Fan", "Xin", ""], ["Wang", "Yue", ""], ["Huo", "Yan", ""], ["Tian", "Zhi", ""]]}, {"id": "2104.03496", "submitter": "Elliott Skomski", "authors": "Elliott Skomski, Aaron Tuor, Andrew Avila, Lauren Phillips, Zachary\n  New, Henry Kvinge, Courtney D. Corley, and Nathan Hodas", "title": "Prototypical Region Proposal Networks for Few-Shot Localization and\n  Classification", "comments": "9 pages, 1 figure. Submitted to 4th Workshop on Meta-Learning at\n  NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently proposed few-shot image classification methods have generally\nfocused on use cases where the objects to be classified are the central subject\nof images. Despite success on benchmark vision datasets aligned with this use\ncase, these methods typically fail on use cases involving densely-annotated,\nbusy images: images common in the wild where objects of relevance are not the\ncentral subject, instead appearing potentially occluded, small, or among other\nincidental objects belonging to other classes of potential interest. To\nlocalize relevant objects, we employ a prototype-based few-shot segmentation\nmodel which compares the encoded features of unlabeled query images with\nsupport class centroids to produce region proposals indicating the presence and\nlocation of support set classes in a query image. These region proposals are\nthen used as additional conditioning input to few-shot image classifiers. We\ndevelop a framework to unify the two stages (segmentation and classification)\ninto an end-to-end classification model -- PRoPnet -- and empirically\ndemonstrate that our methods improve accuracy on image datasets with natural\nscenes containing multiple object classes.\n", "versions": [{"version": "v1", "created": "Thu, 8 Apr 2021 04:03:30 GMT"}], "update_date": "2021-04-09", "authors_parsed": [["Skomski", "Elliott", ""], ["Tuor", "Aaron", ""], ["Avila", "Andrew", ""], ["Phillips", "Lauren", ""], ["New", "Zachary", ""], ["Kvinge", "Henry", ""], ["Corley", "Courtney D.", ""], ["Hodas", "Nathan", ""]]}, {"id": "2104.03502", "submitter": "Leonardo Pepino", "authors": "Leonardo Pepino, Pablo Riera, Luciana Ferrer", "title": "Emotion Recognition from Speech Using Wav2vec 2.0 Embeddings", "comments": "5 pages, 2 figures. Submitted to Interspeech 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Emotion recognition datasets are relatively small, making the use of the more\nsophisticated deep learning approaches challenging. In this work, we propose a\ntransfer learning method for speech emotion recognition where features\nextracted from pre-trained wav2vec 2.0 models are modeled using simple neural\nnetworks. We propose to combine the output of several layers from the\npre-trained model using trainable weights which are learned jointly with the\ndownstream model. Further, we compare performance using two different wav2vec\n2.0 models, with and without finetuning for speech recognition. We evaluate our\nproposed approaches on two standard emotion databases IEMOCAP and RAVDESS,\nshowing superior performance compared to results in the literature.\n", "versions": [{"version": "v1", "created": "Thu, 8 Apr 2021 04:31:58 GMT"}], "update_date": "2021-04-09", "authors_parsed": [["Pepino", "Leonardo", ""], ["Riera", "Pablo", ""], ["Ferrer", "Luciana", ""]]}, {"id": "2104.03503", "submitter": "Zhiwei Xu", "authors": "Zhiwei Xu, Bin Zhang, Yunpeng Bai, Dapeng Li, Guoliang Fan", "title": "Learning to Coordinate via Multiple Graph Neural Networks", "comments": "12 pages, 4 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The collaboration between agents has gradually become an important topic in\nmulti-agent systems. The key is how to efficiently solve the credit assignment\nproblems. This paper introduces MGAN for collaborative multi-agent\nreinforcement learning, a new algorithm that combines graph convolutional\nnetworks and value-decomposition methods. MGAN learns the representation of\nagents from different perspectives through multiple graph networks, and\nrealizes the proper allocation of attention between all agents. We show the\namazing ability of the graph network in representation learning by visualizing\nthe output of the graph network, and therefore improve interpretability for the\nactions of each agent in the multi-agent system.\n", "versions": [{"version": "v1", "created": "Thu, 8 Apr 2021 04:33:00 GMT"}], "update_date": "2021-05-14", "authors_parsed": [["Xu", "Zhiwei", ""], ["Zhang", "Bin", ""], ["Bai", "Yunpeng", ""], ["Li", "Dapeng", ""], ["Fan", "Guoliang", ""]]}, {"id": "2104.03506", "submitter": "Yakoob Khan", "authors": "Yakoob Khan, Weicheng Ma, Soroush Vosoughi", "title": "Lone Pine at SemEval-2021 Task 5: Fine-Grained Detection of Hate Speech\n  Using BERToxic", "comments": "7 pages, 3 figures. Accepted at SemEval-2021 Workshop, ACL-IJCNLP\n  2021", "journal-ref": null, "doi": "10.18653/v1/2021.semeval-1.132", "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper describes our approach to the Toxic Spans Detection problem\n(SemEval-2021 Task 5). We propose BERToxic, a system that fine-tunes a\npre-trained BERT model to locate toxic text spans in a given text and utilizes\nadditional post-processing steps to refine the boundaries. The post-processing\nsteps involve (1) labeling character offsets between consecutive toxic tokens\nas toxic and (2) assigning a toxic label to words that have at least one token\nlabeled as toxic. Through experiments, we show that these two post-processing\nsteps improve the performance of our model by 4.16% on the test set. We also\nstudied the effects of data augmentation and ensemble modeling strategies on\nour system. Our system significantly outperformed the provided baseline and\nachieved an F1-score of 0.683, placing Lone Pine in the 17th place out of 91\nteams in the competition. Our code is made available at\nhttps://github.com/Yakoob-Khan/Toxic-Spans-Detection\n", "versions": [{"version": "v1", "created": "Thu, 8 Apr 2021 04:46:14 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Khan", "Yakoob", ""], ["Ma", "Weicheng", ""], ["Vosoughi", "Soroush", ""]]}, {"id": "2104.03509", "submitter": "Jin Hyun Cheong", "authors": "Jin Hyun Cheong, Tiankang Xie, Sophie Byrne, Luke J. Chang", "title": "Py-Feat: Python Facial Expression Analysis Toolbox", "comments": "25 pages, 3 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Studying facial expressions is a notoriously difficult endeavor. Recent\nadvances in the field of affective computing have yielded impressive progress\nin automatically detecting facial expressions from pictures and videos.\nHowever, much of this work has yet to be widely disseminated in social science\ndomains such as psychology. Current state of the art models require\nconsiderable domain expertise that is not traditionally incorporated into\nsocial science training programs. Furthermore, there is a notable absence of\nuser-friendly and open-source software that provides a comprehensive set of\ntools and functions that support facial expression research. In this paper, we\nintroduce Py-Feat, an open-source Python toolbox that provides support for\ndetecting, preprocessing, analyzing, and visualizing facial expression data.\nPy-Feat makes it easy for domain experts to disseminate and benchmark computer\nvision models and also for end users to quickly process, analyze, and visualize\nface expression data. We hope this platform will facilitate increased use of\nfacial expression data in human behavior research.\n", "versions": [{"version": "v1", "created": "Thu, 8 Apr 2021 04:52:21 GMT"}], "update_date": "2021-04-09", "authors_parsed": [["Cheong", "Jin Hyun", ""], ["Xie", "Tiankang", ""], ["Byrne", "Sophie", ""], ["Chang", "Luke J.", ""]]}, {"id": "2104.03525", "submitter": "Seo Taek Kong", "authors": "Seo Taek Kong, Soomin Jeon, Jaewon Lee, Hongseok Lee, Kyu-Hwan Jung", "title": "Relieving the Plateau: Active Semi-Supervised Learning for a Better\n  Landscape", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning (DL) relies on massive amounts of labeled data, and improving\nits labeled sample-efficiency remains one of the most important problems since\nits advent. Semi-supervised learning (SSL) leverages unlabeled data that are\nmore accessible than their labeled counterparts. Active learning (AL) selects\nunlabeled instances to be annotated by a human-in-the-loop in hopes of better\nperformance with less labeled data. Given the accessible pool of unlabeled data\nin pool-based AL, it seems natural to use SSL when training and AL to update\nthe labeled set; however, algorithms designed for their combination remain\nlimited. In this work, we first prove that convergence of gradient descent on\nsufficiently wide ReLU networks can be expressed in terms of their Gram matrix'\neigen-spectrum. Equipped with a few theoretical insights, we propose\nconvergence rate control (CRC), an AL algorithm that selects unlabeled data to\nimprove the problem conditioning upon inclusion to the labeled set, by\nformulating an acquisition step in terms of improving training dynamics.\nExtensive experiments show that SSL algorithms coupled with CRC can achieve\nhigh performance using very few labeled data.\n", "versions": [{"version": "v1", "created": "Thu, 8 Apr 2021 06:03:59 GMT"}], "update_date": "2021-04-09", "authors_parsed": [["Kong", "Seo Taek", ""], ["Jeon", "Soomin", ""], ["Lee", "Jaewon", ""], ["Lee", "Hongseok", ""], ["Jung", "Kyu-Hwan", ""]]}, {"id": "2104.03527", "submitter": "Kayhan Behdin", "authors": "Kayhan Behdin and Rahul Mazumder", "title": "Archetypal Analysis for Sparse Nonnegative Matrix Factorization:\n  Robustness Under Misspecification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of sparse nonnegative matrix factorization (NMF) with\narchetypal regularization. The goal is to represent a collection of data points\nas nonnegative linear combinations of a few nonnegative sparse factors with\nappealing geometric properties, arising from the use of archetypal\nregularization. We generalize the notion of robustness studied in Javadi and\nMontanari (2019) (without sparsity) to the notions of (a) strong robustness\nthat implies each estimated archetype is close to the underlying archetypes and\n(b) weak robustness that implies there exists at least one recovered archetype\nthat is close to the underlying archetypes. Our theoretical results on\nrobustness guarantees hold under minimal assumptions on the underlying data,\nand applies to settings where the underlying archetypes need not be sparse. We\npropose new algorithms for our optimization problem; and present numerical\nexperiments on synthetic and real datasets that shed further insights into our\nproposed framework and theoretical developments.\n", "versions": [{"version": "v1", "created": "Thu, 8 Apr 2021 06:06:48 GMT"}], "update_date": "2021-04-09", "authors_parsed": [["Behdin", "Kayhan", ""], ["Mazumder", "Rahul", ""]]}, {"id": "2104.03528", "submitter": "Oleksandr Shchur", "authors": "Oleksandr Shchur, Ali Caner T\\\"urkmen, Tim Januschowski, Stephan\n  G\\\"unnemann", "title": "Neural Temporal Point Processes: A Review", "comments": "International Joint Conference on Artificial Intelligence (IJCAI)\n  2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Temporal point processes (TPP) are probabilistic generative models for\ncontinuous-time event sequences. Neural TPPs combine the fundamental ideas from\npoint process literature with deep learning approaches, thus enabling\nconstruction of flexible and efficient models. The topic of neural TPPs has\nattracted significant attention in the recent years, leading to the development\nof numerous new architectures and applications for this class of models. In\nthis review paper we aim to consolidate the existing body of knowledge on\nneural TPPs. Specifically, we focus on important design choices and general\nprinciples for defining neural TPP models. Next, we provide an overview of\napplication areas commonly considered in the literature. We conclude this\nsurvey with the list of open challenges and important directions for future\nwork in the field of neural TPPs.\n", "versions": [{"version": "v1", "created": "Thu, 8 Apr 2021 06:10:50 GMT"}, {"version": "v2", "created": "Wed, 21 Apr 2021 15:40:50 GMT"}, {"version": "v3", "created": "Tue, 27 Apr 2021 19:59:30 GMT"}, {"version": "v4", "created": "Fri, 7 May 2021 18:35:19 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Shchur", "Oleksandr", ""], ["T\u00fcrkmen", "Ali Caner", ""], ["Januschowski", "Tim", ""], ["G\u00fcnnemann", "Stephan", ""]]}, {"id": "2104.03531", "submitter": "Zhao Kang", "authors": "Juncheng Lv and Zhao Kang and Xiao Lu and Zenglin Xu", "title": "Pseudo-supervised Deep Subspace Clustering", "comments": null, "journal-ref": "IEEE Transactions on Image Processing 2021", "doi": "10.1109/TIP.2021.3079800", "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Auto-Encoder (AE)-based deep subspace clustering (DSC) methods have achieved\nimpressive performance due to the powerful representation extracted using deep\nneural networks while prioritizing categorical separability. However,\nself-reconstruction loss of an AE ignores rich useful relation information and\nmight lead to indiscriminative representation, which inevitably degrades the\nclustering performance. It is also challenging to learn high-level similarity\nwithout feeding semantic labels. Another unsolved problem facing DSC is the\nhuge memory cost due to $n\\times n$ similarity matrix, which is incurred by the\nself-expression layer between an encoder and decoder. To tackle these problems,\nwe use pairwise similarity to weigh the reconstruction loss to capture local\nstructure information, while a similarity is learned by the self-expression\nlayer. Pseudo-graphs and pseudo-labels, which allow benefiting from uncertain\nknowledge acquired during network training, are further employed to supervise\nsimilarity learning. Joint learning and iterative training facilitate to obtain\nan overall optimal solution. Extensive experiments on benchmark datasets\ndemonstrate the superiority of our approach. By combining with the $k$-nearest\nneighbors algorithm, we further show that our method can address the\nlarge-scale and out-of-sample problems.\n", "versions": [{"version": "v1", "created": "Thu, 8 Apr 2021 06:25:47 GMT"}], "update_date": "2021-05-17", "authors_parsed": [["Lv", "Juncheng", ""], ["Kang", "Zhao", ""], ["Lu", "Xiao", ""], ["Xu", "Zenglin", ""]]}, {"id": "2104.03535", "submitter": "Makoto Takamoto", "authors": "Makoto Takamoto and Yusuke Morishita", "title": "An Empirical Study of the Effects of Sample-Mixing Methods for Efficient\n  Training of Generative Adversarial Networks", "comments": "draft version, accepted by IEEE 4th International Conference on\n  Multimedia Information Processing and Retrieval (IEEE MIPR 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  It is well-known that training of generative adversarial networks (GANs)\nrequires huge iterations before the generator's providing good-quality samples.\nAlthough there are several studies to tackle this problem, there is still no\nuniversal solution. In this paper, we investigated the effect of sample mixing\nmethods, that is, Mixup, CutMix, and newly proposed Smoothed Regional Mix\n(SRMix), to alleviate this problem. The sample-mixing methods are known to\nenhance the accuracy and robustness in the wide range of classification\nproblems, and can naturally be applicable to GANs because the role of the\ndiscriminator can be interpreted as the classification between real and fake\nsamples. We also proposed a new formalism applying the sample-mixing methods to\nGANs with the saturated losses which do not have a clear \"label\" of real and\nfake. We performed a vast amount of numerical experiments using LSUN and CelebA\ndatasets. The results showed that Mixup and SRMix improved the quality of the\ngenerated images in terms of FID in most cases, in particular, SRMix showed the\nbest improvement in most cases. Our analysis indicates that the mixed-samples\ncan provide different properties from the vanilla fake samples, and the mixing\npattern strongly affects the decision of the discriminators. The generated\nimages of Mixup have good high-level feature but low-level feature is not so\nimpressible. On the other hand, CutMix showed the opposite tendency. Our SRMix\nshowed the middle tendency, that is, showed good high and low level features.\nWe believe that our finding provides a new perspective to accelerate the GANs\nconvergence and improve the quality of generated samples.\n", "versions": [{"version": "v1", "created": "Thu, 8 Apr 2021 06:40:23 GMT"}], "update_date": "2021-04-09", "authors_parsed": [["Takamoto", "Makoto", ""], ["Morishita", "Yusuke", ""]]}, {"id": "2104.03546", "submitter": "Pieter Ghysels", "authors": "Alice Gatti, Zhixiong Hu, Tess Smidt, Esmond G. Ng, Pieter Ghysels", "title": "Graph Partitioning and Sparse Matrix Ordering using Reinforcement\n  Learning and Graph Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel method for graph partitioning, based on reinforcement\nlearning and graph convolutional neural networks. Our approach is to\nrecursively partition coarser representations of a given graph. The neural\nnetwork is implemented using SAGE graph convolution layers, and trained using\nan advantage actor critic (A2C) agent. We present two variants, one for finding\nan edge separator that minimizes the normalized cut or quotient cut, and one\nthat finds a small vertex separator. The vertex separators are then used to\nconstruct a nested dissection ordering to permute a sparse matrix so that its\ntriangular factorization will incur less fill-in. The partitioning quality is\ncompared with partitions obtained using METIS and SCOTCH, and the nested\ndissection ordering is evaluated in the sparse solver SuperLU. Our results show\nthat the proposed method achieves similar partitioning quality as METIS and\nSCOTCH. Furthermore, the method generalizes across different classes of graphs,\nand works well on a variety of graphs from the SuiteSparse sparse matrix\ncollection.\n", "versions": [{"version": "v1", "created": "Thu, 8 Apr 2021 06:54:24 GMT"}, {"version": "v2", "created": "Mon, 28 Jun 2021 18:03:45 GMT"}], "update_date": "2021-06-30", "authors_parsed": [["Gatti", "Alice", ""], ["Hu", "Zhixiong", ""], ["Smidt", "Tess", ""], ["Ng", "Esmond G.", ""], ["Ghysels", "Pieter", ""]]}, {"id": "2104.03549", "submitter": "Maleeha Khalid Khan", "authors": "Maleeha Khalid Khan (1) Syed Muhammad Anwar (2)", "title": "M-Net with Bidirectional ConvLSTM for Cup and Disc Segmentation in\n  Fundus Images", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Glaucoma is a severe eye disease that is known to deteriorate optic never\nfibers, causing cup size to increase, which could result in permanent loss of\nvision. Glaucoma is the second leading cause of blindness after cataract, but\nglaucoma being more dangerous as it is not curable. Early diagnoses and\ntreatment of glaucoma can help to slow the progression of glaucoma and its\ndamages. For the detection of glaucoma, the Cup to Disc ratio (CDR) provides\nsignificant information. The CDR depends heavily on the accurate segmentation\nof cup and disc regions. In this paper, we have proposed a modified M-Net with\nbidirectional convolution long short-term memory (LSTM), based on joint cup and\ndisc segmentation. The proposed network combines features of encoder and\ndecoder, with bidirectional LSTM. Our proposed model segments cup and disc\nregions based on which the abnormalities in cup to disc ratio can be observed.\nThe proposed model is tested on REFUGE2 data, where our model achieves a dice\nscore of 0.92 for optic disc and an accuracy of 98.99% in segmenting cup and\ndisc regions\n", "versions": [{"version": "v1", "created": "Thu, 8 Apr 2021 07:01:42 GMT"}], "update_date": "2021-04-09", "authors_parsed": [["Khan", "Maleeha Khalid", ""], ["Anwar", "Syed Muhammad", ""]]}, {"id": "2104.03562", "submitter": "Sebastian Peitz", "authors": "Michael Dellnitz and Eyke H\\\"ullermeier and Marvin L\\\"ucke and Sina\n  Ober-Bl\\\"obaum and Christian Offen and Sebastian Peitz and Karlson\n  Pfannschmidt", "title": "Efficient time stepping for numerical integration using reinforcement\n  learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.DS cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Many problems in science and engineering require the efficient numerical\napproximation of integrals, a particularly important application being the\nnumerical solution of initial value problems for differential equations. For\ncomplex systems, an equidistant discretization is often inadvisable, as it\neither results in prohibitively large errors or computational effort. To this\nend, adaptive schemes have been developed that rely on error estimators based\non Taylor series expansions. While these estimators a) rely on strong\nsmoothness assumptions and b) may still result in erroneous steps for complex\nsystems (and thus require step rejection mechanisms), we here propose a\ndata-driven time stepping scheme based on machine learning, and more\nspecifically on reinforcement learning (RL) and meta-learning. First, one or\nseveral (in the case of non-smooth or hybrid systems) base learners are trained\nusing RL. Then, a meta-learner is trained which (depending on the system state)\nselects the base learner that appears to be optimal for the current situation.\nSeveral examples including both smooth and non-smooth problems demonstrate the\nsuperior performance of our approach over state-of-the-art numerical schemes.\nThe code is available under https://github.com/lueckem/quadrature-ML.\n", "versions": [{"version": "v1", "created": "Thu, 8 Apr 2021 07:24:54 GMT"}], "update_date": "2021-04-09", "authors_parsed": [["Dellnitz", "Michael", ""], ["H\u00fcllermeier", "Eyke", ""], ["L\u00fccke", "Marvin", ""], ["Ober-Bl\u00f6baum", "Sina", ""], ["Offen", "Christian", ""], ["Peitz", "Sebastian", ""], ["Pfannschmidt", "Karlson", ""]]}, {"id": "2104.03583", "submitter": "Yuli Jiang", "authors": "Yuli Jiang, Yu Rong, Hong Cheng, Xin Huang, Kangfei Zhao, Junzhou\n  Huang", "title": "QD-GCN: Query-Driven Graph Convolutional Networks for Attributed\n  Community Search", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, attributed community search, a related but different problem to\ncommunity detection and graph clustering, has been widely studied in the\nliterature. Compared with the community detection that finds all existing\nstatic communities from a graph, the attributed community search (ACS) is more\nchallenging since it aims to find dynamic communities with both cohesive\nstructures and homogeneous node attributes given arbitrary queries. To solve\nthe ACS problem, the most popular paradigm is to simplify the problem as two\nsub-problems, that is, structural matching and attribute filtering and deal\nwith them separately. However, in real-world graphs, the community structure\nand the node attributes are actually correlated to each other. In this vein,\ncurrent studies cannot capture these correlations which are vital for the ACS\nproblem.\n  In this paper, we propose Query-Driven Graph Convolutional Networks (QD-GCN),\nan end-to-end framework that unifies the community structure as well as node\nattribute to solve the ACS problem. In particular, QD-GCN leverages the Graph\nConvolutional Networks, which is a powerful tool to encode the graph topology\nand node attributes concurrently, as the backbones to extract the\nquery-dependent community information from the original graph. By utilizing\nthis query-dependent community information, QD-GCN is able to predict the\ntarget community given any queries. Experiments on real-world graphs with\nground-truth communities demonstrate that QD-GCN outperforms existing\nattributed community search algorithms in terms of both efficiency and\neffectiveness.\n", "versions": [{"version": "v1", "created": "Thu, 8 Apr 2021 07:52:48 GMT"}], "update_date": "2021-04-09", "authors_parsed": [["Jiang", "Yuli", ""], ["Rong", "Yu", ""], ["Cheng", "Hong", ""], ["Huang", "Xin", ""], ["Zhao", "Kangfei", ""], ["Huang", "Junzhou", ""]]}, {"id": "2104.03584", "submitter": "Zhengyang Shen", "authors": "Zhengyang Shen, Tiancheng Shen, Zhouchen Lin, Jinwen Ma", "title": "PDO-e$\\text{S}^\\text{2}$CNNs: Partial Differential Operator Based\n  Equivariant Spherical CNNs", "comments": "Accepted by AAAI2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spherical signals exist in many applications, e.g., planetary data, LiDAR\nscans and digitalization of 3D objects, calling for models that can process\nspherical data effectively. It does not perform well when simply projecting\nspherical data into the 2D plane and then using planar convolution neural\nnetworks (CNNs), because of the distortion from projection and ineffective\ntranslation equivariance. Actually, good principles of designing spherical CNNs\nare avoiding distortions and converting the shift equivariance property in\nplanar CNNs to rotation equivariance in the spherical domain. In this work, we\nuse partial differential operators (PDOs) to design a spherical equivariant\nCNN, PDO-e$\\text{S}^\\text{2}$CNN, which is exactly rotation equivariant in the\ncontinuous domain. We then discretize PDO-e$\\text{S}^\\text{2}$CNNs, and analyze\nthe equivariance error resulted from discretization. This is the first time\nthat the equivariance error is theoretically analyzed in the spherical domain.\nIn experiments, PDO-e$\\text{S}^\\text{2}$CNNs show greater parameter efficiency\nand outperform other spherical CNNs significantly on several tasks.\n", "versions": [{"version": "v1", "created": "Thu, 8 Apr 2021 07:54:50 GMT"}], "update_date": "2021-04-09", "authors_parsed": [["Shen", "Zhengyang", ""], ["Shen", "Tiancheng", ""], ["Lin", "Zhouchen", ""], ["Ma", "Jinwen", ""]]}, {"id": "2104.03597", "submitter": "Mahsa Ghorbani", "authors": "Mahsa Ghorbani, Mojtaba Bahrami, Anees Kazi, Mahdieh\n  SoleymaniBaghshah, Hamid R. Rabiee, and Nassir Navab", "title": "GKD: Semi-supervised Graph Knowledge Distillation for Graph-Independent\n  Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The increased amount of multi-modal medical data has opened the opportunities\nto simultaneously process various modalities such as imaging and non-imaging\ndata to gain a comprehensive insight into the disease prediction domain. Recent\nstudies using Graph Convolutional Networks (GCNs) provide novel semi-supervised\napproaches for integrating heterogeneous modalities while investigating the\npatients' associations for disease prediction. However, when the meta-data used\nfor graph construction is not available at inference time (e.g., coming from a\ndistinct population), the conventional methods exhibit poor performance. To\naddress this issue, we propose a novel semi-supervised approach named GKD based\non knowledge distillation. We train a teacher component that employs the\nlabel-propagation algorithm besides a deep neural network to benefit from the\ngraph and non-graph modalities only in the training phase. The teacher\ncomponent embeds all the available information into the soft pseudo-labels. The\nsoft pseudo-labels are then used to train a deep student network for disease\nprediction of unseen test data for which the graph modality is unavailable. We\nperform our experiments on two public datasets for diagnosing Autism spectrum\ndisorder, and Alzheimer's disease, along with a thorough analysis on synthetic\nmulti-modal datasets. According to these experiments, GKD outperforms the\nprevious graph-based deep learning methods in terms of accuracy, AUC, and Macro\nF1.\n", "versions": [{"version": "v1", "created": "Thu, 8 Apr 2021 08:23:37 GMT"}], "update_date": "2021-04-09", "authors_parsed": [["Ghorbani", "Mahsa", ""], ["Bahrami", "Mojtaba", ""], ["Kazi", "Anees", ""], ["SoleymaniBaghshah", "Mahdieh", ""], ["Rabiee", "Hamid R.", ""], ["Navab", "Nassir", ""]]}, {"id": "2104.03602", "submitter": "Sara Atito", "authors": "Sara Atito and Muhammad Awais and Josef Kittler", "title": "SiT: Self-supervised vIsion Transformer", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Self-supervised learning methods are gaining increasing traction in computer\nvision due to their recent success in reducing the gap with supervised\nlearning. In natural language processing (NLP) self-supervised learning and\ntransformers are already the methods of choice. The recent literature suggests\nthat the transformers are becoming increasingly popular also in computer\nvision. So far, the vision transformers have been shown to work well when\npretrained either using a large scale supervised data or with some kind of\nco-supervision, e.g. in terms of teacher network. These supervised pretrained\nvision transformers achieve very good results in downstream tasks with minimal\nchanges. In this work we investigate the merits of self-supervised learning for\npretraining image/vision transformers and then using them for downstream\nclassification tasks. We propose Self-supervised vIsion Transformers (SiT) and\ndiscuss several self-supervised training mechanisms to obtain a pretext model.\nThe architectural flexibility of SiT allows us to use it as an autoencoder and\nwork with multiple self-supervised tasks seamlessly. We show that a pretrained\nSiT can be finetuned for a downstream classification task on small scale\ndatasets, consisting of a few thousand images rather than several millions. The\nproposed approach is evaluated on standard datasets using common protocols. The\nresults demonstrate the strength of the transformers and their suitability for\nself-supervised learning. We outperformed existing self-supervised learning\nmethods by large margin. We also observed that SiT is good for few shot\nlearning and also showed that it is learning useful representation by simply\ntraining a linear classifier on top of the learned features from SiT.\nPretraining, finetuning, and evaluation codes will be available under:\nhttps://github.com/Sara-Ahmed/SiT.\n", "versions": [{"version": "v1", "created": "Thu, 8 Apr 2021 08:34:04 GMT"}], "update_date": "2021-04-09", "authors_parsed": [["Atito", "Sara", ""], ["Awais", "Muhammad", ""], ["Kittler", "Josef", ""]]}, {"id": "2104.03613", "submitter": "Luca Biggio", "authors": "Luca Biggio, Alexander Wieland, Manuel Arias Chao, Iason Kastanis,\n  Olga Fink", "title": "Uncertainty-aware Remaining Useful Life predictor", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.AP", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Remaining Useful Life (RUL) estimation is the problem of inferring how long a\ncertain industrial asset can be expected to operate within its defined\nspecifications. Deploying successful RUL prediction methods in real-life\napplications is a prerequisite for the design of intelligent maintenance\nstrategies with the potential of drastically reducing maintenance costs and\nmachine downtimes. In light of their superior performance in a wide range of\nengineering fields, Machine Learning (ML) algorithms are natural candidates to\ntackle the challenges involved in the design of intelligent maintenance\nsystems. In particular, given the potentially catastrophic consequences or\nsubstantial costs associated with maintenance decisions that are either too\nlate or too early, it is desirable that ML algorithms provide uncertainty\nestimates alongside their predictions. However, standard data-driven methods\nused for uncertainty estimation in RUL problems do not scale well to large\ndatasets or are not sufficiently expressive to model the high-dimensional\nmapping from raw sensor data to RUL estimates. In this work, we consider Deep\nGaussian Processes (DGPs) as possible solutions to the aforementioned\nlimitations. We perform a thorough evaluation and comparison of several\nvariants of DGPs applied to RUL predictions. The performance of the algorithms\nis evaluated on the N-CMAPSS (New Commercial Modular Aero-Propulsion System\nSimulation) dataset from NASA for aircraft engines. The results show that the\nproposed methods are able to provide very accurate RUL predictions along with\nsensible uncertainty estimates, providing more reliable solutions for\n(safety-critical) real-life industrial applications.\n", "versions": [{"version": "v1", "created": "Thu, 8 Apr 2021 08:50:44 GMT"}], "update_date": "2021-04-09", "authors_parsed": [["Biggio", "Luca", ""], ["Wieland", "Alexander", ""], ["Chao", "Manuel Arias", ""], ["Kastanis", "Iason", ""], ["Fink", "Olga", ""]]}, {"id": "2104.03620", "submitter": "Yang Shu", "authors": "Yang Shu, Zhangjie Cao, Chenyu Wang, Jianmin Wang, Mingsheng Long", "title": "Open Domain Generalization with Domain-Augmented Meta-Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Leveraging datasets available to learn a model with high generalization\nability to unseen domains is important for computer vision, especially when the\nunseen domain's annotated data are unavailable. We study a novel and practical\nproblem of Open Domain Generalization (OpenDG), which learns from different\nsource domains to achieve high performance on an unknown target domain, where\nthe distributions and label sets of each individual source domain and the\ntarget domain can be different. The problem can be generally applied to diverse\nsource domains and widely applicable to real-world applications. We propose a\nDomain-Augmented Meta-Learning framework to learn open-domain generalizable\nrepresentations. We augment domains on both feature-level by a new Dirichlet\nmixup and label-level by distilled soft-labeling, which complements each domain\nwith missing classes and other domain knowledge. We conduct meta-learning over\ndomains by designing new meta-learning tasks and losses to preserve domain\nunique knowledge and generalize knowledge across domains simultaneously.\nExperiment results on various multi-domain datasets demonstrate that the\nproposed Domain-Augmented Meta-Learning (DAML) outperforms prior methods for\nunseen domain recognition.\n", "versions": [{"version": "v1", "created": "Thu, 8 Apr 2021 09:12:24 GMT"}], "update_date": "2021-04-09", "authors_parsed": [["Shu", "Yang", ""], ["Cao", "Zhangjie", ""], ["Wang", "Chenyu", ""], ["Wang", "Jianmin", ""], ["Long", "Mingsheng", ""]]}, {"id": "2104.03624", "submitter": "Kurt Willis", "authors": "Kurt Willis, Luis Oala", "title": "Post-Hoc Domain Adaptation via Guided Data Homogenization", "comments": "Published as a conference paper at ICLR 2021; 4 pages, plus appendix,\n  5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Addressing shifts in data distributions is an important prerequisite for the\ndeployment of deep learning models to real-world settings. A general approach\nto this problem involves the adjustment of models to a new domain through\ntransfer learning. However, in many cases, this is not applicable in a post-hoc\nmanner to deployed models and further parameter adjustments jeopardize safety\ncertifications that were established beforehand. In such a context, we propose\nto deal with changes in the data distribution via guided data homogenization\nwhich shifts the burden of adaptation from the model to the data. This approach\nmakes use of information about the training data contained implicitly in the\ndeep learning model to learn a domain transfer function. This allows for a\ntargeted deployment of models to unknown scenarios without changing the model\nitself. We demonstrate the potential of data homogenization through experiments\non the CIFAR-10 and MNIST data sets.\n", "versions": [{"version": "v1", "created": "Thu, 8 Apr 2021 09:18:48 GMT"}], "update_date": "2021-04-09", "authors_parsed": [["Willis", "Kurt", ""], ["Oala", "Luis", ""]]}, {"id": "2104.03630", "submitter": "Maarten De Raedt", "authors": "Maarten De Raedt, Fr\\'ederic Godin, Pieter Buteneers, Chris Develder\n  and Thomas Demeester", "title": "A Simple Geometric Method for Cross-Lingual Linguistic Transformations\n  with Pre-trained Autoencoders", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Powerful sentence encoders trained for multiple languages are on the rise.\nThese systems are capable of embedding a wide range of linguistic properties\ninto vector representations. While explicit probing tasks can be used to verify\nthe presence of specific linguistic properties, it is unclear whether the\nvector representations can be manipulated to indirectly steer such properties.\nWe investigate the use of a geometric mapping in embedding space to transform\nlinguistic properties, without any tuning of the pre-trained sentence encoder\nor decoder. We validate our approach on three linguistic properties using a\npre-trained multilingual autoencoder and analyze the results in both\nmonolingual and cross-lingual settings.\n", "versions": [{"version": "v1", "created": "Thu, 8 Apr 2021 09:33:50 GMT"}], "update_date": "2021-04-09", "authors_parsed": [["De Raedt", "Maarten", ""], ["Godin", "Fr\u00e9deric", ""], ["Buteneers", "Pieter", ""], ["Develder", "Chris", ""], ["Demeester", "Thomas", ""]]}, {"id": "2104.03642", "submitter": "Huy Hoang Nguyen", "authors": "Huy Hoang Nguyen, Simo Saarakkala, Matthew B. Blaschko, Aleksei\n  Tiulpin", "title": "DeepProg: A Transformer-based Framework for Predicting Disease Prognosis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A vast majority of deep learning methods are built to automate diagnostic\ntasks. However, in clinical practice, a more advanced question is how to\npredict the course of a disease. Current methods for this problem are\ncomplicated, and often require domain knowledge, making them difficult for\npractitioners to use. In this paper, we formulate the prognosis prediction task\nas a one-to-many sequence prediction problem. Inspired by a clinical decision\nmaking process with two agents -- a radiologist and a general practitioner --\nwe propose a generic end-to-end transformer-based framework to estimate disease\nprognosis from images and auxiliary data. The effectiveness and validation of\nthe developed method are shown on synthetic data, and in the task of predicting\nthe development of structural osteoarthritic changes in knee joints.\n", "versions": [{"version": "v1", "created": "Thu, 8 Apr 2021 09:53:18 GMT"}], "update_date": "2021-04-09", "authors_parsed": [["Nguyen", "Huy Hoang", ""], ["Saarakkala", "Simo", ""], ["Blaschko", "Matthew B.", ""], ["Tiulpin", "Aleksei", ""]]}, {"id": "2104.03643", "submitter": "Juan Pablo Zuluaga-Gomez", "authors": "Juan Zuluaga-Gomez and Iuliia Nigmatulina and Amrutha Prasad and Petr\n  Motlicek and Karel Vesel\\'y and Martin Kocour and Igor Sz\\\"oke", "title": "Contextual Semi-Supervised Learning: An Approach To Leverage\n  Air-Surveillance and Untranscribed ATC Data in ASR Systems", "comments": "Submitted to: Interspeech conference 2021 (Brno, Czechia, August 30 -\n  September 3)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CV cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Air traffic management and specifically air-traffic control (ATC) rely mostly\non voice communications between Air Traffic Controllers (ATCos) and pilots. In\nmost cases, these voice communications follow a well-defined grammar that could\nbe leveraged in Automatic Speech Recognition (ASR) technologies. The callsign\nused to address an airplane is an essential part of all ATCo-pilot\ncommunications. We propose a two-steps approach to add contextual knowledge\nduring semi-supervised training to reduce the ASR system error rates at\nrecognizing the part of the utterance that contains the callsign. Initially, we\nrepresent in a WFST the contextual knowledge (i.e. air-surveillance data) of an\nATCo-pilot communication. Then, during Semi-Supervised Learning (SSL) the\ncontextual knowledge is added by second-pass decoding (i.e. lattice\nre-scoring). Results show that `unseen domains' (e.g. data from airports not\npresent in the supervised training data) are further aided by contextual SSL\nwhen compared to standalone SSL. For this task, we introduce the Callsign Word\nError Rate (CA-WER) as an evaluation metric, which only assesses ASR\nperformance of the spoken callsign in an utterance. We obtained a 32.1% CA-WER\nrelative improvement applying SSL with an additional 17.5% CA-WER improvement\nby adding contextual knowledge during SSL on a challenging ATC-based test set\ngathered from LiveATC.\n", "versions": [{"version": "v1", "created": "Thu, 8 Apr 2021 09:53:54 GMT"}], "update_date": "2021-04-09", "authors_parsed": [["Zuluaga-Gomez", "Juan", ""], ["Nigmatulina", "Iuliia", ""], ["Prasad", "Amrutha", ""], ["Motlicek", "Petr", ""], ["Vesel\u00fd", "Karel", ""], ["Kocour", "Martin", ""], ["Sz\u00f6ke", "Igor", ""]]}, {"id": "2104.03674", "submitter": "Jing Xu", "authors": "Jing Xu, Minhui (Jason) Xue, Stjepan Picek", "title": "Explainability-based Backdoor Attacks Against Graph Neural Networks", "comments": "6 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Backdoor attacks represent a serious threat to neural network models. A\nbackdoored model will misclassify the trigger-embedded inputs into an\nattacker-chosen target label while performing normally on other benign inputs.\nThere are already numerous works on backdoor attacks on neural networks, but\nonly a few works consider graph neural networks (GNNs). As such, there is no\nintensive research on explaining the impact of trigger injecting position on\nthe performance of backdoor attacks on GNNs.\n  To bridge this gap, we conduct an experimental investigation on the\nperformance of backdoor attacks on GNNs. We apply two powerful GNN\nexplainability approaches to select the optimal trigger injecting position to\nachieve two attacker objectives -- high attack success rate and low clean\naccuracy drop. Our empirical results on benchmark datasets and state-of-the-art\nneural network models demonstrate the proposed method's effectiveness in\nselecting trigger injecting position for backdoor attacks on GNNs. For\ninstance, on the node classification task, the backdoor attack with trigger\ninjecting position selected by GraphLIME reaches over $84 \\%$ attack success\nrate with less than $2.5 \\%$ accuracy drop\n", "versions": [{"version": "v1", "created": "Thu, 8 Apr 2021 10:43:40 GMT"}, {"version": "v2", "created": "Tue, 13 Jul 2021 13:31:52 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Xu", "Jing", "", "Jason"], ["Minhui", "", "", "Jason"], ["Xue", "", ""], ["Picek", "Stjepan", ""]]}, {"id": "2104.03715", "submitter": "Wenqiang Li", "authors": "Wenqiang Li, YM Tang, Ziyang Wang, KM Yu, Sandy To", "title": "Atrous Residual Interconnected Encoder to Attention Decoder Framework\n  for Vertebrae Segmentation via 3D Volumetric CT Images", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic medical image segmentation based on Computed Tomography (CT) has\nbeen widely applied for computer-aided surgery as a prerequisite. With the\ndevelopment of deep learning technologies, deep convolutional neural networks\n(DCNNs) have shown robust performance in automated semantic segmentation of\nmedical images. However, semantic segmentation algorithms based on DCNNs still\nmeet the challenges of feature loss between encoder and decoder, multi-scale\nobject, restricted field of view of filters, and lack of medical image data.\nThis paper proposes a novel algorithm for automated vertebrae segmentation via\n3D volumetric spine CT images. The proposed model is based on the structure of\nencoder to decoder, using layer normalization to optimize mini-batch training\nperformance. To address the concern of the information loss between encoder and\ndecoder, we designed an Atrous Residual Path to pass more features from encoder\nto decoder instead of an easy shortcut connection. The proposed model also\napplied the attention module in the decoder part to extract features from\nvariant scales. The proposed model is evaluated on a publicly available dataset\nby a variety of metrics. The experimental results show that our model achieves\ncompetitive performance compared with other state-of-the-art medical semantic\nsegmentation methods.\n", "versions": [{"version": "v1", "created": "Thu, 8 Apr 2021 12:09:16 GMT"}], "update_date": "2021-04-09", "authors_parsed": [["Li", "Wenqiang", ""], ["Tang", "YM", ""], ["Wang", "Ziyang", ""], ["Yu", "KM", ""], ["To", "Sandy", ""]]}, {"id": "2104.03722", "submitter": "Muhammad AbdurRafae", "authors": "Muhammad AbdurRafae", "title": "HindSight: A Graph-Based Vision Model Architecture For Representing\n  Part-Whole Hierarchies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper presents a model architecture for encoding the representations of\npart-whole hierarchies in images in form of a graph. The idea is to divide the\nimage into patches of different levels and then treat all of these patches as\nnodes for a fully connected graph. A dynamic feature extraction module is used\nto extract feature representations from these patches in each graph iteration.\nThis enables us to learn a rich graph representation of the image that\nencompasses the inherent part-whole hierarchical information. Utilizing proper\nself-supervised training techniques, such a model can be trained as a general\npurpose vision encoder model which can then be used for various vision related\ndownstream tasks (e.g., Image Classification, Object Detection, Image\nCaptioning, etc.).\n", "versions": [{"version": "v1", "created": "Thu, 8 Apr 2021 12:17:54 GMT"}], "update_date": "2021-04-09", "authors_parsed": [["AbdurRafae", "Muhammad", ""]]}, {"id": "2104.03725", "submitter": "Joan Serr\\`a", "authors": "Joan Serr\\`a, Santiago Pascual, Jordi Pons", "title": "On tuning consistent annealed sampling for denoising score matching", "comments": "3 pages and 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Score-based generative models provide state-of-the-art quality for image and\naudio synthesis. Sampling from these models is performed iteratively, typically\nemploying a discretized series of noise levels and a predefined scheme. In this\nnote, we first overview three common sampling schemes for models trained with\ndenoising score matching. Next, we focus on one of them, consistent annealed\nsampling, and study its hyper-parameter boundaries. We then highlight a\npossible formulation of such hyper-parameter that explicitly considers those\nboundaries and facilitates tuning when using few or a variable number of steps.\nFinally, we highlight some connections of the formulation with other sampling\nschemes.\n", "versions": [{"version": "v1", "created": "Thu, 8 Apr 2021 12:19:10 GMT"}], "update_date": "2021-04-09", "authors_parsed": [["Serr\u00e0", "Joan", ""], ["Pascual", "Santiago", ""], ["Pons", "Jordi", ""]]}, {"id": "2104.03736", "submitter": "Su Lu", "authors": "Su Lu, Han-Jia Ye, Le Gan, De-Chuan Zhan", "title": "Towards Enabling Meta-Learning from Target Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Meta-learning can extract an inductive bias from previous learning experience\nand assist the training processes of new tasks. It is often realized through\noptimizing a meta-model with the evaluation loss of a series of task-specific\nsolvers. Most existing algorithms sample non-overlapping $\\mathit{support}$\nsets and $\\mathit{query}$ sets to train and evaluate the solvers respectively\ndue to simplicity ($\\mathcal{S}/\\mathcal{Q}$ protocol). However, another\nevaluation method that assesses the discrepancy between the solver and a target\nmodel is short of research ($\\mathcal{S}/\\mathcal{T}$ protocol).\n$\\mathcal{S}/\\mathcal{T}$ protocol has unique advantages such as offering more\ninformative supervision, but it is computationally expensive. This paper looks\ninto this special evaluation method and takes a step towards putting it into\npractice. We find that with a small ratio of tasks armed with target models,\nclassic meta-learning algorithms can be improved a lot without consuming many\nresources. Furthermore, we empirically verify the effectiveness of\n$\\mathcal{S}/\\mathcal{T}$ protocol in a typical application of meta-learning,\n$\\mathit{i.e.}$, few-shot learning. In detail, after constructing target models\nby fine-tuning the pre-trained network on those hard tasks, we match the\ntask-specific solvers to target models via knowledge distillation. Experiments\ndemonstrate the superiority of our proposal.\n", "versions": [{"version": "v1", "created": "Thu, 8 Apr 2021 12:41:33 GMT"}, {"version": "v2", "created": "Sat, 5 Jun 2021 07:29:24 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Lu", "Su", ""], ["Ye", "Han-Jia", ""], ["Gan", "Le", ""], ["Zhan", "De-Chuan", ""]]}, {"id": "2104.03737", "submitter": "Su Lu", "authors": "Su Lu, Han-Jia Ye, De-Chuan Zhan", "title": "Few-Shot Action Recognition with Compromised Metric via Optimal\n  Transport", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Although vital to computer vision systems, few-shot action recognition is\nstill not mature despite the wide research of few-shot image classification.\nPopular few-shot learning algorithms extract a transferable embedding from seen\nclasses and reuse it on unseen classes by constructing a metric-based\nclassifier. One main obstacle to applying these algorithms in action\nrecognition is the complex structure of videos. Some existing solutions sample\nframes from a video and aggregate their embeddings to form a video-level\nrepresentation, neglecting important temporal relations. Others perform an\nexplicit sequence matching between two videos and define their distance as\nmatching cost, imposing too strong restrictions on sequence ordering. In this\npaper, we propose Compromised Metric via Optimal Transport (CMOT) to combine\nthe advantages of these two solutions. CMOT simultaneously considers semantic\nand temporal information in videos under Optimal Transport framework, and is\ndiscriminative for both content-sensitive and ordering-sensitive tasks. In\ndetail, given two videos, we sample segments from them and cast the calculation\nof their distance as an optimal transport problem between two segment\nsequences. To preserve the inherent temporal ordering information, we\nadditionally amend the ground cost matrix by penalizing it with the positional\ndistance between a pair of segments. Empirical results on benchmark datasets\ndemonstrate the superiority of CMOT.\n", "versions": [{"version": "v1", "created": "Thu, 8 Apr 2021 12:42:05 GMT"}], "update_date": "2021-04-09", "authors_parsed": [["Lu", "Su", ""], ["Ye", "Han-Jia", ""], ["Zhan", "De-Chuan", ""]]}, {"id": "2104.03739", "submitter": "Mostafa Mehdipour Ghazi", "authors": "Mostafa Mehdipour Ghazi, Lauge S{\\o}rensen, S\\'ebastien Ourselin, Mads\n  Nielsen", "title": "CARRNN: A Continuous Autoregressive Recurrent Neural Network for Deep\n  Representation Learning from Sporadic Temporal Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning temporal patterns from multivariate longitudinal data is challenging\nespecially in cases when data is sporadic, as often seen in, e.g., healthcare\napplications where the data can suffer from irregularity and asynchronicity as\nthe time between consecutive data points can vary across features and samples,\nhindering the application of existing deep learning models that are constructed\nfor complete, evenly spaced data with fixed sequence lengths. In this paper, a\nnovel deep learning-based model is developed for modeling multiple temporal\nfeatures in sporadic data using an integrated deep learning architecture based\non a recurrent neural network (RNN) unit and a continuous-time autoregressive\n(CAR) model. The proposed model, called CARRNN, uses a generalized\ndiscrete-time autoregressive model that is trainable end-to-end using neural\nnetworks modulated by time lags to describe the changes caused by the\nirregularity and asynchronicity. It is applied to multivariate time-series\nregression tasks using data provided for Alzheimer's disease progression\nmodeling and intensive care unit (ICU) mortality rate prediction, where the\nproposed model based on a gated recurrent unit (GRU) achieves the lowest\nprediction errors among the proposed RNN-based models and state-of-the-art\nmethods using GRUs and long short-term memory (LSTM) networks in their\narchitecture.\n", "versions": [{"version": "v1", "created": "Thu, 8 Apr 2021 12:43:44 GMT"}], "update_date": "2021-04-09", "authors_parsed": [["Ghazi", "Mostafa Mehdipour", ""], ["S\u00f8rensen", "Lauge", ""], ["Ourselin", "S\u00e9bastien", ""], ["Nielsen", "Mads", ""]]}, {"id": "2104.03743", "submitter": "Wei Xing", "authors": "Wei W. Xing, Akeel A. Shah, Peng Wang, Shandian Zhe Qian Fu, and\n  Robert. M. Kirby", "title": "Residual Gaussian Process: A Tractable Nonparametric Bayesian Emulator\n  for Multi-fidelity Simulations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CE stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Challenges in multi-fidelity modeling relate to accuracy, uncertainty\nestimation and high-dimensionality. A novel additive structure is introduced in\nwhich the highest fidelity solution is written as a sum of the lowest fidelity\nsolution and residuals between the solutions at successive fidelity levels,\nwith Gaussian process priors placed over the low fidelity solution and each of\nthe residuals. The resulting model is equipped with a closed-form solution for\nthe predictive posterior, making it applicable to advanced, high-dimensional\ntasks that require uncertainty estimation. Its advantages are demonstrated on\nunivariate benchmarks and on three challenging multivariate problems. It is\nshown how active learning can be used to enhance the model, especially with a\nlimited computational budget. Furthermore, error bounds are derived for the\nmean prediction in the univariate case.\n", "versions": [{"version": "v1", "created": "Thu, 8 Apr 2021 12:57:46 GMT"}], "update_date": "2021-04-09", "authors_parsed": [["Xing", "Wei W.", ""], ["Shah", "Akeel A.", ""], ["Wang", "Peng", ""], ["Fu", "Shandian Zhe Qian", ""], ["Kirby", "Robert. M.", ""]]}, {"id": "2104.03760", "submitter": "Pierre Tassel", "authors": "Pierre Tassel, Martin Gebser, Konstantin Schekotihin", "title": "A Reinforcement Learning Environment For Job-Shop Scheduling", "comments": "7 pages, 4 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Scheduling is a fundamental task occurring in various automated systems\napplications, e.g., optimal schedules for machines on a job shop allow for a\nreduction of production costs and waste. Nevertheless, finding such schedules\nis often intractable and cannot be achieved by Combinatorial Optimization\nProblem (COP) methods within a given time limit. Recent advances of Deep\nReinforcement Learning (DRL) in learning complex behavior enable new COP\napplication possibilities. This paper presents an efficient DRL environment for\nJob-Shop Scheduling -- an important problem in the field. Furthermore, we\ndesign a meaningful and compact state representation as well as a novel, simple\ndense reward function, closely related to the sparse make-span minimization\ncriteria used by COP methods. We demonstrate that our approach significantly\noutperforms existing DRL methods on classic benchmark instances, coming close\nto state-of-the-art COP approaches.\n", "versions": [{"version": "v1", "created": "Thu, 8 Apr 2021 13:26:30 GMT"}], "update_date": "2021-04-09", "authors_parsed": [["Tassel", "Pierre", ""], ["Gebser", "Martin", ""], ["Schekotihin", "Konstantin", ""]]}, {"id": "2104.03781", "submitter": "Matteo Pirotta", "authors": "Matteo Papini, Andrea Tirinzoni, Marcello Restelli, Alessandro Lazaric\n  and Matteo Pirotta", "title": "Leveraging Good Representations in Linear Contextual Bandits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The linear contextual bandit literature is mostly focused on the design of\nefficient learning algorithms for a given representation. However, a contextual\nbandit problem may admit multiple linear representations, each one with\ndifferent characteristics that directly impact the regret of the learning\nalgorithm. In particular, recent works showed that there exist \"good\"\nrepresentations for which constant problem-dependent regret can be achieved. In\nthis paper, we first provide a systematic analysis of the different definitions\nof \"good\" representations proposed in the literature. We then propose a novel\nselection algorithm able to adapt to the best representation in a set of $M$\ncandidates. We show that the regret is indeed never worse than the regret\nobtained by running LinUCB on the best representation (up to a $\\ln M$ factor).\nAs a result, our algorithm achieves constant regret whenever a \"good\"\nrepresentation is available in the set. Furthermore, we show that the algorithm\nmay still achieve constant regret by implicitly constructing a \"good\"\nrepresentation, even when none of the initial representations is \"good\".\nFinally, we empirically validate our theoretical findings in a number of\nstandard contextual bandit problems.\n", "versions": [{"version": "v1", "created": "Thu, 8 Apr 2021 14:05:31 GMT"}], "update_date": "2021-04-09", "authors_parsed": [["Papini", "Matteo", ""], ["Tirinzoni", "Andrea", ""], ["Restelli", "Marcello", ""], ["Lazaric", "Alessandro", ""], ["Pirotta", "Matteo", ""]]}, {"id": "2104.03804", "submitter": "Fares Mehouachi", "authors": "Fares B. Mehouachi, Chaouki Kasmi", "title": "Exact Stochastic Second Order Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Optimization in Deep Learning is mainly dominated by first-order methods\nwhich are built around the central concept of backpropagation. Second-order\noptimization methods, which take into account the second-order derivatives are\nfar less used despite superior theoretical properties. This inadequacy of\nsecond-order methods stems from its exorbitant computational cost, poor\nperformance, and the ineluctable non-convex nature of Deep Learning. Several\nattempts were made to resolve the inadequacy of second-order optimization\nwithout reaching a cost-effective solution, much less an exact solution. In\nthis work, we show that this long-standing problem in Deep Learning could be\nsolved in the stochastic case, given a suitable regularization of the neural\nnetwork. Interestingly, we provide an expression of the stochastic Hessian and\nits exact eigenvalues. We provide a closed-form formula for the exact\nstochastic second-order Newton direction, we solve the non-convexity issue and\nadjust our exact solution to favor flat minima through regularization and\nspectral adjustment. We test our exact stochastic second-order method on\npopular datasets and reveal its adequacy for Deep Learning.\n", "versions": [{"version": "v1", "created": "Thu, 8 Apr 2021 14:29:31 GMT"}], "update_date": "2021-04-09", "authors_parsed": [["Mehouachi", "Fares B.", ""], ["Kasmi", "Chaouki", ""]]}, {"id": "2104.03829", "submitter": "Abhijit Guha Roy", "authors": "Abhijit Guha Roy, Jie Ren, Shekoofeh Azizi, Aaron Loh, Vivek\n  Natarajan, Basil Mustafa, Nick Pawlowski, Jan Freyberg, Yuan Liu, Zach\n  Beaver, Nam Vo, Peggy Bui, Samantha Winter, Patricia MacWilliams, Greg S.\n  Corrado, Umesh Telang, Yun Liu, Taylan Cemgil, Alan Karthikesalingam, Balaji\n  Lakshminarayanan, Jim Winkens", "title": "Does Your Dermatology Classifier Know What It Doesn't Know? Detecting\n  the Long-Tail of Unseen Conditions", "comments": "Under Review, 19 Pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We develop and rigorously evaluate a deep learning based system that can\naccurately classify skin conditions while detecting rare conditions for which\nthere is not enough data available for training a confident classifier. We\nframe this task as an out-of-distribution (OOD) detection problem. Our novel\napproach, hierarchical outlier detection (HOD) assigns multiple abstention\nclasses for each training outlier class and jointly performs a coarse\nclassification of inliers vs. outliers, along with fine-grained classification\nof the individual classes. We demonstrate the effectiveness of the HOD loss in\nconjunction with modern representation learning approaches (BiT, SimCLR, MICLe)\nand explore different ensembling strategies for further improving the results.\nWe perform an extensive subgroup analysis over conditions of varying risk\nlevels and different skin types to investigate how the OOD detection\nperformance changes over each subgroup and demonstrate the gains of our\nframework in comparison to baselines. Finally, we introduce a cost metric to\napproximate downstream clinical impact. We use this cost metric to compare the\nproposed method against a baseline system, thereby making a stronger case for\nthe overall system effectiveness in a real-world deployment scenario.\n", "versions": [{"version": "v1", "created": "Thu, 8 Apr 2021 15:15:22 GMT"}], "update_date": "2021-04-09", "authors_parsed": [["Roy", "Abhijit Guha", ""], ["Ren", "Jie", ""], ["Azizi", "Shekoofeh", ""], ["Loh", "Aaron", ""], ["Natarajan", "Vivek", ""], ["Mustafa", "Basil", ""], ["Pawlowski", "Nick", ""], ["Freyberg", "Jan", ""], ["Liu", "Yuan", ""], ["Beaver", "Zach", ""], ["Vo", "Nam", ""], ["Bui", "Peggy", ""], ["Winter", "Samantha", ""], ["MacWilliams", "Patricia", ""], ["Corrado", "Greg S.", ""], ["Telang", "Umesh", ""], ["Liu", "Yun", ""], ["Cemgil", "Taylan", ""], ["Karthikesalingam", "Alan", ""], ["Lakshminarayanan", "Balaji", ""], ["Winkens", "Jim", ""]]}, {"id": "2104.03834", "submitter": "Jinu Gong", "authors": "Jinu Gong, Osvaldo Simeone, Joonhyuk Kang", "title": "Bayesian Variational Federated Learning and Unlearning in Decentralized\n  Networks", "comments": "Submitted for conference publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated Bayesian learning offers a principled framework for the definition\nof collaborative training algorithms that are able to quantify epistemic\nuncertainty and to produce trustworthy decisions. Upon the completion of\ncollaborative training, an agent may decide to exercise her legal \"right to be\nforgotten\", which calls for her contribution to the jointly trained model to be\ndeleted and discarded. This paper studies federated learning and unlearning in\na decentralized network within a Bayesian framework. It specifically develops\nfederated variational inference (VI) solutions based on the decentralized\nsolution of local free energy minimization problems within exponential-family\nmodels and on local gossip-driven communication. The proposed protocols are\ndemonstrated to yield efficient unlearning mechanisms.\n", "versions": [{"version": "v1", "created": "Thu, 8 Apr 2021 15:18:35 GMT"}], "update_date": "2021-04-09", "authors_parsed": [["Gong", "Jinu", ""], ["Simeone", "Osvaldo", ""], ["Kang", "Joonhyuk", ""]]}, {"id": "2104.03838", "submitter": "Madhav Kashyap", "authors": "Madhav Mahesh Kashyap, Anuj Tambwekar, Krishnamoorthy Manohara, S\n  Natarajan", "title": "Speech Denoising without Clean Training Data: a Noise2Noise Approach", "comments": "Submitted to INTERSPEECH 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper tackles the problem of the heavy dependence of clean speech data\nrequired by deep learning based audio-denoising methods by showing that it is\npossible to train deep speech denoising networks using only noisy speech\nsamples. Conventional wisdom dictates that in order to achieve good speech\ndenoising performance, there is a requirement for a large quantity of both\nnoisy speech samples and perfectly clean speech samples, resulting in a need\nfor expensive audio recording equipment and extremely controlled soundproof\nrecording studios. These requirements pose significant challenges in data\ncollection, especially in economically disadvantaged regions and for low\nresource languages. This work shows that speech denoising deep neural networks\ncan be successfully trained utilizing only noisy training audio. Furthermore it\nis revealed that such training regimes achieve superior denoising performance\nover conventional training regimes utilizing clean training audio targets, in\ncases involving complex noise distributions and low Signal-to-Noise ratios\n(high noise environments). This is demonstrated through experiments studying\nthe efficacy of our proposed approach over both real-world noises and synthetic\nnoises using the 20 layered Deep Complex U-Net architecture.\n", "versions": [{"version": "v1", "created": "Thu, 8 Apr 2021 15:27:49 GMT"}], "update_date": "2021-04-09", "authors_parsed": [["Kashyap", "Madhav Mahesh", ""], ["Tambwekar", "Anuj", ""], ["Manohara", "Krishnamoorthy", ""], ["Natarajan", "S", ""]]}, {"id": "2104.03842", "submitter": "Samuel Thomas", "authors": "Samuel Thomas, Hong-Kwang J. Kuo, George Saon, Zolt\\'an T\\\"uske, Brian\n  Kingsbury, Gakuto Kurata, Zvi Kons, Ron Hoory", "title": "RNN Transducer Models For Spoken Language Understanding", "comments": "To appear in the proceedings of ICASSP 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a comprehensive study on building and adapting RNN transducer\n(RNN-T) models for spoken language understanding(SLU). These end-to-end (E2E)\nmodels are constructed in three practical settings: a case where verbatim\ntranscripts are available, a constrained case where the only available\nannotations are SLU labels and their values, and a more restrictive case where\ntranscripts are available but not corresponding audio. We show how RNN-T SLU\nmodels can be developed starting from pre-trained automatic speech recognition\n(ASR) systems, followed by an SLU adaptation step. In settings where real audio\ndata is not available, artificially synthesized speech is used to successfully\nadapt various SLU models. When evaluated on two SLU data sets, the ATIS corpus\nand a customer call center data set, the proposed models closely track the\nperformance of other E2E models and achieve state-of-the-art results.\n", "versions": [{"version": "v1", "created": "Thu, 8 Apr 2021 15:35:22 GMT"}], "update_date": "2021-04-09", "authors_parsed": [["Thomas", "Samuel", ""], ["Kuo", "Hong-Kwang J.", ""], ["Saon", "George", ""], ["T\u00fcske", "Zolt\u00e1n", ""], ["Kingsbury", "Brian", ""], ["Kurata", "Gakuto", ""], ["Kons", "Zvi", ""], ["Hoory", "Ron", ""]]}, {"id": "2104.03860", "submitter": "Huazheng Wang", "authors": "Huazheng Wang, Haifeng Xu, Chuanhao Li, Zhiyuan Liu, Hongning Wang", "title": "Incentivizing Exploration in Linear Bandits under Information Gap", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of incentivizing exploration for myopic users in linear\nbandits, where the users tend to exploit arm with the highest predicted reward\ninstead of exploring. In order to maximize the long-term reward, the system\noffers compensation to incentivize the users to pull the exploratory arms, with\nthe goal of balancing the trade-off among exploitation, exploration and\ncompensation. We consider a new and practically motivated setting where the\ncontext features observed by the user are more informative than those used by\nthe system, e.g., features based on users' private information are not\naccessible by the system. We propose a new method to incentivize exploration\nunder such information gap, and prove that the method achieves both sublinear\nregret and sublinear compensation. We theoretical and empirically analyze the\nadded compensation due to the information gap, compared with the case that the\nsystem has access to the same context features as the user, i.e., without\ninformation gap. We also provide a compensation lower bound of our problem.\n", "versions": [{"version": "v1", "created": "Thu, 8 Apr 2021 16:01:56 GMT"}], "update_date": "2021-04-09", "authors_parsed": [["Wang", "Huazheng", ""], ["Xu", "Haifeng", ""], ["Li", "Chuanhao", ""], ["Liu", "Zhiyuan", ""], ["Wang", "Hongning", ""]]}, {"id": "2104.03863", "submitter": "Gauthier Gidel", "authors": "S\\'ebastien Bubeck, Yeshwanth Cherapanamjeri, Gauthier Gidel and\n  R\\'emi Tachet des Combes", "title": "A single gradient step finds adversarial examples on random two-layers\n  neural networks", "comments": "Added a comment about universal adversarial perturbations. 18 pages,\n  7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Daniely and Schacham recently showed that gradient descent finds adversarial\nexamples on random undercomplete two-layers ReLU neural networks. The term\n\"undercomplete\" refers to the fact that their proof only holds when the number\nof neurons is a vanishing fraction of the ambient dimension. We extend their\nresult to the overcomplete case, where the number of neurons is larger than the\ndimension (yet also subexponential in the dimension). In fact we prove that a\nsingle step of gradient descent suffices. We also show this result for any\nsubexponential width random neural network with smooth activation function.\n", "versions": [{"version": "v1", "created": "Thu, 8 Apr 2021 16:06:54 GMT"}, {"version": "v2", "created": "Fri, 9 Apr 2021 22:13:17 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Bubeck", "S\u00e9bastien", ""], ["Cherapanamjeri", "Yeshwanth", ""], ["Gidel", "Gauthier", ""], ["Combes", "R\u00e9mi Tachet des", ""]]}, {"id": "2104.03876", "submitter": "Christopher Mitcheltree", "authors": "Christopher Mitcheltree, Hideki Koike", "title": "SerumRNN: Step by Step Audio VST Effect Programming", "comments": "Audio samples of the system can be listened to at bit.ly/serum_rnn", "journal-ref": "10th International Conference on Artificial Intelligence in Music,\n  Sound, Art, and Design (EvoMUSART 2021), Seville, Spain", "doi": "10.1007/978-3-030-72914-1_15", "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Learning to program an audio production VST synthesizer is a time consuming\nprocess, usually obtained through inefficient trial and error and only mastered\nafter years of experience. As an educational and creative tool for sound\ndesigners, we propose SerumRNN: a system that provides step-by-step\ninstructions for applying audio effects to change a user's input audio towards\na desired sound. We apply our system to Xfer Records Serum: currently one of\nthe most popular and complex VST synthesizers used by the audio production\ncommunity. Our results indicate that SerumRNN is consistently able to provide\nuseful feedback for a variety of different audio effects and synthesizer\npresets. We demonstrate the benefits of using an iterative system and show that\nSerumRNN learns to prioritize effects and can discover more efficient effect\norder sequences than a variety of baselines.\n", "versions": [{"version": "v1", "created": "Thu, 8 Apr 2021 16:32:14 GMT"}], "update_date": "2021-04-12", "authors_parsed": [["Mitcheltree", "Christopher", ""], ["Koike", "Hideki", ""]]}, {"id": "2104.03886", "submitter": "Marc B\\\"ohlen", "authors": "Marc B\\\"ohlen", "title": "Classification, Slippage, Failure and Discovery", "comments": null, "journal-ref": "9th Conference on Computation, Communication, Aesthetics & X 2021", "doi": null, "report-no": null, "categories": "cs.CY cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  This text argues for the potential of machine learning infused classification\nsystems as vectors for a technically-engaged and constructive technology\ncritique. The text describes this potential with several experiments in image\ndata creation and neural network based classification. The text considers\nvarying aspects of slippage in classification and considers the potential for\ndiscovery - as opposed to disaster - stemming from machine learning systems\nwhen they fail to perform as anticipated.\n", "versions": [{"version": "v1", "created": "Thu, 8 Apr 2021 16:52:28 GMT"}], "update_date": "2021-04-09", "authors_parsed": [["B\u00f6hlen", "Marc", ""]]}, {"id": "2104.03888", "submitter": "Manuel Carranza-Garc\\'ia", "authors": "Manuel Carranza-Garc\\'ia, Pedro Lara-Ben\\'itez, Jorge\n  Garc\\'ia-Guti\\'errez, Jos\\'e C. Riquelme", "title": "Enhancing Object Detection for Autonomous Driving by Optimizing Anchor\n  Generation and Addressing Class Imbalance", "comments": null, "journal-ref": "Neurocomputing, 2021", "doi": "10.1016/j.neucom.2021.04.001", "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Object detection has been one of the most active topics in computer vision\nfor the past years. Recent works have mainly focused on pushing the\nstate-of-the-art in the general-purpose COCO benchmark. However, the use of\nsuch detection frameworks in specific applications such as autonomous driving\nis yet an area to be addressed. This study presents an enhanced 2D object\ndetector based on Faster R-CNN that is better suited for the context of\nautonomous vehicles. Two main aspects are improved: the anchor generation\nprocedure and the performance drop in minority classes. The default uniform\nanchor configuration is not suitable in this scenario due to the perspective\nprojection of the vehicle cameras. Therefore, we propose a perspective-aware\nmethodology that divides the image into key regions via clustering and uses\nevolutionary algorithms to optimize the base anchors for each of them.\nFurthermore, we add a module that enhances the precision of the second-stage\nheader network by including the spatial information of the candidate regions\nproposed in the first stage. We also explore different re-weighting strategies\nto address the foreground-foreground class imbalance, showing that the use of a\nreduced version of focal loss can significantly improve the detection of\ndifficult and underrepresented objects in two-stage detectors. Finally, we\ndesign an ensemble model to combine the strengths of the different learning\nstrategies. Our proposal is evaluated with the Waymo Open Dataset, which is the\nmost extensive and diverse up to date. The results demonstrate an average\naccuracy improvement of 6.13% mAP when using the best single model, and of\n9.69% mAP with the ensemble. The proposed modifications over the Faster R-CNN\ndo not increase computational cost and can easily be extended to optimize other\nanchor-based detection frameworks.\n", "versions": [{"version": "v1", "created": "Thu, 8 Apr 2021 16:58:31 GMT"}], "update_date": "2021-04-09", "authors_parsed": [["Carranza-Garc\u00eda", "Manuel", ""], ["Lara-Ben\u00edtez", "Pedro", ""], ["Garc\u00eda-Guti\u00e9rrez", "Jorge", ""], ["Riquelme", "Jos\u00e9 C.", ""]]}, {"id": "2104.03895", "submitter": "Islem Rekik", "authors": "Islem Rekik and Mustafa Burak Gurbuz", "title": "MGN-Net: a multi-view graph normalizer for integrating heterogeneous\n  biological network populations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG q-bio.QM", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  With the recent technological advances, biological datasets, often\nrepresented by networks (i.e., graphs) of interacting entities, proliferate\nwith unprecedented complexity and heterogeneity. Although modern network\nscience opens new frontiers of analyzing connectivity patterns in such\ndatasets, we still lack data-driven methods for extracting an integral\nconnectional fingerprint of a multi-view graph population, let alone\ndisentangling the typical from the atypical variations across the population\nsamples. We present the multi-view graph normalizer network (MGN-Net;\nhttps://github.com/basiralab/MGN-Net), a graph neural network based method to\nnormalize and integrate a set of multi-view biological networks into a single\nconnectional template that is centered, representative, and topologically\nsound. We demonstrate the use of MGN-Net by discovering the connectional\nfingerprints of healthy and neurologically disordered brain network populations\nincluding Alzheimer's disease and Autism spectrum disorder patients.\nAdditionally, by comparing the learned templates of healthy and disordered\npopulations, we show that MGN-Net significantly outperforms conventional\nnetwork integration methods across extensive experiments in terms of producing\nthe most centered templates, recapitulating unique traits of populations, and\npreserving the complex topology of biological networks. Our evaluations showed\nthat MGN-Net is powerfully generic and easily adaptable in design to different\ngraph-based problems such as identification of relevant connections,\nnormalization and integration.\n", "versions": [{"version": "v1", "created": "Sun, 4 Apr 2021 05:45:04 GMT"}], "update_date": "2021-04-09", "authors_parsed": [["Rekik", "Islem", ""], ["Gurbuz", "Mustafa Burak", ""]]}, {"id": "2104.03902", "submitter": "William J. Cunningham", "authors": "Stephon Alexander, William J. Cunningham, Jaron Lanier, Lee Smolin,\n  Stefan Stanojevic, Michael W. Toomey, Dave Wecker", "title": "The Autodidactic Universe", "comments": "79 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "hep-th cs.AI cs.LG gr-qc physics.hist-ph quant-ph", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present an approach to cosmology in which the Universe learns its own\nphysical laws. It does so by exploring a landscape of possible laws, which we\nexpress as a certain class of matrix models. We discover maps that put each of\nthese matrix models in correspondence with both a gauge/gravity theory and a\nmathematical model of a learning machine, such as a deep recurrent, cyclic\nneural network. This establishes a correspondence between each solution of the\nphysical theory and a run of a neural network. This correspondence is not an\nequivalence, partly because gauge theories emerge from $N \\rightarrow \\infty $\nlimits of the matrix models, whereas the same limits of the neural networks\nused here are not well-defined. We discuss in detail what it means to say that\nlearning takes place in autodidactic systems, where there is no supervision. We\npropose that if the neural network model can be said to learn without\nsupervision, the same can be said for the corresponding physical theory. We\nconsider other protocols for autodidactic physical systems, such as\noptimization of graph variety, subset-replication using self-attention and\nlook-ahead, geometrogenesis guided by reinforcement learning, structural\nlearning using renormalization group techniques, and extensions. These\nprotocols together provide a number of directions in which to explore the\norigin of physical laws based on putting machine learning architectures in\ncorrespondence with physical theories.\n", "versions": [{"version": "v1", "created": "Mon, 29 Mar 2021 02:25:02 GMT"}], "update_date": "2021-04-09", "authors_parsed": [["Alexander", "Stephon", ""], ["Cunningham", "William J.", ""], ["Lanier", "Jaron", ""], ["Smolin", "Lee", ""], ["Stanojevic", "Stefan", ""], ["Toomey", "Michael W.", ""], ["Wecker", "Dave", ""]]}, {"id": "2104.03906", "submitter": "David Leslie", "authors": "David Leslie and Morgan Briggs", "title": "Explaining decisions made with AI: A workbook (Use case 1: AI-assisted\n  recruitment tool)", "comments": null, "journal-ref": null, "doi": "10.5281/zenodo.4624711", "report-no": null, "categories": "cs.CY cs.DB cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Over the last two years, The Alan Turing Institute and the Information\nCommissioner's Office (ICO) have been working together to discover ways to\ntackle the difficult issues surrounding explainable AI. The ultimate product of\nthis joint endeavour, Explaining decisions made with AI, published in May 2020,\nis the most comprehensive practical guidance on AI explanation produced\nanywhere to date. We have put together this workbook to help support the uptake\nof that guidance. The goal of the workbook is to summarise some of main themes\nfrom Explaining decisions made with AI and then to provide the materials for a\nworkshop exercise that has been built around a use case created to help you\ngain a flavour of how to put the guidance into practice. In the first three\nsections, we run through the basics of Explaining decisions made with AI. We\nprovide a precis of the four principles of AI explainability, the typology of\nAI explanations, and the tasks involved in the explanation-aware design,\ndevelopment, and use of AI/ML systems. We then provide some reflection\nquestions, which are intended to be a launching pad for group discussion, and a\nstarting point for the case-study-based exercise that we have included as\nAppendix B. In Appendix A, we go into more detailed suggestions about how to\norganise the workshop. These recommendations are based on two workshops we had\nthe privilege of co-hosting with our colleagues from the ICO and Manchester\nMetropolitan University in January 2021. The participants of these workshops\ncame from both the private and public sectors, and we are extremely grateful to\nthem for their energy, enthusiasm, and tremendous insight. This workbook would\nsimply not exist without the commitment and keenness of all our collaborators\nand workshop participants.\n", "versions": [{"version": "v1", "created": "Sat, 20 Mar 2021 17:03:50 GMT"}], "update_date": "2021-04-09", "authors_parsed": [["Leslie", "David", ""], ["Briggs", "Morgan", ""]]}, {"id": "2104.03909", "submitter": "Tina Eliassi-Rad", "authors": "David Liu, Zohair Shafi, William Fleisher, Tina Eliassi-Rad, Scott\n  Alfeld", "title": "RAWLSNET: Altering Bayesian Networks to Encode Rawlsian Fair Equality of\n  Opportunity", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present RAWLSNET, a system for altering Bayesian Network (BN) models to\nsatisfy the Rawlsian principle of fair equality of opportunity (FEO).\nRAWLSNET's BN models generate aspirational data distributions: data generated\nto reflect an ideally fair, FEO-satisfying society. FEO states that everyone\nwith the same talent and willingness to use it should have the same chance of\nachieving advantageous social positions (e.g., employment), regardless of their\nbackground circumstances (e.g., socioeconomic status). Satisfying FEO requires\nalterations to social structures such as school assignments. Our paper\ndescribes RAWLSNET, a method which takes as input a BN representation of an FEO\napplication and alters the BN's parameters so as to satisfy FEO when possible,\nand minimize deviation from FEO otherwise. We also offer guidance for applying\nRAWLSNET, including on recognizing proper applications of FEO. We demonstrate\nthe use of our system with publicly available data sets. RAWLSNET's altered BNs\noffer the novel capability of generating aspirational data for FEO-relevant\ntasks. Aspirational data are free from the biases of real-world data, and thus\nare useful for recognizing and detecting sources of unfairness in machine\nlearning algorithms besides biased data.\n", "versions": [{"version": "v1", "created": "Tue, 16 Mar 2021 03:06:47 GMT"}], "update_date": "2021-04-09", "authors_parsed": [["Liu", "David", ""], ["Shafi", "Zohair", ""], ["Fleisher", "William", ""], ["Eliassi-Rad", "Tina", ""], ["Alfeld", "Scott", ""]]}, {"id": "2104.03916", "submitter": "Thomas Mitchel", "authors": "Thomas W. Mitchel, Vladimir G. Kim, Michael Kazhdan", "title": "Field Convolutions for Surface CNNs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.GR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel surface convolution operator acting on vector fields that\nis based on a simple observation: instead of combining neighboring features\nwith respect to a single coordinate parameterization defined at a given point,\nwe have every neighbor describe the position of the point within its own\ncoordinate frame. This formulation combines intrinsic spatial convolution with\nparallel transport in a scattering operation while placing no constraints on\nthe filters themselves, providing a definition of convolution that commutes\nwith the action of isometries, has increased descriptive potential, and is\nrobust to noise and other nuisance factors. The result is a rich notion of\nconvolution which we call field convolution, well-suited for CNNs on surfaces.\nField convolutions are flexible and straight-forward to implement, and their\nhighly discriminating nature has cascading effects throughout the learning\npipeline. Using simple networks constructed from residual field convolution\nblocks, we achieve state-of-the-art results on standard benchmarks in\nfundamental geometry processing tasks, such as shape classification,\nsegmentation, correspondence, and sparse matching.\n", "versions": [{"version": "v1", "created": "Thu, 8 Apr 2021 17:11:14 GMT"}], "update_date": "2021-04-09", "authors_parsed": [["Mitchel", "Thomas W.", ""], ["Kim", "Vladimir G.", ""], ["Kazhdan", "Michael", ""]]}, {"id": "2104.03935", "submitter": "Mansi Sharma", "authors": "Mohammad Aaftab V, Mansi Sharma", "title": "OGGN: A Novel Generalized Oracle Guided Generative Architecture for\n  Modelling Inverse Function of Artificial Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a novel Generative Neural Network Architecture for\nmodelling the inverse function of an Artificial Neural Network (ANN) either\ncompletely or partially. Modelling the complete inverse function of an ANN\ninvolves generating the values of all features that corresponds to a desired\noutput. On the other hand, partially modelling the inverse function means\ngenerating the values of a subset of features and fixing the remaining feature\nvalues. The feature set generation is a critical step for artificial neural\nnetworks, useful in several practical applications in engineering and science.\nThe proposed Oracle Guided Generative Neural Network, dubbed as OGGN, is\nflexible to handle a variety of feature generation problems. In general, an ANN\nis able to predict the target values based on given feature vectors. The OGGN\narchitecture enables to generate feature vectors given the predetermined target\nvalues of an ANN. When generated feature vectors are fed to the forward ANN,\nthe target value predicted by ANN will be close to the predetermined target\nvalues. Therefore, the OGGN architecture is able to map, inverse function of\nthe function represented by forward ANN. Besides, there is another important\ncontribution of this work. This paper also introduces a new class of functions,\ndefined as constraint functions. The constraint functions enable a neural\nnetwork to investigate a given local space for a longer period of time. Thus,\nenabling to find a local optimum of the loss function apart from just being\nable to find the global optimum. OGGN can also be adapted to solve a system of\npolynomial equations in many variables. The experiments on synthetic datasets\nvalidate the effectiveness of OGGN on various use cases.\n", "versions": [{"version": "v1", "created": "Thu, 8 Apr 2021 17:28:52 GMT"}], "update_date": "2021-04-09", "authors_parsed": [["Aaftab", "Mohammad", "V"], ["Sharma", "Mansi", ""]]}, {"id": "2104.03936", "submitter": "Achkan Salehi", "authors": "Achkan Salehi, Alexandre Coninx, Stephane Doncieux", "title": "BR-NS: an Archive-less Approach to Novelty Search", "comments": "Author version of the paper accepted at GECCO 21", "journal-ref": null, "doi": "10.1145/3449639.3459303", "report-no": null, "categories": "cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As open-ended learning based on divergent search algorithms such as Novelty\nSearch (NS) draws more and more attention from the research community, it is\nnatural to expect that its application to increasingly complex real-world\nproblems will require the exploration to operate in higher dimensional Behavior\nSpaces which will not necessarily be Euclidean. Novelty Search traditionally\nrelies on k-nearest neighbours search and an archive of previously visited\nbehavior descriptors which are assumed to live in a Euclidean space. This is\nproblematic because of a number of issues. On one hand, Euclidean distance and\nNearest-neighbour search are known to behave differently and become less\nmeaningful in high dimensional spaces. On the other hand, the archive has to be\nbounded since, memory considerations aside, the computational complexity of\nfinding nearest neighbours in that archive grows linearithmically with its\nsize. A sub-optimal bound can result in \"cycling\" in the behavior space, which\ninhibits the progress of the exploration. Furthermore, the performance of NS\ndepends on a number of algorithmic choices and hyperparameters, such as the\nstrategies to add or remove elements to the archive and the number of\nneighbours to use in k-nn search. In this paper, we discuss an alternative\napproach to novelty estimation, dubbed Behavior Recognition based Novelty\nSearch (BR-NS), which does not require an archive, makes no assumption on the\nmetrics that can be defined in the behavior space and does not rely on nearest\nneighbours search. We conduct experiments to gain insight into its feasibility\nand dynamics as well as potential advantages over archive-based NS in terms of\ntime complexity.\n", "versions": [{"version": "v1", "created": "Thu, 8 Apr 2021 17:31:34 GMT"}], "update_date": "2021-04-09", "authors_parsed": [["Salehi", "Achkan", ""], ["Coninx", "Alexandre", ""], ["Doncieux", "Stephane", ""]]}, {"id": "2104.03946", "submitter": "David Lindner", "authors": "David Lindner, Rohin Shah, Pieter Abbeel, Anca Dragan", "title": "Learning What To Do by Simulating the Past", "comments": "Presented at ICLR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Since reward functions are hard to specify, recent work has focused on\nlearning policies from human feedback. However, such approaches are impeded by\nthe expense of acquiring such feedback. Recent work proposed that agents have\naccess to a source of information that is effectively free: in any environment\nthat humans have acted in, the state will already be optimized for human\npreferences, and thus an agent can extract information about what humans want\nfrom the state. Such learning is possible in principle, but requires simulating\nall possible past trajectories that could have led to the observed state. This\nis feasible in gridworlds, but how do we scale it to complex tasks? In this\nwork, we show that by combining a learned feature encoder with learned inverse\nmodels, we can enable agents to simulate human actions backwards in time to\ninfer what they must have done. The resulting algorithm is able to reproduce a\nspecific skill in MuJoCo environments given a single state sampled from the\noptimal policy for that skill.\n", "versions": [{"version": "v1", "created": "Thu, 8 Apr 2021 17:43:29 GMT"}, {"version": "v2", "created": "Mon, 3 May 2021 10:51:40 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Lindner", "David", ""], ["Shah", "Rohin", ""], ["Abbeel", "Pieter", ""], ["Dragan", "Anca", ""]]}, {"id": "2104.03952", "submitter": "Niv Cohen", "authors": "Niv Cohen and Yedid Hoshen", "title": "The Single-Noun Prior for Image Clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Self-supervised clustering methods have achieved increasing accuracy in\nrecent years but do not yet perform as well as supervised classification\nmethods. This contrasts with the situation for feature learning, where\nself-supervised features have recently surpassed the performance of supervised\nfeatures on several important tasks. We hypothesize that the performance gap is\ndue to the difficulty of specifying, without supervision, which features\ncorrespond to class differences that are semantic to humans. To reduce the\nperformance gap, we introduce the \"single-noun\" prior - which states that\nsemantic clusters tend to correspond to concepts that humans label by a\nsingle-noun. By utilizing a pre-trained network that maps images and sentences\ninto a common space, we impose this prior obtaining a constrained optimization\ntask. We show that our formulation is a special case of the facility location\nproblem, and introduce a simple-yet-effective approach for solving this\noptimization task at scale. We test our approach on several commonly reported\nimage clustering datasets and obtain significant accuracy gains over the best\nexisting approaches.\n", "versions": [{"version": "v1", "created": "Thu, 8 Apr 2021 17:54:37 GMT"}], "update_date": "2021-04-09", "authors_parsed": [["Cohen", "Niv", ""], ["Hoshen", "Yedid", ""]]}, {"id": "2104.03956", "submitter": "Sean Segal", "authors": "Sean Segal, Nishanth Kumar, Sergio Casas, Wenyuan Zeng, Mengye Ren,\n  Jingkang Wang, Raquel Urtasun", "title": "Just Label What You Need: Fine-Grained Active Selection for Perception\n  and Prediction through Partially Labeled Scenes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Self-driving vehicles must perceive and predict the future positions of\nnearby actors in order to avoid collisions and drive safely. A learned deep\nlearning module is often responsible for this task, requiring large-scale,\nhigh-quality training datasets. As data collection is often significantly\ncheaper than labeling in this domain, the decision of which subset of examples\nto label can have a profound impact on model performance. Active learning\ntechniques, which leverage the state of the current model to iteratively select\nexamples for labeling, offer a promising solution to this problem. However,\ndespite the appeal of this approach, there has been little scientific analysis\nof active learning approaches for the perception and prediction (P&P) problem.\nIn this work, we study active learning techniques for P&P and find that the\ntraditional active learning formulation is ill-suited for the P&P setting. We\nthus introduce generalizations that ensure that our approach is both cost-aware\nand allows for fine-grained selection of examples through partially labeled\nscenes. Our experiments on a real-world, large-scale self-driving dataset\nsuggest that fine-grained selection can improve the performance across\nperception, prediction, and downstream planning tasks.\n", "versions": [{"version": "v1", "created": "Thu, 8 Apr 2021 17:57:41 GMT"}], "update_date": "2021-04-09", "authors_parsed": [["Segal", "Sean", ""], ["Kumar", "Nishanth", ""], ["Casas", "Sergio", ""], ["Zeng", "Wenyuan", ""], ["Ren", "Mengye", ""], ["Wang", "Jingkang", ""], ["Urtasun", "Raquel", ""]]}, {"id": "2104.03958", "submitter": "Piyawat Lertvittayakumjorn", "authors": "Piyawat Lertvittayakumjorn, Leshem Choshen, Eyal Shnarch, Francesca\n  Toni", "title": "GrASP: A Library for Extracting and Exploring Human-Interpretable\n  Textual Patterns", "comments": "4 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data exploration is an important step of every data science and machine\nlearning project, including those involving textual data. We provide a Python\nlibrary for GrASP, an existing algorithm for drawing patterns from textual\ndata. The library is equipped with a web-based interface empowering human users\nto conveniently explore the data and the extracted patterns. We also\ndemonstrate the use of the library in two settings (spam detection and argument\nmining) and discuss future deployments of the library, e.g., beyond textual\ndata exploration.\n", "versions": [{"version": "v1", "created": "Thu, 8 Apr 2021 17:58:03 GMT"}], "update_date": "2021-04-09", "authors_parsed": [["Lertvittayakumjorn", "Piyawat", ""], ["Choshen", "Leshem", ""], ["Shnarch", "Eyal", ""], ["Toni", "Francesca", ""]]}, {"id": "2104.03961", "submitter": "Jingkai Yan", "authors": "Jingkai Yan, Mariam Avagyan, Robert E. Colgan, Do\\u{g}a Veske, Imre\n  Bartos, John Wright, Zsuzsa M\\'arka, Szabolcs M\\'arka", "title": "Generalized Approach to Matched Filtering using Neural Networks", "comments": "18 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "astro-ph.IM astro-ph.HE cs.LG gr-qc", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gravitational wave science is a pioneering field with rapidly evolving data\nanalysis methodology currently assimilating and inventing deep learning\ntechniques. The bulk of the sophisticated flagship searches of the field rely\non the time-tested matched filtering principle within their core. In this\npaper, we make a key observation on the relationship between the emerging deep\nlearning and the traditional techniques: matched filtering is formally\nequivalent to a particular neural network. This means that a neural network can\nbe constructed analytically to exactly implement matched filtering, and can be\nfurther trained on data or boosted with additional complexity for improved\nperformance. This fundamental equivalence allows us to define a \"complexity\nstandard candle\" allowing us to characterize the relative complexity of the\ndifferent approaches to gravitational wave signals in a common framework.\nAdditionally it also provides a glimpse of an intriguing symmetry that could\nprovide clues on how neural networks approach the problem of finding signals in\noverwhelming noise. Moreover, we show that the proposed neural network\narchitecture can outperform matched filtering, both with or without knowledge\nof a prior on the parameter distribution. When a prior is given, the proposed\nneural network can approach the statistically optimal performance. We also\npropose and investigate two different neural network architectures MNet-Shallow\nand MNet-Deep, both of which implement matched filtering at initialization and\ncan be trained on data. MNet-Shallow has simpler structure, while MNet-Deep is\nmore flexible and can deal with a wider range of distributions. Our theoretical\nfindings are corroborated by experiments using real LIGO data and synthetic\ninjections. Finally, our results suggest new perspectives on the role of deep\nlearning in gravitational wave detection.\n", "versions": [{"version": "v1", "created": "Thu, 8 Apr 2021 17:59:07 GMT"}], "update_date": "2021-04-09", "authors_parsed": [["Yan", "Jingkai", ""], ["Avagyan", "Mariam", ""], ["Colgan", "Robert E.", ""], ["Veske", "Do\u011fa", ""], ["Bartos", "Imre", ""], ["Wright", "John", ""], ["M\u00e1rka", "Zsuzsa", ""], ["M\u00e1rka", "Szabolcs", ""]]}, {"id": "2104.03986", "submitter": "Arjit Jain", "authors": "Arjit Jain, Sunita Sarawagi, Prithviraj Sen", "title": "Deep Indexed Active Learning for Matching Heterogeneous Entity\n  Representations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given two large lists of records, the task in entity resolution (ER) is to\nfind the pairs from the Cartesian product of the lists that correspond to the\nsame real world entity. Typically, passive learning methods on tasks like ER\nrequire large amounts of labeled data to yield useful models. Active Learning\nis a promising approach for ER in low resource settings. However, the search\nspace, to find informative samples for the user to label, grows quadratically\nfor instance-pair tasks making active learning hard to scale. Previous works,\nin this setting, rely on hand-crafted predicates, pre-trained language model\nembeddings, or rule learning to prune away unlikely pairs from the Cartesian\nproduct. This blocking step can miss out on important regions in the product\nspace leading to low recall. We propose DIAL, a scalable active learning\napproach that jointly learns embeddings to maximize recall for blocking and\naccuracy for matching blocked pairs. DIAL uses an Index-By-Committee framework,\nwhere each committee member learns representations based on powerful\ntransformer models. We highlight surprising differences between the matcher and\nthe blocker in the creation of the training data and the objective used to\ntrain their parameters. Experiments on five benchmark datasets and a\nmultilingual record matching dataset show the effectiveness of our approach in\nterms of precision, recall and running time. Code is available at\nhttps://github.com/ArjitJ/DIAL\n", "versions": [{"version": "v1", "created": "Thu, 8 Apr 2021 18:00:19 GMT"}], "update_date": "2021-04-12", "authors_parsed": [["Jain", "Arjit", ""], ["Sarawagi", "Sunita", ""], ["Sen", "Prithviraj", ""]]}, {"id": "2104.04000", "submitter": "Callie Hao", "authors": "Cong Hao, Deming Chen", "title": "Software/Hardware Co-design for Multi-modal Multi-task Learning in\n  Autonomous Systems", "comments": "Invited paper at IEEE AICAS 2021, 5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optimizing the quality of result (QoR) and the quality of service (QoS) of\nAI-empowered autonomous systems simultaneously is very challenging. First,\nthere are multiple input sources, e.g., multi-modal data from different\nsensors, requiring diverse data preprocessing, sensor fusion, and feature\naggregation. Second, there are multiple tasks that require various AI models to\nrun simultaneously, e.g., perception, localization, and control. Third, the\ncomputing and control system is heterogeneous, composed of hardware components\nwith varied features, such as embedded CPUs, GPUs, FPGAs, and dedicated\naccelerators. Therefore, autonomous systems essentially require multi-modal\nmulti-task (MMMT) learning which must be aware of hardware performance and\nimplementation strategies. While MMMT learning has been attracting intensive\nresearch interests, its applications in autonomous systems are still\nunderexplored. In this paper, we first discuss the opportunities of applying\nMMMT techniques in autonomous systems and then discuss the unique challenges\nthat must be solved. In addition, we discuss the necessity and opportunities of\nMMMT model and hardware co-design, which is critical for autonomous systems\nespecially with power/resource-limited or heterogeneous platforms. We formulate\nthe MMMT model and heterogeneous hardware implementation co-design as a\ndifferentiable optimization problem, with the objective of improving the\nsolution quality and reducing the overall power consumption and critical path\nlatency. We advocate for further explorations of MMMT in autonomous systems and\nsoftware/hardware co-design solutions.\n", "versions": [{"version": "v1", "created": "Thu, 8 Apr 2021 18:29:30 GMT"}], "update_date": "2021-04-12", "authors_parsed": [["Hao", "Cong", ""], ["Chen", "Deming", ""]]}, {"id": "2104.04004", "submitter": "Pawel Wawrzynski", "authors": "Pawe{\\l} Wawrzy\\'nski, Jakub {\\L}yskawa", "title": "ACERAC: Efficient reinforcement learning in fine time discretization", "comments": "Submitted to Neural Networks. arXiv admin note: text overlap with\n  arXiv:2009.04777", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a framework for reinforcement learning (RL) in fine time\ndiscretization and a learning algorithm in this framework. One of the main\ngoals of RL is to provide a way for physical machines to learn optimal behavior\ninstead of being programmed. However, the machines are usually controlled in\nfine time discretization. The most common RL methods apply independent random\nelements to each action, which is not suitable in that setting. It is not\nfeasible because it causes the controlled system to jerk, and does not ensure\nsufficient exploration since a single action is not long enough to create a\nsignificant experience that could be translated into policy improvement. In the\nRL framework introduced in this paper, policies are considered that produce\nactions based on states and random elements autocorrelated in subsequent time\ninstants. The RL algorithm introduced here approximately optimizes such a\npolicy. The efficiency of this algorithm is verified against three other RL\nmethods (PPO, SAC, ACER) in four simulated learning control problems (Ant,\nHalfCheetah, Hopper, and Walker2D) in diverse time discretization. The\nalgorithm introduced here outperforms the competitors in most cases considered.\n", "versions": [{"version": "v1", "created": "Thu, 8 Apr 2021 18:40:20 GMT"}], "update_date": "2021-04-12", "authors_parsed": [["Wawrzy\u0144ski", "Pawe\u0142", ""], ["\u0141yskawa", "Jakub", ""]]}, {"id": "2104.04013", "submitter": "Mohamed Ibrahim", "authors": "Mohamed R. Ibrahim, James Haworth, Nicola Christie", "title": "Re-designing cities with conditional adversarial networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  This paper introduces a conditional generative adversarial network to\nredesign a street-level image of urban scenes by generating 1) an urban\nintervention policy, 2) an attention map that localises where intervention is\nneeded, 3) a high-resolution street-level image (1024 X 1024 or 1536 X1536)\nafter implementing the intervention. We also introduce a new dataset that\ncomprises aligned street-level images of before and after urban interventions\nfrom real-life scenarios that make this research possible. The introduced\nmethod has been trained on different ranges of urban interventions applied to\nrealistic images. The trained model shows strong performance in re-modelling\ncities, outperforming existing methods that apply image-to-image translation in\nother domains that is computed in a single GPU. This research opens the door\nfor machine intelligence to play a role in re-thinking and re-designing the\ndifferent attributes of cities based on adversarial learning, going beyond the\nmainstream of facial landmarks manipulation or image synthesis from semantic\nsegmentation.\n", "versions": [{"version": "v1", "created": "Thu, 8 Apr 2021 19:03:34 GMT"}, {"version": "v2", "created": "Wed, 14 Apr 2021 09:43:26 GMT"}], "update_date": "2021-04-15", "authors_parsed": [["Ibrahim", "Mohamed R.", ""], ["Haworth", "James", ""], ["Christie", "Nicola", ""]]}, {"id": "2104.04017", "submitter": "Sumit Bhattacharya", "authors": "Sumit Bhattacharya, Devanshu Arya, Debjani Bhowmick, Rajat Mani\n  Thomas, Deepak Kumar Gupta", "title": "Improving Solar Cell Metallization Designs using Convolutional Neural\n  Networks", "comments": "Published as a workshop paper at ICLR 2021 SimDL Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optimizing the design of solar cell metallizations is one of the ways to\nimprove the performance of solar cells. Recently, it has been shown that\nTopology Optimization (TO) can be used to design complex metallization patterns\nfor solar cells that lead to improved performance. TO generates unconventional\ndesign patterns that cannot be obtained with the traditional shape optimization\nmethods. In this paper, we show that this design process can be improved\nfurther using a deep learning inspired strategy. We present SolarNet, a\nCNN-based reparameterization scheme that can be used to obtain improved\nmetallization designs. SolarNet modifies the optimization domain such that\nrather than optimizing the electrode material distribution directly, the\nweights of a CNN model are optimized. The design generated by CNN is then\nevaluated using the physics equations, which in turn generates gradients for\nbackpropagation. SolarNet is trained end-to-end involving backpropagation\nthrough the solar cell model as well as the CNN pipeline. Through application\non solar cells of different shapes as well as different busbar geometries, we\ndemonstrate that SolarNet improves the performance of solar cells compared to\nthe traditional TO approach.\n", "versions": [{"version": "v1", "created": "Thu, 8 Apr 2021 19:24:45 GMT"}], "update_date": "2021-04-12", "authors_parsed": [["Bhattacharya", "Sumit", ""], ["Arya", "Devanshu", ""], ["Bhowmick", "Debjani", ""], ["Thomas", "Rajat Mani", ""], ["Gupta", "Deepak Kumar", ""]]}, {"id": "2104.04026", "submitter": "Petr M\\'anek", "authors": "Petr M\\'anek (1 and 2), Graham Van Goffrier (1), Vignesh Gopakumar\n  (3), Nikolaos Nikolaou (1), Jonathan Shimwell (3) and Ingo Waldmann (1) ((1)\n  Department of Physics and Astronomy, University College London, London, UK,\n  (2) Institute of Experimental and Applied Physics, Czech Technical\n  University, Prague, Czech Republic, (3) UK Atomic Energy Authority, Culham\n  Science Centre, Abingdon, UK)", "title": "Fast Regression of the Tritium Breeding Ratio in Fusion Reactors", "comments": "12 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.comp-ph cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The tritium breeding ratio (TBR) is an essential quantity for the design of\nmodern and next-generation D-T fueled nuclear fusion reactors. Representing the\nratio between tritium fuel generated in breeding blankets and fuel consumed\nduring reactor runtime, the TBR depends on reactor geometry and material\nproperties in a complex manner. In this work, we explored the training of\nsurrogate models to produce a cheap but high-quality approximation for a Monte\nCarlo TBR model in use at the UK Atomic Energy Authority. We investigated\npossibilities for dimensional reduction of its feature space, reviewed 9\nfamilies of surrogate models for potential applicability, and performed\nhyperparameter optimisation. Here we present the performance and scaling\nproperties of these models, the fastest of which, an artificial neural network,\ndemonstrated $R^2=0.985$ and a mean prediction time of $0.898\\ \\mu\\mathrm{s}$,\nrepresenting a relative speedup of $8\\cdot 10^6$ with respect to the expensive\nMC model. We further present a novel adaptive sampling algorithm,\nQuality-Adaptive Surrogate Sampling, capable of interfacing with any of the\nindividually studied surrogates. Our preliminary testing on a toy TBR theory\nhas demonstrated the efficacy of this algorithm for accelerating the surrogate\nmodelling process.\n", "versions": [{"version": "v1", "created": "Thu, 8 Apr 2021 19:55:42 GMT"}], "update_date": "2021-04-12", "authors_parsed": [["M\u00e1nek", "Petr", "", "1 and 2"], ["Van Goffrier", "Graham", ""], ["Gopakumar", "Vignesh", ""], ["Nikolaou", "Nikolaos", ""], ["Shimwell", "Jonathan", ""], ["Waldmann", "Ingo", ""]]}, {"id": "2104.04036", "submitter": "Matias Selser", "authors": "Matias Selser, Javier Kreiner, Manuel Maurette", "title": "Optimal Market Making by Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-fin.ST", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  We apply Reinforcement Learning algorithms to solve the classic quantitative\nfinance Market Making problem, in which an agent provides liquidity to the\nmarket by placing buy and sell orders while maximizing a utility function. The\noptimal agent has to find a delicate balance between the price risk of her\ninventory and the profits obtained by capturing the bid-ask spread. We design\nan environment with a reward function that determines an order relation between\npolicies equivalent to the original utility function. When comparing our agents\nwith the optimal solution and a benchmark symmetric agent, we find that the\nDeep Q-Learning algorithm manages to recover the optimal agent.\n", "versions": [{"version": "v1", "created": "Thu, 8 Apr 2021 20:13:21 GMT"}], "update_date": "2021-04-12", "authors_parsed": [["Selser", "Matias", ""], ["Kreiner", "Javier", ""], ["Maurette", "Manuel", ""]]}, {"id": "2104.04040", "submitter": "Paul Beaujean", "authors": "Paul Beaujean and Florian Sikora and Florian Yger", "title": "Scaling up graph homomorphism for classification via sampling", "comments": "17 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Feature generation is an open topic of investigation in graph machine\nlearning. In this paper, we study the use of graph homomorphism density\nfeatures as a scalable alternative to homomorphism numbers which retain similar\ntheoretical properties and ability to take into account inductive bias. For\nthis, we propose a high-performance implementation of a simple sampling\nalgorithm which computes additive approximations of homomorphism densities. In\nthe context of graph machine learning, we demonstrate in experiments that\nsimple linear models trained on sample homomorphism densities can achieve\nperformance comparable to graph neural networks on standard graph\nclassification datasets. Finally, we show in experiments on synthetic data that\nthis algorithm scales to very large graphs when implemented with Bloom filters.\n", "versions": [{"version": "v1", "created": "Thu, 8 Apr 2021 20:25:37 GMT"}], "update_date": "2021-04-12", "authors_parsed": [["Beaujean", "Paul", ""], ["Sikora", "Florian", ""], ["Yger", "Florian", ""]]}, {"id": "2104.04041", "submitter": "Jia Wang", "authors": "Jia Wang, Tong Sun, Benyuan Liu, Yu Cao, Hongwei Zhu", "title": "CLVSA: A Convolutional LSTM Based Variational Sequence-to-Sequence Model\n  with Attention for Predicting Trends of Financial Markets", "comments": "7 pages, Proceedings of the Twenty-Eighth International Joint\n  Conference on Artificial Intelligence (IJCAI-19)", "journal-ref": null, "doi": "10.24963/ijcai.2019/514", "report-no": null, "categories": "q-fin.ST cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Financial markets are a complex dynamical system. The complexity comes from\nthe interaction between a market and its participants, in other words, the\nintegrated outcome of activities of the entire participants determines the\nmarkets trend, while the markets trend affects activities of participants.\nThese interwoven interactions make financial markets keep evolving. Inspired by\nstochastic recurrent models that successfully capture variability observed in\nnatural sequential data such as speech and video, we propose CLVSA, a hybrid\nmodel that consists of stochastic recurrent networks, the sequence-to-sequence\narchitecture, the self- and inter-attention mechanism, and convolutional LSTM\nunits to capture variationally underlying features in raw financial trading\ndata. Our model outperforms basic models, such as convolutional neural network,\nvanilla LSTM network, and sequence-to-sequence model with attention, based on\nbacktesting results of six futures from January 2010 to December 2017. Our\nexperimental results show that, by introducing an approximate posterior, CLVSA\ntakes advantage of an extra regularizer based on the Kullback-Leibler\ndivergence to prevent itself from overfitting traps.\n", "versions": [{"version": "v1", "created": "Thu, 8 Apr 2021 20:31:04 GMT"}], "update_date": "2021-04-12", "authors_parsed": [["Wang", "Jia", ""], ["Sun", "Tong", ""], ["Liu", "Benyuan", ""], ["Cao", "Yu", ""], ["Zhu", "Hongwei", ""]]}, {"id": "2104.04046", "submitter": "Geoffrey McLachlan", "authors": "Daniel Ahfock, Geoffrey J. McLachlan", "title": "Semi-Supervised Learning of Classifiers from a Statistical Perspective:\n  A Brief Review", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  There has been increasing attention to semi-supervised learning (SSL)\napproaches in machine learning to forming a classifier in situations where the\ntraining data for a classifier consists of a limited number of classified\nobservations but a much larger number of unclassified observations. This is\nbecause the procurement of classified data can be quite costly due to high\nacquisition costs and subsequent financial, time, and ethical issues that can\narise in attempts to provide the true class labels for the unclassified data\nthat have been acquired. We provide here a review of statistical SSL approaches\nto this problem, focussing on the recent result that a classifier formed from a\npartially classified sample can actually have smaller expected error rate than\nthat if the sample were completely classified.\n", "versions": [{"version": "v1", "created": "Thu, 8 Apr 2021 20:41:57 GMT"}, {"version": "v2", "created": "Tue, 13 Apr 2021 03:36:15 GMT"}, {"version": "v3", "created": "Mon, 19 Jul 2021 03:08:08 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Ahfock", "Daniel", ""], ["McLachlan", "Geoffrey J.", ""]]}, {"id": "2104.04047", "submitter": "Mingao Yuan", "authors": "Mingao Yuan and Zuofeng Shang", "title": "Heterogeneous Dense Subhypergraph Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study the problem of testing the existence of a heterogeneous dense\nsubhypergraph. The null hypothesis corresponds to a heterogeneous\nErd\\\"{o}s-R\\'{e}nyi uniform random hypergraph and the alternative hypothesis\ncorresponds to a heterogeneous uniform random hypergraph that contains a dense\nsubhypergraph. We establish detection boundaries when the edge probabilities\nare known and construct an asymptotically powerful test for distinguishing the\nhypotheses. We also construct an adaptive test which does not involve edge\nprobabilities, and hence, is more practically useful.\n", "versions": [{"version": "v1", "created": "Thu, 8 Apr 2021 20:44:22 GMT"}], "update_date": "2021-04-12", "authors_parsed": [["Yuan", "Mingao", ""], ["Shang", "Zuofeng", ""]]}, {"id": "2104.04049", "submitter": "David Von Dollen", "authors": "David Von Dollen, Florian Neukart, Daniel Weimer, Thomas B\\\"ack", "title": "Quantum-Assisted Feature Selection for Vehicle Price Prediction Modeling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Within machine learning model evaluation regimes, feature selection is a\ntechnique to reduce model complexity and improve model performance in regards\nto generalization, model fit, and accuracy of prediction. However, the search\nover the space of features to find the subset of $k$ optimal features is a\nknown NP-Hard problem. In this work, we study metrics for encoding the\ncombinatorial search as a binary quadratic model, such as Generalized Mean\nInformation Coefficient and Pearson Correlation Coefficient in application to\nthe underlying regression problem of price prediction. We investigate\ntrade-offs in the form of run-times and model performance, of leveraging\nquantum-assisted vs. classical subroutines for the combinatorial search, using\nminimum redundancy maximal relevancy as the heuristic for our approach. We\nachieve accuracy scores of 0.9 (in the range of [0,1]) for finding optimal\nsubsets on synthetic data using a new metric that we define. We test and\ncross-validate predictive models on a real-world problem of price prediction,\nand show a performance improvement of mean absolute error scores for our\nquantum-assisted method $(1471.02 \\pm{135.6})$, vs. similar methodologies such\nas recursive feature elimination $(1678.3 \\pm{143.7})$. Our findings show that\nby leveraging quantum-assisted routines we find solutions that increase the\nquality of predictive model output while reducing the input dimensionality to\nthe learning algorithm on synthetic and real-world data.\n", "versions": [{"version": "v1", "created": "Thu, 8 Apr 2021 20:48:44 GMT"}, {"version": "v2", "created": "Mon, 17 May 2021 18:43:13 GMT"}], "update_date": "2021-05-19", "authors_parsed": [["Von Dollen", "David", ""], ["Neukart", "Florian", ""], ["Weimer", "Daniel", ""], ["B\u00e4ck", "Thomas", ""]]}, {"id": "2104.04050", "submitter": "Gaurav Bharaj", "authors": "Mahsa Elyasi, Gaurav Bharaj", "title": "Flavored Tacotron: Conditional Learning for Prosodic-linguistic Features", "comments": "5", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural sequence-to-sequence text-to-speech synthesis (TTS), such as\nTacotron-2, transforms text into high-quality speech. However, generating\nspeech with natural prosody still remains a challenge. Yasuda et. al. show that\nunlike natural speech, Tacotron-2's encoder doesn't fully represent prosodic\nfeatures (e.g. syllable stress in English) from characters, and result in flat\nfundamental frequency variations.\n  In this work, we propose a novel carefully designed strategy for conditioning\nTacotron-2 on two fundamental prosodic features in English -- stress syllable\nand pitch accent, that help achieve more natural prosody. To this end, we use\nof a classifier to learn these features in an end-to-end fashion, and apply\nfeature conditioning at three parts of Tacotron-2's Text-To-Mel Spectrogram:\npre-encoder, post-encoder, and intra-decoder. Further, we show that jointly\nconditioned features at pre-encoder and intra-decoder stages result in\nprosodically natural synthesized speech (vs. Tacotron-2), and allows the model\nto produce speech with more accurate pitch accent and stress patterns.\n  Quantitative evaluations show that our formulation achieves higher\nfundamental frequency contour correlation, and lower Mel Cepstral Distortion\nmeasure between synthesized and natural speech. And subjective evaluation shows\nthat the proposed method's Mean Opinion Score of 4.14 fairs higher than\nbaseline Tacotron-2, 3.91, when compared against natural speech (LJSpeech\ncorpus), 4.28.\n", "versions": [{"version": "v1", "created": "Thu, 8 Apr 2021 20:50:15 GMT"}], "update_date": "2021-04-12", "authors_parsed": [["Elyasi", "Mahsa", ""], ["Bharaj", "Gaurav", ""]]}, {"id": "2104.04059", "submitter": "Kamal Chandra Paul", "authors": "Md. Mokhlesur Rahman, Kamal Chandra Paul (Student Member, IEEE), Md.\n  Amjad Hossain, G. G. Md. NawazAli (Member, IEEE), Md. Shahinoor Rahman, and\n  Jean-Claude Thill", "title": "Machine Learning on the COVID-19 Pandemic, Human Mobility and Air\n  Quality: A Review", "comments": "Machine Learning, COVID_19, Pandemic", "journal-ref": null, "doi": "10.1109/ACCESS.2021.3079121", "report-no": null, "categories": "cs.CY cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The ongoing COVID-19 global pandemic is affecting every facet of human lives\n(e.g., public health, education, economy, transportation, and the environment).\nThis novel pandemic and citywide implemented lockdown measures are affecting\nvirus transmission, people's travel patterns, and air quality. Many studies\nhave been conducted to predict the COVID-19 diffusion, assess the impacts of\nthe pandemic on human mobility and air quality, and assess the impacts of\nlockdown measures on viral spread with a range of Machine Learning (ML)\ntechniques. This review study aims to analyze results from past research to\nunderstand the interactions among the COVID-19 pandemic, lockdown measures,\nhuman mobility, and air quality. The critical review of prior studies indicates\nthat urban form, people's socioeconomic and physical conditions, social\ncohesion, and social distancing measures significantly affect human mobility\nand COVID-19 transmission. during the COVID-19 pandemic, many people are\ninclined to use private transportation for necessary travel purposes to\nmitigate coronavirus-related health problems. This review study also noticed\nthat COVID-19 related lockdown measures significantly improve air quality by\nreducing the concentration of air pollutants, which in turn improves the\nCOVID-19 situation by reducing respiratory-related sickness and deaths of\npeople. It is argued that ML is a powerful, effective, and robust analytic\nparadigm to handle complex and wicked problems such as a global pandemic. This\nstudy also discusses policy implications, which will be helpful for\npolicymakers to take prompt actions to moderate the severity of the pandemic\nand improve urban environments by adopting data-driven analytic methods.\n", "versions": [{"version": "v1", "created": "Sat, 13 Mar 2021 10:08:24 GMT"}], "update_date": "2021-05-14", "authors_parsed": [["Rahman", "Md. Mokhlesur", "", "Student Member, IEEE"], ["Paul", "Kamal Chandra", "", "Student Member, IEEE"], ["Hossain", "Md. Amjad", "", "Member, IEEE"], ["NawazAli", "G. G. Md.", "", "Member, IEEE"], ["Rahman", "Md. Shahinoor", ""], ["Thill", "Jean-Claude", ""]]}, {"id": "2104.04072", "submitter": "Soaad Hossain Mr", "authors": "Soaad Hossain, Syed Ishtiaque Ahmed", "title": "Towards a New Participatory Approach for Designing Artificial\n  Intelligence and Data-Driven Technologies", "comments": "5 pages, 2 figures, accepted to Artificially Intelligent Technology\n  for the Margins workshop at Conference on Human Factors in Computing Systems\n  (CHI 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With there being many technical and ethical issues with artificial\nintelligence (AI) that involve marginalized communities, there is a growing\ninterest for design methods used with marginalized people that may be\ntransferable to the design of AI technologies. Participatory design (PD) is a\ndesign method that is often used with marginalized communities for the design\nof social development, policy, IT and other matters and solutions. However,\nthere are issues with the current PD, raising concerns when it is applied to\nthe design of technologies, including AI technologies. This paper argues for\nthe use of PD for the design of AI technologies, and introduces and proposes a\nnew PD, which we call agile participatory design, that not only can could be\nused for the design of AI and data-driven technologies, but also overcomes\nissues surrounding current PD and its use in the design of such technologies.\n", "versions": [{"version": "v1", "created": "Tue, 30 Mar 2021 23:36:25 GMT"}], "update_date": "2021-04-12", "authors_parsed": [["Hossain", "Soaad", ""], ["Ahmed", "Syed Ishtiaque", ""]]}, {"id": "2104.04074", "submitter": "Taha Yasseri", "authors": "Mary Sanford and Taha Yasseri", "title": "The Kaleidoscope of Privacy: Differences across French, German, UK, and\n  US GDPR Media Discourse", "comments": "Under Review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG cs.SI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Conceptions of privacy differ by culture. In the Internet age, digital tools\ncontinuously challenge the way users, technologists, and governments define,\nvalue, and protect privacy. National and supranational entities attempt to\nregulate privacy and protect data managed online. The European Union passed the\nGeneral Data Protection Regulation (GDPR), which took effect on 25 May 2018.\nThe research presented here draws on two years of media reporting on GDPR from\nFrench, German, UK, and US sources. We use the unsupervised machine learning\nmethod of topic modelling to compare the thematic structure of the news\narticles across time and geographic regions. Our work emphasises the relevance\nof regional differences regarding valuations of privacy and potential obstacles\nto the implementation of unilateral data protection regulation such as GDPR. We\nfind that the topics and trends over time in GDPR media coverage of the four\ncountries reflect the differences found across their traditional privacy\ncultures.\n", "versions": [{"version": "v1", "created": "Wed, 31 Mar 2021 12:46:23 GMT"}], "update_date": "2021-04-12", "authors_parsed": [["Sanford", "Mary", ""], ["Yasseri", "Taha", ""]]}, {"id": "2104.04075", "submitter": "Rohit Saluja Mr.", "authors": "Rohit Saluja, Avleen Malhi, Samanta Knapi\\v{c}, Kary Fr\\\"amling, Cicek\n  Cavdar", "title": "Towards a Rigorous Evaluation of Explainability for Multivariate Time\n  Series", "comments": "Journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Machine learning-based systems are rapidly gaining popularity and in-line\nwith that there has been a huge research surge in the field of explainability\nto ensure that machine learning models are reliable, fair, and can be held\nliable for their decision-making process. Explainable Artificial Intelligence\n(XAI) methods are typically deployed to debug black-box machine learning models\nbut in comparison to tabular, text, and image data, explainability in time\nseries is still relatively unexplored. The aim of this study was to achieve and\nevaluate model agnostic explainability in a time series forecasting problem.\nThis work focused on proving a solution for a digital consultancy company\naiming to find a data-driven approach in order to understand the effect of\ntheir sales related activities on the sales deals closed. The solution involved\nframing the problem as a time series forecasting problem to predict the sales\ndeals and the explainability was achieved using two novel model agnostic\nexplainability techniques, Local explainable model-agnostic explanations (LIME)\nand Shapley additive explanations (SHAP) which were evaluated using human\nevaluation of explainability. The results clearly indicate that the\nexplanations produced by LIME and SHAP greatly helped lay humans in\nunderstanding the predictions made by the machine learning model. The presented\nwork can easily be extended to any time\n", "versions": [{"version": "v1", "created": "Tue, 6 Apr 2021 17:16:36 GMT"}], "update_date": "2021-04-12", "authors_parsed": [["Saluja", "Rohit", ""], ["Malhi", "Avleen", ""], ["Knapi\u010d", "Samanta", ""], ["Fr\u00e4mling", "Kary", ""], ["Cavdar", "Cicek", ""]]}, {"id": "2104.04076", "submitter": "Omer Aydin", "authors": "\\\"Omer Aydin, Cem Ali Kandemir, Umut Kira\\c{c}, Feri\\c{s}tah\n  Dalkili\\c{c}", "title": "An artificial intelligence and Internet of things based automated\n  irrigation system", "comments": null, "journal-ref": "International Conference on Computer Technologies and Applications\n  in Food and Agriculture, 11-12 July 2019, Konya, Turkey. Pages:95-106", "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  It is not hard to see that the need for clean water is growing by considering\nthe decrease of the water sources day by day in the world. Potable fresh water\nis also used for irrigation, so it should be planned to decrease freshwater\nwastage. With the development of technology and the availability of cheaper and\nmore effective solutions, the efficiency of irrigation increased and the water\nloss can be reduced. In particular, Internet of things (IoT) devices has begun\nto be used in all areas. We can easily and precisely collect temperature,\nhumidity and mineral values from the irrigation field with the IoT devices and\nsensors. Most of the operations and decisions about irrigation are carried out\nby people. For people, it is hard to have all the real-time data such as\ntemperature, moisture and mineral levels in the decision-making process and\nmake decisions by considering them. People usually make decisions with their\nexperience. In this study, a wide range of information from the irrigation\nfield was obtained by using IoT devices and sensors. Data collected from IoT\ndevices and sensors sent via communication channels and stored on MongoDB. With\nthe help of Weka software, the data was normalized and the normalized data was\nused as a learning set. As a result of the examinations, a decision tree (J48)\nalgorithm with the highest accuracy was chosen and an artificial intelligence\nmodel was created. Decisions are used to manage operations such as starting,\nmaintaining and stopping the irrigation. The accuracy of the decisions was\nevaluated and the irrigation system was tested with the results. There are\noptions to manage, view the system remotely and manually and also see the\nsystem s decisions with the created mobile application.\n", "versions": [{"version": "v1", "created": "Thu, 1 Apr 2021 21:05:26 GMT"}], "update_date": "2021-04-12", "authors_parsed": [["Aydin", "\u00d6mer", ""], ["Kandemir", "Cem Ali", ""], ["Kira\u00e7", "Umut", ""], ["Dalkili\u00e7", "Feri\u015ftah", ""]]}, {"id": "2104.04078", "submitter": "Yuhang Gai", "authors": "Yuhang Gai, Jiuming Guo, Dan Wu, Ken Chen", "title": "Progressive extension of reinforcement learning action dimension for\n  asymmetric assembly tasks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning (RL) is always the preferred embodiment to construct\nthe control strategy of complex tasks, like asymmetric assembly tasks. However,\nthe convergence speed of reinforcement learning severely restricts its\npractical application. In this paper, the convergence is first accelerated by\ncombining RL and compliance control. Then a completely innovative progressive\nextension of action dimension (PEAD) mechanism is proposed to optimize the\nconvergence of RL algorithms. The PEAD method is verified in DDPG and PPO. The\nresults demonstrate the PEAD method will enhance the data-efficiency and\ntime-efficiency of RL algorithms as well as increase the stable reward, which\nprovides more potential for the application of RL.\n", "versions": [{"version": "v1", "created": "Tue, 6 Apr 2021 11:48:54 GMT"}], "update_date": "2021-04-12", "authors_parsed": [["Gai", "Yuhang", ""], ["Guo", "Jiuming", ""], ["Wu", "Dan", ""], ["Chen", "Ken", ""]]}, {"id": "2104.04080", "submitter": "Marvin Lerousseau", "authors": "Marvin Lerousseau", "title": "Design and implementation of an environment for Learning to Run a Power\n  Network (L2RPN)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This report summarizes work performed as part of an internship at INRIA, in\npartial requirement for the completion of a master degree in math and\ninformatics. The goal of the internship was to develop a software environment\nto simulate electricity transmission in a power grid and actions performed by\noperators to maintain this grid in security. Our environment lends itself to\nautomate the control of the power grid with reinforcement learning agents,\nassisting human operators. It is amenable to organizing benchmarks, including a\nchallenge in machine learning planned by INRIA and RTE for 2019. Our framework,\nbuilt on top of open-source libraries, is available at\nhttps://github.com/MarvinLer/pypownet. In this report we present intermediary\nresults and its usage in the context of a reinforcement learning game.\n", "versions": [{"version": "v1", "created": "Tue, 6 Apr 2021 13:31:11 GMT"}], "update_date": "2021-04-12", "authors_parsed": [["Lerousseau", "Marvin", ""]]}, {"id": "2104.04091", "submitter": "Gaurav Bharaj", "authors": "Eric Engelhart, Mahsa Elyasi, Gaurav Bharaj", "title": "Grapheme-to-Phoneme Transformer Model for Transfer Learning Dialects", "comments": "5", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Grapheme-to-Phoneme (G2P) models convert words to their phonetic\npronunciations. Classic G2P methods include rule-based systems and\npronunciation dictionaries, while modern G2P systems incorporate learning, such\nas, LSTM and Transformer-based attention models. Usually, dictionary-based\nmethods require significant manual effort to build, and have limited adaptivity\non unseen words. And transformer-based models require significant training\ndata, and do not generalize well, especially for dialects with limited data.\n  We propose a novel use of transformer-based attention model that can adapt to\nunseen dialects of English language, while using a small dictionary. We show\nthat our method has potential applications for accent transfer for\ntext-to-speech, and for building robust G2P models for dialects with limited\npronunciation dictionary size.\n  We experiment with two English dialects: Indian and British. A model trained\nfrom scratch using 1000 words from British English dictionary, with 14211 words\nheld out, leads to phoneme error rate (PER) of 26.877%, on a test set generated\nusing the full dictionary. The same model pretrained on CMUDict American\nEnglish dictionary, and fine-tuned on the same dataset leads to PER of 2.469%\non the test set.\n", "versions": [{"version": "v1", "created": "Thu, 8 Apr 2021 21:36:21 GMT"}], "update_date": "2021-04-12", "authors_parsed": [["Engelhart", "Eric", ""], ["Elyasi", "Mahsa", ""], ["Bharaj", "Gaurav", ""]]}, {"id": "2104.04103", "submitter": "Carlos Fern\\'andez-Lor\\'ia", "authors": "Carlos Fern\\'andez-Lor\\'ia and Foster Provost", "title": "Causal Decision Making and Causal Effect Estimation Are Not the Same...\n  and Why It Matters", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Causal decision making (CDM) at scale has become a routine part of business,\nand increasingly CDM is based on machine learning algorithms. For example,\nbusinesses often target offers, incentives, and recommendations with the goal\nof affecting consumer behavior. Recently, we have seen an acceleration of\nresearch related to CDM and to causal effect estimation (CEE) using machine\nlearned models. This article highlights an important perspective: CDM is not\nthe same as CEE, and counterintuitively, accurate CEE is not necessary for\naccurate CDM. Our experience is that this is not well understood by\npractitioners nor by most researchers. Technically, the estimand of interest is\ndifferent, and this has important implications both for modeling and for the\nuse of statistical models for CDM. We draw on recent research to highlight\nthree of these implications. (1) We should carefully consider the objective\nfunction of the causal machine learning, and if possible, we should optimize\nfor accurate \"treatment assignment\" rather than for accurate effect-size\nestimation. (2) Confounding does not have the same effect on CDM as it does on\nCEE. The upshot here is that for supporting CDM it may be just as good to learn\nwith confounded data as with unconfounded data. Finally, (3) causal statistical\nmodeling may not be necessary at all to support CDM, because there may be (and\nperhaps often is) a proxy target for statistical modeling that can do as well\nor better. This observation helps to explain at least one broad common CDM\npractice that seems \"wrong\" at first blush: the widespread use of non-causal\nmodels for targeting interventions. Our perspective is that these observations\nopen up substantial fertile ground for future research. Whether or not you\nshare our perspective completely, we hope we facilitate future research in this\narea by pointing to related articles from multiple contributing fields.\n", "versions": [{"version": "v1", "created": "Thu, 8 Apr 2021 22:50:54 GMT"}], "update_date": "2021-04-12", "authors_parsed": [["Fern\u00e1ndez-Lor\u00eda", "Carlos", ""], ["Provost", "Foster", ""]]}, {"id": "2104.04107", "submitter": "Liang Tong", "authors": "Liang Tong, Zhengzhang Chen, Jingchao Ni, Wei Cheng, Dongjin Song,\n  Haifeng Chen, Yevgeniy Vorobeychik", "title": "FACESEC: A Fine-grained Robustness Evaluation Framework for Face\n  Recognition Systems", "comments": "Accepted by CVPR'21", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present FACESEC, a framework for fine-grained robustness evaluation of\nface recognition systems. FACESEC evaluation is performed along four dimensions\nof adversarial modeling: the nature of perturbation (e.g., pixel-level or face\naccessories), the attacker's system knowledge (about training data and learning\narchitecture), goals (dodging or impersonation), and capability (tailored to\nindividual inputs or across sets of these). We use FACESEC to study five face\nrecognition systems in both closed-set and open-set settings, and to evaluate\nthe state-of-the-art approach for defending against physically realizable\nattacks on these. We find that accurate knowledge of neural architecture is\nsignificantly more important than knowledge of the training data in black-box\nattacks. Moreover, we observe that open-set face recognition systems are more\nvulnerable than closed-set systems under different types of attacks. The\nefficacy of attacks for other threat model variations, however, appears highly\ndependent on both the nature of perturbation and the neural network\narchitecture. For example, attacks that involve adversarial face masks are\nusually more potent, even against adversarially trained models, and the ArcFace\narchitecture tends to be more robust than the others.\n", "versions": [{"version": "v1", "created": "Thu, 8 Apr 2021 23:00:25 GMT"}], "update_date": "2021-04-12", "authors_parsed": [["Tong", "Liang", ""], ["Chen", "Zhengzhang", ""], ["Ni", "Jingchao", ""], ["Cheng", "Wei", ""], ["Song", "Dongjin", ""], ["Chen", "Haifeng", ""], ["Vorobeychik", "Yevgeniy", ""]]}, {"id": "2104.04110", "submitter": "Tianjian Meng", "authors": "Tianjian Meng, Xiaohan Chen, Yifan Jiang, Zhangyang Wang", "title": "A Design Space Study for LISTA and Beyond", "comments": "Published as a conference paper at ICLR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, great success has been witnessed in building\nproblem-specific deep networks from unrolling iterative algorithms, for solving\ninverse problems and beyond. Unrolling is believed to incorporate the\nmodel-based prior with the learning capacity of deep learning. This paper\nrevisits the role of unrolling as a design approach for deep networks: to what\nextent its resulting special architecture is superior, and can we find better?\nUsing LISTA for sparse recovery as a representative example, we conduct the\nfirst thorough design space study for the unrolled models. Among all possible\nvariations, we focus on extensively varying the connectivity patterns and\nneuron types, leading to a gigantic design space arising from LISTA. To\nefficiently explore this space and identify top performers, we leverage the\nemerging tool of neural architecture search (NAS). We carefully examine the\nsearched top architectures in a number of settings, and are able to discover\nnetworks that are consistently better than LISTA. We further present more\nvisualization and analysis to \"open the black box\", and find that the searched\ntop architectures demonstrate highly consistent and potentially transferable\npatterns. We hope our study to spark more reflections and explorations on how\nto better mingle model-based optimization prior and data-driven learning.\n", "versions": [{"version": "v1", "created": "Thu, 8 Apr 2021 23:01:52 GMT"}], "update_date": "2021-04-12", "authors_parsed": [["Meng", "Tianjian", ""], ["Chen", "Xiaohan", ""], ["Jiang", "Yifan", ""], ["Wang", "Zhangyang", ""]]}, {"id": "2104.04114", "submitter": "Yi Xu", "authors": "Yi Xu, Qi Qian, Hao Li, Rong Jin", "title": "A Theoretical Analysis of Learning with Noisily Labeled Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Noisy labels are very common in deep supervised learning. Although many\nstudies tend to improve the robustness of deep training for noisy labels, rare\nworks focus on theoretically explaining the training behaviors of learning with\nnoisily labeled data, which is a fundamental principle in understanding its\ngeneralization. In this draft, we study its two phenomena, clean data first and\nphase transition, by explaining them from a theoretical viewpoint.\nSpecifically, we first show that in the first epoch training, the examples with\nclean labels will be learned first. We then show that after the learning from\nclean data stage, continuously training model can achieve further improvement\nin testing error when the rate of corrupted class labels is smaller than a\ncertain threshold; otherwise, extensively training could lead to an increasing\ntesting error.\n", "versions": [{"version": "v1", "created": "Thu, 8 Apr 2021 23:40:02 GMT"}], "update_date": "2021-04-12", "authors_parsed": [["Xu", "Yi", ""], ["Qian", "Qi", ""], ["Li", "Hao", ""], ["Jin", "Rong", ""]]}, {"id": "2104.04123", "submitter": "Erkan Kayacan", "authors": "Erdal Kayacan, Erkan Kayacan, Herman Ramon, Okyay Kaynak and Wouter\n  Saeys", "title": "Towards Agrobots: Trajectory Control of an Autonomous Tractor Using\n  Type-2 Fuzzy Logic Controllers", "comments": null, "journal-ref": "IEEE/ASME Transactions on Mechatronics, vol. 20, no. 1, pp.\n  287-298, Feb. 2015", "doi": "10.1109/TMECH.2013.2291874.", "report-no": null, "categories": "cs.RO cs.AI cs.LG cs.SY eess.SY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Provision of some autonomous functions to an agricultural vehicle would\nlighten the job of the operator but in doing so, the accuracy should not be\nlost to still obtain an optimal yield. Autonomous navigation of an agricultural\nvehicle involves the control of different dynamic subsystems, such as the yaw\nangle dynamics and the longitudinal speed dynamics. In this study, a\nproportional-integral-derivative controller is used to control the longitudinal\nvelocity of the tractor. For the control of the yaw angle dynamics, a\nproportional-derivative controller works in parallel with a type-2 fuzzy neural\nnetwork. In such an arrangement, the former ensures the stability of the\nrelated subsystem, while the latter learns the system dynamics and becomes the\nleading controller. In this way, instead of modeling the interactions between\nthe subsystems prior to the design of model-based control, we develop a control\nalgorithm which learns the interactions online from the measured feedback\nerror. In addition to the control of the stated subsystems, a kinematic\ncontroller is needed to correct the errors in both the x- and the y- axis for\nthe trajectory tracking problem of the tractor. To demonstrate the real-time\nabilities of the proposed control scheme, an autonomous tractor is equipped\nwith the use of reasonably priced sensors and actuators. Experimental results\nshow the efficacy and efficiency of the proposed learning algorithm.\n", "versions": [{"version": "v1", "created": "Fri, 9 Apr 2021 00:46:23 GMT"}], "update_date": "2021-04-12", "authors_parsed": [["Kayacan", "Erdal", ""], ["Kayacan", "Erkan", ""], ["Ramon", "Herman", ""], ["Kaynak", "Okyay", ""], ["Saeys", "Wouter", ""]]}, {"id": "2104.04128", "submitter": "Pouya Pezeshkpour", "authors": "Pouya Pezeshkpour, Sarthak Jain, Byron C. Wallace and Sameer Singh", "title": "An Empirical Comparison of Instance Attribution Methods for NLP", "comments": "NAACL 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Widespread adoption of deep models has motivated a pressing need for\napproaches to interpret network outputs and to facilitate model debugging.\nInstance attribution methods constitute one means of accomplishing these goals\nby retrieving training instances that (may have) led to a particular\nprediction. Influence functions (IF; Koh and Liang 2017) provide machinery for\ndoing this by quantifying the effect that perturbing individual train instances\nwould have on a specific test prediction. However, even approximating the IF is\ncomputationally expensive, to the degree that may be prohibitive in many cases.\nMight simpler approaches (e.g., retrieving train examples most similar to a\ngiven test point) perform comparably? In this work, we evaluate the degree to\nwhich different potential instance attribution agree with respect to the\nimportance of training samples. We find that simple retrieval methods yield\ntraining instances that differ from those identified via gradient-based methods\n(such as IFs), but that nonetheless exhibit desirable characteristics similar\nto more complex attribution methods. Code for all methods and experiments in\nthis paper is available at:\nhttps://github.com/successar/instance_attributions_NLP.\n", "versions": [{"version": "v1", "created": "Fri, 9 Apr 2021 01:03:17 GMT"}], "update_date": "2021-04-12", "authors_parsed": [["Pezeshkpour", "Pouya", ""], ["Jain", "Sarthak", ""], ["Wallace", "Byron C.", ""], ["Singh", "Sameer", ""]]}, {"id": "2104.04132", "submitter": "Tyler Hayes", "authors": "Tyler L. Hayes, Giri P. Krishnan, Maxim Bazhenov, Hava T. Siegelmann,\n  Terrence J. Sejnowski, Christopher Kanan", "title": "Replay in Deep Learning: Current Approaches and Missing Biological\n  Elements", "comments": "Accepted for publication in the MIT Press journal of Neural\n  Computation", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Replay is the reactivation of one or more neural patterns, which are similar\nto the activation patterns experienced during past waking experiences. Replay\nwas first observed in biological neural networks during sleep, and it is now\nthought to play a critical role in memory formation, retrieval, and\nconsolidation. Replay-like mechanisms have been incorporated into deep\nartificial neural networks that learn over time to avoid catastrophic\nforgetting of previous knowledge. Replay algorithms have been successfully used\nin a wide range of deep learning methods within supervised, unsupervised, and\nreinforcement learning paradigms. In this paper, we provide the first\ncomprehensive comparison between replay in the mammalian brain and replay in\nartificial neural networks. We identify multiple aspects of biological replay\nthat are missing in deep learning systems and hypothesize how they could be\nutilized to improve artificial neural networks.\n", "versions": [{"version": "v1", "created": "Thu, 1 Apr 2021 15:19:08 GMT"}, {"version": "v2", "created": "Fri, 28 May 2021 21:01:25 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Hayes", "Tyler L.", ""], ["Krishnan", "Giri P.", ""], ["Bazhenov", "Maxim", ""], ["Siegelmann", "Hava T.", ""], ["Sejnowski", "Terrence J.", ""], ["Kanan", "Christopher", ""]]}, {"id": "2104.04141", "submitter": "Chunnnan Wang", "authors": "Chunnan Wang, Bozhou Chen, Geng Li, Hongzhi Wang", "title": "FL-AGCNS: Federated Learning Framework for Automatic Graph Convolutional\n  Network Search", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, some Neural Architecture Search (NAS) techniques are proposed for\nthe automatic design of Graph Convolutional Network (GCN) architectures. They\nbring great convenience to the use of GCN, but could hardly apply to the\nFederated Learning (FL) scenarios with distributed and private datasets, which\nlimit their applications. Moreover, they need to train many candidate GCN\nmodels from scratch, which is inefficient for FL. To address these challenges,\nwe propose FL-AGCNS, an efficient GCN NAS algorithm suitable for FL scenarios.\nFL-AGCNS designs a federated evolutionary optimization strategy to enable\ndistributed agents to cooperatively design powerful GCN models while keeping\npersonal information on local devices. Besides, it applies the GCN SuperNet and\na weight sharing strategy to speed up the evaluation of GCN models.\nExperimental results show that FL-AGCNS can find better GCN models in short\ntime under the FL framework, surpassing the state-of-the-arts NAS methods and\nGCN models.\n", "versions": [{"version": "v1", "created": "Fri, 9 Apr 2021 01:42:06 GMT"}], "update_date": "2021-04-12", "authors_parsed": [["Wang", "Chunnan", ""], ["Chen", "Bozhou", ""], ["Li", "Geng", ""], ["Wang", "Hongzhi", ""]]}, {"id": "2104.04144", "submitter": "Alfredo Carrillo MSc", "authors": "Alfredo Carrillo, Luis F. Cant\\'u and Alejandro Noriega", "title": "Individual Explanations in Machine Learning Models: A Survey for\n  Practitioners", "comments": "13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.AP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In recent years, the use of sophisticated statistical models that influence\ndecisions in domains of high societal relevance is on the rise. Although these\nmodels can often bring substantial improvements in the accuracy and efficiency\nof organizations, many governments, institutions, and companies are reluctant\nto their adoption as their output is often difficult to explain in\nhuman-interpretable ways. Hence, these models are often regarded as\nblack-boxes, in the sense that their internal mechanisms can be opaque to human\naudit. In real-world applications, particularly in domains where decisions can\nhave a sensitive impact--e.g., criminal justice, estimating credit scores,\ninsurance risk, health risks, etc.--model interpretability is desired.\nRecently, the academic literature has proposed a substantial amount of methods\nfor providing interpretable explanations to machine learning models. This\nsurvey reviews the most relevant and novel methods that form the\nstate-of-the-art for addressing the particular problem of explaining individual\ninstances in machine learning. It seeks to provide a succinct review that can\nguide data science and machine learning practitioners in the search for\nappropriate methods to their problem domain.\n", "versions": [{"version": "v1", "created": "Fri, 9 Apr 2021 01:46:34 GMT"}, {"version": "v2", "created": "Mon, 12 Apr 2021 02:46:34 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Carrillo", "Alfredo", ""], ["Cant\u00fa", "Luis F.", ""], ["Noriega", "Alejandro", ""]]}, {"id": "2104.04147", "submitter": "David Leslie", "authors": "David Leslie, Christopher Burr, Mhairi Aitken, Josh Cowls, Michael\n  Katell and Morgan Briggs", "title": "Artificial intelligence, human rights, democracy, and the rule of law: a\n  primer", "comments": null, "journal-ref": null, "doi": "10.5281/zenodo.4639743", "report-no": null, "categories": "cs.CY cs.AI cs.HC cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In September 2019, the Council of Europe's Committee of Ministers adopted the\nterms of reference for the Ad Hoc Committee on Artificial Intelligence (CAHAI).\nThe CAHAI is charged with examining the feasibility and potential elements of a\nlegal framework for the design, development, and deployment of AI systems that\naccord with Council of Europe standards across the interrelated areas of human\nrights, democracy, and the rule of law. As a first and necessary step in\ncarrying out this responsibility, the CAHAI's Feasibility Study, adopted by its\nplenary in December 2020, has explored options for an international legal\nresponse that fills existing gaps in legislation and tailors the use of binding\nand non-binding legal instruments to the specific risks and opportunities\npresented by AI systems. The Study examines how the fundamental rights and\nfreedoms that are already codified in international human rights law can be\nused as the basis for such a legal framework. The purpose of this primer is to\nintroduce the main concepts and principles presented in the CAHAI's Feasibility\nStudy for a general, non-technical audience. It also aims to provide some\nbackground information on the areas of AI innovation, human rights law,\ntechnology policy, and compliance mechanisms covered therein. In keeping with\nthe Council of Europe's commitment to broad multi-stakeholder consultations,\noutreach, and engagement, this primer has been designed to help facilitate the\nmeaningful and informed participation of an inclusive group of stakeholders as\nthe CAHAI seeks feedback and guidance regarding the essential issues raised by\nthe Feasibility Study.\n", "versions": [{"version": "v1", "created": "Fri, 2 Apr 2021 05:58:42 GMT"}], "update_date": "2021-04-12", "authors_parsed": [["Leslie", "David", ""], ["Burr", "Christopher", ""], ["Aitken", "Mhairi", ""], ["Cowls", "Josh", ""], ["Katell", "Michael", ""], ["Briggs", "Morgan", ""]]}, {"id": "2104.04148", "submitter": "Alfredo Carrillo MSc", "authors": "Alfredo Carrillo, Luis F. Cant\\'u, Luis Tejerina and Alejandro Noriega", "title": "Individual Explanations in Machine Learning Models: A Case Study on\n  Poverty Estimation", "comments": "15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.AP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Machine learning methods are being increasingly applied in sensitive societal\ncontexts, where decisions impact human lives. Hence it has become necessary to\nbuild capabilities for providing easily-interpretable explanations of models'\npredictions. Recently in academic literature, a vast number of explanations\nmethods have been proposed. Unfortunately, to our knowledge, little has been\ndocumented about the challenges machine learning practitioners most often face\nwhen applying them in real-world scenarios. For example, a typical procedure\nsuch as feature engineering can make some methodologies no longer applicable.\nThe present case study has two main objectives. First, to expose these\nchallenges and how they affect the use of relevant and novel explanations\nmethods. And second, to present a set of strategies that mitigate such\nchallenges, as faced when implementing explanation methods in a relevant\napplication domain -- poverty estimation and its use for prioritizing access to\nsocial policies.\n", "versions": [{"version": "v1", "created": "Fri, 9 Apr 2021 01:54:58 GMT"}, {"version": "v2", "created": "Mon, 12 Apr 2021 03:06:05 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Carrillo", "Alfredo", ""], ["Cant\u00fa", "Luis F.", ""], ["Tejerina", "Luis", ""], ["Noriega", "Alejandro", ""]]}, {"id": "2104.04162", "submitter": "Ademola Okerinde", "authors": "Ademola Okerinde and Lior Shamir and William Hsu and Tom Theis and\n  Nasik Nafi", "title": "eGAN: Unsupervised approach to class imbalance using transfer learning", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Class imbalance is an inherent problem in many machine learning\nclassification tasks. This often leads to trained models that are unusable for\nany practical purpose. In this study we explore an unsupervised approach to\naddress these imbalances by leveraging transfer learning from pre-trained image\nclassification models to encoder-based Generative Adversarial Network (eGAN).\nTo the best of our knowledge, this is the first work to tackle this problem\nusing GAN without needing to augment with synthesized fake images.\n  In the proposed approach we use the discriminator network to output a\nnegative or positive score. We classify as minority, test samples with negative\nscores and as majority those with positive scores. Our approach eliminates\nepistemic uncertainty in model predictions, as the P(minority) + P(majority)\nneed not sum up to 1. The impact of transfer learning and combinations of\ndifferent pre-trained image classification models at the generator and\ndiscriminator is also explored. Best result of 0.69 F1-score was obtained on\nCIFAR-10 classification task with imbalance ratio of 1:2500.\n  Our approach also provides a mechanism of thresholding the specificity or\nsensitivity of our machine learning system. Keywords: Class imbalance, Transfer\nLearning, GAN, nash equilibrium\n", "versions": [{"version": "v1", "created": "Fri, 9 Apr 2021 02:37:55 GMT"}], "update_date": "2021-04-12", "authors_parsed": [["Okerinde", "Ademola", ""], ["Shamir", "Lior", ""], ["Hsu", "William", ""], ["Theis", "Tom", ""], ["Nafi", "Nasik", ""]]}, {"id": "2104.04174", "submitter": "Wenzhen Huang", "authors": "Wenzhen Huang, Qiyue Yin, Junge Zhang, Kaiqi Huang", "title": "Learning to Reweight Imaginary Transitions for Model-Based Reinforcement\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Model-based reinforcement learning (RL) is more sample efficient than\nmodel-free RL by using imaginary trajectories generated by the learned dynamics\nmodel. When the model is inaccurate or biased, imaginary trajectories may be\ndeleterious for training the action-value and policy functions. To alleviate\nsuch problem, this paper proposes to adaptively reweight the imaginary\ntransitions, so as to reduce the negative effects of poorly generated\ntrajectories. More specifically, we evaluate the effect of an imaginary\ntransition by calculating the change of the loss computed on the real samples\nwhen we use the transition to train the action-value and policy functions.\nBased on this evaluation criterion, we construct the idea of reweighting each\nimaginary transition by a well-designed meta-gradient algorithm. Extensive\nexperimental results demonstrate that our method outperforms state-of-the-art\nmodel-based and model-free RL algorithms on multiple tasks. Visualization of\nour changing weights further validates the necessity of utilizing reweight\nscheme.\n", "versions": [{"version": "v1", "created": "Fri, 9 Apr 2021 03:13:35 GMT"}], "update_date": "2021-04-12", "authors_parsed": [["Huang", "Wenzhen", ""], ["Yin", "Qiyue", ""], ["Zhang", "Junge", ""], ["Huang", "Kaiqi", ""]]}, {"id": "2104.04179", "submitter": "Hisaichi Shibata", "authors": "Hisaichi Shibata, Shouhei Hanaoka, Yukihiro Nomura, Takahiro Nakao,\n  Tomomi Takenaga, Naoto Hayashi, Osamu Abe", "title": "X2CT-FLOW: Reconstruction of multiple volumetric chest computed\n  tomography images with different likelihoods from a uni- or biplanar chest\n  X-ray image using a flow-based generative model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose X2CT-FLOW for the reconstruction of volumetric chest computed\ntomography (CT) images from uni- or biplanar digitally reconstructed\nradiographs (DRRs) or chest X-ray (CXR) images on the basis of a flow-based\ndeep generative (FDG) model. With the adoption of X2CT-FLOW, all the\nreconstructed volumetric chest CT images satisfy the condition that each of\nthose projected onto each plane coincides with each input DRR or CXR image.\nMoreover, X2CT-FLOW can reconstruct multiple volumetric chest CT images with\ndifferent likelihoods. The volumetric chest CT images reconstructed from\nbiplanar DRRs showed good agreement with ground truth images in terms of the\nstructural similarity index (0.931 on average). Moreover, we show that\nX2CT-FLOW can actually reconstruct such multiple volumetric chest CT images\nfrom DRRs. Finally, we demonstrate that X2CT-FLOW can reconstruct multiple\nvolumetric chest CT images from a real uniplanar CXR image.\n", "versions": [{"version": "v1", "created": "Fri, 9 Apr 2021 03:30:27 GMT"}], "update_date": "2021-04-12", "authors_parsed": [["Shibata", "Hisaichi", ""], ["Hanaoka", "Shouhei", ""], ["Nomura", "Yukihiro", ""], ["Nakao", "Takahiro", ""], ["Takenaga", "Tomomi", ""], ["Hayashi", "Naoto", ""], ["Abe", "Osamu", ""]]}, {"id": "2104.04184", "submitter": "Firoj Alam", "authors": "Firoj Alam, Tanvirul Alam, Muhammad Imran, Ferda Ofli", "title": "Robust Training of Social Media Image Classification Models for Rapid\n  Disaster Response", "comments": "Social media images, Image Classification, Natural disasters, Crisis\n  Informatics, Deep learning. Extended version of arXiv:2011.08916. arXiv admin\n  note: substantial text overlap with arXiv:2011.08916", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CY cs.LG cs.SI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Images shared on social media help crisis managers gain situational awareness\nand assess incurred damages, among other response tasks. As the volume and\nvelocity of such content are typically high, real-time image classification has\nbecome an urgent need for a faster disaster response. Recent advances in\ncomputer vision and deep neural networks have enabled the development of models\nfor real-time image classification for a number of tasks, including detecting\ncrisis incidents, filtering irrelevant images, classifying images into specific\nhumanitarian categories, and assessing the severity of the damage. To develop\nrobust real-time models, it is necessary to understand the capability of the\npublicly available pre-trained models for these tasks, which remains to be\nunder-explored in the crisis informatics literature. In this study, we address\nsuch limitations by investigating ten different network architectures for four\ndifferent tasks using the largest publicly available datasets for these tasks.\nWe also explore various data augmentation strategies, semi-supervised\ntechniques, and a multitask learning setup. In our extensive experiments, we\nachieve promising results.\n", "versions": [{"version": "v1", "created": "Fri, 9 Apr 2021 04:30:04 GMT"}, {"version": "v2", "created": "Mon, 19 Jul 2021 12:56:08 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Alam", "Firoj", ""], ["Alam", "Tanvirul", ""], ["Imran", "Muhammad", ""], ["Ofli", "Ferda", ""]]}, {"id": "2104.04191", "submitter": "Jessica Yung", "authors": "Jessica Yung, Rob Romijnders, Alexander Kolesnikov, Lucas Beyer, Josip\n  Djolonga, Neil Houlsby, Sylvain Gelly, Mario Lucic, Xiaohua Zhai", "title": "SI-Score: An image dataset for fine-grained analysis of robustness to\n  object location, rotation and size", "comments": "4 pages (10 pages including references and appendix), 10 figures.\n  Accepted at the ICLR 2021 RobustML Workshop. arXiv admin note: text overlap\n  with arXiv:2007.08558", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Before deploying machine learning models it is critical to assess their\nrobustness. In the context of deep neural networks for image understanding,\nchanging the object location, rotation and size may affect the predictions in\nnon-trivial ways. In this work we perform a fine-grained analysis of robustness\nwith respect to these factors of variation using SI-Score, a synthetic dataset.\nIn particular, we investigate ResNets, Vision Transformers and CLIP, and\nidentify interesting qualitative differences between these.\n", "versions": [{"version": "v1", "created": "Fri, 9 Apr 2021 05:00:49 GMT"}], "update_date": "2021-04-12", "authors_parsed": [["Yung", "Jessica", ""], ["Romijnders", "Rob", ""], ["Kolesnikov", "Alexander", ""], ["Beyer", "Lucas", ""], ["Djolonga", "Josip", ""], ["Houlsby", "Neil", ""], ["Gelly", "Sylvain", ""], ["Lucic", "Mario", ""], ["Zhai", "Xiaohua", ""]]}, {"id": "2104.04194", "submitter": "Srividya Subramanian", "authors": "Sihem Amer-Yahia (2), Georgia Koutrika (1), Frederic Bastian (7),\n  Theofilos Belmpas (1), Martin Braschler (9), Ursin Brunner (9), Diego\n  Calvanese (8), Maximilian Fabricius (5), Orest Gkini (1), Catherine Kosten\n  (9), Davide Lanti (8), Antonis Litke (6), Hendrik L\\\"ucke-Tieke (3),\n  Francesco Alessandro Massucci (6), Tarcisio Mendes de Farias (7), Alessandro\n  Mosca (8), Francesco Multari (6), Nikolaos Papadakis (4), Dimitris\n  Papadopoulos (4), Yogendra Patil (2), Aur\\'elien Personnaz (2), Guillem Rull\n  (6), Ana Sima (7), Ellery Smith (9), Dimitrios Skoutas (1), Srividya\n  Subramanian (5), Guohui Xiao (8), Kurt Stockinger (9) ((1) Athena Research\n  Center, Greece, (2) CNRS, University Grenoble Alpes, France, (3) Fraunhofer\n  IGD, Germany, (4) Infili, Greece, (5) Max Planck Institute, Germany, (6)\n  SIRIS Academic, Spain, (7) SIB Swiss Institute of Bioinformatics,\n  Switzerland, (8) Free University of Bozen-Bolzano, Italy, (9) ZHAW Zurich\n  University of Applied Sciences, Switzerland)", "title": "INODE: Building an End-to-End Data Exploration System in Practice\n  [Extended Vision]", "comments": "8 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DB", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A full-fledged data exploration system must combine different access\nmodalities with a powerful concept of guiding the user in the exploration\nprocess, by being reactive and anticipative both for data discovery and for\ndata linking. Such systems are a real opportunity for our community to cater to\nusers with different domain and data science expertise. We introduce INODE --\nan end-to-end data exploration system -- that leverages, on the one hand,\nMachine Learning and, on the other hand, semantics for the purpose of Data\nManagement (DM). Our vision is to develop a classic unified, comprehensive\nplatform that provides extensive access to open datasets, and we demonstrate it\nin three significant use cases in the fields of Cancer Biomarker Reearch,\nResearch and Innovation Policy Making, and Astrophysics. INODE offers\nsustainable services in (a) data modeling and linking, (b) integrated query\nprocessing using natural language, (c) guidance, and (d) data exploration\nthrough visualization, thus facilitating the user in discovering new insights.\nWe demonstrate that our system is uniquely accessible to a wide range of users\nfrom larger scientific communities to the public. Finally, we briefly\nillustrate how this work paves the way for new research opportunities in DM.\n", "versions": [{"version": "v1", "created": "Fri, 9 Apr 2021 05:04:04 GMT"}], "update_date": "2021-04-12", "authors_parsed": [["Amer-Yahia", "Sihem", ""], ["Koutrika", "Georgia", ""], ["Bastian", "Frederic", ""], ["Belmpas", "Theofilos", ""], ["Braschler", "Martin", ""], ["Brunner", "Ursin", ""], ["Calvanese", "Diego", ""], ["Fabricius", "Maximilian", ""], ["Gkini", "Orest", ""], ["Kosten", "Catherine", ""], ["Lanti", "Davide", ""], ["Litke", "Antonis", ""], ["L\u00fccke-Tieke", "Hendrik", ""], ["Massucci", "Francesco Alessandro", ""], ["de Farias", "Tarcisio Mendes", ""], ["Mosca", "Alessandro", ""], ["Multari", "Francesco", ""], ["Papadakis", "Nikolaos", ""], ["Papadopoulos", "Dimitris", ""], ["Patil", "Yogendra", ""], ["Personnaz", "Aur\u00e9lien", ""], ["Rull", "Guillem", ""], ["Sima", "Ana", ""], ["Smith", "Ellery", ""], ["Skoutas", "Dimitrios", ""], ["Subramanian", "Srividya", ""], ["Xiao", "Guohui", ""], ["Stockinger", "Kurt", ""]]}, {"id": "2104.04195", "submitter": "Nadee Seneviratne", "authors": "Nadee Seneviratne, Carol Espy-Wilson", "title": "Speech based Depression Severity Level Classification Using a\n  Multi-Stage Dilated CNN-LSTM Model", "comments": "5 pages, submitted to Interspeech 2021. arXiv admin note: text\n  overlap with arXiv:2011.06739", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Speech based depression classification has gained immense popularity over the\nrecent years. However, most of the classification studies have focused on\nbinary classification to distinguish depressed subjects from non-depressed\nsubjects. In this paper, we formulate the depression classification task as a\nseverity level classification problem to provide more granularity to the\nclassification outcomes. We use articulatory coordination features (ACFs)\ndeveloped to capture the changes of neuromotor coordination that happens as a\nresult of psychomotor slowing, a necessary feature of Major Depressive\nDisorder. The ACFs derived from the vocal tract variables (TVs) are used to\ntrain a dilated Convolutional Neural Network based depression classification\nmodel to obtain segment-level predictions. Then, we propose a Recurrent Neural\nNetwork based approach to obtain session-level predictions from segment-level\npredictions. We show that strengths of the segment-wise classifier are\namplified when a session-wise classifier is trained on embeddings obtained from\nit. The model trained on ACFs derived from TVs show relative improvement of\n27.47% in Unweighted Average Recall (UAR) at the session-level classification\ntask, compared to the ACFs derived from Mel Frequency Cepstral Coefficients\n(MFCCs).\n", "versions": [{"version": "v1", "created": "Fri, 9 Apr 2021 05:10:08 GMT"}], "update_date": "2021-04-12", "authors_parsed": [["Seneviratne", "Nadee", ""], ["Espy-Wilson", "Carol", ""]]}, {"id": "2104.04199", "submitter": "Shiqian Ma", "authors": "Chao Zhang, Xiaojun Chen, Shiqian Ma", "title": "A Riemannian smoothing steepest descent method for non-Lipschitz\n  optimization on submanifolds", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.IT cs.LG eess.SP math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a Riemannian smoothing steepest descent method to\nminimize a nonconvex and non-Lipschitz function on submanifolds. The\ngeneralized subdifferentials on Riemannian manifold and the Riemannian gradient\nsub-consistency are defined and discussed. We prove that any accumulation point\nof the sequence generated by the Riemannian smoothing steepest descent method\nis a stationary point associated with the smoothing function employed in the\nmethod, which is necessary for the local optimality of the original\nnon-Lipschitz problem. Under the Riemannian gradient sub-consistency condition,\nwe also prove that any accumulation point is a Riemannian limiting stationary\npoint of the original non-Lipschitz problem. Numerical experiments are\nconducted to demonstrate the efficiency of the proposed method.\n", "versions": [{"version": "v1", "created": "Fri, 9 Apr 2021 05:38:28 GMT"}], "update_date": "2021-04-12", "authors_parsed": [["Zhang", "Chao", ""], ["Chen", "Xiaojun", ""], ["Ma", "Shiqian", ""]]}, {"id": "2104.04206", "submitter": "Sin Yong Tan", "authors": "Sin Yong Tan, Homagni Saha, Margarite Jacoby, Gregor P. Henze, Soumik\n  Sarkar", "title": "Granger Causality Based Hierarchical Time Series Clustering for State\n  Estimation", "comments": "6 pages, 6 figures, 1 table", "journal-ref": "IFAC-PapersOnLine 53 (2020) 524-529", "doi": "10.1016/j.ifacol.2020.12.324", "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Clustering is an unsupervised learning technique that is useful when working\nwith a large volume of unlabeled data. Complex dynamical systems in real life\noften entail data streaming from a large number of sources. Although it is\ndesirable to use all source variables to form accurate state estimates, it is\noften impractical due to large computational power requirements, and\nsufficiently robust algorithms to handle these cases are not common. We propose\na hierarchical time series clustering technique based on symbolic dynamic\nfiltering and Granger causality, which serves as a dimensionality reduction and\nnoise-rejection tool. Our process forms a hierarchy of variables in the\nmultivariate time series with clustering of relevant variables at each level,\nthus separating out noise and less relevant variables. A new distance metric\nbased on Granger causality is proposed and used for the time series clustering,\nas well as validated on empirical data sets. Experimental results from\noccupancy detection and building temperature estimation tasks show fidelity to\nthe empirical data sets while maintaining state-prediction accuracy with\nsubstantially reduced data dimensionality.\n", "versions": [{"version": "v1", "created": "Fri, 9 Apr 2021 06:14:54 GMT"}], "update_date": "2021-05-20", "authors_parsed": [["Tan", "Sin Yong", ""], ["Saha", "Homagni", ""], ["Jacoby", "Margarite", ""], ["Henze", "Gregor P.", ""], ["Sarkar", "Soumik", ""]]}, {"id": "2104.04244", "submitter": "Konstantin Donhauser", "authors": "Konstantin Donhauser, Mingqi Wu and Fanny Yang", "title": "How rotational invariance of common kernels prevents generalization in\n  high dimensions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Kernel ridge regression is well-known to achieve minimax optimal rates in\nlow-dimensional settings. However, its behavior in high dimensions is much less\nunderstood. Recent work establishes consistency for kernel regression under\ncertain assumptions on the ground truth function and the distribution of the\ninput data. In this paper, we show that the rotational invariance property of\ncommonly studied kernels (such as RBF, inner product kernels and\nfully-connected NTK of any depth) induces a bias towards low-degree polynomials\nin high dimensions. Our result implies a lower bound on the generalization\nerror for a wide range of distributions and various choices of the scaling for\nkernels with different eigenvalue decays. This lower bound suggests that\ngeneral consistency results for kernel ridge regression in high dimensions\nrequire a more refined analysis that depends on the structure of the kernel\nbeyond its eigenvalue decay.\n", "versions": [{"version": "v1", "created": "Fri, 9 Apr 2021 08:27:37 GMT"}], "update_date": "2021-04-12", "authors_parsed": [["Donhauser", "Konstantin", ""], ["Wu", "Mingqi", ""], ["Yang", "Fanny", ""]]}, {"id": "2104.04258", "submitter": "Tim Pearce", "authors": "Tim Pearce, Jun Zhu", "title": "Counter-Strike Deathmatch with Large-Scale Behavioural Cloning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes an AI agent that plays the popular first-person-shooter\n(FPS) video game `Counter-Strike; Global Offensive' (CSGO) from pixel input.\nThe agent, a deep neural network, matches the performance of the medium\ndifficulty built-in AI on the deathmatch game mode, whilst adopting a humanlike\nplay style. Unlike much prior work in games, no API is available for CSGO, so\nalgorithms must train and run in real-time. This limits the quantity of\non-policy data that can be generated, precluding many reinforcement learning\nalgorithms. Our solution uses behavioural cloning - training on a large noisy\ndataset scraped from human play on online servers (4 million frames, comparable\nin size to ImageNet), and a smaller dataset of high-quality expert\ndemonstrations. This scale is an order of magnitude larger than prior work on\nimitation learning in FPS games.\n", "versions": [{"version": "v1", "created": "Fri, 9 Apr 2021 09:12:12 GMT"}], "update_date": "2021-04-12", "authors_parsed": [["Pearce", "Tim", ""], ["Zhu", "Jun", ""]]}, {"id": "2104.04275", "submitter": "Cheol-Hui Min", "authors": "Cheol-Hui Min, Jinseok Bae, Junho Lee and Young Min Kim", "title": "GATSBI: Generative Agent-centric Spatio-temporal Object Interaction", "comments": "accepted to CVPR'2021 as an oral presentation. Code and video will be\n  released soon", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present GATSBI, a generative model that can transform a sequence of raw\nobservations into a structured latent representation that fully captures the\nspatio-temporal context of the agent's actions. In vision-based decision-making\nscenarios, an agent faces complex high-dimensional observations where multiple\nentities interact with each other. The agent requires a good scene\nrepresentation of the visual observation that discerns essential components and\nconsistently propagates along the time horizon. Our method, GATSBI, utilizes\nunsupervised object-centric scene representation learning to separate an active\nagent, static background, and passive objects. GATSBI then models the\ninteractions reflecting the causal relationships among decomposed entities and\npredicts physically plausible future states. Our model generalizes to a variety\nof environments where different types of robots and objects dynamically\ninteract with each other. We show GATSBI achieves superior performance on scene\ndecomposition and video prediction compared to its state-of-the-art\ncounterparts.\n", "versions": [{"version": "v1", "created": "Fri, 9 Apr 2021 09:45:00 GMT"}], "update_date": "2021-04-12", "authors_parsed": [["Min", "Cheol-Hui", ""], ["Bae", "Jinseok", ""], ["Lee", "Junho", ""], ["Kim", "Young Min", ""]]}, {"id": "2104.04282", "submitter": "Naiyan Wang", "authors": "Aoming Liu, Zehao Huang, Zhiwu Huang, Naiyan Wang", "title": "Direct Differentiable Augmentation Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data augmentation has been an indispensable tool to improve the performance\nof deep neural networks, however the augmentation can hardly transfer among\ndifferent tasks and datasets. Consequently, a recent trend is to adopt AutoML\ntechnique to learn proper augmentation policy without extensive hand-crafted\ntuning. In this paper, we propose an efficient differentiable search algorithm\ncalled Direct Differentiable Augmentation Search (DDAS). It exploits\nmeta-learning with one-step gradient update and continuous relaxation to the\nexpected training loss for efficient search. Our DDAS can achieve efficient\naugmentation search without relying on approximations such as Gumbel Softmax or\nsecond order gradient approximation. To further reduce the adverse effect of\nimproper augmentations, we organize the search space into a two level\nhierarchy, in which we first decide whether to apply augmentation, and then\ndetermine the specific augmentation policy. On standard image classification\nbenchmarks, our DDAS achieves state-of-the-art performance and efficiency\ntradeoff while reducing the search cost dramatically, e.g. 0.15 GPU hours for\nCIFAR-10. In addition, we also use DDAS to search augmentation for object\ndetection task and achieve comparable performance with AutoAugment, while being\n1000x faster.\n", "versions": [{"version": "v1", "created": "Fri, 9 Apr 2021 10:02:24 GMT"}], "update_date": "2021-04-12", "authors_parsed": [["Liu", "Aoming", ""], ["Huang", "Zehao", ""], ["Huang", "Zhiwu", ""], ["Wang", "Naiyan", ""]]}, {"id": "2104.04289", "submitter": "Atsushi Hanamoto", "authors": "Ryuji Imamura, Kohei Azuma, Atsushi Hanamoto, and Atsunori Kanemura", "title": "MLF-SC: Incorporating multi-layer features to sparse coding for anomaly\n  detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Anomalies in images occur in various scales from a small hole on a carpet to\na large stain. However, anomaly detection based on sparse coding, one of the\nwidely used anomaly detection methods, has an issue in dealing with anomalies\nthat are out of the patch size employed to sparsely represent images. A large\nanomaly can be considered normal if seen in a small scale, but it is not easy\nto determine a single scale (patch size) that works well for all images. Then,\nwe propose to incorporate multi-scale features to sparse coding and improve the\nperformance of anomaly detection. The proposed method, multi-layer feature\nsparse coding (MLF-SC), employs a neural network for feature extraction, and\nfeature maps from intermediate layers of the network are given to sparse\ncoding, whereas the standard sparse-coding-based anomaly detection method\ndirectly works on given images. We show that MLF-SC outperforms\nstate-of-the-art anomaly detection methods including those employing deep\nlearning. Our target data are the texture categories of the MVTec Anomaly\nDetection (MVTec AD) dataset, which is a modern benchmark dataset consisting of\nimages from the real world. Our idea can be a simple and practical option to\ndeal with practical data.\n", "versions": [{"version": "v1", "created": "Fri, 9 Apr 2021 10:20:34 GMT"}], "update_date": "2021-04-12", "authors_parsed": [["Imamura", "Ryuji", ""], ["Azuma", "Kohei", ""], ["Hanamoto", "Atsushi", ""], ["Kanemura", "Atsunori", ""]]}, {"id": "2104.04291", "submitter": "Heng Fang", "authors": "Heng Fang, Xi Yang, Taichi Kin, Takeo Igarashi", "title": "Brain Surface Reconstruction from MRI Images Based on Segmentation\n  Networks Applying Signed Distance Maps", "comments": "Accepted by IEEE ISBI 2021 (International Symposium on Biomedical\n  Imaging)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Whole-brain surface extraction is an essential topic in medical imaging\nsystems as it provides neurosurgeons with a broader view of surgical planning\nand abnormality detection. To solve the problem confronted in current deep\nlearning skull stripping methods lacking prior shape information, we propose a\nnew network architecture that incorporates knowledge of signed distance fields\nand introduce an additional Laplacian loss to ensure that the prediction\nresults retain shape information. We validated our newly proposed method by\nconducting experiments on our brain magnetic resonance imaging dataset (111\npatients). The evaluation results demonstrate that our approach achieves\ncomparable dice scores and also reduces the Hausdorff distance and average\nsymmetric surface distance, thus producing more stable and smooth brain\nisosurfaces.\n", "versions": [{"version": "v1", "created": "Fri, 9 Apr 2021 10:24:27 GMT"}], "update_date": "2021-04-12", "authors_parsed": [["Fang", "Heng", ""], ["Yang", "Xi", ""], ["Kin", "Taichi", ""], ["Igarashi", "Takeo", ""]]}, {"id": "2104.04295", "submitter": "Alexander Brenning", "authors": "Alexander Brenning", "title": "Transforming Feature Space to Interpret Machine Learning Models", "comments": "13 pages, 7 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Model-agnostic tools for interpreting machine-learning models struggle to\nsummarize the joint effects of strongly dependent features in high-dimensional\nfeature spaces, which play an important role in pattern recognition, for\nexample in remote sensing of landcover. This contribution proposes a novel\napproach that interprets machine-learning models through the lens of feature\nspace transformations. It can be used to enhance unconditional as well as\nconditional post-hoc diagnostic tools including partial dependence plots,\naccumulated local effects plots, or permutation feature importance assessments.\nWhile the approach can also be applied to nonlinear transformations, we focus\non linear ones, including principal component analysis (PCA) and a partial\northogonalization technique. Structured PCA and diagnostics along paths offer\nopportunities for representing domain knowledge. The new approach is\nimplemented in the R package `wiml`, which can be combined with existing\nexplainable machine-learning packages. A case study on remote-sensing landcover\nclassification with 46 features is used to demonstrate the potential of the\nproposed approach for model interpretation by domain experts.\n", "versions": [{"version": "v1", "created": "Fri, 9 Apr 2021 10:48:11 GMT"}], "update_date": "2021-04-12", "authors_parsed": [["Brenning", "Alexander", ""]]}, {"id": "2104.04298", "submitter": "Peter Vieting", "authors": "Peter Vieting, Christoph L\\\"uscher, Wilfried Michel, Ralf Schl\\\"uter,\n  Hermann Ney", "title": "Feature Replacement and Combination for Hybrid ASR Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Acoustic modeling of raw waveform and learning feature extractors as part of\nthe neural network classifier has been the goal of many studies in the area of\nautomatic speech recognition (ASR). Recently, one line of research has focused\non frameworks that can be pre-trained on audio-only data in an unsupervised\nfashion and aim at improving downstream ASR tasks. In this work, we investigate\nthe usefulness of one of these front-end frameworks, namely wav2vec, for hybrid\nASR systems. In addition to deploying a pre-trained feature extractor, we\nexplore how to make use of an existing acoustic model (AM) trained on the same\ntask with different features as well. Another neural front-end which is only\ntrained together with the supervised ASR loss as well as traditional Gammatone\nfeatures are applied for comparison. Moreover, it is shown that the AM can be\nretrofitted with i-vectors for speaker adaptation. Finally, the described\nfeatures are combined in order to further advance the performance. With the\nfinal best system, we obtain a relative improvement of 4% and 6% over our\nprevious best model on the LibriSpeech test-clean and test-other sets.\n", "versions": [{"version": "v1", "created": "Fri, 9 Apr 2021 11:04:58 GMT"}, {"version": "v2", "created": "Wed, 9 Jun 2021 21:42:32 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["Vieting", "Peter", ""], ["L\u00fcscher", "Christoph", ""], ["Michel", "Wilfried", ""], ["Schl\u00fcter", "Ralf", ""], ["Ney", "Hermann", ""]]}, {"id": "2104.04310", "submitter": "Michael Tarasiou", "authors": "Michail Tarasiou, Riza Alp Guler, Stefanos Zafeiriou", "title": "Context-self contrastive pretraining for crop type semantic segmentation", "comments": "11 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper we propose a fully-supervised pretraining scheme based on\ncontrastive learning particularly tailored to dense classification tasks. The\nproposed Context-Self Contrastive Loss (CSCL) learns an embedding space that\nmakes semantic boundaries pop-up by use of a similarity metric between every\nlocation in an training sample and its local context. For crop type semantic\nsegmentation from satellite images we find performance at parcel boundaries to\nbe a critical bottleneck and explain how CSCL tackles the underlying cause of\nthat problem, improving the state-of-the-art performance in this task.\nAdditionally, using images from the Sentinel-2 (S2) satellite missions we\ncompile the largest, to our knowledge, dataset of satellite image timeseries\ndensely annotated by crop type and parcel identities, which we make publicly\navailable together with the data generation pipeline. Using that data we find\nCSCL, even with minimal pretraining, to improve all respective baselines and\npresent a process for semantic segmentation at super-resolution for obtaining\ncrop classes at a more granular level. The proposed method is further validated\non the task of semantic segmentation on 2D and 3D volumetric images showing\nconsistent performance improvements upon competitive baselines.\n", "versions": [{"version": "v1", "created": "Fri, 9 Apr 2021 11:29:44 GMT"}], "update_date": "2021-04-12", "authors_parsed": [["Tarasiou", "Michail", ""], ["Guler", "Riza Alp", ""], ["Zafeiriou", "Stefanos", ""]]}, {"id": "2104.04323", "submitter": "Johannes H\\\"ohne", "authors": "Jonas Dippel, Steffen Vogler, Johannes H\\\"ohne", "title": "Towards Fine-grained Visual Representations by Combining Contrastive\n  Learning with Image Reconstruction and Attention-weighted Pooling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper presents Contrastive Reconstruction, ConRec - a self-supervised\nlearning algorithm that obtains image representations by jointly optimizing a\ncontrastive and a self-reconstruction loss. We showcase that state-of-the-art\ncontrastive learning methods (e.g. SimCLR) have shortcomings to capture\nfine-grained visual features in their representations. ConRec extends the\nSimCLR framework by adding (1) a self-reconstruction task and (2) an attention\nmechanism within the contrastive learning task. This is accomplished by\napplying a simple encoder-decoder architecture with two heads. We show that\nboth extensions contribute towards an improved vector representation for images\nwith fine-grained visual features. Combining those concepts, ConRec outperforms\nSimCLR and SimCLR with Attention-Pooling on fine-grained classification\ndatasets.\n", "versions": [{"version": "v1", "created": "Fri, 9 Apr 2021 12:12:10 GMT"}], "update_date": "2021-04-12", "authors_parsed": [["Dippel", "Jonas", ""], ["Vogler", "Steffen", ""], ["H\u00f6hne", "Johannes", ""]]}, {"id": "2104.04326", "submitter": "Hiske Overweg", "authors": "Hiske Overweg, Herman N.C. Berghuijs, Ioannis N. Athanasiadis", "title": "CropGym: a Reinforcement Learning Environment for Crop Management", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Nitrogen fertilizers have a detrimental effect on the environment, which can\nbe reduced by optimizing fertilizer management strategies. We implement an\nOpenAI Gym environment where a reinforcement learning agent can learn\nfertilization management policies using process-based crop growth models and\nidentify policies with reduced environmental impact. In our environment, an\nagent trained with the Proximal Policy Optimization algorithm is more\nsuccessful at reducing environmental impacts than the other baseline agents we\npresent.\n", "versions": [{"version": "v1", "created": "Fri, 9 Apr 2021 12:17:26 GMT"}, {"version": "v2", "created": "Fri, 23 Apr 2021 12:20:00 GMT"}], "update_date": "2021-04-26", "authors_parsed": [["Overweg", "Hiske", ""], ["Berghuijs", "Herman N. C.", ""], ["Athanasiadis", "Ioannis N.", ""]]}, {"id": "2104.04342", "submitter": "Pablo Budde Genannt Dohmann", "authors": "Pablo Budde gen. Dohmann, Armin Lederer, Marcel Di{\\ss}emond, Sandra\n  Hirche", "title": "Distributed Bayesian Online Learning for Cooperative Manipulation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For tasks where the dynamics of multiple agents are physically coupled, e.g.,\nin cooperative manipulation, the coordination between the individual agents\nbecomes crucial, which requires exact knowledge of the interaction dynamics.\nThis problem is typically addressed using centralized estimators, which can\nnegatively impact the flexibility and robustness of the overall system. To\novercome this shortcoming, we propose a novel distributed learning framework\nfor the exemplary task of cooperative manipulation using Bayesian principles.\nUsing only local state information each agent obtains an estimate of the object\ndynamics and grasp kinematics. These local estimates are combined using dynamic\naverage consensus. Due to the strong probabilistic foundation of the method,\neach estimate of the object dynamics and grasp kinematics is accompanied by a\nmeasure of uncertainty, which allows to guarantee a bounded prediction error\nwith high probability. Moreover, the Bayesian principles directly allow\niterative learning with constant complexity, such that the proposed learning\nmethod can be used online in real-time applications. The effectiveness of the\napproach is demonstrated in a simulated cooperative manipulation task.\n", "versions": [{"version": "v1", "created": "Fri, 9 Apr 2021 13:03:09 GMT"}], "update_date": "2021-04-12", "authors_parsed": [["Dohmann", "Pablo Budde gen.", ""], ["Lederer", "Armin", ""], ["Di\u00dfemond", "Marcel", ""], ["Hirche", "Sandra", ""]]}, {"id": "2104.04345", "submitter": "Josh Mitton Mr", "authors": "Joshua Mitton, Hans M. Senn, Klaas Wynne, Roderick Murray-Smith", "title": "A Graph VAE and Graph Transformer Approach to Generating Molecular\n  Graphs", "comments": "Graph Representation Learning and Beyond (GRL+) (ICML 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose a combination of a variational autoencoder and a transformer based\nmodel which fully utilises graph convolutional and graph pooling layers to\noperate directly on graphs. The transformer model implements a novel node\nencoding layer, replacing the position encoding typically used in transformers,\nto create a transformer with no position information that operates on graphs,\nencoding adjacent node properties into the edge generation process. The\nproposed model builds on graph generative work operating on graphs with edge\nfeatures, creating a model that offers improved scalability with the number of\nnodes in a graph. In addition, our model is capable of learning a disentangled,\ninterpretable latent space that represents graph properties through a mapping\nbetween latent variables and graph properties. In experiments we chose a\nbenchmark task of molecular generation, given the importance of both generated\nnode and edge features. Using the QM9 dataset we demonstrate that our model\nperforms strongly across the task of generating valid, unique and novel\nmolecules. Finally, we demonstrate that the model is interpretable by\ngenerating molecules controlled by molecular properties, and we then analyse\nand visualise the learned latent representation.\n", "versions": [{"version": "v1", "created": "Fri, 9 Apr 2021 13:13:06 GMT"}], "update_date": "2021-04-12", "authors_parsed": [["Mitton", "Joshua", ""], ["Senn", "Hans M.", ""], ["Wynne", "Klaas", ""], ["Murray-Smith", "Roderick", ""]]}, {"id": "2104.04348", "submitter": "Hacene Mellah", "authors": "Hacene Mellah, Kamel Eddine Hemsas, Rachid Taleb", "title": "Cascade-Forward Neural Network Based on Resilient Backpropagation for\n  Simultaneous Parameters and State Space Estimations of Brushed DC Machines", "comments": "arXiv admin note: text overlap with arXiv:1902.03171", "journal-ref": "Advances in Modelling and Analysis B(2021)", "doi": null, "report-no": null, "categories": "eess.SP cs.LG cs.SY eess.SY", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  A sensorless speed, average temperature and resistance estimation technique\nbased on Neural Network (NN) for brushed DC machines is proposed in this paper.\nThe literature on parameters and state spaces estimations of the Brushed DC\nmachines, shows a variety of approaches. However, these observers are sensitive\nto a noise, on the model accuracy also are difficult to stabilize and to\nconverge. Furthermore, the majority of earlier works, estimate either the speed\nor the temperature or the winding resistance. According to the literatures, the\nResilient backpropagation (RBP) as is the known as the faster BP algorithm,\nCascade-Forward Neural Network (CFNN), is known as the among accelerated\nlearning backpropagation algorithms, that's why where it is found in several\nresearches, also in several applications in these few years. The main objective\nof this paper is to introduce an intelligent sensor based on resilient BP to\nestimate simultaneously the speed, armature temperature and resistance of\nbrushed DC machines only from the measured current and voltage. A comparison\nbetween the obtained results and the results of traditional estimator has been\nmade to prove the ability of the proposed method. This method can be embedded\nin thermal monitoring systems, in high performance motor drives.\n", "versions": [{"version": "v1", "created": "Wed, 31 Mar 2021 08:56:14 GMT"}], "update_date": "2021-04-12", "authors_parsed": [["Mellah", "Hacene", ""], ["Hemsas", "Kamel Eddine", ""], ["Taleb", "Rachid", ""]]}, {"id": "2104.04353", "submitter": "Boris Ruf", "authors": "Boris Ruf, Marcin Detyniecki", "title": "Implementing Fair Regression In The Real World", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most fair regression algorithms mitigate bias towards sensitive sub\npopulations and therefore improve fairness at group level. In this paper, we\ninvestigate the impact of such implementation of fair regression on the\nindividual. More precisely, we assess the evolution of continuous predictions\nfrom an unconstrained to a fair algorithm by comparing results from baseline\nalgorithms with fair regression algorithms for the same data points. Based on\nour findings, we propose a set of post-processing algorithms to improve the\nutility of the existing fair regression approaches.\n", "versions": [{"version": "v1", "created": "Fri, 9 Apr 2021 13:31:16 GMT"}], "update_date": "2021-04-12", "authors_parsed": [["Ruf", "Boris", ""], ["Detyniecki", "Marcin", ""]]}, {"id": "2104.04359", "submitter": "David Noever", "authors": "David Noever, Samantha E. Miller Noever", "title": "Rock Hunting With Martian Machine Vision", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  The Mars Perseverance rover applies computer vision for navigation and hazard\navoidance. The challenge to do onboard object recognition highlights the need\nfor low-power, customized training, often including low-contrast backgrounds.\nWe investigate deep learning methods for the classification and detection of\nMartian rocks. We report greater than 97% accuracy for binary classifications\n(rock vs. rover). We fine-tune a detector to render geo-located bounding boxes\nwhile counting rocks. For these models to run on microcontrollers, we shrink\nand quantize the neural networks' weights and demonstrate a low-power rock\nhunter with faster frame rates (1 frame per second) but lower accuracy (37%).\n", "versions": [{"version": "v1", "created": "Fri, 9 Apr 2021 13:44:27 GMT"}], "update_date": "2021-04-12", "authors_parsed": [["Noever", "David", ""], ["Noever", "Samantha E. Miller", ""]]}, {"id": "2104.04377", "submitter": "Prithwish Chakraborty", "authors": "Prithwish Chakraborty, James Codella, Piyush Madan, Ying Li, Hu Huang,\n  Yoonyoung Park, Chao Yan, Ziqi Zhang, Cheng Gao, Steve Nyemba, Xu Min, Sanjib\n  Basak, Mohamed Ghalwash, Zach Shahn, Parthasararathy Suryanarayanan, Italo\n  Buleje, Shannon Harrer, Sarah Miller, Amol Rajmane, Colin Walsh, Jonathan\n  Wanderer, Gigi Yuen Reed, Kenney Ng, Daby Sow, Bradley A. Malin", "title": "Blending Knowledge in Deep Recurrent Networks for Adverse Event\n  Prediction at Hospital Discharge", "comments": "Presented at the AMIA 2021 Virtual Informatics Summit", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning architectures have an extremely high-capacity for modeling\ncomplex data in a wide variety of domains. However, these architectures have\nbeen limited in their ability to support complex prediction problems using\ninsurance claims data, such as readmission at 30 days, mainly due to data\nsparsity issue. Consequently, classical machine learning methods, especially\nthose that embed domain knowledge in handcrafted features, are often on par\nwith, and sometimes outperform, deep learning approaches. In this paper, we\nillustrate how the potential of deep learning can be achieved by blending\ndomain knowledge within deep learning architectures to predict adverse events\nat hospital discharge, including readmissions. More specifically, we introduce\na learning architecture that fuses a representation of patient data computed by\na self-attention based recurrent neural network, with clinically relevant\nfeatures. We conduct extensive experiments on a large claims dataset and show\nthat the blended method outperforms the standard machine learning approaches.\n", "versions": [{"version": "v1", "created": "Fri, 9 Apr 2021 14:07:45 GMT"}], "update_date": "2021-04-12", "authors_parsed": [["Chakraborty", "Prithwish", ""], ["Codella", "James", ""], ["Madan", "Piyush", ""], ["Li", "Ying", ""], ["Huang", "Hu", ""], ["Park", "Yoonyoung", ""], ["Yan", "Chao", ""], ["Zhang", "Ziqi", ""], ["Gao", "Cheng", ""], ["Nyemba", "Steve", ""], ["Min", "Xu", ""], ["Basak", "Sanjib", ""], ["Ghalwash", "Mohamed", ""], ["Shahn", "Zach", ""], ["Suryanarayanan", "Parthasararathy", ""], ["Buleje", "Italo", ""], ["Harrer", "Shannon", ""], ["Miller", "Sarah", ""], ["Rajmane", "Amol", ""], ["Walsh", "Colin", ""], ["Wanderer", "Jonathan", ""], ["Reed", "Gigi Yuen", ""], ["Ng", "Kenney", ""], ["Sow", "Daby", ""], ["Malin", "Bradley A.", ""]]}, {"id": "2104.04405", "submitter": "Zhou Zhou", "authors": "Zhou Zhai, Bin Gu, and Heng Huang", "title": "Learning Sampling Policy for Faster Derivative Free Optimization", "comments": "arXiv admin note: text overlap with arXiv:1910.09464 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Zeroth-order (ZO, also known as derivative-free) methods, which estimate the\ngradient only by two function evaluations, have attracted much attention\nrecently because of its broad applications in machine learning community. The\ntwo function evaluations are normally generated with random perturbations from\nstandard Gaussian distribution. To speed up ZO methods, many methods, such as\nvariance reduced stochastic ZO gradients and learning an adaptive Gaussian\ndistribution, have recently been proposed to reduce the variances of ZO\ngradients. However, it is still an open problem whether there is a space to\nfurther improve the convergence of ZO methods. To explore this problem, in this\npaper, we propose a new reinforcement learning based ZO algorithm (ZO-RL) with\nlearning the sampling policy for generating the perturbations in ZO\noptimization instead of using random sampling. To find the optimal policy, an\nactor-critic RL algorithm called deep deterministic policy gradient (DDPG) with\ntwo neural network function approximators is adopted. The learned sampling\npolicy guides the perturbed points in the parameter space to estimate a more\naccurate ZO gradient. To the best of our knowledge, our ZO-RL is the first\nalgorithm to learn the sampling policy using reinforcement learning for ZO\noptimization which is parallel to the existing methods. Especially, our ZO-RL\ncan be combined with existing ZO algorithms that could further accelerate the\nalgorithms. Experimental results for different ZO optimization problems show\nthat our ZO-RL algorithm can effectively reduce the variances of ZO gradient by\nlearning a sampling policy, and converge faster than existing ZO algorithms in\ndifferent scenarios.\n", "versions": [{"version": "v1", "created": "Fri, 9 Apr 2021 14:50:59 GMT"}], "update_date": "2021-04-12", "authors_parsed": [["Zhai", "Zhou", ""], ["Gu", "Bin", ""], ["Huang", "Heng", ""]]}, {"id": "2104.04413", "submitter": "Matthew Sotoudeh", "authors": "Matthew Sotoudeh and Aditya V. Thakur", "title": "Provable Repair of Deep Neural Networks", "comments": "Accepted paper at PLDI 2021. Tool will be available at\n  https://github.com/95616ARG/PRDNN/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Neural Networks (DNNs) have grown in popularity over the past decade and\nare now being used in safety-critical domains such as aircraft collision\navoidance. This has motivated a large number of techniques for finding unsafe\nbehavior in DNNs. In contrast, this paper tackles the problem of correcting a\nDNN once unsafe behavior is found. We introduce the provable repair problem,\nwhich is the problem of repairing a network N to construct a new network N'\nthat satisfies a given specification. If the safety specification is over a\nfinite set of points, our Provable Point Repair algorithm can find a provably\nminimal repair satisfying the specification, regardless of the activation\nfunctions used. For safety specifications addressing convex polytopes\ncontaining infinitely many points, our Provable Polytope Repair algorithm can\nfind a provably minimal repair satisfying the specification for DNNs using\npiecewise-linear activation functions. The key insight behind both of these\nalgorithms is the introduction of a Decoupled DNN architecture, which allows us\nto reduce provable repair to a linear programming problem. Our experimental\nresults demonstrate the efficiency and effectiveness of our Provable Repair\nalgorithms on a variety of challenging tasks.\n", "versions": [{"version": "v1", "created": "Fri, 9 Apr 2021 15:03:53 GMT"}, {"version": "v2", "created": "Sun, 25 Apr 2021 00:57:46 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Sotoudeh", "Matthew", ""], ["Thakur", "Aditya V.", ""]]}, {"id": "2104.04424", "submitter": "Ammar Fayad", "authors": "Ammar Fayad and Majd Ibrahim", "title": "Behavior-Guided Actor-Critic: Improving Exploration via Learning Policy\n  Behavior Representation for Deep Reinforcement Learning", "comments": "Preprint. Under Review. 9 pages, 3 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we propose Behavior-Guided Actor-Critic (BAC), an off-policy\nactor-critic deep RL algorithm. BAC mathematically formulates the behavior of\nthe policy through autoencoders by providing an accurate estimation of how\nfrequently each state-action pair was visited while taking into consideration\nstate dynamics that play a crucial role in determining the trajectories\nproduced by the policy. The agent is encouraged to change its behavior\nconsistently towards less-visited state-action pairs while attaining good\nperformance by maximizing the expected discounted sum of rewards, resulting in\nan efficient exploration of the environment and good exploitation of all high\nreward regions. One prominent aspect of our approach is that it is applicable\nto both stochastic and deterministic actors in contrast to maximum entropy deep\nreinforcement learning algorithms. Results show considerably better\nperformances of BAC when compared to several cutting-edge learning algorithms.\n", "versions": [{"version": "v1", "created": "Fri, 9 Apr 2021 15:22:35 GMT"}], "update_date": "2021-04-12", "authors_parsed": [["Fayad", "Ammar", ""], ["Ibrahim", "Majd", ""]]}, {"id": "2104.04448", "submitter": "David Stutz", "authors": "David Stutz, Matthias Hein, Bernt Schiele", "title": "Relating Adversarially Robust Generalization to Flat Minima", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial training (AT) has become the de-facto standard to obtain models\nrobust against adversarial examples. However, AT exhibits severe robust\noverfitting: cross-entropy loss on adversarial examples, so-called robust loss,\ndecreases continuously on training examples, while eventually increasing on\ntest examples. In practice, this leads to poor robust generalization, i.e.,\nadversarial robustness does not generalize well to new examples. In this paper,\nwe study the relationship between robust generalization and flatness of the\nrobust loss landscape in weight space, i.e., whether robust loss changes\nsignificantly when perturbing weights. To this end, we propose average- and\nworst-case metrics to measure flatness in the robust loss landscape and show a\ncorrelation between good robust generalization and flatness. For example,\nthroughout training, flatness reduces significantly during overfitting such\nthat early stopping effectively finds flatter minima in the robust loss\nlandscape. Similarly, AT variants achieving higher adversarial robustness also\ncorrespond to flatter minima. This holds for many popular choices, e.g.,\nAT-AWP, TRADES, MART, AT with self-supervision or additional unlabeled\nexamples, as well as simple regularization techniques, e.g., AutoAugment,\nweight decay or label noise. For fair comparison across these approaches, our\nflatness measures are specifically designed to be scale-invariant and we\nconduct extensive experiments to validate our findings.\n", "versions": [{"version": "v1", "created": "Fri, 9 Apr 2021 15:55:01 GMT"}], "update_date": "2021-04-12", "authors_parsed": [["Stutz", "David", ""], ["Hein", "Matthias", ""], ["Schiele", "Bernt", ""]]}, {"id": "2104.04450", "submitter": "Kun Cao", "authors": "Shivam Khare, Kun Cao, James Rehg", "title": "Unsupervised Class-Incremental Learning Through Confusion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  While many works on Continual Learning have shown promising results for\nmitigating catastrophic forgetting, they have relied on supervised training. To\nsuccessfully learn in a label-agnostic incremental setting, a model must\ndistinguish between learned and novel classes to properly include samples for\ntraining. We introduce a novelty detection method that leverages network\nconfusion caused by training incoming data as a new class. We found that\nincorporating a class-imbalance during this detection method substantially\nenhances performance. The effectiveness of our approach is demonstrated across\na set of image classification benchmarks: MNIST, SVHN, CIFAR-10, CIFAR-100, and\nCRIB.\n", "versions": [{"version": "v1", "created": "Fri, 9 Apr 2021 15:58:43 GMT"}], "update_date": "2021-04-12", "authors_parsed": [["Khare", "Shivam", ""], ["Cao", "Kun", ""], ["Rehg", "James", ""]]}, {"id": "2104.04457", "submitter": "Kevin Yang", "authors": "Zachary Wu, Kadina E. Johnston, Frances H. Arnold, Kevin K. Yang", "title": "Protein sequence design with deep generative models", "comments": "11 pages, 2 figures", "journal-ref": null, "doi": "10.1016/j.cbpa.2021.04.004", "report-no": null, "categories": "q-bio.QM cs.LG q-bio.BM stat.ML", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Protein engineering seeks to identify protein sequences with optimized\nproperties. When guided by machine learning, protein sequence generation\nmethods can draw on prior knowledge and experimental efforts to improve this\nprocess. In this review, we highlight recent applications of machine learning\nto generate protein sequences, focusing on the emerging field of deep\ngenerative methods.\n", "versions": [{"version": "v1", "created": "Fri, 9 Apr 2021 16:08:15 GMT"}], "update_date": "2021-05-28", "authors_parsed": [["Wu", "Zachary", ""], ["Johnston", "Kadina E.", ""], ["Arnold", "Frances H.", ""], ["Yang", "Kevin K.", ""]]}, {"id": "2104.04465", "submitter": "Shikun Liu", "authors": "Shikun Liu, Shuaifeng Zhi, Edward Johns, Andrew J. Davison", "title": "Bootstrapping Semantic Segmentation with Regional Contrast", "comments": "Project Page: https://shikun.io/projects/regional-contrast Code:\n  https://github.com/lorenmt/reco", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present ReCo, a contrastive learning framework designed at a regional\nlevel to assist learning in semantic segmentation. ReCo performs\nsemi-supervised or supervised pixel-level contrastive learning on a sparse set\nof hard negative pixels, with minimal additional memory footprint. ReCo is easy\nto implement, being built on top of off-the-shelf segmentation networks, and\nconsistently improves performance in both semi-supervised and supervised\nsemantic segmentation methods, achieving smoother segmentation boundaries and\nfaster convergence. The strongest effect is in semi-supervised learning with\nvery few labels. With ReCo, we achieve 50% mIoU in the CityScapes dataset,\nwhilst requiring only 20 labelled images, improving by 10% relative to the\nprevious state-of-the-art. Code is available at\nhttps://github.com/lorenmt/reco.\n", "versions": [{"version": "v1", "created": "Fri, 9 Apr 2021 16:26:29 GMT"}, {"version": "v2", "created": "Mon, 12 Apr 2021 00:53:22 GMT"}, {"version": "v3", "created": "Wed, 12 May 2021 18:01:39 GMT"}], "update_date": "2021-05-14", "authors_parsed": [["Liu", "Shikun", ""], ["Zhi", "Shuaifeng", ""], ["Johns", "Edward", ""], ["Davison", "Andrew J.", ""]]}, {"id": "2104.04466", "submitter": "Weizhe Lin", "authors": "Weizhe Lin, Bo-Hsian Tseng, Bill Byrne", "title": "Knowledge-Aware Graph-Enhanced GPT-2 for Dialogue State Tracking", "comments": "8 pages of main content", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dialogue State Tracking is a crucial part of multi-domain task-oriented\ndialogue systems, responsible for extracting information from user utterances.\nWe present a novel architecture that utilizes the powerful generative model\nGPT-2 to generate slot values one by one causally, and at the same time\nutilizes Graph Attention Networks to enable inter-slot information exchanges,\nwhich exploits the inter-slot relations such as correlations. Our model\nachieves $54.86\\%$ joint accuracy in MultiWOZ 2.0, and it retains a performance\nof up to $50.43\\%$ in sparse supervision training, where only session-level\nannotations ($14.3\\%$ of the full training set) are used. We conduct detailed\nanalyses to demonstrate the significance of using graph models in this task,\nand show by experiments that the proposed graph modules indeed help to capture\nmore inter-slot relations.\n", "versions": [{"version": "v1", "created": "Fri, 9 Apr 2021 16:27:34 GMT"}], "update_date": "2021-04-12", "authors_parsed": [["Lin", "Weizhe", ""], ["Tseng", "Bo-Hsian", ""], ["Byrne", "Bill", ""]]}, {"id": "2104.04477", "submitter": "Xueyuan Wang", "authors": "Xueyuan Wang, M. Cenk Gursoy, Tugba Erpek and Yalin E. Sagduyu", "title": "Jamming-Resilient Path Planning for Multiple UAVs via Deep Reinforcement\n  Learning", "comments": "To be published in IEEE International Conference on Communications\n  (ICC) 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.MA", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Unmanned aerial vehicles (UAVs) are expected to be an integral part of\nwireless networks. In this paper, we aim to find collision-free paths for\nmultiple cellular-connected UAVs, while satisfying requirements of connectivity\nwith ground base stations (GBSs) in the presence of a dynamic jammer. We first\nformulate the problem as a sequential decision making problem in discrete\ndomain, with connectivity, collision avoidance, and kinematic constraints. We,\nthen, propose an offline temporal difference (TD) learning algorithm with\nonline signal-to-interference-plus-noise ratio (SINR) mapping to solve the\nproblem. More specifically, a value network is constructed and trained offline\nby TD method to encode the interactions among the UAVs and between the UAVs and\nthe environment; and an online SINR mapping deep neural network (DNN) is\ndesigned and trained by supervised learning, to encode the influence and\nchanges due to the jammer. Numerical results show that, without any information\non the jammer, the proposed algorithm can achieve performance levels close to\nthat of the ideal scenario with the perfect SINR-map. Real-time navigation for\nmulti-UAVs can be efficiently performed with high success rates, and collisions\nare avoided.\n", "versions": [{"version": "v1", "created": "Fri, 9 Apr 2021 16:52:33 GMT"}, {"version": "v2", "created": "Thu, 15 Apr 2021 19:11:40 GMT"}], "update_date": "2021-04-19", "authors_parsed": [["Wang", "Xueyuan", ""], ["Gursoy", "M. Cenk", ""], ["Erpek", "Tugba", ""], ["Sagduyu", "Yalin E.", ""]]}, {"id": "2104.04483", "submitter": "Samuel Tesfazgi", "authors": "Samuel Tesfazgi, Armin Lederer and Sandra Hirche", "title": "Inverse Reinforcement Learning a Control Lyapunov Approach", "comments": "This work has been submitted to the IEEE CDC 2021 for possible\n  publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inferring the intent of an intelligent agent from demonstrations and\nsubsequently predicting its behavior, is a critical task in many collaborative\nsettings. A common approach to solve this problem is the framework of inverse\nreinforcement learning (IRL), where the observed agent, e.g., a human\ndemonstrator, is assumed to behave according to an intrinsic cost function that\nreflects its intent and informs its control actions. In this work, we\nreformulate the IRL inference problem to learning control Lyapunov functions\n(CLF) from demonstrations by exploiting the inverse optimality property, which\nstates that every CLF is also a meaningful value function. Moreover, the\nderived CLF formulation directly guarantees stability of inferred control\npolicies. We show the flexibility of our proposed method by learning from\ngoal-directed movement demonstrations in a continuous environment.\n", "versions": [{"version": "v1", "created": "Fri, 9 Apr 2021 17:08:16 GMT"}], "update_date": "2021-04-12", "authors_parsed": [["Tesfazgi", "Samuel", ""], ["Lederer", "Armin", ""], ["Hirche", "Sandra", ""]]}, {"id": "2104.04485", "submitter": "Reza Sepasdar", "authors": "Reza Sepasdar, Anuj Karpatne, Maryam Shakiba", "title": "A Data-Driven Approach to Full-Field Damage and Failure Pattern\n  Prediction in Microstructure-Dependent Composites using Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An image-based deep learning framework is developed in this paper to predict\ndamage and failure in microstructure-dependent composite materials. The work is\nmotivated by the complexity and computational cost of high-fidelity simulations\nof such materials. The proposed deep learning framework predicts the\npost-failure full-field stress distribution and crack pattern in\ntwo-dimensional representations of the composites based on the geometry of\nmicrostructures. The material of interest is selected to be a high-performance\nunidirectional carbon fiber-reinforced polymer composite. The deep learning\nframework contains two stacked fully-convolutional networks, namely, Generator\n1 and Generator 2, trained sequentially. First, Generator 1 learns to translate\nthe microstructural geometry to the full-field post-failure stress\ndistribution. Then, Generator 2 learns to translate the output of Generator 1\nto the failure pattern. A physics-informed loss function is also designed and\nincorporated to further improve the performance of the proposed framework and\nfacilitate the validation process. In order to provide a sufficiently large\ndata set for training and validating the deep learning framework, 4500\nmicrostructural representations are synthetically generated and simulated in an\nefficient finite element framework. It is shown that the proposed deep learning\napproach can effectively predict the composites' post-failure full-field stress\ndistribution and failure pattern, two of the most complex phenomena to simulate\nin computational solid mechanics.\n", "versions": [{"version": "v1", "created": "Fri, 9 Apr 2021 17:11:50 GMT"}], "update_date": "2021-04-12", "authors_parsed": [["Sepasdar", "Reza", ""], ["Karpatne", "Anuj", ""], ["Shakiba", "Maryam", ""]]}, {"id": "2104.04487", "submitter": "Rodrigo Cabrera", "authors": "Rodrigo Cabrera, Xiaofeng Liu, Mohammadreza Ghodsi, Zebulun Matteson,\n  Eugene Weinstein, Anjuli Kannan", "title": "Language model fusion for streaming end to end speech recognition", "comments": "5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SD eess.AS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Streaming processing of speech audio is required for many contemporary\npractical speech recognition tasks. Even with the large corpora of manually\ntranscribed speech data available today, it is impossible for such corpora to\ncover adequately the long tail of linguistic content that's important for tasks\nsuch as open-ended dictation and voice search. We seek to address both the\nstreaming and the tail recognition challenges by using a language model (LM)\ntrained on unpaired text data to enhance the end-to-end (E2E) model. We extend\nshallow fusion and cold fusion approaches to streaming Recurrent Neural Network\nTransducer (RNNT), and also propose two new competitive fusion approaches that\nfurther enhance the RNNT architecture. Our results on multiple languages with\nvarying training set sizes show that these fusion methods improve streaming\nRNNT performance through introducing extra linguistic features. Cold fusion\nworks consistently better on streaming RNNT with up to a 8.5% WER improvement.\n", "versions": [{"version": "v1", "created": "Fri, 9 Apr 2021 17:14:28 GMT"}], "update_date": "2021-04-12", "authors_parsed": [["Cabrera", "Rodrigo", ""], ["Liu", "Xiaofeng", ""], ["Ghodsi", "Mohammadreza", ""], ["Matteson", "Zebulun", ""], ["Weinstein", "Eugene", ""], ["Kannan", "Anjuli", ""]]}, {"id": "2104.04497", "submitter": "Lifeng Han", "authors": "Lifeng Han, Gareth J. F. Jones, Alan F. Smeaton and Paolo Bolzoni", "title": "Chinese Character Decomposition for Neural MT with Multi-Word\n  Expressions", "comments": "Accepted to publish in NoDaLiDa2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Chinese character decomposition has been used as a feature to enhance Machine\nTranslation (MT) models, combining radicals into character and word level\nmodels. Recent work has investigated ideograph or stroke level embedding.\nHowever, questions remain about different decomposition levels of Chinese\ncharacter representations, radical and strokes, best suited for MT. To\ninvestigate the impact of Chinese decomposition embedding in detail, i.e.,\nradical, stroke, and intermediate levels, and how well these decompositions\nrepresent the meaning of the original character sequences, we carry out\nanalysis with both automated and human evaluation of MT. Furthermore, we\ninvestigate if the combination of decomposed Multiword Expressions (MWEs) can\nenhance the model learning. MWE integration into MT has seen more than a decade\nof exploration. However, decomposed MWEs has not previously been explored.\n", "versions": [{"version": "v1", "created": "Fri, 9 Apr 2021 17:28:49 GMT"}], "update_date": "2021-04-12", "authors_parsed": [["Han", "Lifeng", ""], ["Jones", "Gareth J. F.", ""], ["Smeaton", "Alan F.", ""], ["Bolzoni", "Paolo", ""]]}, {"id": "2104.04517", "submitter": "Vaibhav Bhat", "authors": "Vaibhav Bhat, Anita Yadav, Sonal Yadav, Dhivya Chandrasekran, Vijay\n  Mago", "title": "AdCOFE: Advanced Contextual Feature Extraction in Conversations for\n  emotion classification", "comments": "12 pages, to be published in PeerJ Computer Science Journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Emotion recognition in conversations is an important step in various virtual\nchat bots which require opinion-based feedback, like in social media threads,\nonline support and many more applications. Current Emotion recognition in\nconversations models face issues like (a) loss of contextual information in\nbetween two dialogues of a conversation, (b) failure to give appropriate\nimportance to significant tokens in each utterance and (c) inability to pass on\nthe emotional information from previous utterances.The proposed model of\nAdvanced Contextual Feature Extraction (AdCOFE) addresses these issues by\nperforming unique feature extraction using knowledge graphs, sentiment lexicons\nand phrases of natural language at all levels (word and position embedding) of\nthe utterances. Experiments on the Emotion recognition in conversations dataset\nshow that AdCOFE is beneficial in capturing emotions in conversations.\n", "versions": [{"version": "v1", "created": "Fri, 9 Apr 2021 17:58:19 GMT"}], "update_date": "2021-04-12", "authors_parsed": [["Bhat", "Vaibhav", ""], ["Yadav", "Anita", ""], ["Yadav", "Sonal", ""], ["Chandrasekran", "Dhivya", ""], ["Mago", "Vijay", ""]]}, {"id": "2104.04523", "submitter": "Matthew Berger", "authors": "Yuzhe Lu, Kairong Jiang, Joshua A. Levine, and Matthew Berger", "title": "Compressive Neural Representations of Volumetric Scalar Fields", "comments": "EuroVis 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.GR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present an approach for compressing volumetric scalar fields using\nimplicit neural representations. Our approach represents a scalar field as a\nlearned function, wherein a neural network maps a point in the domain to an\noutput scalar value. By setting the number of weights of the neural network to\nbe smaller than the input size, we achieve compressed representations of scalar\nfields, thus framing compression as a type of function approximation. Combined\nwith carefully quantizing network weights, we show that this approach yields\nhighly compact representations that outperform state-of-the-art volume\ncompression approaches. The conceptual simplicity of our approach enables a\nnumber of benefits, such as support for time-varying scalar fields, optimizing\nto preserve spatial gradients, and random-access field evaluation. We study the\nimpact of network design choices on compression performance, highlighting how\nsimple network architectures are effective for a broad range of volumes.\n", "versions": [{"version": "v1", "created": "Sun, 11 Apr 2021 15:24:14 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Lu", "Yuzhe", ""], ["Jiang", "Kairong", ""], ["Levine", "Joshua A.", ""], ["Berger", "Matthew", ""]]}, {"id": "2104.04546", "submitter": "Maria A. Zuluaga", "authors": "Laura M. Ferrari, Guy Abi Hanna, Paolo Volpe, Esma Ismailova,\n  Fran\\c{c}ois Bremond, Maria A. Zuluaga", "title": "One-class Autoencoder Approach for Optimal Electrode Set-up\n  Identification in Wearable EEG Event Monitoring", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A limiting factor towards the wide routine use of wearables devices for\ncontinuous healthcare monitoring is their cumbersome and obtrusive nature. This\nis particularly true for electroencephalography (EEG) recordings, which require\nthe placement of multiple electrodes in contact with the scalp. In this work,\nwe propose to identify the optimal wearable EEG electrode set-up, in terms of\nminimal number of electrodes, comfortable location and performance, for\nEEG-based event detection and monitoring. By relying on the demonstrated power\nof autoencoder (AE) networks to learn latent representations from\nhigh-dimensional data, our proposed strategy trains an AE architecture in a\none-class classification setup with different electrode set-ups as input data.\nThe resulting models are assessed using the F-score and the best set-up is\nchosen according to the established optimal criteria. Using alpha wave\ndetection as use case, we demonstrate that the proposed method allows to detect\nan alpha state from an optimal set-up consisting of electrodes in the forehead\nand behind the ear, with an average F-score of 0.78. Our results suggest that a\nlearning-based approach can be used to enable the design and implementation of\noptimized wearable devices for real-life healthcare monitoring.\n", "versions": [{"version": "v1", "created": "Fri, 9 Apr 2021 18:17:22 GMT"}, {"version": "v2", "created": "Tue, 13 Apr 2021 16:02:50 GMT"}, {"version": "v3", "created": "Wed, 19 May 2021 08:16:45 GMT"}], "update_date": "2021-05-20", "authors_parsed": [["Ferrari", "Laura M.", ""], ["Hanna", "Guy Abi", ""], ["Volpe", "Paolo", ""], ["Ismailova", "Esma", ""], ["Bremond", "Fran\u00e7ois", ""], ["Zuluaga", "Maria A.", ""]]}, {"id": "2104.04547", "submitter": "Garrett A. Stevenson", "authors": "Garrett A. Stevenson, Derek Jones, Hyojin Kim, W. F. Drew Bennett,\n  Brian J. Bennion, Monica Borucki, Feliza Bourguet, Aidan Epstein, Magdalena\n  Franco, Brooke Harmon, Stewart He, Max P. Katz, Daniel Kirshner, Victoria\n  Lao, Edmond Y. Lau, Jacky Lo, Kevin McLoughlin, Richard Mosesso, Deepa K.\n  Murugesh, Oscar A. Negrete, Edwin A. Saada, Brent Segelke, Maxwell Stefan,\n  Marisa W. Torres, Dina Weilhammer, Sergio Wong, Yue Yang, Adam Zemla, Xiaohua\n  Zhang, Fangqiang Zhu, Felice C. Lightstone, Jonathan E. Allen", "title": "High-Throughput Virtual Screening of Small Molecule Inhibitors for\n  SARS-CoV-2 Protein Targets with Deep Fusion Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-bio.BM", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Structure-based Deep Fusion models were recently shown to outperform several\nphysics- and machine learning-based protein-ligand binding affinity prediction\nmethods. As part of a multi-institutional COVID-19 pandemic response, over 500\nmillion small molecules were computationally screened against four protein\nstructures from the novel coronavirus (SARS-CoV-2), which causes COVID-19.\nThree enhancements to Deep Fusion were made in order to evaluate more than 5\nbillion docked poses on SARS-CoV-2 protein targets. First, the Deep Fusion\nconcept was refined by formulating the architecture as one, coherently\nbackpropagated model (Coherent Fusion) to improve binding-affinity prediction\naccuracy. Secondly, the model was trained using a distributed, genetic\nhyper-parameter optimization. Finally, a scalable, high-throughput screening\ncapability was developed to maximize the number of ligands evaluated and\nexpedite the path to experimental evaluation. In this work, we present both the\nmethods developed for machine learning-based high-throughput screening and\nresults from using our computational pipeline to find SARS-CoV-2 inhibitors.\n", "versions": [{"version": "v1", "created": "Fri, 9 Apr 2021 18:18:26 GMT"}, {"version": "v2", "created": "Sun, 30 May 2021 06:33:10 GMT"}, {"version": "v3", "created": "Tue, 1 Jun 2021 01:13:21 GMT"}], "update_date": "2021-06-02", "authors_parsed": [["Stevenson", "Garrett A.", ""], ["Jones", "Derek", ""], ["Kim", "Hyojin", ""], ["Bennett", "W. F. Drew", ""], ["Bennion", "Brian J.", ""], ["Borucki", "Monica", ""], ["Bourguet", "Feliza", ""], ["Epstein", "Aidan", ""], ["Franco", "Magdalena", ""], ["Harmon", "Brooke", ""], ["He", "Stewart", ""], ["Katz", "Max P.", ""], ["Kirshner", "Daniel", ""], ["Lao", "Victoria", ""], ["Lau", "Edmond Y.", ""], ["Lo", "Jacky", ""], ["McLoughlin", "Kevin", ""], ["Mosesso", "Richard", ""], ["Murugesh", "Deepa K.", ""], ["Negrete", "Oscar A.", ""], ["Saada", "Edwin A.", ""], ["Segelke", "Brent", ""], ["Stefan", "Maxwell", ""], ["Torres", "Marisa W.", ""], ["Weilhammer", "Dina", ""], ["Wong", "Sergio", ""], ["Yang", "Yue", ""], ["Zemla", "Adam", ""], ["Zhang", "Xiaohua", ""], ["Zhu", "Fangqiang", ""], ["Lightstone", "Felice C.", ""], ["Allen", "Jonathan E.", ""]]}, {"id": "2104.04569", "submitter": "Nathaniel Diamant", "authors": "Nathaniel Diamant, Erik Reinertsen, Steven Song, Aaron Aguirre, Collin\n  Stultz, Puneet Batra", "title": "Patient Contrastive Learning: a Performant, Expressive, and Practical\n  Approach to ECG Modeling", "comments": "17 pages, 7 figures. Submitted to Machine Learning for Healthcare\n  2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Supervised machine learning applications in health care are often limited due\nto a scarcity of labeled training data. To mitigate this effect of small sample\nsize, we introduce a pre-training approach, Patient Contrastive Learning of\nRepresentations (PCLR), which creates latent representations of ECGs from a\nlarge number of unlabeled examples. The resulting representations are\nexpressive, performant, and practical across a wide spectrum of clinical tasks.\nWe develop PCLR using a large health care system with over 3.2 million 12-lead\nECGs, and demonstrate substantial improvements across multiple new tasks when\nthere are fewer than 5,000 labels. We release our model to extract ECG\nrepresentations at\nhttps://github.com/broadinstitute/ml4h/tree/master/model_zoo/PCLR.\n", "versions": [{"version": "v1", "created": "Fri, 9 Apr 2021 18:58:08 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Diamant", "Nathaniel", ""], ["Reinertsen", "Erik", ""], ["Song", "Steven", ""], ["Aguirre", "Aaron", ""], ["Stultz", "Collin", ""], ["Batra", "Puneet", ""]]}, {"id": "2104.04570", "submitter": "Marco Due\\~nas", "authors": "Marco Due\\~nas and V\\'ictor Ortiz and Massimo Riccaboni and Francesco\n  Serti", "title": "Assessing the Impact of COVID-19 on Trade: a Machine Learning\n  Counterfactual Analysis", "comments": "31 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.GN cs.LG q-fin.EC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  By interpreting exporters' dynamics as a complex learning process, this paper\nconstitutes the first attempt to investigate the effectiveness of different\nMachine Learning (ML) techniques in predicting firms' trade status. We focus on\nthe probability of Colombian firms surviving in the export market under two\ndifferent scenarios: a COVID-19 setting and a non-COVID-19 counterfactual\nsituation. By comparing the resulting predictions, we estimate the individual\ntreatment effect of the COVID-19 shock on firms' outcomes. Finally, we use\nrecursive partitioning methods to identify subgroups with differential\ntreatment effects. We find that, besides the temporal dimension, the main\nfactors predicting treatment heterogeneity are interactions between firm size\nand industry.\n", "versions": [{"version": "v1", "created": "Fri, 9 Apr 2021 19:00:03 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Due\u00f1as", "Marco", ""], ["Ortiz", "V\u00edctor", ""], ["Riccaboni", "Massimo", ""], ["Serti", "Francesco", ""]]}, {"id": "2104.04576", "submitter": "Max Sponner", "authors": "Max Sponner, Bernd Waschneck and Akash Kumar", "title": "Compiler Toolchains for Deep Learning Workloads on Embedded Platforms", "comments": "tinyML 2021 conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As the usage of deep learning becomes increasingly popular in mobile and\nembedded solutions, it is necessary to convert the framework-specific network\nrepresentations into executable code for these embedded platforms. This paper\nconsists of two parts: The first section is made up of a survey and benchmark\nof the available open source deep learning compiler toolchains, which focus on\nthe capabilities and performance of the individual solutions in regard to\ntargeting embedded devices and microcontrollers that are combined with a\ndedicated accelerator in a heterogeneous fashion. The second part explores the\nimplementation and evaluation of a compilation flow for such a heterogeneous\ndevice and reuses one of the existing toolchains to demonstrate the necessary\nsteps for hardware developers that plan to build a software flow for their own\nhardware.\n", "versions": [{"version": "v1", "created": "Mon, 8 Mar 2021 13:54:25 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Sponner", "Max", ""], ["Waschneck", "Bernd", ""], ["Kumar", "Akash", ""]]}, {"id": "2104.04580", "submitter": "Jian Wu", "authors": "Jian Wu, Rajal Nivargi, Sree Sai Teja Lanka, Arjun Manoj Menon, Sai\n  Ajay Modukuri, Nishanth Nakshatri, Xin Wei, Zhuoer Wang, James Caverlee,\n  Sarah M. Rajtmajer, C. Lee Giles", "title": "Predicting the Reproducibility of Social and Behavioral Science Papers\n  Using Supervised Learning Models", "comments": "17 pages, 8 figures, a draft to be submitted to JCDL'21", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.AI cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  In recent years, significant effort has been invested verifying the\nreproducibility and robustness of research claims in social and behavioral\nsciences (SBS), much of which has involved resource-intensive replication\nprojects. In this paper, we investigate prediction of the reproducibility of\nSBS papers using machine learning methods based on a set of features. We\npropose a framework that extracts five types of features from scholarly work\nthat can be used to support assessments of reproducibility of published\nresearch claims. Bibliometric features, venue features, and author features are\ncollected from public APIs or extracted using open source machine learning\nlibraries with customized parsers. Statistical features, such as p-values, are\nextracted by recognizing patterns in the body text. Semantic features, such as\nfunding information, are obtained from public APIs or are extracted using\nnatural language processing models. We analyze pairwise correlations between\nindividual features and their importance for predicting a set of human-assessed\nground truth labels. In doing so, we identify a subset of 9 top features that\nplay relatively more important roles in predicting the reproducibility of SBS\npapers in our corpus. Results are verified by comparing performances of 10\nsupervised predictive classifiers trained on different sets of features.\n", "versions": [{"version": "v1", "created": "Thu, 8 Apr 2021 00:45:20 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Wu", "Jian", ""], ["Nivargi", "Rajal", ""], ["Lanka", "Sree Sai Teja", ""], ["Menon", "Arjun Manoj", ""], ["Modukuri", "Sai Ajay", ""], ["Nakshatri", "Nishanth", ""], ["Wei", "Xin", ""], ["Wang", "Zhuoer", ""], ["Caverlee", "James", ""], ["Rajtmajer", "Sarah M.", ""], ["Giles", "C. Lee", ""]]}, {"id": "2104.04584", "submitter": "Swakkhar Shatabda", "authors": "Md. Mahinur Rashid, Hasin Kawsar Jahan, Annysha Huzzat, Riyasaat Ahmed\n  Rahul, Tamim Bin Zakir, Farhana Meem, Md. Saddam Hossain Mukta and Swakkhar\n  Shatabda", "title": "Text2Chart: A Multi-Staged Chart Generator from Natural Language Text", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.HC cs.IR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Generation of scientific visualization from analytical natural language text\nis a challenging task. In this paper, we propose Text2Chart, a multi-staged\nchart generator method. Text2Chart takes natural language text as input and\nproduce visualization as two-dimensional charts. Text2Chart approaches the\nproblem in three stages. Firstly, it identifies the axis elements of a chart\nfrom the given text known as x and y entities. Then it finds a mapping of\nx-entities with its corresponding y-entities. Next, it generates a chart type\nsuitable for the given text: bar, line or pie. Combination of these three\nstages is capable of generating visualization from the given analytical text.\nWe have also constructed a dataset for this problem. Experiments show that\nText2Chart achieves best performances with BERT based encodings with LSTM\nmodels in the first stage to label x and y entities, Random Forest classifier\nfor the mapping stage and fastText embedding with LSTM for the chart type\nprediction. In our experiments, all the stages show satisfactory results and\neffectiveness considering formation of charts from analytical text, achieving a\ncommendable overall performance.\n", "versions": [{"version": "v1", "created": "Fri, 9 Apr 2021 19:42:24 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Rashid", "Md. Mahinur", ""], ["Jahan", "Hasin Kawsar", ""], ["Huzzat", "Annysha", ""], ["Rahul", "Riyasaat Ahmed", ""], ["Zakir", "Tamim Bin", ""], ["Meem", "Farhana", ""], ["Mukta", "Md. Saddam Hossain", ""], ["Shatabda", "Swakkhar", ""]]}, {"id": "2104.04597", "submitter": "Muhao Chen", "authors": "Xuelu Chen, Michael Boratko, Muhao Chen, Shib Sankar Dasgupta, Xiang\n  Lorraine Li, Andrew McCallum", "title": "Probabilistic Box Embeddings for Uncertain Knowledge Graph Reasoning", "comments": "NAACL-HLT 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge bases often consist of facts which are harvested from a variety of\nsources, many of which are noisy and some of which conflict, resulting in a\nlevel of uncertainty for each triple. Knowledge bases are also often\nincomplete, prompting the use of embedding methods to generalize from known\nfacts, however, existing embedding methods only model triple-level uncertainty,\nand reasoning results lack global consistency. To address these shortcomings,\nwe propose BEUrRE, a novel uncertain knowledge graph embedding method with\ncalibrated probabilistic semantics. BEUrRE models each entity as a box (i.e.\naxis-aligned hyperrectangle) and relations between two entities as affine\ntransforms on the head and tail entity boxes. The geometry of the boxes allows\nfor efficient calculation of intersections and volumes, endowing the model with\ncalibrated probabilistic semantics and facilitating the incorporation of\nrelational constraints. Extensive experiments on two benchmark datasets show\nthat BEUrRE consistently outperforms baselines on confidence prediction and\nfact ranking due to its probabilistic calibration and ability to capture\nhigh-order dependencies among facts.\n", "versions": [{"version": "v1", "created": "Fri, 9 Apr 2021 21:01:52 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Chen", "Xuelu", ""], ["Boratko", "Michael", ""], ["Chen", "Muhao", ""], ["Dasgupta", "Shib Sankar", ""], ["Li", "Xiang Lorraine", ""], ["McCallum", "Andrew", ""]]}, {"id": "2104.04598", "submitter": "Jayaprakash Akula", "authors": "Jatin Lamba, Abhishek, Jayaprakash Akula, Rishabh Dabral, Preethi\n  Jyothi, Ganesh Ramakrishnan", "title": "Cross-Modal learning for Audio-Visual Video Parsing", "comments": "Work accepted at Interspeech 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.CV cs.LG eess.AS eess.IV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we present a novel approach to the audio-visual video parsing\n(AVVP) task that demarcates events from a video separately for audio and visual\nmodalities. The proposed parsing approach simultaneously detects the temporal\nboundaries in terms of start and end times of such events. We show how AVVP can\nbenefit from the following techniques geared towards effective cross-modal\nlearning: (i) adversarial training and skip connections (ii) global context\naware attention and, (iii) self-supervised pretraining using an audio-video\ngrounding objective to obtain cross-modal audio-video representations. We\npresent extensive experimental evaluations on the Look, Listen, and Parse (LLP)\ndataset and show that we outperform the state-of-the-art Hybrid Attention\nNetwork (HAN) on all five metrics proposed for AVVP. We also present several\nablations to validate the effect of pretraining, global attention and\nadversarial training.\n", "versions": [{"version": "v1", "created": "Sat, 3 Apr 2021 07:07:21 GMT"}, {"version": "v2", "created": "Mon, 21 Jun 2021 10:56:29 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Lamba", "Jatin", ""], ["Abhishek", "", ""], ["Akula", "Jayaprakash", ""], ["Dabral", "Rishabh", ""], ["Jyothi", "Preethi", ""], ["Ramakrishnan", "Ganesh", ""]]}, {"id": "2104.04599", "submitter": "Liangrui Pan", "authors": "Liangrui Pan, Peng Zhang, Chalongrat Daengngam, Mitchai\n  Chongcheawchamnan", "title": "A review of artificial intelligence methods combined with Raman\n  spectroscopy to identify the composition of substances", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG physics.chem-ph", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  In general, most of the substances in nature exist in mixtures, and the\nnoninvasive identification of mixture composition with high speed and accuracy\nremains a difficult task. However, the development of Raman spectroscopy,\nmachine learning, and deep learning techniques have paved the way for achieving\nefficient analytical tools capable of identifying mixture components, making an\napparent breakthrough in the identification of mixtures beyond the traditional\nchemical analysis methods. This article summarizes the work of Raman\nspectroscopy in identifying the composition of substances as well as provides\ndetailed reviews on the preprocessing process of Raman spectroscopy, the\nanalysis methods and applications of artificial intelligence. This review\nsummarizes the work of Raman spectroscopy in identifying the composition of\nsubstances and reviews the preprocessing process of Raman spectroscopy, the\nanalysis methods and applications of artificial intelligence. Finally, the\nadvantages and disadvantages and development prospects of Raman spectroscopy\nare discussed in detail.\n", "versions": [{"version": "v1", "created": "Mon, 5 Apr 2021 02:24:05 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Pan", "Liangrui", ""], ["Zhang", "Peng", ""], ["Daengngam", "Chalongrat", ""], ["Chongcheawchamnan", "Mitchai", ""]]}, {"id": "2104.04610", "submitter": "Vincent Le-Guen", "authors": "Vincent Le Guen, Nicolas Thome", "title": "Deep Time Series Forecasting with Shape and Temporal Criteria", "comments": "arXiv admin note: text overlap with arXiv:2010.07349", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper addresses the problem of multi-step time series forecasting for\nnon-stationary signals that can present sudden changes. Current\nstate-of-the-art deep learning forecasting methods, often trained with variants\nof the MSE, lack the ability to provide sharp predictions in deterministic and\nprobabilistic contexts. To handle these challenges, we propose to incorporate\nshape and temporal criteria in the training objective of deep models. We define\nshape and temporal similarities and dissimilarities, based on a smooth\nrelaxation of Dynamic Time Warping (DTW) and Temporal Distortion Index (TDI),\nthat enable to build differentiable loss functions and positive semi-definite\n(PSD) kernels. With these tools, we introduce DILATE (DIstortion Loss including\nshApe and TimE), a new objective for deterministic forecasting, that explicitly\nincorporates two terms supporting precise shape and temporal change detection.\nFor probabilistic forecasting, we introduce STRIPE++ (Shape and Time diverRsIty\nin Probabilistic forEcasting), a framework for providing a set of sharp and\ndiverse forecasts, where the structured shape and time diversity is enforced\nwith a determinantal point process (DPP) diversity loss. Extensive experiments\nand ablations studies on synthetic and real-world datasets confirm the benefits\nof leveraging shape and time features in time series forecasting.\n", "versions": [{"version": "v1", "created": "Fri, 9 Apr 2021 21:24:33 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Guen", "Vincent Le", ""], ["Thome", "Nicolas", ""]]}, {"id": "2104.04627", "submitter": "Elizabeth Combs", "authors": "Xiangyun Chu (1), Elizabeth Combs (1), Amber Wang (1), Michael Picheny\n  (2) ((1) Center for Data Science, New York University, (2) Courant Computer\n  Science and Center for Data Science, New York University)", "title": "Accented Speech Recognition Inspired by Human Perception", "comments": "Submitted to INTERSPEECH 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While improvements have been made in automatic speech recognition performance\nover the last several years, machines continue to have significantly lower\nperformance on accented speech than humans. In addition, the most significant\nimprovements on accented speech primarily arise by overwhelming the problem\nwith hundreds or even thousands of hours of data. Humans typically require much\nless data to adapt to a new accent. This paper explores methods that are\ninspired by human perception to evaluate possible performance improvements for\nrecognition of accented speech, with a specific focus on recognizing speech\nwith a novel accent relative to that of the training data. Our experiments are\nrun on small, accessible datasets that are available to the research community.\nWe explore four methodologies: pre-exposure to multiple accents, grapheme and\nphoneme-based pronunciations, dropout (to improve generalization to a novel\naccent), and the identification of the layers in the neural network that can\nspecifically be associated with accent modeling. Our results indicate that\nmethods based on human perception are promising in reducing WER and\nunderstanding how accented speech is modeled in neural networks for novel\naccents.\n", "versions": [{"version": "v1", "created": "Fri, 9 Apr 2021 22:35:09 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Chu", "Xiangyun", ""], ["Combs", "Elizabeth", ""], ["Wang", "Amber", ""], ["Picheny", "Michael", ""]]}, {"id": "2104.04630", "submitter": "Tharindu Ranasinghe Mr", "authors": "Tharindu Ranasinghe, Diptanu Sarkar, Marcos Zampieri, Alexander\n  Ororbia", "title": "WLV-RIT at SemEval-2021 Task 5: A Neural Transformer Framework for\n  Detecting Toxic Spans", "comments": "Accepted to SemEval-2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In recent years, the widespread use of social media has led to an increase in\nthe generation of toxic and offensive content on online platforms. In response,\nsocial media platforms have worked on developing automatic detection methods\nand employing human moderators to cope with this deluge of offensive content.\nWhile various state-of-the-art statistical models have been applied to detect\ntoxic posts, there are only a few studies that focus on detecting the words or\nexpressions that make a post offensive. This motivates the organization of the\nSemEval-2021 Task 5: Toxic Spans Detection competition, which has provided\nparticipants with a dataset containing toxic spans annotation in English posts.\nIn this paper, we present the WLV-RIT entry for the SemEval-2021 Task 5. Our\nbest performing neural transformer model achieves an $0.68$ F1-Score.\nFurthermore, we develop an open-source framework for multilingual detection of\noffensive spans, i.e., MUDES, based on neural transformers that detect toxic\nspans in texts.\n", "versions": [{"version": "v1", "created": "Fri, 9 Apr 2021 22:52:26 GMT"}, {"version": "v2", "created": "Thu, 15 Apr 2021 22:32:17 GMT"}, {"version": "v3", "created": "Thu, 27 May 2021 22:09:39 GMT"}], "update_date": "2021-05-31", "authors_parsed": [["Ranasinghe", "Tharindu", ""], ["Sarkar", "Diptanu", ""], ["Zampieri", "Marcos", ""], ["Ororbia", "Alexander", ""]]}, {"id": "2104.04632", "submitter": "Tharindu Ranasinghe Mr", "authors": "Hansi Hettiarachchi, Tharindu Ranasinghe", "title": "TransWiC at SemEval-2021 Task 2: Transformer-based Multilingual and\n  Cross-lingual Word-in-Context Disambiguation", "comments": "Accepted to SemEval-2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Identifying whether a word carries the same meaning or different meaning in\ntwo contexts is an important research area in natural language processing which\nplays a significant role in many applications such as question answering,\ndocument summarisation, information retrieval and information extraction. Most\nof the previous work in this area rely on language-specific resources making it\ndifficult to generalise across languages. Considering this limitation, our\napproach to SemEval-2021 Task 2 is based only on pretrained transformer models\nand does not use any language-specific processing and resources. Despite that,\nour best model achieves 0.90 accuracy for English-English subtask which is very\ncompatible compared to the best result of the subtask; 0.93 accuracy. Our\napproach also achieves satisfactory results in other monolingual and\ncross-lingual language pairs as well.\n", "versions": [{"version": "v1", "created": "Fri, 9 Apr 2021 23:06:05 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Hettiarachchi", "Hansi", ""], ["Ranasinghe", "Tharindu", ""]]}, {"id": "2104.04644", "submitter": "Yuxiang Yang", "authors": "Yuxiang Yang, Tingnan Zhang, Erwin Coumans, Jie Tan, Byron Boots", "title": "Fast and Efficient Locomotion via Learned Gait Transitions", "comments": "Preprint. Under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We focus on the problem of developing energy efficient controllers for\nquadrupedal robots. Animals can actively switch gaits at different speeds to\nlower their energy consumption. In this paper, we devise a hierarchical\nlearning framework, in which distinctive locomotion gaits and natural gait\ntransitions emerge automatically with a simple reward of energy minimization.\nWe use reinforcement learning to train a high-level gait policy that specifies\ngait patterns of each foot, while the low-level whole-body controller optimizes\nthe motor commands so that the robot can walk at a desired velocity using that\ngait pattern. We test our learning framework on a quadruped robot and\ndemonstrate automatic gait transitions, from walking to trotting and to\nfly-trotting, as the robot increases its speed. We show that the learned\nhierarchical controller consumes much less energy across a wide range of\nlocomotion speed than baseline controllers.\n", "versions": [{"version": "v1", "created": "Fri, 9 Apr 2021 23:53:28 GMT"}, {"version": "v2", "created": "Thu, 24 Jun 2021 05:08:07 GMT"}], "update_date": "2021-06-25", "authors_parsed": [["Yang", "Yuxiang", ""], ["Zhang", "Tingnan", ""], ["Coumans", "Erwin", ""], ["Tan", "Jie", ""], ["Boots", "Byron", ""]]}, {"id": "2104.04646", "submitter": "Brandon Jacques", "authors": "Brandon Jacques, Zoran Tiganj, Marc W. Howard, Per B. Sederberg", "title": "DeepSITH: Efficient Learning via Decomposition of What and When Across\n  Time Scales", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Extracting temporal relationships over a range of scales is a hallmark of\nhuman perception and cognition -- and thus it is a critical feature of machine\nlearning applied to real-world problems. Neural networks are either plagued by\nthe exploding/vanishing gradient problem in recurrent neural networks (RNNs) or\nmust adjust their parameters to learn the relevant time scales (e.g., in\nLSTMs). This paper introduces DeepSITH, a network comprising\nbiologically-inspired Scale-Invariant Temporal History (SITH) modules in series\nwith dense connections between layers. SITH modules respond to their inputs\nwith a geometrically-spaced set of time constants, enabling the DeepSITH\nnetwork to learn problems along a continuum of time-scales. We compare DeepSITH\nto LSTMs and other recent RNNs on several time series prediction and decoding\ntasks. DeepSITH achieves state-of-the-art performance on these problems.\n", "versions": [{"version": "v1", "created": "Fri, 9 Apr 2021 23:58:14 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Jacques", "Brandon", ""], ["Tiganj", "Zoran", ""], ["Howard", "Marc W.", ""], ["Sederberg", "Per B.", ""]]}, {"id": "2104.04657", "submitter": "Max Vladymyrov", "authors": "Mark Sandler and Max Vladymyrov and Andrey Zhmoginov and Nolan Miller\n  and Andrew Jackson and Tom Madams and Blaise Aguera y Arcas", "title": "Meta-Learning Bidirectional Update Rules", "comments": "ICML 2021, 17 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce a new type of generalized neural network where\nneurons and synapses maintain multiple states. We show that classical\ngradient-based backpropagation in neural networks can be seen as a special case\nof a two-state network where one state is used for activations and another for\ngradients, with update rules derived from the chain rule. In our generalized\nframework, networks have neither explicit notion of nor ever receive gradients.\nThe synapses and neurons are updated using a bidirectional Hebb-style update\nrule parameterized by a shared low-dimensional \"genome\". We show that such\ngenomes can be meta-learned from scratch, using either conventional\noptimization techniques, or evolutionary strategies, such as CMA-ES. Resulting\nupdate rules generalize to unseen tasks and train faster than gradient descent\nbased optimizers for several standard computer vision and synthetic tasks.\n", "versions": [{"version": "v1", "created": "Sat, 10 Apr 2021 00:56:35 GMT"}, {"version": "v2", "created": "Fri, 11 Jun 2021 21:13:25 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Sandler", "Mark", ""], ["Vladymyrov", "Max", ""], ["Zhmoginov", "Andrey", ""], ["Miller", "Nolan", ""], ["Jackson", "Andrew", ""], ["Madams", "Tom", ""], ["Arcas", "Blaise Aguera y", ""]]}, {"id": "2104.04665", "submitter": "Bin Deng", "authors": "Bin Deng, Yabin Zhang, Hui Tang, Changxing Ding, Kui Jia", "title": "On Universal Black-Box Domain Adaptation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study an arguably least restrictive setting of domain\nadaptation in a sense of practical deployment, where only the interface of\nsource model is available to the target domain, and where the label-space\nrelations between the two domains are allowed to be different and unknown. We\nterm such a setting as Universal Black-Box Domain Adaptation (UB$^2$DA). The\ngreat promise that UB$^2$DA makes, however, brings significant learning\nchallenges, since domain adaptation can only rely on the predictions of\nunlabeled target data in a partially overlapped label space, by accessing the\ninterface of source model. To tackle the challenges, we first note that the\nlearning task can be converted as two subtasks of in-class\\footnote{In this\npaper we use in-class (out-class) to describe the classes observed (not\nobserved) in the source black-box model.} discrimination and out-class\ndetection, which can be respectively learned by model distillation and entropy\nseparation. We propose to unify them into a self-training framework,\nregularized by consistency of predictions in local neighborhoods of target\nsamples. Our framework is simple, robust, and easy to be optimized. Experiments\non domain adaptation benchmarks show its efficacy. Notably, by accessing the\ninterface of source model only, our framework outperforms existing methods of\nuniversal domain adaptation that make use of source data and/or source models,\nwith a newly proposed (and arguably more reasonable) metric of H-score, and\nperforms on par with them with the metric of averaged class accuracy.\n", "versions": [{"version": "v1", "created": "Sat, 10 Apr 2021 02:21:09 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Deng", "Bin", ""], ["Zhang", "Yabin", ""], ["Tang", "Hui", ""], ["Ding", "Changxing", ""], ["Jia", "Kui", ""]]}, {"id": "2104.04668", "submitter": "Reo Yoneyama", "authors": "Reo Yoneyama, Yi-Chiao Wu, Tomoki Toda", "title": "Unified Source-Filter GAN: Unified Source-filter Network Based On\n  Factorization of Quasi-Periodic Parallel WaveGAN", "comments": "Submitted to INTERSPEECH 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a unified approach to data-driven source-filter modeling using a\nsingle neural network for developing a neural vocoder capable of generating\nhigh-quality synthetic speech waveforms while retaining flexibility of the\nsource-filter model to control their voice characteristics. Our proposed\nnetwork called unified source-filter generative adversarial networks (uSFGAN)\nis developed by factorizing quasi-periodic parallel WaveGAN (QPPWG), one of the\nneural vocoders based on a single neural network, into a source excitation\ngeneration network and a vocal tract resonance filtering network by\nadditionally implementing a regularization loss. Moreover, inspired by neural\nsource filter (NSF), only a sinusoidal waveform is additionally used as the\nsimplest clue to generate a periodic source excitation waveform while\nminimizing the effect of approximations in the source filter model. The\nexperimental results demonstrate that uSFGAN outperforms conventional neural\nvocoders, such as QPPWG and NSF in both speech quality and pitch\ncontrollability.\n", "versions": [{"version": "v1", "created": "Sat, 10 Apr 2021 02:38:26 GMT"}, {"version": "v2", "created": "Tue, 13 Apr 2021 03:14:06 GMT"}, {"version": "v3", "created": "Sun, 27 Jun 2021 11:30:56 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Yoneyama", "Reo", ""], ["Wu", "Yi-Chiao", ""], ["Toda", "Tomoki", ""]]}, {"id": "2104.04672", "submitter": "Chen Liu", "authors": "Nanyan Zhu, Chen Liu, Xinyang Feng, Dipika Sikka, Sabrina\n  Gjerswold-Selleck, Scott A. Small, Jia Guo", "title": "Deep Learning Identifies Neuroimaging Signatures of Alzheimer's Disease\n  Using Structural and Synthesized Functional MRI Data", "comments": "Published in IEEE ISBI 2021. Available at\n  https://ieeexplore.ieee.org/document/9433808", "journal-ref": null, "doi": "10.1109/ISBI48211.2021.9433808", "report-no": null, "categories": "q-bio.QM cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Current neuroimaging techniques provide paths to investigate the structure\nand function of the brain in vivo and have made great advances in understanding\nAlzheimer's disease (AD). However, the group-level analyses prevalently used\nfor investigation and understanding of the disease are not applicable for\ndiagnosis of individuals. More recently, deep learning, which can efficiently\nanalyze large-scale complex patterns in 3D brain images, has helped pave the\nway for computer-aided individual diagnosis by providing accurate and automated\ndisease classification. Great progress has been made in classifying AD with\ndeep learning models developed upon increasingly available structural MRI data.\nThe lack of scale-matched functional neuroimaging data prevents such models\nfrom being further improved by observing functional changes in pathophysiology.\nHere we propose a potential solution by first learning a\nstructural-to-functional transformation in brain MRI, and further synthesizing\nspatially matched functional images from large-scale structural scans. We\nevaluated our approach by building computational models to discriminate\npatients with AD from healthy normal subjects and demonstrated a performance\nboost after combining the structural and synthesized functional brain images\ninto the same model. Furthermore, our regional analyses identified the temporal\nlobe to be the most predictive structural-region and the parieto-occipital lobe\nto be the most predictive functional-region of our model, which are both in\nconcordance with previous group-level neuroimaging findings. Together, we\ndemonstrate the potential of deep learning with large-scale structural and\nsynthesized functional MRI to impact AD classification and to identify AD's\nneuroimaging signatures.\n", "versions": [{"version": "v1", "created": "Sat, 10 Apr 2021 03:16:33 GMT"}, {"version": "v2", "created": "Fri, 28 May 2021 15:56:28 GMT"}], "update_date": "2021-05-31", "authors_parsed": [["Zhu", "Nanyan", ""], ["Liu", "Chen", ""], ["Feng", "Xinyang", ""], ["Sikka", "Dipika", ""], ["Gjerswold-Selleck", "Sabrina", ""], ["Small", "Scott A.", ""], ["Guo", "Jia", ""]]}, {"id": "2104.04676", "submitter": "Xutan Peng", "authors": "Xutan Peng, Guanyi Chen, Chenghua Lin, Mark Stevenson", "title": "Highly Efficient Knowledge Graph Embedding Learning with Orthogonal\n  Procrustes Analysis", "comments": "To appear at NAACL 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge Graph Embeddings (KGEs) have been intensively explored in recent\nyears due to their promise for a wide range of applications. However, existing\nstudies focus on improving the final model performance without acknowledging\nthe computational cost of the proposed approaches, in terms of execution time\nand environmental impact. This paper proposes a simple yet effective KGE\nframework which can reduce the training time and carbon footprint by orders of\nmagnitudes compared with state-of-the-art approaches, while producing\ncompetitive performance. We highlight three technical innovations: full batch\nlearning via relational matrices, closed-form Orthogonal Procrustes Analysis\nfor KGEs, and non-negative-sampling training. In addition, as the first KGE\nmethod whose entity embeddings also store full relation information, our\ntrained models encode rich semantics and are highly interpretable.\nComprehensive experiments and ablation studies involving 13 strong baselines\nand two standard datasets verify the effectiveness and efficiency of our\nalgorithm.\n", "versions": [{"version": "v1", "created": "Sat, 10 Apr 2021 03:55:45 GMT"}, {"version": "v2", "created": "Sat, 17 Apr 2021 12:17:05 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Peng", "Xutan", ""], ["Chen", "Guanyi", ""], ["Lin", "Chenghua", ""], ["Stevenson", "Mark", ""]]}, {"id": "2104.04679", "submitter": "Ken Kobayashi", "authors": "Akinori Tanaka, Akiyoshi Sannai, Ken Kobayashi, and Naoki Hamada", "title": "Approximate Bayesian Computation of B\\'ezier Simplices", "comments": null, "journal-ref": null, "doi": null, "report-no": "RIKEN-iTHEMS-Report-21", "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  B\\'ezier simplex fitting algorithms have been recently proposed to\napproximate the Pareto set/front of multi-objective continuous optimization\nproblems. These new methods have shown to be successful at approximating\nvarious shapes of Pareto sets/fronts when sample points exactly lie on the\nPareto set/front. However, if the sample points scatter away from the Pareto\nset/front, those methods often likely suffer from over-fitting. To overcome\nthis issue, in this paper, we extend the B\\'ezier simplex model to a\nprobabilistic one and propose a new learning algorithm of it, which falls into\nthe framework of approximate Bayesian computation (ABC) based on the\nWasserstein distance. We also study the convergence property of the Wasserstein\nABC algorithm. An extensive experimental evaluation on publicly available\nproblem instances shows that the new algorithm converges on a finite sample.\nMoreover, it outperforms the deterministic fitting methods on noisy instances.\n", "versions": [{"version": "v1", "created": "Sat, 10 Apr 2021 04:20:19 GMT"}, {"version": "v2", "created": "Tue, 13 Apr 2021 01:44:44 GMT"}], "update_date": "2021-04-14", "authors_parsed": [["Tanaka", "Akinori", ""], ["Sannai", "Akiyoshi", ""], ["Kobayashi", "Ken", ""], ["Hamada", "Naoki", ""]]}, {"id": "2104.04697", "submitter": "Cheng-Te Li", "authors": "Chih-Yao Chen, Cheng-Te Li", "title": "ZS-BERT: Towards Zero-Shot Relation Extraction with Attribute\n  Representation Learning", "comments": "Accepted to NAACL 2021. Code is available at\n  https://github.com/dinobby/ZS-BERT", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While relation extraction is an essential task in knowledge acquisition and\nrepresentation, and new-generated relations are common in the real world, less\neffort is made to predict unseen relations that cannot be observed at the\ntraining stage. In this paper, we formulate the zero-shot relation extraction\nproblem by incorporating the text description of seen and unseen relations. We\npropose a novel multi-task learning model, zero-shot BERT (ZS-BERT), to\ndirectly predict unseen relations without hand-crafted attribute labeling and\nmultiple pairwise classifications. Given training instances consisting of input\nsentences and the descriptions of their relations, ZS-BERT learns two functions\nthat project sentences and relation descriptions into an embedding space by\njointly minimizing the distances between them and classifying seen relations.\nBy generating the embeddings of unseen relations and new-coming sentences based\non such two functions, we use nearest neighbor search to obtain the prediction\nof unseen relations. Experiments conducted on two well-known datasets exhibit\nthat ZS-BERT can outperform existing methods by at least 13.54\\% improvement on\nF1 score.\n", "versions": [{"version": "v1", "created": "Sat, 10 Apr 2021 06:53:41 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Chen", "Chih-Yao", ""], ["Li", "Cheng-Te", ""]]}, {"id": "2104.04704", "submitter": "Swapnil Mache", "authors": "Swapnil Mache, Praveen Kumar Pokala, Kusala Rajendran and Chandra\n  Sekhar Seelamantula", "title": "DuRIN: A Deep-unfolded Sparse Seismic Reflectivity Inversion Network", "comments": "12 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.geo-ph cs.LG eess.SP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We consider the reflection seismology problem of recovering the locations of\ninterfaces and the amplitudes of reflection coefficients from seismic data,\nwhich are vital for estimating the subsurface structure. The reflectivity\ninversion problem is typically solved using greedy algorithms and iterative\ntechniques. Sparse Bayesian learning framework, and more recently, deep\nlearning techniques have shown the potential of data-driven approaches to solve\nthe problem. In this paper, we propose a weighted minimax-concave\npenalty-regularized reflectivity inversion formulation and solve it through a\nmodel-based neural network. The network is referred to as deep-unfolded\nreflectivity inversion network (DuRIN). We demonstrate the efficacy of the\nproposed approach over the benchmark techniques by testing on synthetic 1-D\nseismic traces and 2-D wedge models and validation with the simulated 2-D\nMarmousi2 model and real data from the Penobscot 3D survey off the coast of\nNova Scotia, Canada.\n", "versions": [{"version": "v1", "created": "Sat, 10 Apr 2021 07:49:38 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Mache", "Swapnil", ""], ["Pokala", "Praveen Kumar", ""], ["Rajendran", "Kusala", ""], ["Seelamantula", "Chandra Sekhar", ""]]}, {"id": "2104.04706", "submitter": "Amir M. Mir", "authors": "Amir M. Mir, Evaldas Latoskinas, Georgios Gousios", "title": "ManyTypes4Py: A Benchmark Python Dataset for Machine Learning-based Type\n  Inference", "comments": "MSR'21, Data Showcase To download the dataset, check out its GitHub\n  repo: https://github.com/saltudelft/many-types-4-py-dataset", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.LG cs.PL", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  In this paper, we present ManyTypes4Py, a large Python dataset for machine\nlearning (ML)-based type inference. The dataset contains a total of 5,382\nPython projects with more than 869K type annotations. Duplicate source code\nfiles were removed to eliminate the negative effect of the duplication bias. To\nfacilitate training and evaluation of ML models, the dataset was split into\ntraining, validation and test sets by files. To extract type information from\nabstract syntax trees (ASTs), a lightweight static analyzer pipeline is\ndeveloped and accompanied with the dataset. Using this pipeline, the collected\nPython projects were analyzed and the results of the AST analysis were stored\nin JSON-formatted files. The ManyTypes4Py dataset is shared on zenodo and its\ntools are publicly available on GitHub.\n", "versions": [{"version": "v1", "created": "Sat, 10 Apr 2021 08:10:06 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Mir", "Amir M.", ""], ["Latoskinas", "Evaldas", ""], ["Gousios", "Georgios", ""]]}, {"id": "2104.04710", "submitter": "Claudio Gallicchio", "authors": "Filippo Maria Bianchi, Claudio Gallicchio, Alessio Micheli", "title": "Pyramidal Reservoir Graph Neural Network", "comments": "this is a pre-print version of a paper submitted for journal\n  publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  We propose a deep Graph Neural Network (GNN) model that alternates two types\nof layers. The first type is inspired by Reservoir Computing (RC) and generates\nnew vertex features by iterating a non-linear map until it converges to a fixed\npoint. The second type of layer implements graph pooling operations, that\ngradually reduce the support graph and the vertex features, and further improve\nthe computational efficiency of the RC-based GNN. The architecture is,\ntherefore, pyramidal. In the last layer, the features of the remaining vertices\nare combined into a single vector, which represents the graph embedding.\nThrough a mathematical derivation introduced in this paper, we show formally\nhow graph pooling can reduce the computational complexity of the model and\nspeed-up the convergence of the dynamical updates of the vertex features. Our\nproposed approach to the design of RC-based GNNs offers an advantageous and\nprincipled trade-off between accuracy and complexity, which we extensively\ndemonstrate in experiments on a large set of graph datasets.\n", "versions": [{"version": "v1", "created": "Sat, 10 Apr 2021 08:34:09 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Bianchi", "Filippo Maria", ""], ["Gallicchio", "Claudio", ""], ["Micheli", "Alessio", ""]]}, {"id": "2104.04714", "submitter": "Chuanhou Gao", "authors": "Qiuqiang Lin, Chuanhou Gao", "title": "Random Intersection Chains", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interactions between several features sometimes play an important role in\nprediction tasks. But taking all the interactions into consideration will lead\nto an extremely heavy computational burden. For categorical features, the\nsituation is more complicated since the input will be extremely\nhigh-dimensional and sparse if one-hot encoding is applied. Inspired by\nassociation rule mining, we propose a method that selects interactions of\ncategorical features, called Random Intersection Chains. It uses random\nintersections to detect frequent patterns, then selects the most meaningful\nones among them. At first a number of chains are generated, in which each node\nis the intersection of the previous node and a random chosen observation. The\nfrequency of patterns in the tail nodes is estimated by maximum likelihood\nestimation, then the patterns with largest estimated frequency are selected.\nAfter that, their confidence is calculated by Bayes' theorem. The most\nconfident patterns are finally returned by Random Intersection Chains. We show\nthat if the number and length of chains are appropriately chosen, the patterns\nin the tail nodes are indeed the most frequent ones in the data set. We analyze\nthe computation complexity of the proposed algorithm and prove the convergence\nof the estimators. The results of a series of experiments verify the efficiency\nand effectiveness of the algorithm.\n", "versions": [{"version": "v1", "created": "Sat, 10 Apr 2021 08:41:15 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Lin", "Qiuqiang", ""], ["Gao", "Chuanhou", ""]]}, {"id": "2104.04718", "submitter": "Pak Lok Poon", "authors": "Tsong Yueh Chen, Pak-Lok Poon, Kun Qiu, Zheng Zheng, Jinyi Zhou", "title": "Use of Metamorphic Relations as Knowledge Carriers to Train Deep Neural\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training multiple-layered deep neural networks (DNNs) is difficult. The\nstandard practice of using a large number of samples for training often does\nnot improve the performance of a DNN to a satisfactory level. Thus, a\nsystematic training approach is needed. To address this need, we introduce an\ninnovative approach of using metamorphic relations (MRs) as \"knowledge\ncarriers\" to train DNNs. Based on the concept of metamorphic testing and MRs\n(which play the role of a test oracle in software testing), we make use of the\nnotion of metamorphic group of inputs as concrete instances of MRs (which are\nabstractions of knowledge) to train a DNN in a systematic and effective manner.\nTo verify the viability of our training approach, we have conducted a\npreliminary experiment to compare the performance of two DNNs: one trained with\nMRs and the other trained without MRs. We found that the DNN trained with MRs\nhas delivered a better performance, thereby confirming that our approach of\nusing MRs as knowledge carriers to train DNNs is promising. More work and\nstudies, however, are needed to solidify and leverage this approach to generate\nwidespread impact on effective DNN training.\n", "versions": [{"version": "v1", "created": "Sat, 10 Apr 2021 09:15:17 GMT"}, {"version": "v2", "created": "Tue, 11 May 2021 05:13:39 GMT"}], "update_date": "2021-05-12", "authors_parsed": [["Chen", "Tsong Yueh", ""], ["Poon", "Pak-Lok", ""], ["Qiu", "Kun", ""], ["Zheng", "Zheng", ""], ["Zhou", "Jinyi", ""]]}, {"id": "2104.04728", "submitter": "Chuanhou Gao", "authors": "Qiuqiang Lin, Chuanhou Gao", "title": "Discovering Categorical Main and Interaction Effects Based on\n  Association Rule Mining", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the growing size of data sets, feature selection becomes increasingly\nimportant. Taking interactions of original features into consideration will\nlead to extremely high dimension, especially when the features are categorical\nand one-hot encoding is applied. This makes it more worthwhile mining useful\nfeatures as well as their interactions. Association rule mining aims to extract\ninteresting correlations between items, but it is difficult to use rules as a\nqualified classifier themselves. Drawing inspiration from association rule\nmining, we come up with a method that uses association rules to select features\nand their interactions, then modify the algorithm for several practical\nconcerns. We analyze the computational complexity of the proposed algorithm to\nshow its efficiency. And the results of a series of experiments verify the\neffectiveness of the algorithm.\n", "versions": [{"version": "v1", "created": "Sat, 10 Apr 2021 10:13:07 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Lin", "Qiuqiang", ""], ["Gao", "Chuanhou", ""]]}, {"id": "2104.04731", "submitter": "Dennis Rieber", "authors": "Dennis Rieber, Axel Acosta, Holger Fr\\\"oning", "title": "Joint Program and Layout Transformations to enable DNN Operators on\n  Specialized Hardware based on Constraint Programming", "comments": "25 Pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The success of Deep Artificial Neural Networks (DNNs) in many domains created\na rich body of research concerned with hardwareaccelerators for\ncompute-intensive DNN operators. However, implementing such operators\nefficiently with complex hardwareintrinsics such as matrix multiply is a task\nnot yet automated gracefully. Solving this task often requires joint program\nand data layouttransformations. First solutions to this problem have been\nproposed, such as TVM, UNIT or ISAMIR, which work on a loop-levelrepresentation\nof operators and specify data layout and possible program transformations\nbefore the embedding into the operator isperformed. This top-down approach\ncreates a tension between exploration range and search space complexity,\nespecially when alsoexploring data layout transformations such as im2col,\nchannel packing or padding.In this work, we propose a new approach to this\nproblem. We created a bottom-up method that allows the joint transformation\nofboth compuation and data layout based on the found embedding. By formulating\nthe embedding as a constraint satisfaction problemover the scalar dataflow,\nevery possible embedding solution is contained in the search space. Adding\nadditional constraints andoptmization targets to the solver generates the\nsubset of preferable solutions.An evaluation using the VTA hardware accelerator\nwith the Baidu DeepBench inference benchmark shows that our approach\ncanautomatically generate code competitive to reference implementations.\nFurther, we show that dynamically determining the data layoutbased on intrinsic\nand workload is beneficial for hardware utilization and performance. In cases\nwhere the reference implementationhas low hardware utilization due to its fixed\ndeployment strategy, we achieve a geomean speedup of up to x2.813, while\nindividualoperators can improve as much as x170.\n", "versions": [{"version": "v1", "created": "Sat, 10 Apr 2021 10:39:47 GMT"}, {"version": "v2", "created": "Tue, 13 Apr 2021 06:16:45 GMT"}, {"version": "v3", "created": "Fri, 9 Jul 2021 06:42:29 GMT"}], "update_date": "2021-07-12", "authors_parsed": [["Rieber", "Dennis", ""], ["Acosta", "Axel", ""], ["Fr\u00f6ning", "Holger", ""]]}, {"id": "2104.04739", "submitter": "Anna Glazkova", "authors": "Mikhail Kotyushev, Anna Glazkova, Dmitry Morozov", "title": "MIPT-NSU-UTMN at SemEval-2021 Task 5: Ensembling Learning with\n  Pre-trained Language Models for Toxic Spans Detection", "comments": "Accepted at SemEval-2021 Workshop, ACL-IJCNLP 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper describes our system for SemEval-2021 Task 5 on Toxic Spans\nDetection. We developed ensemble models using BERT-based neural architectures\nand post-processing to combine tokens into spans. We evaluated several\npre-trained language models using various ensemble techniques for toxic span\nidentification and achieved sizable improvements over our baseline fine-tuned\nBERT models. Finally, our system obtained a F1-score of 67.55% on test data.\n", "versions": [{"version": "v1", "created": "Sat, 10 Apr 2021 11:27:32 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Kotyushev", "Mikhail", ""], ["Glazkova", "Anna", ""], ["Morozov", "Dmitry", ""]]}, {"id": "2104.04748", "submitter": "Zhengxu Hou", "authors": "Zhengxu Hou, Bang Liu, Ruihui Zhao, Zijing Ou, Yafei Liu, Xi Chen,\n  Yefeng Zheng", "title": "Imperfect also Deserves Reward: Multi-Level and Sequential Reward\n  Modeling for Better Dialog Management", "comments": "9 pages", "journal-ref": "NAACL 2021", "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For task-oriented dialog systems, training a Reinforcement Learning (RL)\nbased Dialog Management module suffers from low sample efficiency and slow\nconvergence speed due to the sparse rewards in RL.To solve this problem, many\nstrategies have been proposed to give proper rewards when training RL, but\ntheir rewards lack interpretability and cannot accurately estimate the\ndistribution of state-action pairs in real dialogs. In this paper, we propose a\nmulti-level reward modeling approach that factorizes a reward into a\nthree-level hierarchy: domain, act, and slot. Based on inverse adversarial\nreinforcement learning, our designed reward model can provide more accurate and\nexplainable reward signals for state-action pairs.Extensive evaluations show\nthat our approach can be applied to a wide range of reinforcement\nlearning-based dialog systems and significantly improves both the performance\nand the speed of convergence.\n", "versions": [{"version": "v1", "created": "Sat, 10 Apr 2021 12:20:23 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Hou", "Zhengxu", ""], ["Liu", "Bang", ""], ["Zhao", "Ruihui", ""], ["Ou", "Zijing", ""], ["Liu", "Yafei", ""], ["Chen", "Xi", ""], ["Zheng", "Yefeng", ""]]}, {"id": "2104.04757", "submitter": "Vincent Tan", "authors": "Ting Cai, Vincent Y. F. Tan, C\\'edric F\\'evotte", "title": "Adversarially-Trained Nonnegative Matrix Factorization", "comments": "Accepted to the IEEE Signal Processing Letters; 5 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We consider an adversarially-trained version of the nonnegative matrix\nfactorization, a popular latent dimensionality reduction technique. In our\nformulation, an attacker adds an arbitrary matrix of bounded norm to the given\ndata matrix. We design efficient algorithms inspired by adversarial training to\noptimize for dictionary and coefficient matrices with enhanced generalization\nabilities. Extensive simulations on synthetic and benchmark datasets\ndemonstrate the superior predictive performance on matrix completion tasks of\nour proposed method compared to state-of-the-art competitors, including other\nvariants of adversarial nonnegative matrix factorization.\n", "versions": [{"version": "v1", "created": "Sat, 10 Apr 2021 13:13:17 GMT"}, {"version": "v2", "created": "Tue, 22 Jun 2021 10:46:19 GMT"}], "update_date": "2021-06-23", "authors_parsed": [["Cai", "Ting", ""], ["Tan", "Vincent Y. F.", ""], ["F\u00e9votte", "C\u00e9dric", ""]]}, {"id": "2104.04764", "submitter": "Alex Sun", "authors": "Alexander Y. Sun, Hongkyu Yoon, Chung-Yan Shih, Zhi Zhong", "title": "Applications of physics-informed scientific machine learning in\n  subsurface science: A survey", "comments": "20 pages, 2 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.geo-ph cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Geosystems are geological formations altered by humans activities such as\nfossil energy exploration, waste disposal, geologic carbon sequestration, and\nrenewable energy generation. Geosystems also represent a critical link in the\nglobal water-energy nexus, providing both the source and buffering mechanisms\nfor enabling societal adaptation to climate variability and change. The\nresponsible use and exploration of geosystems are thus critical to the\ngeosystem governance, which in turn depends on the efficient monitoring, risk\nassessment, and decision support tools for practical implementation. Fast\nadvances in machine learning (ML) algorithms and novel sensing technologies in\nrecent years have presented new opportunities for the subsurface research\ncommunity to improve the efficacy and transparency of geosystem governance.\nAlthough recent studies have shown the great promise of scientific ML (SciML)\nmodels, questions remain on how to best leverage ML in the management of\ngeosystems, which are typified by multiscality, high-dimensionality, and data\nresolution inhomogeneity. This survey will provide a systematic review of the\nrecent development and applications of domain-aware SciML in geosystem\nresearches, with an emphasis on how the accuracy, interpretability,\nscalability, defensibility, and generalization skill of ML approaches can be\nimproved to better serve the geoscientific community.\n", "versions": [{"version": "v1", "created": "Sat, 10 Apr 2021 13:40:22 GMT"}, {"version": "v2", "created": "Tue, 13 Apr 2021 12:09:57 GMT"}], "update_date": "2021-04-14", "authors_parsed": [["Sun", "Alexander Y.", ""], ["Yoon", "Hongkyu", ""], ["Shih", "Chung-Yan", ""], ["Zhong", "Zhi", ""]]}, {"id": "2104.04765", "submitter": "Nitin Khanna Dr.", "authors": "Vinay Verma, Deepak Singh, and Nitin Khanna", "title": "Q-matrix Unaware Double JPEG Detection using DCT-Domain Deep BiLSTM\n  Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG cs.MM", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  The double JPEG compression detection has received much attention in recent\nyears due to its applicability as a forensic tool for the most widely used JPEG\nfile format. Existing state-of-the-art CNN-based methods either use histograms\nof all the frequencies or rely on heuristics to select histograms of specific\nlow frequencies to classify single and double compressed images. However, even\namidst lower frequencies of double compressed images/patches, histograms of all\nthe frequencies do not have distinguishable features to separate them from\nsingle compressed images. This paper directly extracts the quantized DCT\ncoefficients from the JPEG images without decompressing them in the pixel\ndomain, obtains all AC frequencies' histograms, uses a module based on $1\\times\n1$ depth-wise convolutions to learn the inherent relation between each\nhistogram and corresponding q-factor, and utilizes a tailor-made BiLSTM network\nfor selectively encoding these feature vector sequences. The proposed system\noutperforms several baseline methods on a relatively large and diverse publicly\navailable dataset of single and double compressed patches. Another essential\naspect of any single vs. double JPEG compression detection system is handling\nthe scenario where test patches are compressed with entirely different\nquantization matrices (Q-matrices) than those used while training; different\ncamera manufacturers and image processing software generally utilize their\ncustomized quantization matrices. A set of extensive experiments shows that the\nproposed system trained on a single dataset generalizes well on other datasets\ncompressed with completely unseen quantization matrices and outperforms the\nstate-of-the-art methods in both seen and unseen quantization matrices\nscenarios.\n", "versions": [{"version": "v1", "created": "Sat, 10 Apr 2021 13:41:29 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Verma", "Vinay", ""], ["Singh", "Deepak", ""], ["Khanna", "Nitin", ""]]}, {"id": "2104.04768", "submitter": "Alexandre Chenu", "authors": "Alexandre Chenu, Nicolas Perrin-Gilbert, St\\'ephane Doncieux, Olivier\n  Sigaud", "title": "Selection-Expansion: A Unifying Framework for Motion-Planning and\n  Diversity Search Algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning agents need a reward signal to learn successful\npolicies. When this signal is sparse or the corresponding gradient is\ndeceptive, such agents need a dedicated mechanism to efficiently explore their\nsearch space without relying on the reward. Looking for a large diversity of\nbehaviors or using Motion Planning (MP) algorithms are two options in this\ncontext. In this paper, we build on the common roots between these two options\nto investigate the properties of two diversity search algorithms, the Novelty\nSearch and the Goal Exploration Process algorithms. These algorithms look for\ndiversity in an outcome space or behavioral space which is generally\nhand-designed to represent what matters for a given task. The relation to MP\nalgorithms reveals that the smoothness, or lack of smoothness of the mapping\nbetween the policy parameter space and the outcome space plays a key role in\nthe search efficiency. In particular, we show empirically that, if the mapping\nis smooth enough, i.e. if two close policies in the parameter space lead to\nsimilar outcomes, then diversity algorithms tend to inherit exploration\nproperties of MP algorithms. By contrast, if it is not, diversity algorithms\nlose these properties and their performance strongly depends on specific\nheuristics, notably filtering mechanisms that discard some of the explored\npolicies.\n", "versions": [{"version": "v1", "created": "Sat, 10 Apr 2021 13:52:27 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Chenu", "Alexandre", ""], ["Perrin-Gilbert", "Nicolas", ""], ["Doncieux", "St\u00e9phane", ""], ["Sigaud", "Olivier", ""]]}, {"id": "2104.04781", "submitter": "Sankeerth Rao Karingula", "authors": "Sankeerth Rao Karingula and Nandini Ramanan and Rasool Tahmasbi and\n  Mehrnaz Amjadi and Deokwoo Jung and Ricky Si and Charanraj Thimmisetty and\n  Luisa Polania Cabrera and Marjorie Sayer and Claudionor Nunes Coelho Jr", "title": "Boosted Embeddings for Time Series Forecasting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Time series forecasting is a fundamental task emerging from diverse\ndata-driven applications. Many advanced autoregressive methods such as ARIMA\nwere used to develop forecasting models. Recently, deep learning based methods\nsuch as DeepAr, NeuralProphet, Seq2Seq have been explored for time series\nforecasting problem. In this paper, we propose a novel time series forecast\nmodel, DeepGB. We formulate and implement a variant of Gradient boosting\nwherein the weak learners are DNNs whose weights are incrementally found in a\ngreedy manner over iterations. In particular, we develop a new embedding\narchitecture that improves the performance of many deep learning models on time\nseries using Gradient boosting variant. We demonstrate that our model\noutperforms existing comparable state-of-the-art models using real-world sensor\ndata and public dataset.\n", "versions": [{"version": "v1", "created": "Sat, 10 Apr 2021 14:38:11 GMT"}, {"version": "v2", "created": "Sun, 11 Jul 2021 17:45:20 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Karingula", "Sankeerth Rao", ""], ["Ramanan", "Nandini", ""], ["Tahmasbi", "Rasool", ""], ["Amjadi", "Mehrnaz", ""], ["Jung", "Deokwoo", ""], ["Si", "Ricky", ""], ["Thimmisetty", "Charanraj", ""], ["Cabrera", "Luisa Polania", ""], ["Sayer", "Marjorie", ""], ["Coelho", "Claudionor Nunes", "Jr"]]}, {"id": "2104.04785", "submitter": "Bjorn Lutjens", "authors": "Bj\\\"orn L\\\"utjens, Brandon Leshchinskiy, Christian Requena-Mesa,\n  Farrukh Chishtie, Natalia D\\'iaz-Rodr\\'iguez, Oc\\'eane Boulais, Aruna\n  Sankaranarayanan, Aaron Pi\\~na, Yarin Gal, Chedy Ra\\\"issi, Alexander Lavin,\n  Dava Newman", "title": "Physically-Consistent Generative Adversarial Networks for Coastal Flood\n  Visualization", "comments": "arXiv admin note: text overlap with arXiv:2010.08103", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As climate change increases the intensity of natural disasters, society needs\nbetter tools for adaptation. Floods, for example, are the most frequent natural\ndisaster, and better tools for flood risk communication could increase the\nsupport for flood-resilient infrastructure development. Our work aims to enable\nmore visual communication of large-scale climate impacts via visualizing the\noutput of coastal flood models as satellite imagery. We propose the first deep\nlearning pipeline to ensure physical-consistency in synthetic visual satellite\nimagery. We advanced a state-of-the-art GAN called pix2pixHD, such that it\nproduces imagery that is physically-consistent with the output of an\nexpert-validated storm surge model (NOAA SLOSH). By evaluating the imagery\nrelative to physics-based flood maps, we find that our proposed framework\noutperforms baseline models in both physical-consistency and photorealism. We\nenvision our work to be the first step towards a global visualization of how\nclimate change shapes our landscape. Continuing on this path, we show that the\nproposed pipeline generalizes to visualize arctic sea ice melt. We also publish\na dataset of over 25k labelled image-pairs to study image-to-image translation\nin Earth observation.\n", "versions": [{"version": "v1", "created": "Sat, 10 Apr 2021 15:00:15 GMT"}, {"version": "v2", "created": "Wed, 5 May 2021 13:19:04 GMT"}, {"version": "v3", "created": "Wed, 19 May 2021 18:56:56 GMT"}], "update_date": "2021-05-21", "authors_parsed": [["L\u00fctjens", "Bj\u00f6rn", ""], ["Leshchinskiy", "Brandon", ""], ["Requena-Mesa", "Christian", ""], ["Chishtie", "Farrukh", ""], ["D\u00edaz-Rodr\u00edguez", "Natalia", ""], ["Boulais", "Oc\u00e9ane", ""], ["Sankaranarayanan", "Aruna", ""], ["Pi\u00f1a", "Aaron", ""], ["Gal", "Yarin", ""], ["Ra\u00efssi", "Chedy", ""], ["Lavin", "Alexander", ""], ["Newman", "Dava", ""]]}, {"id": "2104.04787", "submitter": "Cuneyt Gurcan Akcora", "authors": "Baris Coskunuzer and CUneyt Gurcan Akcora and Ignacio Segovia\n  Dominguez and Zhiwei Zhen and Murat Kantarcioglu and Yulia R. Gel", "title": "Smart Vectorizations for Single and Multiparameter Persistence", "comments": "27 pages, 7 figures 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The machinery of topological data analysis becomes increasingly popular in a\nbroad range of machine learning tasks, ranging from anomaly detection and\nmanifold learning to graph classification. Persistent homology is one of the\nkey approaches here, allowing us to systematically assess the evolution of\nvarious hidden patterns in the data as we vary a scale parameter. The extracted\npatterns, or homological features, along with information on how long such\nfeatures persist throughout the considered filtration of a scale parameter,\nconvey a critical insight into salient data characteristics and data\norganization.\n  In this work, we introduce two new and easily interpretable topological\nsummaries for single and multi-parameter persistence, namely, saw functions and\nmulti-persistence grid functions, respectively. Compared to the existing\ntopological summaries which tend to assess the numbers of topological features\nand/or their lifespans at a given filtration step, our proposed saw and\nmulti-persistence grid functions allow us to explicitly account for essential\ncomplementary information such as the numbers of births and deaths at each\nfiltration step.\n  These new topological summaries can be regarded as the complexity measures of\nthe evolving subspaces determined by the filtration and are of particular\nutility for applications of persistent homology on graphs. We derive\ntheoretical guarantees on the stability of the new saw and multi-persistence\ngrid functions and illustrate their applicability for graph classification\ntasks.\n", "versions": [{"version": "v1", "created": "Sat, 10 Apr 2021 15:09:31 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Coskunuzer", "Baris", ""], ["Akcora", "CUneyt Gurcan", ""], ["Dominguez", "Ignacio Segovia", ""], ["Zhen", "Zhiwei", ""], ["Kantarcioglu", "Murat", ""], ["Gel", "Yulia R.", ""]]}, {"id": "2104.04790", "submitter": "Tinkle Chugh", "authors": "Clym Stock-Williams, Tinkle Chugh, Alma Rahat, Wei Yu", "title": "What Makes an Effective Scalarising Function for Multi-Objective\n  Bayesian Optimisation?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Performing multi-objective Bayesian optimisation by scalarising the\nobjectives avoids the computation of expensive multi-dimensional integral-based\nacquisition functions, instead of allowing one-dimensional standard acquisition\nfunctions\\textemdash such as Expected Improvement\\textemdash to be applied.\nHere, two infill criteria based on hypervolume improvement\\textemdash one\nrecently introduced and one novel\\textemdash are compared with the\nmulti-surrogate Expected Hypervolume Improvement. The reasons for the\ndisparities in these methods' effectiveness in maximising the hypervolume of\nthe acquired Pareto Front are investigated. In addition, the effect of the\nsurrogate model mean function on exploration and exploitation is examined:\ncareful choice of data normalisation is shown to be preferable to the\nexploration parameter commonly used with the Expected Improvement acquisition\nfunction. Finally, the effectiveness of all the methodological improvements\ndefined here is demonstrated on a real-world problem: the optimisation of a\nwind turbine blade aerofoil for both aerodynamic performance and structural\nstiffness. With effective scalarisation, Bayesian optimisation finds a large\nnumber of new aerofoil shapes that strongly dominate standard designs.\n", "versions": [{"version": "v1", "created": "Sat, 10 Apr 2021 15:18:58 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Stock-Williams", "Clym", ""], ["Chugh", "Tinkle", ""], ["Rahat", "Alma", ""], ["Yu", "Wei", ""]]}, {"id": "2104.04795", "submitter": "Anwesh Bhattacharya", "authors": "Urvil Nileshbhai Jivani, Omatharv Bharat Vaidya, Anwesh Bhattacharya,\n  Snehanshu Saha", "title": "A Swarm Variant for the Schr\\\"odinger Solver", "comments": "8 pages, 5 figures, Accepted at IJCNN 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE math.OC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper introduces application of the Exponentially Averaged Momentum\nParticle Swarm Optimization (EM-PSO) as a derivative-free optimizer for Neural\nNetworks. It adopts PSO's major advantages such as search space exploration and\nhigher robustness to local minima compared to gradient-descent optimizers such\nas Adam. Neural network based solvers endowed with gradient optimization are\nnow being used to approximate solutions to Differential Equations. Here, we\ndemonstrate the novelty of EM-PSO in approximating gradients and leveraging the\nproperty in solving the Schr\\\"odinger equation, for the Particle-in-a-Box\nproblem. We also provide the optimal set of hyper-parameters supported by\nmathematical proofs, suited for our algorithm.\n", "versions": [{"version": "v1", "created": "Sat, 10 Apr 2021 15:51:36 GMT"}, {"version": "v2", "created": "Tue, 20 Apr 2021 12:58:32 GMT"}], "update_date": "2021-04-21", "authors_parsed": [["Jivani", "Urvil Nileshbhai", ""], ["Vaidya", "Omatharv Bharat", ""], ["Bhattacharya", "Anwesh", ""], ["Saha", "Snehanshu", ""]]}, {"id": "2104.04797", "submitter": "Anda Trifan", "authors": "Alexander Brace, Hyungro Lee, Heng Ma, Anda Trifan, Matteo Turilli,\n  Igor Yakushin, Todd Munson, Ian Foster, Shantenu Jha and Arvind Ramanathan", "title": "Achieving 100X faster simulations of complex biological phenomena by\n  coupling ML to HPC ensembles", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The use of ML methods to dynamically steer ensemble-based simulations\npromises significant improvements in the performance of scientific\napplications. We present DeepDriveMD, a tool for a range of prototypical\nML-driven HPC simulation scenarios, and use it to quantify improvements in the\nscientific performance of ML-driven ensemble-based applications. We discuss its\ndesign and characterize its performance. Motivated by the potential for further\nscientific improvements and applicability to more sophisticated physical\nsystems, we extend the design of DeepDriveMD to support stream-based\ncommunication between simulations and learning methods. It demonstrates a 100x\nspeedup to fold proteins, and performs 1.6x more simulations per unit time,\nimproving resource utilization compared to the sequential framework.\nExperiments are performed on leadership-class platforms, at scales of up to\nO(1000) nodes, and for production workloads. We establish DeepDriveMD as a\nhigh-performance framework for ML-driven HPC simulation scenarios, that\nsupports diverse simulation and ML back-ends, and which enables new scientific\ninsights by improving length- and time-scale accessed.\n", "versions": [{"version": "v1", "created": "Sat, 10 Apr 2021 15:52:39 GMT"}, {"version": "v2", "created": "Mon, 26 Apr 2021 16:35:20 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Brace", "Alexander", ""], ["Lee", "Hyungro", ""], ["Ma", "Heng", ""], ["Trifan", "Anda", ""], ["Turilli", "Matteo", ""], ["Yakushin", "Igor", ""], ["Munson", "Todd", ""], ["Foster", "Ian", ""], ["Jha", "Shantenu", ""], ["Ramanathan", "Arvind", ""]]}, {"id": "2104.04828", "submitter": "Radu Tudor Ionescu", "authors": "Radu Tudor Ionescu, Adrian Gabriel Chifu", "title": "FreSaDa: A French Satire Data Set for Cross-Domain Satire Detection", "comments": "Accepted at IJCNN 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce FreSaDa, a French Satire Data Set, which is\ncomposed of 11,570 articles from the news domain. In order to avoid reporting\nunreasonably high accuracy rates due to the learning of characteristics\nspecific to publication sources, we divided our samples into training,\nvalidation and test, such that the training publication sources are distinct\nfrom the validation and test publication sources. This gives rise to a\ncross-domain (cross-source) satire detection task. We employ two classification\nmethods as baselines for our new data set, one based on low-level features\n(character n-grams) and one based on high-level features (average of CamemBERT\nword embeddings). As an additional contribution, we present an unsupervised\ndomain adaptation method based on regarding the pairwise similarities (given by\nthe dot product) between the training samples and the validation samples as\nfeatures. By including these domain-specific features, we attain significant\nimprovements for both character n-grams and CamemBERT embeddings.\n", "versions": [{"version": "v1", "created": "Sat, 10 Apr 2021 18:21:53 GMT"}, {"version": "v2", "created": "Sun, 16 May 2021 07:28:47 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Ionescu", "Radu Tudor", ""], ["Chifu", "Adrian Gabriel", ""]]}, {"id": "2104.04829", "submitter": "Sally Ghanem", "authors": "Sally Ghanem, Siddharth Roheda, and Hamid Krim", "title": "Latent Code-Based Fusion: A Volterra Neural Network Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose a deep structure encoder using the recently introduced Volterra\nNeural Networks (VNNs) to seek a latent representation of multi-modal data\nwhose features are jointly captured by a union of subspaces. The so-called\nself-representation embedding of the latent codes leads to a simplified fusion\nwhich is driven by a similarly constructed decoding. The Volterra Filter\narchitecture achieved reduction in parameter complexity is primarily due to\ncontrolled non-linearities being introduced by the higher-order convolutions in\ncontrast to generalized activation functions. Experimental results on two\ndifferent datasets have shown a significant improvement in the clustering\nperformance for VNNs auto-encoder over conventional Convolutional Neural\nNetworks (CNNs) auto-encoder. In addition, we also show that the proposed\napproach demonstrates a much-improved sample complexity over CNN-based\nauto-encoder with a superb robust classification performance.\n", "versions": [{"version": "v1", "created": "Sat, 10 Apr 2021 18:29:01 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Ghanem", "Sally", ""], ["Roheda", "Siddharth", ""], ["Krim", "Hamid", ""]]}, {"id": "2104.04840", "submitter": "Alexander Jones", "authors": "Alex Jones, Derry Tanti Wijaya", "title": "Sentiment-based Candidate Selection for NMT", "comments": "14 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The explosion of user-generated content (UGC)--e.g. social media posts,\ncomments, and reviews--has motivated the development of NLP applications\ntailored to these types of informal texts. Prevalent among these applications\nhave been sentiment analysis and machine translation (MT). Grounded in the\nobservation that UGC features highly idiomatic, sentiment-charged language, we\npropose a decoder-side approach that incorporates automatic sentiment scoring\ninto the MT candidate selection process. We train separate English and Spanish\nsentiment classifiers, then, using n-best candidates generated by a baseline MT\nmodel with beam search, select the candidate that minimizes the absolute\ndifference between the sentiment score of the source sentence and that of the\ntranslation, and perform a human evaluation to assess the produced\ntranslations. Unlike previous work, we select this minimally divergent\ntranslation by considering the sentiment scores of the source sentence and\ntranslation on a continuous interval, rather than using e.g. binary\nclassification, allowing for more fine-grained selection of translation\ncandidates. The results of human evaluations show that, in comparison to the\nopen-source MT baseline model on top of which our sentiment-based pipeline is\nbuilt, our pipeline produces more accurate translations of colloquial,\nsentiment-heavy source texts.\n", "versions": [{"version": "v1", "created": "Sat, 10 Apr 2021 19:01:52 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Jones", "Alex", ""], ["Wijaya", "Derry Tanti", ""]]}, {"id": "2104.04848", "submitter": "Sourya Basu", "authors": "Sourya Basu, Akshayaa Magesh, Harshit Yadav, Lav R. Varshney", "title": "Autoequivariant Network Search via Group Decomposition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recent works show that group equivariance as an inductive bias improves\nneural network performance for both classification and generation. However,\ndesigning group-equivariant neural networks is challenging when the group of\ninterest is large and is unknown. Moreover, inducing equivariance can\nsignificantly reduce the number of independent parameters in a network with\nfixed feature size, affecting its overall performance. We address these\nproblems by proving a new group-theoretic result in the context of equivariant\nneural networks that shows that a network is equivariant to a large group if\nand only if it is equivariant to smaller groups from which it is constructed.\nUsing this result, we design a novel fast group equivariant construction\nalgorithm, and a deep Q-learning-based search algorithm in a reduced search\nspace, yielding what we call autoequivariant networks (AENs). AENs find the\nright balance between equivariance and network size when tested on new\nbenchmark datasets, G-MNIST and G-Fashion-MNIST, obtained via group\ntransformations on MNIST and Fashion-MNIST respectively that we release.\nExtending these results to group convolutional neural networks, where we\noptimize between equivariances, augmentations, and network sizes, we find group\nequivariance to be the most dominating factor in all high-performing GCNNs on\nseveral datasets like CIFAR10, SVHN, RotMNIST, ASL, EMNIST, and KMNIST.\n", "versions": [{"version": "v1", "created": "Sat, 10 Apr 2021 19:37:25 GMT"}, {"version": "v2", "created": "Tue, 8 Jun 2021 17:43:10 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Basu", "Sourya", ""], ["Magesh", "Akshayaa", ""], ["Yadav", "Harshit", ""], ["Varshney", "Lav R.", ""]]}, {"id": "2104.04853", "submitter": "Shaojie Tang", "authors": "Shaojie Tang", "title": "Beyond Pointwise Submodularity: Non-Monotone Adaptive Submodular\n  Maximization subject to a Knapsack Constraint", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we study the non-monotone adaptive submodular maximization\nproblem subject to a knapsack constraint. The input of our problem is a set of\nitems, where each item has a particular state drawn from a known prior\ndistribution. However, the state of an item is initially unknown, one must\nselect an item in order to reveal the state of that item. Moreover, each item\nhas a fixed cost. There is a utility function which is defined over items and\nstates. Our objective is to sequentially select a group of items to maximize\nthe expected utility subject to a knapsack constraint. Although the\ncardinality-constrained, as well as the more general matroid-constrained,\nadaptive submodular maximization has been well studied in the literature,\nwhether there exists a constant approximation solution for the\nknapsack-constrained adaptive submodular maximization problem remains an open\nproblem. We fill this gap by proposing the first constant approximation\nsolution. In particular, our main contribution is to develop a sampling-based\nrandomized algorithm that achieves a $\\frac{1}{10}$ approximation for\nmaximizing an adaptive submodular function subject to a knapsack constraint.\n", "versions": [{"version": "v1", "created": "Sat, 10 Apr 2021 20:11:11 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Tang", "Shaojie", ""]]}, {"id": "2104.04855", "submitter": "Yifan Zhou", "authors": "Yifan Zhou and Peng Zhang", "title": "Noise-Resilient Quantum Machine Learning for Stability Assessment of\n  Power Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transient stability assessment (TSA) is a cornerstone for resilient\noperations of today's interconnected power grids. This paper is a confluence of\nquantum computing, data science and machine learning to potentially address the\npower system TSA challenge. We devise a quantum TSA (qTSA) method to enable\nscalable and efficient data-driven transient stability prediction for bulk\npower systems, which is the first attempt to tackle the TSA issue with quantum\ncomputing. Our contributions are three-fold: 1) A low-depth, high\nexpressibility quantum neural network for accurate and noise-resilient TSA; 2)\nA quantum natural gradient descent algorithm for efficient qTSA training; 3) A\nsystematical analysis on qTSA's performance under various quantum factors. qTSA\nunderpins a foundation of quantum-enabled and data-driven power grid stability\nanalytics. It renders the intractable TSA straightforward and effortless in the\nHilbert space, and therefore provides stability information for power system\noperations. Extensive experiments on quantum simulators and real quantum\ncomputers verify the accuracy, noise-resilience, scalability and universality\nof qTSA.\n", "versions": [{"version": "v1", "created": "Sat, 10 Apr 2021 20:26:09 GMT"}, {"version": "v2", "created": "Sun, 23 May 2021 22:26:56 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Zhou", "Yifan", ""], ["Zhang", "Peng", ""]]}, {"id": "2104.04866", "submitter": "Ruoyu Wang", "authors": "Ruoyu Wang, Xuchu Xu, Li Ding, Yang Huang, Chen Feng", "title": "Deep Weakly Supervised Positioning", "comments": "8 pages, 8 figures, submitted to IEEE Robotics and Automation Letters\n  (RA-L) and 2021 IEEE/RSJ International Conference on Intelligent Robots and\n  Systems (IROS 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  PoseNet can map a photo to the position where it is taken, which is appealing\nin robotics. However, training PoseNet requires full supervision, where ground\ntruth positions are non-trivial to obtain. Can we train PoseNet without knowing\nthe ground truth positions for each observation? We show that this is possible\nvia constraint-based weak-supervision, leading to the proposed framework:\nDeepGPS. Particularly, using wheel-encoder-estimated distances traveled by a\nrobot along random straight line segments as constraints between PoseNet\noutputs, DeepGPS can achieve a relative positioning error of less than 2%.\nMoreover, training DeepGPS can be done as auto-calibration with almost no human\nattendance, which is more attractive than its competing methods that typically\nrequire careful and expert-level manual calibration. We conduct various\nexperiments on simulated and real datasets to demonstrate the general\napplicability, effectiveness, and accuracy of DeepGPS, and perform a\ncomprehensive analysis of its robustness. Our code is available at\nhttps://ai4ce.github.io/DeepGPS/.\n", "versions": [{"version": "v1", "created": "Sat, 10 Apr 2021 21:19:08 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Wang", "Ruoyu", ""], ["Xu", "Xuchu", ""], ["Ding", "Li", ""], ["Huang", "Yang", ""], ["Feng", "Chen", ""]]}, {"id": "2104.04868", "submitter": "Zi Wang", "authors": "Zi Wang", "title": "Data-Free Knowledge Distillation with Soft Targeted Transfer Set\n  Synthesis", "comments": "Accepted to AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Knowledge distillation (KD) has proved to be an effective approach for deep\nneural network compression, which learns a compact network (student) by\ntransferring the knowledge from a pre-trained, over-parameterized network\n(teacher). In traditional KD, the transferred knowledge is usually obtained by\nfeeding training samples to the teacher network to obtain the class\nprobabilities. However, the original training dataset is not always available\ndue to storage costs or privacy issues. In this study, we propose a novel\ndata-free KD approach by modeling the intermediate feature space of the teacher\nwith a multivariate normal distribution and leveraging the soft targeted labels\ngenerated by the distribution to synthesize pseudo samples as the transfer set.\nSeveral student networks trained with these synthesized transfer sets present\ncompetitive performance compared to the networks trained with the original\ntraining set and other data-free KD approaches.\n", "versions": [{"version": "v1", "created": "Sat, 10 Apr 2021 22:42:14 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Wang", "Zi", ""]]}, {"id": "2104.04874", "submitter": "Dan Roberts", "authors": "Daniel A. Roberts", "title": "SGD Implicitly Regularizes Generalization Error", "comments": "First appeared at the \"Workshop on Integration of Deep Learning\n  Theories\" at NeurIPS in 2018 and has been available since then at\n  https://research.fb.com/publications/sgd-implicitly-regularizes-generalization-error/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We derive a simple and model-independent formula for the change in the\ngeneralization gap due to a gradient descent update. We then compare the change\nin the test error for stochastic gradient descent to the change in test error\nfrom an equivalent number of gradient descent updates and show explicitly that\nstochastic gradient descent acts to regularize generalization error by\ndecorrelating nearby updates. These calculations depends on the details of the\nmodel only through the mean and covariance of the gradient distribution, which\nmay be readily measured for particular models of interest. We discuss further\nimprovements to these calculations and comment on possible implications for\nstochastic optimization.\n", "versions": [{"version": "v1", "created": "Sat, 10 Apr 2021 23:10:14 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Roberts", "Daniel A.", ""]]}, {"id": "2104.04883", "submitter": "Michelle Li", "authors": "Michelle M. Li, Kexin Huang, Marinka Zitnik", "title": "Representation Learning for Networks in Biology and Medicine:\n  Advancements, Challenges, and Opportunities", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI q-bio.BM q-bio.GN q-bio.MN", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  With the remarkable success of representation learning in providing powerful\npredictions and data insights, we have witnessed a rapid expansion of\nrepresentation learning techniques into modeling, analysis, and learning with\nnetworks. Biomedical networks are universal descriptors of systems of\ninteracting elements, from protein interactions to disease networks, all the\nway to healthcare systems and scientific knowledge. In this review, we put\nforward an observation that long-standing principles of network biology and\nmedicine -- while often unspoken in machine learning research -- can provide\nthe conceptual grounding for representation learning, explain its current\nsuccesses and limitations, and inform future advances. We synthesize a spectrum\nof algorithmic approaches that, at their core, leverage topological features to\nembed networks into compact vector spaces. We also provide a taxonomy of\nbiomedical areas that are likely to benefit most from algorithmic innovation.\nRepresentation learning techniques are becoming essential for identifying\ncausal variants underlying complex traits, disentangling behaviors of single\ncells and their impact on health, and diagnosing and treating diseases with\nsafe and effective medicines.\n", "versions": [{"version": "v1", "created": "Sun, 11 Apr 2021 00:20:00 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Li", "Michelle M.", ""], ["Huang", "Kexin", ""], ["Zitnik", "Marinka", ""]]}, {"id": "2104.04885", "submitter": "Massinissa Hamidi", "authors": "Massinissa Hamidi, Aomar Osmani", "title": "Description of Structural Biases and Associated Data in Sensor-Rich\n  Environments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  In this article, we study activity recognition in the context of sensor-rich\nenvironments. We address, in particular, the problem of inductive biases and\ntheir impact on the data collection process. To be effective and robust,\nactivity recognition systems must take these biases into account at all levels\nand model them as hyperparameters by which they can be controlled. Whether it\nis a bias related to sensor measurement, transmission protocol, sensor\ndeployment topology, heterogeneity, dynamicity, or stochastic effects, it is\nimportant to understand their substantial impact on the quality of activity\nrecognition models. This study highlights the need to separate the different\ntypes of biases arising in real situations so that machine learning models,\ne.g., adapt to the dynamicity of these environments, resist to sensor failures,\nand follow the evolution of the sensors topology. We propose a metamodeling\nprocess in which the sensor data is structured in layers. The lower layers\nencode the various biases linked to transformations, transmissions, and\ntopology of data. The upper layers encode biases related to the data itself.\nThis way, it becomes easier to model hyperparameters and follow changes in the\ndata acquisition infrastructure. We illustrate our approach on the SHL dataset\nwhich provides motion sensor data for a list of human activities collected\nunder real conditions. The trade-offs exposed and the broader implications of\nour approach are discussed with alternative techniques to encode and\nincorporate knowledge into activity recognition models.\n", "versions": [{"version": "v1", "created": "Sun, 11 Apr 2021 00:26:59 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Hamidi", "Massinissa", ""], ["Osmani", "Aomar", ""]]}, {"id": "2104.04886", "submitter": "Simiao Zuo", "authors": "Simiao Zuo, Chen Liang, Haoming Jiang, Xiaodong Liu, Pengcheng He,\n  Jianfeng Gao, Weizhu Chen, Tuo Zhao", "title": "Adversarial Training as Stackelberg Game: An Unrolled Optimization\n  Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial training has been shown to improve the generalization performance\nof deep learning models in various natural language processing tasks. Existing\nworks usually formulate adversarial training as a zero-sum game, which is\nsolved by alternating gradient descent/ascent algorithms. Such a formulation\ntreats the adversarial and the defending players equally, which is undesirable\nbecause only the defending player contributes to the generalization\nperformance. To address this issue, we propose Stackelberg Adversarial Training\n(SALT), which formulates adversarial training as a Stackelberg game. This\nformulation induces a competition between a leader and a follower, where the\nfollower generates perturbations, and the leader trains the model subject to\nthe perturbations. Different from conventional adversarial training, in SALT,\nthe leader is in an advantageous position. When the leader moves, it recognizes\nthe strategy of the follower and takes the anticipated follower's outcomes into\nconsideration. Such a leader's advantage enables us to improve the model\nfitting to the unperturbed data. The leader's strategic information is captured\nby the Stackelberg gradient, which is obtained using an unrolling algorithm.\nOur experimental results on a set of machine translation and natural language\nunderstanding tasks show that SALT outperforms existing adversarial training\nbaselines across all tasks.\n", "versions": [{"version": "v1", "created": "Sun, 11 Apr 2021 00:44:57 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Zuo", "Simiao", ""], ["Liang", "Chen", ""], ["Jiang", "Haoming", ""], ["Liu", "Xiaodong", ""], ["He", "Pengcheng", ""], ["Gao", "Jianfeng", ""], ["Chen", "Weizhu", ""], ["Zhao", "Tuo", ""]]}, {"id": "2104.04889", "submitter": "Massinissa Hamidi", "authors": "Aomar Osmani, Massinissa Hamidi, Pegah Alizadeh", "title": "Affinity-Based Hierarchical Learning of Dependent Concepts for Human\n  Activity Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  In multi-class classification tasks, like human activity recognition, it is\noften assumed that classes are separable. In real applications, this assumption\nbecomes strong and generates inconsistencies. Besides, the most commonly used\napproach is to learn classes one-by-one against the others. This computational\nsimplification principle introduces strong inductive biases on the learned\ntheories. In fact, the natural connections among some classes, and not others,\ndeserve to be taken into account. In this paper, we show that the organization\nof overlapping classes (multiple inheritances) into hierarchies considerably\nimproves classification performances. This is particularly true in the case of\nactivity recognition tasks featured in the SHL dataset. After theoretically\nshowing the exponential complexity of possible class hierarchies, we propose an\napproach based on transfer affinity among the classes to determine an optimal\nhierarchy for the learning process. Extensive experiments show improved\nperformances and a reduction in the number of examples needed to learn.\n", "versions": [{"version": "v1", "created": "Sun, 11 Apr 2021 01:08:48 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Osmani", "Aomar", ""], ["Hamidi", "Massinissa", ""], ["Alizadeh", "Pegah", ""]]}, {"id": "2104.04893", "submitter": "Brittany Davis Pierson", "authors": "Brittany Davis Pierson, Justine Ventura, Matthew E. Taylor", "title": "The Atari Data Scraper", "comments": "3 authors, nine pages, 6 figures, papers with code", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.SY eess.SY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Reinforcement learning has made great strides in recent years due to the\nsuccess of methods using deep neural networks. However, such neural networks\nact as a black box, obscuring the inner workings. While reinforcement learning\nhas the potential to solve unique problems, a lack of trust and understanding\nof reinforcement learning algorithms could prevent their widespread adoption.\nHere, we present a library that attaches a \"data scraper\" to deep reinforcement\nlearning agents, acting as an observer, and then show how the data collected by\nthe Atari Data Scraper can be used to understand and interpret deep\nreinforcement learning agents. The code for the Atari Data Scraper can be found\nhere: https://github.com/IRLL/Atari-Data-Scraper\n", "versions": [{"version": "v1", "created": "Sun, 11 Apr 2021 01:39:33 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Pierson", "Brittany Davis", ""], ["Ventura", "Justine", ""], ["Taylor", "Matthew E.", ""]]}, {"id": "2104.04906", "submitter": "Xu Jiang", "authors": "Qi Wang, Xu Jiang, Mulin Chen and Xuelong Li", "title": "Auto-weighted Multi-view Feature Selection with Graph Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we focus on the unsupervised multi-view feature selection\nwhich tries to handle high dimensional data in the field of multi-view\nlearning. Although some graph-based methods have achieved satisfactory\nperformance, they ignore the underlying data structure across different views.\nBesides, their pre-defined laplacian graphs are sensitive to the noises in the\noriginal data space, and fail to get the optimal neighbor assignment. To\naddress the above problems, we propose a novel unsupervised multi-view feature\nselection model based on graph learning, and the contributions are threefold:\n(1) during the feature selection procedure, the consensus similarity graph\nshared by different views is learned. Therefore, the proposed model can reveal\nthe data relationship from the feature subset. (2) a reasonable rank constraint\nis added to optimize the similarity matrix to obtain more accurate information;\n(3) an auto-weighted framework is presented to assign view weights adaptively,\nand an effective alternative iterative algorithm is proposed to optimize the\nproblem. Experiments on various datasets demonstrate the superiority of the\nproposed method compared with the state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Sun, 11 Apr 2021 03:25:25 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Wang", "Qi", ""], ["Jiang", "Xu", ""], ["Chen", "Mulin", ""], ["Li", "Xuelong", ""]]}, {"id": "2104.04909", "submitter": "Saed Rezayi", "authors": "Saed Rezayi, Handong Zhao, Sungchul Kim, Ryan A. Rossi, Nedim Lipka,\n  Sheng Li", "title": "Edge: Enriching Knowledge Graph Embeddings with External Text", "comments": "Accepted in NAACL'21", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Knowledge graphs suffer from sparsity which degrades the quality of\nrepresentations generated by various methods. While there is an abundance of\ntextual information throughout the web and many existing knowledge bases,\naligning information across these diverse data sources remains a challenge in\nthe literature. Previous work has partially addressed this issue by enriching\nknowledge graph entities based on \"hard\" co-occurrence of words present in the\nentities of the knowledge graphs and external text, while we achieve \"soft\"\naugmentation by proposing a knowledge graph enrichment and embedding framework\nnamed Edge. Given an original knowledge graph, we first generate a rich but\nnoisy augmented graph using external texts in semantic and structural level. To\ndistill the relevant knowledge and suppress the introduced noise, we design a\ngraph alignment term in a shared embedding space between the original graph and\naugmented graph. To enhance the embedding learning on the augmented graph, we\nfurther regularize the locality relationship of target entity based on negative\nsampling. Experimental results on four benchmark datasets demonstrate the\nrobustness and effectiveness of Edge in link prediction and node\nclassification.\n", "versions": [{"version": "v1", "created": "Sun, 11 Apr 2021 03:47:06 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Rezayi", "Saed", ""], ["Zhao", "Handong", ""], ["Kim", "Sungchul", ""], ["Rossi", "Ryan A.", ""], ["Lipka", "Nedim", ""], ["Li", "Sheng", ""]]}, {"id": "2104.04916", "submitter": "Xutan Peng", "authors": "Xutan Peng, Chenghua Lin, Mark Stevenson", "title": "Cross-Lingual Word Embedding Refinement by $\\ell_{1}$ Norm Optimisation", "comments": "To appear at NAACL 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cross-Lingual Word Embeddings (CLWEs) encode words from two or more languages\nin a shared high-dimensional space in which vectors representing words with\nsimilar meaning (regardless of language) are closely located. Existing methods\nfor building high-quality CLWEs learn mappings that minimise the $\\ell_{2}$\nnorm loss function. However, this optimisation objective has been demonstrated\nto be sensitive to outliers. Based on the more robust Manhattan norm (aka.\n$\\ell_{1}$ norm) goodness-of-fit criterion, this paper proposes a simple\npost-processing step to improve CLWEs. An advantage of this approach is that it\nis fully agnostic to the training process of the original CLWEs and can\ntherefore be applied widely. Extensive experiments are performed involving ten\ndiverse languages and embeddings trained on different corpora. Evaluation\nresults based on bilingual lexicon induction and cross-lingual transfer for\nnatural language inference tasks show that the $\\ell_{1}$ refinement\nsubstantially outperforms four state-of-the-art baselines in both supervised\nand unsupervised settings. It is therefore recommended that this strategy be\nadopted as a standard for CLWE methods.\n", "versions": [{"version": "v1", "created": "Sun, 11 Apr 2021 04:37:54 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Peng", "Xutan", ""], ["Lin", "Chenghua", ""], ["Stevenson", "Mark", ""]]}, {"id": "2104.04923", "submitter": "Arun Babu", "authors": "Arun Babu, Akshat Shrivastava, Armen Aghajanyan, Ahmed Aly, Angela Fan\n  and Marjan Ghazvininejad", "title": "Non-Autoregressive Semantic Parsing for Compositional Task-Oriented\n  Dialog", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semantic parsing using sequence-to-sequence models allows parsing of deeper\nrepresentations compared to traditional word tagging based models. In spite of\nthese advantages, widespread adoption of these models for real-time\nconversational use cases has been stymied by higher compute requirements and\nthus higher latency. In this work, we propose a non-autoregressive approach to\npredict semantic parse trees with an efficient seq2seq model architecture. By\ncombining non-autoregressive prediction with convolutional neural networks, we\nachieve significant latency gains and parameter size reduction compared to\ntraditional RNN models. Our novel architecture achieves up to an 81% reduction\nin latency on TOP dataset and retains competitive performance to non-pretrained\nmodels on three different semantic parsing datasets. Our code is available at\nhttps://github.com/facebookresearch/pytext\n", "versions": [{"version": "v1", "created": "Sun, 11 Apr 2021 05:44:35 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Babu", "Arun", ""], ["Shrivastava", "Akshat", ""], ["Aghajanyan", "Armen", ""], ["Aly", "Ahmed", ""], ["Fan", "Angela", ""], ["Ghazvininejad", "Marjan", ""]]}, {"id": "2104.04926", "submitter": "Dipti Mishra", "authors": "Dipti Mishra, Satish Kumar Singh, Rajat Kumar Singh, Krishna Preetham", "title": "Edge-Aware Image Compression using Deep Learning-based Super-resolution\n  Network", "comments": "13 pages, 9 figures, 16 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose a learning-based compression scheme that envelopes a standard\ncodec between pre and post-processing deep CNNs. Specifically, we demonstrate\nimprovements over prior approaches utilizing a compression-decompression\nnetwork by introducing: (a) an edge-aware loss function to prevent blurring\nthat is commonly occurred in prior works & (b) a super-resolution convolutional\nneural network (CNN) for post-processing along with a corresponding\npre-processing network for improved rate-distortion performance in the low rate\nregime. The algorithm is assessed on a variety of datasets varying from low to\nhigh resolution namely Set 5, Set 7, Classic 5, Set 14, Live 1, Kodak, General\n100, CLIC 2019. When compared to JPEG, JPEG2000, BPG, and recent CNN approach,\nthe proposed algorithm contributes significant improvement in PSNR with an\napproximate gain of 20.75%, 8.47%, 3.22%, 3.23% and 24.59%, 14.46%, 10.14%,\n8.57% at low and high bit-rates respectively. Similarly, this improvement in\nMS-SSIM is approximately 71.43%, 50%, 36.36%, 23.08%, 64.70% and 64.47%,\n61.29%, 47.06%, 51.52%, 16.28% at low and high bit-rates respectively. With\nCLIC 2019 dataset, PSNR is found to be superior with approximately 16.67%,\n10.53%, 6.78%, and 24.62%, 17.39%, 14.08% at low and high bit-rates\nrespectively, over JPEG2000, BPG, and recent CNN approach. Similarly, the\nMS-SSIM is found to be superior with approximately 72%, 45.45%, 39.13%, 18.52%,\nand 71.43%, 50%, 41.18%, 17.07% at low and high bit-rates respectively,\ncompared to the same approaches. A similar type of improvement is achieved with\nother datasets also.\n", "versions": [{"version": "v1", "created": "Sun, 11 Apr 2021 05:50:31 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Mishra", "Dipti", ""], ["Singh", "Satish Kumar", ""], ["Singh", "Rajat Kumar", ""], ["Preetham", "Krishna", ""]]}, {"id": "2104.04939", "submitter": "Abdul Wahid", "authors": "Abdul Wahid, Rajesh Sharma, and Chandra Sekhara Rao Annavarapu", "title": "A Graph Convolutional Neural Network based Framework for Estimating\n  Future Citations Count of Research Articles", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.AI cs.ET cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Scientific publications play a vital role in the career of a researcher.\nHowever, some articles become more popular than others among the research\ncommunity and subsequently drive future research directions. One of the\nindicative signs of popular articles is the number of citations an article\nreceives. The citation count, which is also the basis with various other\nmetrics, such as the journal impact factor score, the $h$-index, is an\nessential measure for assessing a scientific paper's quality. In this work, we\nproposed a Graph Convolutional Network (GCN) based framework for estimating\nfuture research publication citations for both the short-term (1-year) and\nlong-term (for 5-years and 10-years) duration. We have tested our proposed\napproach over the AMiner dataset, specifically on research articles from the\ncomputer science domain, consisting of more than 0.8 million articles.\n", "versions": [{"version": "v1", "created": "Sun, 11 Apr 2021 07:20:53 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Wahid", "Abdul", ""], ["Sharma", "Rajesh", ""], ["Annavarapu", "Chandra Sekhara Rao", ""]]}, {"id": "2104.04955", "submitter": "R. Baghdadi", "authors": "Riyadh Baghdadi, Massinissa Merouani, Mohamed-Hicham Leghettas, Kamel\n  Abdous, Taha Arbaoui, Karima Benatchba, Saman Amarasinghe", "title": "A Deep Learning Based Cost Model for Automatic Code Optimization", "comments": null, "journal-ref": "Proceedings of the 4th MLSys Conference, San Jose, CA, USA, 2021", "doi": null, "report-no": null, "categories": "cs.PL cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Enabling compilers to automatically optimize code has been a longstanding\ngoal for the compiler community. Efficiently solving this problem requires\nusing precise cost models. These models predict whether applying a sequence of\ncode transformations reduces the execution time of the program. Building an\nanalytical cost model to do so is hard in modern x86 architectures due to the\ncomplexity of the microarchitecture. In this paper, we present a novel deep\nlearning based cost model for automatic code optimization. This model was\nintegrated in a search method and implemented in the Tiramisu compiler to\nselect the best code transformations. The input of the proposed model is a set\nof simple features representing the unoptimized code and a sequence of code\ntransformations. The model predicts the speedup expected when the code\ntransformations are applied. Unlike previous models, the proposed one works on\nfull programs and does not rely on any heavy feature engineering. The proposed\nmodel has only 16% of mean absolute percentage error in predicting speedups on\nfull programs. The proposed model enables Tiramisu to automatically find code\ntransformations that match or are better than state-of-the-art compilers\nwithout requiring the same level of heavy feature engineering required by those\ncompilers.\n", "versions": [{"version": "v1", "created": "Sun, 11 Apr 2021 08:32:42 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Baghdadi", "Riyadh", ""], ["Merouani", "Massinissa", ""], ["Leghettas", "Mohamed-Hicham", ""], ["Abdous", "Kamel", ""], ["Arbaoui", "Taha", ""], ["Benatchba", "Karima", ""], ["Amarasinghe", "Saman", ""]]}, {"id": "2104.04958", "submitter": "Mario Di Mauro", "authors": "Mario Di Mauro, Giovanni Galatro, Giancarlo Fortino, Antonio Liotta", "title": "Supervised Feature Selection Techniques in Network Intrusion Detection:\n  a Critical Review", "comments": null, "journal-ref": "Engineering Applications of Artificial Intelligence Volume 101,\n  May 2021, 104216", "doi": "10.1016/j.engappai.2021.104216", "report-no": null, "categories": "cs.CR cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine Learning (ML) techniques are becoming an invaluable support for\nnetwork intrusion detection, especially in revealing anomalous flows, which\noften hide cyber-threats. Typically, ML algorithms are exploited to\nclassify/recognize data traffic on the basis of statistical features such as\ninter-arrival times, packets length distribution, mean number of flows, etc.\nDealing with the vast diversity and number of features that typically\ncharacterize data traffic is a hard problem. This results in the following\nissues: i) the presence of so many features leads to lengthy training processes\n(particularly when features are highly correlated), while prediction accuracy\ndoes not proportionally improve; ii) some of the features may introduce bias\nduring the classification process, particularly those that have scarce relation\nwith the data traffic to be classified. To this end, by reducing the feature\nspace and retaining only the most significant features, Feature Selection (FS)\nbecomes a crucial pre-processing step in network management and, specifically,\nfor the purposes of network intrusion detection. In this review paper, we\ncomplement other surveys in multiple ways: i) evaluating more recent datasets\n(updated w.r.t. obsolete KDD 99) by means of a designed-from-scratch\nPython-based procedure; ii) providing a synopsis of most credited FS approaches\nin the field of intrusion detection, including Multi-Objective Evolutionary\ntechniques; iii) assessing various experimental analyses such as feature\ncorrelation, time complexity, and performance. Our comparisons offer useful\nguidelines to network/security managers who are considering the incorporation\nof ML concepts into network intrusion detection, where trade-offs between\nperformance and resource consumption are crucial.\n", "versions": [{"version": "v1", "created": "Sun, 11 Apr 2021 08:42:01 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Di Mauro", "Mario", ""], ["Galatro", "Giovanni", ""], ["Fortino", "Giancarlo", ""], ["Liotta", "Antonio", ""]]}, {"id": "2104.04975", "submitter": "Alexander Immer", "authors": "Alexander Immer, Matthias Bauer, Vincent Fortuin, Gunnar R\\\"atsch,\n  Mohammad Emtiyaz Khan", "title": "Scalable Marginal Likelihood Estimation for Model Selection in Deep\n  Learning", "comments": "ICML 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Marginal-likelihood based model-selection, even though promising, is rarely\nused in deep learning due to estimation difficulties. Instead, most approaches\nrely on validation data, which may not be readily available. In this work, we\npresent a scalable marginal-likelihood estimation method to select both\nhyperparameters and network architectures, based on the training data alone.\nSome hyperparameters can be estimated online during training, simplifying the\nprocedure. Our marginal-likelihood estimate is based on Laplace's method and\nGauss-Newton approximations to the Hessian, and it outperforms cross-validation\nand manual-tuning on standard regression and image classification datasets,\nespecially in terms of calibration and out-of-distribution detection. Our work\nshows that marginal likelihoods can improve generalization and be useful when\nvalidation data is unavailable (e.g., in nonstationary settings).\n", "versions": [{"version": "v1", "created": "Sun, 11 Apr 2021 09:50:24 GMT"}, {"version": "v2", "created": "Tue, 11 May 2021 13:17:14 GMT"}, {"version": "v3", "created": "Tue, 15 Jun 2021 10:50:22 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Immer", "Alexander", ""], ["Bauer", "Matthias", ""], ["Fortuin", "Vincent", ""], ["R\u00e4tsch", "Gunnar", ""], ["Khan", "Mohammad Emtiyaz", ""]]}, {"id": "2104.04987", "submitter": "Chaoyu Guan", "authors": "Chaoyu Guan, Ziwei Zhang, Haoyang Li, Heng Chang, Zeyang Zhang, Yijian\n  Qin, Jiyan Jiang, Xin Wang, Wenwu Zhu", "title": "AutoGL: A Library for Automated Graph Learning", "comments": "*Equal contributions. 8 pages, 1 figure, accepted at ICLR 2021\n  Workshop on Geometrical and Topological Representation Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recent years have witnessed an upsurge of research interests and applications\nof machine learning on graphs. Automated machine learning (AutoML) on graphs is\non the horizon to automatically design the optimal machine learning algorithm\nfor a given graph task. However, none of the existing libraries can fully\nsupport AutoML on graphs. To fill this gap, we present Automated Graph Learning\n(AutoGL), the first library for automated machine learning on graphs. AutoGL is\nopen-source, easy to use, and flexible to be extended. Specifically, we propose\nan automated machine learning pipeline for graph data containing four modules:\nauto feature engineering, model training, hyper-parameter optimization, and\nauto ensemble. For each module, we provide numerous state-of-the-art methods\nand flexible base classes and APIs, which allow easy customization. We further\nprovide experimental results to showcase the usage of our AutoGL library.\n", "versions": [{"version": "v1", "created": "Sun, 11 Apr 2021 10:49:23 GMT"}, {"version": "v2", "created": "Tue, 4 May 2021 10:50:50 GMT"}], "update_date": "2021-05-05", "authors_parsed": [["Guan", "Chaoyu", ""], ["Zhang", "Ziwei", ""], ["Li", "Haoyang", ""], ["Chang", "Heng", ""], ["Zhang", "Zeyang", ""], ["Qin", "Yijian", ""], ["Jiang", "Jiyan", ""], ["Wang", "Xin", ""], ["Zhu", "Wenwu", ""]]}, {"id": "2104.04998", "submitter": "Ayush Maheshwari", "authors": "Atul Sahay, Ayush Maheshwari, Ritesh Kumar, Ganesh Ramakrishnan,\n  Manjesh Kumar Hanawal, Kavi Arya", "title": "Unsupervised Learning of Explainable Parse Trees for Improved\n  Generalisation", "comments": "8 Pages, 5 Tables, 4 Figures. To appear at IJCNN 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recursive neural networks (RvNN) have been shown useful for learning sentence\nrepresentations and helped achieve competitive performance on several natural\nlanguage inference tasks. However, recent RvNN-based models fail to learn\nsimple grammar and meaningful semantics in their intermediate tree\nrepresentation. In this work, we propose an attention mechanism over Tree-LSTMs\nto learn more meaningful and explainable parse tree structures. We also\ndemonstrate the superior performance of our proposed model on natural language\ninference, semantic relatedness, and sentiment analysis tasks and compare them\nwith other state-of-the-art RvNN based methods. Further, we present a detailed\nqualitative and quantitative analysis of the learned parse trees and show that\nthe discovered linguistic structures are more explainable, semantically\nmeaningful, and grammatically correct than recent approaches. The source code\nof the paper is available at\nhttps://github.com/atul04/Explainable-Latent-Structures-Using-Attention.\n", "versions": [{"version": "v1", "created": "Sun, 11 Apr 2021 12:10:03 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Sahay", "Atul", ""], ["Maheshwari", "Ayush", ""], ["Kumar", "Ritesh", ""], ["Ramakrishnan", "Ganesh", ""], ["Hanawal", "Manjesh Kumar", ""], ["Arya", "Kavi", ""]]}, {"id": "2104.04999", "submitter": "Huong Ha", "authors": "Huong Ha, Sunil Gupta, Santu Rana, Svetha Venkatesh", "title": "ALT-MAS: A Data-Efficient Framework for Active Testing of Machine\n  Learning Algorithms", "comments": "Accepted to the RobustML workshop at ICLR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.SE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning models are being used extensively in many important areas,\nbut there is no guarantee a model will always perform well or as its developers\nintended. Understanding the correctness of a model is crucial to prevent\npotential failures that may have significant detrimental impact in critical\napplication areas. In this paper, we propose a novel framework to efficiently\ntest a machine learning model using only a small amount of labeled test data.\nThe idea is to estimate the metrics of interest for a model-under-test using\nBayesian neural network (BNN). We develop a novel data augmentation method\nhelping to train the BNN to achieve high accuracy. We also devise a theoretic\ninformation based sampling strategy to sample data points so as to achieve\naccurate estimations for the metrics of interest. Finally, we conduct an\nextensive set of experiments to test various machine learning models for\ndifferent types of metrics. Our experiments show that the metrics estimations\nby our method are significantly better than existing baselines.\n", "versions": [{"version": "v1", "created": "Sun, 11 Apr 2021 12:14:04 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Ha", "Huong", ""], ["Gupta", "Sunil", ""], ["Rana", "Santu", ""], ["Venkatesh", "Svetha", ""]]}, {"id": "2104.05000", "submitter": "Samuel Gerber", "authors": "Samuel Gerber", "title": "Saddlepoints in Unsupervised Least Squares", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper sheds light on the risk landscape of unsupervised least squares in\nthe context of deep auto-encoding neural nets. We formally establish an\nequivalence between unsupervised least squares and principal manifolds. This\nlink provides insight into the risk landscape of auto--encoding under the mean\nsquared error, in particular all non-trivial critical points are saddlepoints.\nFinding saddlepoints is in itself difficult, overcomplete auto-encoding poses\nthe additional challenge that the saddlepoints are degenerate. Within this\ncontext we discuss regularization of auto-encoders, in particular bottleneck,\ndenoising and contraction auto-encoding and propose a new optimization strategy\nthat can be framed as particular form of contractive regularization.\n", "versions": [{"version": "v1", "created": "Sun, 11 Apr 2021 12:15:36 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Gerber", "Samuel", ""]]}, {"id": "2104.05018", "submitter": "Yu Pan", "authors": "Yu Pan, Maolin Wang, Zenglin Xu", "title": "TedNet: A Pytorch Toolkit for Tensor Decomposition Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tensor Decomposition Networks(TDNs) prevail for their inherent compact\narchitectures. For providing convenience, we present a toolkit named TedNet\nthat is based on the Pytorch framework, to give more researchers a flexible way\nto exploit TDNs. TedNet implements 5 kinds of tensor decomposition(i.e.,\nCANDECOMP/PARAFAC(CP), Block-Term Tucker(BT), Tucker-2, Tensor Train(TT) and\nTensor Ring(TR)) on traditional deep neural layers, the convolutional layer and\nthe fully-connected layer. By utilizing these basic layers, it is simple to\nconstruct a variety of TDNs like TR-ResNet, TT-LSTM, etc. TedNet is available\nat https://github.com/tnbar/tednet.\n", "versions": [{"version": "v1", "created": "Sun, 11 Apr 2021 14:04:06 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Pan", "Yu", ""], ["Wang", "Maolin", ""], ["Xu", "Zenglin", ""]]}, {"id": "2104.05025", "submitter": "Eugene Belilovsky", "authors": "Lucas Caccia, Rahaf Aljundi, Nader Asadi, Tinne Tuytelaars, Joelle\n  Pineau, Eugene Belilovsky", "title": "Reducing Representation Drift in Online Continual Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the online continual learning paradigm, agents must learn from a changing\ndistribution while respecting memory and compute constraints. Previous work in\nthis setting often tries to reduce catastrophic forgetting by limiting changes\nin the space of model parameters. In this work we instead focus on the change\nin representations of observed data that arises when previously unobserved\nclasses appear in the incoming data stream, and new classes must be\ndistinguished from previous ones. Starting from a popular approach, experience\nreplay, we consider metric learning based loss functions which, when adjusted\nto appropriately select negative samples, can effectively nudge the learned\nrepresentations to be more robust to new future classes. We show that this\nselection of negatives is in fact critical for reducing representation drift of\npreviously observed data. Motivated by this we further introduce a simple\nadjustment to the standard cross entropy loss used in prior experience replay\nthat achieves similar effect. Our approach directly improves the performance of\nexperience replay for this setting, obtaining state-of-the-art results on\nseveral existing benchmarks in online continual learning, while remaining\nefficient in both memory and compute. We release an implementation of our\nexperiments at https://github.com/naderAsadi/AML\n", "versions": [{"version": "v1", "created": "Sun, 11 Apr 2021 15:19:30 GMT"}, {"version": "v2", "created": "Tue, 29 Jun 2021 23:29:16 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Caccia", "Lucas", ""], ["Aljundi", "Rahaf", ""], ["Asadi", "Nader", ""], ["Tuytelaars", "Tinne", ""], ["Pineau", "Joelle", ""], ["Belilovsky", "Eugene", ""]]}, {"id": "2104.05043", "submitter": "Jinxin Liu", "authors": "Jinxin Liu, Donglin Wang, Qiangxing Tian, Zhengyu Chen", "title": "Learn Goal-Conditioned Policy with Intrinsic Motivation for Deep\n  Reinforcement Learning", "comments": "19 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is of significance for an agent to learn a widely applicable and\ngeneral-purpose policy that can achieve diverse goals including images and text\ndescriptions. Considering such perceptually-specific goals, the frontier of\ndeep reinforcement learning research is to learn a goal-conditioned policy\nwithout hand-crafted rewards. To learn this kind of policy, recent works\nusually take as the reward the non-parametric distance to a given goal in an\nexplicit embedding space. From a different viewpoint, we propose a novel\nunsupervised learning approach named goal-conditioned policy with intrinsic\nmotivation (GPIM), which jointly learns both an abstract-level policy and a\ngoal-conditioned policy. The abstract-level policy is conditioned on a latent\nvariable to optimize a discriminator and discovers diverse states that are\nfurther rendered into perceptually-specific goals for the goal-conditioned\npolicy. The learned discriminator serves as an intrinsic reward function for\nthe goal-conditioned policy to imitate the trajectory induced by the\nabstract-level policy. Experiments on various robotic tasks demonstrate the\neffectiveness and efficiency of our proposed GPIM method which substantially\noutperforms prior techniques.\n", "versions": [{"version": "v1", "created": "Sun, 11 Apr 2021 16:26:10 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Liu", "Jinxin", ""], ["Wang", "Donglin", ""], ["Tian", "Qiangxing", ""], ["Chen", "Zhengyu", ""]]}, {"id": "2104.05047", "submitter": "Evgeny Frolov", "authors": "Oluwafemi Olaleke, Ivan Oseledets, Evgeny Frolov", "title": "Dynamic Modeling of User Preferences for Stable Recommendations", "comments": "8 pages, 1 figure, accepted at UMAP'21 conference", "journal-ref": null, "doi": "10.1145/3450613.3456830", "report-no": null, "categories": "cs.IR cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  In domains where users tend to develop long-term preferences that do not\nchange too frequently, the stability of recommendations is an important factor\nof the perceived quality of a recommender system. In such cases, unstable\nrecommendations may lead to poor personalization experience and distrust,\ndriving users away from a recommendation service. We propose an incremental\nlearning scheme that mitigates such problems through the dynamic modeling\napproach. It incorporates a generalized matrix form of a partial differential\nequation integrator that yields a dynamic low-rank approximation of\ntime-dependent matrices representing user preferences. The scheme allows\nextending the famous PureSVD approach to time-aware settings and significantly\nimproves its stability without sacrificing the accuracy in standard top-$n$\nrecommendations tasks.\n", "versions": [{"version": "v1", "created": "Sun, 11 Apr 2021 16:32:11 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Olaleke", "Oluwafemi", ""], ["Oseledets", "Ivan", ""], ["Frolov", "Evgeny", ""]]}, {"id": "2104.05048", "submitter": "Konstantinos Makantasis", "authors": "Konstantinos Makantasis, Alexandros Georgogiannis, Athanasios\n  Voulodimos, Ioannis Georgoulas, Anastasios Doulamis, Nikolaos Doulamis", "title": "Rank-R FNN: A Tensor-Based Learning Model for High-Order Data\n  Classification", "comments": "12 pages, 5 figures, 4 tables, Accepted for publication to IEEE\n  Access", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  An increasing number of emerging applications in data science and engineering\nare based on multidimensional and structurally rich data. The irregularities,\nhowever, of high-dimensional data often compromise the effectiveness of\nstandard machine learning algorithms. We hereby propose the Rank-R Feedforward\nNeural Network (FNN), a tensor-based nonlinear learning model that imposes\nCanonical/Polyadic decomposition on its parameters, thereby offering two core\nadvantages compared to typical machine learning methods. First, it handles\ninputs as multilinear arrays, bypassing the need for vectorization, and can\nthus fully exploit the structural information along every data dimension.\nMoreover, the number of the model's trainable parameters is substantially\nreduced, making it very efficient for small sample setting problems. We\nestablish the universal approximation and learnability properties of Rank-R\nFNN, and we validate its performance on real-world hyperspectral datasets.\nExperimental evaluations show that Rank-R FNN is a computationally inexpensive\nalternative of ordinary FNN that achieves state-of-the-art performance on\nhigher-order tensor data.\n", "versions": [{"version": "v1", "created": "Sun, 11 Apr 2021 16:37:32 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Makantasis", "Konstantinos", ""], ["Georgogiannis", "Alexandros", ""], ["Voulodimos", "Athanasios", ""], ["Georgoulas", "Ioannis", ""], ["Doulamis", "Anastasios", ""], ["Doulamis", "Nikolaos", ""]]}, {"id": "2104.05049", "submitter": "Alaaeddine Chaoub", "authors": "Alaaeddine Chaoub, Alexandre Voisin, Christophe Cerisara, Beno\\^it\n  Iung", "title": "Learning representations with end-to-end models for improved remaining\n  useful life prognostics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The remaining Useful Life (RUL) of equipment is defined as the duration\nbetween the current time and its failure. An accurate and reliable prognostic\nof the remaining useful life provides decision-makers with valuable information\nto adopt an appropriate maintenance strategy to maximize equipment utilization\nand avoid costly breakdowns. In this work, we propose an end-to-end deep\nlearning model based on multi-layer perceptron and long short-term memory\nlayers (LSTM) to predict the RUL. After normalization of all data, inputs are\nfed directly to an MLP layers for feature learning, then to an LSTM layer to\ncapture temporal dependencies, and finally to other MLP layers for RUL\nprognostic. The proposed architecture is tested on the NASA commercial modular\naero-propulsion system simulation (C-MAPSS) dataset. Despite its simplicity\nwith respect to other recently proposed models, the model developed outperforms\nthem with a significant decrease in the competition score and in the root mean\nsquare error score between the predicted and the gold value of the RUL. In this\npaper, we will discuss how the proposed end-to-end model is able to achieve\nsuch good results and compare it to other deep learning and state-of-the-art\nmethods.\n", "versions": [{"version": "v1", "created": "Sun, 11 Apr 2021 16:45:18 GMT"}, {"version": "v2", "created": "Wed, 26 May 2021 15:35:54 GMT"}], "update_date": "2021-05-27", "authors_parsed": [["Chaoub", "Alaaeddine", ""], ["Voisin", "Alexandre", ""], ["Cerisara", "Christophe", ""], ["Iung", "Beno\u00eet", ""]]}, {"id": "2104.05062", "submitter": "Maor Ivgi", "authors": "Maor Ivgi and Jonathan Berant", "title": "Achieving Model Robustness through Discrete Adversarial Training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Discrete adversarial attacks are symbolic perturbations to a language input\nthat preserve the output label but lead to a prediction error. While such\nattacks have been extensively explored for the purpose of evaluating model\nrobustness, their utility for improving robustness has been limited to offline\naugmentation only, i.e., given a trained model, attacks are used to generate\nperturbed (adversarial) examples, and the model is re-trained exactly once. In\nthis work, we address this gap and leverage discrete attacks for online\naugmentation, where adversarial examples are generated at every step, adapting\nto the changing nature of the model. We also consider efficient attacks based\non random sampling, that unlike prior work are not based on expensive\nsearch-based procedures. As a second contribution, we provide a general\nformulation for multiple search-based attacks from past work, and propose a new\nattack based on best-first search. Surprisingly, we find that random sampling\nleads to impressive gains in robustness, outperforming the commonly-used\noffline augmentation, while leading to a speedup at training time of ~10x.\nFurthermore, online augmentation with search-based attacks justifies the higher\ntraining cost, significantly improving robustness on three datasets. Last, we\nshow that our proposed algorithm substantially improves robustness compared to\nprior methods.\n", "versions": [{"version": "v1", "created": "Sun, 11 Apr 2021 17:49:21 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Ivgi", "Maor", ""], ["Berant", "Jonathan", ""]]}, {"id": "2104.05069", "submitter": "Satpreet Harcharan Singh", "authors": "Satpreet H. Singh", "title": "A Non-Negative Matrix Factorization Game", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present a novel game-theoretic formulation of Non-Negative Matrix\nFactorization (NNMF), a popular data-analysis method with many scientific and\nengineering applications. The game-theoretic formulation is shown to have\nfavorable scaling and parallelization properties, while retaining\nreconstruction and convergence performance comparable to the traditional\nMultiplicative Updates algorithm.\n", "versions": [{"version": "v1", "created": "Sun, 11 Apr 2021 18:25:34 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Singh", "Satpreet H.", ""]]}, {"id": "2104.05077", "submitter": "Grigorios Chrysos", "authors": "Grigorios G Chrysos, Markos Georgopoulos, Yannis Panagakis", "title": "CoPE: Conditional image generation using Polynomial Expansions", "comments": "Under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative modeling has evolved to a notable field of machine learning. Deep\npolynomial neural networks (PNNs) have demonstrated impressive results in\nunsupervised image generation, where the task is to map an input vector (i.e.,\nnoise) to a synthesized image. However, the success of PNNs has not been\nreplicated in conditional generation tasks, such as super-resolution. Existing\nPNNs focus on single-variable polynomial expansions which do not fare well to\ntwo-variable inputs, i.e., the noise variable and the conditional variable. In\nthis work, we introduce a general framework, called CoPE, that enables a\npolynomial expansion of two input variables and captures their auto- and\ncross-correlations. We exhibit how CoPE can be trivially augmented to accept an\narbitrary number of input variables. CoPE is evaluated in five tasks\n(class-conditional generation, inverse problems, edges-to-image translation,\nimage-to-image translation, attribute-guided generation) involving eight\ndatasets. The thorough evaluation suggests that CoPE can be useful for tackling\ndiverse conditional generation tasks.\n", "versions": [{"version": "v1", "created": "Sun, 11 Apr 2021 19:02:37 GMT"}, {"version": "v2", "created": "Mon, 14 Jun 2021 12:52:20 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Chrysos", "Grigorios G", ""], ["Georgopoulos", "Markos", ""], ["Panagakis", "Yannis", ""]]}, {"id": "2104.05087", "submitter": "Orestis Plevrakis", "authors": "Orestis Plevrakis", "title": "Learning from Censored and Dependent Data: The case of Linear Dynamics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC math.ST stat.TH", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Observations from dynamical systems often exhibit irregularities, such as\ncensoring, where values are recorded only if they fall within a certain range.\nCensoring is ubiquitous in practice, due to saturating sensors,\nlimit-of-detection effects, and image-frame effects. In light of recent\ndevelopments on learning linear dynamical systems (LDSs), and on censored\nstatistics with independent data, we revisit the decades-old problem of\nlearning an LDS, from censored observations (Lee and Maddala (1985); Zeger and\nBrookmeyer (1986)). Here, the learner observes the state $x_t \\in \\mathbb{R}^d$\nif and only if $x_t$ belongs to some set $S_t \\subseteq \\mathbb{R}^d$. We\ndevelop the first computationally and statistically efficient algorithm for\nlearning the system, assuming only oracle access to the sets $S_t$. Our\nalgorithm, Stochastic Online Newton with Switching Gradients, is a novel\nsecond-order method that builds on the Online Newton Step (ONS) of Hazan et al.\n(2007). Our Switching-Gradient scheme does not always use (stochastic)\ngradients of the function we want to optimize, which we call \"censor-aware\"\nfunction. Instead, in each iteration, it performs a simple test to decide\nwhether to use the censor-aware, or another \"censor-oblivious\" function, for\ngetting a stochastic gradient.\n  In our analysis, we consider a \"generic\" Online Newton method, which uses\narbitrary vectors instead of gradients, and we prove an error-bound for it.\nThis can be used to appropriately design these vectors, leading to our\nSwitching-Gradient scheme. This framework significantly deviates from the\nrecent long line of works on censored statistics (e.g., Daskalakis et al.\n(2018); Kontonis et al. (2019); Daskalakis et al. (2019)), which apply\nStochastic Gradient Descent (SGD), and their analysis reduces to establishing\nconditions for off-the-shelf SGD-bounds.\n", "versions": [{"version": "v1", "created": "Sun, 11 Apr 2021 19:55:24 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Plevrakis", "Orestis", ""]]}, {"id": "2104.05089", "submitter": "Bjorn Lutjens", "authors": "Salva R\\\"uhling Cachay, Emma Erickson, Arthur Fender C. Bucker, Ernest\n  Pokropek, Willa Potosnak, Suyash Bire, Salomey Osei, Bj\\\"orn L\\\"utjens", "title": "The World as a Graph: Improving El Ni\\~no Forecasts with Graph Neural\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE physics.ao-ph stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deep learning-based models have recently outperformed state-of-the-art\nseasonal forecasting models, such as for predicting El Ni\\~no-Southern\nOscillation (ENSO). However, current deep learning models are based on\nconvolutional neural networks which are difficult to interpret and can fail to\nmodel large-scale atmospheric patterns. In comparison, graph neural networks\n(GNNs) are capable of modeling large-scale spatial dependencies and are more\ninterpretable due to the explicit modeling of information flow through edge\nconnections. We propose the first application of graph neural networks to\nseasonal forecasting. We design a novel graph connectivity learning module that\nenables our GNN model to learn large-scale spatial interactions jointly with\nthe actual ENSO forecasting task. Our model, \\graphino, outperforms\nstate-of-the-art deep learning-based models for forecasts up to six months\nahead. Additionally, we show that our model is more interpretable as it learns\nsensible connectivity structures that correlate with the ENSO anomaly pattern.\n", "versions": [{"version": "v1", "created": "Sun, 11 Apr 2021 19:55:55 GMT"}, {"version": "v2", "created": "Wed, 19 May 2021 20:57:30 GMT"}], "update_date": "2021-05-21", "authors_parsed": [["Cachay", "Salva R\u00fchling", ""], ["Erickson", "Emma", ""], ["Bucker", "Arthur Fender C.", ""], ["Pokropek", "Ernest", ""], ["Potosnak", "Willa", ""], ["Bire", "Suyash", ""], ["Osei", "Salomey", ""], ["L\u00fctjens", "Bj\u00f6rn", ""]]}, {"id": "2104.05094", "submitter": "Yangkai Du", "authors": "Yangkai Du, Tengfei Ma, Lingfei Wu, Fangli Xu, Xuhong Zhang, Shouling\n  Ji", "title": "Constructing Contrastive samples via Summarization for Text\n  Classification with limited annotations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Contrastive Learning has emerged as a powerful representation learning method\nand facilitates various downstream tasks especially when supervised data is\nlimited. How to construct efficient contrastive samples through data\naugmentation is key to its success. Unlike vision tasks, the data augmentation\nmethod for contrastive learning has not been investigated sufficiently in\nlanguage tasks. In this paper, we propose a novel approach to constructing\ncontrastive samples for language tasks using text summarization. We use these\nsamples for supervised contrastive learning to gain better text representations\nwhich greatly benefit text classification tasks with limited annotations. To\nfurther improve the method, we mix up samples from different classes and add an\nextra regularization, named mix-sum regularization, in addition to the\ncross-entropy-loss. Experiments on real-world text classification datasets\n(Amazon-5, Yelp-5, AG News) demonstrate the effectiveness of the proposed\ncontrastive learning framework with summarization-based data augmentation and\nmix-sum regularization.\n", "versions": [{"version": "v1", "created": "Sun, 11 Apr 2021 20:13:24 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Du", "Yangkai", ""], ["Ma", "Tengfei", ""], ["Wu", "Lingfei", ""], ["Xu", "Fangli", ""], ["Zhang", "Xuhong", ""], ["Ji", "Shouling", ""]]}, {"id": "2104.05096", "submitter": "Kevin Course", "authors": "Kevin L. Course, Trefor W. Evans, Prasanth B. Nair", "title": "Weak Form Generalized Hamiltonian Learning", "comments": "34th Conference on Neural Information Processing Systems, 18 pages", "journal-ref": "Advances in Neural Information Processing Systems. Vol. 33 (2020),\n  pp. 18716-18726", "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a method for learning generalized Hamiltonian decompositions of\nordinary differential equations given a set of noisy time series measurements.\nOur method simultaneously learns a continuous time model and a scalar energy\nfunction for a general dynamical system. Learning predictive models in this\nform allows one to place strong, high-level, physics inspired priors onto the\nform of the learnt governing equations for general dynamical systems. Moreover,\nhaving shown how our method extends and unifies some previous work in deep\nlearning with physics inspired priors, we present a novel method for learning\ncontinuous time models from the weak form of the governing equations which is\nless computationally taxing than standard adjoint methods.\n", "versions": [{"version": "v1", "created": "Sun, 11 Apr 2021 20:25:55 GMT"}], "update_date": "2021-04-16", "authors_parsed": [["Course", "Kevin L.", ""], ["Evans", "Trefor W.", ""], ["Nair", "Prasanth B.", ""]]}, {"id": "2104.05097", "submitter": "Louis B\\'ethune", "authors": "Louis B\\'ethune, Alberto Gonz\\'alez-Sanz, Franck Mamalet, Mathieu\n  Serrurier", "title": "The Many Faces of 1-Lipschitz Neural Networks", "comments": "21 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Lipschitz constrained models have been used to solve specifics deep learning\nproblems such as the estimation of Wasserstein distance for GAN, or the\ntraining of neural networks robust to adversarial attacks. Regardless the novel\nand effective algorithms to build such 1-Lipschitz networks, their usage\nremains marginal, and they are commonly considered as less expressive and less\nable to fit properly the data than their unconstrained counterpart.\n  The goal of the paper is to demonstrate that, despite being empirically\nharder to train, 1-Lipschitz neural networks are theoretically better grounded\nthan unconstrained ones when it comes to classification. To achieve that we\nrecall some results about 1-Lipschitz function in the scope of deep learning\nand we extend and illustrate them to derive general properties for\nclassification.\n  First, we show that 1-Lipschitz neural network can fit arbitrarily difficult\nfrontier making them as expressive as classical ones. When minimizing the log\nloss, we prove that the optimization problem under Lipschitz constraint is well\nposed and have a minimum, whereas regular neural networks can diverge even on\nremarkably simple situations. Then, we study the link between classification\nwith 1-Lipschitz network and optimal transport thanks to regularized versions\nof Kantorovich-Rubinstein duality theory. Last, we derive preliminary bounds on\ntheir VC dimension.\n", "versions": [{"version": "v1", "created": "Sun, 11 Apr 2021 20:31:32 GMT"}, {"version": "v2", "created": "Tue, 13 Apr 2021 10:15:02 GMT"}, {"version": "v3", "created": "Tue, 18 May 2021 20:27:55 GMT"}, {"version": "v4", "created": "Thu, 27 May 2021 10:01:49 GMT"}], "update_date": "2021-05-28", "authors_parsed": [["B\u00e9thune", "Louis", ""], ["Gonz\u00e1lez-Sanz", "Alberto", ""], ["Mamalet", "Franck", ""], ["Serrurier", "Mathieu", ""]]}, {"id": "2104.05121", "submitter": "Sharath Chandra Guntuku", "authors": "Shubham Chaudhary, Sadbhawna, Vinit Jakhetiya, Badri N Subudhi, Ujjwal\n  Baid, Sharath Chandra Guntuku", "title": "Detecting COVID-19 and Community Acquired Pneumonia using Chest CT scan\n  images with Deep Learning", "comments": "Top Ranked Model Paper at the ICASSP 2021 COVID-19 Grand Challenge", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  We propose a two-stage Convolutional Neural Network (CNN) based\nclassification framework for detecting COVID-19 and Community-Acquired\nPneumonia (CAP) using the chest Computed Tomography (CT) scan images. In the\nfirst stage, an infection - COVID-19 or CAP, is detected using a pre-trained\nDenseNet architecture. Then, in the second stage, a fine-grained three-way\nclassification is done using EfficientNet architecture. The proposed\nCOVID+CAP-CNN framework achieved a slice-level classification accuracy of over\n94% at identifying COVID-19 and CAP. Further, the proposed framework has the\npotential to be an initial screening tool for differential diagnosis of\nCOVID-19 and CAP, achieving a validation accuracy of over 89.3% at the finer\nthree-way COVID-19, CAP, and healthy classification. Within the IEEE ICASSP\n2021 Signal Processing Grand Challenge (SPGC) on COVID-19 Diagnosis, our\nproposed two-stage classification framework achieved an overall accuracy of 90%\nand sensitivity of .857, .9, and .942 at distinguishing COVID-19, CAP, and\nnormal individuals respectively, to rank first in the evaluation. Code and\nmodel weights are available at\nhttps://github.com/shubhamchaudhary2015/ct_covid19_cap_cnn\n", "versions": [{"version": "v1", "created": "Sun, 11 Apr 2021 22:05:19 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Chaudhary", "Shubham", ""], ["Sadbhawna", "", ""], ["Jakhetiya", "Vinit", ""], ["Subudhi", "Badri N", ""], ["Baid", "Ujjwal", ""], ["Guntuku", "Sharath Chandra", ""]]}, {"id": "2104.05154", "submitter": "Wenjun Tang", "authors": "Wenjun Tang, Hao Wang, Xian-Long Lee, Hong-Tzer Yang", "title": "Uncover Residential Energy Consumption Patterns Using Socioeconomic and\n  Smart Meter Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NA math.NA", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  This paper models residential consumers' energy-consumption behavior by load\npatterns and distributions and reveals the relationship between consumers' load\npatterns and socioeconomic features by machine learning. We analyze the\nreal-world smart meter data and extract load patterns using K-Medoids\nclustering, which is robust to outliers. We develop an analytical framework\nwith feature selection and deep learning models to estimate the relationship\nbetween load patterns and socioeconomic features. Specifically, we use an\nentropy-based feature selection method to identify the critical socioeconomic\ncharacteristics that affect load patterns and benefit our method's\ninterpretability. We further develop a customized deep neural network model to\ncharacterize the relationship between consumers' load patterns and selected\nsocioeconomic features. Numerical studies validate our proposed framework using\nPecan Street smart meter data and survey. We demonstrate that our framework can\ncapture the relationship between load patterns and socioeconomic information\nand outperform benchmarks such as regression and single DNN models.\n", "versions": [{"version": "v1", "created": "Mon, 12 Apr 2021 01:57:14 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Tang", "Wenjun", ""], ["Wang", "Hao", ""], ["Lee", "Xian-Long", ""], ["Yang", "Hong-Tzer", ""]]}, {"id": "2104.05158", "submitter": "Dheevatsa Mudigere", "authors": "Dheevatsa Mudigere, Yuchen Hao, Jianyu Huang, Andrew Tulloch, Srinivas\n  Sridharan, Xing Liu, Mustafa Ozdal, Jade Nie, Jongsoo Park, Liang Luo, Jie\n  Amy Yang, Leon Gao, Dmytro Ivchenko, Aarti Basant, Yuxi Hu, Jiyan Yang, Ehsan\n  K. Ardestani, Xiaodong Wang, Rakesh Komuravelli, Ching-Hsiang Chu, Serhat\n  Yilmaz, Huayu Li, Jiyuan Qian, Zhuobo Feng, Yinbin Ma, Junjie Yang, Ellie\n  Wen, Hong Li, Lin Yang, Chonglin Sun, Whitney Zhao, Dimitry Melts, Krishna\n  Dhulipala, KR Kishore, Tyler Graf, Assaf Eisenman, Kiran Kumar Matam, Adi\n  Gangidi, Guoqiang Jerry Chen, Manoj Krishnan, Avinash Nayak, Krishnakumar\n  Nair, Bharath Muthiah, Mahmoud khorashadi, Pallab Bhattacharya, Petr\n  Lapukhov, Maxim Naumov, Lin Qiao, Mikhail Smelyanskiy, Bill Jia, Vijay Rao", "title": "High-performance, Distributed Training of Large-scale Deep Learning\n  Recommendation Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AI cs.LG cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning recommendation models (DLRMs) are used across many\nbusiness-critical services at Facebook and are the single largest AI\napplication in terms of infrastructure demand in its data-centers. In this\npaper we discuss the SW/HW co-designed solution for high-performance\ndistributed training of large-scale DLRMs. We introduce a high-performance\nscalable software stack based on PyTorch and pair it with the new evolution of\nZion platform, namely ZionEX. We demonstrate the capability to train very large\nDLRMs with up to 12 Trillion parameters and show that we can attain 40X speedup\nin terms of time to solution over previous systems. We achieve this by (i)\ndesigning the ZionEX platform with dedicated scale-out network, provisioned\nwith high bandwidth, optimal topology and efficient transport (ii) implementing\nan optimized PyTorch-based training stack supporting both model and data\nparallelism (iii) developing sharding algorithms capable of hierarchical\npartitioning of the embedding tables along row, column dimensions and load\nbalancing them across multiple workers; (iv) adding high-performance core\noperators while retaining flexibility to support optimizers with fully\ndeterministic updates (v) leveraging reduced precision communications,\nmulti-level memory hierarchy (HBM+DDR+SSD) and pipelining. Furthermore, we\ndevelop and briefly comment on distributed data ingestion and other supporting\nservices that are required for the robust and efficient end-to-end training in\nproduction environments.\n", "versions": [{"version": "v1", "created": "Mon, 12 Apr 2021 02:15:55 GMT"}, {"version": "v2", "created": "Tue, 13 Apr 2021 01:30:23 GMT"}, {"version": "v3", "created": "Thu, 15 Apr 2021 22:58:58 GMT"}], "update_date": "2021-04-19", "authors_parsed": [["Mudigere", "Dheevatsa", ""], ["Hao", "Yuchen", ""], ["Huang", "Jianyu", ""], ["Tulloch", "Andrew", ""], ["Sridharan", "Srinivas", ""], ["Liu", "Xing", ""], ["Ozdal", "Mustafa", ""], ["Nie", "Jade", ""], ["Park", "Jongsoo", ""], ["Luo", "Liang", ""], ["Yang", "Jie Amy", ""], ["Gao", "Leon", ""], ["Ivchenko", "Dmytro", ""], ["Basant", "Aarti", ""], ["Hu", "Yuxi", ""], ["Yang", "Jiyan", ""], ["Ardestani", "Ehsan K.", ""], ["Wang", "Xiaodong", ""], ["Komuravelli", "Rakesh", ""], ["Chu", "Ching-Hsiang", ""], ["Yilmaz", "Serhat", ""], ["Li", "Huayu", ""], ["Qian", "Jiyuan", ""], ["Feng", "Zhuobo", ""], ["Ma", "Yinbin", ""], ["Yang", "Junjie", ""], ["Wen", "Ellie", ""], ["Li", "Hong", ""], ["Yang", "Lin", ""], ["Sun", "Chonglin", ""], ["Zhao", "Whitney", ""], ["Melts", "Dimitry", ""], ["Dhulipala", "Krishna", ""], ["Kishore", "KR", ""], ["Graf", "Tyler", ""], ["Eisenman", "Assaf", ""], ["Matam", "Kiran Kumar", ""], ["Gangidi", "Adi", ""], ["Chen", "Guoqiang Jerry", ""], ["Krishnan", "Manoj", ""], ["Nayak", "Avinash", ""], ["Nair", "Krishnakumar", ""], ["Muthiah", "Bharath", ""], ["khorashadi", "Mahmoud", ""], ["Bhattacharya", "Pallab", ""], ["Lapukhov", "Petr", ""], ["Naumov", "Maxim", ""], ["Qiao", "Lin", ""], ["Smelyanskiy", "Mikhail", ""], ["Jia", "Bill", ""], ["Rao", "Vijay", ""]]}, {"id": "2104.05177", "submitter": "Cheng Chi", "authors": "Cheng Chi and Shuran Song", "title": "GarmentNets: Category-Level Pose Estimation for Garments via Canonical\n  Space Shape Completion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper tackles the task of category-level pose estimation for garments.\nWith a near infinite degree of freedom, a garment's full configuration (i.e.,\nposes) is often described by the per-vertex 3D locations of its entire 3D\nsurface. However, garments are also commonly subject to extreme cases of\nself-occlusion, especially when folded or crumpled, making it challenging to\nperceive their full 3D surface. To address these challenges, we propose\nGarmentNets, where the key idea is to formulate the deformable object pose\nestimation problem as a shape completion task in the canonical space. This\ncanonical space is defined across garments instances within a category,\ntherefore, specifies the shared category-level pose. By mapping the observed\npartial surface to the canonical space and completing it in this space, the\noutput representation describes the garment's full configuration using a\ncomplete 3D mesh with the per-vertex canonical coordinate label. To properly\nhandle the thin 3D structure presented on garments, we proposed a novel 3D\nshape representation using the generalized winding number field. Experiments\ndemonstrate that GarmentNets is able to generalize to unseen garment instances\nand achieve significantly better performance compared to alternative\napproaches.\n", "versions": [{"version": "v1", "created": "Mon, 12 Apr 2021 03:18:00 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Chi", "Cheng", ""], ["Song", "Shuran", ""]]}, {"id": "2104.05182", "submitter": "Hanrui Zhang", "authors": "Hanrui Zhang, Yu Cheng, Vincent Conitzer", "title": "Automated Mechanism Design for Classification with Partial Verification", "comments": "AAAI'21", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study the problem of automated mechanism design with partial verification,\nwhere each type can (mis)report only a restricted set of types (rather than any\nother type), induced by the principal's limited verification power. We prove\nhardness results when the revelation principle does not necessarily hold, as\nwell as when types have even minimally different preferences. In light of these\nhardness results, we focus on truthful mechanisms in the setting where all\ntypes share the same preference over outcomes, which is motivated by\napplications in, e.g., strategic classification. We present a number of\nalgorithmic and structural results, including an efficient algorithm for\nfinding optimal deterministic truthful mechanisms, which also implies a faster\nalgorithm for finding optimal randomized truthful mechanisms via a\ncharacterization based on convexity. We then consider a more general setting,\nwhere the principal's cost is a function of the combination of outcomes\nassigned to each type. In particular, we focus on the case where the cost\nfunction is submodular, and give generalizations of essentially all our results\nin the classical setting where the cost function is additive. Our results\nprovide a relatively complete picture for automated mechanism design with\npartial verification.\n", "versions": [{"version": "v1", "created": "Mon, 12 Apr 2021 03:29:31 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Zhang", "Hanrui", ""], ["Cheng", "Yu", ""], ["Conitzer", "Vincent", ""]]}, {"id": "2104.05196", "submitter": "Paul Pu Liang", "authors": "Yiwei Lyu, Paul Pu Liang, Hai Pham, Eduard Hovy, Barnab\\'as P\\'oczos,\n  Ruslan Salakhutdinov, Louis-Philippe Morency", "title": "StylePTB: A Compositional Benchmark for Fine-grained Controllable Text\n  Style Transfer", "comments": "NAACL 2021, code available at https://github.com/lvyiwei1/StylePTB/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Text style transfer aims to controllably generate text with targeted\nstylistic changes while maintaining core meaning from the source sentence\nconstant. Many of the existing style transfer benchmarks primarily focus on\nindividual high-level semantic changes (e.g. positive to negative), which\nenable controllability at a high level but do not offer fine-grained control\ninvolving sentence structure, emphasis, and content of the sentence. In this\npaper, we introduce a large-scale benchmark, StylePTB, with (1) paired\nsentences undergoing 21 fine-grained stylistic changes spanning atomic lexical,\nsyntactic, semantic, and thematic transfers of text, as well as (2)\ncompositions of multiple transfers which allow modeling of fine-grained\nstylistic changes as building blocks for more complex, high-level transfers. By\nbenchmarking existing methods on StylePTB, we find that they struggle to model\nfine-grained changes and have an even more difficult time composing multiple\nstyles. As a result, StylePTB brings novel challenges that we hope will\nencourage future research in controllable text style transfer, compositional\nmodels, and learning disentangled representations. Solving these challenges\nwould present important steps towards controllable text generation.\n", "versions": [{"version": "v1", "created": "Mon, 12 Apr 2021 04:25:09 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Lyu", "Yiwei", ""], ["Liang", "Paul Pu", ""], ["Pham", "Hai", ""], ["Hovy", "Eduard", ""], ["P\u00f3czos", "Barnab\u00e1s", ""], ["Salakhutdinov", "Ruslan", ""], ["Morency", "Louis-Philippe", ""]]}, {"id": "2104.05217", "submitter": "Shamma Nasrin", "authors": "Shamma Nasrin, Ahish Shylendra, Yuti Kadakia, Nick Iliev, Wilfred\n  Gomes, Theja Tulabandhula, and Amit Ranjan Trivedi", "title": "ENOS: Energy-Aware Network Operator Search for Hybrid Digital and\n  Compute-in-Memory DNN Accelerators", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.LG cs.SY", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  This work proposes a novel Energy-Aware Network Operator Search (ENOS)\napproach to address the energy-accuracy trade-offs of a deep neural network\n(DNN) accelerator. In recent years, novel inference operators have been\nproposed to improve the computational efficiency of a DNN. Augmenting the\noperators, their corresponding novel computing modes have also been explored.\nHowever, simplification of DNN operators invariably comes at the cost of lower\naccuracy, especially on complex processing tasks. Our proposed ENOS framework\nallows an optimal layer-wise integration of inference operators and computing\nmodes to achieve the desired balance of energy and accuracy. The search in ENOS\nis formulated as a continuous optimization problem, solvable using typical\ngradient descent methods, thereby scalable to larger DNNs with minimal increase\nin training cost. We characterize ENOS under two settings. In the first\nsetting, for digital accelerators, we discuss ENOS on multiply-accumulate (MAC)\ncores that can be reconfigured to different operators. ENOS training methods\nwith single and bi-level optimization objectives are discussed and compared. We\nalso discuss a sequential operator assignment strategy in ENOS that only learns\nthe assignment for one layer in one training step, enabling greater flexibility\nin converging towards the optimal operator allocations. Furthermore, following\nBayesian principles, a sampling-based variational mode of ENOS is also\npresented. ENOS is characterized on popular DNNs ShuffleNet and SqueezeNet on\nCIFAR10 and CIFAR100.\n", "versions": [{"version": "v1", "created": "Mon, 12 Apr 2021 05:57:06 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Nasrin", "Shamma", ""], ["Shylendra", "Ahish", ""], ["Kadakia", "Yuti", ""], ["Iliev", "Nick", ""], ["Gomes", "Wilfred", ""], ["Tulabandhula", "Theja", ""], ["Trivedi", "Amit Ranjan", ""]]}, {"id": "2104.05218", "submitter": "Kevin Yang", "authors": "Kevin Yang and Dan Klein", "title": "FUDGE: Controlled Text Generation With Future Discriminators", "comments": "To appear at NAACL 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose Future Discriminators for Generation (FUDGE), a flexible and\nmodular method for controlled text generation. Given a pre-existing model G for\ngenerating text from a distribution of interest, FUDGE enables conditioning on\na desired attribute a (for example, formality) while requiring access only to\nG's output logits. FUDGE learns an attribute predictor operating on a partial\nsequence, and uses this predictor's outputs to adjust G's original\nprobabilities. We show that FUDGE models terms corresponding to a Bayesian\ndecomposition of the conditional distribution of G given attribute a. Moreover,\nFUDGE can easily compose predictors for multiple desired attributes. We\nevaluate FUDGE on three tasks -- couplet completion in poetry, topic control in\nlanguage generation, and formality change in machine translation -- and observe\ngains in all three tasks.\n", "versions": [{"version": "v1", "created": "Mon, 12 Apr 2021 05:59:53 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Yang", "Kevin", ""], ["Klein", "Dan", ""]]}, {"id": "2104.05220", "submitter": "Zhongfen Deng", "authors": "Zhongfen Deng, Hao Peng, Dongxiao He, Jianxin Li, Philip S. Yu", "title": "HTCInfoMax: A Global Model for Hierarchical Text Classification via\n  Information Maximization", "comments": "Accepted by NAACL-HLT 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The current state-of-the-art model HiAGM for hierarchical text classification\nhas two limitations. First, it correlates each text sample with all labels in\nthe dataset which contains irrelevant information. Second, it does not consider\nany statistical constraint on the label representations learned by the\nstructure encoder, while constraints for representation learning are proved to\nbe helpful in previous work. In this paper, we propose HTCInfoMax to address\nthese issues by introducing information maximization which includes two\nmodules: text-label mutual information maximization and label prior matching.\nThe first module can model the interaction between each text sample and its\nground truth labels explicitly which filters out irrelevant information. The\nsecond one encourages the structure encoder to learn better representations\nwith desired characteristics for all labels which can better handle label\nimbalance in hierarchical text classification. Experimental results on two\nbenchmark datasets demonstrate the effectiveness of the proposed HTCInfoMax.\n", "versions": [{"version": "v1", "created": "Mon, 12 Apr 2021 06:04:20 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Deng", "Zhongfen", ""], ["Peng", "Hao", ""], ["He", "Dongxiao", ""], ["Li", "Jianxin", ""], ["Yu", "Philip S.", ""]]}, {"id": "2104.05225", "submitter": "Won-Yong Shin", "authors": "Yong-Min Shin, Cong Tran, Won-Yong Shin, Xin Cao", "title": "Edgeless-GNN: Unsupervised Inductive Edgeless Network Embedding", "comments": "14 pages, 6 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.IT cs.LG cs.NE math.IT", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study the problem of embedding edgeless nodes such as users who newly\nenter the underlying network, while using graph neural networks (GNNs) widely\nstudied for effective representation learning of graphs thanks to its highly\nexpressive capability via message passing. Our study is motivated by the fact\nthat existing GNNs cannot be adopted for our problem since message passing to\nsuch edgeless nodes having no connections is impossible. To tackle this\nchallenge, we propose Edgeless-GNN, a new framework that enables GNNs to\ngenerate node embeddings even for edgeless nodes through unsupervised inductive\nlearning. Specifically, we start by constructing a $k$-nearest neighbor graph\n($k$NNG) based on the similarity of node attributes to replace the GNN's\ncomputation graph defined by the neighborhood-based aggregation of each node.\nAs our main contributions, the known network structure is used to train model\nparameters, while a new loss function is established using energy-based\nlearning in such a way that our model learns the network structure. For the\nedgeless nodes, we inductively infer embeddings for the edgeless nodes by using\nedges via $k$NNG construction as a computation graph. By evaluating the\nperformance of various downstream machine learning (ML) tasks, we empirically\ndemonstrate that Edgeless-GNN consistently outperforms state-of-the-art methods\nof inductive network embedding. Moreover, our findings corroborate the\neffectiveness of Edgeless-GNN in judiciously combining the replaced computation\ngraph with our newly designed loss. Our framework is GNN-model-agnostic; thus,\nGNN models can be appropriately chosen according to ones' needs and ML tasks.\n", "versions": [{"version": "v1", "created": "Mon, 12 Apr 2021 06:37:31 GMT"}, {"version": "v2", "created": "Mon, 26 Jul 2021 05:30:09 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Shin", "Yong-Min", ""], ["Tran", "Cong", ""], ["Shin", "Won-Yong", ""], ["Cao", "Xin", ""]]}, {"id": "2104.05232", "submitter": "Chong Zhang", "authors": "Chong Zhang, Jieyu Zhao, Huan Zhang, Kai-Wei Chang, Cho-Jui Hsieh", "title": "Double Perturbation: On the Robustness of Robustness and Counterfactual\n  Bias Evaluation", "comments": "NAACL 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robustness and counterfactual bias are usually evaluated on a test dataset.\nHowever, are these evaluations robust? If the test dataset is perturbed\nslightly, will the evaluation results keep the same? In this paper, we propose\na \"double perturbation\" framework to uncover model weaknesses beyond the test\ndataset. The framework first perturbs the test dataset to construct abundant\nnatural sentences similar to the test data, and then diagnoses the prediction\nchange regarding a single-word substitution. We apply this framework to study\ntwo perturbation-based approaches that are used to analyze models' robustness\nand counterfactual bias in English. (1) For robustness, we focus on synonym\nsubstitutions and identify vulnerable examples where prediction can be altered.\nOur proposed attack attains high success rates (96.0%-99.8%) in finding\nvulnerable examples on both original and robustly trained CNNs and\nTransformers. (2) For counterfactual bias, we focus on substituting demographic\ntokens (e.g., gender, race) and measure the shift of the expected prediction\namong constructed sentences. Our method is able to reveal the hidden model\nbiases not directly shown in the test dataset. Our code is available at\nhttps://github.com/chong-z/nlp-second-order-attack.\n", "versions": [{"version": "v1", "created": "Mon, 12 Apr 2021 06:57:36 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Zhang", "Chong", ""], ["Zhao", "Jieyu", ""], ["Zhang", "Huan", ""], ["Chang", "Kai-Wei", ""], ["Hsieh", "Cho-Jui", ""]]}, {"id": "2104.05245", "submitter": "Ce Zhang", "authors": "Ji Liu, Ce Zhang", "title": "Distributed Learning Systems with First-order Methods", "comments": "Foundations and Trends in Databases: Vol. 9: No. 1", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DB cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Scalable and efficient distributed learning is one of the main driving forces\nbehind the recent rapid advancement of machine learning and artificial\nintelligence. One prominent feature of this topic is that recent progresses\nhave been made by researchers in two communities: (1) the system community such\nas database, data management, and distributed systems, and (2) the machine\nlearning and mathematical optimization community. The interaction and knowledge\nsharing between these two communities has led to the rapid development of new\ndistributed learning systems and theory.\n  In this work, we hope to provide a brief introduction of some distributed\nlearning techniques that have recently been developed, namely lossy\ncommunication compression (e.g., quantization and sparsification), asynchronous\ncommunication, and decentralized communication. One special focus in this work\nis on making sure that it can be easily understood by researchers in both\ncommunities -- On the system side, we rely on a simplified system model hiding\nmany system details that are not necessary for the intuition behind the system\nspeedups; while, on the theory side, we rely on minimal assumptions and\nsignificantly simplify the proof of some recent work to achieve comparable\nresults.\n", "versions": [{"version": "v1", "created": "Mon, 12 Apr 2021 07:27:07 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Liu", "Ji", ""], ["Zhang", "Ce", ""]]}, {"id": "2104.05248", "submitter": "Islam Nassar", "authors": "Islam Nassar, Samitha Herath, Ehsan Abbasnejad, Wray Buntine,\n  Gholamreza Haffari", "title": "All Labels Are Not Created Equal: Enhancing Semi-supervision via Label\n  Grouping and Co-training", "comments": "Accepted in CVPR2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pseudo-labeling is a key component in semi-supervised learning (SSL). It\nrelies on iteratively using the model to generate artificial labels for the\nunlabeled data to train against. A common property among its various methods is\nthat they only rely on the model's prediction to make labeling decisions\nwithout considering any prior knowledge about the visual similarity among the\nclasses. In this paper, we demonstrate that this degrades the quality of\npseudo-labeling as it poorly represents visually similar classes in the pool of\npseudo-labeled data. We propose SemCo, a method which leverages label semantics\nand co-training to address this problem. We train two classifiers with two\ndifferent views of the class labels: one classifier uses the one-hot view of\nthe labels and disregards any potential similarity among the classes, while the\nother uses a distributed view of the labels and groups potentially similar\nclasses together. We then co-train the two classifiers to learn based on their\ndisagreements. We show that our method achieves state-of-the-art performance\nacross various SSL tasks including 5.6% accuracy improvement on Mini-ImageNet\ndataset with 1000 labeled examples. We also show that our method requires\nsmaller batch size and fewer training iterations to reach its best performance.\nWe make our code available at https://github.com/islam-nassar/semco.\n", "versions": [{"version": "v1", "created": "Mon, 12 Apr 2021 07:33:16 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Nassar", "Islam", ""], ["Herath", "Samitha", ""], ["Abbasnejad", "Ehsan", ""], ["Buntine", "Wray", ""], ["Haffari", "Gholamreza", ""]]}, {"id": "2104.05252", "submitter": "Victor Berger", "authors": "Victor Berger (TAU), Michele Sebag (TAU)", "title": "Boltzmann Tuning of Generative Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper focuses on the a posteriori tuning of a generative model in order\nto favor the generation of good instances in the sense of some external\ndifferentiable criterion. The proposed approach, called Boltzmann Tuning of\nGenerative Models (BTGM), applies to a wide range of applications. It covers\nconditional generative modelling as a particular case, and offers an affordable\nalternative to rejection sampling. The contribution of the paper is twofold.\nFirstly, the objective is formalized and tackled as a well-posed optimization\nproblem; a practical methodology is proposed to choose among the candidate\ncriteria representing the same goal, the one best suited to efficiently learn a\ntuned generative model. Secondly, the merits of the approach are demonstrated\non a real-world application, in the context of robust design for energy\npolicies, showing the ability of BTGM to sample the extreme regions of the\nconsidered criteria.\n", "versions": [{"version": "v1", "created": "Mon, 12 Apr 2021 07:35:27 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Berger", "Victor", "", "TAU"], ["Sebag", "Michele", "", "TAU"]]}, {"id": "2104.05279", "submitter": "Ahmet Iscen", "authors": "Ahmet Iscen, Andr\\'e Araujo, Boqing Gong, Cordelia Schmid", "title": "Class-Balanced Distillation for Long-Tailed Visual Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Real-world imagery is often characterized by a significant imbalance of the\nnumber of images per class, leading to long-tailed distributions. An effective\nand simple approach to long-tailed visual recognition is to learn feature\nrepresentations and a classifier separately, with instance and class-balanced\nsampling, respectively. In this work, we introduce a new framework, by making\nthe key observation that a feature representation learned with instance\nsampling is far from optimal in a long-tailed setting. Our main contribution is\na new training method, referred to as Class-Balanced Distillation (CBD), that\nleverages knowledge distillation to enhance feature representations. CBD allows\nthe feature representation to evolve in the second training stage, guided by\nthe teacher learned in the first stage. The second stage uses class-balanced\nsampling, in order to focus on under-represented classes. This framework can\nnaturally accommodate the usage of multiple teachers, unlocking the information\nfrom an ensemble of models to enhance recognition capabilities. Our experiments\nshow that the proposed technique consistently outperforms the state of the art\non long-tailed recognition benchmarks such as ImageNet-LT, iNaturalist17 and\niNaturalist18. The experiments also show that our method does not sacrifice the\naccuracy of head classes to improve the performance of tail classes, unlike\nmost existing work.\n", "versions": [{"version": "v1", "created": "Mon, 12 Apr 2021 08:21:03 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Iscen", "Ahmet", ""], ["Araujo", "Andr\u00e9", ""], ["Gong", "Boqing", ""], ["Schmid", "Cordelia", ""]]}, {"id": "2104.05294", "submitter": "Shubham Gupta", "authors": "Shubham Gupta, Aadirupa Saha, and Sumeet Katariya", "title": "Pure Exploration with Structured Preference Feedback", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of pure exploration with subset-wise preference\nfeedback, which contains $N$ arms with features. The learner is allowed to\nquery subsets of size $K$ and receives feedback in the form of a noisy winner.\nThe goal of the learner is to identify the best arm efficiently using as few\nqueries as possible. This setting is relevant in various online decision-making\nscenarios involving human feedback such as online retailing, streaming\nservices, news feed, and online advertising; since it is easier and more\nreliable for people to choose a preferred item from a subset than to assign a\nlikability score to an item in isolation. To the best of our knowledge, this is\nthe first work that considers the subset-wise preference feedback model in a\nstructured setting, which allows for potentially infinite set of arms. We\npresent two algorithms that guarantee the detection of the best-arm in\n$\\tilde{O} (\\frac{d^2}{K \\Delta^2})$ samples with probability at least $1 -\n\\delta$, where $d$ is the dimension of the arm-features and $\\Delta$ is the\nappropriate notion of utility gap among the arms. We also derive an\ninstance-dependent lower bound of $\\Omega(\\frac{d}{\\Delta^2} \\log\n\\frac{1}{\\delta})$ which matches our upper bound on a worst-case instance.\nFinally, we run extensive experiments to corroborate our theoretical findings,\nand observe that our adaptive algorithm stops and requires up to 12x fewer\nsamples than a non-adaptive algorithm.\n", "versions": [{"version": "v1", "created": "Mon, 12 Apr 2021 08:57:29 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Gupta", "Shubham", ""], ["Saha", "Aadirupa", ""], ["Katariya", "Sumeet", ""]]}, {"id": "2104.05307", "submitter": "Qilin Deng", "authors": "Qilin Deng, Kai Wang, Minghao Zhao, Zhene Zou, Runze Wu, Jianrong Tao,\n  Changjie Fan, Liang Chen", "title": "Personalized Bundle Recommendation in Online Games", "comments": "8 pages, 10 figures, accepted paper on CIKM 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In business domains, \\textit{bundling} is one of the most important marketing\nstrategies to conduct product promotions, which is commonly used in online\ne-commerce and offline retailers. Existing recommender systems mostly focus on\nrecommending individual items that users may be interested in. In this paper,\nwe target at a practical but less explored recommendation problem named bundle\nrecommendation, which aims to offer a combination of items to users. To tackle\nthis specific recommendation problem in the context of the \\emph{virtual mall}\nin online games, we formalize it as a link prediction problem on a\nuser-item-bundle tripartite graph constructed from the historical interactions,\nand solve it with a neural network model that can learn directly on the\ngraph-structure data. Extensive experiments on three public datasets and one\nindustrial game dataset demonstrate the effectiveness of the proposed method.\nFurther, the bundle recommendation model has been deployed in production for\nmore than one year in a popular online game developed by Netease Games, and the\nlaunch of the model yields more than 60\\% improvement on conversion rate of\nbundles, and a relative improvement of more than 15\\% on gross merchandise\nvolume (GMV).\n", "versions": [{"version": "v1", "created": "Mon, 12 Apr 2021 09:28:16 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Deng", "Qilin", ""], ["Wang", "Kai", ""], ["Zhao", "Minghao", ""], ["Zou", "Zhene", ""], ["Wu", "Runze", ""], ["Tao", "Jianrong", ""], ["Fan", "Changjie", ""], ["Chen", "Liang", ""]]}, {"id": "2104.05309", "submitter": "Kaicheng Yu", "authors": "Kaicheng Yu, Rene Ranftl, Mathieu Salzmann", "title": "Landmark Regularization: Ranking Guided Super-Net Training in Neural\n  Architecture Search", "comments": "Accepted to CVPR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Weight sharing has become a de facto standard in neural architecture search\nbecause it enables the search to be done on commodity hardware. However, recent\nworks have empirically shown a ranking disorder between the performance of\nstand-alone architectures and that of the corresponding shared-weight networks.\nThis violates the main assumption of weight-sharing NAS algorithms, thus\nlimiting their effectiveness. We tackle this issue by proposing a\nregularization term that aims to maximize the correlation between the\nperformance rankings of the shared-weight network and that of the standalone\narchitectures using a small set of landmark architectures. We incorporate our\nregularization term into three different NAS algorithms and show that it\nconsistently improves performance across algorithms, search-spaces, and tasks.\n", "versions": [{"version": "v1", "created": "Mon, 12 Apr 2021 09:32:33 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Yu", "Kaicheng", ""], ["Ranftl", "Rene", ""], ["Salzmann", "Mathieu", ""]]}, {"id": "2104.05316", "submitter": "Lu Xu", "authors": "Lu Xu, Zhanming Jie, Wei Lu and Lidong Bing", "title": "Better Feature Integration for Named Entity Recognition", "comments": "Accepted by NAACL 2021. 13 pages, 9 Figure, 10 Tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  It has been shown that named entity recognition (NER) could benefit from\nincorporating the long-distance structured information captured by dependency\ntrees. We believe this is because both types of features - the contextual\ninformation captured by the linear sequences and the structured information\ncaptured by the dependency trees may complement each other. However, existing\napproaches largely focused on stacking the LSTM and graph neural networks such\nas graph convolutional networks (GCNs) for building improved NER models, where\nthe exact interaction mechanism between the two types of features is not very\nclear, and the performance gain does not appear to be significant. In this\nwork, we propose a simple and robust solution to incorporate both types of\nfeatures with our Synergized-LSTM (Syn-LSTM), which clearly captures how the\ntwo types of features interact. We conduct extensive experiments on several\nstandard datasets across four languages. The results demonstrate that the\nproposed model achieves better performance than previous approaches while\nrequiring fewer parameters. Our further analysis demonstrates that our model\ncan capture longer dependencies compared with strong baselines.\n", "versions": [{"version": "v1", "created": "Mon, 12 Apr 2021 09:55:06 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Xu", "Lu", ""], ["Jie", "Zhanming", ""], ["Lu", "Wei", ""], ["Bing", "Lidong", ""]]}, {"id": "2104.05321", "submitter": "Rachit Bansal", "authors": "Rachit Bansal, William Scott Paka, Nidhi, Shubhashis Sengupta, Tanmoy\n  Chakraborty", "title": "Combining exogenous and endogenous signals with a semi-supervised\n  co-attention network for early detection of COVID-19 fake tweets", "comments": "Pacific-Asia Conference on Knowledge Discovery and Data Mining\n  (PAKDD) 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Fake tweets are observed to be ever-increasing, demanding immediate\ncountermeasures to combat their spread. During COVID-19, tweets with\nmisinformation should be flagged and neutralized in their early stages to\nmitigate the damages. Most of the existing methods for early detection of fake\nnews assume to have enough propagation information for large labeled tweets --\nwhich may not be an ideal setting for cases like COVID-19 where both aspects\nare largely absent. In this work, we present ENDEMIC, a novel early detection\nmodel which leverages exogenous and endogenous signals related to tweets, while\nlearning on limited labeled data. We first develop a novel dataset, called CTF\nfor early COVID-19 Twitter fake news, with additional behavioral test sets to\nvalidate early detection. We build a heterogeneous graph with\nfollower-followee, user-tweet, and tweet-retweet connections and train a graph\nembedding model to aggregate propagation information. Graph embeddings and\ncontextual features constitute endogenous, while time-relative web-scraped\ninformation constitutes exogenous signals. ENDEMIC is trained in a\nsemi-supervised fashion, overcoming the challenge of limited labeled data. We\npropose a co-attention mechanism to fuse signal representations optimally.\nExperimental results on ECTF, PolitiFact, and GossipCop show that ENDEMIC is\nhighly reliable in detecting early fake tweets, outperforming nine\nstate-of-the-art methods significantly.\n", "versions": [{"version": "v1", "created": "Mon, 12 Apr 2021 10:01:44 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Bansal", "Rachit", ""], ["Paka", "William Scott", ""], ["Nidhi", "", ""], ["Sengupta", "Shubhashis", ""], ["Chakraborty", "Tanmoy", ""]]}, {"id": "2104.05336", "submitter": "R\\'emi Leblond", "authors": "R\\'emi Leblond, Jean-Baptiste Alayrac, Laurent Sifre, Miruna Pislar,\n  Jean-Baptiste Lespiau, Ioannis Antonoglou, Karen Simonyan and Oriol Vinyals", "title": "Machine Translation Decoding beyond Beam Search", "comments": "23 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Beam search is the go-to method for decoding auto-regressive machine\ntranslation models. While it yields consistent improvements in terms of BLEU,\nit is only concerned with finding outputs with high model likelihood, and is\nthus agnostic to whatever end metric or score practitioners care about. Our aim\nis to establish whether beam search can be replaced by a more powerful\nmetric-driven search technique. To this end, we explore numerous decoding\nalgorithms, including some which rely on a value function parameterised by a\nneural network, and report results on a variety of metrics. Notably, we\nintroduce a Monte-Carlo Tree Search (MCTS) based method and showcase its\ncompetitiveness. We provide a blueprint for how to use MCTS fruitfully in\nlanguage applications, which opens promising future directions. We find that\nwhich algorithm is best heavily depends on the characteristics of the goal\nmetric; we believe that our extensive experiments and analysis will inform\nfurther research in this area.\n", "versions": [{"version": "v1", "created": "Mon, 12 Apr 2021 10:28:17 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Leblond", "R\u00e9mi", ""], ["Alayrac", "Jean-Baptiste", ""], ["Sifre", "Laurent", ""], ["Pislar", "Miruna", ""], ["Lespiau", "Jean-Baptiste", ""], ["Antonoglou", "Ioannis", ""], ["Simonyan", "Karen", ""], ["Vinyals", "Oriol", ""]]}, {"id": "2104.05343", "submitter": "Yang You", "authors": "Qifan Xu and Shenggui Li and Chaoyu Gong and Yang You", "title": "An Efficient 2D Method for Training Super-Large Deep Learning Models", "comments": "Mr. Qifan Xu finished this work when he was an intern in Dr. Yang\n  You's group at NUS", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Huge neural network models have shown unprecedented performance in real-world\napplications. However, due to memory constraints, model parallelism must be\nutilized to host large models that would otherwise not fit into the memory of a\nsingle device. Previous methods like Megatron partition the parameters of the\nentire model among multiple devices, while each device has to accommodate the\nredundant activations in forward and backward pass. In this work, we propose\nOptimus, a highly efficient and scalable 2D-partition paradigm of model\nparallelism that would facilitate the training of infinitely large language\nmodels. In Optimus, activations are partitioned and distributed among devices,\nfurther reducing redundancy. In terms of isoefficiency, Optimus significantly\noutperforms Megatron. On 64 GPUs of TACC Frontera, Optimus achieves 1.48X\nspeedup for training, 1.78X speedup for inference, and 8X increase in maximum\nbatch size over Megatron. Optimus surpasses Megatron in scaling efficiency by a\ngreat margin. The code is available at https://github.com/xuqifan897/Optimus.\n", "versions": [{"version": "v1", "created": "Mon, 12 Apr 2021 10:47:16 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Xu", "Qifan", ""], ["Li", "Shenggui", ""], ["Gong", "Chaoyu", ""], ["You", "Yang", ""]]}, {"id": "2104.05344", "submitter": "Mateusz Ochal", "authors": "Mateusz Ochal, Massimiliano Patacchiola, Amos Storkey, Jose Vazquez,\n  Sen Wang", "title": "How Sensitive are Meta-Learners to Dataset Imbalance?", "comments": "Published as a workshop paper at the Learning to Learn workshop at\n  ICLR 2021. arXiv admin note: text overlap with arXiv:2101.02523", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Meta-Learning (ML) has proven to be a useful tool for training Few-Shot\nLearning (FSL) algorithms by exposure to batches of tasks sampled from a\nmeta-dataset. However, the standard training procedure overlooks the dynamic\nnature of the real-world where object classes are likely to occur at different\nfrequencies. While it is generally understood that imbalanced tasks harm the\nperformance of supervised methods, there is no significant research examining\nthe impact of imbalanced meta-datasets on the FSL evaluation task. This study\nexposes the magnitude and extent of this problem. Our results show that ML\nmethods are more robust against meta-dataset imbalance than imbalance at the\ntask-level with a similar imbalance ratio ($\\rho<20$), with the effect holding\neven in long-tail datasets under a larger imbalance ($\\rho=65$). Overall, these\nresults highlight an implicit strength of ML algorithms, capable of learning\ngeneralizable features under dataset imbalance and domain-shift. The code to\nreproduce the experiments is released under an open-source license.\n", "versions": [{"version": "v1", "created": "Mon, 12 Apr 2021 10:47:42 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Ochal", "Mateusz", ""], ["Patacchiola", "Massimiliano", ""], ["Storkey", "Amos", ""], ["Vazquez", "Jose", ""], ["Wang", "Sen", ""]]}, {"id": "2104.05353", "submitter": "Can Bakiskan", "authors": "Can Bakiskan, Metehan Cekic, Ahmet Dundar Sezer, Upamanyu Madhow", "title": "Sparse Coding Frontend for Robust Neural Networks", "comments": "International Conference on Learning Representations (ICLR) 2021\n  Workshop on Security and Safety in Machine Learning Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Deep Neural Networks are known to be vulnerable to small, adversarially\ncrafted, perturbations. The current most effective defense methods against\nthese adversarial attacks are variants of adversarial training. In this paper,\nwe introduce a radically different defense trained only on clean images: a\nsparse coding based frontend which significantly attenuates adversarial attacks\nbefore they reach the classifier. We evaluate our defense on CIFAR-10 dataset\nunder a wide range of attack types (including Linf , L2, and L1 bounded\nattacks), demonstrating its promise as a general-purpose approach for defense.\n", "versions": [{"version": "v1", "created": "Mon, 12 Apr 2021 11:14:32 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Bakiskan", "Can", ""], ["Cekic", "Metehan", ""], ["Sezer", "Ahmet Dundar", ""], ["Madhow", "Upamanyu", ""]]}, {"id": "2104.05358", "submitter": "Hiroshi Sasaki", "authors": "Hiroshi Sasaki, Chris G. Willcocks, Toby P. Breckon", "title": "UNIT-DDPM: UNpaired Image Translation with Denoising Diffusion\n  Probabilistic Models", "comments": "10 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel unpaired image-to-image translation method that uses\ndenoising diffusion probabilistic models without requiring adversarial\ntraining. Our method, UNpaired Image Translation with Denoising Diffusion\nProbabilistic Models (UNIT-DDPM), trains a generative model to infer the joint\ndistribution of images over both domains as a Markov chain by minimising a\ndenoising score matching objective conditioned on the other domain. In\nparticular, we update both domain translation models simultaneously, and we\ngenerate target domain images by a denoising Markov Chain Monte Carlo approach\nthat is conditioned on the input source domain images, based on Langevin\ndynamics. Our approach provides stable model training for image-to-image\ntranslation and generates high-quality image outputs. This enables\nstate-of-the-art Fr\\'echet Inception Distance (FID) performance on several\npublic datasets, including both colour and multispectral imagery, significantly\noutperforming the contemporary adversarial image-to-image translation methods.\n", "versions": [{"version": "v1", "created": "Mon, 12 Apr 2021 11:22:56 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Sasaki", "Hiroshi", ""], ["Willcocks", "Chris G.", ""], ["Breckon", "Toby P.", ""]]}, {"id": "2104.05379", "submitter": "Nick Rossenbach", "authors": "Nick Rossenbach, Mohammad Zeineldeen, Benedikt Hilmes, Ralf\n  Schl\\\"uter, Hermann Ney", "title": "Comparing the Benefit of Synthetic Training Data for Various Automatic\n  Speech Recognition Architectures", "comments": "Submitted to ASRU 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent publications on automatic-speech-recognition (ASR) have a strong focus\non attention encoder-decoder (AED) architectures which tend to suffer from\nover-fitting in low resource scenarios. One solution to tackle this issue is to\ngenerate synthetic data with a trained text-to-speech system (TTS) if\nadditional text is available. This was successfully applied in many\npublications with AED systems, but only very limited in the context of other\nASR architectures. We investigate the effect of varying pre-processing, the\nspeaker embedding and input encoding of the TTS system w.r.t. the effectiveness\nof the synthesized data for AED-ASR training. Additionally, we also consider\ninternal language model subtraction for the first time, resulting in up to 38%\nrelative improvement. We compare the AED results to a state-of-the-art hybrid\nASR system, a monophone based system using\nconnectionist-temporal-classification (CTC) and a monotonic transducer based\nsystem. We show that for the later systems the addition of synthetic data has\nno relevant effect, but they still outperform the AED systems on\nLibriSpeech-100h. We achieve a final word-error-rate of 3.3%/10.0% with a\nhybrid system on the clean/noisy test-sets, surpassing any previous\nstate-of-the-art systems on Librispeech-100h that do not include unlabeled\naudio data.\n", "versions": [{"version": "v1", "created": "Mon, 12 Apr 2021 11:59:23 GMT"}, {"version": "v2", "created": "Wed, 9 Jun 2021 21:37:06 GMT"}, {"version": "v3", "created": "Tue, 13 Jul 2021 15:02:15 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Rossenbach", "Nick", ""], ["Zeineldeen", "Mohammad", ""], ["Hilmes", "Benedikt", ""], ["Schl\u00fcter", "Ralf", ""], ["Ney", "Hermann", ""]]}, {"id": "2104.05413", "submitter": "Jia Wang", "authors": "Jia Wang, Tong Sun, Benyuan Liu, Yu Cao, Degang Wang", "title": "Financial Markets Prediction with Deep Learning", "comments": "8 pages, 2018 17th IEEE International Conference on Machine Learning\n  and Applications (ICMLA). IEEE, 2018", "journal-ref": null, "doi": "10.1109/ICMLA.2018.00022", "report-no": null, "categories": "q-fin.ST cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Financial markets are difficult to predict due to its complex systems\ndynamics. Although there have been some recent studies that use machine\nlearning techniques for financial markets prediction, they do not offer\nsatisfactory performance on financial returns. We propose a novel\none-dimensional convolutional neural networks (CNN) model to predict financial\nmarket movement. The customized one-dimensional convolutional layers scan\nfinancial trading data through time, while different types of data, such as\nprices and volume, share parameters (kernels) with each other. Our model\nautomatically extracts features instead of using traditional technical\nindicators and thus can avoid biases caused by selection of technical\nindicators and pre-defined coefficients in technical indicators. We evaluate\nthe performance of our prediction model with strictly backtesting on historical\ntrading data of six futures from January 2010 to October 2017. The experiment\nresults show that our CNN model can effectively extract more generalized and\ninformative features than traditional technical indicators, and achieves more\nrobust and profitable financial performance than previous machine learning\napproaches.\n", "versions": [{"version": "v1", "created": "Mon, 5 Apr 2021 19:36:48 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Wang", "Jia", ""], ["Sun", "Tong", ""], ["Liu", "Benyuan", ""], ["Cao", "Yu", ""], ["Wang", "Degang", ""]]}, {"id": "2104.05417", "submitter": "Kevin Brol{\\o}s", "authors": "Kevin Ren\\'e Brol{\\o}s, Meera Vieira Machado, Chris Cave, Jaan Kasak,\n  Valdemar Stentoft-Hansen, Victor Galindo Batanero, Tom Jelen, Casper Wilstrup", "title": "An Approach to Symbolic Regression Using Feyn", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.ET", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this article we introduce the supervised machine learning tool called\nFeyn. The simulation engine that powers this tool is called the QLattice. The\nQLattice is a supervised machine learning tool inspired by Richard Feynman's\npath integral formulation, that explores many potential models that solves a\ngiven problem. It formulates these models as graphs that can be interpreted as\nmathematical equations, allowing the user to completely decide on the trade-off\nbetween interpretability, complexity and model performance.\n  We touch briefly upon the inner workings of the QLattice, and show how to\napply the python package, Feyn, to scientific problems. We show how it differs\nfrom traditional machine learning approaches, what it has in common with them,\nas well as some of its commonalities with symbolic regression. We describe the\nbenefits of this approach as opposed to black box models.\n  To illustrate this, we go through an investigative workflow using a basic\ndata set and show how the QLattice can help you reason about the relationships\nbetween your features and do data discovery.\n", "versions": [{"version": "v1", "created": "Mon, 12 Apr 2021 12:50:50 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Brol\u00f8s", "Kevin Ren\u00e9", ""], ["Machado", "Meera Vieira", ""], ["Cave", "Chris", ""], ["Kasak", "Jaan", ""], ["Stentoft-Hansen", "Valdemar", ""], ["Batanero", "Victor Galindo", ""], ["Jelen", "Tom", ""], ["Wilstrup", "Casper", ""]]}, {"id": "2104.05418", "submitter": "Shuang Ma", "authors": "Shuang Ma, Zhaoyang Zeng, Daniel McDuff, Yale Song", "title": "Contrastive Learning of Global and Local Audio-Visual Representations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.SD eess.AS eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Contrastive learning has delivered impressive results in many audio-visual\nrepresentation learning scenarios. However, existing approaches optimize for\nlearning either \\textit{global} representations useful for tasks such as\nclassification, or \\textit{local} representations useful for tasks such as\naudio-visual source localization and separation. While they produce\nsatisfactory results in their intended downstream scenarios, they often fail to\ngeneralize to tasks that they were not originally designed for. In this work,\nwe propose a versatile self-supervised approach to learn audio-visual\nrepresentations that generalize to both the tasks which require global semantic\ninformation (e.g., classification) and the tasks that require fine-grained\nspatio-temporal information (e.g. localization). We achieve this by optimizing\ntwo cross-modal contrastive objectives that together encourage our model to\nlearn discriminative global-local visual information given audio signals. To\nshow that our approach learns generalizable video representations, we evaluate\nit on various downstream scenarios including action/sound classification, lip\nreading, deepfake detection, and sound source localization.\n", "versions": [{"version": "v1", "created": "Wed, 7 Apr 2021 07:35:08 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Ma", "Shuang", ""], ["Zeng", "Zhaoyang", ""], ["McDuff", "Daniel", ""], ["Song", "Yale", ""]]}, {"id": "2104.05421", "submitter": "Mahdi Nazemi", "authors": "Mahdi Nazemi, Arash Fayyazi, Amirhossein Esmaili, Atharva Khare,\n  Soheil Nazar Shahsavani, and Massoud Pedram", "title": "NullaNet Tiny: Ultra-low-latency DNN Inference Through Fixed-function\n  Combinational Logic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  While there is a large body of research on efficient processing of deep\nneural networks (DNNs), ultra-low-latency realization of these models for\napplications with stringent, sub-microsecond latency requirements continues to\nbe an unresolved, challenging problem. Field-programmable gate array\n(FPGA)-based DNN accelerators are gaining traction as a serious contender to\nreplace graphics processing unit/central processing unit-based platforms\nconsidering their performance, flexibility, and energy efficiency. This paper\npresents NullaNet Tiny, an across-the-stack design and optimization framework\nfor constructing resource and energy-efficient, ultra-low-latency FPGA-based\nneural network accelerators. The key idea is to replace expensive operations\nrequired to compute various filter/neuron functions in a DNN with Boolean logic\nexpressions that are mapped to the native look-up tables (LUTs) of the FPGA\ndevice (examples of such operations are multiply-and-accumulate and batch\nnormalization). At about the same level of classification accuracy, compared to\nXilinx's LogicNets, our design achieves 2.36$\\times$ lower latency and\n24.42$\\times$ lower LUT utilization.\n", "versions": [{"version": "v1", "created": "Wed, 7 Apr 2021 00:16:39 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Nazemi", "Mahdi", ""], ["Fayyazi", "Arash", ""], ["Esmaili", "Amirhossein", ""], ["Khare", "Atharva", ""], ["Shahsavani", "Soheil Nazar", ""], ["Pedram", "Massoud", ""]]}, {"id": "2104.05432", "submitter": "Nils Gumpfer", "authors": "Michael Guckert, Nils Gumpfer, Jennifer Hannig, Till Keller and Neil\n  Urquhart", "title": "A Conceptual Framework for Establishing Trust in Real World Intelligent\n  Systems", "comments": null, "journal-ref": null, "doi": "10.1016/j.cogsys.2021.04.001", "report-no": null, "categories": "cs.CY cs.AI cs.GT cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Intelligent information systems that contain emergent elements often\nencounter trust problems because results do not get sufficiently explained and\nthe procedure itself can not be fully retraced. This is caused by a control\nflow depending either on stochastic elements or on the structure and relevance\nof the input data. Trust in such algorithms can be established by letting users\ninteract with the system so that they can explore results and find patterns\nthat can be compared with their expected solution. Reflecting features and\npatterns of human understanding of a domain against algorithmic results can\ncreate awareness of such patterns and may increase the trust that a user has in\nthe solution. If expectations are not met, close inspection can be used to\ndecide whether a solution conforms to the expectations or whether it goes\nbeyond the expected. By either accepting or rejecting a solution, the user's\nset of expectations evolves and a learning process for the users is\nestablished. In this paper we present a conceptual framework that reflects and\nsupports this process. The framework is the result of an analysis of two\nexemplary case studies from two different disciplines with information systems\nthat assist experts in their complex tasks.\n", "versions": [{"version": "v1", "created": "Mon, 12 Apr 2021 12:58:47 GMT"}], "update_date": "2021-04-30", "authors_parsed": [["Guckert", "Michael", ""], ["Gumpfer", "Nils", ""], ["Hannig", "Jennifer", ""], ["Keller", "Till", ""], ["Urquhart", "Neil", ""]]}, {"id": "2104.05435", "submitter": "Ruixuan Yan", "authors": "Ruixuan Yan, Agung Julius", "title": "Neural Network for Weighted Signal Temporal Logic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a neuro-symbolic framework called weighted Signal\nTemporal Logic Neural Network (wSTL-NN) that combines the characteristics of\nneural networks and temporal logics. Weighted Signal Temporal Logic (wSTL)\nformulas are recursively composed of subformulas that are combined using\nlogical and temporal operators. The quantitative semantics of wSTL is defined\nsuch that the quantitative satisfaction of subformulas with higher weights has\nmore influence on the quantitative satisfaction of the overall wSTL formula. In\nthe wSTL-NN, each neuron corresponds to a wSTL subformula, and its output\ncorresponds to the quantitative satisfaction of the formula. We use wSTL-NN to\nrepresent wSTL formulas as features to classify time series data. STL features\nare more explainable than those used in classical methods. The wSTL-NN is\nend-to-end differentiable, which allows learning of wSTL formulas to be done\nusing back-propagation. To reduce the number of weights, we introduce two\ntechniques to sparsify the wSTL-NN.We apply our framework to an occupancy\ndetection time-series dataset to learn a classifier that predicts the occupancy\nstatus of an office room.\n", "versions": [{"version": "v1", "created": "Thu, 8 Apr 2021 20:44:26 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Yan", "Ruixuan", ""], ["Julius", "Agung", ""]]}, {"id": "2104.05437", "submitter": "Michael D. Graham", "authors": "Kevin Zeng, Michael D. Graham", "title": "Symmetry reduction for deep reinforcement learning active control of\n  chaotic spatiotemporal dynamics", "comments": "Submitted to Physical Review E", "journal-ref": "Phys. Rev. E 104, 014210 (2021)", "doi": "10.1103/PhysRevE.104.014210", "report-no": null, "categories": "cs.LG nlin.CD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning (RL) is a data-driven, model-free method capable\nof discovering complex control strategies for macroscopic objectives in\nhigh-dimensional systems, making its application towards flow control\npromising. Many systems of flow control interest possess symmetries that, when\nneglected, can significantly inhibit the learning and performance of a naive\ndeep RL approach. Using a test-bed consisting of the Kuramoto-Sivashinsky\nEquation (KSE), equally spaced actuators, and a goal of minimizing dissipation\nand power cost, we demonstrate that by moving the deep RL problem to a\nsymmetry-reduced space, we can alleviate limitations inherent in the naive\napplication of deep RL. We demonstrate that symmetry-reduced deep RL yields\nimproved data efficiency as well as improved control policy efficacy compared\nto policies found by naive deep RL. Interestingly, the policy learned by the\nthe symmetry aware control agent drives the system toward an equilibrium state\nof the forced KSE that is connected by continuation to an equilibrium of the\nunforced KSE, despite having been given no explicit information regarding its\nexistence. I.e., to achieve its goal, the RL algorithm discovers and stabilizes\nan equilibrium state of the system. Finally, we demonstrate that the\nsymmetry-reduced control policy is robust to observation and actuation signal\nnoise, as well as to system parameters it has not observed before.\n", "versions": [{"version": "v1", "created": "Fri, 9 Apr 2021 17:55:12 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Zeng", "Kevin", ""], ["Graham", "Michael D.", ""]]}, {"id": "2104.05439", "submitter": "Shuqian Ye", "authors": "Haoxiang Lin, Shuqian Ye, Xi Zhu", "title": "Tensor Network for Supervised Learning at Finite Temperature", "comments": "Video and slide are available on\n  https://tensorworkshop.github.io/2020/program.html", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The large variation of datasets is a huge barrier for image classification\ntasks. In this paper, we embraced this observation and introduce the finite\ntemperature tensor network (FTTN), which imports the thermal perturbation into\nthe matrix product states framework by placing all images in an environment\nwith constant temperature, in analog to energy-based learning. Tensor network\nis chosen since it is the best platform to introduce thermal fluctuation.\nDifferent from traditional network structure which directly takes the summation\nof individual losses as its loss function, FTTN regards it as thermal average\nloss computed from the entanglement with the environment. The temperature-like\nparameter can be automatically optimized, which gives each database an\nindividual temperature. FTTN obtains improvement in both test accuracy and\nconvergence speed in several datasets. The non-zero temperature automatically\nseparates similar features, avoiding the wrong classification in previous\narchitecture. The thermal fluctuation may give a better improvement in other\nframeworks, and we may also implement the temperature of database to improve\nthe training effect.\n", "versions": [{"version": "v1", "created": "Fri, 9 Apr 2021 05:02:36 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Lin", "Haoxiang", ""], ["Ye", "Shuqian", ""], ["Zhu", "Xi", ""]]}, {"id": "2104.05441", "submitter": "Marcus Kaiser", "authors": "Marcus Kaiser, Maksim Sipos", "title": "Unsuitability of NOTEARS for Causal Graph Discovery", "comments": "6 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Causal Discovery methods aim to identify a DAG structure that represents\ncausal relationships from observational data. In this article, we stress that\nit is important to test such methods for robustness in practical settings. As\nour main example, we analyze the NOTEARS method, for which we demonstrate a\nlack of scale-invariance. We show that NOTEARS is a method that aims to\nidentify a parsimonious DAG from the data that explains the residual variance.\nWe conclude that NOTEARS is not suitable for identifying truly causal\nrelationships from the data.\n", "versions": [{"version": "v1", "created": "Mon, 12 Apr 2021 13:09:10 GMT"}, {"version": "v2", "created": "Tue, 15 Jun 2021 10:38:53 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Kaiser", "Marcus", ""], ["Sipos", "Maksim", ""]]}, {"id": "2104.05442", "submitter": "Sudipan Saha", "authors": "Jakob Gawlikowski, Sudipan Saha, Anna Kruspe, Xiao Xiang Zhu", "title": "Out-of-distribution detection in satellite image classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In satellite image analysis, distributional mismatch between the training and\ntest data may arise due to several reasons, including unseen classes in the\ntest data and differences in the geographic area. Deep learning based models\nmay behave in unexpected manner when subjected to test data that has such\ndistributional shifts from the training data, also called out-of-distribution\n(OOD) examples. Predictive uncertainly analysis is an emerging research topic\nwhich has not been explored much in context of satellite image analysis.\nTowards this, we adopt a Dirichlet Prior Network based model to quantify\ndistributional uncertainty of deep learning models for remote sensing. The\napproach seeks to maximize the representation gap between the in-domain and OOD\nexamples for a better identification of unknown examples at test time.\nExperimental results on three exemplary test scenarios show the efficacy of the\nmodel in satellite image analysis.\n", "versions": [{"version": "v1", "created": "Fri, 9 Apr 2021 11:11:52 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Gawlikowski", "Jakob", ""], ["Saha", "Sudipan", ""], ["Kruspe", "Anna", ""], ["Zhu", "Xiao Xiang", ""]]}, {"id": "2104.05443", "submitter": "Sudipan Saha", "authors": "Sudipan Saha, Biplab Banerjee, Xiao Xiang Zhu", "title": "Trusting small training dataset for supervised change detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning (DL) based supervised change detection (CD) models require\nlarge labeled training data. Due to the difficulty of collecting labeled\nmulti-temporal data, unsupervised methods are preferred in the CD literature.\nHowever, unsupervised methods cannot fully exploit the potentials of\ndata-driven deep learning and thus they are not absolute alternative to the\nsupervised methods. This motivates us to look deeper into the supervised DL\nmethods and investigate how they can be adopted intelligently for CD by\nminimizing the requirement of labeled training data. Towards this, in this work\nwe show that geographically diverse training dataset can yield significant\nimprovement over less diverse training datasets of the same size. We propose a\nsimple confidence indicator for verifying the trustworthiness/confidence of\nsupervised models trained with small labeled dataset. Moreover, we show that\nfor the test cases where supervised CD model is found to be less\nconfident/trustworthy, unsupervised methods often produce better result than\nthe supervised ones.\n", "versions": [{"version": "v1", "created": "Fri, 9 Apr 2021 10:57:03 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Saha", "Sudipan", ""], ["Banerjee", "Biplab", ""], ["Zhu", "Xiao Xiang", ""]]}, {"id": "2104.05447", "submitter": "Hao Jin", "authors": "Guangzeng Xie, Hao Jin, Dachao Lin, Zhihua Zhang", "title": "Meta-Regularization: An Approach to Adaptive Choice of the Learning Rate\n  in Gradient Descent", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose \\textit{Meta-Regularization}, a novel approach for the adaptive\nchoice of the learning rate in first-order gradient descent methods. Our\napproach modifies the objective function by adding a regularization term on the\nlearning rate, and casts the joint updating process of parameters and learning\nrates into a maxmin problem. Given any regularization term, our approach\nfacilitates the generation of practical algorithms. When\n\\textit{Meta-Regularization} takes the $\\varphi$-divergence as a regularizer,\nthe resulting algorithms exhibit comparable theoretical convergence performance\nwith other first-order gradient-based algorithms. Furthermore, we theoretically\nprove that some well-designed regularizers can improve the convergence\nperformance under the strong-convexity condition of the objective function.\nNumerical experiments on benchmark problems demonstrate the effectiveness of\nalgorithms derived from some common $\\varphi$-divergence in full batch as well\nas online learning settings.\n", "versions": [{"version": "v1", "created": "Mon, 12 Apr 2021 13:13:34 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Xie", "Guangzeng", ""], ["Jin", "Hao", ""], ["Lin", "Dachao", ""], ["Zhang", "Zhihua", ""]]}, {"id": "2104.05448", "submitter": "Bing Zha", "authors": "Bing Zha, Alessandro Vanni, Yassin Hassan, Tunc Aldemir, Alper Yilmaz", "title": "Deep Transformer Networks for Time Series Classification: The NPP Safety\n  Case", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  A challenging part of dynamic probabilistic risk assessment for nuclear power\nplants is the need for large amounts of temporal simulations given various\ninitiating events and branching conditions from which representative feature\nextraction becomes complicated for subsequent applications. Artificial\nIntelligence techniques have been shown to be powerful tools in time-dependent\nsequential data processing to automatically extract and yield complex features\nfrom large data. An advanced temporal neural network referred to as the\nTransformer is used within a supervised learning fashion to model the\ntime-dependent NPP simulation data and to infer whether a given sequence of\nevents leads to core damage or not. The training and testing datasets for the\nTransformer are obtained by running 10,000 RELAP5-3D NPP blackout simulations\nwith the list of variables obtained from the RAVEN software. Each simulation is\nclassified as \"OK\" or \"CORE DAMAGE\" based on the consequence. The results show\nthat the Transformer can learn the characteristics of the sequential data and\nyield promising performance with approximately 99% classification accuracy on\nthe testing dataset.\n", "versions": [{"version": "v1", "created": "Fri, 9 Apr 2021 14:26:25 GMT"}, {"version": "v2", "created": "Sun, 18 Apr 2021 12:41:36 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Zha", "Bing", ""], ["Vanni", "Alessandro", ""], ["Hassan", "Yassin", ""], ["Aldemir", "Tunc", ""], ["Yilmaz", "Alper", ""]]}, {"id": "2104.05450", "submitter": "Thibaud Brochet", "authors": "Thibaud Brochet, Jerome Lapuyade-Lahorgue, Sebastien Bougleux, Mathieu\n  Salaun, Su Ruan", "title": "Deep learning using Havrda-Charvat entropy for classification of\n  pulmonary endomicroscopy", "comments": "8 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pulmonary optical endomicroscopy (POE) is an imaging technology in real time.\nIt allows to examine pulmonary alveoli at a microscopic level. Acquired in\nclinical settings, a POE image sequence can have as much as 25% of the sequence\nbeing uninformative frames (i.e. pure-noise and motion artefacts). For future\ndata analysis, these uninformative frames must be first removed from the\nsequence. Therefore, the objective of our work is to develop an automatic\ndetection method of uninformative images in endomicroscopy images. We propose\nto take the detection problem as a classification one. Considering advantages\nof deep learning methods, a classifier based on CNN (Convolutional Neural\nNetwork) is designed with a new loss function based on Havrda-Charvat entropy\nwhich is a parametrical generalization of the Shannon entropy. We propose to\nuse this formula to get a better hold on all sorts of data since it provides a\nmodel more stable than the Shannon entropy. Our method is tested on one POE\ndataset including 2947 distinct images, is showing better results than using\nShannon entropy and behaves better with regard to the problem of overfitting.\n  Keywords: Deep Learning, CNN, Shannon entropy, Havrda-Charvat entropy,\nPulmonary optical endomicroscopy.\n", "versions": [{"version": "v1", "created": "Mon, 12 Apr 2021 13:16:04 GMT"}, {"version": "v2", "created": "Tue, 13 Apr 2021 14:50:52 GMT"}, {"version": "v3", "created": "Mon, 19 Apr 2021 09:53:20 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Brochet", "Thibaud", ""], ["Lapuyade-Lahorgue", "Jerome", ""], ["Bougleux", "Sebastien", ""], ["Salaun", "Mathieu", ""], ["Ruan", "Su", ""]]}, {"id": "2104.05463", "submitter": "Xiaochen Zhang Mr.", "authors": "Xiaochen Zhang, Haitao Zhao, Jun Xiong, Li Zhou, Jibo Wei", "title": "Scalable Power Control/Beamforming in Heterogeneous Wireless Networks\n  with Graph Neural Networks", "comments": "6 pages, 6 figures, submitted to the IEEE for possible publication.\n  Copyright may be transferred without notice, after which this version may no\n  longer be accessible", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning (ML) has been widely used for efficient resource allocation\n(RA) in wireless networks. Although superb performance is achieved on small and\nsimple networks, most existing ML-based approaches are confronted with\ndifficulties when heterogeneity occurs and network size expands. In this paper,\nspecifically focusing on power control/beamforming (PC/BF) in heterogeneous\ndevice-to-device (D2D) networks, we propose a novel unsupervised learning-based\nframework named heterogeneous interference graph neural network (HIGNN) to\nhandle these challenges. First, we characterize diversified link features and\ninterference relations with heterogeneous graphs. Then, HIGNN is proposed to\nempower each link to obtain its individual transmission scheme after limited\ninformation exchange with neighboring links. It is noteworthy that HIGNN is\nscalable to wireless networks of growing sizes with robust performance after\ntrained on small-sized networks. Numerical results show that compared with\nstate-of-the-art benchmarks, HIGNN achieves much higher execution efficiency\nwhile providing strong performance.\n", "versions": [{"version": "v1", "created": "Mon, 12 Apr 2021 13:36:32 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Zhang", "Xiaochen", ""], ["Zhao", "Haitao", ""], ["Xiong", "Jun", ""], ["Zhou", "Li", ""], ["Wei", "Jibo", ""]]}, {"id": "2104.05467", "submitter": "Thibault Laugel", "authors": "Xavier Renard, Thibault Laugel, Marcin Detyniecki", "title": "Understanding Prediction Discrepancies in Machine Learning Classifiers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A multitude of classifiers can be trained on the same data to achieve similar\nperformances during test time, while having learned significantly different\nclassification patterns. This phenomenon, which we call prediction\ndiscrepancies, is often associated with the blind selection of one model\ninstead of another with similar performances. When making a choice, the machine\nlearning practitioner has no understanding on the differences between models,\ntheir limits, where they agree and where they don't. But his/her choice will\nresult in concrete consequences for instances to be classified in the\ndiscrepancy zone, since the final decision will be based on the selected\nclassification pattern. Besides the arbitrary nature of the result, a bad\nchoice could have further negative consequences such as loss of opportunity or\nlack of fairness. This paper proposes to address this question by analyzing the\nprediction discrepancies in a pool of best-performing models trained on the\nsame data. A model-agnostic algorithm, DIG, is proposed to capture and explain\ndiscrepancies locally, to enable the practitioner to make the best educated\ndecision when selecting a model by anticipating its potential undesired\nconsequences. All the code to reproduce the experiments is available.\n", "versions": [{"version": "v1", "created": "Mon, 12 Apr 2021 13:42:50 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Renard", "Xavier", ""], ["Laugel", "Thibault", ""], ["Detyniecki", "Marcin", ""]]}, {"id": "2104.05497", "submitter": "Marco A. Formoso", "authors": "Marco A. Formoso, Andr\\'es Ortiz, Francisco J. Mart\\'inez-Murcia,\n  Nicol\\'as Gallego-Molina, Juan L. Luque", "title": "Modelling Brain Connectivity Networks by Graph Embedding for Dyslexia\n  Diagnosis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Several methods have been developed to extract information from\nelectroencephalograms (EEG). One of them is Phase-Amplitude Coupling (PAC)\nwhich is a type of Cross-Frequency Coupling (CFC) method, consisting in measure\nthe synchronization of phase and amplitude for the different EEG bands and\nelectrodes. This provides information regarding brain areas that are\nsynchronously activated, and eventually, a marker of functional connectivity\nbetween these areas. In this work, intra and inter electrode PAC is computed\nobtaining the relationship among different electrodes used in EEG. The\nconnectivity information is then treated as a graph in which the different\nnodes are the electrodes and the edges PAC values between them. These\nstructures are embedded to create a feature vector that can be further used to\nclassify multichannel EEG samples. The proposed method has been applied to\nclassified EEG samples acquired using specific auditory stimuli in a task\ndesigned for dyslexia disorder diagnosis in seven years old children EEG's. The\nproposed method provides AUC values up to 0.73 and allows selecting the most\ndiscriminant electrodes and EEG bands.\n", "versions": [{"version": "v1", "created": "Mon, 12 Apr 2021 14:27:29 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Formoso", "Marco A.", ""], ["Ortiz", "Andr\u00e9s", ""], ["Mart\u00ednez-Murcia", "Francisco J.", ""], ["Gallego-Molina", "Nicol\u00e1s", ""], ["Luque", "Juan L.", ""]]}, {"id": "2104.05499", "submitter": "Danilo Comminiello", "authors": "Eric Guizzo, Riccardo F. Gramaccioni, Saeid Jamili, Christian\n  Marinoni, Edoardo Massaro, Claudia Medaglia, Giuseppe Nachira, Leonardo\n  Nucciarelli, Ludovica Paglialunga, Marco Pennese, Sveva Pepe, Enrico Rocchi,\n  Aurelio Uncini, Danilo Comminiello", "title": "L3DAS21 Challenge: Machine Learning for 3D Audio Signal Processing", "comments": "Documentation paper for the L3DAS21 Challenge for IEEE MLSP 2021.\n  Further information on www.l3das.com/mlsp2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD eess.SP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The L3DAS21 Challenge is aimed at encouraging and fostering collaborative\nresearch on machine learning for 3D audio signal processing, with particular\nfocus on 3D speech enhancement (SE) and 3D sound localization and detection\n(SELD). Alongside with the challenge, we release the L3DAS21 dataset, a 65\nhours 3D audio corpus, accompanied with a Python API that facilitates the data\nusage and results submission stage. Usually, machine learning approaches to 3D\naudio tasks are based on single-perspective Ambisonics recordings or on arrays\nof single-capsule microphones. We propose, instead, a novel multichannel audio\nconfiguration based multiple-source and multiple-perspective Ambisonics\nrecordings, performed with an array of two first-order Ambisonics microphones.\nTo the best of our knowledge, it is the first time that a dual-mic Ambisonics\nconfiguration is used for these tasks. We provide baseline models and results\nfor both tasks, obtained with state-of-the-art architectures: FaSNet for SE and\nSELDNet for SELD. This report is aimed at providing all needed information to\nparticipate in the L3DAS21 Challenge, illustrating the details of the L3DAS21\ndataset, the challenge tasks and the baseline models.\n", "versions": [{"version": "v1", "created": "Mon, 12 Apr 2021 14:29:54 GMT"}, {"version": "v2", "created": "Thu, 22 Apr 2021 16:11:26 GMT"}, {"version": "v3", "created": "Thu, 29 Apr 2021 18:18:30 GMT"}], "update_date": "2021-05-03", "authors_parsed": [["Guizzo", "Eric", ""], ["Gramaccioni", "Riccardo F.", ""], ["Jamili", "Saeid", ""], ["Marinoni", "Christian", ""], ["Massaro", "Edoardo", ""], ["Medaglia", "Claudia", ""], ["Nachira", "Giuseppe", ""], ["Nucciarelli", "Leonardo", ""], ["Paglialunga", "Ludovica", ""], ["Pennese", "Marco", ""], ["Pepe", "Sveva", ""], ["Rocchi", "Enrico", ""], ["Uncini", "Aurelio", ""], ["Comminiello", "Danilo", ""]]}, {"id": "2104.05500", "submitter": "Arseny Moskvichev", "authors": "Arseny Moskvichev, James A. Liu", "title": "Updater-Extractor Architecture for Inductive World State Representations", "comments": "15 pages (12 main content, 3 references and appendix), 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Developing NLP models traditionally involves two stages - training and\napplication. Retention of information acquired after training (at application\ntime) is architecturally limited by the size of the model's context window (in\nthe case of transformers), or by the practical difficulties associated with\nlong sequences (in the case of RNNs). In this paper, we propose a novel\ntransformer-based Updater-Extractor architecture and a training procedure that\ncan work with sequences of arbitrary length and refine its knowledge about the\nworld based on linguistic inputs. We explicitly train the model to incorporate\nincoming information into its world state representation, obtaining strong\ninductive generalization and the ability to handle extremely long-range\ndependencies. We prove a lemma that provides a theoretical basis for our\napproach. The result also provides insight into success and failure modes of\nmodels trained with variants of Truncated Back-Propagation Through Time (such\nas Transformer XL). Empirically, we investigate the model performance on three\ndifferent tasks, demonstrating its promise. This preprint is still a work in\nprogress. At present, we focused on easily interpretable tasks, leaving the\napplication of the proposed ideas to practical NLP applications for the future.\n", "versions": [{"version": "v1", "created": "Mon, 12 Apr 2021 14:30:11 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Moskvichev", "Arseny", ""], ["Liu", "James A.", ""]]}, {"id": "2104.05508", "submitter": "Grzegorz G{\\l}uch", "authors": "Grzegorz G{\\l}uch, R\\\"udiger Urbanke", "title": "Noether: The More Things Change, the More Stay the Same", "comments": "35 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Symmetries have proven to be important ingredients in the analysis of neural\nnetworks. So far their use has mostly been implicit or seemingly coincidental.\n  We undertake a systematic study of the role that symmetry plays. In\nparticular, we clarify how symmetry interacts with the learning algorithm. The\nkey ingredient in our study is played by Noether's celebrated theorem which,\ninformally speaking, states that symmetry leads to conserved quantities (e.g.,\nconservation of energy or conservation of momentum). In the realm of neural\nnetworks under gradient descent, model symmetries imply restrictions on the\ngradient path. E.g., we show that symmetry of activation functions leads to\nboundedness of weight matrices, for the specific case of linear activations it\nleads to balance equations of consecutive layers, data augmentation leads to\ngradient paths that have \"momentum\"-type restrictions, and time symmetry leads\nto a version of the Neural Tangent Kernel.\n  Symmetry alone does not specify the optimization path, but the more\nsymmetries are contained in the model the more restrictions are imposed on the\npath. Since symmetry also implies over-parametrization, this in effect implies\nthat some part of this over-parametrization is cancelled out by the existence\nof the conserved quantities.\n  Symmetry can therefore be thought of as one further important tool in\nunderstanding the performance of neural networks under gradient descent.\n", "versions": [{"version": "v1", "created": "Mon, 12 Apr 2021 14:41:05 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["G\u0142uch", "Grzegorz", ""], ["Urbanke", "R\u00fcdiger", ""]]}, {"id": "2104.05509", "submitter": "Abdullatif Albaseer Mr", "authors": "Abdullatif Albaseer, Mohamed Abdallah, Ala Al-Fuqaha, and Aiman Erbad", "title": "Threshold-Based Data Exclusion Approach for Energy-Efficient Federated\n  Edge Learning", "comments": "accepted to IEEE ICC 2021 WS", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated edge learning (FEEL) is a promising distributed learning technique\nfor next-generation wireless networks. FEEL preserves the user's privacy,\nreduces the communication costs, and exploits the unprecedented capabilities of\nedge devices to train a shared global model by leveraging a massive amount of\ndata generated at the network edge. However, FEEL might significantly shorten\nenergy-constrained participating devices' lifetime due to the power consumed\nduring the model training round. This paper proposes a novel approach that\nendeavors to minimize computation and communication energy consumption during\nFEEL rounds to address this issue. First, we introduce a modified local\ntraining algorithm that intelligently selects only the samples that enhance the\nmodel's quality based on a predetermined threshold probability. Then, the\nproblem is formulated as joint energy minimization and resource allocation\noptimization problem to obtain the optimal local computation time and the\noptimal transmission time that minimize the total energy consumption\nconsidering the worker's energy budget, available bandwidth, channel states,\nbeamforming, and local CPU speed. After that, we introduce a tractable solution\nto the formulated problem that ensures the robustness of FEEL. Our simulation\nresults show that our solution substantially outperforms the baseline FEEL\nalgorithm as it reduces the local consumed energy by up to 79%.\n", "versions": [{"version": "v1", "created": "Tue, 30 Mar 2021 13:34:40 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Albaseer", "Abdullatif", ""], ["Abdallah", "Mohamed", ""], ["Al-Fuqaha", "Ala", ""], ["Erbad", "Aiman", ""]]}, {"id": "2104.05512", "submitter": "Lu Lu", "authors": "Lu Lu, Haiyang He, Priya Kasimbeg, Rishikesh Ranade, Jay Pathak", "title": "One-shot learning for solution operators of partial differential\n  equations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG physics.comp-ph", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Discovering governing equations of a physical system, represented by partial\ndifferential equations (PDEs), from data is a central challenge in a variety of\nareas of science and engineering. Current methods require either some prior\nknowledge (e.g., candidate PDE terms) to discover the PDE form, or a large\ndataset to learn a surrogate model of the PDE solution operator. Here, we\npropose the first learning method that only needs one PDE solution, i.e.,\none-shot learning. We first decompose the entire computational domain into\nsmall domains, where we learn a local solution operator, and then find the\ncoupled solution via a fixed-point iteration. We demonstrate the effectiveness\nof our method on different PDEs, and our method exhibits a strong\ngeneralization property.\n", "versions": [{"version": "v1", "created": "Tue, 6 Apr 2021 17:35:10 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Lu", "Lu", ""], ["He", "Haiyang", ""], ["Kasimbeg", "Priya", ""], ["Ranade", "Rishikesh", ""], ["Pathak", "Jay", ""]]}, {"id": "2104.05522", "submitter": "Kin Gutierrez Olivares", "authors": "Kin G. Olivares and Cristian Challu and Grzegorz Marcjasz and Rafa{\\l}\n  Weron and Artur Dubrawski", "title": "Neural basis expansion analysis with exogenous variables: Forecasting\n  electricity prices with NBEATSx", "comments": "30 pages, 7 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We extend the neural basis expansion analysis (NBEATS) to incorporate\nexogenous factors. The resulting method, called NBEATSx, improves on a well\nperforming deep learning model, extending its capabilities by including\nexogenous variables and allowing it to integrate multiple sources of useful\ninformation. To showcase the utility of the NBEATSx model, we conduct a\ncomprehensive study of its application to electricity price forecasting (EPF)\ntasks across a broad range of years and markets. We observe state-of-the-art\nperformance, significantly improving the forecast accuracy by nearly 20% over\nthe original NBEATS model, and by up to 5% over other well established\nstatistical and machine learning methods specialized for these tasks.\nAdditionally, the proposed neural network has an interpretable configuration\nthat can structurally decompose time series, visualizing the relative impact of\ntrend and seasonal components and revealing the modeled processes' interactions\nwith exogenous factors. To assist related work we made the code available in\nhttps://github.com/cchallu/nbeatsx.\n", "versions": [{"version": "v1", "created": "Mon, 12 Apr 2021 14:47:55 GMT"}, {"version": "v2", "created": "Tue, 13 Apr 2021 14:36:36 GMT"}, {"version": "v3", "created": "Wed, 21 Apr 2021 20:38:24 GMT"}, {"version": "v4", "created": "Fri, 23 Apr 2021 12:48:00 GMT"}], "update_date": "2021-04-26", "authors_parsed": [["Olivares", "Kin G.", ""], ["Challu", "Cristian", ""], ["Marcjasz", "Grzegorz", ""], ["Weron", "Rafa\u0142", ""], ["Dubrawski", "Artur", ""]]}, {"id": "2104.05528", "submitter": "Robin Walters", "authors": "Steven Wong, Lejun Jiang, Robin Walters, Tam\\'as G. Moln\\'ar, G\\'abor\n  Orosz, Rose Yu", "title": "Traffic Forecasting using Vehicle-to-Vehicle Communication", "comments": "13 pages, 3rd Annual Conference on Learning for Dynamics and Control\n  2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We take the first step in using vehicle-to-vehicle (V2V) communication to\nprovide real-time on-board traffic predictions. In order to best utilize\nreal-world V2V communication data, we integrate first principle models with\ndeep learning. Specifically, we train recurrent neural networks to improve the\npredictions given by first principle models. Our approach is able to predict\nthe velocity of individual vehicles up to a minute into the future with\nimproved accuracy over first principle-based baselines. We conduct a\ncomprehensive study to evaluate different methods of integrating first\nprinciple models with deep learning techniques. The source code for our models\nis available at https://github.com/Rose-STL-Lab/V2V-traffic-forecast .\n", "versions": [{"version": "v1", "created": "Mon, 12 Apr 2021 14:56:11 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Wong", "Steven", ""], ["Jiang", "Lejun", ""], ["Walters", "Robin", ""], ["Moln\u00e1r", "Tam\u00e1s G.", ""], ["Orosz", "G\u00e1bor", ""], ["Yu", "Rose", ""]]}, {"id": "2104.05541", "submitter": "Jiaqi Zhang", "authors": "Jiaqi Zhang, Xiangru Chen, Sandip Ray", "title": "Optimizing the Whole-life Cost in End-to-end CNN Acceleration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The acceleration of CNNs has gained increasing atten-tion since their success\nin computer vision. With the heterogeneous functional layers that cannot be\npro-cessed by the accelerators proposed for convolution layers only, modern\nend-to-end CNN acceleration so-lutions either transform the diverse computation\ninto matrix/vector arithmetic, which loses data reuse op-portunities in\nconvolution, or introduce dedicated functional unit to each kind of layer,\nwhich results in underutilization and high update expense. To enhance the\nwhole-life cost efficiency, we need an acceleration solution that is efficient\nin processing CNN layers and has the generality to apply to all kinds of\nexisting and emerging layers. To this end, we pro-pose GCONV Chain, a method to\nconvert the entire CNN computation into a chain of standard general\nconvolutions (GCONV) that can be efficiently pro-cessed by the existing CNN\naccelerators. This paper comprehensively analyzes the GCONV Chain model and\nproposes a full-stack implementation to support GCONV Chain. On one hand, the\nresults on seven var-ious CNNs demonstrate that GCONV Chain improves the\nperformance and energy efficiency of existing CNN accelerators by an average of\n3.4x and 3.2x re-spectively. On the other hand, we show that GCONV Chain\nprovides low whole-life costs for CNN accelera-tion, including both developer\nefforts and total cost of ownership for the users.\n", "versions": [{"version": "v1", "created": "Mon, 12 Apr 2021 15:12:42 GMT"}, {"version": "v2", "created": "Thu, 22 Jul 2021 00:46:39 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Zhang", "Jiaqi", ""], ["Chen", "Xiangru", ""], ["Ray", "Sandip", ""]]}, {"id": "2104.05554", "submitter": "Junwhan Kim", "authors": "Kihoon Jang, Junwhan Kim, Byunggu Yu", "title": "On Analyzing Churn Prediction in Mobile Games", "comments": "8 pages, 10 figures, 2021 6th International Conference on Machine\n  Learning Technologies", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In subscription-based businesses, the churn rate refers to the percentage of\ncustomers who discontinue their subscriptions within a given time period.\nParticularly, in the mobile games industry, the churn rate is often pronounced\ndue to the high competition and cost in customer acquisition; therefore, the\nprocess of minimizing the churn rate is crucial. This needs churn prediction,\npredicting users who will be churning within a given time period. Accurate\nchurn prediction can enable the businesses to devise and engage strategic\nremediations to maintain a low churn rate. The paper presents our highly\naccurate churn prediction method. We designed this method to take into account\neach individual user's distinct usage period in churn prediction. As presented\nin the paper, this approach was able to achieve 96.6% churn prediction accuracy\non a real game business. In addition, the paper shows that other existing churn\nprediction algorithms are improved in prediction accuracy when this method is\napplied.\n", "versions": [{"version": "v1", "created": "Mon, 12 Apr 2021 15:22:42 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Jang", "Kihoon", ""], ["Kim", "Junwhan", ""], ["Yu", "Byunggu", ""]]}, {"id": "2104.05565", "submitter": "Victor Uc-Cetina", "authors": "Victor Uc-Cetina, Nicolas Navarro-Guerrero, Anabel Martin-Gonzalez,\n  Cornelius Weber, Stefan Wermter", "title": "Survey on reinforcement learning for language processing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In recent years some researchers have explored the use of reinforcement\nlearning (RL) algorithms as key components in the solution of various natural\nlanguage processing tasks. For instance, some of these algorithms leveraging\ndeep neural learning have found their way into conversational systems. This\npaper reviews the state of the art of RL methods for their possible use for\ndifferent problems of natural language processing, focusing primarily on\nconversational systems, mainly due to their growing relevance. We provide\ndetailed descriptions of the problems as well as discussions of why RL is\nwell-suited to solve them. Also, we analyze the advantages and limitations of\nthese methods. Finally, we elaborate on promising research directions in\nnatural language processing that might benefit from reinforcement learning.\n", "versions": [{"version": "v1", "created": "Mon, 12 Apr 2021 15:33:11 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Uc-Cetina", "Victor", ""], ["Navarro-Guerrero", "Nicolas", ""], ["Martin-Gonzalez", "Anabel", ""], ["Weber", "Cornelius", ""], ["Wermter", "Stefan", ""]]}, {"id": "2104.05569", "submitter": "Tao Lin", "authors": "Tao Lin", "title": "Deep Learning for IoT", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deep learning and other machine learning approaches are deployed to many\nsystems related to Internet of Things or IoT. However, it faces challenges that\nadversaries can take loopholes to hack these systems through tampering history\ndata. This paper first presents overall points of adversarial machine learning.\nThen, we illustrate traditional methods, such as Petri Net cannot solve this\nnew question efficiently. To help IoT data analysis more efficient, we propose\na retrieval method based on deep learning (recurrent neural network). Besides,\nthis paper presents a research on data retrieval solution to avoid hacking by\nadversaries in the fields of adversary machine leaning. It further directs the\nnew approaches in terms of how to implementing this framework in IoT settings\nbased on adversarial deep learning.\n", "versions": [{"version": "v1", "created": "Mon, 12 Apr 2021 15:39:30 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Lin", "Tao", ""]]}, {"id": "2104.05571", "submitter": "Junwhan Kim", "authors": "Byunggu Yu, Junwhan Kim", "title": "Using a Neural Network to Detect Anomalies given an N-gram Profile", "comments": "17 pages, 7 figures, 5th International Symposium on Cyber Security\n  Cryptology and Machine Learning (CSCML 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to detect unknown intrusions and runtime errors of computer\nprograms, the cyber-security community has developed various detection\ntechniques. Anomaly detection is an approach that is designed to profile the\nnormal runtime behavior of computer programs in order to detect intrusions and\nerrors as anomalous deviations from the observed normal. However, normal but\nunobserved behavior can trigger false positives. This limitation has\nsignificantly decreased the practical viability of anomaly detection\ntechniques. Reported approaches to this limitation span a simple alert\nthreshold definition to distribution models for approximating all normal\nbehavior based on the limited observation. However, each assumption or\napproximation poses the potential for even greater false positive rates. This\npaper presents our study on how to explain the presence of anomalies using a\nneural network, particularly Long Short-Term Memory, independent of actual data\ndistributions. We present and compare three anomaly detection models, and\nreport on our experience running different types of attacks on an Apache\nHypertext Transfer Protocol server. We performed a comparative study, focusing\non each model's ability to detect the onset of each attack while avoiding false\npositives resulting from unknown normal behavior. Our best-performing model\ndetected the true onset of every attack with zero false positives.\n", "versions": [{"version": "v1", "created": "Mon, 12 Apr 2021 15:40:43 GMT"}, {"version": "v2", "created": "Tue, 1 Jun 2021 23:55:51 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Yu", "Byunggu", ""], ["Kim", "Junwhan", ""]]}, {"id": "2104.05588", "submitter": "Daniel Coquelin", "authors": "Daniel Coquelin, Charlotte Debus, Markus G\\\"otz, Fabrice von der Lehr,\n  James Kahn, Martin Siggel, and Achim Streit", "title": "Accelerating Neural Network Training with Distributed Asynchronous and\n  Selective Optimization (DASO)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  With increasing data and model complexities, the time required to train\nneural networks has become prohibitively large. To address the exponential rise\nin training time, users are turning to data parallel neural networks (DPNN) to\nutilize large-scale distributed resources on computer clusters. Current DPNN\napproaches implement the network parameter updates by synchronizing and\naveraging gradients across all processes with blocking communication\noperations. This synchronization is the central algorithmic bottleneck. To\ncombat this, we introduce the Distributed Asynchronous and Selective\nOptimization (DASO) method which leverages multi-GPU compute node architectures\nto accelerate network training. DASO uses a hierarchical and asynchronous\ncommunication scheme comprised of node-local and global networks while\nadjusting the global synchronization rate during the learning process. We show\nthat DASO yields a reduction in training time of up to 34% on classical and\nstate-of-the-art networks, as compared to other existing data parallel training\nmethods.\n", "versions": [{"version": "v1", "created": "Mon, 12 Apr 2021 16:02:20 GMT"}, {"version": "v2", "created": "Thu, 15 Apr 2021 09:37:04 GMT"}], "update_date": "2021-04-16", "authors_parsed": [["Coquelin", "Daniel", ""], ["Debus", "Charlotte", ""], ["G\u00f6tz", "Markus", ""], ["von der Lehr", "Fabrice", ""], ["Kahn", "James", ""], ["Siggel", "Martin", ""], ["Streit", "Achim", ""]]}, {"id": "2104.05592", "submitter": "Philip Naumann", "authors": "Philip Naumann and Eirini Ntoutsi", "title": "Consequence-aware Sequential Counterfactual Generation", "comments": "16 pages, 6 figures, Accepted for publication in the research track\n  at ECML-PKDD 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Counterfactuals have become a popular technique nowadays for interacting with\nblack-box machine learning models and understanding how to change a particular\ninstance to obtain a desired outcome from the model. However, most existing\napproaches assume instant materialization of these changes, ignoring that they\nmay require effort and a specific order of application. Recently, methods have\nbeen proposed that also consider the order in which actions are applied,\nleading to the so-called sequential counterfactual generation problem.\n  In this work, we propose a model-agnostic method for sequential\ncounterfactual generation. We formulate the task as a multi-objective\noptimization problem and present a genetic algorithm approach to find optimal\nsequences of actions leading to the counterfactuals. Our cost model considers\nnot only the direct effect of an action, but also its consequences.\nExperimental results show that compared to state-of-the-art, our approach\ngenerates less costly solutions, is more efficient and provides the user with a\ndiverse set of solutions to choose from.\n", "versions": [{"version": "v1", "created": "Mon, 12 Apr 2021 16:10:03 GMT"}, {"version": "v2", "created": "Fri, 2 Jul 2021 15:41:39 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Naumann", "Philip", ""], ["Ntoutsi", "Eirini", ""]]}, {"id": "2104.05600", "submitter": "Seong Jae Hwang", "authors": "Anthony Sicilia, Xingchen Zhao, Anastasia Sosnovskikh, Seong Jae Hwang", "title": "PAC Bayesian Performance Guarantees for Deep (Stochastic) Networks in\n  Medical Imaging", "comments": "MICCAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Application of deep neural networks to medical imaging tasks has in some\nsense become commonplace. Still, a \"thorn in the side\" of the deep learning\nmovement is the argument that deep networks are prone to overfitting and are\nthus unable to generalize well when datasets are small (as is common in medical\nimaging tasks). One way to bolster confidence is to provide mathematical\nguarantees, or bounds, on network performance after training which explicitly\nquantify the possibility of overfitting. In this work, we explore recent\nadvances using the PAC-Bayesian framework to provide bounds on generalization\nerror for large (stochastic) networks. While previous efforts focus on\nclassification in larger natural image datasets (e.g., MNIST and CIFAR-10), we\napply these techniques to both classification and segmentation in a smaller\nmedical imagining dataset: the ISIC 2018 challenge set. We observe the\nresultant bounds are competitive compared to a simpler baseline, while also\nbeing more explainable and alleviating the need for holdout sets.\n", "versions": [{"version": "v1", "created": "Mon, 12 Apr 2021 16:21:07 GMT"}, {"version": "v2", "created": "Thu, 8 Jul 2021 21:26:29 GMT"}], "update_date": "2021-07-12", "authors_parsed": [["Sicilia", "Anthony", ""], ["Zhao", "Xingchen", ""], ["Sosnovskikh", "Anastasia", ""], ["Hwang", "Seong Jae", ""]]}, {"id": "2104.05605", "submitter": "Yogesh Balaji", "authors": "Yogesh Balaji, Mohammadmahdi Sajedi, Neha Mukund Kalibhat, Mucong\n  Ding, Dominik St\\\"oger, Mahdi Soltanolkotabi, Soheil Feizi", "title": "Understanding Overparameterization in Generative Adversarial Networks", "comments": "Accepted in ICLR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A broad class of unsupervised deep learning methods such as Generative\nAdversarial Networks (GANs) involve training of overparameterized models where\nthe number of parameters of the model exceeds a certain threshold. A large body\nof work in supervised learning have shown the importance of model\noverparameterization in the convergence of the gradient descent (GD) to\nglobally optimal solutions. In contrast, the unsupervised setting and GANs in\nparticular involve non-convex concave mini-max optimization problems that are\noften trained using Gradient Descent/Ascent (GDA). The role and benefits of\nmodel overparameterization in the convergence of GDA to a global saddle point\nin non-convex concave problems is far less understood. In this work, we present\na comprehensive analysis of the importance of model overparameterization in\nGANs both theoretically and empirically. We theoretically show that in an\noverparameterized GAN model with a $1$-layer neural network generator and a\nlinear discriminator, GDA converges to a global saddle point of the underlying\nnon-convex concave min-max problem. To the best of our knowledge, this is the\nfirst result for global convergence of GDA in such settings. Our theory is\nbased on a more general result that holds for a broader class of nonlinear\ngenerators and discriminators that obey certain assumptions (including deeper\ngenerators and random feature discriminators). We also empirically study the\nrole of model overparameterization in GANs using several large-scale\nexperiments on CIFAR-10 and Celeb-A datasets. Our experiments show that\noverparameterization improves the quality of generated samples across various\nmodel architectures and datasets. Remarkably, we observe that\noverparameterization leads to faster and more stable convergence behavior of\nGDA across the board.\n", "versions": [{"version": "v1", "created": "Mon, 12 Apr 2021 16:23:37 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Balaji", "Yogesh", ""], ["Sajedi", "Mohammadmahdi", ""], ["Kalibhat", "Neha Mukund", ""], ["Ding", "Mucong", ""], ["St\u00f6ger", "Dominik", ""], ["Soltanolkotabi", "Mahdi", ""], ["Feizi", "Soheil", ""]]}, {"id": "2104.05608", "submitter": "Chen Cai", "authors": "Chen Cai, Nikolaos Vlassis, Lucas Magee, Ran Ma, Zeyu Xiong, Bahador\n  Bahmani, Teng-Fong Wong, Yusu Wang, WaiChing Sun", "title": "Equivariant geometric learning for digital rock physics: estimating\n  formation factor and effective permeability tensors from Morse graph", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present a SE(3)-equivariant graph neural network (GNN) approach that\ndirectly predicting the formation factor and effective permeability from\nmicro-CT images. FFT solvers are established to compute both the formation\nfactor and effective permeability, while the topology and geometry of the pore\nspace are represented by a persistence-based Morse graph. Together, they\nconstitute the database for training, validating, and testing the neural\nnetworks. While the graph and Euclidean convolutional approaches both employ\nneural networks to generate low-dimensional latent space to represent the\nfeatures of the micro-structures for forward predictions, the SE(3) equivariant\nneural network is found to generate more accurate predictions, especially when\nthe training data is limited. Numerical experiments have also shown that the\nnew SE(3) approach leads to predictions that fulfill the material frame\nindifference whereas the predictions from classical convolutional neural\nnetworks (CNN) may suffer from spurious dependence on the coordinate system of\nthe training data. Comparisons among predictions inferred from training the CNN\nand those from graph convolutional neural networks (GNN) with and without the\nequivariant constraint indicate that the equivariant graph neural network seems\nto perform better than the CNN and GNN without enforcing equivariant\nconstraints.\n", "versions": [{"version": "v1", "created": "Mon, 12 Apr 2021 16:28:25 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Cai", "Chen", ""], ["Vlassis", "Nikolaos", ""], ["Magee", "Lucas", ""], ["Ma", "Ran", ""], ["Xiong", "Zeyu", ""], ["Bahmani", "Bahador", ""], ["Wong", "Teng-Fong", ""], ["Wang", "Yusu", ""], ["Sun", "WaiChing", ""]]}, {"id": "2104.05610", "submitter": "Daan Klijn", "authors": "Daan Klijn, A.E. Eiben", "title": "A coevolutionary approach to deep multi-agent reinforcement learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditionally, Deep Artificial Neural Networks (DNN's) are trained through\ngradient descent. Recent research shows that Deep Neuroevolution (DNE) is also\ncapable of evolving multi-million-parameter DNN's, which proved to be\nparticularly useful in the field of Reinforcement Learning (RL). This is mainly\ndue to its excellent scalability and simplicity compared to the traditional\nMDP-based RL methods. So far, DNE has only been applied to complex single-agent\nproblems. As evolutionary methods are a natural choice for multi-agent\nproblems, the question arises whether DNE can also be applied in a complex\nmulti-agent setting. In this paper, we describe and validate a new approach\nbased on Coevolution. To validate our approach, we benchmark two Deep\nCoevolutionary Algorithms on a range of multi-agent Atari games and compare our\nresults against the results of Ape-X DQN. Our results show that these Deep\nCoevolutionary algorithms (1) can be successfully trained to play various\ngames, (2) outperform Ape-X DQN in some of them, and therefore (3) show that\nCoevolution can be a viable approach to solving complex multi-agent\ndecision-making problems.\n", "versions": [{"version": "v1", "created": "Mon, 12 Apr 2021 16:30:03 GMT"}, {"version": "v2", "created": "Tue, 13 Apr 2021 10:07:16 GMT"}], "update_date": "2021-04-14", "authors_parsed": [["Klijn", "Daan", ""], ["Eiben", "A. E.", ""]]}, {"id": "2104.05613", "submitter": "Tan Zhu", "authors": "Tan Zhu, Guannan Liang, Chunjiang Zhu, Haining Li, Jinbo Bi", "title": "An Efficient Algorithm for Deep Stochastic Contextual Bandits", "comments": "Accepted by AAAI 2021 Appendix uploaded", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In stochastic contextual bandit (SCB) problems, an agent selects an action\nbased on certain observed context to maximize the cumulative reward over\niterations. Recently there have been a few studies using a deep neural network\n(DNN) to predict the expected reward for an action, and the DNN is trained by a\nstochastic gradient based method. However, convergence analysis has been\ngreatly ignored to examine whether and where these methods converge. In this\nwork, we formulate the SCB that uses a DNN reward function as a non-convex\nstochastic optimization problem, and design a stage-wise stochastic gradient\ndescent algorithm to optimize the problem and determine the action policy. We\nprove that with high probability, the action sequence chosen by this algorithm\nconverges to a greedy action policy respecting a local optimal reward function.\nExtensive experiments have been performed to demonstrate the effectiveness and\nefficiency of the proposed algorithm on multiple real-world datasets.\n", "versions": [{"version": "v1", "created": "Mon, 12 Apr 2021 16:34:43 GMT"}, {"version": "v2", "created": "Thu, 22 Apr 2021 00:46:50 GMT"}], "update_date": "2021-04-23", "authors_parsed": [["Zhu", "Tan", ""], ["Liang", "Guannan", ""], ["Zhu", "Chunjiang", ""], ["Li", "Haining", ""], ["Bi", "Jinbo", ""]]}, {"id": "2104.05628", "submitter": "Maciej Skorski", "authors": "Maciej Skorski", "title": "Confidence-Optimal Random Embeddings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The seminal result of Johnson and Lindenstrauss on random embeddings has been\nintensively studied in applied and theoretical computer science. Despite that\nvast body of literature, we still lack of complete understanding of statistical\nproperties of random projections; a particularly intriguing question is: why\nare the theoretical bounds that far behind the empirically observed\nperformance? Motivated by this question, this work develops\nJohnson-Lindenstrauss distributions with optimal, data-oblivious, statistical\nconfidence bounds. These bounds are numerically best possible, for any given\ndata dimension, embedding dimension, and distortion tolerance. They improve\nupon prior works in terms of statistical accuracy, as well as exactly determine\nthe no-go regimes for data-oblivious approaches. Furthermore, the corresponding\nprojection matrices are efficiently samplable. The construction relies on\northogonal matrices, and the proof uses certain elegant properties of the unit\nsphere. The following techniques introduced in this work are of independent\ninterest: a) a compact expression for distortion in terms of singular\neigenvalues of the projection matrix, b) a parametrization linking the unit\nsphere and the Dirichlet distribution and c) anti-concentration bounds for the\nDirichlet distribution.\n  Besides the technical contribution, the paper presents applications and\nnumerical evaluation along with working implementation in Python.\n", "versions": [{"version": "v1", "created": "Tue, 6 Apr 2021 18:00:02 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Skorski", "Maciej", ""]]}, {"id": "2104.05632", "submitter": "Philip Ball", "authors": "Philip J. Ball, Cong Lu, Jack Parker-Holder, Stephen Roberts", "title": "Augmented World Models Facilitate Zero-Shot Dynamics Generalization From\n  a Single Offline Environment", "comments": "Accepted @ ICML 2021; Spotlight @ ICLR 2021 \"Self-Supervision for\n  Reinforcement Learning Workshop\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Reinforcement learning from large-scale offline datasets provides us with the\nability to learn policies without potentially unsafe or impractical\nexploration. Significant progress has been made in the past few years in\ndealing with the challenge of correcting for differing behavior between the\ndata collection and learned policies. However, little attention has been paid\nto potentially changing dynamics when transferring a policy to the online\nsetting, where performance can be up to 90% reduced for existing methods. In\nthis paper we address this problem with Augmented World Models (AugWM). We\naugment a learned dynamics model with simple transformations that seek to\ncapture potential changes in physical properties of the robot, leading to more\nrobust policies. We not only train our policy in this new setting, but also\nprovide it with the sampled augmentation as a context, allowing it to adapt to\nchanges in the environment. At test time we learn the context in a\nself-supervised fashion by approximating the augmentation which corresponds to\nthe new environment. We rigorously evaluate our approach on over 100 different\nchanged dynamics settings, and show that this simple approach can significantly\nimprove the zero-shot generalization of a recent state-of-the-art baseline,\noften achieving successful policies where the baseline fails.\n", "versions": [{"version": "v1", "created": "Mon, 12 Apr 2021 16:53:55 GMT"}, {"version": "v2", "created": "Sat, 12 Jun 2021 16:51:52 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Ball", "Philip J.", ""], ["Lu", "Cong", ""], ["Parker-Holder", "Jack", ""], ["Roberts", "Stephen", ""]]}, {"id": "2104.05641", "submitter": "Matus Telgarsky", "authors": "Daniel Hsu and Ziwei Ji and Matus Telgarsky and Lan Wang", "title": "Generalization bounds via distillation", "comments": "To appear, ICLR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper theoretically investigates the following empirical phenomenon:\ngiven a high-complexity network with poor generalization bounds, one can\ndistill it into a network with nearly identical predictions but low complexity\nand vastly smaller generalization bounds. The main contribution is an analysis\nshowing that the original network inherits this good generalization bound from\nits distillation, assuming the use of well-behaved data augmentation. This\nbound is presented both in an abstract and in a concrete form, the latter\ncomplemented by a reduction technique to handle modern computation graphs\nfeaturing convolutional layers, fully-connected layers, and skip connections,\nto name a few. To round out the story, a (looser) classical uniform convergence\nanalysis of compression is also presented, as well as a variety of experiments\non cifar and mnist demonstrating similar generalization performance between the\noriginal network and its distillation.\n", "versions": [{"version": "v1", "created": "Mon, 12 Apr 2021 17:03:13 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Hsu", "Daniel", ""], ["Ji", "Ziwei", ""], ["Telgarsky", "Matus", ""], ["Wang", "Lan", ""]]}, {"id": "2104.05647", "submitter": "Jordan J. Bird", "authors": "Jordan J. Bird, Chloe M. Barnes, Luis J. Manso, Anik\\'o Ek\\'art, Diego\n  R. Faria", "title": "Fruit Quality and Defect Image Classification with Conditional GAN Data\n  Augmentation", "comments": "16 pages, 12 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Contemporary Artificial Intelligence technologies allow for the employment of\nComputer Vision to discern good crops from bad, providing a step in the\npipeline of selecting healthy fruit from undesirable fruit, such as those which\nare mouldy or gangrenous. State-of-the-art works in the field report high\naccuracy results on small datasets (<1000 images), which are not representative\nof the population regarding real-world usage. The goals of this study are to\nfurther enable real-world usage by improving generalisation with data\naugmentation as well as to reduce overfitting and energy usage through model\npruning. In this work, we suggest a machine learning pipeline that combines the\nideas of fine-tuning, transfer learning, and generative model-based training\ndata augmentation towards improving fruit quality image classification. A\nlinear network topology search is performed to tune a VGG16 lemon quality\nclassification model using a publicly-available dataset of 2690 images. We find\nthat appending a 4096 neuron fully connected layer to the convolutional layers\nleads to an image classification accuracy of 83.77%. We then train a\nConditional Generative Adversarial Network on the training data for 2000\nepochs, and it learns to generate relatively realistic images. Grad-CAM\nanalysis of the model trained on real photographs shows that the synthetic\nimages can exhibit classifiable characteristics such as shape, mould, and\ngangrene. A higher image classification accuracy of 88.75% is then attained by\naugmenting the training with synthetic images, arguing that Conditional\nGenerative Adversarial Networks have the ability to produce new data to\nalleviate issues of data scarcity. Finally, model pruning is performed via\npolynomial decay, where we find that the Conditional GAN-augmented\nclassification network can retain 81.16% classification accuracy when\ncompressed to 50% of its original size.\n", "versions": [{"version": "v1", "created": "Mon, 12 Apr 2021 17:13:05 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Bird", "Jordan J.", ""], ["Barnes", "Chloe M.", ""], ["Manso", "Luis J.", ""], ["Ek\u00e1rt", "Anik\u00f3", ""], ["Faria", "Diego R.", ""]]}, {"id": "2104.05652", "submitter": "Fenggen Yu", "authors": "Fenggen Yu, Zhiqin Chen, Manyi Li, Aditya Sanghi, Hooman Shayani, Ali\n  Mahdavi-Amiri and Hao Zhang", "title": "CAPRI-Net: Learning Compact CAD Shapes with Adaptive Primitive Assembly", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.GR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce CAPRI-Net, a neural network for learning compact and\ninterpretable implicit representations of 3D computer-aided design (CAD)\nmodels, in the form of adaptive primitive assemblies. Our network takes an\ninput 3D shape that can be provided as a point cloud or voxel grids, and\nreconstructs it by a compact assembly of quadric surface primitives via\nconstructive solid geometry (CSG) operations. The network is self-supervised\nwith a reconstruction loss, leading to faithful 3D reconstructions with sharp\nedges and plausible CSG trees, without any ground-truth shape assemblies. While\nthe parametric nature of CAD models does make them more predictable locally, at\nthe shape level, there is a great deal of structural and topological\nvariations, which present a significant generalizability challenge to\nstate-of-the-art neural models for 3D shapes. Our network addresses this\nchallenge by adaptive training with respect to each test shape, with which we\nfine-tune the network that was pre-trained on a model collection. We evaluate\nour learning framework on both ShapeNet and ABC, the largest and most diverse\nCAD dataset to date, in terms of reconstruction quality, shape edges,\ncompactness, and interpretability, to demonstrate superiority over current\nalternatives suitable for neural CAD reconstruction.\n", "versions": [{"version": "v1", "created": "Mon, 12 Apr 2021 17:21:19 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Yu", "Fenggen", ""], ["Chen", "Zhiqin", ""], ["Li", "Manyi", ""], ["Sanghi", "Aditya", ""], ["Shayani", "Hooman", ""], ["Mahdavi-Amiri", "Ali", ""], ["Zhang", "Hao", ""]]}, {"id": "2104.05657", "submitter": "Jiyang Tang", "authors": "Jiyang Tang, Ming Li", "title": "End-to-End Mandarin Tone Classification with Short Term Context\n  Information", "comments": "Submitted to APSIPA ASC 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose an end-to-end Mandarin tone classification method\nfrom continuous speech utterances utilizing both the spectrogram and the\nshort-term context information as the input. Both spectrograms and context\nsegment features are used to train the tone classifier. We first divide the\nspectrogram frames into syllable segments using force alignment results\nproduced by an ASR model. Then we extract the short-term segment features to\ncapture the context information across multiple syllables. Feeding both the\nspectrogram and the short-term context segment features into an end-to-end\nmodel could significantly improve the performance. Experiments are performed on\na large-scale open-source Mandarin speech dataset to evaluate the proposed\nmethod. Results show that this method improves the classification accuracy from\n79.5% to 92.6% on the AISHELL3 database.\n", "versions": [{"version": "v1", "created": "Mon, 12 Apr 2021 17:27:39 GMT"}, {"version": "v2", "created": "Mon, 12 Jul 2021 07:38:20 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Tang", "Jiyang", ""], ["Li", "Ming", ""]]}, {"id": "2104.05661", "submitter": "Lars Klitzke", "authors": "Lars Klitzke, Kay Gimm, Carsten Koch, Frank K\\\"oster", "title": "Unsupervised Lane-Change Identification for On-Ramp Merge Analysis in\n  Naturalistic Driving Data", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Connected and Automated Vehicles (CAVs) are envisioned to transform the\nfuture industrial and private transportation sectors. Due to the complexity of\nthe systems, functional verification and validation of safety aspects are\nessential before the technology merges into the public domain. In recent years,\na scenario-driven approach has gained acceptance for CAVs emphasizing the\nrequirement of a solid data basis of scenarios. The large-scale research\nfacility Test Bed Lower Saxony (TFNDS) enables the provision of substantial\ninformation for a database of scenarios on motorways. For that purpose,\nhowever, the scenarios of interest must be identified and categorized in the\ncollected trajectory data. This work addresses this problem and proposes a\nframework for on-ramp scenario identification that also enables for scenario\ncategorization and assessment. The efficacy of the framework is shown with a\ndataset collected on the TFNDS.\n", "versions": [{"version": "v1", "created": "Mon, 12 Apr 2021 17:32:22 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Klitzke", "Lars", ""], ["Gimm", "Kay", ""], ["Koch", "Carsten", ""], ["K\u00f6ster", "Frank", ""]]}, {"id": "2104.05674", "submitter": "Vincent Dutordoir", "authors": "Vincent Dutordoir, Hugh Salimbeni, Eric Hambro, John McLeod, Felix\n  Leibfried, Artem Artemev, Mark van der Wilk, James Hensman, Marc P.\n  Deisenroth, ST John", "title": "GPflux: A Library for Deep Gaussian Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce GPflux, a Python library for Bayesian deep learning with a\nstrong emphasis on deep Gaussian processes (DGPs). Implementing DGPs is a\nchallenging endeavour due to the various mathematical subtleties that arise\nwhen dealing with multivariate Gaussian distributions and the complex\nbookkeeping of indices. To date, there are no actively maintained, open-sourced\nand extendable libraries available that support research activities in this\narea. GPflux aims to fill this gap by providing a library with state-of-the-art\nDGP algorithms, as well as building blocks for implementing novel Bayesian and\nGP-based hierarchical models and inference schemes. GPflux is compatible with\nand built on top of the Keras deep learning eco-system. This enables\npractitioners to leverage tools from the deep learning community for building\nand training customised Bayesian models, and create hierarchical models that\nconsist of Bayesian and standard neural network layers in a single coherent\nframework. GPflux relies on GPflow for most of its GP objects and operations,\nwhich makes it an efficient, modular and extensible library, while having a\nlean codebase.\n", "versions": [{"version": "v1", "created": "Mon, 12 Apr 2021 17:41:18 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Dutordoir", "Vincent", ""], ["Salimbeni", "Hugh", ""], ["Hambro", "Eric", ""], ["McLeod", "John", ""], ["Leibfried", "Felix", ""], ["Artemev", "Artem", ""], ["van der Wilk", "Mark", ""], ["Hensman", "James", ""], ["Deisenroth", "Marc P.", ""], ["John", "ST", ""]]}, {"id": "2104.05694", "submitter": "Tianyi Zhang", "authors": "Tianyi Zhang and Tatsunori Hashimoto", "title": "On the Inductive Bias of Masked Language Modeling: From Statistical to\n  Syntactic Dependencies", "comments": "NAACL-HLT 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study how masking and predicting tokens in an unsupervised fashion can\ngive rise to linguistic structures and downstream performance gains. Recent\ntheories have suggested that pretrained language models acquire useful\ninductive biases through masks that implicitly act as cloze reductions for\ndownstream tasks. While appealing, we show that the success of the random\nmasking strategy used in practice cannot be explained by such cloze-like masks\nalone. We construct cloze-like masks using task-specific lexicons for three\ndifferent classification datasets and show that the majority of pretrained\nperformance gains come from generic masks that are not associated with the\nlexicon. To explain the empirical success of these generic masks, we\ndemonstrate a correspondence between the Masked Language Model (MLM) objective\nand existing methods for learning statistical dependencies in graphical models.\nUsing this, we derive a method for extracting these learned statistical\ndependencies in MLMs and show that these dependencies encode useful inductive\nbiases in the form of syntactic structures. In an unsupervised parsing\nevaluation, simply forming a minimum spanning tree on the implied statistical\ndependence structure outperforms a classic method for unsupervised parsing\n(58.74 vs. 55.91 UUAS).\n", "versions": [{"version": "v1", "created": "Mon, 12 Apr 2021 17:55:27 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Zhang", "Tianyi", ""], ["Hashimoto", "Tatsunori", ""]]}, {"id": "2104.05700", "submitter": "Thamme Gowda", "authors": "Thamme Gowda, Weiqiu You, Constantine Lignos, Jonathan May", "title": "Macro-Average: Rare Types Are Important Too", "comments": null, "journal-ref": null, "doi": "10.18653/v1/2021.naacl-main.90", "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  While traditional corpus-level evaluation metrics for machine translation\n(MT) correlate well with fluency, they struggle to reflect adequacy.\nModel-based MT metrics trained on segment-level human judgments have emerged as\nan attractive replacement due to strong correlation results. These models,\nhowever, require potentially expensive re-training for new domains and\nlanguages. Furthermore, their decisions are inherently non-transparent and\nappear to reflect unwelcome biases. We explore the simple type-based classifier\nmetric, MacroF1, and study its applicability to MT evaluation. We find that\nMacroF1 is competitive on direct assessment, and outperforms others in\nindicating downstream cross-lingual information retrieval task performance.\nFurther, we show that MacroF1 can be used to effectively compare supervised and\nunsupervised neural machine translation, and reveal significant qualitative\ndifferences in the methods' outputs.\n", "versions": [{"version": "v1", "created": "Mon, 12 Apr 2021 17:57:42 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Gowda", "Thamme", ""], ["You", "Weiqiu", ""], ["Lignos", "Constantine", ""], ["May", "Jonathan", ""]]}, {"id": "2104.05702", "submitter": "Zhiding Yu", "authors": "Nadine Chang, Zhiding Yu, Yu-Xiong Wang, Anima Anandkumar, Sanja\n  Fidler, Jose M. Alvarez", "title": "Image-Level or Object-Level? A Tale of Two Resampling Strategies for\n  Long-Tailed Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training on datasets with long-tailed distributions has been challenging for\nmajor recognition tasks such as classification and detection. To deal with this\nchallenge, image resampling is typically introduced as a simple but effective\napproach. However, we observe that long-tailed detection differs from\nclassification since multiple classes may be present in one image. As a result,\nimage resampling alone is not enough to yield a sufficiently balanced\ndistribution at the object level. We address object-level resampling by\nintroducing an object-centric memory replay strategy based on dynamic, episodic\nmemory banks. Our proposed strategy has two benefits: 1) convenient\nobject-level resampling without significant extra computation, and 2) implicit\nfeature-level augmentation from model updates. We show that image-level and\nobject-level resamplings are both important, and thus unify them with a joint\nresampling strategy (RIO). Our method outperforms state-of-the-art long-tailed\ndetection and segmentation methods on LVIS v0.5 across various backbones.\n", "versions": [{"version": "v1", "created": "Mon, 12 Apr 2021 17:58:30 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Chang", "Nadine", ""], ["Yu", "Zhiding", ""], ["Wang", "Yu-Xiong", ""], ["Anandkumar", "Anima", ""], ["Fidler", "Sanja", ""], ["Alvarez", "Jose M.", ""]]}, {"id": "2104.05704", "submitter": "Humphrey Shi", "authors": "Ali Hassani, Steven Walton, Nikhil Shah, Abulikemu Abuduweili, Jiachen\n  Li, Humphrey Shi", "title": "Escaping the Big Data Paradigm with Compact Transformers", "comments": "Added experiments on ImageNet and NLP tasks", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the rise of Transformers as the standard for language processing, and\ntheir advancements in computer vision, along with their unprecedented size and\namounts of training data, many have come to believe that they are not suitable\nfor small sets of data. This trend leads to great concerns, including but not\nlimited to: limited availability of data in certain scientific domains and the\nexclusion of those with limited resource from research in the field. In this\npaper, we dispel the myth that transformers are \"data hungry\" and therefore can\nonly be applied to large sets of data. We show for the first time that with the\nright size and tokenization, transformers can perform head-to-head with\nstate-of-the-art CNNs on small datasets. Our model eliminates the requirement\nfor class token and positional embeddings through a novel sequence pooling\nstrategy and the use of convolutions. We show that compared to CNNs, our\ncompact transformers have fewer parameters and MACs, while obtaining similar\naccuracies. Our method is flexible in terms of model size, and can have as\nlittle as 0.28M parameters and achieve reasonable results. It can reach an\naccuracy of 95.29 % when training from scratch on CIFAR-10, which is comparable\nwith modern CNN based approaches, and a significant improvement over previous\nTransformer based models. Our simple and compact design democratizes\ntransformers by making them accessible to those equipped with basic computing\nresources and/or dealing with important small datasets. Our method works on\nlarger datasets, such as ImageNet (80.28% accuracy with 29% parameters of ViT),\nand NLP tasks as well. Our code and pre-trained models are publicly available\nat https://github.com/SHI-Labs/Compact-Transformers.\n", "versions": [{"version": "v1", "created": "Mon, 12 Apr 2021 17:58:56 GMT"}, {"version": "v2", "created": "Wed, 30 Jun 2021 17:03:41 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Hassani", "Ali", ""], ["Walton", "Steven", ""], ["Shah", "Nikhil", ""], ["Abuduweili", "Abulikemu", ""], ["Li", "Jiachen", ""], ["Shi", "Humphrey", ""]]}, {"id": "2104.05712", "submitter": "Massimo Nazaria", "authors": "Massimo Nazaria", "title": "Predicting the Accuracy of Early-est Earthquake Magnitude Estimates with\n  an LSTM Neural Network: A Preliminary Analysis", "comments": "Data and code are available at\n  https://github.com/massimo-nazaria/lstm", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.geo-ph cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This report presents a preliminary analysis of an LSTM neural network\ndesigned to predict the accuracy of magnitude estimates computed by Early-est\nduring the first minutes after an earthquake occurs.\n", "versions": [{"version": "v1", "created": "Mon, 12 Apr 2021 10:36:34 GMT"}, {"version": "v2", "created": "Wed, 26 May 2021 07:40:45 GMT"}], "update_date": "2021-05-27", "authors_parsed": [["Nazaria", "Massimo", ""]]}, {"id": "2104.05741", "submitter": "Martha Dais Ferreira", "authors": "Martha Dais Ferreira, Michal Malyska, Nicola Sahar, Riccardo Miotto,\n  Fernando Paulovich, Evangelos Milios", "title": "Active learning for medical code assignment", "comments": "It was accepted in the ACM CHIL 2021 workshop track", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine Learning (ML) is widely used to automatically extract meaningful\ninformation from Electronic Health Records (EHR) to support operational,\nclinical, and financial decision-making. However, ML models require a large\nnumber of annotated examples to provide satisfactory results, which is not\npossible in most healthcare scenarios due to the high cost of clinician-labeled\ndata. Active Learning (AL) is a process of selecting the most informative\ninstances to be labeled by an expert to further train a supervised algorithm.\nWe demonstrate the effectiveness of AL in multi-label text classification in\nthe clinical domain. In this context, we apply a set of well-known AL methods\nto help automatically assign ICD-9 codes on the MIMIC-III dataset. Our results\nshow that the selection of informative instances provides satisfactory\nclassification with a significantly reduced training set (8.3\\% of the total\ninstances). We conclude that AL methods can significantly reduce the manual\nannotation cost while preserving model performance.\n", "versions": [{"version": "v1", "created": "Mon, 12 Apr 2021 18:11:17 GMT"}], "update_date": "2021-04-14", "authors_parsed": [["Ferreira", "Martha Dais", ""], ["Malyska", "Michal", ""], ["Sahar", "Nicola", ""], ["Miotto", "Riccardo", ""], ["Paulovich", "Fernando", ""], ["Milios", "Evangelos", ""]]}, {"id": "2104.05743", "submitter": "Pavlos Papadopoulos", "authors": "Tom Titcombe, Adam J. Hall, Pavlos Papadopoulos, Daniele Romanini", "title": "Practical Defences Against Model Inversion Attacks for Split Neural\n  Networks", "comments": "ICLR 2021 Workshop on Distributed and Private Machine Learning (DPML\n  2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.DC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We describe a threat model under which a split network-based federated\nlearning system is susceptible to a model inversion attack by a malicious\ncomputational server. We demonstrate that the attack can be successfully\nperformed with limited knowledge of the data distribution by the attacker. We\npropose a simple additive noise method to defend against model inversion,\nfinding that the method can significantly reduce attack efficacy at an\nacceptable accuracy trade-off on MNIST. Furthermore, we show that NoPeekNN, an\nexisting defensive method, protects different information from exposure,\nsuggesting that a combined defence is necessary to fully protect private user\ndata.\n", "versions": [{"version": "v1", "created": "Mon, 12 Apr 2021 18:12:17 GMT"}, {"version": "v2", "created": "Wed, 21 Apr 2021 11:01:25 GMT"}], "update_date": "2021-04-22", "authors_parsed": [["Titcombe", "Tom", ""], ["Hall", "Adam J.", ""], ["Papadopoulos", "Pavlos", ""], ["Romanini", "Daniele", ""]]}, {"id": "2104.05752", "submitter": "My Phung", "authors": "Sujeong Cha, Wangrui Hou, Hyun Jung, My Phung, Michael Picheny,\n  Hong-Kwang Kuo, Samuel Thomas, Edmilson Morais", "title": "Speak or Chat with Me: End-to-End Spoken Language Understanding System\n  with Flexible Inputs", "comments": "Accepted to Interspeech 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A major focus of recent research in spoken language understanding (SLU) has\nbeen on the end-to-end approach where a single model can predict intents\ndirectly from speech inputs without intermediate transcripts. However, this\napproach presents some challenges. First, since speech can be considered as\npersonally identifiable information, in some cases only automatic speech\nrecognition (ASR) transcripts are accessible. Second, intent-labeled speech\ndata is scarce. To address the first challenge, we propose a novel system that\ncan predict intents from flexible types of inputs: speech, ASR transcripts, or\nboth. We demonstrate strong performance for either modality separately, and\nwhen both speech and ASR transcripts are available, through system combination,\nwe achieve better results than using a single input modality. To address the\nsecond challenge, we leverage a semantically robust pre-trained BERT model and\nadopt a cross-modal system that co-trains text embeddings and acoustic\nembeddings in a shared latent space. We further enhance this system by\nutilizing an acoustic module pre-trained on LibriSpeech and domain-adapting the\ntext module on our target datasets. Our experiments show significant advantages\nfor these pre-training and fine-tuning strategies, resulting in a system that\nachieves competitive intent-classification performance on Snips SLU and Fluent\nSpeech Commands datasets.\n", "versions": [{"version": "v1", "created": "Wed, 7 Apr 2021 20:48:08 GMT"}, {"version": "v2", "created": "Mon, 14 Jun 2021 13:55:41 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Cha", "Sujeong", ""], ["Hou", "Wangrui", ""], ["Jung", "Hyun", ""], ["Phung", "My", ""], ["Picheny", "Michael", ""], ["Kuo", "Hong-Kwang", ""], ["Thomas", "Samuel", ""], ["Morais", "Edmilson", ""]]}, {"id": "2104.05781", "submitter": "Arun Verma", "authors": "Arun Verma, Manjesh K. Hanawal, Arun Rajkumar, Raman Sankaran", "title": "Censored Semi-Bandits for Resource Allocation", "comments": "Extended version of the NeurIPS 2019 paper (Censored Semi-Bandits: A\n  Framework for Resource Allocation with Censored Feedback)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We consider the problem of sequentially allocating resources in a censored\nsemi-bandits setup, where the learner allocates resources at each step to the\narms and observes loss. The loss depends on two hidden parameters, one specific\nto the arm but independent of the resource allocation, and the other depends on\nthe allocated resource. More specifically, the loss equals zero for an arm if\nthe resource allocated to it exceeds a constant (but unknown) arm dependent\nthreshold. The goal is to learn a resource allocation that minimizes the\nexpected loss. The problem is challenging because the loss distribution and\nthreshold value of each arm are unknown. We study this setting by establishing\nits `equivalence' to Multiple-Play Multi-Armed Bandits (MP-MAB) and\nCombinatorial Semi-Bandits. Exploiting these equivalences, we derive optimal\nalgorithms for our problem setting using known algorithms for MP-MAB and\nCombinatorial Semi-Bandits. The experiments on synthetically generated data\nvalidate the performance guarantees of the proposed algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 12 Apr 2021 19:15:32 GMT"}], "update_date": "2021-04-14", "authors_parsed": [["Verma", "Arun", ""], ["Hanawal", "Manjesh K.", ""], ["Rajkumar", "Arun", ""], ["Sankaran", "Raman", ""]]}, {"id": "2104.05785", "submitter": "Kenji Kawaguchi", "authors": "Kenji Kawaguchi, Qingyun Sun", "title": "A Recipe for Global Convergence Guarantee in Deep Neural Networks", "comments": "Published in AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing global convergence guarantees of (stochastic) gradient descent do\nnot apply to practical deep networks in the practical regime of deep learning\nbeyond the neural tangent kernel (NTK) regime. This paper proposes an\nalgorithm, which is ensured to have global convergence guarantees in the\npractical regime beyond the NTK regime, under a verifiable condition called the\nexpressivity condition. The expressivity condition is defined to be both\ndata-dependent and architecture-dependent, which is the key property that makes\nour results applicable for practical settings beyond the NTK regime. On the one\nhand, the expressivity condition is theoretically proven to hold\ndata-independently for fully-connected deep neural networks with narrow hidden\nlayers and a single wide layer. On the other hand, the expressivity condition\nis numerically shown to hold data-dependently for deep (convolutional) ResNet\nwith batch normalization with various standard image datasets. We also show\nthat the proposed algorithm has generalization performances comparable with\nthose of the heuristic algorithm, with the same hyper-parameters and total\nnumber of iterations. Therefore, the proposed algorithm can be viewed as a step\ntowards providing theoretical guarantees for deep learning in the practical\nregime.\n", "versions": [{"version": "v1", "created": "Mon, 12 Apr 2021 19:25:30 GMT"}, {"version": "v2", "created": "Thu, 15 Apr 2021 20:35:03 GMT"}], "update_date": "2021-04-19", "authors_parsed": [["Kawaguchi", "Kenji", ""], ["Sun", "Qingyun", ""]]}, {"id": "2104.05801", "submitter": "Sarik Ghazarian", "authors": "Sarik Ghazarian, Zixi Liu, Akash SM, Ralph Weischedel, Aram Galstyan,\n  Nanyun Peng", "title": "Plot-guided Adversarial Example Construction for Evaluating Open-domain\n  Story Generation", "comments": "NAACL 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the recent advances of open-domain story generation, the lack of\nreliable automatic evaluation metrics becomes an increasingly imperative issue\nthat hinders the fast development of story generation. According to conducted\nresearches in this regard, learnable evaluation metrics have promised more\naccurate assessments by having higher correlations with human judgments. A\ncritical bottleneck of obtaining a reliable learnable evaluation metric is the\nlack of high-quality training data for classifiers to efficiently distinguish\nplausible and implausible machine-generated stories. Previous works relied on\n\\textit{heuristically manipulated} plausible examples to mimic possible system\ndrawbacks such as repetition, contradiction, or irrelevant content in the text\nlevel, which can be \\textit{unnatural} and \\textit{oversimplify} the\ncharacteristics of implausible machine-generated stories. We propose to tackle\nthese issues by generating a more comprehensive set of implausible stories\nusing {\\em plots}, which are structured representations of controllable factors\nused to generate stories. Since these plots are compact and structured, it is\neasier to manipulate them to generate text with targeted undesirable\nproperties, while at the same time maintain the grammatical correctness and\nnaturalness of the generated sentences. To improve the quality of generated\nimplausible stories, we further apply the adversarial filtering procedure\npresented by \\citet{zellers2018swag} to select a more nuanced set of\nimplausible texts. Experiments show that the evaluation metrics trained on our\ngenerated data result in more reliable automatic assessments that correlate\nremarkably better with human judgments compared to the baselines.\n", "versions": [{"version": "v1", "created": "Mon, 12 Apr 2021 20:19:24 GMT"}, {"version": "v2", "created": "Tue, 25 May 2021 20:01:43 GMT"}], "update_date": "2021-05-27", "authors_parsed": [["Ghazarian", "Sarik", ""], ["Liu", "Zixi", ""], ["SM", "Akash", ""], ["Weischedel", "Ralph", ""], ["Galstyan", "Aram", ""], ["Peng", "Nanyun", ""]]}, {"id": "2104.05802", "submitter": "Dongsheng An", "authors": "Dongsheng An, Na Lei and Xianfeng Gu", "title": "Efficient Optimal Transport Algorithm by Accelerated Gradient descent", "comments": "ICML 2021 workshop for Beyond first-order methods in machine learning\n  systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Optimal transport (OT) plays an essential role in various areas like machine\nlearning and deep learning. However, computing discrete optimal transport plan\nfor large scale problems with adequate accuracy and efficiency is still highly\nchallenging. Recently, methods based on the Sinkhorn algorithm add an entropy\nregularizer to the prime problem and get a trade off between efficiency and\naccuracy. In this paper, we propose a novel algorithm to further improve the\nefficiency and accuracy based on Nesterov's smoothing technique. Basically, the\nnon-smooth c-transform of the Kantorovich potential is approximated by the\nsmooth Log-Sum-Exp function, which finally smooths the original non-smooth\nKantorovich dual functional (energy). The smooth Kantorovich functional can be\noptimized by the fast proximal gradient algorithm (FISTA) efficiently.\nTheoretically, the computational complexity of the proposed method is given by\n$O(n^{\\frac{5}{2}} \\sqrt{\\log n} /\\epsilon)$, which is lower than that of the\nSinkhorn algorithm. Empirically, compared with the Sinkhorn algorithm, our\nexperimental results demonstrate that the proposed method achieves faster\nconvergence and better accuracy with the same parameter.\n", "versions": [{"version": "v1", "created": "Mon, 12 Apr 2021 20:23:29 GMT"}, {"version": "v2", "created": "Mon, 19 Jul 2021 17:38:37 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["An", "Dongsheng", ""], ["Lei", "Na", ""], ["Gu", "Xianfeng", ""]]}, {"id": "2104.05807", "submitter": "Marco Valentino", "authors": "Deborah Ferreira, Julia Rozanova, Mokanarangan Thayaparan, Marco\n  Valentino, Andr\\'e Freitas", "title": "Does My Representation Capture X? Probe-Ably", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Probing (or diagnostic classification) has become a popular strategy for\ninvestigating whether a given set of intermediate features is present in the\nrepresentations of neural models. Naive probing studies may have misleading\nresults, but various recent works have suggested more reliable methodologies\nthat compensate for the possible pitfalls of probing. However, these best\npractices are numerous and fast-evolving. To simplify the process of running a\nset of probing experiments in line with suggested methodologies, we introduce\nProbe-Ably: an extendable probing framework which supports and automates the\napplication of probing methods to the user's inputs\n", "versions": [{"version": "v1", "created": "Mon, 12 Apr 2021 20:43:10 GMT"}], "update_date": "2021-04-14", "authors_parsed": [["Ferreira", "Deborah", ""], ["Rozanova", "Julia", ""], ["Thayaparan", "Mokanarangan", ""], ["Valentino", "Marco", ""], ["Freitas", "Andr\u00e9", ""]]}, {"id": "2104.05828", "submitter": "Pg Madhavan", "authors": "PG Madhavan", "title": "Evidence-based Prescriptive Analytics, CAUSAL Digital Twin and a\n  Learning Estimation Algorithm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.LG cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Evidence-based Prescriptive Analytics (EbPA) is necessary to determine\noptimal operational set-points that will improve business productivity. EbPA\nresults from what-if analysis and counterfactual experimentation on CAUSAL\nDigital Twins (CDTs) that quantify cause-effect relationships in the DYNAMICS\nof a system of connected assets. We describe the basics of Causality and Causal\nGraphs and develop a Learning Causal Digital Twin (LCDT) solution; our\nalgorithm uses a simple recurrent neural network with some innovative\nmodifications incorporating Causal Graph simulation. Since LCDT is a learning\ndigital twin where parameters are learned online in real-time with minimal\npre-configuration, the work of deploying digital twins will be significantly\nsimplified. A proof-of-principle of LCDT was conducted using real vibration\ndata from a system of bearings; results of causal factor estimation, what-if\nanalysis study and counterfactual experiment are very encouraging.\n", "versions": [{"version": "v1", "created": "Mon, 12 Apr 2021 21:30:53 GMT"}], "update_date": "2021-04-14", "authors_parsed": [["Madhavan", "PG", ""]]}, {"id": "2104.05831", "submitter": "Gabriel Suarez", "authors": "Gabriel Suarez, Juan Raful, Maria A. Luque, Carlos F. Valencia,\n  Alejandro Correa-Bahnsen", "title": "Enhancing User' s Income Estimation with Super-App Alternative Data", "comments": "5 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-fin.RM", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  This paper presents the advantages of alternative data from Super-Apps to\nenhance user' s income estimation models. It compares the performance of these\nalternative data sources with the performance of industry-accepted bureau\nincome estimators that takes into account only financial system information;\nsuccessfully showing that the alternative data manage to capture information\nthat bureau income estimators do not. By implementing the TreeSHAP method for\nStochastic Gradient Boosting Interpretation, this paper highlights which of the\ncustomer' s behavioral and transactional patterns within a Super-App have a\nstronger predictive power when estimating user' s income. Ultimately, this\npaper shows the incentive for financial institutions to seek to incorporate\nalternative data into constructing their risk profiles.\n", "versions": [{"version": "v1", "created": "Mon, 12 Apr 2021 21:34:44 GMT"}], "update_date": "2021-04-14", "authors_parsed": [["Suarez", "Gabriel", ""], ["Raful", "Juan", ""], ["Luque", "Maria A.", ""], ["Valencia", "Carlos F.", ""], ["Correa-Bahnsen", "Alejandro", ""]]}, {"id": "2104.05833", "submitter": "Daiqing Li", "authors": "Daiqing Li, Junlin Yang, Karsten Kreis, Antonio Torralba, Sanja Fidler", "title": "Semantic Segmentation with Generative Models: Semi-Supervised Learning\n  and Strong Out-of-Domain Generalization", "comments": "CVPR2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Training deep networks with limited labeled data while achieving a strong\ngeneralization ability is key in the quest to reduce human annotation efforts.\nThis is the goal of semi-supervised learning, which exploits more widely\navailable unlabeled data to complement small labeled data sets. In this paper,\nwe propose a novel framework for discriminative pixel-level tasks using a\ngenerative model of both images and labels. Concretely, we learn a generative\nadversarial network that captures the joint image-label distribution and is\ntrained efficiently using a large set of unlabeled images supplemented with\nonly few labeled ones. We build our architecture on top of StyleGAN2, augmented\nwith a label synthesis branch. Image labeling at test time is achieved by first\nembedding the target image into the joint latent space via an encoder network\nand test-time optimization, and then generating the label from the inferred\nembedding. We evaluate our approach in two important domains: medical image\nsegmentation and part-based face segmentation. We demonstrate strong in-domain\nperformance compared to several baselines, and are the first to showcase\nextreme out-of-domain generalization, such as transferring from CT to MRI in\nmedical imaging, and photographs of real faces to paintings, sculptures, and\neven cartoons and animal faces. Project Page:\n\\url{https://nv-tlabs.github.io/semanticGAN/}\n", "versions": [{"version": "v1", "created": "Mon, 12 Apr 2021 21:41:25 GMT"}], "update_date": "2021-04-14", "authors_parsed": [["Li", "Daiqing", ""], ["Yang", "Junlin", ""], ["Kreis", "Karsten", ""], ["Torralba", "Antonio", ""], ["Fidler", "Sanja", ""]]}, {"id": "2104.05837", "submitter": "Tara Safavi", "authors": "Tara Safavi, Danai Koutra", "title": "Relational world knowledge representation in contextual language models:\n  A review", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Relational knowledge bases (KBs) are established tools for world knowledge\nrepresentation in machines. While they are advantageous for their precision and\ninterpretability, they usually sacrifice some data modeling flexibility for\nthese advantages because they adhere to a manually engineered schema. In this\nreview, we take a natural language processing perspective to the limitations of\nKBs, examining how they may be addressed in part by training neural contextual\nlanguage models (LMs) to internalize and express relational knowledge in\nfree-text form. We propose a novel taxonomy for relational knowledge\nrepresentation in contextual LMs based on the level of KB supervision provided,\nconsidering both works that probe LMs for implicit relational knowledge\nacquired during self-supervised pretraining on unstructured text alone, and\nworks that explicitly supervise LMs at the level of KB entities and/or\nrelations. We conclude that LMs and KBs are complementary representation tools,\nas KBs provide a high standard of factual precision which can in turn be\nflexibly and expressively modeled by LMs, and provide suggestions for future\nresearch in this direction.\n", "versions": [{"version": "v1", "created": "Mon, 12 Apr 2021 21:50:55 GMT"}], "update_date": "2021-04-14", "authors_parsed": [["Safavi", "Tara", ""], ["Koutra", "Danai", ""]]}, {"id": "2104.05845", "submitter": "Yue Yang", "authors": "Yue Yang, Artemis Panagopoulou, Qing Lyu, Li Zhang, Mark Yatskar,\n  Chris Callison-Burch", "title": "Visual Goal-Step Inference using wikiHow", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL cs.LG cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Procedural events can often be thought of as a high level goal composed of a\nsequence of steps. Inferring the sub-sequence of steps of a goal can help\nartificial intelligence systems reason about human activities. Past work in NLP\nhas examined the task of goal-step inference for text. We introduce the visual\nanalogue. We propose the Visual Goal-Step Inference (VGSI) task where a model\nis given a textual goal and must choose a plausible step towards that goal from\namong four candidate images. Our task is challenging for state-of-the-art\nmuitimodal models. We introduce a novel dataset harvested from wikiHow that\nconsists of 772,294 images representing human actions. We show that the\nknowledge learned from our data can effectively transfer to other datasets like\nHowTo100M, increasing the multiple-choice accuracy by 15% to 20%. Our task will\nfacilitate multi-modal reasoning about procedural events.\n", "versions": [{"version": "v1", "created": "Mon, 12 Apr 2021 22:20:09 GMT"}], "update_date": "2021-04-14", "authors_parsed": [["Yang", "Yue", ""], ["Panagopoulou", "Artemis", ""], ["Lyu", "Qing", ""], ["Zhang", "Li", ""], ["Yatskar", "Mark", ""], ["Callison-Burch", "Chris", ""]]}, {"id": "2104.05859", "submitter": "Dhruv Shah", "authors": "Dhruv Shah, Benjamin Eysenbach, Nicholas Rhinehart, Sergey Levine", "title": "RECON: Rapid Exploration for Open-World Navigation with Latent Goal\n  Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We describe a robotic learning system for autonomous navigation in diverse\nenvironments. At the core of our method are two components: (i) a\nnon-parametric map that reflects the connectivity of the environment but does\nnot require geometric reconstruction or localization, and (ii) a latent\nvariable model of distances and actions that enables efficiently constructing\nand traversing this map. The model is trained on a large dataset of prior\nexperience to predict the expected amount of time and next action needed to\ntransit between the current image and a goal image. Training the model in this\nway enables it to develop a representation of goals robust to distracting\ninformation in the input images, which aids in deploying the system to quickly\nexplore new environments. We demonstrate our method on a mobile ground robot in\na range of outdoor navigation scenarios. Our method can learn to reach new\ngoals, specified as images, in a radius of up to 80 meters in just 20 minutes,\nand reliably revisit these goals in changing environments. We also demonstrate\nour method's robustness to previously-unseen obstacles and variable weather\nconditions. We encourage the reader to visit the project website for videos of\nour experiments and demonstrations https://sites.google.com/view/recon-robot\n", "versions": [{"version": "v1", "created": "Mon, 12 Apr 2021 23:14:41 GMT"}, {"version": "v2", "created": "Wed, 14 Apr 2021 04:30:53 GMT"}], "update_date": "2021-04-15", "authors_parsed": [["Shah", "Dhruv", ""], ["Eysenbach", "Benjamin", ""], ["Rhinehart", "Nicholas", ""], ["Levine", "Sergey", ""]]}, {"id": "2104.05860", "submitter": "Angus Lamb", "authors": "Angus Lamb, Evgeny Saveliev, Yingzhen Li, Sebastian Tschiatschek,\n  Camilla Longden, Simon Woodhead, Jos\\'e Miguel Hern\\'andez-Lobato, Richard E.\n  Turner, Pashmina Cameron, Cheng Zhang", "title": "Contextual HyperNetworks for Novel Feature Adaptation", "comments": "17 pages, 9 Figures, workshop paper at NeurIPS 2020 Meta-Learning\n  Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While deep learning has obtained state-of-the-art results in many\napplications, the adaptation of neural network architectures to incorporate new\noutput features remains a challenge, as neural networks are commonly trained to\nproduce a fixed output dimension. This issue is particularly severe in online\nlearning settings, where new output features, such as items in a recommender\nsystem, are added continually with few or no associated observations. As such,\nmethods for adapting neural networks to novel features which are both time and\ndata-efficient are desired. To address this, we propose the Contextual\nHyperNetwork (CHN), an auxiliary model which generates parameters for extending\nthe base model to a new feature, by utilizing both existing data as well as any\nobservations and/or metadata associated with the new feature. At prediction\ntime, the CHN requires only a single forward pass through a neural network,\nyielding a significant speed-up when compared to re-training and fine-tuning\napproaches.\n  To assess the performance of CHNs, we use a CHN to augment a partial\nvariational autoencoder (P-VAE), a deep generative model which can impute the\nvalues of missing features in sparsely-observed data. We show that this system\nobtains improved few-shot learning performance for novel features over existing\nimputation and meta-learning baselines across recommender systems, e-learning,\nand healthcare tasks.\n", "versions": [{"version": "v1", "created": "Mon, 12 Apr 2021 23:19:49 GMT"}], "update_date": "2021-04-14", "authors_parsed": [["Lamb", "Angus", ""], ["Saveliev", "Evgeny", ""], ["Li", "Yingzhen", ""], ["Tschiatschek", "Sebastian", ""], ["Longden", "Camilla", ""], ["Woodhead", "Simon", ""], ["Hern\u00e1ndez-Lobato", "Jos\u00e9 Miguel", ""], ["Turner", "Richard E.", ""], ["Cameron", "Pashmina", ""], ["Zhang", "Cheng", ""]]}, {"id": "2104.05861", "submitter": "Mohammad Hadi", "authors": "Mohammad Abdul Hadi, Fatemeh H. Fard", "title": "Evaluating Pre-Trained Models for User Feedback Analysis in Software\n  Engineering: A Study on Classification of App-Reviews", "comments": "11 pages, 1 table, MSR 2021 Registered Report Track", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Context: Mobile app reviews written by users on app stores or social media\nare significant resources for app developers.Analyzing app reviews have proved\nto be useful for many areas of software engineering (e.g., requirement\nengineering, testing). Automatic classification of app reviews requires\nextensive efforts to manually curate a labeled dataset. When the classification\npurpose changes (e.g. identifying bugs versus usability issues or sentiment),\nnew datasets should be labeled, which prevents the extensibility of the\ndeveloped models for new desired classes/tasks in practice. Recent pre-trained\nneural language models (PTM) are trained on large corpora in an unsupervised\nmanner and have found success in solving similar Natural Language Processing\nproblems. However, the applicability of PTMs is not explored for app review\nclassification Objective: We investigate the benefits of PTMs for app review\nclassification compared to the existing models, as well as the transferability\nof PTMs in multiple settings. Method: We empirically study the accuracy and\ntime efficiency of PTMs compared to prior approaches using six datasets from\nliterature. In addition, we investigate the performance of the PTMs trained on\napp reviews (i.e. domain-specific PTMs) . We set up different studies to\nevaluate PTMs in multiple settings: binary vs. multi-class classification,\nzero-shot classification (when new labels are introduced to the model),\nmulti-task setting, and classification of reviews from different resources. The\ndatasets are manually labeled app review datasets from Google Play Store, Apple\nApp Store, and Twitter data. In all cases, Micro and Macro Precision, Recall,\nand F1-scores will be used and we will report the time required for training\nand prediction with the models.\n", "versions": [{"version": "v1", "created": "Mon, 12 Apr 2021 23:23:45 GMT"}, {"version": "v2", "created": "Fri, 23 Apr 2021 16:53:01 GMT"}], "update_date": "2021-04-26", "authors_parsed": [["Hadi", "Mohammad Abdul", ""], ["Fard", "Fatemeh H.", ""]]}, {"id": "2104.05866", "submitter": "Angelika Romanou", "authors": "Angelika Romanou, Panayiotis Smeros, Karl Aberer", "title": "On Representation Learning for Scientific News Articles Using\n  Heterogeneous Knowledge Graphs", "comments": null, "journal-ref": null, "doi": "10.1145/3442442.3451362", "report-no": null, "categories": "cs.SI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In the era of misinformation and information inflation, the credibility\nassessment of the produced news is of the essence. However, fact-checking can\nbe challenging considering the limited references presented in the news. This\nchallenge can be transcended by utilizing the knowledge graph that is related\nto the news articles. In this work, we present a methodology for creating\nscientific news article representations by modeling the directed graph between\nthe scientific news articles and the cited scientific publications. The network\nused for the experiments is comprised of the scientific news articles, their\ntopic, the cited research literature, and their corresponding authors. We\nimplement and present three different approaches: 1) a baseline Relational\nGraph Convolutional Network (R-GCN), 2) a Heterogeneous Graph Neural Network\n(HetGNN) and 3) a Heterogeneous Graph Transformer (HGT). We test these models\nin the downstream task of link prediction on the: a) news article - paper links\nand b) news article - article topic links. The results show promising\napplications of graph neural network approaches in the domains of knowledge\ntracing and scientific news credibility assessment.\n", "versions": [{"version": "v1", "created": "Mon, 12 Apr 2021 23:46:54 GMT"}], "update_date": "2021-04-14", "authors_parsed": [["Romanou", "Angelika", ""], ["Smeros", "Panayiotis", ""], ["Aberer", "Karl", ""]]}, {"id": "2104.05868", "submitter": "Andrew Arrasmith", "authors": "Andrew Arrasmith, Zo\\\"e Holmes, M. Cerezo, Patrick J. Coles", "title": "Equivalence of quantum barren plateaus to cost concentration and narrow\n  gorges", "comments": "12 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": "LA-UR-21-23454", "categories": "quant-ph cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optimizing parameterized quantum circuits (PQCs) is the leading approach to\nmake use of near-term quantum computers. However, very little is known about\nthe cost function landscape for PQCs, which hinders progress towards\nquantum-aware optimizers. In this work, we investigate the connection between\nthree different landscape features that have been observed for PQCs: (1)\nexponentially vanishing gradients (called barren plateaus), (2) exponential\ncost concentration about the mean, and (3) the exponential narrowness of minina\n(called narrow gorges). We analytically prove that these three phenomena occur\ntogether, i.e., when one occurs then so do the other two. A key implication of\nthis result is that one can numerically diagnose barren plateaus via cost\ndifferences rather than via the computationally more expensive gradients. More\nbroadly, our work shows that quantum mechanics rules out certain cost\nlandscapes (which otherwise would be mathematically possible), and hence our\nresults are interesting from a quantum foundations perspective.\n", "versions": [{"version": "v1", "created": "Mon, 12 Apr 2021 23:52:16 GMT"}], "update_date": "2021-04-14", "authors_parsed": [["Arrasmith", "Andrew", ""], ["Holmes", "Zo\u00eb", ""], ["Cerezo", "M.", ""], ["Coles", "Patrick J.", ""]]}, {"id": "2104.05878", "submitter": "James Martens", "authors": "James Martens", "title": "On the validity of kernel approximations for orthogonally-initialized\n  neural networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this note we extend kernel function approximation results for neural\nnetworks with Gaussian-distributed weights to single-layer networks initialized\nusing Haar-distributed random orthogonal matrices (with possible rescaling).\nThis is accomplished using recent results from random matrix theory.\n", "versions": [{"version": "v1", "created": "Tue, 13 Apr 2021 00:57:39 GMT"}], "update_date": "2021-04-14", "authors_parsed": [["Martens", "James", ""]]}, {"id": "2104.05888", "submitter": "Xingjian Zhen", "authors": "Xingjian Zhen, Rudrasis Chakraborty, Vikas Singh", "title": "Simpler Certified Radius Maximization by Propagating Covariances", "comments": "This paper has been accepted by CVPR 2021 as an oral presentation. An\n  introduction video can be found: https://youtu.be/m1ya2oNf5iE", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One strategy for adversarially training a robust model is to maximize its\ncertified radius -- the neighborhood around a given training sample for which\nthe model's prediction remains unchanged. The scheme typically involves\nanalyzing a \"smoothed\" classifier where one estimates the prediction\ncorresponding to Gaussian samples in the neighborhood of each sample in the\nmini-batch, accomplished in practice by Monte Carlo sampling. In this paper, we\ninvestigate the hypothesis that this sampling bottleneck can potentially be\nmitigated by identifying ways to directly propagate the covariance matrix of\nthe smoothed distribution through the network. To this end, we find that other\nthan certain adjustments to the network, propagating the covariances must also\nbe accompanied by additional accounting that keeps track of how the\ndistributional moments transform and interact at each stage in the network. We\nshow how satisfying these criteria yields an algorithm for maximizing the\ncertified radius on datasets including Cifar-10, ImageNet, and Places365 while\noffering runtime savings on networks with moderate depth, with a small\ncompromise in overall accuracy. We describe the details of the key\nmodifications that enable practical use. Via various experiments, we evaluate\nwhen our simplifications are sensible, and what the key benefits and\nlimitations are.\n", "versions": [{"version": "v1", "created": "Tue, 13 Apr 2021 01:38:36 GMT"}], "update_date": "2021-04-14", "authors_parsed": [["Zhen", "Xingjian", ""], ["Chakraborty", "Rudrasis", ""], ["Singh", "Vikas", ""]]}, {"id": "2104.05889", "submitter": "Shumit Saha", "authors": "Zabir Al Nazi, Fazla Rabbi Mashrur, Md Amirul Islam, Shumit Saha", "title": "Fibro-CoSANet: Pulmonary Fibrosis Prognosis Prediction using a\n  Convolutional Self Attention Network", "comments": "12 Pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Idiopathic pulmonary fibrosis (IPF) is a restrictive interstitial lung\ndisease that causes lung function decline by lung tissue scarring. Although\nlung function decline is assessed by the forced vital capacity (FVC),\ndetermining the accurate progression of IPF remains a challenge. To address\nthis challenge, we proposed Fibro-CoSANet, a novel end-to-end multi-modal\nlearning-based approach, to predict the FVC decline. Fibro-CoSANet utilized CT\nimages and demographic information in convolutional neural network frameworks\nwith a stacked attention layer. Extensive experiments on the OSIC Pulmonary\nFibrosis Progression Dataset demonstrated the superiority of our proposed\nFibro-CoSANet by achieving the new state-of-the-art modified Laplace\nLog-Likelihood score of -6.68. This network may benefit research areas\nconcerned with designing networks to improve the prognostic accuracy of IPF.\nThe source-code for Fibro-CoSANet is available at:\n\\url{https://github.com/zabir-nabil/Fibro-CoSANet}.\n", "versions": [{"version": "v1", "created": "Tue, 13 Apr 2021 01:44:08 GMT"}], "update_date": "2021-04-14", "authors_parsed": [["Nazi", "Zabir Al", ""], ["Mashrur", "Fazla Rabbi", ""], ["Islam", "Md Amirul", ""], ["Saha", "Shumit", ""]]}, {"id": "2104.05892", "submitter": "Jong Chul Ye", "authors": "Yujin Oh and Jong Chul Ye", "title": "Unifying domain adaptation and self-supervised learning for CXR\n  segmentation via AdaIN-based knowledge distillation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As the segmentation labels are scarce, extensive researches have been\nconducted to train segmentation networks without labels or with only limited\nlabels. In particular, domain adaptation, self-supervised learning, and\nteacher-student architecture have been introduced to distill knowledge from\nvarious tasks to improve the segmentation performance. However, these\napproaches appear different from each other, so it is not clear how these\nseemingly different approaches can be combined for better performance. Inspired\nby the recent StarGANv2 for multi-domain image translation, here we propose a\nnovel segmentation framework via AdaIN-based knowledge distillation, where a\nsingle generator with AdaIN layers is trained along with the AdaIN code\ngenerator and style encoder so that the generator can perform both domain\nadaptation and segmentation. Specifically, our framework is designed to deal\nwith difficult situations in chest X-ray (CXR) segmentation tasks where\nsegmentation masks are only available for normal CXR data, but the trained\nmodel should be applied for both normal and abnormal CXR images. Since a single\ngenerator is used for abnormal to normal domain conversion and segmentation by\nsimply changing the AdaIN codes, the generator can synergistically learn the\ncommon features to improve segmentation performance. Experimental results using\nCXR data confirm that the trained network can achieve the state-of-the art\nsegmentation performance for both normal and abnormal CXR images.\n", "versions": [{"version": "v1", "created": "Tue, 13 Apr 2021 01:53:04 GMT"}, {"version": "v2", "created": "Fri, 23 Apr 2021 14:54:50 GMT"}], "update_date": "2021-04-26", "authors_parsed": [["Oh", "Yujin", ""], ["Ye", "Jong Chul", ""]]}, {"id": "2104.05902", "submitter": "Haotian Liu", "authors": "Haotian Liu, Wenchuan Wu", "title": "Bi-level Off-policy Reinforcement Learning for Volt/VAR Control\n  Involving Continuous and Discrete Devices", "comments": "10 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.AI cs.LG cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In Volt/Var control (VVC) of active distribution networks(ADNs), both slow\ntimescale discrete devices (STDDs) and fast timescale continuous devices\n(FTCDs) are involved. The STDDs such as on-load tap changers (OLTC) and FTCDs\nsuch as distributed generators should be coordinated in time sequence. Such VCC\nis formulated as a two-timescale optimization problem to jointly optimize FTCDs\nand STDDs in ADNs. Traditional optimization methods are heavily based on\naccurate models of the system, but sometimes impractical because of their\nunaffordable effort on modelling. In this paper, a novel bi-level off-policy\nreinforcement learning (RL) algorithm is proposed to solve this problem in a\nmodel-free manner. A Bi-level Markov decision process (BMDP) is defined to\ndescribe the two-timescale VVC problem and separate agents are set up for the\nslow and fast timescale sub-problems. For the fast timescale sub-problem, we\nadopt an off-policy RL method soft actor-critic with high sample efficiency.\nFor the slow one, we develop an off-policy multi-discrete soft actor-critic\n(MDSAC) algorithm to address the curse of dimensionality with various STDDs. To\nmitigate the non-stationary issue existing the two agents' learning processes,\nwe propose a multi-timescale off-policy correction (MTOPC) method by adopting\nimportance sampling technique. Comprehensive numerical studies not only\ndemonstrate that the proposed method can achieve stable and satisfactory\noptimization of both STDDs and FTCDs without any model information, but also\nsupport that the proposed method outperforms existing two-timescale VVC\nmethods.\n", "versions": [{"version": "v1", "created": "Tue, 13 Apr 2021 02:22:43 GMT"}], "update_date": "2021-04-14", "authors_parsed": [["Liu", "Haotian", ""], ["Wu", "Wenchuan", ""]]}, {"id": "2104.05914", "submitter": "Yang Li", "authors": "Yang Li, Di Wang, and Jos\\'e M. F. Moura", "title": "GSA-Forecaster: Forecasting Graph-Based Time-Dependent Data with Graph\n  Sequence Attention", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Forecasting graph-based time-dependent data has many practical applications.\nThis task is challenging as models need not only to capture spatial dependency\nand temporal dependency within the data, but also to leverage useful auxiliary\ninformation for accurate predictions. In this paper, we analyze limitations of\nstate-of-the-art models on dealing with temporal dependency. To address this\nlimitation, we propose GSA-Forecaster, a new deep learning model for\nforecasting graph-based time-dependent data. GSA-Forecaster leverages graph\nsequence attention (GSA), a new attention mechanism proposed in this paper, for\neffectively capturing temporal dependency. GSA-Forecaster embeds the graph\nstructure of the data into its architecture to address spatial dependency.\nGSA-Forecaster also accounts for auxiliary information to further improve\npredictions. We evaluate GSA-Forecaster with large-scale real-world graph-based\ntime-dependent data and demonstrate its effectiveness over state-of-the-art\nmodels with 6.7% RMSE and 5.8% MAPE reduction.\n", "versions": [{"version": "v1", "created": "Tue, 13 Apr 2021 03:19:10 GMT"}], "update_date": "2021-04-14", "authors_parsed": [["Li", "Yang", ""], ["Wang", "Di", ""], ["Moura", "Jos\u00e9 M. F.", ""]]}, {"id": "2104.05915", "submitter": "Rohitash Chandra", "authors": "Rohitash Chandra, Mahir Jain, Manavendra Maharana, Pavel N. Krivitsky", "title": "Revisiting Bayesian Autoencoders with MCMC", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.AP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Autoencoders gained popularity in the deep learning revolution given their\nability to compress data and provide dimensionality reduction. Although\nprominent deep learning methods have been used to enhance autoencoders, the\nneed to provide robust uncertainty quantification remains a challenge. This has\nbeen addressed with variational autoencoders so far. Bayesian inference via\nMCMC methods have faced limitations but recent advances with parallel computing\nand advanced proposal schemes that incorporate gradients have opened routes\nless travelled. In this paper, we present Bayesian autoencoders powered MCMC\nsampling implemented using parallel computing and Langevin gradient proposal\nscheme. Our proposed Bayesian autoencoder provides similar performance accuracy\nwhen compared to related methods from the literature, with the additional\nfeature of robust uncertainty quantification in compressed datasets. This\nmotivates further application of the Bayesian autoencoder framework for other\ndeep learning models.\n", "versions": [{"version": "v1", "created": "Tue, 13 Apr 2021 03:23:07 GMT"}], "update_date": "2021-04-14", "authors_parsed": [["Chandra", "Rohitash", ""], ["Jain", "Mahir", ""], ["Maharana", "Manavendra", ""], ["Krivitsky", "Pavel N.", ""]]}, {"id": "2104.05921", "submitter": "Xinyi Zhang", "authors": "Xinyi Zhang, Chengfang Fang, Jie Shi", "title": "Thief, Beware of What Get You There: Towards Understanding Model\n  Extraction Attack", "comments": "8 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model extraction increasingly attracts research attentions as keeping\ncommercial AI models private can retain a competitive advantage. In some\nscenarios, AI models are trained proprietarily, where neither pre-trained\nmodels nor sufficient in-distribution data is publicly available. Model\nextraction attacks against these models are typically more devastating.\nTherefore, in this paper, we empirically investigate the behaviors of model\nextraction under such scenarios. We find the effectiveness of existing\ntechniques significantly affected by the absence of pre-trained models. In\naddition, the impacts of the attacker's hyperparameters, e.g. model\narchitecture and optimizer, as well as the utilities of information retrieved\nfrom queries, are counterintuitive. We provide some insights on explaining the\npossible causes of these phenomena. With these observations, we formulate model\nextraction attacks into an adaptive framework that captures these factors with\ndeep reinforcement learning. Experiments show that the proposed framework can\nbe used to improve existing techniques, and show that model extraction is still\npossible in such strict scenarios. Our research can help system designers to\nconstruct better defense strategies based on their scenarios.\n", "versions": [{"version": "v1", "created": "Tue, 13 Apr 2021 03:46:59 GMT"}], "update_date": "2021-04-14", "authors_parsed": [["Zhang", "Xinyi", ""], ["Fang", "Chengfang", ""], ["Shi", "Jie", ""]]}, {"id": "2104.05928", "submitter": "James Evans", "authors": "Brendan Chambers and James Evans", "title": "Semantic maps and metrics for science Semantic maps and metrics for\n  science using deep transformer encoders", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The growing deluge of scientific publications demands text analysis tools\nthat can help scientists and policy-makers navigate, forecast and beneficially\nguide scientific research. Recent advances in natural language understanding\ndriven by deep transformer networks offer new possibilities for mapping\nscience. Because the same surface text can take on multiple and sometimes\ncontradictory specialized senses across distinct research communities,\nsensitivity to context is critical for infometric applications. Transformer\nembedding models such as BERT capture shades of association and connotation\nthat vary across the different linguistic contexts of any particular word or\nspan of text. Here we report a procedure for encoding scientific documents with\nthese tools, measuring their improvement over static word embeddings in a\nnearest-neighbor retrieval task. We find discriminability of contextual\nrepresentations is strongly influenced by choice of pooling strategy for\nsummarizing the high-dimensional network activations. Importantly, we note that\nfundamentals such as domain-matched training data are more important than\nstate-of-the-art NLP tools. Yet state-of-the-art models did offer significant\ngains. The best approach we investigated combined domain-matched pretraining,\nsound pooling, and state-of-the-art deep transformer network encoders. Finally,\nwith the goal of leveraging contextual representations from deep encoders, we\npresent a range of measurements for understanding and forecasting research\ncommunities in science.\n", "versions": [{"version": "v1", "created": "Tue, 13 Apr 2021 04:12:20 GMT"}], "update_date": "2021-04-14", "authors_parsed": [["Chambers", "Brendan", ""], ["Evans", "James", ""]]}, {"id": "2104.05929", "submitter": "Mohammad Nazmul Haque", "authors": "Pablo Moscato, Hugh Craig, Gabriel Egan, Mohammad Nazmul Haque, Kevin\n  Huang, Julia Sloan, Jon Corrales de Oliveira", "title": "Multiple regression techniques for modeling dates of first performances\n  of Shakespeare-era plays", "comments": "Submitted to Expert Systems with Applications", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  The date of the first performance of a play of Shakespeare's time must\nusually be guessed with reference to multiple indirect external sources, or to\nsome aspect of the content or style of the play. Identifying these dates is\nimportant to literary history and to accounts of developing authorial styles,\nsuch as Shakespeare's. In this study, we took a set of Shakespeare-era plays\n(181 plays from the period 1585--1610), added the best-guess dates for them\nfrom a standard reference work as metadata, and calculated a set of\nprobabilities of individual words in these samples. We applied 11 regression\nmethods to predict the dates of the plays at an 80/20 training/test split. We\nwithdrew one play at a time, used the best-guess date metadata with the\nprobabilities and weightings to infer its date, and thus built a model of\ndate-probabilities interaction. We introduced a memetic algorithm-based\nContinued Fraction Regression (CFR) which delivered models using a small number\nof variables, leading to an interpretable model and reduced dimensionality. An\nin-depth analysis of the most commonly occurring 20 words in the CFR models in\n100 independent runs helps explain the trends in linguistic and stylistic\nterms. The analysis with the subset of words revealed an interesting\ncorrelation of signature words with the Shakespeare-era play's genre.\n", "versions": [{"version": "v1", "created": "Tue, 13 Apr 2021 04:13:53 GMT"}, {"version": "v2", "created": "Wed, 14 Apr 2021 23:37:45 GMT"}], "update_date": "2021-04-16", "authors_parsed": [["Moscato", "Pablo", ""], ["Craig", "Hugh", ""], ["Egan", "Gabriel", ""], ["Haque", "Mohammad Nazmul", ""], ["Huang", "Kevin", ""], ["Sloan", "Julia", ""], ["de Oliveira", "Jon Corrales", ""]]}, {"id": "2104.05930", "submitter": "Brenden Petersen", "authors": "Joanne T. Kim, Mikel Landajuela Larma, Brenden K. Petersen", "title": "Distilling Wikipedia mathematical knowledge into neural network models", "comments": "6 pages, 4 figures", "journal-ref": "1st Mathematical Reasoning in General Artificial Intelligence\n  Workshop, ICLR 2021", "doi": null, "report-no": "LLNL-CONF-820039", "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning applications to symbolic mathematics are becoming\nincreasingly popular, yet there lacks a centralized source of real-world\nsymbolic expressions to be used as training data. In contrast, the field of\nnatural language processing leverages resources like Wikipedia that provide\nenormous amounts of real-world textual data. Adopting the philosophy of\n\"mathematics as language,\" we bridge this gap by introducing a pipeline for\ndistilling mathematical expressions embedded in Wikipedia into symbolic\nencodings to be used in downstream machine learning tasks. We demonstrate that\na $\\textit{mathematical}$ $\\textit{language}$ $\\textit{model}$ trained on this\n\"corpus\" of expressions can be used as a prior to improve the performance of\nneural-guided search for the task of symbolic regression.\n", "versions": [{"version": "v1", "created": "Tue, 13 Apr 2021 04:16:50 GMT"}], "update_date": "2021-04-14", "authors_parsed": [["Kim", "Joanne T.", ""], ["Larma", "Mikel Landajuela", ""], ["Petersen", "Brenden K.", ""]]}, {"id": "2104.05932", "submitter": "Shubham Shrivastava", "authors": "Shubham Shrivastava", "title": "VR3Dense: Voxel Representation Learning for 3D Object Detection and\n  Monocular Dense Depth Reconstruction", "comments": "7 pages, 4 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  3D object detection and dense depth estimation are one of the most vital\ntasks in autonomous driving. Multiple sensor modalities can jointly attribute\ntowards better robot perception, and to that end, we introduce a method for\njointly training 3D object detection and monocular dense depth reconstruction\nneural networks. It takes as inputs, a LiDAR point-cloud, and a single RGB\nimage during inference and produces object pose predictions as well as a\ndensely reconstructed depth map. LiDAR point-cloud is converted into a set of\nvoxels, and its features are extracted using 3D convolution layers, from which\nwe regress object pose parameters. Corresponding RGB image features are\nextracted using another 2D convolutional neural network. We further use these\ncombined features to predict a dense depth map. While our object detection is\ntrained in a supervised manner, the depth prediction network is trained with\nboth self-supervised and supervised loss functions. We also introduce a loss\nfunction, edge-preserving smooth loss, and show that this results in better\ndepth estimation compared to the edge-aware smooth loss function, frequently\nused in depth prediction works.\n", "versions": [{"version": "v1", "created": "Tue, 13 Apr 2021 04:25:54 GMT"}], "update_date": "2021-04-14", "authors_parsed": [["Shrivastava", "Shubham", ""]]}, {"id": "2104.05942", "submitter": "Ian Manchester", "authors": "Max Revay, Ruigang Wang, Ian R. Manchester", "title": "Recurrent Equilibrium Networks: Flexible Dynamic Models with Guaranteed\n  Stability and Robustness", "comments": "Journal submission, extended version of conference paper (v1 of this\n  arxiv preprint)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SY math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces recurrent equilibrium networks (RENs), a new class of\nnonlinear dynamical models for applications in machine learning, system\nidentification and control. The new model class has ``built in'' guarantees of\nstability and robustness: all models in the class are contracting - a strong\nform of nonlinear stability - and models can satisfy prescribed incremental\nintegral quadratic constraints (IQC), including Lipschitz bounds and\nincremental passivity. RENs are otherwise very flexible: they can represent all\nstable linear systems, all previously-known sets of contracting recurrent\nneural networks and echo state networks, all deep feedforward neural networks,\nand all stable Wiener/Hammerstein models. RENs are parameterized directly by a\nvector in R^N, i.e. stability and robustness are ensured without parameter\nconstraints, which simplifies learning since generic methods for unconstrained\noptimization can be used. The performance and robustness of the new model set\nis evaluated on benchmark nonlinear system identification problems, and the\npaper also presents applications in data-driven nonlinear observer design and\ncontrol with stability guarantees.\n", "versions": [{"version": "v1", "created": "Tue, 13 Apr 2021 05:09:41 GMT"}, {"version": "v2", "created": "Tue, 13 Jul 2021 05:30:44 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Revay", "Max", ""], ["Wang", "Ruigang", ""], ["Manchester", "Ian R.", ""]]}, {"id": "2104.05959", "submitter": "Yunsheng Tian", "authors": "Yunsheng Tian, Mina Konakovi\\'c Lukovi\\'c, Timothy Erps, Michael\n  Foshey, Wojciech Matusik", "title": "AutoOED: Automated Optimal Experiment Design Platform", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present AutoOED, an Optimal Experiment Design platform powered with\nautomated machine learning to accelerate the discovery of optimal solutions.\nThe platform solves multi-objective optimization problems in time- and\ndata-efficient manner by automatically guiding the design of experiments to be\nevaluated. To automate the optimization process, we implement several\nmulti-objective Bayesian optimization algorithms with state-of-the-art\nperformance. AutoOED is open-source and written in Python. The codebase is\nmodular, facilitating extensions and tailoring the code, serving as a testbed\nfor machine learning researchers to easily develop and evaluate their own\nmulti-objective Bayesian optimization algorithms. An intuitive graphical user\ninterface (GUI) is provided to visualize and guide the experiments for users\nwith little or no experience with coding, machine learning, or optimization.\nFurthermore, a distributed system is integrated to enable parallelized\nexperimental evaluations by independent workers in remote locations. The\nplatform is available at https://autooed.org.\n", "versions": [{"version": "v1", "created": "Tue, 13 Apr 2021 06:20:54 GMT"}], "update_date": "2021-04-14", "authors_parsed": [["Tian", "Yunsheng", ""], ["Lukovi\u0107", "Mina Konakovi\u0107", ""], ["Erps", "Timothy", ""], ["Foshey", "Michael", ""], ["Matusik", "Wojciech", ""]]}, {"id": "2104.05960", "submitter": "Ning Liu", "authors": "Ning Liu, Songlei Jian, Dongsheng Li, Yiming Zhang, Zhiquan Lai,\n  Hongzuo Xu", "title": "Hierarchical Adaptive Pooling by Capturing High-order Dependency for\n  Graph Representation Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NI cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph neural networks (GNN) have been proven to be mature enough for handling\ngraph-structured data on node-level graph representation learning tasks.\nHowever, the graph pooling technique for learning expressive graph-level\nrepresentation is critical yet still challenging. Existing pooling methods\neither struggle to capture the local substructure or fail to effectively\nutilize high-order dependency, thus diminishing the expression capability. In\nthis paper we propose HAP, a hierarchical graph-level representation learning\nframework, which is adaptively sensitive to graph structures, i.e., HAP\nclusters local substructures incorporating with high-order dependencies. HAP\nutilizes a novel cross-level attention mechanism MOA to naturally focus more on\nclose neighborhood while effectively capture higher-order dependency that may\ncontain crucial information. It also learns a global graph content GCont that\nextracts the graph pattern properties to make the pre- and post-coarsening\ngraph content maintain stable, thus providing global guidance in graph\ncoarsening. This novel innovation also facilitates generalization across graphs\nwith the same form of features. Extensive experiments on fourteen datasets show\nthat HAP significantly outperforms twelve popular graph pooling methods on\ngraph classification task with an maximum accuracy improvement of 22.79%, and\nexceeds the performance of state-of-the-art graph matching and graph similarity\nlearning algorithms by over 3.5% and 16.7%.\n", "versions": [{"version": "v1", "created": "Tue, 13 Apr 2021 06:22:24 GMT"}], "update_date": "2021-04-14", "authors_parsed": [["Liu", "Ning", ""], ["Jian", "Songlei", ""], ["Li", "Dongsheng", ""], ["Zhang", "Yiming", ""], ["Lai", "Zhiquan", ""], ["Xu", "Hongzuo", ""]]}, {"id": "2104.05978", "submitter": "Djamila Aouada", "authors": "Mohamed Adel Musallam, Kassem Al Ismaeil, Oyebade Oyedotun, Marcos\n  Damian Perez, Michel Poucet, Djamila Aouada", "title": "SPARK: SPAcecraft Recognition leveraging Knowledge of Space Environment", "comments": "5 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This paper proposes the SPARK dataset as a new unique space object\nmulti-modal image dataset. Image-based object recognition is an important\ncomponent of Space Situational Awareness, especially for applications such as\non-orbit servicing, active debris removal, and satellite formation. However,\nthe lack of sufficient annotated space data has limited research efforts in\ndeveloping data-driven spacecraft recognition approaches. The SPARK dataset has\nbeen generated under a realistic space simulation environment, with a large\ndiversity in sensing conditions for different orbital scenarios. It provides\nabout 150k images per modality, RGB and depth, and 11 classes for spacecrafts\nand debris. This dataset offers an opportunity to benchmark and further develop\nobject recognition, classification and detection algorithms, as well as\nmulti-modal RGB-Depth approaches under space sensing conditions. Preliminary\nexperimental evaluation validates the relevance of the data, and highlights\ninteresting challenging scenarios specific to the space environment.\n", "versions": [{"version": "v1", "created": "Tue, 13 Apr 2021 07:16:55 GMT"}, {"version": "v2", "created": "Wed, 14 Apr 2021 01:58:18 GMT"}], "update_date": "2021-04-15", "authors_parsed": [["Musallam", "Mohamed Adel", ""], ["Ismaeil", "Kassem Al", ""], ["Oyedotun", "Oyebade", ""], ["Perez", "Marcos Damian", ""], ["Poucet", "Michel", ""], ["Aouada", "Djamila", ""]]}, {"id": "2104.05988", "submitter": "Marcel B\\\"uhler", "authors": "Marcel C. B\\\"uhler (1), Abhimitra Meka (2), Gengyan Li (1 and 2),\n  Thabo Beeler (2), Otmar Hilliges (1) ((1) ETH Zurich, (2) Google)", "title": "VariTex: Variational Neural Face Textures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.GR cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Deep generative models have recently demonstrated the ability to synthesize\nphotorealistic images of human faces with novel identities. A key challenge to\nthe wide applicability of such techniques is to provide independent control\nover semantically meaningful parameters: appearance, head pose, face shape, and\nfacial expressions. In this paper, we propose VariTex - to the best of our\nknowledge the first method that learns a variational latent feature space of\nneural face textures, which allows sampling of novel identities. We combine\nthis generative model with a parametric face model and gain explicit control\nover head pose and facial expressions. To generate images of complete human\nheads, we propose an additive decoder that generates plausible additional\ndetails such as hair. A novel training scheme enforces a pose independent\nlatent space and in consequence, allows learning of a one-to-many mapping\nbetween latent codes and pose-conditioned exterior regions. The resulting\nmethod can generate geometrically consistent images of novel identities\nallowing fine-grained control over head pose, face shape, and facial\nexpressions, facilitating a broad range of downstream tasks, like sampling\nnovel identities, re-posing, expression transfer, and more.\n", "versions": [{"version": "v1", "created": "Tue, 13 Apr 2021 07:47:53 GMT"}, {"version": "v2", "created": "Wed, 23 Jun 2021 17:24:03 GMT"}], "update_date": "2021-06-24", "authors_parsed": [["B\u00fchler", "Marcel C.", "", "ETH Zurich"], ["Meka", "Abhimitra", "", "Google"], ["Li", "Gengyan", "", "1 and 2"], ["Beeler", "Thabo", "", "Google"], ["Hilliges", "Otmar", "", "ETH Zurich"]]}, {"id": "2104.05991", "submitter": "Nicol\\'as Gallego", "authors": "Nicol\\'as Gallego-Molina, Marco Formoso, Andr\\'es Ortiz, Francisco J.\n  Mart\\'inez-Murcia, Juan L. Luque", "title": "Temporal EigenPAC for dyslexia diagnosis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Electroencephalography signals allow to explore the functional activity of\nthe brain cortex in a non-invasive way. However, the analysis of these signals\nis not straightforward due to the presence of different artifacts and the very\nlow signal-to-noise ratio. Cross-Frequency Coupling (CFC) methods provide a way\nto extract information from EEG, related to the synchronization among frequency\nbands. However, CFC methods are usually applied in a local way, computing the\ninteraction between phase and amplitude at the same electrode. In this work we\nshow a method to compute PAC features among electrodes to study the functional\nconnectivity. Moreover, this has been applied jointly with Principal Component\nAnalysis to explore patterns related to Dyslexia in 7-years-old children. The\ndeveloped methodology reveals the temporal evolution of PAC-based connectivity.\nDirections of greatest variance computed by PCA are called eigenPACs here,\nsince they resemble the classical \\textit{eigenfaces} representation. The\nprojection of PAC data onto the eigenPACs provide a set of features that has\ndemonstrates their discriminative capability, specifically in the Beta-Gamma\nbands.\n", "versions": [{"version": "v1", "created": "Tue, 13 Apr 2021 07:51:07 GMT"}], "update_date": "2021-04-14", "authors_parsed": [["Gallego-Molina", "Nicol\u00e1s", ""], ["Formoso", "Marco", ""], ["Ortiz", "Andr\u00e9s", ""], ["Mart\u00ednez-Murcia", "Francisco J.", ""], ["Luque", "Juan L.", ""]]}, {"id": "2104.05996", "submitter": "Luca Pajola", "authors": "Luca Pajola and Mauro Conti", "title": "Fall of Giants: How popular text-based MLaaS fall against a simple\n  evasion attack", "comments": "Accepted to appear in the Proceedings of the 2021 IEEE European\n  Symposium on Security and Privacy (EUROS&P)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The increased demand for machine learning applications made companies offer\nMachine-Learning-as-a-Service (MLaaS). In MLaaS (a market estimated 8000M USD\nby 2025), users pay for well-performing ML models without dealing with the\ncomplicated training procedure. Among MLaaS, text-based applications are the\nmost popular ones (e.g., language translators). Given this popularity, MLaaS\nmust provide resiliency to adversarial manipulations. For example, a wrong\ntranslation might lead to a misunderstanding between two parties. In the text\ndomain, state-of-the-art attacks mainly focus on strategies that leverage ML\nmodels' weaknesses. Unfortunately, not much attention has been given to the\nother pipeline' stages, such as the indexing stage (i.e., when a sentence is\nconverted from a textual to a numerical representation) that, if manipulated,\ncan significantly affect the final performance of the application.\n  In this paper, we propose a novel text evasion technique called\n\"\\textit{Zero-Width} attack\" (ZeW) that leverages the injection of human\nnon-readable characters, affecting indexing stage mechanisms. We demonstrate\nthat our simple yet effective attack deceives MLaaS of \"giants\" such as Amazon,\nGoogle, IBM, and Microsoft. Our case study, based on the manipulation of\nhateful tweets, shows that out of 12 analyzed services, only one is resistant\nto our injection strategy. We finally introduce and test a simple \\textit{input\nvalidation} defense that can prevent our proposed attack.\n", "versions": [{"version": "v1", "created": "Tue, 13 Apr 2021 08:01:19 GMT"}], "update_date": "2021-04-14", "authors_parsed": [["Pajola", "Luca", ""], ["Conti", "Mauro", ""]]}, {"id": "2104.05997", "submitter": "Johannes Christiaan Myburgh", "authors": "Johannes C. Myburgh, Coenraad Mouton, Marelie H. Davel", "title": "Tracking translation invariance in CNNs", "comments": null, "journal-ref": "Artificial Intelligence Research (2020) 282-295", "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although Convolutional Neural Networks (CNNs) are widely used, their\ntranslation invariance (ability to deal with translated inputs) is still\nsubject to some controversy. We explore this question using\ntranslation-sensitivity maps to quantify how sensitive a standard CNN is to a\ntranslated input. We propose the use of Cosine Similarity as sensitivity metric\nover Euclidean Distance, and discuss the importance of restricting the\ndimensionality of either of these metrics when comparing architectures. Our\nmain focus is to investigate the effect of different architectural components\nof a standard CNN on that network's sensitivity to translation. By varying\nconvolutional kernel sizes and amounts of zero padding, we control the size of\nthe feature maps produced, allowing us to quantify the extent to which these\nelements influence translation invariance. We also measure translation\ninvariance at different locations within the CNN to determine the extent to\nwhich convolutional and fully connected layers, respectively, contribute to the\ntranslation invariance of a CNN as a whole. Our analysis indicates that both\nconvolutional kernel size and feature map size have a systematic influence on\ntranslation invariance. We also see that convolutional layers contribute less\nthan expected to translation invariance, when not specifically forced to do so.\n", "versions": [{"version": "v1", "created": "Tue, 13 Apr 2021 08:05:56 GMT"}, {"version": "v2", "created": "Mon, 19 Apr 2021 09:14:21 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Myburgh", "Johannes C.", ""], ["Mouton", "Coenraad", ""], ["Davel", "Marelie H.", ""]]}, {"id": "2104.06010", "submitter": "Timothy Praditia", "authors": "Timothy Praditia, Matthias Karlbauer, Sebastian Otte, Sergey\n  Oladyshkin, Martin V. Butz, Wolfgang Nowak", "title": "Finite Volume Neural Network: Modeling Subsurface Contaminant Transport", "comments": "Published as a workshop paper at ICLR 2021 SimDL Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Data-driven modeling of spatiotemporal physical processes with general deep\nlearning methods is a highly challenging task. It is further exacerbated by the\nlimited availability of data, leading to poor generalizations in standard\nneural network models. To tackle this issue, we introduce a new approach called\nthe Finite Volume Neural Network (FINN). The FINN method adopts the numerical\nstructure of the well-known Finite Volume Method for handling partial\ndifferential equations, so that each quantity of interest follows its own\nadaptable conservation law, while it concurrently accommodates learnable\nparameters. As a result, FINN enables better handling of fluxes between control\nvolumes and therefore proper treatment of different types of numerical boundary\nconditions. We demonstrate the effectiveness of our approach with a subsurface\ncontaminant transport problem, which is governed by a non-linear\ndiffusion-sorption process. FINN does not only generalize better to differing\nboundary conditions compared to other methods, it is also capable to explicitly\nextract and learn the constitutive relationships (expressed by the retardation\nfactor). More importantly, FINN shows excellent generalization ability when\napplied to both synthetic datasets and real, sparse experimental data, thus\nunderlining its relevance as a data-driven modeling tool.\n", "versions": [{"version": "v1", "created": "Tue, 13 Apr 2021 08:23:44 GMT"}], "update_date": "2021-04-14", "authors_parsed": [["Praditia", "Timothy", ""], ["Karlbauer", "Matthias", ""], ["Otte", "Sebastian", ""], ["Oladyshkin", "Sergey", ""], ["Butz", "Martin V.", ""], ["Nowak", "Wolfgang", ""]]}, {"id": "2104.06011", "submitter": "Ying Cui", "authors": "Chencheng Ye, Ying Cui", "title": "Sample-based and Feature-based Federated Learning via Mini-batch SSCA", "comments": "18 pages, 4 figures. arXiv admin note: substantial text overlap with\n  arXiv:2103.09506", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to the resource consumption for transmitting massive data and the concern\nfor exposing sensitive data, it is impossible or undesirable to upload clients'\nlocal databases to a central server. Thus, federated learning has become a hot\nresearch area in enabling the collaborative training of machine learning models\namong multiple clients that hold sensitive local data. Nevertheless,\nunconstrained federated optimization has been studied mainly using stochastic\ngradient descent (SGD), which may converge slowly, and constrained federated\noptimization, which is more challenging, has not been investigated so far. This\npaper investigates sample-based and feature-based federated optimization,\nrespectively, and considers both the unconstrained problem and the constrained\nproblem for each of them. We propose federated learning algorithms using\nstochastic successive convex approximation (SSCA) and mini-batch techniques. We\nshow that the proposed algorithms can preserve data privacy through the model\naggregation mechanism, and their security can be enhanced via additional\nprivacy mechanisms. We also show that the proposed algorithms converge to\nKarush-Kuhn-Tucker (KKT) points of the respective federated optimization\nproblems. Besides, we customize the proposed algorithms to application examples\nand show that all updates have closed-form expressions. Finally, numerical\nexperiments demonstrate the inherent advantages of the proposed algorithms in\nconvergence speeds, communication costs, and model specifications.\n", "versions": [{"version": "v1", "created": "Tue, 13 Apr 2021 08:23:46 GMT"}], "update_date": "2021-04-14", "authors_parsed": [["Ye", "Chencheng", ""], ["Cui", "Ying", ""]]}, {"id": "2104.06014", "submitter": "William Ljungbergh", "authors": "Georg Hess and William Ljungbergh", "title": "Deep Deterministic Path Following", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper deploys the Deep Deterministic Policy Gradient (DDPG) algorithm\nfor longitudinal and lateral control of a simulated car to solve a path\nfollowing task. The DDPG agent was implemented using PyTorch and trained and\nevaluated on a custom kinematic bicycle environment created in Python. The\nperformance was evaluated by measuring cross-track error and velocity error,\nrelative to a reference path. Results show how the agent can learn a policy\nallowing for small cross-track error, as well as adapting the acceleration to\nminimize the velocity error.\n", "versions": [{"version": "v1", "created": "Tue, 13 Apr 2021 08:30:53 GMT"}], "update_date": "2021-04-14", "authors_parsed": [["Hess", "Georg", ""], ["Ljungbergh", "William", ""]]}, {"id": "2104.06022", "submitter": "Sho Takase", "authors": "Sho Takase and Shun Kiyono", "title": "Lessons on Parameter Sharing across Layers in Transformers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a parameter sharing method for Transformers (Vaswani et al.,\n2017). The proposed approach relaxes a widely used technique, which shares\nparameters for one layer with all layers such as Universal Transformers\n(Dehghani et al., 2019), to increase the efficiency in the computational time.\nWe propose three strategies: Sequence, Cycle, and Cycle (rev) to assign\nparameters to each layer. Experimental results show that the proposed\nstrategies are efficient in the parameter size and computational time.\nMoreover, we indicate that the proposed strategies are also effective in the\nconfiguration where we use many training data such as the recent WMT\ncompetition.\n", "versions": [{"version": "v1", "created": "Tue, 13 Apr 2021 08:41:07 GMT"}], "update_date": "2021-04-14", "authors_parsed": [["Takase", "Sho", ""], ["Kiyono", "Shun", ""]]}, {"id": "2104.06039", "submitter": "Alon Talmor", "authors": "Alon Talmor, Ori Yoran, Amnon Catav, Dan Lahav, Yizhong Wang, Akari\n  Asai, Gabriel Ilharco, Hannaneh Hajishirzi, Jonathan Berant", "title": "MultiModalQA: Complex Question Answering over Text, Tables and Images", "comments": "ICLR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When answering complex questions, people can seamlessly combine information\nfrom visual, textual and tabular sources. While interest in models that reason\nover multiple pieces of evidence has surged in recent years, there has been\nrelatively little work on question answering models that reason across multiple\nmodalities. In this paper, we present MultiModalQA(MMQA): a challenging\nquestion answering dataset that requires joint reasoning over text, tables and\nimages. We create MMQA using a new framework for generating complex multi-modal\nquestions at scale, harvesting tables from Wikipedia, and attaching images and\ntext paragraphs using entities that appear in each table. We then define a\nformal language that allows us to take questions that can be answered from a\nsingle modality, and combine them to generate cross-modal questions. Last,\ncrowdsourcing workers take these automatically-generated questions and rephrase\nthem into more fluent language. We create 29,918 questions through this\nprocedure, and empirically demonstrate the necessity of a multi-modal multi-hop\napproach to solve our task: our multi-hop model, ImplicitDecomp, achieves an\naverage F1of 51.7 over cross-modal questions, substantially outperforming a\nstrong baseline that achieves 38.2 F1, but still lags significantly behind\nhuman performance, which is at 90.1 F1\n", "versions": [{"version": "v1", "created": "Tue, 13 Apr 2021 09:14:28 GMT"}], "update_date": "2021-04-14", "authors_parsed": [["Talmor", "Alon", ""], ["Yoran", "Ori", ""], ["Catav", "Amnon", ""], ["Lahav", "Dan", ""], ["Wang", "Yizhong", ""], ["Asai", "Akari", ""], ["Ilharco", "Gabriel", ""], ["Hajishirzi", "Hannaneh", ""], ["Berant", "Jonathan", ""]]}, {"id": "2104.06040", "submitter": "Ioannis Mollas", "authors": "Ioannis Mollas, Nick Bassiliades, Grigorios Tsoumakas", "title": "Conclusive Local Interpretation Rules for Random Forests", "comments": "32 pages, 31 figures, 4 Tables, submitted to data mining and\n  knowledge discovery journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In critical situations involving discrimination, gender inequality, economic\ndamage, and even the possibility of casualties, machine learning models must be\nable to provide clear interpretations for their decisions. Otherwise, their\nobscure decision-making processes can lead to socioethical issues as they\ninterfere with people's lives. In the aforementioned sectors, random forest\nalgorithms strive, thus their ability to explain themselves is an obvious\nrequirement. In this paper, we present LionForests, which relies on a\npreliminary work of ours. LionForests is a random forest-specific\ninterpretation technique, which provides rules as explanations. It is\napplicable from binary classification tasks to multi-class classification and\nregression tasks, and it is supported by a stable theoretical background.\nExperimentation, including sensitivity analysis and comparison with\nstate-of-the-art techniques, is also performed to demonstrate the efficacy of\nour contribution. Finally, we highlight a unique property of LionForests,\ncalled conclusiveness, that provides interpretation validity and distinguishes\nit from previous techniques.\n", "versions": [{"version": "v1", "created": "Tue, 13 Apr 2021 09:15:23 GMT"}], "update_date": "2021-04-14", "authors_parsed": [["Mollas", "Ioannis", ""], ["Bassiliades", "Nick", ""], ["Tsoumakas", "Grigorios", ""]]}, {"id": "2104.06045", "submitter": "Vincent Micheli", "authors": "Vincent Micheli, Quentin Heinrich, Fran\\c{c}ois Fleuret, Wacim\n  Belblidia", "title": "Structural analysis of an all-purpose question answering model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Attention is a key component of the now ubiquitous pre-trained language\nmodels. By learning to focus on relevant pieces of information, these\nTransformer-based architectures have proven capable of tackling several tasks\nat once and sometimes even surpass their single-task counterparts. To better\nunderstand this phenomenon, we conduct a structural analysis of a new\nall-purpose question answering model that we introduce. Surprisingly, this\nmodel retains single-task performance even in the absence of a strong transfer\neffect between tasks. Through attention head importance scoring, we observe\nthat attention heads specialize in a particular task and that some heads are\nmore conducive to learning than others in both the multi-task and single-task\nsettings.\n", "versions": [{"version": "v1", "created": "Tue, 13 Apr 2021 09:20:44 GMT"}], "update_date": "2021-04-14", "authors_parsed": [["Micheli", "Vincent", ""], ["Heinrich", "Quentin", ""], ["Fleuret", "Fran\u00e7ois", ""], ["Belblidia", "Wacim", ""]]}, {"id": "2104.06046", "submitter": "Yingfang Yuan", "authors": "Yingfang Yuan, Wenjun Wang, Wei Pang", "title": "Which Hyperparameters to Optimise? An Investigation of Evolutionary\n  Hyperparameter Optimisation in Graph Neural Network For Molecular Property\n  Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recently, the study of graph neural network (GNN) has attracted much\nattention and achieved promising performance in molecular property prediction.\nMost GNNs for molecular property prediction are proposed based on the idea of\nlearning the representations for the nodes by aggregating the information of\ntheir neighbor nodes (e.g. atoms). Then, the representations can be passed to\nsubsequent layers to deal with individual downstream tasks. Therefore, the\narchitectures of GNNs can be considered as being composed of two core parts:\ngraph-related layers and task-specific layers. Facing real-world molecular\nproblems, the hyperparameter optimization for those layers are vital.\nHyperparameter optimization (HPO) becomes expensive in this situation because\nevaluating candidate solutions requires massive computational resources to\ntrain and validate models. Furthermore, a larger search space often makes the\nHPO problems more challenging. In this research, we focus on the impact of\nselecting two types of GNN hyperparameters, those belonging to graph-related\nlayers and those of task-specific layers, on the performance of GNN for\nmolecular property prediction. In our experiments. we employed a\nstate-of-the-art evolutionary algorithm (i.e., CMA-ES) for HPO. The results\nreveal that optimizing the two types of hyperparameters separately can gain the\nimprovements on GNNs' performance, but optimising both types of hyperparameters\nsimultaneously will lead to predominant improvements. Meanwhile, our study also\nfurther confirms the importance of HPO for GNNs in molecular property\nprediction problems.\n", "versions": [{"version": "v1", "created": "Tue, 13 Apr 2021 09:21:27 GMT"}, {"version": "v2", "created": "Wed, 14 Apr 2021 09:45:54 GMT"}], "update_date": "2021-04-15", "authors_parsed": [["Yuan", "Yingfang", ""], ["Wang", "Wenjun", ""], ["Pang", "Wei", ""]]}, {"id": "2104.06050", "submitter": "Anant Shah", "authors": "Anant Shah and Arun Rajkumar", "title": "Sequential Ski Rental Problem", "comments": "Accepted at AAMAS 2021, Added proof of Theorem 3. Updated argument in\n  Theorem 6", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The classical 'buy or rent' ski-rental problem was recently considered in the\nsetting where multiple experts (such as Machine Learning algorithms) advice on\nthe length of the ski season. Here, robust algorithms were developed with\nimproved theoretical performance over adversarial scenarios where such expert\npredictions were unavailable. We consider a variant of this problem which we\ncall the 'sequential ski-rental' problem. Here, a sequence of ski-rental\nproblems has to be solved in an online fashion where both the buy cost and the\nlength of the ski season are unknown to the learner. The learner has access to\ntwo sets of experts, one set who advise on the true cost of buying the ski and\nanother set who advise on the length of the ski season. Under certain\nstochastic assumptions on the experts who predict the buy costs, we develop\nonline algorithms and prove regret bounds for the same. Our experimental\nevaluations confirm our theoretical results.\n", "versions": [{"version": "v1", "created": "Tue, 13 Apr 2021 09:28:17 GMT"}, {"version": "v2", "created": "Tue, 20 Apr 2021 20:09:58 GMT"}], "update_date": "2021-04-22", "authors_parsed": [["Shah", "Anant", ""], ["Rajkumar", "Arun", ""]]}, {"id": "2104.06057", "submitter": "Ioannis Mollas", "authors": "Ioannis Mollas, Nick Bassiliades, Grigorios Tsoumakas", "title": "LioNets: A Neural-Specific Local Interpretation Technique Exploiting\n  Penultimate Layer Information", "comments": "23 pages, 22 figures, 2 tables, submitted to Information Fusion\n  Journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial Intelligence (AI) has a tremendous impact on the unexpected growth\nof technology in almost every aspect. AI-powered systems are monitoring and\ndeciding about sensitive economic and societal issues. The future is towards\nautomation, and it must not be prevented. However, this is a conflicting\nviewpoint for a lot of people, due to the fear of uncontrollable AI systems.\nThis concern could be reasonable if it was originating from considerations\nassociated with social issues, like gender-biased, or obscure decision-making\nsystems. Explainable AI (XAI) is recently treated as a huge step towards\nreliable systems, enhancing the trust of people to AI. Interpretable machine\nlearning (IML), a subfield of XAI, is also an urgent topic of research. This\npaper presents a small but significant contribution to the IML community,\nfocusing on a local-based, neural-specific interpretation process applied to\ntextual and time-series data. The proposed methodology introduces new\napproaches to the presentation of feature importance based interpretations, as\nwell as the production of counterfactual words on textual datasets. Eventually,\nan improved evaluation metric is introduced for the assessment of\ninterpretation techniques, which supports an extensive set of qualitative and\nquantitative experiments.\n", "versions": [{"version": "v1", "created": "Tue, 13 Apr 2021 09:39:33 GMT"}], "update_date": "2021-04-14", "authors_parsed": [["Mollas", "Ioannis", ""], ["Bassiliades", "Nick", ""], ["Tsoumakas", "Grigorios", ""]]}, {"id": "2104.06060", "submitter": "Marco Virgolin", "authors": "Marco Virgolin, Andrea De Lorenzo, Francesca Randone, Eric Medvet,\n  Mattias Wahde", "title": "Model Learning with Personalized Interpretability Estimation (ML-PIE)", "comments": "fix typos", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  High-stakes applications require AI-generated models to be interpretable.\nCurrent algorithms for the synthesis of potentially interpretable models rely\non objectives or regularization terms that represent interpretability only\ncoarsely (e.g., model size) and are not designed for a specific user. Yet,\ninterpretability is intrinsically subjective. In this paper, we propose an\napproach for the synthesis of models that are tailored to the user by enabling\nthe user to steer the model synthesis process according to her or his\npreferences. We use a bi-objective evolutionary algorithm to synthesize models\nwith trade-offs between accuracy and a user-specific notion of\ninterpretability. The latter is estimated by a neural network that is trained\nconcurrently to the evolution using the feedback of the user, which is\ncollected using uncertainty-based active learning. To maximize usability, the\nuser is only asked to tell, given two models at the time, which one is less\ncomplex. With experiments on two real-world datasets involving 61 participants,\nwe find that our approach is capable of learning estimations of\ninterpretability that can be very different for different users. Moreover, the\nusers tend to prefer models found using the proposed approach over models found\nusing non-personalized interpretability indices.\n", "versions": [{"version": "v1", "created": "Tue, 13 Apr 2021 09:47:48 GMT"}, {"version": "v2", "created": "Wed, 14 Apr 2021 10:43:12 GMT"}, {"version": "v3", "created": "Tue, 27 Apr 2021 08:52:36 GMT"}], "update_date": "2021-04-28", "authors_parsed": [["Virgolin", "Marco", ""], ["De Lorenzo", "Andrea", ""], ["Randone", "Francesca", ""], ["Medvet", "Eric", ""], ["Wahde", "Mattias", ""]]}, {"id": "2104.06069", "submitter": "Conglong Li", "authors": "Conglong Li, Ammar Ahmad Awan, Hanlin Tang, Samyam Rajbhandari,\n  Yuxiong He", "title": "1-bit LAMB: Communication Efficient Large-Scale Large-Batch Training\n  with LAMB's Convergence Speed", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  To train large models (like BERT and GPT-3) with hundreds or even thousands\nof GPUs, the communication has become a major bottleneck, especially on\ncommodity systems with limited-bandwidth TCP interconnects network. On one side\nlarge-batch optimization such as LAMB algorithm was proposed to reduce the\nnumber of communications. On the other side, communication compression\nalgorithms such as 1-bit SGD and 1-bit Adam help to reduce the volume of each\ncommunication. However, we find that simply using one of the techniques is not\nsufficient to solve the communication challenge, especially on low-bandwidth\nEthernet networks. Motivated by this we aim to combine the power of large-batch\noptimization and communication compression, but we find that existing\ncompression strategies cannot be directly applied to LAMB due to its unique\nadaptive layerwise learning rates. To this end, we design a new\ncommunication-efficient algorithm, 1-bit LAMB, which introduces a novel way to\nsupport adaptive layerwise learning rates even when communication is\ncompressed. In addition, we introduce a new system implementation for\ncompressed communication using the NCCL backend of PyTorch distributed, which\nimproves both usability and performance compared to existing MPI-based\nimplementation. For BERT-Large pre-training task with batch sizes from 8K to\n64K, our evaluations on up to 256 GPUs demonstrate that 1-bit LAMB with\nNCCL-based backend is able to achieve up to 4.6x communication volume\nreduction, up to 2.8x end-to-end speedup (in terms of number of training\nsamples per second), and the same convergence speed (in terms of number of\npre-training samples to reach the same accuracy on fine-tuning tasks) compared\nto uncompressed LAMB.\n", "versions": [{"version": "v1", "created": "Tue, 13 Apr 2021 10:07:49 GMT"}], "update_date": "2021-04-14", "authors_parsed": [["Li", "Conglong", ""], ["Awan", "Ammar Ahmad", ""], ["Tang", "Hanlin", ""], ["Rajbhandari", "Samyam", ""], ["He", "Yuxiong", ""]]}, {"id": "2104.06070", "submitter": "Zahra Gharaee", "authors": "Zahra Gharaee and Peter G\\\"ardenfors and Magnus Johnsson", "title": "Online Recognition of Actions Involving Objects", "comments": null, "journal-ref": null, "doi": "10.1016/j.bica.2017.09.007", "report-no": null, "categories": "cs.RO cs.CV cs.HC cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We present an online system for real time recognition of actions involving\nobjects working in online mode. The system merges two streams of information\nprocessing running in parallel. One is carried out by a hierarchical\nself-organizing map (SOM) system that recognizes the performed actions by\nanalysing the spatial trajectories of the agent's movements. It consists of two\nlayers of SOMs and a custom made supervised neural network. The activation\nsequences in the first layer SOM represent the sequences of significant\npostures of the agent during the performance of actions. These activation\nsequences are subsequently recoded and clustered in the second layer SOM, and\nthen labeled by the activity in the third layer custom made supervised neural\nnetwork. The second information processing stream is carried out by a second\nsystem that determines which object among several in the agent's vicinity the\naction is applied to. This is achieved by applying a proximity measure. The\npresented method combines the two information processing streams to determine\nwhat action the agent performed and on what object. The action recognition\nsystem has been tested with excellent performance.\n", "versions": [{"version": "v1", "created": "Tue, 13 Apr 2021 10:08:20 GMT"}], "update_date": "2021-04-14", "authors_parsed": [["Gharaee", "Zahra", ""], ["G\u00e4rdenfors", "Peter", ""], ["Johnsson", "Magnus", ""]]}, {"id": "2104.06074", "submitter": "Shijun Wang", "authors": "Shijun Wang and Damian Borth", "title": "NoiseVC: Towards High Quality Zero-Shot Voice Conversion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Voice conversion (VC) is a task that transforms voice from target audio to\nsource without losing linguistic contents, it is challenging especially when\nsource and target speakers are unseen during training (zero-shot VC). Previous\napproaches require a pre-trained model or linguistic data to do the zero-shot\nconversion. Meanwhile, VC models with Vector Quantization (VQ) or Instance\nNormalization (IN) are able to disentangle contents from audios and achieve\nsuccessful conversions. However, disentanglement in these models highly relies\non heavily constrained bottleneck layers, thus, the sound quality is\ndrastically sacrificed. In this paper, we propose NoiseVC, an approach that can\ndisentangle contents based on VQ and Contrastive Predictive Coding (CPC).\nAdditionally, Noise Augmentation is performed to further enhance\ndisentanglement capability. We conduct several experiments and demonstrate that\nNoiseVC has a strong disentanglement ability with a small sacrifice of quality.\n", "versions": [{"version": "v1", "created": "Tue, 13 Apr 2021 10:12:38 GMT"}], "update_date": "2021-04-14", "authors_parsed": [["Wang", "Shijun", ""], ["Borth", "Damian", ""]]}, {"id": "2104.06135", "submitter": "Nis Meinert", "authors": "Nis Meinert and Alexander Lavin", "title": "Multivariate Deep Evidential Regression", "comments": "20 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  There is significant need for principled uncertainty reasoning in machine\nlearning systems as they are increasingly deployed in safety-critical domains.\nA new approach with uncertainty-aware neural networks (NNs), based on learning\nevidential distributions for aleatoric and epistemic uncertainties, shows\npromise over traditional deterministic methods and typical Bayesian NNs, yet\nseveral important gaps in the theory and implementation of these networks\nremain. We discuss three issues with a proposed solution to extract aleatoric\nand epistemic uncertainties from regression-based neural networks. The approach\nderives a technique by placing evidential priors over the original Gaussian\nlikelihood function and training the NN to infer the hyperparameters of the\nevidential distribution. Doing so allows for the simultaneous extraction of\nboth uncertainties without sampling or utilization of out-of-distribution data\nfor univariate regression tasks. We describe the outstanding issues in detail,\nprovide a possible solution, and generalize the deep evidential regression\ntechnique for multivariate cases.\n", "versions": [{"version": "v1", "created": "Tue, 13 Apr 2021 12:20:18 GMT"}, {"version": "v2", "created": "Thu, 15 Apr 2021 12:47:38 GMT"}, {"version": "v3", "created": "Mon, 31 May 2021 07:41:18 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Meinert", "Nis", ""], ["Lavin", "Alexander", ""]]}, {"id": "2104.06139", "submitter": "Yiping Xie", "authors": "Chao Xu, Yiping Xie, Xijun Wang, Howard H. Yang, Dusit Niyato, Tony Q.\n  S. Quek", "title": "Optimizing the Long-Term Average Reward for Continuing MDPs: A Technical\n  Report", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT cs.NI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, we have struck the balance between the information freshness, in\nterms of age of information (AoI), experienced by users and energy consumed by\nsensors, by appropriately activating sensors to update their current status in\ncaching enabled Internet of Things (IoT) networks [1]. To solve this problem,\nwe cast the corresponding status update procedure as a continuing Markov\nDecision Process (MDP) (i.e., without termination states), where the number of\nstate-action pairs increases exponentially with respect to the number of\nconsidered sensors and users. Moreover, to circumvent the curse of\ndimensionality, we have established a methodology for designing deep\nreinforcement learning (DRL) algorithms to maximize (resp. minimize) the\naverage reward (resp. cost), by integrating R-learning, a tabular reinforcement\nlearning (RL) algorithm tailored for maximizing the long-term average reward,\nand traditional DRL algorithms, initially developed to optimize the discounted\nlong-term cumulative reward rather than the average one. In this technical\nreport, we would present detailed discussions on the technical contributions of\nthis methodology.\n", "versions": [{"version": "v1", "created": "Tue, 13 Apr 2021 12:29:55 GMT"}, {"version": "v2", "created": "Wed, 14 Apr 2021 10:32:18 GMT"}], "update_date": "2021-04-15", "authors_parsed": [["Xu", "Chao", ""], ["Xie", "Yiping", ""], ["Wang", "Xijun", ""], ["Yang", "Howard H.", ""], ["Niyato", "Dusit", ""], ["Quek", "Tony Q. S.", ""]]}, {"id": "2104.06153", "submitter": "Karim Huesmann", "authors": "Karim Huesmann, Luis Garcia Rodriguez, Lars Linsen, and Benjamin Risse", "title": "The Impact of Activation Sparsity on Overfitting in Convolutional Neural\n  Networks", "comments": null, "journal-ref": "Pattern Recognition. ICPR International Workshops and Challenges\n  (2021) 130-145", "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Overfitting is one of the fundamental challenges when training convolutional\nneural networks and is usually identified by a diverging training and test\nloss. The underlying dynamics of how the flow of activations induce overfitting\nis however poorly understood. In this study we introduce a perplexity-based\nsparsity definition to derive and visualise layer-wise activation measures.\nThese novel explainable AI strategies reveal a surprising relationship between\nactivation sparsity and overfitting, namely an increase in sparsity in the\nfeature extraction layers shortly before the test loss starts rising. This\ntendency is preserved across network architectures and reguralisation\nstrategies so that our measures can be used as a reliable indicator for\noverfitting while decoupling the network's generalisation capabilities from its\nloss-based definition. Moreover, our differentiable sparsity formulation can be\nused to explicitly penalise the emergence of sparsity during training so that\nthe impact of reduced sparsity on overfitting can be studied in real-time.\nApplying this penalty and analysing activation sparsity for well known\nregularisers and in common network architectures supports the hypothesis that\nreduced activation sparsity can effectively improve the generalisation and\nclassification performance. In line with other recent work on this topic, our\nmethods reveal novel insights into the contradicting concepts of activation\nsparsity and network capacity by demonstrating that dense activations can\nenable discriminative feature learning while efficiently exploiting the\ncapacity of deep models without suffering from overfitting, even when trained\nexcessively.\n", "versions": [{"version": "v1", "created": "Tue, 13 Apr 2021 12:55:37 GMT"}], "update_date": "2021-04-14", "authors_parsed": [["Huesmann", "Karim", ""], ["Rodriguez", "Luis Garcia", ""], ["Linsen", "Lars", ""], ["Risse", "Benjamin", ""]]}, {"id": "2104.06159", "submitter": "Ivo Danihelka", "authors": "Matteo Hessel, Ivo Danihelka, Fabio Viola, Arthur Guez, Simon Schmitt,\n  Laurent Sifre, Theophane Weber, David Silver, Hado van Hasselt", "title": "Muesli: Combining Improvements in Policy Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel policy update that combines regularized policy\noptimization with model learning as an auxiliary loss. The update (henceforth\nMuesli) matches MuZero's state-of-the-art performance on Atari. Notably, Muesli\ndoes so without using deep search: it acts directly with a policy network and\nhas computation speed comparable to model-free baselines. The Atari results are\ncomplemented by extensive ablations, and by additional results on continuous\ncontrol and 9x9 Go.\n", "versions": [{"version": "v1", "created": "Tue, 13 Apr 2021 13:04:29 GMT"}], "update_date": "2021-04-14", "authors_parsed": [["Hessel", "Matteo", ""], ["Danihelka", "Ivo", ""], ["Viola", "Fabio", ""], ["Guez", "Arthur", ""], ["Schmitt", "Simon", ""], ["Sifre", "Laurent", ""], ["Weber", "Theophane", ""], ["Silver", "David", ""], ["van Hasselt", "Hado", ""]]}, {"id": "2104.06163", "submitter": "Takato Okudo", "authors": "Takato Okudo and Seiji Yamada", "title": "Reward Shaping with Dynamic Trajectory Aggregation", "comments": "accepted by The International Joint Conference on Neural\n  Networks(IJCNN2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Reinforcement learning, which acquires a policy maximizing long-term rewards,\nhas been actively studied. Unfortunately, this learning type is too slow and\ndifficult to use in practical situations because the state-action space becomes\nhuge in real environments. The essential factor for learning efficiency is\nrewards. Potential-based reward shaping is a basic method for enriching\nrewards. This method is required to define a specific real-value function\ncalled a potential function for every domain. It is often difficult to\nrepresent the potential function directly. SARSA-RS learns the potential\nfunction and acquires it. However, SARSA-RS can only be applied to the simple\nenvironment. The bottleneck of this method is the aggregation of states to make\nabstract states since it is almost impossible for designers to build an\naggregation function for all states. We propose a trajectory aggregation that\nuses subgoal series. This method dynamically aggregates states in an episode\nduring trial and error with only the subgoal series and subgoal identification\nfunction. It makes designer effort minimal and the application to environments\nwith high-dimensional observations possible. We obtained subgoal series from\nparticipants for experiments. We conducted the experiments in three domains,\nfour-rooms(discrete states and discrete actions), pinball(continuous and\ndiscrete), and picking(both continuous). We compared our method with a baseline\nreinforcement learning algorithm and other subgoal-based methods, including\nrandom subgoal and naive subgoal-based reward shaping. As a result, our reward\nshaping outperformed all other methods in learning efficiency.\n", "versions": [{"version": "v1", "created": "Tue, 13 Apr 2021 13:07:48 GMT"}], "update_date": "2021-04-14", "authors_parsed": [["Okudo", "Takato", ""], ["Yamada", "Seiji", ""]]}, {"id": "2104.06164", "submitter": "Jacopo Teneggi", "authors": "Jacopo Teneggi, Alexandre Luster, Jeremias Sulam", "title": "Fast Hierarchical Games for Image Explanations", "comments": "20 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As modern complex neural networks keep breaking records and solving harder\nproblems, their predictions also become less and less intelligible. The current\nlack of interpretability often undermines the deployment of accurate machine\nlearning tools in sensitive settings. In this work, we present a model-agnostic\nexplanation method for image classification based on a hierarchical extension\nof Shapley coefficients --Hierarchical Shap (h-Shap)-- that resolves some of\nthe limitations of current approaches. Unlike other Shapley-based explanation\nmethods, h-Shap is scalable and can be computed without the need of\napproximation. Under certain distributional assumptions, such as those common\nin multiple instance learning, h-Shap retrieves the exact Shapley coefficients\nwith an exponential improvement in computational complexity. We compare our\nhierarchical approach with popular Shapley-based and non-Shapley-based methods\non a synthetic dataset, a medical imaging scenario, and a general computer\nvision problem, showing that h-Shap outperforms the state of the art in both\naccuracy and runtime. Code and experiments are made publicly available.\n", "versions": [{"version": "v1", "created": "Tue, 13 Apr 2021 13:11:02 GMT"}], "update_date": "2021-04-14", "authors_parsed": [["Teneggi", "Jacopo", ""], ["Luster", "Alexandre", ""], ["Sulam", "Jeremias", ""]]}, {"id": "2104.06176", "submitter": "Pedro Ricardo Ariel Salvador Bassi", "authors": "Pedro R. A. S. Bassi, Romis Attux", "title": "COVID-19 detection using chest X-rays: is lung segmentation important\n  for generalization?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  We evaluated the generalization capability of deep neural networks (DNNs),\ntrained to classify chest X-rays as COVID-19, normal or pneumonia, using a\nrelatively small and mixed dataset.\n  We proposed a DNN architecture to perform lung segmentation and\nclassification. It stacks a segmentation module (U-Net), an original\nintermediate module and a classification module (DenseNet201). We compared it\nto a DenseNet201.\n  To evaluate generalization, we tested the DNNs with an external dataset (from\ndistinct localities) and used Bayesian inference to estimate the probability\ndistributions of performance metrics, like F1-Score.\n  Our proposed DNN achieved 0.917 AUC on the external test dataset, and the\nDenseNet, 0.906. Bayesian inference indicated mean accuracy of 76.1% and\n[0.695, 0.826] 95% HDI with segmentation and, without segmentation, 71.7% and\n[0.646, 0.786].\n  We proposed a novel DNN evaluation technique, using Layer-wise Relevance\nPropagation (LRP) and the Brixia score. LRP heatmaps indicated that areas where\nradiologists found strong COVID-19 symptoms and attributed high Brixia scores\nare the most important for the stacked DNN classification.\n  External validation showed smaller accuracies than internal validation,\nindicating dataset bias, which segmentation reduces. Performance in the\nexternal dataset and LRP analysis suggest that DNNs can be trained in small and\nmixed datasets and detect COVID-19.\n", "versions": [{"version": "v1", "created": "Mon, 12 Apr 2021 09:06:28 GMT"}], "update_date": "2021-04-14", "authors_parsed": [["Bassi", "Pedro R. A. S.", ""], ["Attux", "Romis", ""]]}, {"id": "2104.06182", "submitter": "Jose Manuel Gomez-Perez", "authors": "Andres Garcia-Silva, Cristian Berrio, Jose Manuel Gomez-Perez", "title": "Understanding Transformers for Bot Detection in Twitter", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we shed light on the impact of fine-tuning over social media\ndata in the internal representations of neural language models. We focus on bot\ndetection in Twitter, a key task to mitigate and counteract the automatic\nspreading of disinformation and bias in social media. We investigate the use of\npre-trained language models to tackle the detection of tweets generated by a\nbot or a human account based exclusively on its content. Unlike the general\ntrend in benchmarks like GLUE, where BERT generally outperforms generative\ntransformers like GPT and GPT-2 for most classification tasks on regular text,\nwe observe that fine-tuning generative transformers on a bot detection task\nproduces higher accuracies. We analyze the architectural components of each\ntransformer and study the effect of fine-tuning on their hidden states and\noutput representations. Among our findings, we show that part of the\nsyntactical information and distributional properties captured by BERT during\npre-training is lost upon fine-tuning while the generative pre-training\napproach manage to preserve these properties.\n", "versions": [{"version": "v1", "created": "Tue, 13 Apr 2021 13:32:55 GMT"}], "update_date": "2021-04-14", "authors_parsed": [["Garcia-Silva", "Andres", ""], ["Berrio", "Cristian", ""], ["Gomez-Perez", "Jose Manuel", ""]]}, {"id": "2104.06204", "submitter": "Qin Luo", "authors": "Qin Luo, Kun Fang, Jie Yang, Xiaolin Huang", "title": "Towards Unbiased Random Features with Lower Variance For Stationary\n  Indefinite Kernels", "comments": "Accepted by IJCNN2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Random Fourier Features (RFF) demonstrate wellappreciated performance in\nkernel approximation for largescale situations but restrict kernels to be\nstationary and positive definite. And for non-stationary kernels, the\ncorresponding RFF could be converted to that for stationary indefinite kernels\nwhen the inputs are restricted to the unit sphere. Numerous methods provide\naccessible ways to approximate stationary but indefinite kernels. However, they\nare either biased or possess large variance. In this article, we propose the\ngeneralized orthogonal random features, an unbiased estimation with lower\nvariance.Experimental results on various datasets and kernels verify that our\nalgorithm achieves lower variance and approximation error compared with the\nexisting kernel approximation methods. With better approximation to the\noriginally selected kernels, improved classification accuracy and regression\nability is obtained with our approximation algorithm in the framework of\nsupport vector machine and regression.\n", "versions": [{"version": "v1", "created": "Tue, 13 Apr 2021 13:56:50 GMT"}, {"version": "v2", "created": "Wed, 14 Apr 2021 00:54:53 GMT"}], "update_date": "2021-04-15", "authors_parsed": [["Luo", "Qin", ""], ["Fang", "Kun", ""], ["Yang", "Jie", ""], ["Huang", "Xiaolin", ""]]}, {"id": "2104.06214", "submitter": "Zhe Zhou", "authors": "Zhe Zhou, Bizhao Shi, Zhe Zhang, Yijin Guan, Guangyu Sun, Guojie Luo", "title": "BlockGNN: Towards Efficient GNN Acceleration Using Block-Circulant\n  Weight Matrices", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.AR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, Graph Neural Networks (GNNs) appear to be state-of-the-art\nalgorithms for analyzing non-euclidean graph data. By applying deep-learning to\nextract high-level representations from graph structures, GNNs achieve\nextraordinary accuracy and great generalization ability in various tasks.\nHowever, with the ever-increasing graph sizes, more and more complicated GNN\nlayers, and higher feature dimensions, the computational complexity of GNNs\ngrows exponentially. How to inference GNNs in real time has become a\nchallenging problem, especially for some resource-limited edge-computing\nplatforms.\n  To tackle this challenge, we propose BlockGNN, a software-hardware co-design\napproach to realize efficient GNN acceleration. At the algorithm level, we\npropose to leverage block-circulant weight matrices to greatly reduce the\ncomplexity of various GNN models. At the hardware design level, we propose a\npipelined CirCore architecture, which supports efficient block-circulant\nmatrices computation. Basing on CirCore, we present a novel BlockGNN\naccelerator to compute various GNNs with low latency. Moreover, to determine\nthe optimal configurations for diverse deployed tasks, we also introduce a\nperformance and resource model that helps choose the optimal hardware\nparameters automatically. Comprehensive experiments on the ZC706 FPGA platform\ndemonstrate that on various GNN tasks, BlockGNN achieves up to $8.3\\times$\nspeedup compared to the baseline HyGCN architecture and $111.9\\times$ energy\nreduction compared to the Intel Xeon CPU platform.\n", "versions": [{"version": "v1", "created": "Tue, 13 Apr 2021 14:09:22 GMT"}, {"version": "v2", "created": "Fri, 25 Jun 2021 16:43:09 GMT"}], "update_date": "2021-06-28", "authors_parsed": [["Zhou", "Zhe", ""], ["Shi", "Bizhao", ""], ["Zhang", "Zhe", ""], ["Guan", "Yijin", ""], ["Sun", "Guangyu", ""], ["Luo", "Guojie", ""]]}, {"id": "2104.06219", "submitter": "Hubert P. H. Shum", "authors": "Daniel Organisciak, Brian K. S. Isaac-Medina, Matthew Poyser, Shanfeng\n  Hu, Toby P. Breckon, Hubert P. H. Shum", "title": "UAV-ReID: A Benchmark on Unmanned Aerial Vehicle Re-identification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As unmanned aerial vehicles (UAVs) become more accessible with a growing\nrange of applications, the potential risk of UAV disruption increases. Recent\ndevelopment in deep learning allows vision-based counter-UAV systems to detect\nand track UAVs with a single camera. However, the coverage of a single camera\nis limited, necessitating the need for multicamera configurations to match UAVs\nacross cameras - a problem known as re-identification (reID). While there has\nbeen extensive research on person and vehicle reID to match objects across time\nand viewpoints, to the best of our knowledge, there has been no research in UAV\nreID. UAVs are challenging to re-identify: they are much smaller than\npedestrians and vehicles and they are often detected in the air so appear at a\ngreater range of angles. Because no UAV data sets currently use multiple\ncameras, we propose the first new UAV re-identification data set, UAV-reID,\nthat facilitates the development of machine learning solutions in this emerging\narea. UAV-reID has two settings: Temporally-Near to evaluate performance across\nviews to assist tracking frameworks, and Big-to-Small to evaluate reID\nperformance across scale and to allow early reID when UAVs are detected from a\nlong distance. We conduct a benchmark study by extensively evaluating different\nreID backbones and loss functions. We demonstrate that with the right setup,\ndeep networks are powerful enough to learn good representations for UAVs,\nachieving 81.9% mAP on the Temporally-Near setting and 46.5% on the challenging\nBig-to-Small setting. Furthermore, we find that vision transformers are the\nmost robust to extreme variance of scale.\n", "versions": [{"version": "v1", "created": "Tue, 13 Apr 2021 14:13:09 GMT"}], "update_date": "2021-04-14", "authors_parsed": [["Organisciak", "Daniel", ""], ["Isaac-Medina", "Brian K. S.", ""], ["Poyser", "Matthew", ""], ["Hu", "Shanfeng", ""], ["Breckon", "Toby P.", ""], ["Shum", "Hubert P. H.", ""]]}, {"id": "2104.06237", "submitter": "Micha\\\"el Defferrard", "authors": "Jelena Banjac, Laur\\`ene Donati, Micha\\\"el Defferrard", "title": "Learning to recover orientations from projections in single-particle\n  cryo-EM", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV q-bio.QM stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A major challenge in single-particle cryo-electron microscopy (cryo-EM) is\nthat the orientations adopted by the 3D particles prior to imaging are unknown;\nyet, this knowledge is essential for high-resolution reconstruction. We present\na method to recover these orientations directly from the acquired set of 2D\nprojections. Our approach consists of two steps: (i) the estimation of\ndistances between pairs of projections, and (ii) the recovery of the\norientation of each projection from these distances. In step (i), pairwise\ndistances are estimated by a Siamese neural network trained on synthetic\ncryo-EM projections from resolved bio-structures. In step (ii), orientations\nare recovered by minimizing the difference between the distances estimated from\nthe projections and the distances induced by the recovered orientations. We\nevaluated the method on synthetic cryo-EM datasets. Current results demonstrate\nthat orientations can be accurately recovered from projections that are shifted\nand corrupted with a high level of noise. The accuracy of the recovery depends\non the accuracy of the distance estimator. While not yet deployed in a real\nexperimental setup, the proposed method offers a novel learning-based take on\norientation recovery in SPA. Our code is available at\nhttps://github.com/JelenaBanjac/protein-reconstruction\n", "versions": [{"version": "v1", "created": "Tue, 13 Apr 2021 14:31:37 GMT"}], "update_date": "2021-04-14", "authors_parsed": [["Banjac", "Jelena", ""], ["Donati", "Laur\u00e8ne", ""], ["Defferrard", "Micha\u00ebl", ""]]}, {"id": "2104.06243", "submitter": "Xintong Li", "authors": "Chen Li, Xintong Li, Xiaoyan Li, Md Mamunur Rahaman, Xiaoqi Li, Jian\n  Wu, Yudong Yao, Marcin Grzegorzek", "title": "A State-of-the-art Survey of Artificial Neural Networks for Whole-slide\n  Image Analysis:from Popular Convolutional Neural Networks to Potential Visual\n  Transformers", "comments": "22 pages, 38 figures. arXiv admin note: substantial text overlap with\n  arXiv:2102.10553", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In recent years, with the advancement of computer-aided diagnosis (CAD)\ntechnology and whole slide image (WSI), histopathological WSI has gradually\nplayed a crucial aspect in the diagnosis and analysis of diseases. To increase\nthe objectivity and accuracy of pathologists' work, artificial neural network\n(ANN) methods have been generally needed in the segmentation, classification,\nand detection of histopathological WSI. In this paper, WSI analysis methods\nbased on ANN are reviewed. Firstly, the development status of WSI and ANN\nmethods is introduced. Secondly, we summarize the common ANN methods. Next, we\ndiscuss publicly available WSI datasets and evaluation metrics. These ANN\narchitectures for WSI processing are divided into classical neural networks and\ndeep neural networks (DNNs) and then analyzed. Finally, the application\nprospect of the analytical method in this field is discussed. The important\npotential method is Visual Transformers.\n", "versions": [{"version": "v1", "created": "Tue, 13 Apr 2021 14:39:33 GMT"}, {"version": "v2", "created": "Tue, 4 May 2021 06:09:58 GMT"}], "update_date": "2021-05-05", "authors_parsed": [["Li", "Chen", ""], ["Li", "Xintong", ""], ["Li", "Xiaoyan", ""], ["Rahaman", "Md Mamunur", ""], ["Li", "Xiaoqi", ""], ["Wu", "Jian", ""], ["Yao", "Yudong", ""], ["Grzegorzek", "Marcin", ""]]}, {"id": "2104.06245", "submitter": "Karl Stratos", "authors": "Wenzheng Zhang and Karl Stratos", "title": "Understanding Hard Negatives in Noise Contrastive Estimation", "comments": "NAACL 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The choice of negative examples is important in noise contrastive estimation.\nRecent works find that hard negatives -- highest-scoring incorrect examples\nunder the model -- are effective in practice, but they are used without a\nformal justification. We develop analytical tools to understand the role of\nhard negatives. Specifically, we view the contrastive loss as a biased\nestimator of the gradient of the cross-entropy loss, and show both\ntheoretically and empirically that setting the negative distribution to be the\nmodel distribution results in bias reduction. We also derive a general form of\nthe score function that unifies various architectures used in text retrieval.\nBy combining hard negatives with appropriate score functions, we obtain strong\nresults on the challenging task of zero-shot entity linking.\n", "versions": [{"version": "v1", "created": "Tue, 13 Apr 2021 14:42:41 GMT"}], "update_date": "2021-04-14", "authors_parsed": [["Zhang", "Wenzheng", ""], ["Stratos", "Karl", ""]]}, {"id": "2104.06249", "submitter": "Saurabh Gore", "authors": "Manuel Ntumba, Saurabh Gore, Jean-Baptiste Awanyo", "title": "Prediction of Apophis Asteroid Flyby Optimal Trajectories and Data\n  Fusion of Earth-Apophis Mission Launch Windows using Deep Neural Networks", "comments": "6 pages, 5 figures", "journal-ref": null, "doi": "10.13140/RG.2.2.26280.49924", "report-no": "http://dx.doi.org/10.13140/RG.2.2.26280.49924", "categories": "astro-ph.IM astro-ph.EP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, understanding asteroids has shifted from light worlds to\ngeological worlds by exploring modern spacecraft and advanced radar and\ntelescopic surveys. However, flyby in 2029 will be an opportunity to conduct an\ninternal geophysical study and test the current hypothesis on the effects of\ntidal forces on asteroids. The Earth-Apophis mission is driven by additional\nfactors and scientific goals beyond the unique opportunity for natural\nexperimentation. However, the internal geophysical structures remain largely\nunknown. Understanding the strength and internal integrity of asteroids is not\njust a matter of scientific curiosity. It is a practical imperative to advance\nknowledge for planetary defense against the possibility of an asteroid impact.\nThis paper presents a conceptual robotics system required for efficiency at\nevery stage from entry to post-landing and for asteroid monitoring. In short,\nasteroid surveillance missions are futuristic frontiers, with the potential for\ntechnological growth that could revolutionize space exploration. Advanced space\ntechnologies and robotic systems are needed to minimize risk and prepare these\ntechnologies for future missions. A neural network model is implemented to\ntrack and predict asteroids' orbits. Advanced algorithms are also needed to\nnumerically predict orbital events to minimize error\n", "versions": [{"version": "v1", "created": "Sun, 11 Apr 2021 21:42:53 GMT"}, {"version": "v2", "created": "Sat, 5 Jun 2021 13:58:51 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Ntumba", "Manuel", ""], ["Gore", "Saurabh", ""], ["Awanyo", "Jean-Baptiste", ""]]}, {"id": "2104.06255", "submitter": "Ali Siahkoohi", "authors": "Ali Siahkoohi and Felix J. Herrmann", "title": "Learning by example: fast reliability-aware seismic imaging with\n  normalizing flows", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.geo-ph cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Uncertainty quantification provides quantitative measures on the reliability\nof candidate solutions of ill-posed inverse problems. Due to their sequential\nnature, Monte Carlo sampling methods require large numbers of sampling steps\nfor accurate Bayesian inference and are often computationally infeasible for\nlarge-scale inverse problems, such as seismic imaging. Our main contribution is\na data-driven variational inference approach where we train a normalizing flow\n(NF), a type of invertible neural net, capable of cheaply sampling the\nposterior distribution given previously unseen seismic data from neighboring\nsurveys. To arrive at this result, we train the NF on pairs of low- and\nhigh-fidelity migrated images. In our numerical example, we obtain\nhigh-fidelity images from the Parihaka dataset and low-fidelity images are\nderived from these images through the process of demigration, followed by\nadding noise and migration. During inference, given shot records from a new\nneighboring seismic survey, we first compute the reverse-time migration image.\nNext, by feeding this low-fidelity migrated image to the NF we gain access to\nsamples from the posterior distribution virtually for free. We use these\nsamples to compute a high-fidelity image including a first assessment of the\nimage's reliability. To our knowledge, this is the first attempt to train a\nconditional network on what we know from neighboring images to improve the\ncurrent image and assess its reliability.\n", "versions": [{"version": "v1", "created": "Tue, 13 Apr 2021 15:13:45 GMT"}], "update_date": "2021-04-14", "authors_parsed": [["Siahkoohi", "Ali", ""], ["Herrmann", "Felix J.", ""]]}, {"id": "2104.06256", "submitter": "Xueyuan Wang", "authors": "Xueyuan Wang and M. Cenk Gursoy", "title": "Learning-Based UAV Trajectory Optimization with Collision Avoidance and\n  Connectivity Constraints", "comments": "This paper has been submitted to IEEE for publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.IT cs.LG math.IT", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Unmanned aerial vehicles (UAVs) are expected to be an integral part of\nwireless networks, and determining collision-free trajectories for multiple\nUAVs while satisfying requirements of connectivity with ground base stations\n(GBSs) is a challenging task. In this paper, we first reformulate the multi-UAV\ntrajectory optimization problem with collision avoidance and wireless\nconnectivity constraints as a sequential decision making problem in the\ndiscrete time domain. We, then, propose a decentralized deep reinforcement\nlearning approach to solve the problem. More specifically, a value network is\ndeveloped to encode the expected time to destination given the agent's joint\nstate (including the agent's information, the nearby agents' observable\ninformation, and the locations of the nearby GBSs). A\nsignal-to-interference-plus-noise ratio (SINR)-prediction neural network is\nalso designed, using accumulated SINR measurements obtained when interacting\nwith the cellular network, to map the GBSs' locations into the SINR levels in\norder to predict the UAV's SINR. Numerical results show that with the value\nnetwork and SINR-prediction network, real-time navigation for multi-UAVs can be\nefficiently performed in various environments with high success rate.\n", "versions": [{"version": "v1", "created": "Sat, 3 Apr 2021 22:22:20 GMT"}, {"version": "v2", "created": "Thu, 15 Apr 2021 19:22:20 GMT"}], "update_date": "2021-04-19", "authors_parsed": [["Wang", "Xueyuan", ""], ["Gursoy", "M. Cenk", ""]]}, {"id": "2104.06259", "submitter": "Jaydip Sen", "authors": "Jaydip Sen, Abhishek Dutta, Sidra Mehtab", "title": "Profitability Analysis in Stock Investment Using an LSTM-Based Deep\n  Learning Model", "comments": "This is the accepted version of our paper in the Second IEEE\n  International Conference on Emerging Technologies (IEEE INCET 2021) which\n  will be organized in Belgaum, Karnataka, INDIA from May 21 to May 23, 2021.\n  The paper is eight pages long, and has fifteen tables and fourteen figures.\n  This is not the final version of the paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Designing robust systems for precise prediction of future prices of stocks\nhas always been considered a very challenging research problem. Even more\nchallenging is to build a system for constructing an optimum portfolio of\nstocks based on the forecasted future stock prices. We present a deep\nlearning-based regression model built on a long-and-short-term memory network\n(LSTM) network that automatically scraps the web and extracts historical stock\nprices based on a stock's ticker name for a specified pair of start and end\ndates, and forecasts the future stock prices. We deploy the model on 75\nsignificant stocks chosen from 15 critical sectors of the Indian stock market.\nFor each of the stocks, the model is evaluated for its forecast accuracy.\nMoreover, the predicted values of the stock prices are used as the basis for\ninvestment decisions, and the returns on the investments are computed.\nExtensive results are presented on the performance of the model. The analysis\nof the results demonstrates the efficacy and effectiveness of the system and\nenables us to compare the profitability of the sectors from the point of view\nof the investors in the stock market.\n", "versions": [{"version": "v1", "created": "Tue, 6 Apr 2021 11:09:51 GMT"}], "update_date": "2021-04-14", "authors_parsed": [["Sen", "Jaydip", ""], ["Dutta", "Abhishek", ""], ["Mehtab", "Sidra", ""]]}, {"id": "2104.06268", "submitter": "Genta Indra Winata", "authors": "Genta Indra Winata", "title": "Multilingual Transfer Learning for Code-Switched Language and Speech\n  Neural Modeling", "comments": "HKUST PhD Thesis. 120 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this thesis, we address the data scarcity and limitations of linguistic\ntheory by proposing language-agnostic multi-task training methods. First, we\nintroduce a meta-learning-based approach, meta-transfer learning, in which\ninformation is judiciously extracted from high-resource monolingual speech data\nto the code-switching domain. The meta-transfer learning quickly adapts the\nmodel to the code-switching task from a number of monolingual tasks by learning\nto learn in a multi-task learning fashion. Second, we propose a novel\nmultilingual meta-embeddings approach to effectively represent code-switching\ndata by acquiring useful knowledge learned in other languages, learning the\ncommonalities of closely related languages and leveraging lexical composition.\nThe method is far more efficient compared to contextualized pre-trained\nmultilingual models. Third, we introduce multi-task learning to integrate\nsyntactic information as a transfer learning strategy to a language model and\nlearn where to code-switch. To further alleviate the aforementioned issues, we\npropose a data augmentation method using Pointer-Gen, a neural network using a\ncopy mechanism to teach the model the code-switch points from monolingual\nparallel sentences. We disentangle the need for linguistic theory, and the\nmodel captures code-switching points by attending to input words and aligning\nthe parallel words, without requiring any word alignments or constituency\nparsers. More importantly, the model can be effectively used for languages that\nare syntactically different, and it outperforms the linguistic theory-based\nmodels.\n", "versions": [{"version": "v1", "created": "Tue, 13 Apr 2021 14:49:26 GMT"}], "update_date": "2021-04-14", "authors_parsed": [["Winata", "Genta Indra", ""]]}, {"id": "2104.06271", "submitter": "Enes Avcu", "authors": "Enes Avcu, Olivia Newman, David Gow", "title": "A Tale of Two Lexica Testing Computational Hypotheses with Deep\n  Convolutional Neural Networks", "comments": "8 pages, 3 figures, Presented as a talk at the Psychonomic Society's\n  61st Annual Meeting and poster at the SNL 2020 Annual Meeting", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Gow's (2012) dual lexicon model suggests that the primary purpose of words is\nto mediate the mappings between acoustic-phonetic input and other forms of\nlinguistic representation. Motivated by evidence from functional imaging,\naphasia, and behavioral results, the model argues for the existence of two\nparallel wordform stores: the dorsal and ventral processing streams. In this\npaper, we tested the hypothesis that the complex, but systematic mapping\nbetween sound and articulation in the dorsal stream poses different\ncomputational pressures on feature sets than the more arbitrary mapping between\nsound and meaning. To test this hypothesis, we created two deep convolutional\nneural networks (CNNs). While the dorsal network was trained to identify\nindividual spoken words, the ventral network was trained to map them onto\nsemantic classes. We then extracted patterns of network activation from the\npenultimate level of each network and tested how well features generated by the\nnetwork supported generalization to linguistic categorization associated with\nthe dorsal versus ventral processing streams. Our preliminary results showed\nboth models successfully learned their tasks. Secondary generalization testing\nshowed the ventral CNN outperformed the dorsal CNN on a semantic task:\nconcreteness classification, while the dorsal CNN outperformed the ventral CNN\non articulation tasks: classification by onset phoneme class and syllable\nlength. These results are consistent with the hypothesis that the divergent\nprocessing demands of the ventral and dorsal processing streams impose\ncomputational pressures for the development of multiple lexica.\n", "versions": [{"version": "v1", "created": "Tue, 13 Apr 2021 15:03:14 GMT"}], "update_date": "2021-04-14", "authors_parsed": [["Avcu", "Enes", ""], ["Newman", "Olivia", ""], ["Gow", "David", ""]]}, {"id": "2104.06272", "submitter": "Matteo Hessel", "authors": "Matteo Hessel, Manuel Kroiss, Aidan Clark, Iurii Kemaev, John Quan,\n  Thomas Keck, Fabio Viola and Hado van Hasselt", "title": "Podracer architectures for scalable Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Supporting state-of-the-art AI research requires balancing rapid prototyping,\nease of use, and quick iteration, with the ability to deploy experiments at a\nscale traditionally associated with production systems.Deep learning frameworks\nsuch as TensorFlow, PyTorch and JAX allow users to transparently make use of\naccelerators, such as TPUs and GPUs, to offload the more computationally\nintensive parts of training and inference in modern deep learning systems.\nPopular training pipelines that use these frameworks for deep learning\ntypically focus on (un-)supervised learning. How to best train reinforcement\nlearning (RL) agents at scale is still an active research area. In this report\nwe argue that TPUs are particularly well suited for training RL agents in a\nscalable, efficient and reproducible way. Specifically we describe two\narchitectures designed to make the best use of the resources available on a TPU\nPod (a special configuration in a Google data center that features multiple TPU\ndevices connected to each other by extremely low latency communication\nchannels).\n", "versions": [{"version": "v1", "created": "Tue, 13 Apr 2021 15:05:35 GMT"}], "update_date": "2021-04-14", "authors_parsed": [["Hessel", "Matteo", ""], ["Kroiss", "Manuel", ""], ["Clark", "Aidan", ""], ["Kemaev", "Iurii", ""], ["Quan", "John", ""], ["Keck", "Thomas", ""], ["Viola", "Fabio", ""], ["van Hasselt", "Hado", ""]]}, {"id": "2104.06279", "submitter": "Yihao Liu", "authors": "Yihao Liu, Jingwen He, Xiangyu Chen, Zhengwen Zhang, Hengyuan Zhao,\n  Chao Dong, Yu Qiao", "title": "Very Lightweight Photo Retouching Network with Conditional Sequential\n  Modulation", "comments": "Extended version of CSRNet (ECCV2020). arXiv admin note: substantial\n  text overlap with arXiv:2009.10390", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Photo retouching aims at improving the aesthetic visual quality of images\nthat suffer from photographic defects such as poor contrast, over/under\nexposure, and inharmonious saturation. In practice, photo retouching can be\naccomplished by a series of image processing operations. As most commonly-used\nretouching operations are pixel-independent, i.e., the manipulation on one\npixel is uncorrelated with its neighboring pixels, we can take advantage of\nthis property and design a specialized algorithm for efficient global photo\nretouching. We analyze these global operations and find that they can be\nmathematically formulated by a Multi-Layer Perceptron (MLP). Based on this\nobservation, we propose an extremely lightweight framework -- Conditional\nSequential Retouching Network (CSRNet). Benefiting from the utilization of\n$1\\times1$ convolution, CSRNet only contains less than 37K trainable\nparameters, which are orders of magnitude smaller than existing learning-based\nmethods. Experiments show that our method achieves state-of-the-art performance\non the benchmark MIT-Adobe FiveK dataset quantitively and qualitatively. In\naddition to achieve global photo retouching, the proposed framework can be\neasily extended to learn local enhancement effects. The extended model, namly\nCSRNet-L, also achieves competitive results in various local enhancement tasks.\nCodes will be available.\n", "versions": [{"version": "v1", "created": "Tue, 13 Apr 2021 15:11:02 GMT"}], "update_date": "2021-04-14", "authors_parsed": [["Liu", "Yihao", ""], ["He", "Jingwen", ""], ["Chen", "Xiangyu", ""], ["Zhang", "Zhengwen", ""], ["Zhao", "Hengyuan", ""], ["Dong", "Chao", ""], ["Qiao", "Yu", ""]]}, {"id": "2104.06294", "submitter": "Julian Schrittwieser", "authors": "Julian Schrittwieser and Thomas Hubert and Amol Mandhane and\n  Mohammadamin Barekatain and Ioannis Antonoglou and David Silver", "title": "Online and Offline Reinforcement Learning by Planning with a Learned\n  Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning efficiently from small amounts of data has long been the focus of\nmodel-based reinforcement learning, both for the online case when interacting\nwith the environment and the offline case when learning from a fixed dataset.\nHowever, to date no single unified algorithm could demonstrate state-of-the-art\nresults in both settings. In this work, we describe the Reanalyse algorithm\nwhich uses model-based policy and value improvement operators to compute new\nimproved training targets on existing data points, allowing efficient learning\nfor data budgets varying by several orders of magnitude. We further show that\nReanalyse can also be used to learn entirely from demonstrations without any\nenvironment interactions, as in the case of offline Reinforcement Learning\n(offline RL). Combining Reanalyse with the MuZero algorithm, we introduce\nMuZero Unplugged, a single unified algorithm for any data budget, including\noffline RL. In contrast to previous work, our algorithm does not require any\nspecial adaptations for the off-policy or offline RL settings. MuZero Unplugged\nsets new state-of-the-art results in the RL Unplugged offline RL benchmark as\nwell as in the online RL benchmark of Atari in the standard 200 million frame\nsetting.\n", "versions": [{"version": "v1", "created": "Tue, 13 Apr 2021 15:36:06 GMT"}], "update_date": "2021-04-14", "authors_parsed": [["Schrittwieser", "Julian", ""], ["Hubert", "Thomas", ""], ["Mandhane", "Amol", ""], ["Barekatain", "Mohammadamin", ""], ["Antonoglou", "Ioannis", ""], ["Silver", "David", ""]]}, {"id": "2104.06297", "submitter": "C\\'esar Quilodr\\'an-Casas", "authors": "C\\'esar Quilodr\\'an-Casas, Rossella Arcucci, Laetitia Mottet, Yike\n  Guo, Christopher Pain", "title": "Adversarial autoencoders and adversarial LSTM for improved forecasts of\n  urban air pollution simulations", "comments": "8 pages; 3 figures; Published as a workshop paper at ICLR 2021 SimDL\n  Workshop. arXiv admin note: text overlap with arXiv:2101.01568", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG physics.comp-ph physics.flu-dyn", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents an approach to improve the forecast of computational\nfluid dynamics (CFD) simulations of urban air pollution using deep learning,\nand most specifically adversarial training. This adversarial approach aims to\nreduce the divergence of the forecasts from the underlying physical model. Our\ntwo-step method integrates a Principal Components Analysis (PCA) based\nadversarial autoencoder (PC-AAE) with adversarial Long short-term memory (LSTM)\nnetworks. Once the reduced-order model (ROM) of the CFD solution is obtained\nvia PCA, an adversarial autoencoder is used on the principal components time\nseries. Subsequentially, a Long Short-Term Memory network (LSTM) is\nadversarially trained on the latent space produced by the PC-AAE to make\nforecasts. Once trained, the adversarially trained LSTM outperforms a LSTM\ntrained in a classical way. The study area is in South London, including\nthree-dimensional velocity vectors in a busy traffic junction.\n", "versions": [{"version": "v1", "created": "Tue, 13 Apr 2021 15:43:50 GMT"}, {"version": "v2", "created": "Fri, 16 Apr 2021 16:02:14 GMT"}], "update_date": "2021-04-19", "authors_parsed": [["Quilodr\u00e1n-Casas", "C\u00e9sar", ""], ["Arcucci", "Rossella", ""], ["Mottet", "Laetitia", ""], ["Guo", "Yike", ""], ["Pain", "Christopher", ""]]}, {"id": "2104.06303", "submitter": "Julian Schrittwieser", "authors": "Thomas Hubert and Julian Schrittwieser and Ioannis Antonoglou and\n  Mohammadamin Barekatain and Simon Schmitt and David Silver", "title": "Learning and Planning in Complex Action Spaces", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many important real-world problems have action spaces that are\nhigh-dimensional, continuous or both, making full enumeration of all possible\nactions infeasible. Instead, only small subsets of actions can be sampled for\nthe purpose of policy evaluation and improvement. In this paper, we propose a\ngeneral framework to reason in a principled way about policy evaluation and\nimprovement over such sampled action subsets. This sample-based policy\niteration framework can in principle be applied to any reinforcement learning\nalgorithm based upon policy iteration. Concretely, we propose Sampled MuZero,\nan extension of the MuZero algorithm that is able to learn in domains with\narbitrarily complex action spaces by planning over sampled actions. We\ndemonstrate this approach on the classical board game of Go and on two\ncontinuous control benchmark domains: DeepMind Control Suite and Real-World RL\nSuite.\n", "versions": [{"version": "v1", "created": "Tue, 13 Apr 2021 15:48:48 GMT"}], "update_date": "2021-04-14", "authors_parsed": [["Hubert", "Thomas", ""], ["Schrittwieser", "Julian", ""], ["Antonoglou", "Ioannis", ""], ["Barekatain", "Mohammadamin", ""], ["Schmitt", "Simon", ""], ["Silver", "David", ""]]}, {"id": "2104.06307", "submitter": "Bowen Xu", "authors": "Bowen Xu, Fanghong Guo, Changyun Wen, Wen-An Zhang", "title": "Stealthy False Data Injection Attack Detection in Smart Grids with\n  Uncertainties: A Deep Transfer Learning Based Approach", "comments": "8 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.CR cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most traditional false data injection attack (FDIA) detection approaches rely\non static system parameters or a single known snapshot of dynamic ones.\nHowever, such a setting significantly weakens the practicality of these\napproaches when facing the fact that the system parameters are dynamic and\ncannot be accurately known during operation due to the presence of\nuncertainties in practical smart grids. In this paper, we propose an FDIA\ndetection mechanism from the perspective of transfer learning. Specifically,\nthe known initial/approximate system is treated as a source domain, which\nprovides abundant simulated normal and attack data. The real world's unknown\nrunning system is taken as a target domain where sufficient real normal data\nare collected for tracking the latest system states online. The designed\ntransfer strategy that aims at making full use of data in hand is divided into\ntwo optimization stages. In the first stage, a deep neural network (DNN) is\nbuilt by simultaneously optimizing several well-designed terms with both\nsimulated data and real data, and then it is fine-tuned via real data in the\nsecond stage. Several case studies on the IEEE 14-bus power system verify the\neffectiveness of the proposed mechanism.\n", "versions": [{"version": "v1", "created": "Fri, 9 Apr 2021 15:32:20 GMT"}], "update_date": "2021-04-14", "authors_parsed": [["Xu", "Bowen", ""], ["Guo", "Fanghong", ""], ["Wen", "Changyun", ""], ["Zhang", "Wen-An", ""]]}, {"id": "2104.06308", "submitter": "Xiangwen Deng", "authors": "Xiangwen Deng, Junlin Zhu and Shangming Yang", "title": "SFE-Net: EEG-based Emotion Recognition with Symmetrical Spatial Feature\n  Extraction", "comments": "10 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Emotion recognition based on EEG (electroencephalography) has been widely\nused in human-computer interaction, distance education and health care.\nHowever, the conventional methods ignore the adjacent and symmetrical\ncharacteristics of EEG signals, which also contain salient information related\nto emotion. In this paper, we present a spatial folding ensemble network\n(SFENet) for EEG feature extraction and emotion recognition. Firstly, for the\nundetected area between EEG electrodes, we employ an improved Bicubic-EEG\ninterpolation algorithm for EEG channel information completion, which allows us\nto extract a wider range of adjacent space features. Then, motivated by the\nspatial symmetry mechanism of human brain, we fold the input EEG channel data\nwith five different symmetrical strategies: the left-right folds, the\nright-left folds, the top-bottom folds, the bottom-top folds, and the entire\ndouble-sided brain folding, which enable the proposed network to extract the\ninformation of space features of EEG signals more effectively. Finally, 3DCNN\nbased spatial and temporal extraction and multi voting strategy of ensemble\nLearning are employed to model a new neural network. With this network, the\nspatial features of different symmetric folding signlas can be extracted\nsimultaneously, which greatly improves the robustness and accuracy of feature\nrecognition. The experimental results on DEAP and SEED data sets show that the\nproposed algorithm has comparable performance in term of recognition accuracy.\n", "versions": [{"version": "v1", "created": "Fri, 9 Apr 2021 12:59:38 GMT"}, {"version": "v2", "created": "Fri, 16 Apr 2021 04:01:56 GMT"}, {"version": "v3", "created": "Sun, 25 Apr 2021 07:44:13 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Deng", "Xiangwen", ""], ["Zhu", "Junlin", ""], ["Yang", "Shangming", ""]]}, {"id": "2104.06310", "submitter": "Umberto Michelucci", "authors": "Francesca Venturini and Michela Sperti and Umberto Michelucci and Ivo\n  Herzig and Michael Baumgartner and Josep Palau Caballero and Arturo Jimenez\n  and and Marco Agostino Deriu", "title": "Exploration of Spanish Olive Oil Quality with a Miniaturized Low-Cost\n  Fluorescence Sensor and Machine Learning Techniques", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Extra virgin olive oil (EVOO) is the highest quality of olive oil and is\ncharacterized by highly beneficial nutritional properties. The large increase\nin both consumption and fraud, for example through adulteration, creates new\nchallenges and an increasing demand for developing new quality assessment\nmethodologies that are easier and cheaper to perform. As of today, the\ndetermination of olive oil quality is performed by producers through chemical\nanalysis and organoleptic evaluation. The chemical analysis requires the\nadvanced equipment and chemical knowledge of certified laboratories, and has\ntherefore a limited accessibility. In this work a minimalist, portable and\nlow-cost sensor is presented, which can perform olive oil quality assessment\nusing fluorescence spectroscopy. The potential of the proposed technology is\nexplored by analyzing several olive oils of different quality levels, EVOO,\nvirgin olive oil (VOO), and lampante olive oil (LOO). The spectral data were\nanalyzed using a large number of machine learning methods, including artificial\nneural networks. The analysis performed in this work demonstrates the\npossibility of performing classification of olive oil in the three mentioned\nclasses with an accuracy of 100$\\%$. These results confirm that this minimalist\nlow-cost sensor has the potential of substituting expensive and complex\nchemical analysis.\n", "versions": [{"version": "v1", "created": "Fri, 9 Apr 2021 11:50:33 GMT"}], "update_date": "2021-04-14", "authors_parsed": [["Venturini", "Francesca", ""], ["Sperti", "Michela", ""], ["Michelucci", "Umberto", ""], ["Herzig", "Ivo", ""], ["Baumgartner", "Michael", ""], ["Caballero", "Josep Palau", ""], ["Jimenez", "Arturo", ""], ["Deriu", "and Marco Agostino", ""]]}, {"id": "2104.06313", "submitter": "Yang Gao", "authors": "Yang Gao, Yi-Fan Li, Yu Lin, Charu Aggarwal, Latifur Khan", "title": "SetConv: A New Approach for Learning from Imbalanced Data", "comments": "Accepted by EMNLP 2020 (11 pages, 9 figures)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  For many real-world classification problems, e.g., sentiment classification,\nmost existing machine learning methods are biased towards the majority class\nwhen the Imbalance Ratio (IR) is high. To address this problem, we propose a\nset convolution (SetConv) operation and an episodic training strategy to\nextract a single representative for each class, so that classifiers can later\nbe trained on a balanced class distribution. We prove that our proposed\nalgorithm is permutation-invariant despite the order of inputs, and experiments\non multiple large-scale benchmark text datasets show the superiority of our\nproposed framework when compared to other SOTA methods.\n", "versions": [{"version": "v1", "created": "Sat, 3 Apr 2021 22:33:30 GMT"}], "update_date": "2021-04-14", "authors_parsed": [["Gao", "Yang", ""], ["Li", "Yi-Fan", ""], ["Lin", "Yu", ""], ["Aggarwal", "Charu", ""], ["Khan", "Latifur", ""]]}, {"id": "2104.06317", "submitter": "Shiyi Chen", "authors": "Shiyi Chen, Ziao Wang, Xinni Zhang, Xiaofeng Zhang, Dan Peng", "title": "Probing Negative Sampling Strategies to Learn GraphRepresentations via\n  Unsupervised Contrastive Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Graph representation learning has long been an important yet challenging task\nfor various real-world applications. However, their downstream tasks are mainly\nperformed in the settings of supervised or semi-supervised learning. Inspired\nby recent advances in unsupervised contrastive learning, this paper is thus\nmotivated to investigate how the node-wise contrastive learning could be\nperformed. Particularly, we respectively resolve the class collision issue and\nthe imbalanced negative data distribution issue. Extensive experiments are\nperformed on three real-world datasets and the proposed approach achieves the\nSOTA model performance.\n", "versions": [{"version": "v1", "created": "Tue, 13 Apr 2021 15:53:48 GMT"}], "update_date": "2021-04-14", "authors_parsed": [["Chen", "Shiyi", ""], ["Wang", "Ziao", ""], ["Zhang", "Xinni", ""], ["Zhang", "Xiaofeng", ""], ["Peng", "Dan", ""]]}, {"id": "2104.06323", "submitter": "Dan Ley", "authors": "Dan Ley, Umang Bhatt, Adrian Weller", "title": "{\\delta}-CLUE: Diverse Sets of Explanations for Uncertainty Estimates", "comments": "Appeared as a workshop paper at ICLR 2021 (Responsible AI | Secure ML\n  | Robust ML)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To interpret uncertainty estimates from differentiable probabilistic models,\nrecent work has proposed generating Counterfactual Latent Uncertainty\nExplanations (CLUEs). However, for a single input, such approaches could output\na variety of explanations due to the lack of constraints placed on the\nexplanation. Here we augment the original CLUE approach, to provide what we\ncall $\\delta$-CLUE. CLUE indicates $\\it{one}$ way to change an input, while\nremaining on the data manifold, such that the model becomes more confident\nabout its prediction. We instead return a $\\it{set}$ of plausible CLUEs:\nmultiple, diverse inputs that are within a $\\delta$ ball of the original input\nin latent space, all yielding confident predictions.\n", "versions": [{"version": "v1", "created": "Tue, 13 Apr 2021 16:03:27 GMT"}, {"version": "v2", "created": "Wed, 14 Apr 2021 08:10:33 GMT"}, {"version": "v3", "created": "Sat, 24 Apr 2021 14:08:57 GMT"}, {"version": "v4", "created": "Tue, 27 Apr 2021 15:23:09 GMT"}, {"version": "v5", "created": "Sat, 8 May 2021 09:29:40 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Ley", "Dan", ""], ["Bhatt", "Umang", ""], ["Weller", "Adrian", ""]]}, {"id": "2104.06335", "submitter": "Ian Berlot-Attwell", "authors": "Ian Berlot-Attwell and Frank Rudzicz", "title": "On the Use of Linguistic Features for the Evaluation of Generative\n  Dialogue Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Automatically evaluating text-based, non-task-oriented dialogue systems\n(i.e., `chatbots') remains an open problem. Previous approaches have suffered\nchallenges ranging from poor correlation with human judgment to poor\ngeneralization and have often required a gold standard reference for comparison\nor human-annotated data. Extending existing evaluation methods, we propose that\na metric based on linguistic features may be able to maintain good correlation\nwith human judgment and be interpretable, without requiring a gold-standard\nreference or human-annotated data. To support this proposition, we measure and\nanalyze various linguistic features on dialogues produced by multiple dialogue\nmodels. We find that the features' behaviour is consistent with the known\nproperties of the models tested, and is similar across domains. We also\ndemonstrate that this approach exhibits promising properties such as zero-shot\ngeneralization to new domains on the related task of evaluating response\nrelevance.\n", "versions": [{"version": "v1", "created": "Tue, 13 Apr 2021 16:28:00 GMT"}], "update_date": "2021-04-14", "authors_parsed": [["Berlot-Attwell", "Ian", ""], ["Rudzicz", "Frank", ""]]}, {"id": "2104.06339", "submitter": "Chiara Mastrogiuseppe", "authors": "Ruben Moreno-Bote and Chiara Mastrogiuseppe", "title": "Deep imagination is a close to optimal policy for planning in large\n  decision trees under limited resources", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG q-bio.NC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Many decisions involve choosing an uncertain course of actions in deep and\nwide decision trees, as when we plan to visit an exotic country for vacation.\nIn these cases, exhaustive search for the best sequence of actions is not\ntractable due to the large number of possibilities and limited time or\ncomputational resources available to make the decision. Therefore, planning\nagents need to balance breadth (exploring many actions at each level of the\ntree) and depth (exploring many levels in the tree) to allocate optimally their\nfinite search capacity. We provide efficient analytical solutions and numerical\nanalysis to the problem of allocating finite sampling capacity in one shot to\nlarge decision trees. We find that in general the optimal policy is to allocate\nfew samples per level so that deep levels can be reached, thus favoring depth\nover breadth search. In contrast, in poor environments and at low capacity, it\nis best to broadly sample branches at the cost of not sampling deeply, although\nthis policy is marginally better than deep allocations. Our results provide a\ntheoretical foundation for the optimality of deep imagination for planning and\nshow that it is a generally valid heuristic that could have evolved from the\nfinite constraints of cognitive systems.\n", "versions": [{"version": "v1", "created": "Tue, 13 Apr 2021 16:31:24 GMT"}], "update_date": "2021-04-14", "authors_parsed": [["Moreno-Bote", "Ruben", ""], ["Mastrogiuseppe", "Chiara", ""]]}, {"id": "2104.06353", "submitter": "Xianjie Gao", "authors": "Xianjie Gao, Xueguan Song, Maolin Shi, Chao Zhang and Hongwei Zhang", "title": "Real-time Forecast Models for TBM Load Parameters Based on Machine\n  Learning Methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Because of the fast advance rate and the improved personnel safety, tunnel\nboring machines (TBMs) have been widely used in a variety of tunnel\nconstruction projects. The dynamic modeling of TBM load parameters (including\ntorque, advance rate and thrust) plays an essential part in the design, safe\noperation and fault prognostics of this complex engineering system. In this\npaper, based on in-situ TBM operational data, we use the machine-learning (ML)\nmethods to build the real-time forecast models for TBM load parameters, which\ncan instantaneously provide the future values of the TBM load parameters as\nlong as the current data are collected. To decrease the model complexity and\nimprove the generalization, we also apply the least absolute shrinkage and\nselection (Lasso) method to extract the essential features of the forecast\ntask. The experimental results show that the forecast models based on\ndeep-learning methods, {\\it e.g.}, recurrent neural network and its variants,\noutperform the ones based on the shallow-learning methods, {\\it e.g.}, support\nvector regression and random forest. Moreover, the Lasso-based feature\nextraction significantly improves the performance of the resultant models.\n", "versions": [{"version": "v1", "created": "Mon, 12 Apr 2021 07:31:39 GMT"}], "update_date": "2021-04-14", "authors_parsed": [["Gao", "Xianjie", ""], ["Song", "Xueguan", ""], ["Shi", "Maolin", ""], ["Zhang", "Chao", ""], ["Zhang", "Hongwei", ""]]}, {"id": "2104.06357", "submitter": "Corey Nolet", "authors": "Corey J. Nolet, Divye Gala, Edward Raff, Joe Eaton, Brad Rees, John\n  Zedlewski, Tim Oates", "title": "Semiring Primitives for Sparse Neighborhood Methods on the GPU", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC math.RA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  High-performance primitives for mathematical operations on sparse vectors\nmust deal with the challenges of skewed degree distributions and limits on\nmemory consumption that are typically not issues in dense operations. We\ndemonstrate that a sparse semiring primitive can be flexible enough to support\na wide range of critical distance measures while maintaining performance and\nmemory efficiency on the GPU. We further show that this primitive is a\nfoundational component for enabling many neighborhood-based information\nretrieval and machine learning algorithms to accept sparse input. To our\nknowledge, this is the first work aiming to unify the computation of several\ncritical distance measures on the GPU under a single flexible design paradigm\nand we hope that it provides a good baseline for future research in this area.\nOur implementation is fully open source and publicly available at\nhttps://github.com/rapidsai/cuml.\n", "versions": [{"version": "v1", "created": "Tue, 13 Apr 2021 17:05:03 GMT"}], "update_date": "2021-04-14", "authors_parsed": [["Nolet", "Corey J.", ""], ["Gala", "Divye", ""], ["Raff", "Edward", ""], ["Eaton", "Joe", ""], ["Rees", "Brad", ""], ["Zedlewski", "John", ""], ["Oates", "Tim", ""]]}, {"id": "2104.06358", "submitter": "Vihanga Gamage", "authors": "Vihanga Gamage, Cathy Ennis, Robert Ross", "title": "Data-Driven Reinforcement Learning for Virtual Character Animation\n  Control", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Virtual character animation control is a problem for which Reinforcement\nLearning (RL) is a viable approach. While current work have applied RL\neffectively to portray physics-based skills, social behaviours are challenging\nto design reward functions for, due to their lack of physical interaction with\nthe world. On the other hand, data-driven implementations for these skills have\nbeen limited to supervised learning methods which require extensive training\ndata and carry constraints on generalisability. In this paper, we propose\nRLAnimate, a novel data-driven deep RL approach to address this challenge,\nwhere we combine the strengths of RL together with an ability to learn from a\nmotion dataset when creating agents. We formalise a mathematical structure for\ntraining agents by refining the conceptual roles of elements such as agents,\nenvironments, states and actions, in a way that leverages attributes of the\ncharacter animation domain and model-based RL. An agent trained using our\napproach learns versatile animation dynamics to portray multiple behaviours,\nusing an iterative RL training process, which becomes aware of valid behaviours\nvia representations learnt from motion capture clips. We demonstrate, by\ntraining agents that portray realistic pointing and waving behaviours, that our\napproach requires a significantly lower training time, and substantially fewer\nsample episodes to be generated during training relative to state-of-the-art\nphysics-based RL methods. Also, compared to existing supervised learning-based\nanimation agents, RLAnimate needs a limited dataset of motion clips to generate\nrepresentations of valid behaviours during training.\n", "versions": [{"version": "v1", "created": "Tue, 13 Apr 2021 17:05:27 GMT"}], "update_date": "2021-04-14", "authors_parsed": [["Gamage", "Vihanga", ""], ["Ennis", "Cathy", ""], ["Ross", "Robert", ""]]}, {"id": "2104.06365", "submitter": "Ian Berlot-Attwell", "authors": "Ian Berlot-Attwell", "title": "Neuro-Symbolic VQA: A review from the perspective of AGI desiderata", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  An ultimate goal of the AI and ML fields is artificial general intelligence\n(AGI); although such systems remain science fiction, various models exhibit\naspects of AGI. In this work, we look at neuro-symbolic (NS)approaches to\nvisual question answering (VQA) from the perspective of AGI desiderata. We see\nhow well these systems meet these desiderata, and how the desiderata often pull\nthe scientist in opposing directions. It is my hope that through this work we\ncan temper model evaluation on benchmarks with a discussion of the properties\nof these systems and their potential for future extension.\n", "versions": [{"version": "v1", "created": "Tue, 13 Apr 2021 17:23:19 GMT"}], "update_date": "2021-04-14", "authors_parsed": [["Berlot-Attwell", "Ian", ""]]}, {"id": "2104.06374", "submitter": "Aly El Gamal", "authors": "Ahmed P. Mohamed, Abu Shafin Mohammad Mahdee Jameel, Aly El Gamal", "title": "Knowledge Distillation For Wireless Edge Learning", "comments": "5 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a framework for predicting frame errors in the\ncollaborative spectrally congested wireless environments of the DARPA Spectrum\nCollaboration Challenge (SC2) via a recently collected dataset. We employ\ndistributed deep edge learning that is shared among edge nodes and a central\ncloud. Using this close-to-practice dataset, we find that widely used federated\nlearning approaches, specially those that are privacy preserving, are worse\nthan local training for a wide range of settings. We hence utilize the\nsynthetic minority oversampling technique to maintain privacy via avoiding the\ntransfer of local data to the cloud, and utilize knowledge distillation with an\naim to benefit from high cloud computing and storage capabilities. The proposed\nframework achieves overall better performance than both local and federated\ntraining approaches, while being robust against catastrophic failures as well\nas challenging channel conditions that result in high frame error rates.\n", "versions": [{"version": "v1", "created": "Sat, 3 Apr 2021 22:20:08 GMT"}], "update_date": "2021-04-14", "authors_parsed": [["Mohamed", "Ahmed P.", ""], ["Jameel", "Abu Shafin Mohammad Mahdee", ""], ["Gamal", "Aly El", ""]]}, {"id": "2104.06375", "submitter": "Aly El Gamal", "authors": "Jinho Yi and Aly El Gamal", "title": "Gradient-based Adversarial Deep Modulation Classification with\n  Data-driven Subsampling", "comments": "5 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic modulation classification can be a core component for intelligent\nspectrally efficient wireless communication networks, and deep learning\ntechniques have recently been shown to deliver superior performance to\nconventional model-based strategies, particularly when distinguishing between a\nlarge number of modulation types. However, such deep learning techniques have\nalso been recently shown to be vulnerable to gradient-based adversarial attacks\nthat rely on subtle input perturbations, which would be particularly feasible\nin a wireless setting via jamming. One such potent attack is the one known as\nthe Carlini-Wagner attack, which we consider in this work. We further consider\na data-driven subsampling setting, where several recently introduced\ndeep-learning-based algorithms are employed to select a subset of samples that\nlead to reducing the final classifier's training time with minimal loss in\naccuracy. In this setting, the attacker has to make an assumption about the\nemployed subsampling strategy, in order to calculate the loss gradient. Based\non state of the art techniques available to both the attacker and defender, we\nevaluate best strategies under various assumptions on the knowledge of the\nother party's strategy. Interestingly, in presence of knowledgeable attackers,\nwe identify computational cost reduction opportunities for the defender with no\nor minimal loss in performance.\n", "versions": [{"version": "v1", "created": "Sat, 3 Apr 2021 22:28:04 GMT"}], "update_date": "2021-04-14", "authors_parsed": [["Yi", "Jinho", ""], ["Gamal", "Aly El", ""]]}, {"id": "2104.06377", "submitter": "Shanshi Huang", "authors": "Shanshi Huang, Hongwu Jiang and Shimeng Yu", "title": "Mitigating Adversarial Attack for Compute-in-Memory Accelerator\n  Utilizing On-chip Finetune", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Compute-in-memory (CIM) has been proposed to accelerate the convolution\nneural network (CNN) computation by implementing parallel multiply and\naccumulation in analog domain. However, the subsequent processing is still\npreferred to be performed in digital domain. This makes the analog to digital\nconverter (ADC) critical in CIM architectures. One drawback is the ADC error\nintroduced by process variation. While research efforts are being made to\nimprove ADC design to reduce the offset, we find that the accuracy loss\nintroduced by the ADC error could be recovered by model weight finetune. In\naddition to compensate ADC offset, on-chip weight finetune could be leveraged\nto provide additional protection for adversarial attack that aims to fool the\ninference engine with manipulated input samples. Our evaluation results show\nthat by adapting the model weights to the specific ADC offset pattern to each\nchip, the transferability of the adversarial attack is suppressed. For a chip\nbeing attacked by the C&W method, the classification for CIFAR-10 dataset will\ndrop to almost 0%. However, when applying the similarly generated adversarial\nexamples to other chips, the accuracy could still maintain more than 62% and\n85% accuracy for VGG-8 and DenseNet-40, respectively.\n", "versions": [{"version": "v1", "created": "Tue, 13 Apr 2021 17:31:57 GMT"}], "update_date": "2021-04-14", "authors_parsed": [["Huang", "Shanshi", ""], ["Jiang", "Hongwu", ""], ["Yu", "Shimeng", ""]]}, {"id": "2104.06378", "submitter": "Michihiro Yasunaga", "authors": "Michihiro Yasunaga, Hongyu Ren, Antoine Bosselut, Percy Liang and Jure\n  Leskovec", "title": "QA-GNN: Reasoning with Language Models and Knowledge Graphs for Question\n  Answering", "comments": "NAACL 2021. Code & data available at\n  https://github.com/michiyasunaga/qagnn", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The problem of answering questions using knowledge from pre-trained language\nmodels (LMs) and knowledge graphs (KGs) presents two challenges: given a QA\ncontext (question and answer choice), methods need to (i) identify relevant\nknowledge from large KGs, and (ii) perform joint reasoning over the QA context\nand KG. In this work, we propose a new model, QA-GNN, which addresses the above\nchallenges through two key innovations: (i) relevance scoring, where we use LMs\nto estimate the importance of KG nodes relative to the given QA context, and\n(ii) joint reasoning, where we connect the QA context and KG to form a joint\ngraph, and mutually update their representations through graph neural networks.\nWe evaluate QA-GNN on the CommonsenseQA and OpenBookQA datasets, and show its\nimprovement over existing LM and LM+KG models, as well as its capability to\nperform interpretable and structured reasoning, e.g., correctly handling\nnegation in questions.\n", "versions": [{"version": "v1", "created": "Tue, 13 Apr 2021 17:32:51 GMT"}, {"version": "v2", "created": "Thu, 27 May 2021 23:30:14 GMT"}], "update_date": "2021-05-31", "authors_parsed": [["Yasunaga", "Michihiro", ""], ["Ren", "Hongyu", ""], ["Bosselut", "Antoine", ""], ["Liang", "Percy", ""], ["Leskovec", "Jure", ""]]}, {"id": "2104.06387", "submitter": "Pengfei Liu", "authors": "Pengfei Liu, Jinlan Fu, Yang Xiao, Weizhe Yuan, Shuaicheng Chang,\n  Junqi Dai, Yixin Liu, Zihuiwen Ye, Zi-Yi Dou, Graham Neubig", "title": "ExplainaBoard: An Explainable Leaderboard for NLP", "comments": "ACL2021 Demo Track", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  With the rapid development of NLP research, leaderboards have emerged as one\ntool to track the performance of various systems on various NLP tasks. They are\neffective in this goal to some extent, but generally present a rather\nsimplistic one-dimensional view of the submitted systems, communicated only\nthrough holistic accuracy numbers. In this paper, we present a new\nconceptualization and implementation of NLP evaluation: the ExplainaBoard,\nwhich in addition to inheriting the functionality of the standard leaderboard,\nalso allows researchers to (i) diagnose strengths and weaknesses of a single\nsystem (e.g.~what is the best-performing system bad at?) (ii) interpret\nrelationships between multiple systems. (e.g.~where does system A outperform\nsystem B? What if we combine systems A, B, and C?) and (iii) examine prediction\nresults closely (e.g.~what are common errors made by multiple systems, or in\nwhat contexts do particular errors occur?). So far, ExplainaBoard covers more\nthan 400 systems, 50 datasets, 40 languages, and 12 tasks. ExplainaBoard keeps\nupdated and is recently upgraded by supporting (1) multilingual multi-task\nbenchmark, (2) meta-evaluation, and (3) more complicated task: machine\ntranslation, which reviewers also suggested.} We not only released an online\nplatform on the website \\url{http://explainaboard.nlpedia.ai/} but also make\nour evaluation tool an API with MIT Licence at Github\n\\url{https://github.com/neulab/explainaBoard} and PyPi\n\\url{https://pypi.org/project/interpret-eval/} that allows users to\nconveniently assess their models offline. We additionally release all output\nfiles from systems that we have run or collected to motivate \"output-driven\"\nresearch in the future.\n", "versions": [{"version": "v1", "created": "Tue, 13 Apr 2021 17:45:50 GMT"}, {"version": "v2", "created": "Thu, 1 Jul 2021 18:50:23 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Liu", "Pengfei", ""], ["Fu", "Jinlan", ""], ["Xiao", "Yang", ""], ["Yuan", "Weizhe", ""], ["Chang", "Shuaicheng", ""], ["Dai", "Junqi", ""], ["Liu", "Yixin", ""], ["Ye", "Zihuiwen", ""], ["Dou", "Zi-Yi", ""], ["Neubig", "Graham", ""]]}, {"id": "2104.06389", "submitter": "Minjie Wang", "authors": "Minjie Wang, Genevera I. Allen", "title": "Thresholded Graphical Lasso Adjusts for Latent Variables: Application to\n  Functional Neural Connectivity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In neuroscience, researchers seek to uncover the connectivity of neurons from\nlarge-scale neural recordings or imaging; often people employ graphical model\nselection and estimation techniques for this purpose. But, existing\ntechnologies can only record from a small subset of neurons leading to a\nchallenging problem of graph selection in the presence of extensive latent\nvariables. Chandrasekaran et al. (2012) proposed a convex program to address\nthis problem that poses challenges from both a computational and statistical\nperspective. To solve this problem, we propose an incredibly simple solution:\napply a hard thresholding operator to existing graph selection methods.\nConceptually simple and computationally attractive, we demonstrate that\nthresholding the graphical Lasso, neighborhood selection, or CLIME estimators\nhave superior theoretical properties in terms of graph selection consistency as\nwell as stronger empirical results than existing approaches for the latent\nvariable graphical model problem. We also demonstrate the applicability of our\napproach through a neuroscience case study on calcium-imaging data to estimate\nfunctional neural connections.\n", "versions": [{"version": "v1", "created": "Tue, 13 Apr 2021 17:50:26 GMT"}], "update_date": "2021-04-14", "authors_parsed": [["Wang", "Minjie", ""], ["Allen", "Genevera I.", ""]]}, {"id": "2104.06390", "submitter": "Eric Wallace", "authors": "Albert Xu, Eshaan Pathak, Eric Wallace, Suchin Gururangan, Maarten\n  Sap, Dan Klein", "title": "Detoxifying Language Models Risks Marginalizing Minority Voices", "comments": "NAACL 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Language models (LMs) must be both safe and equitable to be responsibly\ndeployed in practice. With safety in mind, numerous detoxification techniques\n(e.g., Dathathri et al. 2020; Krause et al. 2020) have been proposed to\nmitigate toxic LM generations. In this work, we show that current\ndetoxification techniques hurt equity: they decrease the utility of LMs on\nlanguage used by marginalized groups (e.g., African-American English and\nminority identity mentions). In particular, we perform automatic and human\nevaluations of text generation quality when LMs are conditioned on inputs with\ndifferent dialects and group identifiers. We find that detoxification makes LMs\nmore brittle to distribution shift, especially on language used by marginalized\ngroups. We identify that these failures stem from detoxification methods\nexploiting spurious correlations in toxicity datasets. Overall, our results\nhighlight the tension between the controllability and distributional robustness\nof LMs.\n", "versions": [{"version": "v1", "created": "Tue, 13 Apr 2021 17:52:01 GMT"}], "update_date": "2021-04-14", "authors_parsed": [["Xu", "Albert", ""], ["Pathak", "Eshaan", ""], ["Wallace", "Eric", ""], ["Gururangan", "Suchin", ""], ["Sap", "Maarten", ""], ["Klein", "Dan", ""]]}, {"id": "2104.06392", "submitter": "R. Kenny Jones", "authors": "R. Kenny Jones, David Charatan, Paul Guerrero, Niloy J. Mitra, Daniel\n  Ritchie", "title": "ShapeMOD: Macro Operation Discovery for 3D Shape Programs", "comments": "SIGGRAPH 2021. Project Page: https://rkjones4.github.io/shapeMOD.html", "journal-ref": null, "doi": "10.1145/3450626.3459821", "report-no": null, "categories": "cs.GR cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A popular way to create detailed yet easily controllable 3D shapes is via\nprocedural modeling, i.e. generating geometry using programs. Such programs\nconsist of a series of instructions along with their associated parameter\nvalues. To fully realize the benefits of this representation, a shape program\nshould be compact and only expose degrees of freedom that allow for meaningful\nmanipulation of output geometry. One way to achieve this goal is to design\nhigher-level macro operators that, when executed, expand into a series of\ncommands from the base shape modeling language. However, manually authoring\nsuch macros, much like shape programs themselves, is difficult and largely\nrestricted to domain experts. In this paper, we present ShapeMOD, an algorithm\nfor automatically discovering macros that are useful across large datasets of\n3D shape programs. ShapeMOD operates on shape programs expressed in an\nimperative, statement-based language. It is designed to discover macros that\nmake programs more compact by minimizing the number of function calls and free\nparameters required to represent an input shape collection. We run ShapeMOD on\nmultiple collections of programs expressed in a domain-specific language for 3D\nshape structures. We show that it automatically discovers a concise set of\nmacros that abstract out common structural and parametric patterns that\ngeneralize over large shape collections. We also demonstrate that the macros\nfound by ShapeMOD improve performance on downstream tasks including shape\ngenerative modeling and inferring programs from point clouds. Finally, we\nconduct a user study that indicates that ShapeMOD's discovered macros make\ninteractive shape editing more efficient.\n", "versions": [{"version": "v1", "created": "Tue, 13 Apr 2021 17:54:03 GMT"}, {"version": "v2", "created": "Tue, 22 Jun 2021 20:56:17 GMT"}], "update_date": "2021-06-24", "authors_parsed": [["Jones", "R. Kenny", ""], ["Charatan", "David", ""], ["Guerrero", "Paul", ""], ["Mitra", "Niloy J.", ""], ["Ritchie", "Daniel", ""]]}, {"id": "2104.06399", "submitter": "Weijian Xu", "authors": "Weijian Xu, Yifan Xu, Tyler Chang, Zhuowen Tu", "title": "Co-Scale Conv-Attentional Image Transformers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present Co-scale conv-attentional image Transformers\n(CoaT), a Transformer-based image classifier equipped with co-scale and\nconv-attentional mechanisms. First, the co-scale mechanism maintains the\nintegrity of Transformers' encoder branches at individual scales, while\nallowing representations learned at different scales to effectively communicate\nwith each other; we design a series of serial and parallel blocks to realize\nthe co-scale attention mechanism. Second, we devise a conv-attentional\nmechanism by realizing a relative position embedding formulation in the\nfactorized attention module with an efficient convolution-like implementation.\nCoaT empowers image Transformers with enriched multi-scale and contextual\nmodeling capabilities. On ImageNet, relatively small CoaT models attain\nsuperior classification results compared with the similar-sized convolutional\nneural networks and image/vision Transformers. The effectiveness of CoaT's\nbackbone is also illustrated on object detection and instance segmentation,\ndemonstrating its applicability to the downstream computer vision tasks.\n", "versions": [{"version": "v1", "created": "Tue, 13 Apr 2021 17:58:29 GMT"}], "update_date": "2021-04-14", "authors_parsed": [["Xu", "Weijian", ""], ["Xu", "Yifan", ""], ["Chang", "Tyler", ""], ["Tu", "Zhuowen", ""]]}, {"id": "2104.06405", "submitter": "Chen-Hsuan Lin", "authors": "Chen-Hsuan Lin, Wei-Chiu Ma, Antonio Torralba, Simon Lucey", "title": "BARF: Bundle-Adjusting Neural Radiance Fields", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.GR cs.LG cs.RO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Neural Radiance Fields (NeRF) have recently gained a surge of interest within\nthe computer vision community for its power to synthesize photorealistic novel\nviews of real-world scenes. One limitation of NeRF, however, is its requirement\nof accurate camera poses to learn the scene representations. In this paper, we\npropose Bundle-Adjusting Neural Radiance Fields (BARF) for training NeRF from\nimperfect (or even unknown) camera poses -- the joint problem of learning\nneural 3D representations and registering camera frames. We establish a\ntheoretical connection to classical image alignment and show that\ncoarse-to-fine registration is also applicable to NeRF. Furthermore, we show\nthat na\\\"ively applying positional encoding in NeRF has a negative impact on\nregistration with a synthesis-based objective. Experiments on synthetic and\nreal-world data show that BARF can effectively optimize the neural scene\nrepresentations and resolve large camera pose misalignment at the same time.\nThis enables view synthesis and localization of video sequences from unknown\ncamera poses, opening up new avenues for visual localization systems (e.g.\nSLAM) and potential applications for dense 3D mapping and reconstruction.\n", "versions": [{"version": "v1", "created": "Tue, 13 Apr 2021 17:59:51 GMT"}], "update_date": "2021-04-14", "authors_parsed": [["Lin", "Chen-Hsuan", ""], ["Ma", "Wei-Chiu", ""], ["Torralba", "Antonio", ""], ["Lucey", "Simon", ""]]}, {"id": "2104.06410", "submitter": "Takato Okudo", "authors": "Takato Okudo and Seiji Yamada", "title": "Reward Shaping with Subgoals for Social Navigation", "comments": "arXiv admin note: substantial text overlap with arXiv:2104.06163", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Social navigation has been gaining attentions with the growth in machine\nintelligence. Since reinforcement learning can select an action in the\nprediction phase at a low computational cost, it has been formulated in a\nsocial navigation tasks. However, reinforcement learning takes an enormous\nnumber of iterations until acquiring a behavior policy in the learning phase.\nThis negatively affects the learning of robot behaviors in the real world. In\nparticular, social navigation includes humans who are unpredictable moving\nobstacles in an environment. We proposed a reward shaping method with subgoals\nto accelerate learning. The main part is an aggregation method that use\nsubgoals to shape a reinforcement learning algorithm. We performed a learning\nexperiment with a social navigation task in which a robot avoided collisions\nand then reached its goal. The experimental results show that our method\nimproved the learning efficiency from a base algorithm in the task.\n", "versions": [{"version": "v1", "created": "Tue, 13 Apr 2021 13:52:58 GMT"}], "update_date": "2021-04-15", "authors_parsed": [["Okudo", "Takato", ""], ["Yamada", "Seiji", ""]]}, {"id": "2104.06411", "submitter": "Takato Okudo", "authors": "Takato Okudo and Seiji Yamada", "title": "Subgoal-based Reward Shaping to Improve Efficiency in Reinforcement\n  Learning", "comments": "This work has been submitted to the IEEE for possible publication.\n  Copyright may be transferred without notice, after which this version may no\n  longer be accessible. arXiv admin note: substantial text overlap with\n  arXiv:2104.06163", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Reinforcement learning, which acquires a policy maximizing long-term rewards,\nhas been actively studied. Unfortunately, this learning type is too slow and\ndifficult to use in practical situations because the state-action space becomes\nhuge in real environments. Many studies have incorporated human knowledge into\nreinforcement Learning. Though human knowledge on trajectories is often used, a\nhuman could be asked to control an AI agent, which can be difficult. Knowledge\non subgoals may lessen this requirement because humans need only to consider a\nfew representative states on an optimal trajectory in their minds. The\nessential factor for learning efficiency is rewards. Potential-based reward\nshaping is a basic method for enriching rewards. However, it is often difficult\nto incorporate subgoals for accelerating learning over potential-based reward\nshaping. This is because the appropriate potentials are not intuitive for\nhumans. We extend potential-based reward shaping and propose a subgoal-based\nreward shaping. The method makes it easier for human trainers to share their\nknowledge of subgoals. To evaluate our method, we obtained a subgoal series\nfrom participants and conducted experiments in three domains,\nfour-rooms(discrete states and discrete actions), pinball(continuous and\ndiscrete), and picking(both continuous). We compared our method with a baseline\nreinforcement learning algorithm and other subgoal-based methods, including\nrandom subgoal and naive subgoal-based reward shaping. As a result, we found\nout that our reward shaping outperformed all other methods in learning\nefficiency.\n", "versions": [{"version": "v1", "created": "Tue, 13 Apr 2021 14:28:48 GMT"}], "update_date": "2021-04-15", "authors_parsed": [["Okudo", "Takato", ""], ["Yamada", "Seiji", ""]]}, {"id": "2104.06461", "submitter": "Anoop Cherian", "authors": "Anoop Cherian, Panagiotis Stanitsas, Jue Wang, Mehrtash Harandi,\n  Vassilios Morellas, Nikolaos Papanikolopoulos", "title": "Learning Log-Determinant Divergences for Positive Definite Matrices", "comments": "Accepted at Trans. PAMI (extended version of ICCV 2017 paper). arXiv\n  admin note: substantial text overlap with arXiv:1708.01741", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Representations in the form of Symmetric Positive Definite (SPD) matrices\nhave been popularized in a variety of visual learning applications due to their\ndemonstrated ability to capture rich second-order statistics of visual data.\nThere exist several similarity measures for comparing SPD matrices with\ndocumented benefits. However, selecting an appropriate measure for a given\nproblem remains a challenge and in most cases, is the result of a\ntrial-and-error process. In this paper, we propose to learn similarity measures\nin a data-driven manner. To this end, we capitalize on the \\alpha\\beta-log-det\ndivergence, which is a meta-divergence parametrized by scalars \\alpha and\n\\beta, subsuming a wide family of popular information divergences on SPD\nmatrices for distinct and discrete values of these parameters. Our key idea is\nto cast these parameters in a continuum and learn them from data. We\nsystematically extend this idea to learn vector-valued parameters, thereby\nincreasing the expressiveness of the underlying non-linear measure. We conjoin\nthe divergence learning problem with several standard tasks in machine\nlearning, including supervised discriminative dictionary learning and\nunsupervised SPD matrix clustering. We present Riemannian gradient descent\nschemes for optimizing our formulations efficiently, and show the usefulness of\nour method on eight standard computer vision tasks.\n", "versions": [{"version": "v1", "created": "Tue, 13 Apr 2021 19:09:43 GMT"}], "update_date": "2021-04-15", "authors_parsed": [["Cherian", "Anoop", ""], ["Stanitsas", "Panagiotis", ""], ["Wang", "Jue", ""], ["Harandi", "Mehrtash", ""], ["Morellas", "Vassilios", ""], ["Papanikolopoulos", "Nikolaos", ""]]}, {"id": "2104.06467", "submitter": "Weiqi Ji", "authors": "Weiqi Ji, Bo Yuan, Ciyue Shen, Aviv Regev, Chris Sander, Sili Deng", "title": "Inference of cell dynamics on perturbation data using adjoint\n  sensitivity", "comments": "Accepted as a workshop paper at ICLR 2021 SimDL Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.MN cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Data-driven dynamic models of cell biology can be used to predict cell\nresponse to unseen perturbations. Recent work (CellBox) had demonstrated the\nderivation of interpretable models with explicit interaction terms, in which\nthe parameters were optimized using machine learning techniques. While the\nprevious work was tested only in a single biological setting, this work aims to\nextend the range of applicability of this model inference approach to a\ndiversity of biological systems. Here we adapted CellBox in Julia differential\nprogramming and augmented the method with adjoint algorithms, which has\nrecently been used in the context of neural ODEs. We trained the models using\nsimulated data from both abstract and biology-inspired networks, which afford\nthe ability to evaluate the recovery of the ground truth network structure. The\nresulting accuracy of prediction by these models is high both in terms of low\nerror against data and excellent agreement with the network structure used for\nthe simulated training data. While there is no analogous ground truth for real\nlife biological systems, this work demonstrates the ability to construct and\nparameterize a considerable diversity of network models with high predictive\nability. The expectation is that this kind of procedure can be used on real\nperturbation-response data to derive models applicable to diverse biological\nsystems.\n", "versions": [{"version": "v1", "created": "Tue, 13 Apr 2021 19:15:56 GMT"}], "update_date": "2021-04-15", "authors_parsed": [["Ji", "Weiqi", ""], ["Yuan", "Bo", ""], ["Shen", "Ciyue", ""], ["Regev", "Aviv", ""], ["Sander", "Chris", ""], ["Deng", "Sili", ""]]}, {"id": "2104.06486", "submitter": "Jay DeYoung", "authors": "Jay DeYoung, Iz Beltagy, Madeleine van Zuylen, Bailey Kuehl, Lucy Lu\n  Wang", "title": "MS2: Multi-Document Summarization of Medical Studies", "comments": "8 pages of content, 20 pages including references and appendix. See\n  https://github.com/allenai/ms2/ for code,\n  https://ai2-s2-ms2.s3-us-west-2.amazonaws.com/ms_data_2021-04-12.zip for data\n  (1.8G, zipped)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  To assess the effectiveness of any medical intervention, researchers must\nconduct a time-intensive and highly manual literature review. NLP systems can\nhelp to automate or assist in parts of this expensive process. In support of\nthis goal, we release MS^2 (Multi-Document Summarization of Medical Studies), a\ndataset of over 470k documents and 20k summaries derived from the scientific\nliterature. This dataset facilitates the development of systems that can assess\nand aggregate contradictory evidence across multiple studies, and is the first\nlarge-scale, publicly available multi-document summarization dataset in the\nbiomedical domain. We experiment with a summarization system based on BART,\nwith promising early results. We formulate our summarization inputs and targets\nin both free text and structured forms and modify a recently proposed metric to\nassess the quality of our system's generated summaries. Data and models are\navailable at https://github.com/allenai/ms2\n", "versions": [{"version": "v1", "created": "Tue, 13 Apr 2021 19:59:34 GMT"}, {"version": "v2", "created": "Thu, 15 Apr 2021 16:09:21 GMT"}], "update_date": "2021-04-16", "authors_parsed": [["DeYoung", "Jay", ""], ["Beltagy", "Iz", ""], ["van Zuylen", "Madeleine", ""], ["Kuehl", "Bailey", ""], ["Wang", "Lucy Lu", ""]]}, {"id": "2104.06487", "submitter": "Chiwoo Park", "authors": "Chiwoo Park", "title": "Gaussian Process Model for Estimating Piecewise Continuous Regression\n  Functions", "comments": "11 pages; 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a Gaussian process (GP) model for estimating piecewise\ncontinuous regression functions. In scientific and engineering applications of\nregression analysis, the underlying regression functions are piecewise\ncontinuous in that data follow different continuous regression models for\ndifferent regions of the data with possible discontinuities between the\nregions. However, many conventional GP regression approaches are not designed\nfor piecewise regression analysis. We propose a new GP modeling approach for\nestimating an unknown piecewise continuous regression function. The new GP\nmodel seeks for a local GP estimate of an unknown regression function at each\ntest location, using local data neighboring to the test location. To\naccommodate the possibilities of the local data from different regions, the\nlocal data is partitioned into two sides by a local linear boundary, and only\nthe local data belonging to the same side as the test location is used for the\nregression estimate. This local split works very well when the input regions\nare bounded by smooth boundaries, so the local linear approximation of the\nsmooth boundaries works well. We estimate the local linear boundary jointly\nwith the other hyperparameters of the GP model, using the maximum likelihood\napproach. Its computation time is as low as the local GP's time. The superior\nnumerical performance of the proposed approach over the conventional GP\nmodeling approaches is shown using various simulated piecewise regression\nfunctions.\n", "versions": [{"version": "v1", "created": "Tue, 13 Apr 2021 20:01:43 GMT"}], "update_date": "2021-04-15", "authors_parsed": [["Park", "Chiwoo", ""]]}, {"id": "2104.06506", "submitter": "Myounggyu Won", "authors": "Lokesh Das and Myounggyu Won", "title": "SAINT-ACC: Safety-Aware Intelligent Adaptive Cruise Control for\n  Autonomous Vehicles Using Deep Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an autonomous adaptive cruise control (ACC) system namely\nSAINT-ACC: {S}afety-{A}ware {Int}elligent {ACC} system (SAINT-ACC) that is\ndesigned to achieve simultaneous optimization of traffic efficiency, driving\nsafety, and driving comfort through dynamic adaptation of the inter-vehicle gap\nbased on deep reinforcement learning (RL). A novel dual RL agent-based approach\nis developed to seek and adapt the optimal balance between traffic efficiency\nand driving safety/comfort by effectively controlling the driving safety model\nparameters and inter-vehicle gap based on macroscopic and microscopic traffic\ninformation collected from dynamically changing and complex traffic\nenvironments. Results obtained through over 12,000 simulation runs with varying\ntraffic scenarios and penetration rates demonstrate that SAINT-ACC\nsignificantly enhances traffic flow, driving safety and comport compared with\nthe state-of-the-art approach.\n", "versions": [{"version": "v1", "created": "Sat, 6 Mar 2021 14:01:29 GMT"}], "update_date": "2021-04-15", "authors_parsed": [["Das", "Lokesh", ""], ["Won", "Myounggyu", ""]]}, {"id": "2104.06517", "submitter": "Eunjeong Koh", "authors": "Eunjeong Koh and Shlomo Dubnov", "title": "Comparison and Analysis of Deep Audio Embeddings for Music Emotion\n  Recognition", "comments": "AAAI Workshop on Affective Content Analysis 2021 Camera Ready Version", "journal-ref": "AAAI 2021", "doi": null, "report-no": null, "categories": "cs.SD cs.AI cs.LG cs.MM eess.AS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Emotion is a complicated notion present in music that is hard to capture even\nwith fine-tuned feature engineering. In this paper, we investigate the utility\nof state-of-the-art pre-trained deep audio embedding methods to be used in the\nMusic Emotion Recognition (MER) task. Deep audio embedding methods allow us to\nefficiently capture the high dimensional features into a compact\nrepresentation. We implement several multi-class classifiers with deep audio\nembeddings to predict emotion semantics in music. We investigate the\neffectiveness of L3-Net and VGGish deep audio embedding methods for music\nemotion inference over four music datasets. The experiments with several\nclassifiers on the task show that the deep audio embedding solutions can\nimprove the performances of the previous baseline MER models. We conclude that\ndeep audio embeddings represent musical emotion semantics for the MER task\nwithout expert human engineering.\n", "versions": [{"version": "v1", "created": "Tue, 13 Apr 2021 21:09:54 GMT"}], "update_date": "2021-04-15", "authors_parsed": [["Koh", "Eunjeong", ""], ["Dubnov", "Shlomo", ""]]}, {"id": "2104.06521", "submitter": "Haonan Yu", "authors": "Haonan Yu, Wei Xu, Haichao Zhang", "title": "TAAC: Temporally Abstract Actor-Critic for Continuous Control", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose temporally abstract actor-critic (TAAC), an off-policy RL\nalgorithm that incorporates closed-loop temporal abstraction into the\nactor-critic framework in a simple manner. TAAC adds a second-stage binary\npolicy to choose between the previous action and a new action output by an\nactor. Crucially, its act-or-repeat decision hinges on the actually sampled\naction instead of the expected behavior of the actor. This post-acting\nswitching scheme let the overall policy make more informed decisions. TAAC has\ntwo important features: persistent exploration and a new compare-through Q\noperator for multi-step TD backup. We demonstrate TAAC's advantages over\nseveral strong baselines across 5 different categories of 14 continuous control\ntasks. Code is available at https://github.com/hnyu/taac.\n", "versions": [{"version": "v1", "created": "Tue, 13 Apr 2021 21:24:44 GMT"}, {"version": "v2", "created": "Fri, 28 May 2021 02:57:36 GMT"}], "update_date": "2021-05-31", "authors_parsed": [["Yu", "Haonan", ""], ["Xu", "Wei", ""], ["Zhang", "Haichao", ""]]}, {"id": "2104.06523", "submitter": "Iyiola E. Olatunji", "authors": "Iyiola E. Olatunji, Jens Rauch, Matthias Katzensteiner, Megha Khosla", "title": "A Review of Anonymization for Healthcare Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Mining health data can lead to faster medical decisions, improvement in the\nquality of treatment, disease prevention, reduced cost, and it drives\ninnovative solutions within the healthcare sector. However, health data is\nhighly sensitive and subject to regulations such as the General Data Protection\nRegulation (GDPR), which aims to ensure patient's privacy. Anonymization or\nremoval of patient identifiable information, though the most conventional way,\nis the first important step to adhere to the regulations and incorporate\nprivacy concerns. In this paper, we review the existing anonymization\ntechniques and their applicability to various types (relational and\ngraph-based) of health data. Besides, we provide an overview of possible\nattacks on anonymized data. We illustrate via a reconstruction attack that\nanonymization though necessary, is not sufficient to address patient privacy\nand discuss methods for protecting against such attacks. Finally, we discuss\ntools that can be used to achieve anonymization.\n", "versions": [{"version": "v1", "created": "Tue, 13 Apr 2021 21:44:29 GMT"}], "update_date": "2021-04-15", "authors_parsed": [["Olatunji", "Iyiola E.", ""], ["Rauch", "Jens", ""], ["Katzensteiner", "Matthias", ""], ["Khosla", "Megha", ""]]}, {"id": "2104.06524", "submitter": "Madhu Kiran", "authors": "Madhu Kiran, R Gnana Praveen, Le Thanh Nguyen-Meidine, Soufiane\n  Belharbi, Louis-Antoine Blais-Morin, Eric Granger", "title": "Holistic Guidance for Occluded Person Re-Identification", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In real-world video surveillance applications, person re-identification\n(ReID) suffers from the effects of occlusions and detection errors. Despite\nrecent advances, occlusions continue to corrupt the features extracted by\nstate-of-art CNN backbones, and thereby deteriorate the accuracy of ReID\nsystems. To address this issue, methods in the literature use an additional\ncostly process such as pose estimation, where pose maps provide supervision to\nexclude occluded regions. In contrast, we introduce a novel Holistic Guidance\n(HG) method that relies only on person identity labels, and on the distribution\nof pairwise matching distances of datasets to alleviate the problem of\nocclusion, without requiring additional supervision. Hence, our proposed\nstudent-teacher framework is trained to address the occlusion problem by\nmatching the distributions of between- and within-class distances (DCDs) of\noccluded samples with that of holistic (non-occluded) samples, thereby using\nthe latter as a soft labeled reference to learn well separated DCDs. This\napproach is supported by our empirical study where the distribution of between-\nand within-class distances between images have more overlap in occluded than\nholistic datasets. In particular, features extracted from both datasets are\njointly learned using the student model to produce an attention map that allows\nseparating visible regions from occluded ones. In addition to this, a joint\ngenerative-discriminative backbone is trained with a denoising autoencoder,\nallowing the system to self-recover from occlusions. Extensive experiments on\nseveral challenging public datasets indicate that the proposed approach can\noutperform state-of-the-art methods on both occluded and holistic datasets\n", "versions": [{"version": "v1", "created": "Tue, 13 Apr 2021 21:50:29 GMT"}], "update_date": "2021-04-15", "authors_parsed": [["Kiran", "Madhu", ""], ["Praveen", "R Gnana", ""], ["Nguyen-Meidine", "Le Thanh", ""], ["Belharbi", "Soufiane", ""], ["Blais-Morin", "Louis-Antoine", ""], ["Granger", "Eric", ""]]}, {"id": "2104.06529", "submitter": "Rafael Ferreira", "authors": "Rafael Ferreira, David Semedo, Joao Magalhaes", "title": "BERT Embeddings Can Track Context in Conversational Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The use of conversational assistants to search for information is becoming\nincreasingly more popular among the general public, pushing the research\ntowards more advanced and sophisticated techniques. In the last few years, in\nparticular, the interest in conversational search is increasing, not only\nbecause of the generalization of conversational assistants but also because\nconversational search is a step forward in allowing a more natural interaction\nwith the system.\n  In this work, the focus is on exploring the context present of the\nconversation via the historical utterances and respective embeddings with the\naim of developing a conversational search system that helps people search for\ninformation in a natural way. In particular, this system must be able to\nunderstand the context where the question is posed, tracking the current state\nof the conversation and detecting mentions to previous questions and answers.\nWe achieve this by using a context-tracking component based on neural\nquery-rewriting models. Another crucial aspect of the system is to provide the\nmost relevant answers given the question and the conversational history. To\nachieve this objective, we used a Transformer-based re-ranking method and\nexpanded this architecture to use the conversational context.\n  The results obtained with the system developed showed the advantages of using\nthe context present in the natural language utterances and in the neural\nembeddings generated throughout the conversation.\n", "versions": [{"version": "v1", "created": "Tue, 13 Apr 2021 22:02:24 GMT"}], "update_date": "2021-04-15", "authors_parsed": [["Ferreira", "Rafael", ""], ["Semedo", "David", ""], ["Magalhaes", "Joao", ""]]}, {"id": "2104.06534", "submitter": "Rakhil Immidisetti", "authors": "Rakhil Immidisetti, Shuowen Hu, Vishal M. Patel", "title": "Simultaneous Face Hallucination and Translation for Thermal to Visible\n  Face Verification using Axial-GAN", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Existing thermal-to-visible face verification approaches expect the thermal\nand visible face images to be of similar resolution. This is unlikely in\nreal-world long-range surveillance systems, since humans are distant from the\ncameras. To address this issue, we introduce the task of thermal-to-visible\nface verification from low-resolution thermal images. Furthermore, we propose\nAxial-Generative Adversarial Network (Axial-GAN) to synthesize high-resolution\nvisible images for matching. In the proposed approach we augment the GAN\nframework with axial-attention layers which leverage the recent advances in\ntransformers for modelling long-range dependencies. We demonstrate the\neffectiveness of the proposed method by evaluating on two different\nthermal-visible face datasets. When compared to related state-of-the-art works,\nour results show significant improvements in both image quality and face\nverification performance, and are also much more efficient.\n", "versions": [{"version": "v1", "created": "Tue, 13 Apr 2021 22:34:28 GMT"}], "update_date": "2021-04-15", "authors_parsed": [["Immidisetti", "Rakhil", ""], ["Hu", "Shuowen", ""], ["Patel", "Vishal M.", ""]]}, {"id": "2104.06548", "submitter": "Alexander Litvinenko", "authors": "Vladimir Berikov and Alexander Litvinenko", "title": "Solving weakly supervised regression problem using low-rank manifold\n  regularization", "comments": "14 pages, 5 Tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA math.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We solve a weakly supervised regression problem. Under \"weakly\" we understand\nthat for some training points the labels are known, for some unknown, and for\nothers uncertain due to the presence of random noise or other reasons such as\nlack of resources. The solution process requires to optimize a certain\nobjective function (the loss function), which combines manifold regularization\nand low-rank matrix decomposition techniques. These low-rank approximations\nallow us to speed up all matrix calculations and reduce storage requirements.\nThis is especially crucial for large datasets. Ensemble clustering is used for\nobtaining the co-association matrix, which we consider as the similarity\nmatrix. The utilization of these techniques allows us to increase the quality\nand stability of the solution. In the numerical section, we applied the\nsuggested method to artificial and real datasets using Monte-Carlo modeling.\n", "versions": [{"version": "v1", "created": "Tue, 13 Apr 2021 23:21:01 GMT"}], "update_date": "2021-04-15", "authors_parsed": [["Berikov", "Vladimir", ""], ["Litvinenko", "Alexander", ""]]}, {"id": "2104.06556", "submitter": "Matthew Zurek", "authors": "Matthew Zurek, Andreea Bobu, Daniel S. Brown, Anca D. Dragan", "title": "Situational Confidence Assistance for Lifelong Shared Autonomy", "comments": "In proceedings ICRA 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Shared autonomy enables robots to infer user intent and assist in\naccomplishing it. But when the user wants to do a new task that the robot does\nnot know about, shared autonomy will hinder their performance by attempting to\nassist them with something that is not their intent. Our key idea is that the\nrobot can detect when its repertoire of intents is insufficient to explain the\nuser's input, and give them back control. This then enables the robot to\nobserve unhindered task execution, learn the new intent behind it, and add it\nto this repertoire. We demonstrate with both a case study and a user study that\nour proposed method maintains good performance when the human's intent is in\nthe robot's repertoire, outperforms prior shared autonomy approaches when it\nisn't, and successfully learns new skills, enabling efficient lifelong learning\nfor confidence-based shared autonomy.\n", "versions": [{"version": "v1", "created": "Wed, 14 Apr 2021 00:00:07 GMT"}], "update_date": "2021-04-15", "authors_parsed": [["Zurek", "Matthew", ""], ["Bobu", "Andreea", ""], ["Brown", "Daniel S.", ""], ["Dragan", "Anca D.", ""]]}, {"id": "2104.06557", "submitter": "Sreya Francis", "authors": "Sreya Francis, Irene Tenison, Irina Rish", "title": "Towards Causal Federated Learning For Enhanced Robustness and Privacy", "comments": null, "journal-ref": "ICLR 2021 Distributed and Private Machine Learning(DPML) Workshop", "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated Learning is an emerging privacy-preserving distributed machine\nlearning approach to building a shared model by performing distributed training\nlocally on participating devices (clients) and aggregating the local models\ninto a global one. As this approach prevents data collection and aggregation,\nit helps in reducing associated privacy risks to a great extent. However, the\ndata samples across all participating clients are usually not independent and\nidentically distributed (non-iid), and Out of Distribution(OOD) generalization\nfor the learned models can be poor. Besides this challenge, federated learning\nalso remains vulnerable to various attacks on security wherein a few malicious\nparticipating entities work towards inserting backdoors, degrading the\ngenerated aggregated model as well as inferring the data owned by participating\nentities. In this paper, we propose an approach for learning invariant (causal)\nfeatures common to all participating clients in a federated learning setup and\nanalyze empirically how it enhances the Out of Distribution (OOD) accuracy as\nwell as the privacy of the final learned model.\n", "versions": [{"version": "v1", "created": "Wed, 14 Apr 2021 00:08:45 GMT"}], "update_date": "2021-04-15", "authors_parsed": [["Francis", "Sreya", ""], ["Tenison", "Irene", ""], ["Rish", "Irina", ""]]}, {"id": "2104.06559", "submitter": "Jiajun Zhou", "authors": "Jie Shen, Jiajun Zhou, Yunyi Xie, Shanqing Yu, and Qi Xuan", "title": "Identity Inference on Blockchain using Graph Neural Network", "comments": "Under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The anonymity of blockchain has accelerated the growth of illegal activities\nand criminal behaviors on cryptocurrency platforms. Although decentralization\nis one of the typical characteristics of blockchain, we urgently call for\neffective regulation to detect these illegal behaviors to ensure the safety and\nstability of user transactions. Identity inference, which aims to make a\npreliminary inference about account identity, plays a significant role in\nblockchain security. As a common tool, graph mining technique can effectively\nrepresent the interactive information between accounts and be used for identity\ninference. However, existing methods cannot balance scalability and end-to-end\narchitecture, resulting high computational consumption and weak feature\nrepresentation. In this paper, we present a novel approach to analyze user's\nbehavior from the perspective of the transaction subgraph, which naturally\ntransforms the identity inference task into a graph classification pattern and\neffectively avoids computation in large-scale graph. Furthermore, we propose a\ngeneric end-to-end graph neural network model, named $\\text{I}^2 \\text{BGNN}$,\nwhich can accept subgraph as input and learn a function mapping the transaction\nsubgraph pattern to account identity, achieving de-anonymization. Extensive\nexperiments on EOSG and ETHG datasets demonstrate that the proposed method\nachieve the state-of-the-art performance in identity inference.\n", "versions": [{"version": "v1", "created": "Wed, 14 Apr 2021 00:15:38 GMT"}], "update_date": "2021-04-15", "authors_parsed": [["Shen", "Jie", ""], ["Zhou", "Jiajun", ""], ["Xie", "Yunyi", ""], ["Yu", "Shanqing", ""], ["Xuan", "Qi", ""]]}, {"id": "2104.06574", "submitter": "Youngdong Kim", "authors": "Youngdong Kim, Juseung Yun, Hyounguk Shon, Junmo Kim", "title": "Joint Negative and Positive Learning for Noisy Labels", "comments": "CVPR 2021, Accepted", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training of Convolutional Neural Networks (CNNs) with data with noisy labels\nis known to be a challenge. Based on the fact that directly providing the label\nto the data (Positive Learning; PL) has a risk of allowing CNNs to memorize the\ncontaminated labels for the case of noisy data, the indirect learning approach\nthat uses complementary labels (Negative Learning for Noisy Labels; NLNL) has\nproven to be highly effective in preventing overfitting to noisy data as it\nreduces the risk of providing faulty target. NLNL further employs a three-stage\npipeline to improve convergence. As a result, filtering noisy data through the\nNLNL pipeline is cumbersome, increasing the training cost. In this study, we\npropose a novel improvement of NLNL, named Joint Negative and Positive Learning\n(JNPL), that unifies the filtering pipeline into a single stage. JNPL trains\nCNN via two losses, NL+ and PL+, which are improved upon NL and PL loss\nfunctions, respectively. We analyze the fundamental issue of NL loss function\nand develop new NL+ loss function producing gradient that enhances the\nconvergence of noisy data. Furthermore, PL+ loss function is designed to enable\nfaster convergence to expected-to-be-clean data. We show that the NL+ and PL+\ntrain CNN simultaneously, significantly simplifying the pipeline, allowing\ngreater ease of practical use compared to NLNL. With a simple semi-supervised\ntraining technique, our method achieves state-of-the-art accuracy for noisy\ndata classification based on the superior filtering ability.\n", "versions": [{"version": "v1", "created": "Wed, 14 Apr 2021 01:32:25 GMT"}], "update_date": "2021-04-15", "authors_parsed": [["Kim", "Youngdong", ""], ["Yun", "Juseung", ""], ["Shon", "Hyounguk", ""], ["Kim", "Junmo", ""]]}, {"id": "2104.06575", "submitter": "Sterling Baird", "authors": "Sterling G. Baird, Eric R. Homer, David T. Fullwood, Oliver K. Johnson", "title": "Five Degree-of-Freedom Property Interpolation of Arbitrary Grain\n  Boundaries via Voronoi Fundamental Zone Octonion Framework", "comments": "main: 22 pages, 10 figures; appendices: 5 pages, 3 figures; supp: 13\n  pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cond-mat.mtrl-sci cs.CG cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We introduce the Voronoi fundamental zone octonion interpolation framework\nfor grain boundary (GB) structure-property models and surrogates. The VFZO\nframework offers an advantage over other five degree-of-freedom based property\ninterpolation methods because it is constructed as a point set in a manifold.\nThis means that directly computed Euclidean distances approximate the original\noctonion distance with significantly reduced computation runtime (~7 CPU\nminutes vs. 153 CPU days for a 50000x50000 pairwise-distance matrix). This\nincreased efficiency facilitates lower interpolation error through the use of\nsignificantly more input data. We demonstrate grain boundary energy\ninterpolation results for a non-smooth validation function and simulated\nbi-crystal datasets for Fe and Ni using four interpolation methods: barycentric\ninterpolation, Gaussian process regression (GPR), inverse-distance weighting,\nand nearest-neighbor interpolation. These are evaluated for 50000 random input\nGBs and 10 000 random prediction GBs. The best performance was achieved with\nGPR, which resulted in a reduction of the root mean square error (RMSE) by\n83.0% relative to RMSE of a constant, average model. Likewise, interpolation on\na large, noisy, molecular statics Fe simulation dataset improves performance by\n34.4% compared to 21.2% in prior work. Interpolation on a small, low-noise MS\nNi simulation dataset is similar to interpolation results for the original\noctonion metric (57.6% vs. 56.4%). A vectorized, parallelized, MATLAB\ninterpolation function (interp5DOF.m) and related routines are available in our\nVFZO repository (github.com/sgbaird-5dof/interp) which can be applied to other\ncrystallographic point groups. The VFZO framework offers advantages for\ncomputing distances between GBs, estimating property values for arbitrary GBs,\nand modeling surrogates of computationally expensive 5DOF functions and\nsimulations.\n", "versions": [{"version": "v1", "created": "Wed, 14 Apr 2021 01:33:20 GMT"}], "update_date": "2021-04-15", "authors_parsed": [["Baird", "Sterling G.", ""], ["Homer", "Eric R.", ""], ["Fullwood", "David T.", ""], ["Johnson", "Oliver K.", ""]]}, {"id": "2104.06594", "submitter": "Matthias Chung", "authors": "Babak Maboudi Afkham and Julianne Chung and Matthias Chung", "title": "Learning Regularization Parameters of Inverse Problems via Deep Neural\n  Networks", "comments": "27 pages, 16 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.LG cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we describe a new approach that uses deep neural networks (DNN)\nto obtain regularization parameters for solving inverse problems. We consider a\nsupervised learning approach, where a network is trained to approximate the\nmapping from observation data to regularization parameters. Once the network is\ntrained, regularization parameters for newly obtained data can be computed by\nefficient forward propagation of the DNN. We show that a wide variety of\nregularization functionals, forward models, and noise models may be considered.\nThe network-obtained regularization parameters can be computed more efficiently\nand may even lead to more accurate solutions compared to existing\nregularization parameter selection methods. We emphasize that the key advantage\nof using DNNs for learning regularization parameters, compared to previous\nworks on learning via optimal experimental design or empirical Bayes risk\nminimization, is greater generalizability. That is, rather than computing one\nset of parameters that is optimal with respect to one particular design\nobjective, DNN-computed regularization parameters are tailored to the specific\nfeatures or properties of the newly observed data. Thus, our approach may\nbetter handle cases where the observation is not a close representation of the\ntraining set. Furthermore, we avoid the need for expensive and challenging\nbilevel optimization methods as utilized in other existing training approaches.\nNumerical results demonstrate the potential of using DNNs to learn\nregularization parameters.\n", "versions": [{"version": "v1", "created": "Wed, 14 Apr 2021 02:38:38 GMT"}], "update_date": "2021-04-15", "authors_parsed": [["Afkham", "Babak Maboudi", ""], ["Chung", "Julianne", ""], ["Chung", "Matthias", ""]]}, {"id": "2104.06599", "submitter": "Guanghui Qin", "authors": "Guanghui Qin, Jason Eisner", "title": "Learning How to Ask: Querying LMs with Mixtures of Soft Prompts", "comments": "NAACL-HLT 2021 camera-ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Natural-language prompts have recently been used to coax pretrained language\nmodels into performing other AI tasks, using a fill-in-the-blank paradigm\n(Petroni et al., 2019) or a few-shot extrapolation paradigm (Brown et al.,\n2020). For example, language models retain factual knowledge from their\ntraining corpora that can be extracted by asking them to \"fill in the blank\" in\na sentential prompt. However, where does this prompt come from? We explore the\nidea of learning prompts by gradient descent -- either fine-tuning prompts\ntaken from previous work, or starting from random initialization. Our prompts\nconsist of \"soft words,\" i.e., continuous vectors that are not necessarily word\ntype embeddings from the language model. Furthermore, for each task, we\noptimize a mixture of prompts, learning which prompts are most effective and\nhow to ensemble them. Across multiple English LMs and tasks, our approach\nhugely outperforms previous methods, showing that the implicit factual\nknowledge in language models was previously underestimated. Moreover, this\nknowledge is cheap to elicit: random initialization is nearly as good as\ninformed initialization.\n", "versions": [{"version": "v1", "created": "Wed, 14 Apr 2021 02:56:14 GMT"}], "update_date": "2021-04-15", "authors_parsed": [["Qin", "Guanghui", ""], ["Eisner", "Jason", ""]]}, {"id": "2104.06600", "submitter": "Guangliang Li", "authors": "Jie Huang, Rongshun Juan, Randy Gomez, Keisuke Nakamura, Qixin Sha, Bo\n  He, Guangliang Li", "title": "GAN-Based Interactive Reinforcement Learning from Demonstration and\n  Human Evaluative Feedback", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Deep reinforcement learning (DRL) has achieved great successes in many\nsimulated tasks. The sample inefficiency problem makes applying traditional DRL\nmethods to real-world robots a great challenge. Generative Adversarial\nImitation Learning (GAIL) -- a general model-free imitation learning method,\nallows robots to directly learn policies from expert trajectories in large\nenvironments. However, GAIL shares the limitation of other imitation learning\nmethods that they can seldom surpass the performance of demonstrations. In this\npaper, to address the limit of GAIL, we propose GAN-Based Interactive\nReinforcement Learning (GAIRL) from demonstration and human evaluative feedback\nby combining the advantages of GAIL and interactive reinforcement learning. We\ntested our proposed method in six physics-based control tasks, ranging from\nsimple low-dimensional control tasks -- Cart Pole and Mountain Car, to\ndifficult high-dimensional tasks -- Inverted Double Pendulum, Lunar Lander,\nHopper and HalfCheetah. Our results suggest that with both optimal and\nsuboptimal demonstrations, a GAIRL agent can always learn a more stable policy\nwith optimal or close to optimal performance, while the performance of the GAIL\nagent is upper bounded by the performance of demonstrations or even worse than\nit. In addition, our results indicate the reason that GAIRL is superior over\nGAIL is the complementary effect of demonstrations and human evaluative\nfeedback.\n", "versions": [{"version": "v1", "created": "Wed, 14 Apr 2021 02:58:51 GMT"}], "update_date": "2021-04-15", "authors_parsed": [["Huang", "Jie", ""], ["Juan", "Rongshun", ""], ["Gomez", "Randy", ""], ["Nakamura", "Keisuke", ""], ["Sha", "Qixin", ""], ["He", "Bo", ""], ["Li", "Guangliang", ""]]}, {"id": "2104.06608", "submitter": "Huan Zhao Dr.", "authors": "Huan Zhao, Quanming Yao, Weiwei Tu", "title": "Search to aggregate neighborhood for graph neural network", "comments": "Accepted as a long paper in ICDE 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent years have witnessed the popularity and success of graph neural\nnetworks (GNN) in various scenarios. To obtain data-specific GNN architectures,\nresearchers turn to neural architecture search (NAS), which has made impressive\nsuccess in discovering effective architectures in convolutional neural\nnetworks. However, it is non-trivial to apply NAS approaches to GNN due to\nchallenges in search space design and the expensive searching cost of existing\nNAS methods. In this work, to obtain the data-specific GNN architectures and\naddress the computational challenges facing by NAS approaches, we propose a\nframework, which tries to Search to Aggregate NEighborhood (SANE), to\nautomatically design data-specific GNN architectures. By designing a novel and\nexpressive search space, we propose a differentiable search algorithm, which is\nmore efficient than previous reinforcement learning based methods. Experimental\nresults on four tasks and seven real-world datasets demonstrate the superiority\nof SANE compared to existing GNN models and NAS approaches in terms of\neffectiveness and efficiency. (Code is available at:\nhttps://github.com/AutoML-4Paradigm/SANE).\n", "versions": [{"version": "v1", "created": "Wed, 14 Apr 2021 03:15:19 GMT"}, {"version": "v2", "created": "Tue, 20 Apr 2021 03:02:06 GMT"}], "update_date": "2021-04-21", "authors_parsed": [["Zhao", "Huan", ""], ["Yao", "Quanming", ""], ["Tu", "Weiwei", ""]]}, {"id": "2104.06612", "submitter": "Seonho Park", "authors": "Seonho Park, Panos M. Pardalos", "title": "Deep Data Density Estimation through Donsker-Varadhan Representation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.IT math.IT math.PR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Estimating the data density is one of the challenging problems in deep\nlearning. In this paper, we present a simple yet effective method for\nestimating the data density using a deep neural network and the\nDonsker-Varadhan variational lower bound on the KL divergence. We show that the\noptimal critic function associated with the Donsker-Varadhan representation on\nthe KL divergence between the data and the uniform distribution can estimate\nthe data density. We also present the deep neural network-based modeling and\nits stochastic learning. The experimental results and possible applications of\nthe proposed method demonstrate that it is competitive with the previous\nmethods and has a lot of possibilities in applied to various applications.\n", "versions": [{"version": "v1", "created": "Wed, 14 Apr 2021 03:38:32 GMT"}], "update_date": "2021-04-15", "authors_parsed": [["Park", "Seonho", ""], ["Pardalos", "Panos M.", ""]]}, {"id": "2104.06613", "submitter": "Feiyang Cai", "authors": "Feiyang Cai, Ali I. Ozdagli, Xenofon Koutsoukos", "title": "Detection of Dataset Shifts in Learning-Enabled Cyber-Physical Systems\n  using Variational Autoencoder for Regression", "comments": "Accepted by the 4th IEEE International Conference on Industrial\n  Cyber-Physical Systems (ICPS2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cyber-physical systems (CPSs) use learning-enabled components (LECs)\nextensively to cope with various complex tasks under high-uncertainty\nenvironments. However, the dataset shifts between the training and testing\nphase may lead the LECs to become ineffective to make large-error predictions,\nand further, compromise the safety of the overall system. In our paper, we\nfirst provide the formal definitions for different types of dataset shifts in\nlearning-enabled CPS. Then, we propose an approach to detect the dataset shifts\neffectively for regression problems. Our approach is based on the inductive\nconformal anomaly detection and utilizes a variational autoencoder for\nregression model which enables the approach to take into consideration both LEC\ninput and output for detecting dataset shifts. Additionally, in order to\nimprove the robustness of detection, layer-wise relevance propagation (LRP) is\nincorporated into our approach. We demonstrate our approach by using an\nadvanced emergency braking system implemented in an open-source simulator for\nself-driving cars. The evaluation results show that our approach can detect\ndifferent types of dataset shifts with a small number of false alarms while the\nexecution time is smaller than the sampling period of the system.\n", "versions": [{"version": "v1", "created": "Wed, 14 Apr 2021 03:46:37 GMT"}], "update_date": "2021-04-15", "authors_parsed": [["Cai", "Feiyang", ""], ["Ozdagli", "Ali I.", ""], ["Koutsoukos", "Xenofon", ""]]}, {"id": "2104.06622", "submitter": "Yuxin Chen", "authors": "Chinmaya Mahesh, Kristin Dona, David W. Miller, Yuxin Chen", "title": "Towards an Interpretable Data-driven Trigger System for High-throughput\n  Physics Facilities", "comments": "Appeared in the 3rd Workshop on Machine Learning and the Physical\n  Sciences, NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG hep-ex physics.ins-det", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data-intensive science is increasingly reliant on real-time processing\ncapabilities and machine learning workflows, in order to filter and analyze the\nextreme volumes of data being collected. This is especially true at the energy\nand intensity frontiers of particle physics where bandwidths of raw data can\nexceed 100 Tb/s of heterogeneous, high-dimensional data sourced from hundreds\nof millions of individual sensors. In this paper, we introduce a new\ndata-driven approach for designing and optimizing high-throughput data\nfiltering and trigger systems such as those in use at physics facilities like\nthe Large Hadron Collider (LHC). Concretely, our goal is to design a\ndata-driven filtering system with a minimal run-time cost for determining which\ndata event to keep, while preserving (and potentially improving upon) the\ndistribution of the output as generated by the hand-designed trigger system. We\nintroduce key insights from interpretable predictive modeling and\ncost-sensitive learning in order to account for non-local inefficiencies in the\ncurrent paradigm and construct a cost-effective data filtering and trigger\nmodel that does not compromise physics coverage.\n", "versions": [{"version": "v1", "created": "Wed, 14 Apr 2021 05:01:32 GMT"}], "update_date": "2021-04-21", "authors_parsed": [["Mahesh", "Chinmaya", ""], ["Dona", "Kristin", ""], ["Miller", "David W.", ""], ["Chen", "Yuxin", ""]]}, {"id": "2104.06624", "submitter": "Jiangchao Yao", "authors": "Jiangchao Yao and Feng Wang and KunYang Jia and Bo Han and Jingren\n  Zhou and Hongxia Yang", "title": "Device-Cloud Collaborative Learning for Recommendation", "comments": "KDD 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  With the rapid development of storage and computing power on mobile devices,\nit becomes critical and popular to deploy models on devices to save onerous\ncommunication latencies and to capture real-time features. While quite a lot of\nworks have explored to facilitate on-device learning and inference, most of\nthem focus on dealing with response delay or privacy protection. Little has\nbeen done to model the collaboration between the device and the cloud modeling\nand benefit both sides jointly. To bridge this gap, we are among the first\nattempts to study the Device-Cloud Collaborative Learning (DCCL) framework.\nSpecifically, we propose a novel MetaPatch learning approach on the device side\nto efficiently achieve \"thousands of people with thousands of models\" given a\ncentralized cloud model. Then, with billions of updated personalized device\nmodels, we propose a \"model-over-models\" distillation algorithm, namely\nMoMoDistill, to update the centralized cloud model. Our extensive experiments\nover a range of datasets with different settings demonstrate the effectiveness\nof such collaboration on both cloud and devices, especially its superiority to\nmodel long-tailed users.\n", "versions": [{"version": "v1", "created": "Wed, 14 Apr 2021 05:06:59 GMT"}, {"version": "v2", "created": "Sat, 29 May 2021 16:07:24 GMT"}, {"version": "v3", "created": "Tue, 1 Jun 2021 01:57:03 GMT"}, {"version": "v4", "created": "Wed, 2 Jun 2021 03:43:18 GMT"}, {"version": "v5", "created": "Wed, 16 Jun 2021 02:21:31 GMT"}, {"version": "v6", "created": "Thu, 17 Jun 2021 01:33:33 GMT"}], "update_date": "2021-06-18", "authors_parsed": [["Yao", "Jiangchao", ""], ["Wang", "Feng", ""], ["Jia", "KunYang", ""], ["Han", "Bo", ""], ["Zhou", "Jingren", ""], ["Yang", "Hongxia", ""]]}, {"id": "2104.06629", "submitter": "Huiqi Deng", "authors": "Huiqi Deng, Na Zou, Weifu Chen, Guocan Feng, Mengnan Du, Xia Hu", "title": "Mutual Information Preserving Back-propagation: Learn to Invert for\n  Faithful Attribution", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Back propagation based visualizations have been proposed to interpret deep\nneural networks (DNNs), some of which produce interpretations with good visual\nquality. However, there exist doubts about whether these intuitive\nvisualizations are related to the network decisions. Recent studies have\nconfirmed this suspicion by verifying that almost all these modified\nback-propagation visualizations are not faithful to the model's decision-making\nprocess. Besides, these visualizations produce vague \"relative importance\nscores\", among which low values can't guarantee to be independent of the final\nprediction. Hence, it's highly desirable to develop a novel back-propagation\nframework that guarantees theoretical faithfulness and produces a quantitative\nattribution score with a clear understanding. To achieve the goal, we resort to\nmutual information theory to generate the interpretations, studying how much\ninformation of output is encoded in each input neuron. The basic idea is to\nlearn a source signal by back-propagation such that the mutual information\nbetween input and output should be as much as possible preserved in the mutual\ninformation between input and the source signal. In addition, we propose a\nMutual Information Preserving Inverse Network, termed MIP-IN, in which the\nparameters of each layer are recursively trained to learn how to invert. During\nthe inversion, forward Relu operation is adopted to adapt the general\ninterpretations to the specific input. We then empirically demonstrate that the\ninverted source signal satisfies completeness and minimality property, which\nare crucial for a faithful interpretation. Furthermore, the empirical study\nvalidates the effectiveness of interpretations generated by MIP-IN.\n", "versions": [{"version": "v1", "created": "Wed, 14 Apr 2021 05:20:48 GMT"}], "update_date": "2021-04-15", "authors_parsed": [["Deng", "Huiqi", ""], ["Zou", "Na", ""], ["Chen", "Weifu", ""], ["Feng", "Guocan", ""], ["Du", "Mengnan", ""], ["Hu", "Xia", ""]]}, {"id": "2104.06630", "submitter": "Connor van Rossum", "authors": "Connor van Rossum, Candice Feinberg, Adam Abu Shumays, Kyle Baxter,\n  Benedek Bartha", "title": "A Novel Approach to Curiosity and Explainable Reinforcement Learning via\n  Interpretable Sub-Goals", "comments": "This work has been submitted to the IEEE for possible publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Two key challenges within Reinforcement Learning involve improving (a) agent\nlearning within environments with sparse extrinsic rewards and (b) the\nexplainability of agent actions. We describe a curious subgoal focused agent to\naddress both these challenges. We use a novel method for curiosity produced\nfrom a Generative Adversarial Network (GAN) based model of environment\ntransitions that is robust to stochastic environment transitions. Additionally,\nwe use a subgoal generating network to guide navigation. The explainability of\nthe agent's behavior is increased by decomposing complex tasks into a sequence\nof interpretable subgoals that do not require any manual design. We show that\nthis method also enables the agent to solve challenging procedurally-generated\ntasks that contain stochastic transitions above other state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Wed, 14 Apr 2021 05:21:13 GMT"}, {"version": "v2", "created": "Mon, 19 Apr 2021 02:54:33 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["van Rossum", "Connor", ""], ["Feinberg", "Candice", ""], ["Shumays", "Adam Abu", ""], ["Baxter", "Kyle", ""], ["Bartha", "Benedek", ""]]}, {"id": "2104.06643", "submitter": "Wanyu Lin", "authors": "Wanyu Lin and Hao Lan and Baochun Li", "title": "Generative Causal Explanations for Graph Neural Networks", "comments": "To appear in the Thirty-eighth International Conference on Machine\n  Learning (ICML2021). Source code: https://github.com/wanyu-lin/ICML2021-Gem", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper presents Gem, a model-agnostic approach for providing\ninterpretable explanations for any GNNs on various graph learning tasks.\nSpecifically, we formulate the problem of providing explanations for the\ndecisions of GNNs as a causal learning task. Then we train a causal explanation\nmodel equipped with a loss function based on Granger causality. Different from\nexisting explainers for GNNs, Gem explains GNNs on graph-structured data from a\ncausal perspective. It has better generalization ability as it has no\nrequirements on the internal structure of the GNNs or prior knowledge on the\ngraph learning tasks. In addition, Gem, once trained, can be used to explain\nthe target GNN very quickly. Our theoretical analysis shows that several recent\nexplainers fall into a unified framework of additive feature attribution\nmethods. Experimental results on synthetic and real-world datasets show that\nGem achieves a relative increase of the explanation accuracy by up to $30\\%$\nand speeds up the explanation process by up to $110\\times$ as compared to its\nstate-of-the-art alternatives.\n", "versions": [{"version": "v1", "created": "Wed, 14 Apr 2021 06:22:21 GMT"}, {"version": "v2", "created": "Sun, 6 Jun 2021 07:58:14 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Lin", "Wanyu", ""], ["Lan", "Hao", ""], ["Li", "Baochun", ""]]}, {"id": "2104.06644", "submitter": "Koustuv Sinha", "authors": "Koustuv Sinha, Robin Jia, Dieuwke Hupkes, Joelle Pineau, Adina\n  Williams, Douwe Kiela", "title": "Masked Language Modeling and the Distributional Hypothesis: Order Word\n  Matters Pre-training for Little", "comments": "12 pages + Appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A possible explanation for the impressive performance of masked language\nmodel (MLM) pre-training is that such models have learned to represent the\nsyntactic structures prevalent in classical NLP pipelines. In this paper, we\npropose a different explanation: MLMs succeed on downstream tasks almost\nentirely due to their ability to model higher-order word co-occurrence\nstatistics. To demonstrate this, we pre-train MLMs on sentences with randomly\nshuffled word order, and show that these models still achieve high accuracy\nafter fine-tuning on many downstream tasks -- including on tasks specifically\ndesigned to be challenging for models that ignore word order. Our models\nperform surprisingly well according to some parametric syntactic probes,\nindicating possible deficiencies in how we test representations for syntactic\ninformation. Overall, our results show that purely distributional information\nlargely explains the success of pre-training, and underscore the importance of\ncurating challenging evaluation datasets that require deeper linguistic\nknowledge.\n", "versions": [{"version": "v1", "created": "Wed, 14 Apr 2021 06:30:36 GMT"}], "update_date": "2021-04-15", "authors_parsed": [["Sinha", "Koustuv", ""], ["Jia", "Robin", ""], ["Hupkes", "Dieuwke", ""], ["Pineau", "Joelle", ""], ["Williams", "Adina", ""], ["Kiela", "Douwe", ""]]}, {"id": "2104.06648", "submitter": "Eugene Ndiaye", "authors": "Eugene Ndiaye and Ichiro Takeuchi", "title": "Root-finding Approaches for Computing Conformal Prediction Set", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Conformal prediction constructs a confidence set for an unobserved response\nof a feature vector based on previous identically distributed and exchangeable\nobservations of responses and features. It has a coverage guarantee at any\nnominal level without additional assumptions on their distribution. Its\ncomputation deplorably requires a refitting procedure for all replacement\ncandidates of the target response. In regression settings, this corresponds to\nan infinite number of model fit. Apart from relatively simple estimators that\ncan be written as pieces of linear function of the response, efficiently\ncomputing such sets is difficult and is still considered as an open problem. We\nexploit the fact that, \\emph{often}, conformal prediction sets are intervals\nwhose boundaries can be efficiently approximated by classical root-finding\nalgorithm. We investigate how this approach can overcome many limitations of\nformerly used strategies and we discuss its complexity and drawbacks.\n", "versions": [{"version": "v1", "created": "Wed, 14 Apr 2021 06:41:12 GMT"}, {"version": "v2", "created": "Mon, 14 Jun 2021 05:05:26 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Ndiaye", "Eugene", ""], ["Takeuchi", "Ichiro", ""]]}, {"id": "2104.06652", "submitter": "Abhijitt Dhavlle", "authors": "Abhijitt Dhavlle and Sanket Shukla", "title": "A Novel Malware Detection Mechanism based on Features Extracted from\n  Converted Malware Binary Images", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Our computer systems for decades have been threatened by various types of\nhardware and software attacks of which Malwares have been one of them. This\nmalware has the ability to steal, destroy, contaminate, gain unintended access,\nor even disrupt the entire system. There have been techniques to detect malware\nby performing static and dynamic analysis of malware files, but, stealthy\nmalware has circumvented the static analysis method and for dynamic analysis,\nthere have been previous works that propose different methods to detect malware\nbut, in this work we propose a novel technique to detect malware. We use\nmalware binary images and then extract different features from the same and\nthen employ different ML-classifiers on the dataset thus obtained. We show that\nthis technique is successful in differentiating classes of malware based on the\nfeatures extracted.\n", "versions": [{"version": "v1", "created": "Wed, 14 Apr 2021 06:55:52 GMT"}], "update_date": "2021-04-15", "authors_parsed": [["Dhavlle", "Abhijitt", ""], ["Shukla", "Sanket", ""]]}, {"id": "2104.06666", "submitter": "David Peter", "authors": "David Peter, Wolfgang Roth, Franz Pernkopf", "title": "End-to-end Keyword Spotting using Neural Architecture Search and\n  Quantization", "comments": "arXiv admin note: text overlap with arXiv:2012.10138", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces neural architecture search (NAS) for the automatic\ndiscovery of end-to-end keyword spotting (KWS) models in limited resource\nenvironments. We employ a differentiable NAS approach to optimize the structure\nof convolutional neural networks (CNNs) operating on raw audio waveforms. After\na suitable KWS model is found with NAS, we conduct quantization of weights and\nactivations to reduce the memory footprint. We conduct extensive experiments on\nthe Google speech commands dataset. In particular, we compare our end-to-end\napproach to mel-frequency cepstral coefficient (MFCC) based systems. For\nquantization, we compare fixed bit-width quantization and trained bit-width\nquantization. Using NAS only, we were able to obtain a highly efficient model\nwith an accuracy of 95.55% using 75.7k parameters and 13.6M operations. Using\ntrained bit-width quantization, the same model achieves a test accuracy of\n93.76% while using on average only 2.91 bits per activation and 2.51 bits per\nweight.\n", "versions": [{"version": "v1", "created": "Wed, 14 Apr 2021 07:22:22 GMT"}], "update_date": "2021-04-15", "authors_parsed": [["Peter", "David", ""], ["Roth", "Wolfgang", ""], ["Pernkopf", "Franz", ""]]}, {"id": "2104.06670", "submitter": "Yuan Gao", "authors": "Yuan Gao, Jiawei Li, Maoguo Gong, Yu Xie and A. K. Qin", "title": "Towards Explainable Multi-Party Learning: A Contrastive Knowledge\n  Sharing Framework", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-party learning provides solutions for training joint models with\ndecentralized data under legal and practical constraints. However, traditional\nmulti-party learning approaches are confronted with obstacles such as system\nheterogeneity, statistical heterogeneity, and incentive design. How to deal\nwith these challenges and further improve the efficiency and performance of\nmulti-party learning has become an urgent problem to be solved. In this paper,\nwe propose a novel contrastive multi-party learning framework for knowledge\nrefinement and sharing with an accountable incentive mechanism. Since the\nexisting naive model parameter averaging method is contradictory to the\nlearning paradigm of neural networks, we simulate the process of human\ncognition and communication, and analogy multi-party learning as a many-to-one\nknowledge sharing problem. The approach is capable of integrating the acquired\nexplicit knowledge of each client in a transparent manner without privacy\ndisclosure, and it reduces the dependence on data distribution and\ncommunication environments. The proposed scheme achieves significant\nimprovement in model performance in a variety of scenarios, as we demonstrated\nthrough experiments on several real-world datasets.\n", "versions": [{"version": "v1", "created": "Wed, 14 Apr 2021 07:33:48 GMT"}, {"version": "v2", "created": "Tue, 25 May 2021 14:51:20 GMT"}], "update_date": "2021-05-26", "authors_parsed": [["Gao", "Yuan", ""], ["Li", "Jiawei", ""], ["Gong", "Maoguo", ""], ["Xie", "Yu", ""], ["Qin", "A. K.", ""]]}, {"id": "2104.06677", "submitter": "Yuan Gao", "authors": "Maoguo Gong, Yuan Gao, Yu Xie, A. K. Qin, Ke Pan, and Yew-Soon Ong", "title": "Multi-Party Dual Learning", "comments": "submitted to IEEE Transactions on Cybernetics", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The performance of machine learning algorithms heavily relies on the\navailability of a large amount of training data. However, in reality, data\nusually reside in distributed parties such as different institutions and may\nnot be directly gathered and integrated due to various data policy constraints.\nAs a result, some parties may suffer from insufficient data available for\ntraining machine learning models. In this paper, we propose a multi-party dual\nlearning (MPDL) framework to alleviate the problem of limited data with poor\nquality in an isolated party. Since the knowledge sharing processes for\nmultiple parties always emerge in dual forms, we show that dual learning is\nnaturally suitable to handle the challenge of missing data, and explicitly\nexploits the probabilistic correlation and structural relationship between dual\ntasks to regularize the training process. We introduce a feature-oriented\ndifferential privacy with mathematical proof, in order to avoid possible\nprivacy leakage of raw features in the dual inference process. The approach\nrequires minimal modifications to the existing multi-party learning structure,\nand each party can build flexible and powerful models separately, whose\naccuracy is no less than non-distributed self-learning approaches. The MPDL\nframework achieves significant improvement compared with state-of-the-art\nmulti-party learning methods, as we demonstrated through simulations on\nreal-world datasets.\n", "versions": [{"version": "v1", "created": "Wed, 14 Apr 2021 07:39:23 GMT"}], "update_date": "2021-04-15", "authors_parsed": [["Gong", "Maoguo", ""], ["Gao", "Yuan", ""], ["Xie", "Yu", ""], ["Qin", "A. K.", ""], ["Pan", "Ke", ""], ["Ong", "Yew-Soon", ""]]}, {"id": "2104.06683", "submitter": "Vikas Raunak", "authors": "Vikas Raunak, Arul Menezes and Marcin Junczys-Dowmunt", "title": "The Curious Case of Hallucinations in Neural Machine Translation", "comments": "Accepted to NAACL 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this work, we study hallucinations in Neural Machine Translation (NMT),\nwhich lie at an extreme end on the spectrum of NMT pathologies. Firstly, we\nconnect the phenomenon of hallucinations under source perturbation to the\nLong-Tail theory of Feldman (2020), and present an empirically validated\nhypothesis that explains hallucinations under source perturbation. Secondly, we\nconsider hallucinations under corpus-level noise (without any source\nperturbation) and demonstrate that two prominent types of natural\nhallucinations (detached and oscillatory outputs) could be generated and\nexplained through specific corpus-level noise patterns. Finally, we elucidate\nthe phenomenon of hallucination amplification in popular data-generation\nprocesses such as Backtranslation and sequence-level Knowledge Distillation.\n", "versions": [{"version": "v1", "created": "Wed, 14 Apr 2021 08:09:57 GMT"}], "update_date": "2021-04-15", "authors_parsed": [["Raunak", "Vikas", ""], ["Menezes", "Arul", ""], ["Junczys-Dowmunt", "Marcin", ""]]}, {"id": "2104.06685", "submitter": "Heng Zhu", "authors": "Heng Zhu, Qing Ling", "title": "BROADCAST: Reducing Both Stochastic and Compression Noise to Robustify\n  Communication-Efficient Federated Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Communication between workers and the master node to collect local stochastic\ngradients is a key bottleneck in a large-scale federated learning system.\nVarious recent works have proposed to compress the local stochastic gradients\nto mitigate the communication overhead. However, robustness to malicious\nattacks is rarely considered in such a setting. In this work, we investigate\nthe problem of Byzantine-robust federated learning with compression, where the\nattacks from Byzantine workers can be arbitrarily malicious. We point out that\na vanilla combination of compressed stochastic gradient descent (SGD) and\ngeometric median-based robust aggregation suffers from both stochastic and\ncompression noise in the presence of Byzantine attacks. In light of this\nobservation, we propose to jointly reduce the stochastic and compression noise\nso as to improve the Byzantine-robustness. For the stochastic noise, we adopt\nthe stochastic average gradient algorithm (SAGA) to gradually eliminate the\ninner variations of regular workers. For the compression noise, we apply the\ngradient difference compression and achieve compression for free. We\ntheoretically prove that the proposed algorithm reaches a neighborhood of the\noptimal solution at a linear convergence rate, and the asymptotic learning\nerror is in the same order as that of the state-of-the-art uncompressed method.\nFinally, numerical experiments demonstrate effectiveness of the proposed\nmethod.\n", "versions": [{"version": "v1", "created": "Wed, 14 Apr 2021 08:16:03 GMT"}], "update_date": "2021-04-15", "authors_parsed": [["Zhu", "Heng", ""], ["Ling", "Qing", ""]]}, {"id": "2104.06687", "submitter": "Yawei Wang", "authors": "Yawei Wang and Xiu Li", "title": "Reward function shape exploration in adversarial imitation learning: an\n  empirical study", "comments": "Accepted by ICAICA2021, the code will be available soon", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For adversarial imitation learning algorithms (AILs), no true rewards are\nobtained from the environment for learning the strategy. However, the pseudo\nrewards based on the output of the discriminator are still required. Given the\nimplicit reward bias problem in AILs, we design several representative reward\nfunction shapes and compare their performances by large-scale experiments. To\nensure our results' reliability, we conduct the experiments on a series of\nMujoco and Box2D continuous control tasks based on four different AILs.\nBesides, we also compare the performance of various reward function shapes\nusing varying numbers of expert trajectories. The empirical results reveal that\nthe positive logarithmic reward function works well in typical continuous\ncontrol tasks. In contrast, the so-called unbiased reward function is limited\nto specific kinds of tasks. Furthermore, several designed reward functions\nperform excellently in these environments as well.\n", "versions": [{"version": "v1", "created": "Wed, 14 Apr 2021 08:21:49 GMT"}], "update_date": "2021-04-15", "authors_parsed": [["Wang", "Yawei", ""], ["Li", "Xiu", ""]]}, {"id": "2104.06700", "submitter": "Md Vasimuddin", "authors": "Vasimuddin Md, Sanchit Misra, Guixiang Ma, Ramanarayan Mohanty,\n  Evangelos Georganas, Alexander Heinecke, Dhiraj Kalamkar, Nesreen K. Ahmed,\n  Sasikanth Avancha", "title": "DistGNN: Scalable Distributed Training for Large-Scale Graph Neural\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Full-batch training on Graph Neural Networks (GNN) to learn the structure of\nlarge graphs is a critical problem that needs to scale to hundreds of compute\nnodes to be feasible. It is challenging due to large memory capacity and\nbandwidth requirements on a single compute node and high communication volumes\nacross multiple nodes. In this paper, we present DistGNN that optimizes the\nwell-known Deep Graph Library (DGL) for full-batch training on CPU clusters via\nan efficient shared memory implementation, communication reduction using a\nminimum vertex-cut graph partitioning algorithm and communication avoidance\nusing a family of delayed-update algorithms. Our results on four common GNN\nbenchmark datasets: Reddit, OGB-Products, OGB-Papers and Proteins, show up to\n3.7x speed-up using a single CPU socket and up to 97x speed-up using 128 CPU\nsockets, respectively, over baseline DGL implementations running on a single\nCPU socket\n", "versions": [{"version": "v1", "created": "Wed, 14 Apr 2021 08:46:35 GMT"}, {"version": "v2", "created": "Thu, 15 Apr 2021 05:37:53 GMT"}, {"version": "v3", "created": "Fri, 16 Apr 2021 15:04:55 GMT"}], "update_date": "2021-04-19", "authors_parsed": [["Md", "Vasimuddin", ""], ["Misra", "Sanchit", ""], ["Ma", "Guixiang", ""], ["Mohanty", "Ramanarayan", ""], ["Georganas", "Evangelos", ""], ["Heinecke", "Alexander", ""], ["Kalamkar", "Dhiraj", ""], ["Ahmed", "Nesreen K.", ""], ["Avancha", "Sasikanth", ""]]}, {"id": "2104.06703", "submitter": "Dror Moran", "authors": "Dror Moran, Hodaya Koslowsky, Yoni Kasten, Haggai Maron, Meirav Galun,\n  Ronen Basri", "title": "Deep Permutation Equivariant Structure from Motion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing deep methods produce highly accurate 3D reconstructions in stereo\nand multiview stereo settings, i.e., when cameras are both internally and\nexternally calibrated. Nevertheless, the challenge of simultaneous recovery of\ncamera poses and 3D scene structure in multiview settings with deep networks is\nstill outstanding. Inspired by projective factorization for Structure from\nMotion (SFM) and by deep matrix completion techniques, we propose a neural\nnetwork architecture that, given a set of point tracks in multiple images of a\nstatic scene, recovers both the camera parameters and a (sparse) scene\nstructure by minimizing an unsupervised reprojection loss. Our network\narchitecture is designed to respect the structure of the problem: the sought\noutput is equivariant to permutations of both cameras and scene points.\nNotably, our method does not require initialization of camera parameters or 3D\npoint locations. We test our architecture in two setups: (1) single scene\nreconstruction and (2) learning from multiple scenes. Our experiments,\nconducted on a variety of datasets in both internally calibrated and\nuncalibrated settings, indicate that our method accurately recovers pose and\nstructure, on par with classical state of the art methods. Additionally, we\nshow that a pre-trained network can be used to reconstruct novel scenes using\ninexpensive fine-tuning with no loss of accuracy.\n", "versions": [{"version": "v1", "created": "Wed, 14 Apr 2021 08:50:06 GMT"}], "update_date": "2021-04-15", "authors_parsed": [["Moran", "Dror", ""], ["Koslowsky", "Hodaya", ""], ["Kasten", "Yoni", ""], ["Maron", "Haggai", ""], ["Galun", "Meirav", ""], ["Basri", "Ronen", ""]]}, {"id": "2104.06718", "submitter": "Alessandro De Palma", "authors": "Alessandro De Palma, Rudy Bunel, Alban Desmaison, Krishnamurthy\n  Dvijotham, Pushmeet Kohli, Philip H.S. Torr, M. Pawan Kumar", "title": "Improved Branch and Bound for Neural Network Verification via Lagrangian\n  Decomposition", "comments": "Submitted for review to JMLR. This is an extended version of our\n  paper in the UAI-20 conference (arXiv:2002.10410)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.LO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We improve the scalability of Branch and Bound (BaB) algorithms for formally\nproving input-output properties of neural networks. First, we propose novel\nbounding algorithms based on Lagrangian Decomposition. Previous works have used\noff-the-shelf solvers to solve relaxations at each node of the BaB tree, or\nconstructed weaker relaxations that can be solved efficiently, but lead to\nunnecessarily weak bounds. Our formulation restricts the optimization to a\nsubspace of the dual domain that is guaranteed to contain the optimum,\nresulting in accelerated convergence. Furthermore, it allows for a massively\nparallel implementation, which is amenable to GPU acceleration via modern deep\nlearning frameworks. Second, we present a novel activation-based branching\nstrategy. By coupling an inexpensive heuristic with fast dual bounding, our\nbranching scheme greatly reduces the size of the BaB tree compared to previous\nheuristic methods. Moreover, it performs competitively with a recent strategy\nbased on learning algorithms, without its large offline training cost. Finally,\nwe design a BaB framework, named Branch and Dual Network Bound (BaDNB), based\non our novel bounding and branching algorithms. We show that BaDNB outperforms\nprevious complete verification systems by a large margin, cutting average\nverification times by factors up to 50 on adversarial robustness properties.\n", "versions": [{"version": "v1", "created": "Wed, 14 Apr 2021 09:22:42 GMT"}], "update_date": "2021-04-15", "authors_parsed": [["De Palma", "Alessandro", ""], ["Bunel", "Rudy", ""], ["Desmaison", "Alban", ""], ["Dvijotham", "Krishnamurthy", ""], ["Kohli", "Pushmeet", ""], ["Torr", "Philip H. S.", ""], ["Kumar", "M. Pawan", ""]]}, {"id": "2104.06719", "submitter": "Fredrik Carlsson", "authors": "Fredrik Carlsson Magnus Sahlgren", "title": "Sentence Embeddings by Ensemble Distillation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper contributes a new State Of The Art (SOTA) for Semantic Textual\nSimilarity (STS). We compare and combine a number of recently proposed sentence\nembedding methods for STS, and propose a novel and simple ensemble knowledge\ndistillation scheme that improves on previous approaches. Our experiments\ndemonstrate that a model trained to learn the average embedding space from\nmultiple ensemble students outperforms all the other individual models with\nhigh robustness. Utilizing our distillation method in combination with previous\nmethods, we significantly improve on the SOTA unsupervised STS, and by proper\nhyperparameter tuning of previous methods we improve the supervised SOTA\nscores.\n", "versions": [{"version": "v1", "created": "Wed, 14 Apr 2021 09:23:27 GMT"}], "update_date": "2021-04-15", "authors_parsed": [["Sahlgren", "Fredrik Carlsson Magnus", ""]]}, {"id": "2104.06722", "submitter": "Oishik Chatterjee", "authors": "Oishik Chatterjee, Aashish Waikar, Vishwajeet Kumar, Ganesh\n  Ramakrishnan, Kavi Arya", "title": "A Weakly Supervised Model for Solving Math word Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Solving math word problems (MWPs) is an important and challenging problem in\nnatural language processing. Existing approaches to solve MWPs require full\nsupervision in the form of intermediate equations. However, labeling every math\nword problem with its corresponding equations is a time-consuming and expensive\ntask. In order to address this challenge of equation annotation, we propose a\nweakly supervised model for solving math word problems by requiring only the\nfinal answer as supervision. We approach this problem by first learning to\ngenerate the equation using the problem description and the final answer, which\nwe then use to train a supervised MWP solver. We propose and compare various\nweakly supervised techniques to learn to generate equations directly from the\nproblem description and answer. Through extensive experiment, we demonstrate\nthat even without using equations for supervision, our approach achieves an\naccuracy of 56.0 on the standard Math23K dataset. We also curate and release a\nnew dataset for MWPs in English consisting of 10227 instances suitable for\ntraining weakly supervised models.\n", "versions": [{"version": "v1", "created": "Wed, 14 Apr 2021 09:25:38 GMT"}], "update_date": "2021-04-15", "authors_parsed": [["Chatterjee", "Oishik", ""], ["Waikar", "Aashish", ""], ["Kumar", "Vishwajeet", ""], ["Ramakrishnan", "Ganesh", ""], ["Arya", "Kavi", ""]]}, {"id": "2104.06735", "submitter": "Marcin Chlebus", "authors": "Przemys{\\l}aw Biecek, Marcin Chlebus, Janusz Gajda, Alicja Gosiewska,\n  Anna Kozak, Dominik Ogonowski, Jakub Sztachelski, Piotr Wojewnik", "title": "Enabling Machine Learning Algorithms for Credit Scoring -- Explainable\n  Artificial Intelligence (XAI) methods for clear understanding complex\n  predictive models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.RM cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rapid development of advanced modelling techniques gives an opportunity to\ndevelop tools that are more and more accurate. However as usually, everything\ncomes with a price and in this case, the price to pay is to loose\ninterpretability of a model while gaining on its accuracy and precision. For\nmanagers to control and effectively manage credit risk and for regulators to be\nconvinced with model quality the price to pay is too high. In this paper, we\nshow how to take credit scoring analytics in to the next level, namely we\npresent comparison of various predictive models (logistic regression, logistic\nregression with weight of evidence transformations and modern artificial\nintelligence algorithms) and show that advanced tree based models give best\nresults in prediction of client default. What is even more important and\nvaluable we also show how to boost advanced models using techniques which allow\nto interpret them and made them more accessible for credit risk practitioners,\nresolving the crucial obstacle in widespread deployment of more complex, 'black\nbox' models like random forests, gradient boosted or extreme gradient boosted\ntrees. All this will be shown on the large dataset obtained from the Polish\nCredit Bureau to which all the banks and most of the lending companies in the\ncountry do report the credit files. In this paper the data from lending\ncompanies were used. The paper then compares state of the art best practices in\ncredit risk modelling with new advanced modern statistical tools boosted by the\nlatest developments in the field of interpretability and explainability of\nartificial intelligence algorithms. We believe that this is a valuable\ncontribution when it comes to presentation of different modelling tools but\nwhat is even more important it is showing which methods might be used to get\ninsight and understanding of AI methods in credit risk context.\n", "versions": [{"version": "v1", "created": "Wed, 14 Apr 2021 09:44:04 GMT"}], "update_date": "2021-04-15", "authors_parsed": [["Biecek", "Przemys\u0142aw", ""], ["Chlebus", "Marcin", ""], ["Gajda", "Janusz", ""], ["Gosiewska", "Alicja", ""], ["Kozak", "Anna", ""], ["Ogonowski", "Dominik", ""], ["Sztachelski", "Jakub", ""], ["Wojewnik", "Piotr", ""]]}, {"id": "2104.06750", "submitter": "Shoval Frydman", "authors": "Omer Nagar, Shoval Frydman, Ori Hochman and Yoram Louzoun", "title": "Quadratic GCN for Graph Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Graph Convolutional Networks (GCNs) have been extensively used to classify\nvertices in graphs and have been shown to outperform other vertex\nclassification methods. GCNs have been extended to graph classification tasks\n(GCT). In GCT, graphs with different numbers of edges and vertices belong to\ndifferent classes, and one attempts to predict the graph class. GCN based GCT\nhave mostly used pooling and attention-based models. The accuracy of existing\nGCT methods is still limited. We here propose a novel solution combining GCN,\nmethods from knowledge graphs, and a new self-regularized activation function\nto significantly improve the accuracy of the GCN based GCT. We present\nquadratic GCN (QGCN) - A GCN formalism with a quadratic layer. Such a layer\nproduces an output with fixed dimensions, independent of the graph vertex\nnumber. We applied this method to a wide range of graph classification\nproblems, and show that when using a self regularized activation function, QGCN\noutperforms the state of the art methods for all graph classification tasks\ntested with or without external input on each graph. The code for QGCN is\navailable at: https://github.com/Unknown-Data/QGCN .\n", "versions": [{"version": "v1", "created": "Wed, 14 Apr 2021 10:01:09 GMT"}], "update_date": "2021-04-15", "authors_parsed": [["Nagar", "Omer", ""], ["Frydman", "Shoval", ""], ["Hochman", "Ori", ""], ["Louzoun", "Yoram", ""]]}, {"id": "2104.06763", "submitter": "Guy Kornowski", "authors": "Guy Kornowski, Ohad Shamir", "title": "Oracle Complexity in Nonsmooth Nonconvex Optimization", "comments": "35 pages, 4 figures. arXiv admin note: substantial text overlap with\n  arXiv:2002.11962", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is well-known that given a smooth, bounded-from-below, and possibly\nnonconvex function, standard gradient-based methods can find\n$\\epsilon$-stationary points (with gradient norm less than $\\epsilon$) in\n$\\mathcal{O}(1/\\epsilon^2)$ iterations. However, many important nonconvex\noptimization problems, such as those associated with training modern neural\nnetworks, are inherently not smooth, making these results inapplicable. In this\npaper, we study nonsmooth nonconvex optimization from an oracle complexity\nviewpoint, where the algorithm is assumed to be given access only to local\ninformation about the function at various points. We provide two main results\n(under mild assumptions): First, we consider the problem of getting near\n$\\epsilon$-stationary points. This is perhaps the most natural relaxation of\nfinding $\\epsilon$-stationary points, which is impossible in the nonsmooth\nnonconvex case. We prove that this relaxed goal cannot be achieved efficiently,\nfor any distance and $\\epsilon$ smaller than some constants. Our second result\ndeals with the possibility of tackling nonsmooth nonconvex optimization by\nreduction to smooth optimization: Namely, applying smooth optimization methods\non a smooth approximation of the objective function. For this approach, we\nprove an inherent trade-off between oracle complexity and smoothness: On the\none hand, smoothing a nonsmooth nonconvex function can be done very efficiently\n(e.g., by randomized smoothing), but with dimension-dependent factors in the\nsmoothness parameter, which can strongly affect iteration complexity when\nplugging into standard smooth optimization methods. On the other hand, these\ndimension factors can be eliminated with suitable smoothing methods, but only\nby making the oracle complexity of the smoothing process exponentially large.\n", "versions": [{"version": "v1", "created": "Wed, 14 Apr 2021 10:42:45 GMT"}], "update_date": "2021-04-15", "authors_parsed": [["Kornowski", "Guy", ""], ["Shamir", "Ohad", ""]]}, {"id": "2104.06768", "submitter": "Augusto Luis Ballardini PhD", "authors": "Noelia Hern\\'andez, Ignacio Parra, H\\'ector Corrales, Rub\\'en\n  Izquierdo, Augusto Luis Ballardini, Carlota Salinas, Iv\\'an Garcia", "title": "WiFiNet: WiFi-based indoor localisation using CNNs", "comments": null, "journal-ref": "Expert Systems with Applications, Volume 177, 1 September 2021", "doi": "10.1016/j.eswa.2021.114906", "report-no": null, "categories": "cs.LG cs.NI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Different technologies have been proposed to provide indoor localisation:\nmagnetic field, bluetooth , WiFi, etc. Among them, WiFi is the one with the\nhighest availability and highest accuracy. This fact allows for an ubiquitous\naccurate localisation available for almost any environment and any device.\nHowever, WiFi-based localisation is still an open problem.\n  In this article, we propose a new WiFi-based indoor localisation system that\ntakes advantage of the great ability of Convolutional Neural Networks in\nclassification problems. Three different approaches were used to achieve this\ngoal: a custom architecture called WiFiNet designed and trained specifically to\nsolve this problem and the most popular pre-trained networks using both\ntransfer learning and feature extraction.\n  Results indicate that WiFiNet is as a great approach for indoor localisation\nin a medium-sized environment (30 positions and 113 access points) as it\nreduces the mean localisation error (33%) and the processing time when compared\nwith state-of-the-art WiFi indoor localisation algorithms such as SVM.\n", "versions": [{"version": "v1", "created": "Wed, 14 Apr 2021 10:49:17 GMT"}], "update_date": "2021-04-15", "authors_parsed": [["Hern\u00e1ndez", "Noelia", ""], ["Parra", "Ignacio", ""], ["Corrales", "H\u00e9ctor", ""], ["Izquierdo", "Rub\u00e9n", ""], ["Ballardini", "Augusto Luis", ""], ["Salinas", "Carlota", ""], ["Garcia", "Iv\u00e1n", ""]]}, {"id": "2104.06781", "submitter": "Ilker Bozcan", "authors": "Ilker Bozcan and Erdal Kayacan", "title": "Context-Dependent Anomaly Detection for Low Altitude Traffic\n  Surveillance", "comments": "7 pages, 4 figures, Accepted to IEEE International Conference on\n  Robotics and Automation 2021 (ICRA 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The detection of contextual anomalies is a challenging task for surveillance\nsince an observation can be considered anomalous or normal in a specific\nenvironmental context. An unmanned aerial vehicle (UAV) can utilize its aerial\nmonitoring capability and employ multiple sensors to gather contextual\ninformation about the environment and perform contextual anomaly detection. In\nthis work, we introduce a deep neural network-based method (CADNet) to find\npoint anomalies (i.e., single instance anomalous data) and contextual anomalies\n(i.e., context-specific abnormality) in an environment using a UAV. The method\nis based on a variational autoencoder (VAE) with a context sub-network. The\ncontext sub-network extracts contextual information regarding the environment\nusing GPS and time data, then feeds it to the VAE to predict anomalies\nconditioned on the context. To the best of our knowledge, our method is the\nfirst contextual anomaly detection method for UAV-assisted aerial surveillance.\nWe evaluate our method on the AU-AIR dataset in a traffic surveillance\nscenario. Quantitative comparisons against several baselines demonstrate the\nsuperiority of our approach in the anomaly detection tasks. The codes and data\nwill be available at https://bozcani.github.io/cadnet.\n", "versions": [{"version": "v1", "created": "Wed, 14 Apr 2021 11:12:04 GMT"}], "update_date": "2021-04-15", "authors_parsed": [["Bozcan", "Ilker", ""], ["Kayacan", "Erdal", ""]]}, {"id": "2104.06788", "submitter": "Martin Mundt", "authors": "Martin Mundt, Iuliia Pliushch, Visvanathan Ramesh", "title": "Neural Architecture Search of Deep Priors: Towards Continual Learning\n  without Catastrophic Interference", "comments": "Accepted for publication at CVPR-W 2021, Workshop on Continual\n  Learning in Computer Vision (CLVision). First two authors have equal\n  contribution", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we analyze the classification performance of neural network\nstructures without parametric inference. Making use of neural architecture\nsearch, we empirically demonstrate that it is possible to find random weight\narchitectures, a deep prior, that enables a linear classification to perform on\npar with fully trained deep counterparts. Through ablation experiments, we\nexclude the possibility of winning a weight initialization lottery and confirm\nthat suitable deep priors do not require additional inference. In an extension\nto continual learning, we investigate the possibility of catastrophic\ninterference free incremental learning. Under the assumption of classes\noriginating from the same data distribution, a deep prior found on only a\nsubset of classes is shown to allow discrimination of further classes through\ntraining of a simple linear classifier.\n", "versions": [{"version": "v1", "created": "Wed, 14 Apr 2021 11:25:30 GMT"}], "update_date": "2021-04-15", "authors_parsed": [["Mundt", "Martin", ""], ["Pliushch", "Iuliia", ""], ["Ramesh", "Visvanathan", ""]]}, {"id": "2104.06819", "submitter": "Niklas Christoffer Petersen", "authors": "Niklas Christoffer Petersen, Anders Parslov, Filipe Rodrigues", "title": "Short-term bus travel time prediction for transfer synchronization with\n  intelligent uncertainty handling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper presents two novel approaches for uncertainty estimation adapted\nand extended for the multi-link bus travel time problem. The uncertainty is\nmodeled directly as part of recurrent artificial neural networks, but using two\nfundamentally different approaches: one based on Deep Quantile Regression (DQR)\nand the other on Bayesian Recurrent Neural Networks (BRNN). Both models predict\nmultiple time steps into the future, but handle the time-dependent uncertainty\nestimation differently. We present a sampling technique in order to aggregate\nquantile estimates for link level travel time to yield the multi-link travel\ntime distribution needed for a vehicle to travel from its current position to a\nspecific downstream stop point or transfer site.\n  To motivate the relevance of uncertainty-aware models in the domain, we focus\non the connection assurance application as a case study: An expert system to\ndetermine whether a bus driver should hold and wait for a connecting service,\nor break the connection and reduce its own delay. Our results show that the\nDQR-model performs overall best for the 80%, 90% and 95% prediction intervals,\nboth for a 15 minute time horizon into the future (t + 1), but also for the 30\nand 45 minutes time horizon (t + 2 and t + 3), with a constant, but very small\nunderestimation of the uncertainty interval (1-4 pp.). However, we also show,\nthat the BRNN model still can outperform the DQR for specific cases. Lastly, we\ndemonstrate how a simple decision support system can take advantage of our\nuncertainty-aware travel time models to prioritize the difference in travel\ntime uncertainty for bus holding at strategic points, thus reducing the\nintroduced delay for the connection assurance application.\n", "versions": [{"version": "v1", "created": "Wed, 14 Apr 2021 12:38:27 GMT"}], "update_date": "2021-04-15", "authors_parsed": [["Petersen", "Niklas Christoffer", ""], ["Parslov", "Anders", ""], ["Rodrigues", "Filipe", ""]]}, {"id": "2104.06820", "submitter": "Utkarsh Ojha", "authors": "Utkarsh Ojha, Yijun Li, Jingwan Lu, Alexei A. Efros, Yong Jae Lee, Eli\n  Shechtman, Richard Zhang", "title": "Few-shot Image Generation via Cross-domain Correspondence", "comments": "CVPR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.GR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training generative models, such as GANs, on a target domain containing\nlimited examples (e.g., 10) can easily result in overfitting. In this work, we\nseek to utilize a large source domain for pretraining and transfer the\ndiversity information from source to target. We propose to preserve the\nrelative similarities and differences between instances in the source via a\nnovel cross-domain distance consistency loss. To further reduce overfitting, we\npresent an anchor-based strategy to encourage different levels of realism over\ndifferent regions in the latent space. With extensive results in both\nphotorealistic and non-photorealistic domains, we demonstrate qualitatively and\nquantitatively that our few-shot model automatically discovers correspondences\nbetween source and target domains and generates more diverse and realistic\nimages than previous methods.\n", "versions": [{"version": "v1", "created": "Tue, 13 Apr 2021 17:59:35 GMT"}], "update_date": "2021-04-15", "authors_parsed": [["Ojha", "Utkarsh", ""], ["Li", "Yijun", ""], ["Lu", "Jingwan", ""], ["Efros", "Alexei A.", ""], ["Lee", "Yong Jae", ""], ["Shechtman", "Eli", ""], ["Zhang", "Richard", ""]]}, {"id": "2104.06826", "submitter": "Daniel Rivas", "authors": "Daniel Rivas, Francesc Guim, Jord\\`a Polo, Josep Ll. Berral, Pubudu M.\n  Silva, David Carrera", "title": "Towards Unsupervised Fine-Tuning for Edge Video Analytics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Judging by popular and generic computer vision challenges, such as the\nImageNet or PASCAL VOC, neural networks have proven to be exceptionally\naccurate in recognition tasks. However, state-of-the-art accuracy often comes\nat a high computational price, requiring equally state-of-the-art and high-end\nhardware acceleration to achieve anything near real-time performance. At the\nsame time, use cases such as smart cities or autonomous vehicles require an\nautomated analysis of images from fixed cameras in real-time. Due to the huge\nand constant amount of network bandwidth these streams would generate, we\ncannot rely on offloading compute to the omnipresent and omnipotent cloud.\nTherefore, a distributed Edge Cloud must be in charge to process images\nlocally. However, the Edge Cloud is, by nature, resource-constrained, which\nputs a limit on the computational complexity of the models executed in the\nedge. Nonetheless, there is a need for a meeting point between the Edge Cloud\nand accurate real-time video analytics. In this paper, we propose a method for\nimproving accuracy of edge models without any extra compute cost by means of\nautomatic model specialization. First, we show how the sole assumption of\nstatic cameras allows us to make a series of considerations that greatly\nsimplify the scope of the problem. Then, we present Edge AutoTuner, a framework\nthat implements and brings these considerations together to automate the\nend-to-end fine-tuning of models. Finally, we show that complex neural networks\n- able to generalize better - can be effectively used as teachers to annotate\ndatasets for the fine-tuning of lightweight neural networks and tailor them to\nthe specific edge context, which boosts accuracy at constant computational\ncost, and do so without any human interaction. Results show that our method can\nautomatically improve accuracy of pre-trained models by an average of 21%.\n", "versions": [{"version": "v1", "created": "Wed, 14 Apr 2021 12:57:40 GMT"}], "update_date": "2021-04-15", "authors_parsed": [["Rivas", "Daniel", ""], ["Guim", "Francesc", ""], ["Polo", "Jord\u00e0", ""], ["Berral", "Josep Ll.", ""], ["Silva", "Pubudu M.", ""], ["Carrera", "David", ""]]}, {"id": "2104.06879", "submitter": "Fr\\'ed\\'eric Branchaud-Charron", "authors": "Fr\\'ed\\'eric Branchaud-Charron, Parmida Atighehchian, Pau Rodr\\'iguez,\n  Grace Abuhamad, Alexandre Lacoste", "title": "Can Active Learning Preemptively Mitigate Fairness Issues?", "comments": "Presented at ICLR 2021 Workshop on Responsable AI", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dataset bias is one of the prevailing causes of unfairness in machine\nlearning. Addressing fairness at the data collection and dataset preparation\nstages therefore becomes an essential part of training fairer algorithms. In\nparticular, active learning (AL) algorithms show promise for the task by\ndrawing importance to the most informative training samples. However, the\neffect and interaction between existing AL algorithms and algorithmic fairness\nremain under-explored. In this paper, we study whether models trained with\nuncertainty-based AL heuristics such as BALD are fairer in their decisions with\nrespect to a protected class than those trained with identically independently\ndistributed (i.i.d.) sampling. We found a significant improvement on predictive\nparity when using BALD, while also improving accuracy compared to i.i.d.\nsampling. We also explore the interaction of algorithmic fairness methods such\nas gradient reversal (GRAD) and BALD. We found that, while addressing different\nfairness issues, their interaction further improves the results on most\nbenchmarks and metrics we explored.\n", "versions": [{"version": "v1", "created": "Wed, 14 Apr 2021 14:20:22 GMT"}], "update_date": "2021-04-15", "authors_parsed": [["Branchaud-Charron", "Fr\u00e9d\u00e9ric", ""], ["Atighehchian", "Parmida", ""], ["Rodr\u00edguez", "Pau", ""], ["Abuhamad", "Grace", ""], ["Lacoste", "Alexandre", ""]]}, {"id": "2104.06893", "submitter": "Danushka Bollegala", "authors": "James O'Neill and Polina Rozenshtein and Ryuichi Kiryo and Motoko\n  Kubota and Danushka Bollegala", "title": "I Wish I Would Have Loved This One, But I Didn't -- A Multilingual\n  Dataset for Counterfactual Detection in Product Reviews", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Counterfactual statements describe events that did not or cannot take place.\nWe consider the problem of counterfactual detection (CFD) in product reviews.\nFor this purpose, we annotate a multilingual CFD dataset from Amazon product\nreviews covering counterfactual statements written in English, German, and\nJapanese languages. The dataset is unique as it contains counterfactuals in\nmultiple languages, covers a new application area of e-commerce reviews, and\nprovides high quality professional annotations. We train CFD models using\ndifferent text representation methods and classifiers. We find that these\nmodels are robust against the selectional biases introduced due to cue\nphrase-based sentence selection. Moreover, our CFD dataset is compatible with\nprior datasets and can be merged to learn accurate CFD models. Applying machine\ntranslation on English counterfactual examples to create multilingual data\nperforms poorly, demonstrating the language-specificity of this problem, which\nhas been ignored so far.\n", "versions": [{"version": "v1", "created": "Wed, 14 Apr 2021 14:38:36 GMT"}], "update_date": "2021-04-15", "authors_parsed": [["O'Neill", "James", ""], ["Rozenshtein", "Polina", ""], ["Kiryo", "Ryuichi", ""], ["Kubota", "Motoko", ""], ["Bollegala", "Danushka", ""]]}, {"id": "2104.06901", "submitter": "Rohan Kumar Yadav", "authors": "Rohan Kumar Yadav, Lei Jiao, Ole-Christoffer Granmo, and Morten\n  Goodwin", "title": "Distributed Word Representation in Tsetlin Machine", "comments": "9 pages, 13 figures, and 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tsetlin Machine (TM) is an interpretable pattern recognition algorithm based\non propositional logic. The algorithm has demonstrated competitive performance\nin many Natural Language Processing (NLP) tasks, including sentiment analysis,\ntext classification, and Word Sense Disambiguation (WSD). To obtain human-level\ninterpretability, legacy TM employs Boolean input features such as bag-of-words\n(BOW). However, the BOW representation makes it difficult to use any\npre-trained information, for instance, word2vec and GloVe word representations.\nThis restriction has constrained the performance of TM compared to deep neural\nnetworks (DNNs) in NLP. To reduce the performance gap, in this paper, we\npropose a novel way of using pre-trained word representations for TM. The\napproach significantly enhances the TM performance and maintains\ninterpretability at the same time. We achieve this by extracting semantically\nrelated words from pre-trained word representations as input features to the\nTM. Our experiments show that the accuracy of the proposed approach is\nsignificantly higher than the previous BOW-based TM, reaching the level of\nDNN-based models.\n", "versions": [{"version": "v1", "created": "Wed, 14 Apr 2021 14:48:41 GMT"}], "update_date": "2021-04-15", "authors_parsed": [["Yadav", "Rohan Kumar", ""], ["Jiao", "Lei", ""], ["Granmo", "Ole-Christoffer", ""], ["Goodwin", "Morten", ""]]}, {"id": "2104.06917", "submitter": "Dmitry Kazhdan", "authors": "Dmitry Kazhdan, Botty Dimanov, Helena Andres Terre, Mateja Jamnik,\n  Pietro Li\\`o, Adrian Weller", "title": "Is Disentanglement all you need? Comparing Concept-based &\n  Disentanglement Approaches", "comments": "Presented at the RAI, WeaSul, and RobustML workshops at The Ninth\n  International Conference on Learning Representations (ICLR) 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Concept-based explanations have emerged as a popular way of extracting\nhuman-interpretable representations from deep discriminative models. At the\nsame time, the disentanglement learning literature has focused on extracting\nsimilar representations in an unsupervised or weakly-supervised way, using deep\ngenerative models. Despite the overlapping goals and potential synergies, to\nour knowledge, there has not yet been a systematic comparison of the\nlimitations and trade-offs between concept-based explanations and\ndisentanglement approaches. In this paper, we give an overview of these fields,\ncomparing and contrasting their properties and behaviours on a diverse set of\ntasks, and highlighting their potential strengths and limitations. In\nparticular, we demonstrate that state-of-the-art approaches from both classes\ncan be data inefficient, sensitive to the specific nature of the\nclassification/regression task, or sensitive to the employed concept\nrepresentation.\n", "versions": [{"version": "v1", "created": "Wed, 14 Apr 2021 15:06:34 GMT"}], "update_date": "2021-04-15", "authors_parsed": [["Kazhdan", "Dmitry", ""], ["Dimanov", "Botty", ""], ["Terre", "Helena Andres", ""], ["Jamnik", "Mateja", ""], ["Li\u00f2", "Pietro", ""], ["Weller", "Adrian", ""]]}, {"id": "2104.06922", "submitter": "Karam Daaboul", "authors": "Moritz A. Zanger, Karam Daaboul, J. Marius Z\\\"ollner", "title": "Safe Continuous Control with Constrained Model-Based Policy Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The applicability of reinforcement learning (RL) algorithms in real-world\ndomains often requires adherence to safety constraints, a need difficult to\naddress given the asymptotic nature of the classic RL optimization objective.\nIn contrast to the traditional RL objective, safe exploration considers the\nmaximization of expected returns under safety constraints expressed in expected\ncost returns. We introduce a model-based safe exploration algorithm for\nconstrained high-dimensional control to address the often prohibitively high\nsample complexity of model-free safe exploration algorithms. Further, we\nprovide theoretical and empirical analyses regarding the implications of\nmodel-usage on constrained policy optimization problems and introduce a\npractical algorithm that accelerates policy search with model-generated data.\nThe need for accurate estimates of a policy's constraint satisfaction is in\nconflict with accumulating model-errors. We address this issue by quantifying\nmodel-uncertainty as the expected Kullback-Leibler divergence between\npredictions of an ensemble of probabilistic dynamics models and constrain this\nerror-measure, resulting in an adaptive resampling scheme and dynamically\nlimited rollout horizons. We evaluate this approach on several simulated\nconstrained robot locomotion tasks with high-dimensional action- and\nstate-spaces. Our empirical studies find that our algorithm reaches model-free\nperformances with a 10-20 fold reduction of training samples while maintaining\napproximate constraint satisfaction levels of model-free methods.\n", "versions": [{"version": "v1", "created": "Wed, 14 Apr 2021 15:20:55 GMT"}], "update_date": "2021-04-15", "authors_parsed": [["Zanger", "Moritz A.", ""], ["Daaboul", "Karam", ""], ["Z\u00f6llner", "J. Marius", ""]]}, {"id": "2104.06934", "submitter": "Hans Weytjens", "authors": "Hans Weytjens and Jochen De Weerdt", "title": "Process Outcome Prediction: CNN vs. LSTM (with Attention)", "comments": null, "journal-ref": "In: Del R\\'io Ortega A., Leopold H., Santoro F.M. (eds) Business\n  Process Management Workshops. BPM 2020. Lecture Notes in Business Information\n  Processing, vol 397. Springer, Cham", "doi": "10.1007/978-3-030-66498-5_24", "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  The early outcome prediction of ongoing or completed processes confers\ncompetitive advantage to organizations. The performance of classic machine\nlearning and, more recently, deep learning techniques such as Long Short-Term\nMemory (LSTM) on this type of classification problem has been thorougly\ninvestigated. Recently, much research focused on applying Convolutional Neural\nNetworks (CNN) to time series problems including classification, however not\nyet to outcome prediction. The purpose of this paper is to close this gap and\ncompare CNNs to LSTMs. Attention is another technique that, in combination with\nLSTMs, has found application in time series classification and was included in\nour research. Our findings show that all these neural networks achieve\nsatisfactory to high predictive power provided sufficiently large datasets.\nCNNs perfom on par with LSTMs; the Attention mechanism adds no value to the\nlatter. Since CNNs run one order of magnitude faster than both types of LSTM,\ntheir use is preferable. All models are robust with respect to their\nhyperparameters and achieve their maximal predictive power early on in the\ncases, usually after only a few events, making them highly suitable for runtime\npredictions. We argue that CNNs' speed, early predictive power and robustness\nshould pave the way for their application in process outcome prediction.\n", "versions": [{"version": "v1", "created": "Wed, 14 Apr 2021 15:38:32 GMT"}], "update_date": "2021-04-15", "authors_parsed": [["Weytjens", "Hans", ""], ["De Weerdt", "Jochen", ""]]}, {"id": "2104.06935", "submitter": "Julian Chibane", "authors": "Julian Chibane, Aayush Bansal, Verica Lazova, Gerard Pons-Moll", "title": "Stereo Radiance Fields (SRF): Learning View Synthesis for Sparse Views\n  of Novel Scenes", "comments": "IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\n  2021", "journal-ref": "IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\n  2021", "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent neural view synthesis methods have achieved impressive quality and\nrealism, surpassing classical pipelines which rely on multi-view\nreconstruction. State-of-the-Art methods, such as NeRF, are designed to learn a\nsingle scene with a neural network and require dense multi-view inputs. Testing\non a new scene requires re-training from scratch, which takes 2-3 days. In this\nwork, we introduce Stereo Radiance Fields (SRF), a neural view synthesis\napproach that is trained end-to-end, generalizes to new scenes, and requires\nonly sparse views at test time. The core idea is a neural architecture inspired\nby classical multi-view stereo methods, which estimates surface points by\nfinding similar image regions in stereo images. In SRF, we predict color and\ndensity for each 3D point given an encoding of its stereo correspondence in the\ninput images. The encoding is implicitly learned by an ensemble of pair-wise\nsimilarities -- emulating classical stereo. Experiments show that SRF learns\nstructure instead of overfitting on a scene. We train on multiple scenes of the\nDTU dataset and generalize to new ones without re-training, requiring only 10\nsparse and spread-out views as input. We show that 10-15 minutes of fine-tuning\nfurther improve the results, achieving significantly sharper, more detailed\nresults than scene-specific models. The code, model, and videos are available\nat https://virtualhumans.mpi-inf.mpg.de/srf/.\n", "versions": [{"version": "v1", "created": "Wed, 14 Apr 2021 15:38:57 GMT"}], "update_date": "2021-04-15", "authors_parsed": [["Chibane", "Julian", ""], ["Bansal", "Aayush", ""], ["Lazova", "Verica", ""], ["Pons-Moll", "Gerard", ""]]}, {"id": "2104.06942", "submitter": "Jindou Dai", "authors": "Jindou Dai, Yuwei Wu, Zhi Gao, and Yunde Jia", "title": "A Hyperbolic-to-Hyperbolic Graph Convolutional Network", "comments": "CVPR2021, Oral", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Hyperbolic graph convolutional networks (GCNs) demonstrate powerful\nrepresentation ability to model graphs with hierarchical structure. Existing\nhyperbolic GCNs resort to tangent spaces to realize graph convolution on\nhyperbolic manifolds, which is inferior because tangent space is only a local\napproximation of a manifold. In this paper, we propose a\nhyperbolic-to-hyperbolic graph convolutional network (H2H-GCN) that directly\nworks on hyperbolic manifolds. Specifically, we developed a manifold-preserving\ngraph convolution that consists of a hyperbolic feature transformation and a\nhyperbolic neighborhood aggregation. The hyperbolic feature transformation\nworks as linear transformation on hyperbolic manifolds. It ensures the\ntransformed node representations still lie on the hyperbolic manifold by\nimposing the orthogonal constraint on the transformation sub-matrix. The\nhyperbolic neighborhood aggregation updates each node representation via the\nEinstein midpoint. The H2H-GCN avoids the distortion caused by tangent space\napproximations and keeps the global hyperbolic structure. Extensive experiments\nshow that the H2H-GCN achieves substantial improvements on the link prediction,\nnode classification, and graph classification tasks.\n", "versions": [{"version": "v1", "created": "Wed, 14 Apr 2021 16:09:27 GMT"}], "update_date": "2021-04-15", "authors_parsed": [["Dai", "Jindou", ""], ["Wu", "Yuwei", ""], ["Gao", "Zhi", ""], ["Jia", "Yunde", ""]]}, {"id": "2104.06952", "submitter": "Kellin Pelrine", "authors": "Kellin Pelrine, Jacob Danovitch, Reihaneh Rabbany", "title": "The Surprising Performance of Simple Baselines for Misinformation\n  Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  As social media becomes increasingly prominent in our day to day lives, it is\nincreasingly important to detect informative content and prevent the spread of\ndisinformation and unverified rumours. While many sophisticated and successful\nmodels have been proposed in the literature, they are often compared with older\nNLP baselines such as SVMs, CNNs, and LSTMs. In this paper, we examine the\nperformance of a broad set of modern transformer-based language models and show\nthat with basic fine-tuning, these models are competitive with and can even\nsignificantly outperform recently proposed state-of-the-art methods. We present\nour framework as a baseline for creating and evaluating new methods for\nmisinformation detection. We further study a comprehensive set of benchmark\ndatasets, and discuss potential data leakage and the need for careful design of\nthe experiments and understanding of datasets to account for confounding\nvariables. As an extreme case example, we show that classifying only based on\nthe first three digits of tweet ids, which contain information on the date,\ngives state-of-the-art performance on a commonly used benchmark dataset for\nfake news detection --Twitter16. We provide a simple tool to detect this\nproblem and suggest steps to mitigate it in future datasets.\n", "versions": [{"version": "v1", "created": "Wed, 14 Apr 2021 16:25:22 GMT"}], "update_date": "2021-04-15", "authors_parsed": [["Pelrine", "Kellin", ""], ["Danovitch", "Jacob", ""], ["Rabbany", "Reihaneh", ""]]}, {"id": "2104.06970", "submitter": "Gene Li", "authors": "Gene Li, Pritish Kamath, Dylan J. Foster, Nathan Srebro", "title": "Eluder Dimension and Generalized Rank", "comments": "Technical Note", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the relationship between the eluder dimension for a function class\nand a generalized notion of rank, defined for any monotone \"activation\" $\\sigma\n: \\mathbb{R} \\to \\mathbb{R}$, which corresponds to the minimal dimension\nrequired to represent the class as a generalized linear model. When $\\sigma$\nhas derivatives bounded away from $0$, it is known that $\\sigma$-rank gives\nrise to an upper bound on eluder dimension for any function class; we show\nhowever that eluder dimension can be exponentially smaller than $\\sigma$-rank.\nWe also show that the condition on the derivative is necessary; namely, when\n$\\sigma$ is the $\\mathrm{relu}$ activation, we show that eluder dimension can\nbe exponentially larger than $\\sigma$-rank.\n", "versions": [{"version": "v1", "created": "Wed, 14 Apr 2021 16:53:13 GMT"}], "update_date": "2021-04-15", "authors_parsed": [["Li", "Gene", ""], ["Kamath", "Pritish", ""], ["Foster", "Dylan J.", ""], ["Srebro", "Nathan", ""]]}, {"id": "2104.06990", "submitter": "Cong Shen", "authors": "Cong Shen, Jie Xu, Sihui Zheng, Xiang Chen", "title": "Resource Rationing for Wireless Federated Learning: Concept, Benefits,\n  and Challenges", "comments": "7 pages, 6 pages, accepted to IEEE Communications Magazine", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.IT cs.LG cs.NI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We advocate a new resource allocation framework, which we term resource\nrationing, for wireless federated learning (FL). Unlike existing resource\nallocation methods for FL, resource rationing focuses on balancing resources\nacross learning rounds so that their collective impact on the federated\nlearning performance is explicitly captured. This new framework can be\nintegrated seamlessly with existing resource allocation schemes to optimize the\nconvergence of FL. In particular, a novel \"later-is-better\" principle is at the\nfront and center of resource rationing, which is validated empirically in\nseveral instances of wireless FL. We also point out technical challenges and\nresearch opportunities that are worth pursuing. Resource rationing highlights\nthe benefits of treating the emerging FL as a new class of service that has its\nown characteristics, and designing communication algorithms for this particular\nservice.\n", "versions": [{"version": "v1", "created": "Wed, 14 Apr 2021 17:16:33 GMT"}], "update_date": "2021-04-15", "authors_parsed": [["Shen", "Cong", ""], ["Xu", "Jie", ""], ["Zheng", "Sihui", ""], ["Chen", "Xiang", ""]]}, {"id": "2104.07004", "submitter": "Ioannis Kansizoglou", "authors": "Ioannis Kansizoglou, Loukas Bampis, and Antonios Gasteratos", "title": "Do Neural Network Weights account for Classes Centers?", "comments": "Index Terms: Discriminative feature learning, deep neural networks,\n  symmetrical layer, geometric algebra", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The exploitation of Deep Neural Networks (DNNs) as descriptors in feature\nlearning challenges enjoys apparent popularity over the past few years. The\nabove tendency focuses on the development of effective loss functions that\nensure both high feature discrimination among different classes, as well as low\ngeodesic distance between the feature vectors of a given class. The vast\nmajority of the contemporary works rely their formulation on an empirical\nassumption about the feature space of a network's last hidden layer, claiming\nthat the weight vector of a class accounts for its geometrical center in the\nstudied space. The paper at hand follows a theoretical approach and indicates\nthat the aforementioned hypothesis is not exclusively met. This fact raises\nstability issues regarding the training procedure of a DNN, as shown in our\nexperimental study. Consequently, a specific symmetry is proposed and studied\nboth analytically and empirically that satisfies the above assumption,\naddressing the established convergence issues.\n", "versions": [{"version": "v1", "created": "Wed, 14 Apr 2021 17:37:52 GMT"}], "update_date": "2021-04-15", "authors_parsed": [["Kansizoglou", "Ioannis", ""], ["Bampis", "Loukas", ""], ["Gasteratos", "Antonios", ""]]}, {"id": "2104.07006", "submitter": "Anastasios Kyrillidis", "authors": "Junhyung Lyle Kim, George Kollias, Amir Kalev, Ken X. Wei, Anastasios\n  Kyrillidis", "title": "Fast quantum state reconstruction via accelerated non-convex programming", "comments": "46 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.IT cs.LG math.IT math.OC stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose a new quantum state reconstruction method that combines ideas from\ncompressed sensing, non-convex optimization, and acceleration methods. The\nalgorithm, called Momentum-Inspired Factored Gradient Descent (\\texttt{MiFGD}),\nextends the applicability of quantum tomography for larger systems. Despite\nbeing a non-convex method, \\texttt{MiFGD} converges \\emph{provably} to the true\ndensity matrix at a linear rate, in the absence of experimental and statistical\nnoise, and under common assumptions. With this manuscript, we present the\nmethod, prove its convergence property and provide Frobenius norm bound\nguarantees with respect to the true density matrix. From a practical point of\nview, we benchmark the algorithm performance with respect to other existing\nmethods, in both synthetic and real experiments performed on an IBM's quantum\nprocessing unit. We find that the proposed algorithm performs orders of\nmagnitude faster than state of the art approaches, with the same or better\naccuracy. In both synthetic and real experiments, we observed accurate and\nrobust reconstruction, despite experimental and statistical noise in the\ntomographic data. Finally, we provide a ready-to-use code for state tomography\nof multi-qubit systems.\n", "versions": [{"version": "v1", "created": "Wed, 14 Apr 2021 17:38:40 GMT"}, {"version": "v2", "created": "Fri, 30 Apr 2021 15:51:00 GMT"}, {"version": "v3", "created": "Fri, 25 Jun 2021 08:38:20 GMT"}], "update_date": "2021-06-28", "authors_parsed": [["Kim", "Junhyung Lyle", ""], ["Kollias", "George", ""], ["Kalev", "Amir", ""], ["Wei", "Ken X.", ""], ["Kyrillidis", "Anastasios", ""]]}, {"id": "2104.07010", "submitter": "Adri\\'an Bazaga", "authors": "Adri\\'an Bazaga and Nupur Gunwant and Gos Micklem", "title": "Translating synthetic natural language to database queries: a polyglot\n  deep learning framework", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.DB cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The number of databases as well as their size and complexity is increasing.\nThis creates a barrier to use especially for non-experts, who have to come to\ngrips with the nature of the data, the way it has been represented in the\ndatabase, and the specific query languages or user interfaces by which data are\naccessed. These difficulties worsen in research settings, where it is common to\nwork with many different databases. One approach to improving this situation is\nto allow users to pose their queries in natural language.\n  In this work we describe a machine learning framework, Polyglotter, that in a\ngeneral way supports the mapping of natural language searches to database\nqueries. Importantly, it does not require the creation of manually annotated\ndata for training and therefore can be applied easily to multiple domains. The\nframework is polyglot in the sense that it supports multiple different database\nengines that are accessed with a variety of query languages, including SQL and\nCypher. Furthermore Polyglotter also supports multi-class queries.\n  Our results indicate that our framework performs well on both synthetic and\nreal databases, and may provide opportunities for database maintainers to\nimprove accessibility to their resources.\n", "versions": [{"version": "v1", "created": "Wed, 14 Apr 2021 17:43:51 GMT"}], "update_date": "2021-04-15", "authors_parsed": [["Bazaga", "Adri\u00e1n", ""], ["Gunwant", "Nupur", ""], ["Micklem", "Gos", ""]]}, {"id": "2104.07012", "submitter": "Biao Zhang", "authors": "Biao Zhang, Ivan Titov, Rico Sennrich", "title": "Sparse Attention with Linear Units", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Recently, it has been argued that encoder-decoder models can be made more\ninterpretable by replacing the softmax function in the attention with its\nsparse variants. In this work, we introduce a novel, simple method for\nachieving sparsity in attention: we replace the softmax activation with a ReLU,\nand show that sparsity naturally emerges from such a formulation. Training\nstability is achieved with layer normalization with either a specialized\ninitialization or an additional gating function. Our model, which we call\nRectified Linear Attention (ReLA), is easy to implement and more efficient than\npreviously proposed sparse attention mechanisms. We apply ReLA to the\nTransformer and conduct experiments on five machine translation tasks. ReLA\nachieves translation performance comparable to several strong baselines, with\ntraining and decoding speed similar to that of the vanilla attention. Our\nanalysis shows that ReLA delivers high sparsity rate and head diversity, and\nthe induced cross attention achieves better accuracy with respect to\nsource-target word alignment than recent sparsified softmax-based models.\nIntriguingly, ReLA heads also learn to attend to nothing (i.e. 'switch off')\nfor some queries, which is not possible with sparsified softmax alternatives.\n", "versions": [{"version": "v1", "created": "Wed, 14 Apr 2021 17:52:38 GMT"}], "update_date": "2021-04-15", "authors_parsed": [["Zhang", "Biao", ""], ["Titov", "Ivan", ""], ["Sennrich", "Rico", ""]]}, {"id": "2104.07029", "submitter": "Maciej Skorski", "authors": "Maciej Skorski", "title": "Mean-Squared Accuracy of Good-Turing Estimator", "comments": null, "journal-ref": null, "doi": "10.13140/RG.2.2.31351.44960/1", "report-no": null, "categories": "stat.ML cs.CR cs.IT cs.LG math.IT stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The brilliant method due to Good and Turing allows for estimating objects not\noccurring in a sample. The problem, known under names \"sample coverage\" or\n\"missing mass\" goes back to their cryptographic work during WWII, but over\nyears has found has many applications, including language modeling, inference\nin ecology and estimation of distribution properties. This work characterizes\nthe maximal mean-squared error of the Good-Turing estimator, for any sample\n\\emph{and} alphabet size.\n", "versions": [{"version": "v1", "created": "Wed, 14 Apr 2021 17:23:46 GMT"}], "update_date": "2021-04-16", "authors_parsed": [["Skorski", "Maciej", ""]]}, {"id": "2104.07054", "submitter": "Giorgio Gnecco", "authors": "Giorgio Gnecco, Andrea Bacigalupo", "title": "On principal component analysis of the convex combination of two data\n  matrices and its application to acoustic metamaterial filters", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this short paper, a matrix perturbation bound on the eigenvalues found by\nprincipal component analysis is investigated, for the case in which the data\nmatrix on which principal component analysis is performed is a convex\ncombination of two data matrices. The application of the theoretical analysis\nto multi-objective optimization problems (e.g., those arising in the design of\nacoustic metamaterial filters) is briefly discussed, together with possible\nextensions.\n", "versions": [{"version": "v1", "created": "Sun, 4 Apr 2021 11:26:32 GMT"}, {"version": "v2", "created": "Fri, 16 Apr 2021 11:42:22 GMT"}], "update_date": "2021-04-19", "authors_parsed": [["Gnecco", "Giorgio", ""], ["Bacigalupo", "Andrea", ""]]}, {"id": "2104.07059", "submitter": "SueYeon Chung", "authors": "SueYeon Chung, L. F. Abbott", "title": "Neural population geometry: An approach for understanding biological and\n  artificial neural networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Advances in experimental neuroscience have transformed our ability to explore\nthe structure and function of neural circuits. At the same time, advances in\nmachine learning have unleashed the remarkable computational power of\nartificial neural networks (ANNs). While these two fields have different tools\nand applications, they present a similar challenge: namely, understanding how\ninformation is embedded and processed through high-dimensional representations\nto solve complex tasks. One approach to addressing this challenge is to utilize\nmathematical and computational tools to analyze the geometry of these\nhigh-dimensional representations, i.e., neural population geometry. We review\nexamples of geometrical approaches providing insight into the function of\nbiological and artificial neural networks: representation untangling in\nperception, a geometric theory of classification capacity, disentanglement and\nabstraction in cognitive systems, topological representations underlying\ncognitive maps, dynamic untangling in motor systems, and a dynamical approach\nto cognition. Together, these findings illustrate an exciting trend at the\nintersection of machine learning, neuroscience, and geometry, in which neural\npopulation geometry provides a useful population-level mechanistic descriptor\nunderlying task implementation. Importantly, geometric descriptions are\napplicable across sensory modalities, brain regions, network architectures and\ntimescales. Thus, neural population geometry has the potential to unify our\nunderstanding of structure and function in biological and artificial neural\nnetworks, bridging the gap between single neurons, populations and behavior.\n", "versions": [{"version": "v1", "created": "Wed, 14 Apr 2021 18:10:34 GMT"}, {"version": "v2", "created": "Sat, 17 Apr 2021 03:30:26 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Chung", "SueYeon", ""], ["Abbott", "L. F.", ""]]}, {"id": "2104.07060", "submitter": "Mohit Kumar", "authors": "Mohit Kumar, Bernhard A. Moser, Lukas Fischer, Bernhard Freudenthaler", "title": "Membership-Mappings for Data Representation Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.FA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This study introduces using measure theoretic basis the notion of\nmembership-mapping for representing data points through attribute values\n(motivated by fuzzy theory). A property of the membership-mapping, that can be\nexploited for data representation learning, is of providing an interpolation on\nthe given data points in the data space. The study outlines an analytical\napproach to the variational learning of a membership-mappings based data\nrepresentation model. An alternative idea of deep autoencoder, referred to as\nBregman Divergence Based Conditionally Deep Autoencoder (that consists of\nlayers such that each layer learns data representation at certain abstraction\nlevel through a membership-mappings based autoencoder), is presented.\nExperiments are provided to demonstrate the competitive performance of the\nproposed framework in classifying high-dimensional feature vectors and in\nrendering robustness to the classification.\n", "versions": [{"version": "v1", "created": "Wed, 14 Apr 2021 18:10:59 GMT"}, {"version": "v2", "created": "Fri, 28 May 2021 11:11:56 GMT"}], "update_date": "2021-05-31", "authors_parsed": [["Kumar", "Mohit", ""], ["Moser", "Bernhard A.", ""], ["Fischer", "Lukas", ""], ["Freudenthaler", "Bernhard", ""]]}, {"id": "2104.07061", "submitter": "Sebastian Macaluso", "authors": "Craig S. Greenberg, Sebastian Macaluso, Nicholas Monath, Avinava\n  Dubey, Patrick Flaherty, Manzil Zaheer, Amr Ahmed, Kyle Cranmer, Andrew\n  McCallum", "title": "Exact and Approximate Hierarchical Clustering Using A*", "comments": "30 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS physics.data-an stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hierarchical clustering is a critical task in numerous domains. Many\napproaches are based on heuristics and the properties of the resulting\nclusterings are studied post hoc. However, in several applications, there is a\nnatural cost function that can be used to characterize the quality of the\nclustering. In those cases, hierarchical clustering can be seen as a\ncombinatorial optimization problem. To that end, we introduce a new approach\nbased on A* search. We overcome the prohibitively large search space by\ncombining A* with a novel \\emph{trellis} data structure. This combination\nresults in an exact algorithm that scales beyond previous state of the art,\nfrom a search space with $10^{12}$ trees to $10^{15}$ trees, and an approximate\nalgorithm that improves over baselines, even in enormous search spaces that\ncontain more than $10^{1000}$ trees. We empirically demonstrate that our method\nachieves substantially higher quality results than baselines for a particle\nphysics use case and other clustering benchmarks. We describe how our method\nprovides significantly improved theoretical bounds on the time and space\ncomplexity of A* for clustering.\n", "versions": [{"version": "v1", "created": "Wed, 14 Apr 2021 18:15:27 GMT"}], "update_date": "2021-04-16", "authors_parsed": [["Greenberg", "Craig S.", ""], ["Macaluso", "Sebastian", ""], ["Monath", "Nicholas", ""], ["Dubey", "Avinava", ""], ["Flaherty", "Patrick", ""], ["Zaheer", "Manzil", ""], ["Ahmed", "Amr", ""], ["Cranmer", "Kyle", ""], ["McCallum", "Andrew", ""]]}, {"id": "2104.07072", "submitter": "Georgios Paraskevopoulos", "authors": "Georgios Paraskevopoulos, Efthymios Tzinis, Nikolaos Ellinas,\n  Theodoros Giannakopoulos and Alexandros Potamianos", "title": "Unsupervised low-rank representations for speech emotion recognition", "comments": "Published at Interspeech 2019\n  https://www.isca-speech.org/archive/Interspeech_2019/abstracts/2769.html", "journal-ref": null, "doi": "10.21437/Interspeech.2019-2769", "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We examine the use of linear and non-linear dimensionality reduction\nalgorithms for extracting low-rank feature representations for speech emotion\nrecognition. Two feature sets are used, one based on low-level descriptors and\ntheir aggregations (IS10) and one modeling recurrence dynamics of speech (RQA),\nas well as their fusion. We report speech emotion recognition (SER) results for\nlearned representations on two databases using different classification\nmethods. Classification with low-dimensional representations yields performance\nimprovement in a variety of settings. This indicates that dimensionality\nreduction is an effective way to combat the curse of dimensionality for SER.\nVisualization of features in two dimensions provides insight into\ndiscriminatory abilities of reduced feature sets.\n", "versions": [{"version": "v1", "created": "Wed, 14 Apr 2021 18:30:58 GMT"}], "update_date": "2021-04-16", "authors_parsed": [["Paraskevopoulos", "Georgios", ""], ["Tzinis", "Efthymios", ""], ["Ellinas", "Nikolaos", ""], ["Giannakopoulos", "Theodoros", ""], ["Potamianos", "Alexandros", ""]]}, {"id": "2104.07079", "submitter": "Maria Leonor Pacheco", "authors": "I-Ta Lee, Maria Leonor Pacheco and Dan Goldwasser", "title": "Modeling Human Mental States with an Entity-based Narrative Graph", "comments": "Accepted at NAACL 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding narrative text requires capturing characters' motivations,\ngoals, and mental states. This paper proposes an Entity-based Narrative Graph\n(ENG) to model the internal-states of characters in a story. We explicitly\nmodel entities, their interactions and the context in which they appear, and\nlearn rich representations for them. We experiment with different task-adaptive\npre-training objectives, in-domain training, and symbolic inference to capture\ndependencies between different decisions in the output space. We evaluate our\nmodel on two narrative understanding tasks: predicting character mental states,\nand desire fulfillment, and conduct a qualitative analysis.\n", "versions": [{"version": "v1", "created": "Wed, 14 Apr 2021 19:05:19 GMT"}], "update_date": "2021-04-16", "authors_parsed": [["Lee", "I-Ta", ""], ["Pacheco", "Maria Leonor", ""], ["Goldwasser", "Dan", ""]]}, {"id": "2104.07084", "submitter": "Hussein Hazimeh", "authors": "Hussein Hazimeh, Rahul Mazumder, Peter Radchenko", "title": "Grouped Variable Selection with Discrete Optimization: Computational and\n  Statistical Perspectives", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.LG math.OC stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new algorithmic framework for grouped variable selection that is\nbased on discrete mathematical optimization. While there exist several\nappealing approaches based on convex relaxations and nonconvex heuristics, we\nfocus on optimal solutions for the $\\ell_0$-regularized formulation, a problem\nthat is relatively unexplored due to computational challenges. Our methodology\ncovers both high-dimensional linear regression and nonparametric sparse\nadditive modeling with smooth components. Our algorithmic framework consists of\napproximate and exact algorithms. The approximate algorithms are based on\ncoordinate descent and local search, with runtimes comparable to popular sparse\nlearning algorithms. Our exact algorithm is based on a standalone\nbranch-and-bound (BnB) framework, which can solve the associated mixed integer\nprogramming (MIP) problem to certified optimality. By exploiting the problem\nstructure, our custom BnB algorithm can solve to optimality problem instances\nwith $5 \\times 10^6$ features in minutes to hours -- over $1000$ times larger\nthan what is currently possible using state-of-the-art commercial MIP solvers.\nWe also explore statistical properties of the $\\ell_0$-based estimators. We\ndemonstrate, theoretically and empirically, that our proposed estimators have\nan edge over popular group-sparse estimators in terms of statistical\nperformance in various regimes.\n", "versions": [{"version": "v1", "created": "Wed, 14 Apr 2021 19:21:59 GMT"}], "update_date": "2021-04-16", "authors_parsed": [["Hazimeh", "Hussein", ""], ["Mazumder", "Rahul", ""], ["Radchenko", "Peter", ""]]}, {"id": "2104.07128", "submitter": "Julia A. Meister", "authors": "Julia A. Meister and Khuong An Nguyen and Zhiyuan Luo", "title": "Audio feature ranking for sound-based COVID-19 patient detection", "comments": "22 pages, 6 figures, 8 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Audio classification using breath and cough samples has recently emerged as a\nlow-cost, non-invasive, and accessible COVID-19 screening method. However, no\napplication has been approved for official use at the time of writing due to\nthe stringent reliability and accuracy requirements of the critical healthcare\nsetting. To support the development of the Machine Learning classification\nmodels, we performed an extensive comparative investigation and ranking of 15\naudio features, including less well-known ones. The results were verified on\ntwo independent COVID-19 sound datasets. By using the identified top-performing\nfeatures, we have increased the COVID-19 classification accuracy by up to 17%\non the Cambridge dataset, and up to 10% on the Coswara dataset, compared to the\noriginal baseline accuracy without our feature ranking.\n", "versions": [{"version": "v1", "created": "Wed, 14 Apr 2021 21:06:20 GMT"}], "update_date": "2021-04-16", "authors_parsed": [["Meister", "Julia A.", ""], ["Nguyen", "Khuong An", ""], ["Luo", "Zhiyuan", ""]]}, {"id": "2104.07136", "submitter": "Pedro Kaufmann", "authors": "Alirio G\\'omez G\\'omez, Pedro L. Kaufmann", "title": "On the Vapnik-Chervonenkis dimension of products of intervals in\n  $\\mathbb{R}^d$", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.MG cs.LG math.CO stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study combinatorial complexity of certain classes of products of intervals\nin $\\mathbb{R}^d$, from the point of view of Vapnik-Chervonenkis geometry. As a\nconsequence of the obtained results, we conclude that the Vapnik-Chervonenkis\ndimension of the set of balls in $\\ell_\\infty^d$ -- which denotes $\\R^d$\nequipped with the sup norm -- equals $\\lfloor (3d+1)/2\\rfloor$.\n", "versions": [{"version": "v1", "created": "Wed, 14 Apr 2021 21:40:15 GMT"}], "update_date": "2021-04-16", "authors_parsed": [["G\u00f3mez", "Alirio G\u00f3mez", ""], ["Kaufmann", "Pedro L.", ""]]}, {"id": "2104.07143", "submitter": "Tolga Bolukbasi", "authors": "Tolga Bolukbasi, Adam Pearce, Ann Yuan, Andy Coenen, Emily Reif,\n  Fernanda Vi\\'egas, Martin Wattenberg", "title": "An Interpretability Illusion for BERT", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe an \"interpretability illusion\" that arises when analyzing the\nBERT model. Activations of individual neurons in the network may spuriously\nappear to encode a single, simple concept, when in fact they are encoding\nsomething far more complex. The same effect holds for linear combinations of\nactivations. We trace the source of this illusion to geometric properties of\nBERT's embedding space as well as the fact that common text corpora represent\nonly narrow slices of possible English sentences. We provide a taxonomy of\nmodel-learned concepts and discuss methodological implications for\ninterpretability research, especially the importance of testing hypotheses on\nmultiple data sets.\n", "versions": [{"version": "v1", "created": "Wed, 14 Apr 2021 22:04:48 GMT"}], "update_date": "2021-04-16", "authors_parsed": [["Bolukbasi", "Tolga", ""], ["Pearce", "Adam", ""], ["Yuan", "Ann", ""], ["Coenen", "Andy", ""], ["Reif", "Emily", ""], ["Vi\u00e9gas", "Fernanda", ""], ["Wattenberg", "Martin", ""]]}, {"id": "2104.07145", "submitter": "Chaoyang He", "authors": "Chaoyang He, Keshav Balasubramanian, Emir Ceyani, Yu Rong, Peilin\n  Zhao, Junzhou Huang, Murali Annavaram, Salman Avestimehr", "title": "FedGraphNN: A Federated Learning System and Benchmark for Graph Neural\n  Networks", "comments": "The first three authors contribute equally. Our shorter versions are\n  accepted to ICLR 2021 Workshop on Distributed and Private Machine\n  Learning(DPML) and MLSys 2021 GNNSys Workshop on Graph Neural Networks and\n  Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Graph Neural Network (GNN) research is rapidly growing thanks to the capacity\nof GNNs to learn representations from graph-structured data. However,\ncentralizing a massive amount of real-world graph data for GNN training is\nprohibitive due to user-side privacy concerns, regulation restrictions, and\ncommercial competition. Federated learning (FL), a trending distributed\nlearning paradigm, aims to solve this challenge while preserving privacy.\nDespite recent advances in vision and language domains, there is no suitable\nplatform for the federated training of GNNs. To this end, we introduce\nFedGraphNN, an open research federated learning system and a benchmark to\nfacilitate GNN-based FL research. FedGraphNN is built on a unified formulation\nof federated GNNs and supports commonly used datasets, GNN models, FL\nalgorithms, and flexible APIs. We also contribute a new molecular dataset,\nhERG, to promote research exploration. Our experimental results present\nsignificant challenges in federated GNN training: federated GNNs perform worse\nin most datasets with a non-I.I.D split than centralized GNNs; the GNN model\nthat attains the best result in the centralized setting may not hold its\nadvantage in the federated setting. These results imply that more research\nefforts are needed to unravel the mystery behind federated GNN training.\nMoreover, our system performance analysis demonstrates that the FedGraphNN\nsystem is computationally affordable to most research labs with limited GPUs.\nWe maintain the source code at https://github.com/FedML-AI/FedGraphNN.\n", "versions": [{"version": "v1", "created": "Wed, 14 Apr 2021 22:11:35 GMT"}], "update_date": "2021-04-16", "authors_parsed": [["He", "Chaoyang", ""], ["Balasubramanian", "Keshav", ""], ["Ceyani", "Emir", ""], ["Rong", "Yu", ""], ["Zhao", "Peilin", ""], ["Huang", "Junzhou", ""], ["Annavaram", "Murali", ""], ["Avestimehr", "Salman", ""]]}, {"id": "2104.07150", "submitter": "Chuanhao Li", "authors": "Chuanhao Li, Qingyun Wu, Hongning Wang", "title": "When and Whom to Collaborate with in a Changing Environment: A\n  Collaborative Dynamic Bandit Solution", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Collaborative bandit learning, i.e., bandit algorithms that utilize\ncollaborative filtering techniques to improve sample efficiency in online\ninteractive recommendation, has attracted much research attention as it enjoys\nthe best of both worlds. However, all existing collaborative bandit learning\nsolutions impose a stationary assumption about the environment, i.e., both user\npreferences and the dependency among users are assumed static over time.\nUnfortunately, this assumption hardly holds in practice due to users'\never-changing interests and dependence relations, which inevitably costs a\nrecommender system sub-optimal performance in practice.\n  In this work, we develop a collaborative dynamic bandit solution to handle a\nchanging environment for recommendation. We explicitly model the underlying\nchanges in both user preferences and their dependency relation as a stochastic\nprocess. Individual user's preference is modeled by a mixture of globally\nshared contextual bandit models with a Dirichlet Process prior. Collaboration\namong users is thus achieved via Bayesian inference over the global bandit\nmodels. Model selection and arm selection for each user are done via Thompson\nsampling to balance exploitation and exploration. Our solution is proved to\nmaintain a standard $\\tilde O(\\sqrt{T})$ sublinear regret even in such a\nchallenging environment. And extensive empirical evaluations on both synthetic\nand real-world datasets further confirmed the necessity of modeling a changing\nenvironment and our algorithm's practical advantages against several\nstate-of-the-art online learning solutions.\n", "versions": [{"version": "v1", "created": "Wed, 14 Apr 2021 22:15:58 GMT"}], "update_date": "2021-04-16", "authors_parsed": [["Li", "Chuanhao", ""], ["Wu", "Qingyun", ""], ["Wang", "Hongning", ""]]}, {"id": "2104.07155", "submitter": "Xiongyi Zhang", "authors": "Xiongyi Zhang, Jan-Willem van de Meent, Byron C. Wallace", "title": "Disentangling Representations of Text by Masking Transformers", "comments": "11 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Representations from large pretrained models such as BERT encode a range of\nfeatures into monolithic vectors, affording strong predictive accuracy across a\nmultitude of downstream tasks. In this paper we explore whether it is possible\nto learn disentangled representations by identifying existing subnetworks\nwithin pretrained models that encode distinct, complementary aspect\nrepresentations. Concretely, we learn binary masks over transformer weights or\nhidden units to uncover subsets of features that correlate with a specific\nfactor of variation; this eliminates the need to train a disentangled model\nfrom scratch for a particular task. We evaluate this method with respect to its\nability to disentangle representations of sentiment from genre in movie\nreviews, \"toxicity\" from dialect in Tweets, and syntax from semantics.\n  By combining masking with magnitude pruning we find that we can identify\nsparse subnetworks within BERT that strongly encode particular aspects (e.g.,\ntoxicity) while only weakly encoding others (e.g., race). Moreover, despite\nonly learning masks, we find that disentanglement-via-masking performs as well\nas -- and often better than -- previously proposed methods based on variational\nautoencoders and adversarial training.\n", "versions": [{"version": "v1", "created": "Wed, 14 Apr 2021 22:45:34 GMT"}], "update_date": "2021-04-16", "authors_parsed": [["Zhang", "Xiongyi", ""], ["van de Meent", "Jan-Willem", ""], ["Wallace", "Byron C.", ""]]}, {"id": "2104.07161", "submitter": "Jayaraman J. Thiagarajan", "authors": "Vivek Sivaraman Narayanaswamy, Jayaraman J. Thiagarajan, Andreas\n  Spanias", "title": "On the Design of Deep Priors for Unsupervised Audio Restoration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unsupervised deep learning methods for solving audio restoration problems\nextensively rely on carefully tailored neural architectures that carry strong\ninductive biases for defining priors in the time or spectral domain. In this\ncontext, lot of recent success has been achieved with sophisticated\nconvolutional network constructions that recover audio signals in the spectral\ndomain. However, in practice, audio priors require careful engineering of the\nconvolutional kernels to be effective at solving ill-posed restoration tasks,\nwhile also being easy to train. To this end, in this paper, we propose a new\nU-Net based prior that does not impact either the network complexity or\nconvergence behavior of existing convolutional architectures, yet leads to\nsignificantly improved restoration. In particular, we advocate the use of\ncarefully designed dilation schedules and dense connections in the U-Net\narchitecture to obtain powerful audio priors. Using empirical studies on\nstandard benchmarks and a variety of ill-posed restoration tasks, such as audio\ndenoising, in-painting and source separation, we demonstrate that our proposed\napproach consistently outperforms widely adopted audio prior architectures.\n", "versions": [{"version": "v1", "created": "Wed, 14 Apr 2021 23:16:25 GMT"}], "update_date": "2021-04-16", "authors_parsed": [["Narayanaswamy", "Vivek Sivaraman", ""], ["Thiagarajan", "Jayaraman J.", ""], ["Spanias", "Andreas", ""]]}, {"id": "2104.07163", "submitter": "Mehdi Rezagholizadeh", "authors": "Aref Jafari, Mehdi Rezagholizadeh, Pranav Sharma, Ali Ghodsi", "title": "Annealing Knowledge Distillation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Significant memory and computational requirements of large deep neural\nnetworks restrict their application on edge devices. Knowledge distillation\n(KD) is a prominent model compression technique for deep neural networks in\nwhich the knowledge of a trained large teacher model is transferred to a\nsmaller student model. The success of knowledge distillation is mainly\nattributed to its training objective function, which exploits the soft-target\ninformation (also known as \"dark knowledge\") besides the given regular hard\nlabels in a training set. However, it is shown in the literature that the\nlarger the gap between the teacher and the student networks, the more difficult\nis their training using knowledge distillation. To address this shortcoming, we\npropose an improved knowledge distillation method (called Annealing-KD) by\nfeeding the rich information provided by the teacher's soft-targets\nincrementally and more efficiently. Our Annealing-KD technique is based on a\ngradual transition over annealed soft-targets generated by the teacher at\ndifferent temperatures in an iterative process, and therefore, the student is\ntrained to follow the annealed teacher output in a step-by-step manner. This\npaper includes theoretical and empirical evidence as well as practical\nexperiments to support the effectiveness of our Annealing-KD method. We did a\ncomprehensive set of experiments on different tasks such as image\nclassification (CIFAR-10 and 100) and NLP language inference with BERT-based\nmodels on the GLUE benchmark and consistently got superior results.\n", "versions": [{"version": "v1", "created": "Wed, 14 Apr 2021 23:45:03 GMT"}], "update_date": "2021-04-16", "authors_parsed": [["Jafari", "Aref", ""], ["Rezagholizadeh", "Mehdi", ""], ["Sharma", "Pranav", ""], ["Ghodsi", "Ali", ""]]}, {"id": "2104.07167", "submitter": "Asher Trockman", "authors": "Asher Trockman, J. Zico Kolter", "title": "Orthogonalizing Convolutional Layers with the Cayley Transform", "comments": "To appear in ICLR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work has highlighted several advantages of enforcing orthogonality in\nthe weight layers of deep networks, such as maintaining the stability of\nactivations, preserving gradient norms, and enhancing adversarial robustness by\nenforcing low Lipschitz constants. Although numerous methods exist for\nenforcing the orthogonality of fully-connected layers, those for convolutional\nlayers are more heuristic in nature, often focusing on penalty methods or\nlimited classes of convolutions. In this work, we propose and evaluate an\nalternative approach to directly parameterize convolutional layers that are\nconstrained to be orthogonal. Specifically, we propose to apply the Cayley\ntransform to a skew-symmetric convolution in the Fourier domain, so that the\ninverse convolution needed by the Cayley transform can be computed efficiently.\nWe compare our method to previous Lipschitz-constrained and orthogonal\nconvolutional layers and show that it indeed preserves orthogonality to a high\ndegree even for large convolutions. Applied to the problem of certified\nadversarial robustness, we show that networks incorporating the layer\noutperform existing deterministic methods for certified defense against\n$\\ell_2$-norm-bounded adversaries, while scaling to larger architectures than\npreviously investigated. Code is available at\nhttps://github.com/locuslab/orthogonal-convolutions.\n", "versions": [{"version": "v1", "created": "Wed, 14 Apr 2021 23:54:55 GMT"}], "update_date": "2021-04-19", "authors_parsed": [["Trockman", "Asher", ""], ["Kolter", "J. Zico", ""]]}, {"id": "2104.07168", "submitter": "Taylor Henderson", "authors": "Taylor West Henderson and Yuheng Zhi and Angela Liu and Michael C. Yip", "title": "Data-driven Actuator Selection for Artificial Muscle-Powered Robots", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Even though artificial muscles have gained popularity due to their compliant,\nflexible, and compact properties, there currently does not exist an easy way of\nmaking informed decisions on the appropriate actuation strategy when designing\na muscle-powered robot; thus limiting the transition of such technologies into\nbroader applications. What's more, when a new muscle actuation technology is\ndeveloped, it is difficult to compare it against existing robot muscles. To\naccelerate the development of artificial muscle applications, we propose a data\ndriven approach for robot muscle actuator selection using Support Vector\nMachines (SVM). This first-of-its-kind method gives users gives users insight\ninto which actuators fit their specific needs and actuation performance\ncriteria, making it possible for researchers and engineer with little to no\nprior knowledge of artificial muscles to focus on application design. It also\nprovides a platform to benchmark existing, new, or yet-to-be-discovered\nartificial muscle technologies. We test our method on unseen existing robot\nmuscle designs to prove its usability on real-world applications. We provide an\nopen-access, web-searchable interface for easy access to our models that will\nadditionally allow for continuous contribution of new actuator data from groups\naround the world to enhance and expand these models.\n", "versions": [{"version": "v1", "created": "Thu, 15 Apr 2021 00:05:13 GMT"}], "update_date": "2021-04-16", "authors_parsed": [["Henderson", "Taylor West", ""], ["Zhi", "Yuheng", ""], ["Liu", "Angela", ""], ["Yip", "Michael C.", ""]]}, {"id": "2104.07183", "submitter": "Siamak Layeghy", "authors": "Mohanad Sarhan, Siamak Layeghy, Marius Portmann", "title": "An Explainable Machine Learning-based Network Intrusion Detection System\n  for Enabling Generalisability in Securing IoT Networks", "comments": "11 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Machine Learning (ML)-based network intrusion detection systems bring many\nbenefits for enhancing the security posture of an organisation. Many systems\nhave been designed and developed in the research community, often achieving a\nperfect detection rate when evaluated using certain datasets. However, the high\nnumber of academic research has not translated into practical deployments.\nThere are a number of causes behind the lack of production usage. This paper\ntightens the gap by evaluating the generalisability of a common feature set to\ndifferent network environments and attack types. Therefore, two feature sets\n(NetFlow and CICFlowMeter) have been evaluated across three datasets, i.e.\nCSE-CIC-IDS2018, BoT-IoT, and ToN-IoT. The results showed that the NetFlow\nfeature set enhances the two ML models' detection accuracy in detecting\nintrusions across different datasets. In addition, due to the complexity of the\nlearning models, the SHAP, an explainable AI methodology, has been adopted to\nexplain and interpret the classification decisions of two ML models. The\nShapley values of the features have been analysed across multiple datasets to\ndetermine the influence contributed by each feature towards the final ML\nprediction.\n", "versions": [{"version": "v1", "created": "Thu, 15 Apr 2021 00:44:45 GMT"}], "update_date": "2021-04-16", "authors_parsed": [["Sarhan", "Mohanad", ""], ["Layeghy", "Siamak", ""], ["Portmann", "Marius", ""]]}, {"id": "2104.07191", "submitter": "Xiaodong Wang", "authors": "Fushing Hsieh and Xiaodong Wang", "title": "Coarse- and fine-scale geometric information content of Multiclass\n  Classification and implied Data-driven Intelligence", "comments": "15 pages, 5 figures", "journal-ref": "In Proceedings of the 16th International Conference on Machine\n  Learning and Data Mining, MLDM 2020, July 20-21, 2020, Amsterdam, The\n  Netherlands, pp 171-184", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Under any Multiclass Classification (MCC) setting defined by a collection of\nlabeled point-cloud specified by a feature-set, we extract only stochastic\npartial orderings from all possible triplets of point-cloud without explicitly\nmeasuring the three cloud-to-cloud distances. We demonstrate that such a\ncollective of partial ordering can efficiently compute a label embedding tree\ngeometry on the Label-space. This tree in turn gives rise to a predictive\ngraph, or a network with precisely weighted linkages. Such two multiscale\ngeometries are taken as the coarse scale information content of MCC. They\nindeed jointly shed lights on explainable knowledge on why and how labeling\ncomes about and facilitates error-free prediction with potential multiple\ncandidate labels supported by data. For revealing within-label heterogeneity,\nwe further undergo labeling naturally found clusters within each point-cloud,\nand likewise derive multiscale geometry as its fine-scale information content\ncontained in data. This fine-scale endeavor shows that our computational\nproposal is indeed scalable to a MCC setting having a large label-space.\nOverall the computed multiscale collective of data-driven patterns and\nknowledge will serve as a basis for constructing visible and explainable\nsubject matter intelligence regarding the system of interest.\n", "versions": [{"version": "v1", "created": "Thu, 15 Apr 2021 01:24:17 GMT"}], "update_date": "2021-04-16", "authors_parsed": [["Hsieh", "Fushing", ""], ["Wang", "Xiaodong", ""]]}, {"id": "2104.07195", "submitter": "Wei Li", "authors": "Lei Zhang, Wei Bai, Wei Li, Shiming Xia, Qibin Zheng", "title": "Discover the Hidden Attack Path in Multi-domain Cyberspace Based on\n  Reinforcement Learning", "comments": "12 pages, 2 figures, 3 tables. arXiv admin note: substantial text\n  overlap with arXiv:2007.04614", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In this work, we present a learning-based approach to analysis cyberspace\nsecurity configuration. Unlike prior methods, our approach has the ability to\nlearn from past experience and improve over time. In particular, as we train\nover a greater number of agents as attackers, our method becomes better at\ndiscovering hidden attack paths for previously methods, especially in\nmulti-domain cyberspace. To achieve these results, we pose discovering attack\npaths as a Reinforcement Learning (RL) problem and train an agent to discover\nmulti-domain cyberspace attack paths. To enable our RL policy to discover more\nhidden attack paths and shorter attack paths, we ground representation\nintroduction an multi-domain action select module in RL. Our objective is to\ndiscover more hidden attack paths and shorter attack paths by our proposed\nmethod, to analysis the weakness of cyberspace security configuration. At last,\nwe designed a simulated cyberspace experimental environment to verify our\nproposed method, the experimental results show that our method can discover\nmore hidden multi-domain attack paths and shorter attack paths than existing\nbaseline methods.\n", "versions": [{"version": "v1", "created": "Thu, 15 Apr 2021 01:38:51 GMT"}], "update_date": "2021-04-16", "authors_parsed": [["Zhang", "Lei", ""], ["Bai", "Wei", ""], ["Li", "Wei", ""], ["Xia", "Shiming", ""], ["Zheng", "Qibin", ""]]}, {"id": "2104.07208", "submitter": "Behrouz Azimian", "authors": "B. Azimian, R. Sen Biswas, A. Pal, Lang Tong, Gautam Dasarathy", "title": "State and Topology Estimation for Unobservable Distribution Systems\n  using Deep Neural Networks", "comments": "9 pages. arXiv admin note: substantial text overlap with\n  arXiv:2011.04272", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Time-synchronized state estimation for reconfigurable distribution networks\nis challenging because of limited real-time observability. This paper addresses\nthis challenge by formulating a deep learning (DL)-based approach for topology\nidentification (TI) and unbalanced three-phase distribution system state\nestimation (DSSE). Two deep neural networks (DNNs) are trained to operate in a\nsequential manner for implementing DNN-based TI and DSSE for systems that are\nincompletely observed by synchrophasor measurement devices (SMDs). A\ndata-driven approach for judicious measurement selection to facilitate reliable\nTI and DSSE is also provided. Robustness of the proposed methodology is\ndemonstrated by considering realistic measurement error models for SMDs as well\nas presence of renewable energy. A comparative study of the DNN-based DSSE with\nclassical linear state estimation (LSE) indicates that the DL-based approach\ngives better accuracy with a significantly smaller number of SMDs\n", "versions": [{"version": "v1", "created": "Thu, 15 Apr 2021 02:46:50 GMT"}], "update_date": "2021-04-16", "authors_parsed": [["Azimian", "B.", ""], ["Biswas", "R. Sen", ""], ["Pal", "A.", ""], ["Tong", "Lang", ""], ["Dasarathy", "Gautam", ""]]}, {"id": "2104.07213", "submitter": "Hye-jin Shim", "authors": "Hye-jin Shim, Ju-ho Kim, Jee-weon Jung, Ha-Jin Yu", "title": "Attentive Max Feature Map for Acoustic Scene Classification with Joint\n  Learning considering the Abstraction of Classes", "comments": "5 pages, 2 figure, 5 tables, submitted to INTERSPEECH 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The attention mechanism has been widely adopted in acoustic scene\nclassification. However, we find that during the process of attention\nexclusively emphasizing information, it tends to excessively discard\ninformation although improving the performance. We propose a mechanism referred\nto as the attentive max feature map which combines two effective techniques,\nattention and max feature map, to further elaborate the attention mechanism and\nmitigate the abovementioned phenomenon. Furthermore, we explore various joint\nlearning methods that utilize additional labels originally generated for\nsubtask B (3-classes) on top of existing labels for subtask A (10-classes) of\nthe DCASE2020 challenge. We expect that using two kinds of labels\nsimultaneously would be helpful because the labels of the two subtasks differ\nin their degree of abstraction. Applying two proposed techniques, our proposed\nsystem achieves state-of-the-art performance among single systems on subtask A.\nIn addition, because the model has a complexity comparable to subtask B's\nrequirement, it shows the possibility of developing a system that fulfills the\nrequirements of both subtasks; generalization on multiple devices and\nlow-complexity.\n", "versions": [{"version": "v1", "created": "Thu, 15 Apr 2021 03:14:15 GMT"}], "update_date": "2021-04-16", "authors_parsed": [["Shim", "Hye-jin", ""], ["Kim", "Ju-ho", ""], ["Jung", "Jee-weon", ""], ["Yu", "Ha-Jin", ""]]}, {"id": "2104.07219", "submitter": "Athul Paul Jacob", "authors": "Athul Paul Jacob, Mike Lewis, Jacob Andreas", "title": "Multitasking Inhibits Semantic Drift", "comments": "NAACL 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  When intelligent agents communicate to accomplish shared goals, how do these\ngoals shape the agents' language? We study the dynamics of learning in latent\nlanguage policies (LLPs), in which instructor agents generate natural-language\nsubgoal descriptions and executor agents map these descriptions to low-level\nactions. LLPs can solve challenging long-horizon reinforcement learning\nproblems and provide a rich model for studying task-oriented language use. But\nprevious work has found that LLP training is prone to semantic drift (use of\nmessages in ways inconsistent with their original natural language meanings).\nHere, we demonstrate theoretically and empirically that multitask training is\nan effective counter to this problem: we prove that multitask training\neliminates semantic drift in a well-studied family of signaling games, and show\nthat multitask training of neural LLPs in a complex strategy game reduces drift\nand while improving sample efficiency.\n", "versions": [{"version": "v1", "created": "Thu, 15 Apr 2021 03:42:17 GMT"}], "update_date": "2021-04-16", "authors_parsed": [["Jacob", "Athul Paul", ""], ["Lewis", "Mike", ""], ["Andreas", "Jacob", ""]]}, {"id": "2104.07232", "submitter": "Zeyu Zhou", "authors": "David I. Inouye, Zeyu Zhou, Ziyu Gong, Pradeep Ravikumar", "title": "Iterative Barycenter Flows", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The task of mapping two or more distributions to a shared representation has\nmany applications including fair representations, batch effect mitigation, and\nunsupervised domain adaptation. However, most existing formulations only\nconsider the setting of two distributions, and moreover, do not have an\nidentifiable, unique shared latent representation. We use optimal transport\ntheory to consider a natural multiple distribution extension of the Monge\nassignment problem we call the symmetric Monge map problem and show that it is\nequivalent to the Wasserstein barycenter problem. Yet, the maps to the\nbarycenter are challenging to estimate. Prior methods often ignore\ntransportation cost, rely on adversarial methods, or only work for discrete\ndistributions. Therefore, our goal is to estimate invertible maps between two\nor more distributions and their corresponding barycenter via a simple iterative\nflow method. Our method decouples each iteration into two subproblems: 1)\nestimate simple distributions and 2) estimate the invertible maps to the\nbarycenter via known closed-form OT results. Our empirical results give\nevidence that this iterative algorithm approximates the maps to the barycenter.\n", "versions": [{"version": "v1", "created": "Thu, 15 Apr 2021 04:28:56 GMT"}], "update_date": "2021-04-16", "authors_parsed": [["Inouye", "David I.", ""], ["Zhou", "Zeyu", ""], ["Gong", "Ziyu", ""], ["Ravikumar", "Pradeep", ""]]}, {"id": "2104.07235", "submitter": "Jong Chul Ye", "authors": "Sangjoon Park, Gwanghyun Kim, Yujin Oh, Joon Beom Seo, Sang Min Lee,\n  Jin Hwan Kim, Sungjun Moon, Jae-Kwang Lim, Jong Chul Ye", "title": "Vision Transformer using Low-level Chest X-ray Feature Corpus for\n  COVID-19 Diagnosis and Severity Quantification", "comments": "13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Developing a robust algorithm to diagnose and quantify the severity of\nCOVID-19 using Chest X-ray (CXR) requires a large number of well-curated\nCOVID-19 datasets, which is difficult to collect under the global COVID-19\npandemic. On the other hand, CXR data with other findings are abundant. This\nsituation is ideally suited for the Vision Transformer (ViT) architecture,\nwhere a lot of unlabeled data can be used through structural modeling by the\nself-attention mechanism. However, the use of existing ViT is not optimal,\nsince feature embedding through direct patch flattening or ResNet backbone in\nthe standard ViT is not intended for CXR. To address this problem, here we\npropose a novel Vision Transformer that utilizes low-level CXR feature corpus\nobtained from a backbone network that extracts common CXR findings.\nSpecifically, the backbone network is first trained with large public datasets\nto detect common abnormal findings such as consolidation, opacity, edema, etc.\nThen, the embedded features from the backbone network are used as corpora for a\nTransformer model for the diagnosis and the severity quantification of\nCOVID-19. We evaluate our model on various external test datasets from totally\ndifferent institutions to evaluate the generalization capability. The\nexperimental results confirm that our model can achieve the state-of-the-art\nperformance in both diagnosis and severity quantification tasks with superior\ngeneralization capability, which are sine qua non of widespread deployment.\n", "versions": [{"version": "v1", "created": "Thu, 15 Apr 2021 04:54:48 GMT"}], "update_date": "2021-04-16", "authors_parsed": [["Park", "Sangjoon", ""], ["Kim", "Gwanghyun", ""], ["Oh", "Yujin", ""], ["Seo", "Joon Beom", ""], ["Lee", "Sang Min", ""], ["Kim", "Jin Hwan", ""], ["Moon", "Sungjun", ""], ["Lim", "Jae-Kwang", ""], ["Ye", "Jong Chul", ""]]}, {"id": "2104.07245", "submitter": "Shaily Kabir", "authors": "Shaily Kabir, Christian Wagner and Zack Ellerby", "title": "Towards Handling Uncertainty-at-Source in AI -- A Review and Next Steps\n  for Interval Regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most of statistics and AI draw insights through modelling discord or variance\nbetween sources of information (i.e., inter-source uncertainty). Increasingly,\nhowever, research is focusing upon uncertainty arising at the level of\nindividual measurements (i.e., within- or intra-source), such as for a given\nsensor output or human response. Here, adopting intervals rather than numbers\nas the fundamental data-type provides an efficient, powerful, yet challenging\nway forward -- offering systematic capture of uncertainty-at-source, increasing\ninformational capacity, and ultimately potential for insight. Following recent\nprogress in the capture of interval-valued data, including from human\nparticipants, conducting machine learning directly upon intervals is a crucial\nnext step. This paper focuses on linear regression for interval-valued data as\na recent growth area, providing an essential foundation for broader use of\nintervals in AI. We conduct an in-depth analysis of state-of-the-art methods,\nelucidating their behaviour, advantages, and pitfalls when applied to datasets\nwith different properties. Specific emphasis is given to the challenge of\npreserving mathematical coherence -- i.e., ensuring that models maintain\nfundamental mathematical properties of intervals throughout -- and the paper\nputs forward extensions to an existing approach to guarantee this. Carefully\ndesigned experiments, using both synthetic and real-world data, are conducted\n-- with findings presented alongside novel visualizations for interval-valued\nregression outputs, designed to maximise model interpretability. Finally, the\npaper makes recommendations concerning method suitability for data sets with\nspecific properties and highlights remaining challenges and important next\nsteps for developing AI with the capacity to handle uncertainty-at-source.\n", "versions": [{"version": "v1", "created": "Thu, 15 Apr 2021 05:31:10 GMT"}], "update_date": "2021-04-16", "authors_parsed": [["Kabir", "Shaily", ""], ["Wagner", "Christian", ""], ["Ellerby", "Zack", ""]]}, {"id": "2104.07253", "submitter": "Donghyun Kwak", "authors": "Seunghyun Seo, Donghyun Kwak, Bowon Lee", "title": "Integration of Pre-trained Networks with Continuous Token Interface for\n  End-to-End Spoken Language Understanding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most End-to-End (E2E) SLU networks leverage the pre-trained ASR networks but\nstill lack the capability to understand the semantics of utterances, crucial\nfor the SLU task. To solve this, recently proposed studies use pre-trained NLU\nnetworks. However, it is not trivial to fully utilize both pre-trained\nnetworks; many solutions were proposed, such as Knowledge Distillation,\ncross-modal shared embedding, and network integration with Interface. We\npropose a simple and robust integration method for the E2E SLU network with\nnovel Interface, Continuous Token Interface (CTI), the junctional\nrepresentation of the ASR and NLU networks when both networks are pre-trained\nwith the same vocabulary. Because the only difference is the noise level, we\ndirectly feed the ASR network's output to the NLU network. Thus, we can train\nour SLU network in an E2E manner without additional modules, such as\nGumbel-Softmax. We evaluate our model using SLURP, a challenging SLU dataset\nand achieve state-of-the-art scores on both intent classification and slot\nfilling tasks. We also verify the NLU network, pre-trained with Masked Language\nModel, can utilize a noisy textual representation of CTI. Moreover, we show our\nmodel can be trained with multi-task learning from heterogeneous data even\nafter integration with CTI.\n", "versions": [{"version": "v1", "created": "Thu, 15 Apr 2021 05:59:28 GMT"}], "update_date": "2021-04-16", "authors_parsed": [["Seo", "Seunghyun", ""], ["Kwak", "Donghyun", ""], ["Lee", "Bowon", ""]]}, {"id": "2104.07255", "submitter": "S\\'ebastien Arnold", "authors": "S\\'ebastien M. R. Arnold and Fei Sha", "title": "Embedding Adaptation is Still Needed for Few-Shot Learning", "comments": "In submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Constructing new and more challenging tasksets is a fruitful methodology to\nanalyse and understand few-shot classification methods. Unfortunately, existing\napproaches to building those tasksets are somewhat unsatisfactory: they either\nassume train and test task distributions to be identical -- which leads to\noverly optimistic evaluations -- or take a \"worst-case\" philosophy -- which\ntypically requires additional human labor such as obtaining semantic class\nrelationships. We propose ATG, a principled clustering method to defining train\nand test tasksets without additional human knowledge. ATG models train and test\ntask distributions while requiring them to share a predefined amount of\ninformation. We empirically demonstrate the effectiveness of ATG in generating\ntasksets that are easier, in-between, or harder than existing benchmarks,\nincluding those that rely on semantic information. Finally, we leverage our\ngenerated tasksets to shed a new light on few-shot classification:\ngradient-based methods -- previously believed to underperform -- can outperform\nmetric-based ones when transfer is most challenging.\n", "versions": [{"version": "v1", "created": "Thu, 15 Apr 2021 06:00:04 GMT"}], "update_date": "2021-04-16", "authors_parsed": [["Arnold", "S\u00e9bastien M. R.", ""], ["Sha", "Fei", ""]]}, {"id": "2104.07269", "submitter": "Dongsheng Li", "authors": "Dongsheng Li, Haodong Liu, Chao Chen, Yingying Zhao, Stephen M. Chu,\n  Bo Yang", "title": "NeuSE: A Neural Snapshot Ensemble Method for Collaborative Filtering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  In collaborative filtering (CF) algorithms, the optimal models are usually\nlearned by globally minimizing the empirical risks averaged over all the\nobserved data. However, the global models are often obtained via a performance\ntradeoff among users/items, i.e., not all users/items are perfectly fitted by\nthe global models due to the hard non-convex optimization problems in CF\nalgorithms. Ensemble learning can address this issue by learning multiple\ndiverse models but usually suffer from efficiency issue on large datasets or\ncomplex algorithms. In this paper, we keep the intermediate models obtained\nduring global model learning as the snapshot models, and then adaptively\ncombine the snapshot models for individual user-item pairs using a memory\nnetwork-based method. Empirical studies on three real-world datasets show that\nthe proposed method can extensively and significantly improve the accuracy (up\nto 15.9% relatively) when applied to a variety of existing collaborative\nfiltering methods.\n", "versions": [{"version": "v1", "created": "Thu, 15 Apr 2021 06:43:40 GMT"}], "update_date": "2021-04-16", "authors_parsed": [["Li", "Dongsheng", ""], ["Liu", "Haodong", ""], ["Chen", "Chao", ""], ["Zhao", "Yingying", ""], ["Chu", "Stephen M.", ""], ["Yang", "Bo", ""]]}, {"id": "2104.07279", "submitter": "Mohammad Reza Feizi Derakhshi", "authors": "Mohammad Saber Iraji, Mohammad-Reza Feizi-Derakhshi, Jafar Tanha", "title": "COVID-19 detection using deep convolutional neural networks and\n  binary-differential-algorithm-based feature selection on X-ray images", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The new Coronavirus is spreading rapidly, and it has taken the lives of many\npeople so far. The virus has destructive effects on the human lung, and early\ndetection is very important. Deep Convolution neural networks are such powerful\ntools in classifying images. Therefore, in this paper, a hybrid approach based\non a deep network is presented. Feature vectors were extracted by applying a\ndeep convolution neural network on the images, and useful features were\nselected by the binary differential meta-heuristic algorithm. These optimized\nfeatures were given to the SVM classifier. A database consisting of three\ncategories of images such as COVID-19, pneumonia, and healthy included in 1092\nX-ray samples was considered. The proposed method achieved an accuracy of\n99.43%, a sensitivity of 99.16%, and a specificity of 99.57%. Our results\ndemonstrate that the suggested approach is better than recent studies on\nCOVID-19 detection with X-ray images.\n", "versions": [{"version": "v1", "created": "Thu, 15 Apr 2021 07:12:58 GMT"}, {"version": "v2", "created": "Sun, 30 May 2021 16:17:19 GMT"}, {"version": "v3", "created": "Mon, 5 Jul 2021 09:45:44 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Iraji", "Mohammad Saber", ""], ["Feizi-Derakhshi", "Mohammad-Reza", ""], ["Tanha", "Jafar", ""]]}, {"id": "2104.07283", "submitter": "Cl\\'ement Le Moine Veillon", "authors": "Cl\\'ement Le Moine Veillon, Nicolas Obin and Axel Roebel", "title": "Towards end-to-end F0 voice conversion based on Dual-GAN with\n  convolutional wavelet kernels", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This paper presents a end-to-end framework for the F0 transformation in the\ncontext of expressive voice conversion. A single neural network is proposed, in\nwhich a first module is used to learn F0 representation over different temporal\nscales and a second adversarial module is used to learn the transformation from\none emotion to another. The first module is composed of a convolution layer\nwith wavelet kernels so that the various temporal scales of F0 variations can\nbe efficiently encoded. The single decomposition/transformation network allows\nto learn in a end-to-end manner the F0 decomposition that are optimal with\nrespect to the transformation, directly from the raw F0 signal.\n", "versions": [{"version": "v1", "created": "Thu, 15 Apr 2021 07:42:59 GMT"}], "update_date": "2021-04-16", "authors_parsed": [["Veillon", "Cl\u00e9ment Le Moine", ""], ["Obin", "Nicolas", ""], ["Roebel", "Axel", ""]]}, {"id": "2104.07286", "submitter": "Haoxin Ma", "authors": "Haoxin Ma, Jiangyan Yi, Jianhua Tao, Ye Bai, Zhengkun Tian, Chenglong\n  Wang", "title": "Continual Learning for Fake Audio Detection", "comments": "5 pages, conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fake audio attack becomes a major threat to the speaker verification system.\nAlthough current detection approaches have achieved promising results on\ndataset-specific scenarios, they encounter difficulties on unseen spoofing\ndata. Fine-tuning and retraining from scratch have been applied to incorporate\nnew data. However, fine-tuning leads to performance degradation on previous\ndata. Retraining takes a lot of time and computation resources. Besides,\nprevious data are unavailable due to privacy in some situations. To solve the\nabove problems, this paper proposes detecting fake without forgetting, a\ncontinual-learning-based method, to make the model learn new spoofing attacks\nincrementally. A knowledge distillation loss is introduced to loss function to\npreserve the memory of original model. Supposing the distribution of genuine\nvoice is consistent among different scenarios, an extra embedding similarity\nloss is used as another constraint to further do a positive sample alignment.\nExperiments are conducted on the ASVspoof2019 dataset. The results show that\nour proposed method outperforms fine-tuning by the relative reduction of\naverage equal error rate up to 81.62%.\n", "versions": [{"version": "v1", "created": "Thu, 15 Apr 2021 07:57:05 GMT"}], "update_date": "2021-04-16", "authors_parsed": [["Ma", "Haoxin", ""], ["Yi", "Jiangyan", ""], ["Tao", "Jianhua", ""], ["Bai", "Ye", ""], ["Tian", "Zhengkun", ""], ["Wang", "Chenglong", ""]]}, {"id": "2104.07288", "submitter": "Cl\\'ement Le Moine Veillon", "authors": "Cl\\'ement Le Moine, Nicolas Obin and Axel Roebel", "title": "Speaker Attentive Speech Emotion Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Speech Emotion Recognition (SER) task has known significant improvements over\nthe last years with the advent of Deep Neural Networks (DNNs). However, even\nthe most successful methods are still rather failing when adaptation to\nspecific speakers and scenarios is needed, inevitably leading to poorer\nperformances when compared to humans. In this paper, we present novel work\nbased on the idea of teaching the emotion recognition network about speaker\nidentity. Our system is a combination of two ACRNN classifiers respectively\ndedicated to speaker and emotion recognition. The first informs the latter\nthrough a Self Speaker Attention (SSA) mechanism that is shown to considerably\nhelp to focus on emotional information of the speech signal. Experiments on\nsocial attitudes database Att-HACK and IEMOCAP corpus demonstrate the\neffectiveness of the proposed method and achieve the state-of-the-art\nperformance in terms of unweighted average recall.\n", "versions": [{"version": "v1", "created": "Thu, 15 Apr 2021 07:59:37 GMT"}], "update_date": "2021-04-16", "authors_parsed": [["Moine", "Cl\u00e9ment Le", ""], ["Obin", "Nicolas", ""], ["Roebel", "Axel", ""]]}, {"id": "2104.07294", "submitter": "Christopher Bamford", "authors": "Christopher Bamford, Alvaro Ovalle", "title": "Generalising Discrete Action Spaces with Conditional Action Trees", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  There are relatively few conventions followed in reinforcement learning (RL)\nenvironments to structure the action spaces. As a consequence the application\nof RL algorithms to tasks with large action spaces with multiple components\nrequire additional effort to adjust to different formats. In this paper we\nintroduce {\\em Conditional Action Trees} with two main objectives: (1) as a\nmethod of structuring action spaces in RL to generalise across several action\nspace specifications, and (2) to formalise a process to significantly reduce\nthe action space by decomposing it into multiple sub-spaces, favoring a\nmulti-staged decision making approach. We show several proof-of-concept\nexperiments validating our scheme, ranging from environments with basic\ndiscrete action spaces to those with large combinatorial action spaces commonly\nfound in RTS-style games.\n", "versions": [{"version": "v1", "created": "Thu, 15 Apr 2021 08:10:18 GMT"}], "update_date": "2021-04-16", "authors_parsed": [["Bamford", "Christopher", ""], ["Ovalle", "Alvaro", ""]]}, {"id": "2104.07295", "submitter": "Shuiqiao Yang", "authors": "Shuiqiao Yang, Sunny Verma, Borui Cai, Jiaojiao Jiang, Kun Yu, Fang\n  Chen, Shui Yu", "title": "Variational Co-embedding Learning for Attributed Network Clustering", "comments": "This manuscript is under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent works for attributed network clustering utilize graph convolution to\nobtain node embeddings and simultaneously perform clustering assignments on the\nembedding space. It is effective since graph convolution combines the\nstructural and attributive information for node embedding learning. However, a\nmajor limitation of such works is that the graph convolution only incorporates\nthe attribute information from the local neighborhood of nodes but fails to\nexploit the mutual affinities between nodes and attributes. In this regard, we\npropose a variational co-embedding learning model for attributed network\nclustering (VCLANC). VCLANC is composed of dual variational auto-encoders to\nsimultaneously embed nodes and attributes. Relying on this, the mutual affinity\ninformation between nodes and attributes could be reconstructed from the\nembedding space and served as extra self-supervised knowledge for\nrepresentation learning. At the same time, trainable Gaussian mixture model is\nused as priors to infer the node clustering assignments. To strengthen the\nperformance of the inferred clusters, we use a mutual distance loss on the\ncenters of the Gaussian priors and a clustering assignment hardening loss on\nthe node embeddings. Experimental results on four real-world attributed network\ndatasets demonstrate the effectiveness of the proposed VCLANC for attributed\nnetwork clustering.\n", "versions": [{"version": "v1", "created": "Thu, 15 Apr 2021 08:11:47 GMT"}], "update_date": "2021-04-16", "authors_parsed": [["Yang", "Shuiqiao", ""], ["Verma", "Sunny", ""], ["Cai", "Borui", ""], ["Jiang", "Jiaojiao", ""], ["Yu", "Kun", ""], ["Chen", "Fang", ""], ["Yu", "Shui", ""]]}, {"id": "2104.07324", "submitter": "Shayan Hashemi", "authors": "Shayan Hashemi, Mika M\\\"antyl\\\"a", "title": "OneLog: Towards End-to-End Training in Software Log Anomaly Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In recent years, with the growth of online services and IoT devices, software\nlog anomaly detection has become a significant concern for both academia and\nindustry. However, at the time of writing this paper, almost all contributions\nto the log anomaly detection task, follow the same traditional architecture\nbased on parsing, vectorizing, and classifying. This paper proposes OneLog, a\nnew approach that uses a large deep model based on instead of multiple small\ncomponents. OneLog utilizes a character-based convolutional neural network\n(CNN) originating from traditional NLP tasks. This allows the model to take\nadvantage of multiple datasets at once and take advantage of numbers and\npunctuations, which were removed in previous architectures. We evaluate OneLog\nusing four open data sets Hadoop Distributed File System (HDFS), BlueGene/L\n(BGL), Hadoop, and OpenStack. We evaluate our model with single and\nmulti-project datasets. Additionally, we evaluate robustness with synthetically\nevolved datasets and ahead-of-time anomaly detection test that indicates\ncapabilities to predict anomalies before occurring. To the best of our\nknowledge, our multi-project model outperforms state-of-the-art methods in\nHDFS, Hadoop, and BGL datasets, respectively setting getting F1 scores of\n99.99, 99.99, and 99.98. However, OneLog's performance on the Openstack is\nunsatisfying with F1 score of only 21.18. Furthermore, Onelogs performance\nsuffers very little from noise showing F1 scores of 99.95, 99.92, and 99.98 in\nHDFS, Hadoop, and BGL.\n", "versions": [{"version": "v1", "created": "Thu, 15 Apr 2021 09:23:32 GMT"}], "update_date": "2021-04-16", "authors_parsed": [["Hashemi", "Shayan", ""], ["M\u00e4ntyl\u00e4", "Mika", ""]]}, {"id": "2104.07329", "submitter": "Cheng-Wei Huang", "authors": "Cheng-Wei Huang, Tim-Wei Chen, and Juinn-Dar Huang", "title": "All-You-Can-Fit 8-Bit Flexible Floating-Point Format for Accurate and\n  Memory-Efficient Inference of Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern deep neural network (DNN) models generally require a huge amount of\nweight and activation values to achieve good inference outcomes. Those data\ninevitably demand a massive off-chip memory capacity/bandwidth, and the\nsituation gets even worse if they are represented in high-precision\nfloating-point formats. Effort has been made for representing those data in\ndifferent 8-bit floating-point formats, nevertheless, a notable accuracy loss\nis still unavoidable. In this paper we introduce an extremely flexible 8-bit\nfloating-point (FFP8) format whose defining factors - the bit width of\nexponent/fraction field, the exponent bias, and even the presence of the sign\nbit - are all configurable. We also present a methodology to properly determine\nthose factors so that the accuracy of model inference can be maximized. The\nfoundation of this methodology is based on a key observation - both the maximum\nmagnitude and the value distribution are quite dissimilar between weights and\nactivations in most DNN models. Experimental results demonstrate that the\nproposed FFP8 format achieves an extremely low accuracy loss of $0.1\\%\\sim\n0.3\\%$ for several representative image classification models even without the\nneed of model retraining. Besides, it is easy to turn a classical\nfloating-point processing unit into an FFP8-compliant one, and the extra\nhardware cost is minor.\n", "versions": [{"version": "v1", "created": "Thu, 15 Apr 2021 09:37:23 GMT"}, {"version": "v2", "created": "Thu, 22 Apr 2021 05:32:02 GMT"}, {"version": "v3", "created": "Sat, 24 Apr 2021 07:14:41 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Huang", "Cheng-Wei", ""], ["Chen", "Tim-Wei", ""], ["Huang", "Juinn-Dar", ""]]}, {"id": "2104.07353", "submitter": "Mohammad Sadeq Dousti", "authors": "Ernst Althaus, Mohammad Sadeq Dousti and Stefan Kramer", "title": "Fast Private Parameter Learning and Evaluation for Sum-Product Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A sum-product network (SPN) is a graphical model that allows several types of\ninferences to be drawn efficiently. There are two types of learning for SPNs:\nLearning the architecture of the model, and learning the parameters. In this\npaper, we tackle the second problem: We show how to learn the weights for the\nsum nodes, assuming the architecture is fixed, and the data is horizontally\npartitioned between multiple parties. The computations will preserve the\nprivacy of each participant. Furthermore, we will use secret sharing instead of\n(homomorphic) encryption, which allows fast computations and requires little\ncomputational resources. To this end, we use a novel integer division to\ncompute approximate real divisions. We also show how simple and private\nevaluations can be performed using the learned SPN.\n", "versions": [{"version": "v1", "created": "Thu, 15 Apr 2021 10:21:51 GMT"}], "update_date": "2021-04-16", "authors_parsed": [["Althaus", "Ernst", ""], ["Dousti", "Mohammad Sadeq", ""], ["Kramer", "Stefan", ""]]}, {"id": "2104.07361", "submitter": "Rahul Madhavan", "authors": "Rahul Madhavan, Gugan Thoppe, Hemanta Makwana", "title": "Scale Invariant Solutions for Overdetermined Linear Systems with\n  Applications to Reinforcement Learning", "comments": "53 pages, 12 figures (9 pages main body with 5 figures)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Overdetermined linear systems are common in reinforcement learning, e.g., in\nQ and value function estimation with function approximation. The standard\nleast-squares criterion, however, leads to a solution that is unduly influenced\nby rows with large norms. This is a serious issue, especially when the matrices\nin these systems are beyond user control. To address this, we propose a\nscale-invariant criterion that we then use to develop two novel algorithms for\nvalue function estimation: Normalized Monte Carlo and Normalized TD(0).\nSeparately, we also introduce a novel adaptive stepsize that may be useful\nbeyond this work as well. We use simulations and theoretical guarantees to\ndemonstrate the efficacy of our ideas.\n", "versions": [{"version": "v1", "created": "Thu, 15 Apr 2021 10:37:38 GMT"}], "update_date": "2021-04-16", "authors_parsed": [["Madhavan", "Rahul", ""], ["Thoppe", "Gugan", ""], ["Makwana", "Hemanta", ""]]}, {"id": "2104.07365", "submitter": "Erick Lavoie", "authors": "Aur\\'elien Bellet, Anne-Marie Kermarrec, Erick Lavoie", "title": "D-Cliques: Compensating NonIIDness in Decentralized Federated Learning\n  with Topology", "comments": "22 pages, 11 figures. Revisions in v2 and v3: Corrected typos, minor\n  mistakes in scaling analysis that did not affect the overall argument, and\n  clarified convergence plots to read better in black&white", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The convergence speed of machine learning models trained with Federated\nLearning is significantly affected by non-independent and identically\ndistributed (non-IID) data partitions, even more so in a fully decentralized\nsetting without a central server. In this paper, we show that the impact of\nlocal class bias, an important type of data non-IIDness, can be significantly\nreduced by carefully designing the underlying communication topology. We\npresent D-Cliques, a novel topology that reduces gradient bias by grouping\nnodes in interconnected cliques such that the local joint distribution in a\nclique is representative of the global class distribution. We also show how to\nadapt the updates of decentralized SGD to obtain unbiased gradients and\nimplement an effective momentum with D-Cliques. Our empirical evaluation on\nMNIST and CIFAR10 demonstrates that our approach provides similar convergence\nspeed as a fully-connected topology with a significant reduction in the number\nof edges and messages. In a 1000-node topology, D-Cliques requires 98% less\nedges and 96% less total messages, with further possible gains using a\nsmall-world topology across cliques.\n", "versions": [{"version": "v1", "created": "Thu, 15 Apr 2021 10:47:27 GMT"}, {"version": "v2", "created": "Mon, 7 Jun 2021 10:05:56 GMT"}, {"version": "v3", "created": "Mon, 26 Jul 2021 13:58:09 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Bellet", "Aur\u00e9lien", ""], ["Kermarrec", "Anne-Marie", ""], ["Lavoie", "Erick", ""]]}, {"id": "2104.07377", "submitter": "Jianlong Zhou", "authors": "Jianlong Zhou, Weidong Huang, and Fang Chen", "title": "Facilitating Machine Learning Model Comparison and Explanation Through A\n  Radial Visualisation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.HC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Building an effective Machine Learning (ML) model for a data set is a\ndifficult task involving various steps. One of the most important steps is to\ncompare generated substantial amounts of ML models to find the optimal one for\nthe deployment. It is challenging to compare such models with dynamic number of\nfeatures. Comparison is more than just finding differences of ML model\nperformance, users are also interested in the relations between features and\nmodel performance such as feature importance for ML explanations. This paper\nproposes RadialNet Chart, a novel visualisation approach to compare ML models\ntrained with a different number of features of a given data set while revealing\nimplicit dependent relations. In RadialNet Chart, ML models and features are\nrepresented by lines and arcs respectively. These lines are generated\neffectively using a recursive function. The dependence of ML models with\ndynamic number of features is encoded into the structure of visualisation,\nwhere ML models and their dependent features are directly revealed from related\nline connections. ML model performance information is encoded with colour and\nline width in RadialNet Chart. Together with the structure of visualisation,\nfeature importance can be directly discerned in RadialNet Chart for ML\nexplanations.\n", "versions": [{"version": "v1", "created": "Thu, 15 Apr 2021 11:13:48 GMT"}], "update_date": "2021-04-16", "authors_parsed": [["Zhou", "Jianlong", ""], ["Huang", "Weidong", ""], ["Chen", "Fang", ""]]}, {"id": "2104.07388", "submitter": "Salah Zaiem", "authors": "Salah Zaiem, Titouan Parcollet, Slim Essid", "title": "Conditional independence for pretext task selection in Self-supervised\n  speech representation learning", "comments": "5 pages, Accepted for presentation at Interspeech2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD eess.SP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Through solving pretext tasks, self-supervised learning (SSL) leverages\nunlabeled data to extract useful latent representations replacing traditional\ninput features in the downstream task. A common pretext task consists in\npretraining a SSL model on pseudo-labels derived from the original signal. This\ntechnique is particularly relevant for speech data where various meaningful\nsignal processing features may serve as pseudo-labels. However, the process of\nselecting pseudo-labels, for speech or other types of data, remains mostly\nunexplored and currently relies on observing the results on the final\ndownstream task. Nevertheless, this methodology is not sustainable at scale due\nto substantial computational (hence carbon) costs. Thus, this paper introduces\na practical and theoretical framework to select relevant pseudo-labels with\nrespect to a given downstream task. More precisely, we propose a functional\nestimator of the pseudo-label utility grounded in the conditional independence\ntheory, which does not require any training. The experiments conducted on\nspeaker recognition and automatic speech recognition validate our estimator,\nshowing a significant correlation between the performance observed on the\ndownstream task and the utility estimates obtained with our approach,\nfacilitating the prospection of relevant pseudo-labels for self-supervised\nspeech representation learning.\n", "versions": [{"version": "v1", "created": "Thu, 15 Apr 2021 11:32:59 GMT"}, {"version": "v2", "created": "Thu, 1 Jul 2021 14:45:04 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Zaiem", "Salah", ""], ["Parcollet", "Titouan", ""], ["Essid", "Slim", ""]]}, {"id": "2104.07389", "submitter": "Pooja Prajod", "authors": "Pooja Prajod, Dominik Schiller, Tobias Huber, Elisabeth Andr\\'e", "title": "Do Deep Neural Networks Forget Facial Action Units? -- Exploring the\n  Effects of Transfer Learning in Health Related Facial Expression Recognition", "comments": "The 5th International Workshop on Health Intelligence (W3PHIAI-21)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In this paper, we present a process to investigate the effects of transfer\nlearning for automatic facial expression recognition from emotions to pain. To\nthis end, we first train a VGG16 convolutional neural network to automatically\ndiscern between eight categorical emotions. We then fine-tune successively\nlarger parts of this network to learn suitable representations for the task of\nautomatic pain recognition. Subsequently, we apply those fine-tuned\nrepresentations again to the original task of emotion recognition to further\ninvestigate the differences in performance between the models. In the second\nstep, we use Layer-wise Relevance Propagation to analyze predictions of the\nmodel that have been predicted correctly previously but are now wrongly\nclassified. Based on this analysis, we rely on the visual inspection of a human\nobserver to generate hypotheses about what has been forgotten by the model.\nFinally, we test those hypotheses quantitatively utilizing concept embedding\nanalysis methods. Our results show that the network, which was fully fine-tuned\nfor pain recognition, indeed payed less attention to two action units that are\nrelevant for expression recognition but not for pain recognition.\n", "versions": [{"version": "v1", "created": "Thu, 15 Apr 2021 11:37:19 GMT"}], "update_date": "2021-04-16", "authors_parsed": [["Prajod", "Pooja", ""], ["Schiller", "Dominik", ""], ["Huber", "Tobias", ""], ["Andr\u00e9", "Elisabeth", ""]]}, {"id": "2104.07391", "submitter": "Daniel Weber", "authors": "Daniel Weber, Clemens G\\\"uhmann, Thomas Seel", "title": "RIANN -- A Robust Neural Network Outperforms Attitude Estimation Filters", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inertial-sensor-based attitude estimation is a crucial technology in various\napplications, from human motion tracking to autonomous aerial and ground\nvehicles. Application scenarios differ in characteristics of the performed\nmotion, presence of disturbances, and environmental conditions. Since\nstate-of-the-art attitude estimators do not generalize well over these\ncharacteristics, their parameters must be tuned for the individual motion\ncharacteristics and circumstances. We propose RIANN, a real-time-capable neural\nnetwork for robust IMU-based attitude estimation, which generalizes well across\ndifferent motion dynamics, environments, and sampling rates, without the need\nfor application-specific adaptations. We exploit two publicly available\ndatasets for the method development and the training, and we add four\ncompletely different datasets for evaluation of the trained neural network in\nthree different test scenarios with varying practical relevance. Results show\nthat RIANN performs at least as well as state-of-the-art attitude estimation\nfilters and outperforms them in several cases, even if the filter is tuned on\nthe very same test dataset itself while RIANN has never seen data from that\ndataset, from the specific application, the same sensor hardware, or the same\nsampling frequency before. RIANN is expected to enable plug-and-play solutions\nin numerous applications, especially when accuracy is crucial but no\nground-truth data is available for tuning or when motion and disturbance\ncharacteristics are uncertain. We made RIANN publicly available.\n", "versions": [{"version": "v1", "created": "Thu, 15 Apr 2021 11:40:25 GMT"}, {"version": "v2", "created": "Wed, 5 May 2021 12:43:55 GMT"}], "update_date": "2021-05-06", "authors_parsed": [["Weber", "Daniel", ""], ["G\u00fchmann", "Clemens", ""], ["Seel", "Thomas", ""]]}, {"id": "2104.07396", "submitter": "Dai Quoc Nguyen", "authors": "Dai Quoc Nguyen and Vinh Tong and Dinh Phung and Dat Quoc Nguyen", "title": "Node Co-occurrence based Dual Quaternion Graph Neural Networks for\n  Knowledge Graph Link Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a novel embedding model, named NoGE, which aims to integrate\nco-occurrence among entities and relations into graph neural networks to\nimprove knowledge graph completion (i.e., link prediction). Given a knowledge\ngraph, NoGE constructs a single graph considering entities and relations as\nindividual nodes. NoGE then computes weights for edges among nodes based on the\nco-occurrence of entities and relations. Next, NoGE proposes Dual Quaternion\nGraph Neural Networks (Dual-QGNN) and utilizes Dual-QGNN to update vector\nrepresentations for entity and relation nodes. NoGE then adopts a score\nfunction to produce the triple scores. Comprehensive experimental results show\nthat NoGE obtains state-of-the-art results on three new and difficult benchmark\ndatasets CoDEx for knowledge graph completion.\n", "versions": [{"version": "v1", "created": "Thu, 15 Apr 2021 11:51:52 GMT"}, {"version": "v2", "created": "Mon, 12 Jul 2021 05:41:26 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Nguyen", "Dai Quoc", ""], ["Tong", "Vinh", ""], ["Phung", "Dinh", ""], ["Nguyen", "Dat Quoc", ""]]}, {"id": "2104.07409", "submitter": "Manoj Basnet", "authors": "Manoj Basnet, Subash Poudyal, Mohd. Hasan Ali, Dipankar Dasgupta", "title": "Ransomware Detection Using Deep Learning in the SCADA System of Electric\n  Vehicle Charging Station", "comments": "conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.LG cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Supervisory control and data acquisition (SCADA) systems have been\ncontinuously leveraging the evolution of network architecture, communication\nprotocols, next-generation communication techniques (5G, 6G, Wi-Fi 6), and the\ninternet of things (IoT). However, SCADA system has become the most profitable\nand alluring target for ransomware attackers. This paper proposes the deep\nlearning-based novel ransomware detection framework in the SCADA controlled\nelectric vehicle charging station (EVCS) with the performance analysis of three\ndeep learning algorithms, namely deep neural network (DNN), 1D convolution\nneural network (CNN), and long short-term memory (LSTM) recurrent neural\nnetwork. All three-deep learning-based simulated frameworks achieve around 97%\naverage accuracy (ACC), more than 98% of the average area under the curve\n(AUC), and an average F1-score under 10-fold stratified cross-validation with\nan average false alarm rate (FAR) less than 1.88%. Ransomware driven\ndistributed denial of service (DDoS) attack tends to shift the SOC profile by\nexceeding the SOC control thresholds. The severity has been found to increase\nas the attack progress and penetration increases. Also, ransomware driven false\ndata injection (FDI) attack has the potential to damage the entire BES or\nphysical system by manipulating the SOC control thresholds. It's a design\nchoice and optimization issue that a deep learning algorithm can deploy based\non the tradeoffs between performance metrics.\n", "versions": [{"version": "v1", "created": "Thu, 15 Apr 2021 12:13:43 GMT"}], "update_date": "2021-04-16", "authors_parsed": [["Basnet", "Manoj", ""], ["Poudyal", "Subash", ""], ["Ali", "Mohd. Hasan", ""], ["Dasgupta", "Dipankar", ""]]}, {"id": "2104.07411", "submitter": "Dieter Brughmans", "authors": "Dieter Brughmans and David Martens", "title": "NICE: An Algorithm for Nearest Instance Counterfactual Explanations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we suggest NICE: a new algorithm to generate counterfactual\nexplanations for heterogeneous tabular data. The design of our algorithm\nspecifically takes into account algorithmic requirements that often emerge in\nreal-life deployments: the ability to provide an explanation for all\npredictions, being efficient in run-time, and being able to handle any\nclassification model (also non-differentiable ones). More specifically, our\napproach exploits information from a nearest instance tospeed up the search\nprocess. We propose four versions of NICE, where three of them optimize the\nexplanations for one of the following properties: sparsity, proximity or\nplausibility. An extensive empirical comparison on 10 datasets shows that our\nalgorithm performs better on all properties than the current state-of-the-art.\nThese analyses show a trade-off between on the one hand plausiblity and on the\nother hand proximity or sparsity, with our different optimization methods\noffering the choice to select the preferred trade-off. An open-source\nimplementation of NICE can be found at https://github.com/ADMAntwerp/NICE.\n", "versions": [{"version": "v1", "created": "Thu, 15 Apr 2021 12:21:01 GMT"}], "update_date": "2021-04-16", "authors_parsed": [["Brughmans", "Dieter", ""], ["Martens", "David", ""]]}, {"id": "2104.07423", "submitter": "Preslav Nakov", "authors": "Shaden Shaar, Firoj Alam, Giovanni Da San Martino, Preslav Nakov", "title": "The Role of Context in Detecting Previously Fact-Checked Claims", "comments": "detecting previously fact-checked claims, fact-checking,\n  disinformation, fake news, social media, political debates", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent years have seen the proliferation of disinformation and misinformation\nonline, thanks to the freedom of expression on the Internet and to the rise of\nsocial media. Two solutions were proposed to address the problem: (i) manual\nfact-checking, which is accurate and credible, but slow and non-scalable, and\n(ii) automatic fact-checking, which is fast and scalable, but lacks\nexplainability and credibility. With the accumulation of enough manually\nfact-checked claims, a middle-ground approach has emerged: checking whether a\ngiven claim has previously been fact-checked. This can be made automatically,\nand thus fast, while also offering credibility and explainability, thanks to\nthe human fact-checking and explanations in the associated fact-checking\narticle. This is a relatively new and understudied research direction, and here\nwe focus on claims made in a political debate, where context really matters.\nThus, we study the impact of modeling the context of the claim: both on the\nsource side, i.e., in the debate, as well as on the target side, i.e., in the\nfact-checking explanation document. We do this by modeling the local context,\nthe global context, as well as by means of co-reference resolution, and\nreasoning over the target text using Transformer-XH. The experimental results\nshow that each of these represents a valuable information source, but that\nmodeling the source-side context is more important, and can yield 10+ points of\nabsolute improvement.\n", "versions": [{"version": "v1", "created": "Thu, 15 Apr 2021 12:39:37 GMT"}], "update_date": "2021-04-16", "authors_parsed": [["Shaar", "Shaden", ""], ["Alam", "Firoj", ""], ["Martino", "Giovanni Da San", ""], ["Nakov", "Preslav", ""]]}, {"id": "2104.07427", "submitter": "Onur Karaman", "authors": "N. Korucuk, C. Polat, E. S. Gunduz, O. Karaman, V. Tosun, M. Onac, N.\n  Yildirim, Y. Cete, K. Polat", "title": "Estimation of atrial fibrillation from lead-I ECGs: Comparison with\n  cardiologists and machine learning model (CurAlive), a clinical validation\n  study", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Electrocardiogram recognition of cardiac arrhythmias is critical for cardiac\nabnormality diagnosis. Because of their strong prediction characteristics,\nartificial neural networks are the preferred method in medical diagnosis\nsystems. This study presents a method to detect atrial fibrillation with lead-I\nECGs using artificial intelligence. The aim of the study is to compare the\naccuracy of the diagnoses estimated by cardiologists and artificial\nintelligence over lead-I ECGs using 12-lead ECGs as references. To evaluate the\nperformance of the proposed model, dataset were collected from China\nPhysiological Signal Challenge 2018. In the study, diagnoses were examined in\nthree groups as normal sinus rhythm, atrial fibrillation and OTHER. All rhythm\nand beat types except NSR and AFIB were labeled as OTHER super-class. OTHER\ncontains First-degree atrioventricular blocks, Conduction disturbances, Left\nbundle branch block, Right bundle branch block, Premature atrial contraction,\nPremature ventricular contraction, ST-segment depression and ST-segment\nelevated type ECGs. CurAlive A.I. model which is using DenseNet as a CNN\narchitecture and continuous wavelet transform as feature extraction method,\nshowed a great performance on classifying ECGs from only lead-I compared to\ncardiologists. The AI model reached the weighted average precision, recall,\nF1-score and total accuracy 94.1%, 93.6%, 93.7% and 93.6% respectively, and the\naverage of each of the three cardiologists has reached weighted average\nprecision, recall, F1-score and total accuracy 82.2%, 54.6%, 57.5% and 54.6%\nrespectively. This study showed that the proposed CNN model CurAlive, can be\nused to accurately diagnose AFIB, NSR, and OTHER rhythm using lead-I ECGs to\naccelerate the early detection of AFIB as a cardiologist assistant. It is also\nable to identify patients into different risk groups as part of remote patient\nmonitoring systems.\n", "versions": [{"version": "v1", "created": "Thu, 15 Apr 2021 12:50:16 GMT"}], "update_date": "2021-04-16", "authors_parsed": [["Korucuk", "N.", ""], ["Polat", "C.", ""], ["Gunduz", "E. S.", ""], ["Karaman", "O.", ""], ["Tosun", "V.", ""], ["Onac", "M.", ""], ["Yildirim", "N.", ""], ["Cete", "Y.", ""], ["Polat", "K.", ""]]}, {"id": "2104.07440", "submitter": "Fabrice Daniel", "authors": "Fabrice Daniel", "title": "Bayesian and Dempster-Shafer models for combining multiple sources of\n  evidence in a fraud detection system", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Combining evidence from different sources can be achieved with Bayesian or\nDempster-Shafer methods. The first requires an estimate of the priors and\nlikelihoods while the second only needs an estimate of the posterior\nprobabilities and enables reasoning with uncertain information due to\nimprecision of the sources and with the degree of conflict between them. This\npaper describes the two methods and how they can be applied to the estimation\nof a global score in the context of fraud detection.\n", "versions": [{"version": "v1", "created": "Thu, 15 Apr 2021 13:19:19 GMT"}], "update_date": "2021-04-16", "authors_parsed": [["Daniel", "Fabrice", ""]]}, {"id": "2104.07446", "submitter": "Matthias De Lange", "authors": "Eli Verwimp, Matthias De Lange, Tinne Tuytelaars", "title": "Rehearsal revealed: The limits and merits of revisiting samples in\n  continual learning", "comments": "Preprint, code publicly available", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning from non-stationary data streams and overcoming catastrophic\nforgetting still poses a serious challenge for machine learning research.\nRather than aiming to improve state-of-the-art, in this work we provide insight\ninto the limits and merits of rehearsal, one of continual learning's most\nestablished methods. We hypothesize that models trained sequentially with\nrehearsal tend to stay in the same low-loss region after a task has finished,\nbut are at risk of overfitting on its sample memory, hence harming\ngeneralization. We provide both conceptual and strong empirical evidence on\nthree benchmarks for both behaviors, bringing novel insights into the dynamics\nof rehearsal and continual learning in general. Finally, we interpret important\ncontinual learning works in the light of our findings, allowing for a deeper\nunderstanding of their successes.\n", "versions": [{"version": "v1", "created": "Thu, 15 Apr 2021 13:28:14 GMT"}], "update_date": "2021-04-16", "authors_parsed": [["Verwimp", "Eli", ""], ["De Lange", "Matthias", ""], ["Tuytelaars", "Tinne", ""]]}, {"id": "2104.07448", "submitter": "Paul Baggenstoss", "authors": "Paul M Baggenstoss", "title": "Maximum Entropy Auto-Encoding", "comments": "5 pages, submission to EUSIPCO 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  In this paper, it is shown that an auto-encoder using optimal reconstruction\nsignificantly outperforms a conventional auto-encoder. Optimal reconstruction\nuses the conditional mean of the input given the features, under a maximum\nentropy prior distribution. The optimal reconstruction network, which is called\ndeterministic projected belied network (D-PBN), resembles a standard\nreconstruction network, but with special non-linearities that mist be\niteratively solved. The method, which can be seen as a generalization of\nmaximum entropy image reconstruction, extends to multiple layers. In\nexperiments, mean square reconstruction error reduced by up to a factor of two.\nThe performance improvement diminishes for deeper networks, or for input data\nwith unconstrained values (Gaussian assumption).\n", "versions": [{"version": "v1", "created": "Tue, 13 Apr 2021 09:21:19 GMT"}], "update_date": "2021-04-16", "authors_parsed": [["Baggenstoss", "Paul M", ""]]}, {"id": "2104.07451", "submitter": "Zhenghang Xu", "authors": "Yihan Pan, Zhenghang Xu, Jin Guang, Jingjing Sun, Chengwenjian Wang,\n  Xuanming Zhang, Xinyun Chen, J.G. Dai, Yichuan Ding, Pengyi Shi, Hongxin Pan,\n  Kai Yang, and Song Wu", "title": "A High-fidelity, Machine-learning Enhanced Queueing Network Simulation\n  Model for Hospital Ultrasound Operations", "comments": "21 pages, 15 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We collaborate with a large teaching hospital in Shenzhen, China and build a\nhigh-fidelity simulation model for its ultrasound center to predict key\nperformance metrics, including the distributions of queue length, waiting time\nand sojourn time, with high accuracy. The key challenge to build an accurate\nsimulation model is to understanding the complicated patient routing at the\nultrasound center. To address the issue, we propose a novel two-level routing\ncomponent to the queueing network model. We apply machine learning tools to\ncalibrate the key components of the queueing model from data with enhanced\naccuracy.\n", "versions": [{"version": "v1", "created": "Mon, 12 Apr 2021 08:22:58 GMT"}], "update_date": "2021-04-16", "authors_parsed": [["Pan", "Yihan", ""], ["Xu", "Zhenghang", ""], ["Guang", "Jin", ""], ["Sun", "Jingjing", ""], ["Wang", "Chengwenjian", ""], ["Zhang", "Xuanming", ""], ["Chen", "Xinyun", ""], ["Dai", "J. G.", ""], ["Ding", "Yichuan", ""], ["Shi", "Pengyi", ""], ["Pan", "Hongxin", ""], ["Yang", "Kai", ""], ["Wu", "Song", ""]]}, {"id": "2104.07454", "submitter": "Rohitash Chandra", "authors": "Animesh Renanse, Rohitash Chandra, Alok Sharma", "title": "Memory Capacity of Neural Turing Machines with Matrix Representation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  It is well known that recurrent neural networks (RNNs) faced limitations in\nlearning long-term dependencies that have been addressed by memory structures\nin long short-term memory (LSTM) networks. Matrix neural networks feature\nmatrix representation which inherently preserves the spatial structure of data\nand has the potential to provide better memory structures when compared to\ncanonical neural networks that use vector representation. Neural Turing\nmachines (NTMs) are novel RNNs that implement notion of programmable computers\nwith neural network controllers to feature algorithms that have copying,\nsorting, and associative recall tasks. In this paper, we study the augmentation\nof memory capacity with a matrix representation of RNNs and NTMs (MatNTMs). We\ninvestigate if matrix representation has a better memory capacity than the\nvector representations in conventional neural networks. We use a probabilistic\nmodel of the memory capacity using Fisher information and investigate how the\nmemory capacity for matrix representation networks are limited under various\nconstraints, and in general, without any constraints. In the case of memory\ncapacity without any constraints, we found that the upper bound on memory\ncapacity to be $N^2$ for an $N\\times N$ state matrix. The results from our\nexperiments using synthetic algorithmic tasks show that MatNTMs have a better\nlearning capacity when compared to its counterparts.\n", "versions": [{"version": "v1", "created": "Sun, 11 Apr 2021 23:43:28 GMT"}], "update_date": "2021-04-16", "authors_parsed": [["Renanse", "Animesh", ""], ["Chandra", "Rohitash", ""], ["Sharma", "Alok", ""]]}, {"id": "2104.07461", "submitter": "Min-Hung Chen", "authors": "Min-Hung Chen, Baopu Li, Yingze Bao, Ghassan AlRegib", "title": "Action Segmentation with Mixed Temporal Domain Adaptation", "comments": "Winter Conference on Applications of Computer Vision (WACV) 2020.\n  Website: https://minhungchen.netlify.app/publication/mtda", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The main progress for action segmentation comes from densely-annotated data\nfor fully-supervised learning. Since manual annotation for frame-level actions\nis time-consuming and challenging, we propose to exploit auxiliary unlabeled\nvideos, which are much easier to obtain, by shaping this problem as a domain\nadaptation (DA) problem. Although various DA techniques have been proposed in\nrecent years, most of them have been developed only for the spatial direction.\nTherefore, we propose Mixed Temporal Domain Adaptation (MTDA) to jointly align\nframe- and video-level embedded feature spaces across domains, and further\nintegrate with the domain attention mechanism to focus on aligning the\nframe-level features with higher domain discrepancy, leading to more effective\ndomain adaptation. Finally, we evaluate our proposed methods on three\nchallenging datasets (GTEA, 50Salads, and Breakfast), and validate that MTDA\noutperforms the current state-of-the-art methods on all three datasets by large\nmargins (e.g. 6.4% gain on F1@50 and 6.8% gain on the edit score for GTEA).\n", "versions": [{"version": "v1", "created": "Thu, 15 Apr 2021 13:48:14 GMT"}, {"version": "v2", "created": "Fri, 16 Apr 2021 00:46:15 GMT"}], "update_date": "2021-04-19", "authors_parsed": [["Chen", "Min-Hung", ""], ["Li", "Baopu", ""], ["Bao", "Yingze", ""], ["AlRegib", "Ghassan", ""]]}, {"id": "2104.07467", "submitter": "Momchil Hardalov", "authors": "Momchil Hardalov, Arnav Arora, Preslav Nakov, Isabelle Augenstein", "title": "Cross-Domain Label-Adaptive Stance Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Stance detection concerns the classification of a writer's viewpoint towards\na target. There are different task variants, e.g., stance of a tweet vs. a full\narticle, or stance with respect to a claim vs. an (implicit) topic. Moreover,\ntask definitions vary, which includes the label inventory, the data collection,\nand the annotation protocol. All these aspects hinder cross-domain studies, as\nthey require changes to standard domain adaptation approaches. In this paper,\nwe perform an in-depth analysis of 16 stance detection datasets, and we explore\nthe possibility for cross-domain learning from them. Moreover, we propose an\nend-to-end unsupervised framework for out-of-domain prediction of unseen,\nuser-defined labels. In particular, we combine domain adaptation techniques\nsuch as mixture of experts and domain-adversarial training with label\nembeddings, and we demonstrate sizable performance gains over strong baselines\n-- both (i) in-domain, i.e., for seen targets, and (ii) out-of-domain, i.e.,\nfor unseen targets. Finally, we perform an exhaustive analysis of the\ncross-domain results, and we highlight the important factors influencing the\nmodel performance.\n", "versions": [{"version": "v1", "created": "Thu, 15 Apr 2021 14:04:29 GMT"}], "update_date": "2021-04-16", "authors_parsed": [["Hardalov", "Momchil", ""], ["Arora", "Arnav", ""], ["Nakov", "Preslav", ""], ["Augenstein", "Isabelle", ""]]}, {"id": "2104.07468", "submitter": "Georgios Leontidis", "authors": "Aiden Durrant, Milan Markovic, David Matthews, David May, Jessica\n  Enright and Georgios Leontidis", "title": "The Role of Cross-Silo Federated Learning in Facilitating Data Sharing\n  in the Agri-Food Sector", "comments": "23 pages, 5 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data sharing remains a major hindering factor when it comes to adopting\nemerging AI technologies in general, but particularly in the agri-food sector.\nProtectiveness of data is natural in this setting; data is a precious commodity\nfor data owners, which if used properly can provide them with useful insights\non operations and processes leading to a competitive advantage. Unfortunately,\nnovel AI technologies often require large amounts of training data in order to\nperform well, something that in many scenarios is unrealistic. However, recent\nmachine learning advances, e.g. federated learning and privacy-preserving\ntechnologies, can offer a solution to this issue via providing the\ninfrastructure and underpinning technologies needed to use data from various\nsources to train models without ever sharing the raw data themselves. In this\npaper, we propose a technical solution based on federated learning that uses\ndecentralized data, (i.e. data that are not exchanged or shared but remain with\nthe owners) to develop a cross-silo machine learning model that facilitates\ndata sharing across supply chains. We focus our data sharing proposition on\nimproving production optimization through soybean yield prediction, and provide\npotential use-cases that such methods can assist in other problem settings. Our\nresults demonstrate that our approach not only performs better than each of the\nmodels trained on an individual data source, but also that data sharing in the\nagri-food sector can be enabled via alternatives to data exchange, whilst also\nhelping to adopt emerging machine learning technologies to boost productivity.\n", "versions": [{"version": "v1", "created": "Wed, 14 Apr 2021 16:00:28 GMT"}], "update_date": "2021-04-16", "authors_parsed": [["Durrant", "Aiden", ""], ["Markovic", "Milan", ""], ["Matthews", "David", ""], ["May", "David", ""], ["Enright", "Jessica", ""], ["Leontidis", "Georgios", ""]]}, {"id": "2104.07469", "submitter": "Muhammad Ilyas Dr.", "authors": "Nazish Ashfaq, Zubair Nawaz, Muhammad Ilyas", "title": "A comparative study of Different Machine Learning Regressors For Stock\n  Market Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For the development of successful share trading strategies, forecasting the\ncourse of action of the stock market index is important. Effective prediction\nof closing stock prices could guarantee investors attractive benefits. Machine\nlearning algorithms have the ability to process and forecast almost reliable\nclosing prices for historical stock patterns. In this article, we intensively\nstudied NASDAQ stock market and targeted to choose the portfolio of ten\ndifferent companies belongs to different sectors. The objective is to compute\nopening price of next day stock using historical data. To fulfill this task\nnine different Machine Learning regressor applied on this data and evaluated\nusing MSE and R2 as performance metric.\n", "versions": [{"version": "v1", "created": "Wed, 14 Apr 2021 15:37:33 GMT"}], "update_date": "2021-04-16", "authors_parsed": [["Ashfaq", "Nazish", ""], ["Nawaz", "Zubair", ""], ["Ilyas", "Muhammad", ""]]}, {"id": "2104.07473", "submitter": "Xiaoyu Xiang", "authors": "Xiaoyu Xiang, Yapeng Tian, Yulun Zhang, Yun Fu, Jan P. Allebach,\n  Chenliang Xu", "title": "Zooming SlowMo: An Efficient One-Stage Framework for Space-Time Video\n  Super-Resolution", "comments": "Journal version of \"Zooming Slow-Mo: Fast and Accurate One-Stage\n  Space-Time Video Super-Resolution\"(CVPR-2020). 14 pages, 14 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.MM eess.IV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we address the space-time video super-resolution, which aims\nat generating a high-resolution (HR) slow-motion video from a low-resolution\n(LR) and low frame rate (LFR) video sequence. A na\\\"ive method is to decompose\nit into two sub-tasks: video frame interpolation (VFI) and video\nsuper-resolution (VSR). Nevertheless, temporal interpolation and spatial\nupscaling are intra-related in this problem. Two-stage approaches cannot fully\nmake use of this natural property. Besides, state-of-the-art VFI or VSR deep\nnetworks usually have a large frame reconstruction module in order to obtain\nhigh-quality photo-realistic video frames, which makes the two-stage approaches\nhave large models and thus be relatively time-consuming. To overcome the\nissues, we present a one-stage space-time video super-resolution framework,\nwhich can directly reconstruct an HR slow-motion video sequence from an input\nLR and LFR video. Instead of reconstructing missing LR intermediate frames as\nVFI models do, we temporally interpolate LR frame features of the missing LR\nframes capturing local temporal contexts by a feature temporal interpolation\nmodule. Extensive experiments on widely used benchmarks demonstrate that the\nproposed framework not only achieves better qualitative and quantitative\nperformance on both clean and noisy LR frames but also is several times faster\nthan recent state-of-the-art two-stage networks. The source code is released in\nhttps://github.com/Mukosame/Zooming-Slow-Mo-CVPR-2020 .\n", "versions": [{"version": "v1", "created": "Thu, 15 Apr 2021 17:59:23 GMT"}], "update_date": "2021-04-16", "authors_parsed": [["Xiang", "Xiaoyu", ""], ["Tian", "Yapeng", ""], ["Zhang", "Yulun", ""], ["Fu", "Yun", ""], ["Allebach", "Jan P.", ""], ["Xu", "Chenliang", ""]]}, {"id": "2104.07474", "submitter": "Murali Karthick Baskar", "authors": "Murali Karthick Baskar, Luk\\'a\\v{s} Burget, Shinji Watanabe, Ramon\n  Fernandez Astudillo, and Jan \"Honza'' \\v{C}ernock\\'y", "title": "EAT: Enhanced ASR-TTS for Self-supervised Speech Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.AI cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Self-supervised ASR-TTS models suffer in out-of-domain data conditions. Here\nwe propose an enhanced ASR-TTS (EAT) model that incorporates two main features:\n1) The ASR$\\rightarrow$TTS direction is equipped with a language model reward\nto penalize the ASR hypotheses before forwarding it to TTS. 2) In the\nTTS$\\rightarrow$ASR direction, a hyper-parameter is introduced to scale the\nattention context from synthesized speech before sending it to ASR to handle\nout-of-domain data. Training strategies and the effectiveness of the EAT model\nare explored under out-of-domain data conditions. The results show that EAT\nreduces the performance gap between supervised and self-supervised training\nsignificantly by absolute 2.6\\% and 2.7\\% on Librispeech and BABEL\nrespectively.\n", "versions": [{"version": "v1", "created": "Tue, 13 Apr 2021 23:18:25 GMT"}], "update_date": "2021-04-16", "authors_parsed": [["Baskar", "Murali Karthick", ""], ["Burget", "Luk\u00e1\u0161", ""], ["Watanabe", "Shinji", ""], ["Astudillo", "Ramon Fernandez", ""], ["\u010cernock\u00fd", "Jan \"Honza''", ""]]}, {"id": "2104.07477", "submitter": "Yiding Zhang", "authors": "Yiding Zhang, Xiao Wang, Chuan Shi, Nian Liu, Guojie Song", "title": "Lorentzian Graph Convolutional Networks", "comments": "12 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Graph convolutional networks (GCNs) have received considerable research\nattention recently. Most GCNs learn the node representations in Euclidean\ngeometry, but that could have a high distortion in the case of embedding graphs\nwith scale-free or hierarchical structure. Recently, some GCNs are proposed to\ndeal with this problem in non-Euclidean geometry, e.g., hyperbolic geometry.\nAlthough hyperbolic GCNs achieve promising performance, existing hyperbolic\ngraph operations actually cannot rigorously follow the hyperbolic geometry,\nwhich may limit the ability of hyperbolic geometry and thus hurt the\nperformance of hyperbolic GCNs. In this paper, we propose a novel hyperbolic\nGCN named Lorentzian graph convolutional network (LGCN), which rigorously\nguarantees the learned node features follow the hyperbolic geometry.\nSpecifically, we rebuild the graph operations of hyperbolic GCNs with\nLorentzian version, e.g., the feature transformation and non-linear activation.\nAlso, an elegant neighborhood aggregation method is designed based on the\ncentroid of Lorentzian distance. Moreover, we prove some proposed graph\noperations are equivalent in different types of hyperbolic geometry, which\nfundamentally indicates their correctness. Experiments on six datasets show\nthat LGCN performs better than the state-of-the-art methods. LGCN has lower\ndistortion to learn the representation of tree-likeness graphs compared with\nexisting hyperbolic GCNs. We also find that the performance of some hyperbolic\nGCNs can be improved by simply replacing the graph operations with those we\ndefined in this paper.\n", "versions": [{"version": "v1", "created": "Thu, 15 Apr 2021 14:14:25 GMT"}], "update_date": "2021-04-16", "authors_parsed": [["Zhang", "Yiding", ""], ["Wang", "Xiao", ""], ["Shi", "Chuan", ""], ["Liu", "Nian", ""], ["Song", "Guojie", ""]]}, {"id": "2104.07491", "submitter": "Jindong Wang", "authors": "Wenxin Hou, Jindong Wang, Xu Tan, Tao Qin, Takahiro Shinozaki", "title": "Cross-domain Speech Recognition with Unsupervised Character-level\n  Distribution Matching", "comments": "Accepted to INTERSPEECH 2021; code available at\n  https://github.com/jindongwang/transferlearning/tree/master/code/ASR/CMatch", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  End-to-end automatic speech recognition (ASR) can achieve promising\nperformance with large-scale training data. However, it is known that domain\nmismatch between training and testing data often leads to a degradation of\nrecognition accuracy. In this work, we focus on the unsupervised domain\nadaptation for ASR and propose CMatch, a Character-level distribution matching\nmethod to perform fine-grained adaptation between each character in two\ndomains. First, to obtain labels for the features belonging to each character,\nwe achieve frame-level label assignment using the Connectionist Temporal\nClassification (CTC) pseudo labels. Then, we match the character-level\ndistributions using Maximum Mean Discrepancy. We train our algorithm using the\nself-training technique. Experiments on the Libri-Adapt dataset show that our\nproposed approach achieves 14.39% and 16.50% relative Word Error Rate (WER)\nreduction on both cross-device and cross-environment ASR. We also\ncomprehensively analyze the different strategies for frame-level label\nassignment and Transformer adaptations.\n", "versions": [{"version": "v1", "created": "Thu, 15 Apr 2021 14:36:54 GMT"}, {"version": "v2", "created": "Fri, 16 Apr 2021 02:10:45 GMT"}, {"version": "v3", "created": "Wed, 9 Jun 2021 01:43:26 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Hou", "Wenxin", ""], ["Wang", "Jindong", ""], ["Tan", "Xu", ""], ["Qin", "Tao", ""], ["Shinozaki", "Takahiro", ""]]}, {"id": "2104.07495", "submitter": "Pietro Mazzaglia", "authors": "Pietro Mazzaglia, Ozan Catal, Tim Verbelen, Bart Dhoedt", "title": "Self-Supervised Exploration via Latent Bayesian Surprise", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Training with Reinforcement Learning requires a reward function that is used\nto guide the agent towards achieving its objective. However, designing smooth\nand well-behaved rewards is in general not trivial and requires significant\nhuman engineering efforts. Generating rewards in self-supervised way, by\ninspiring the agent with an intrinsic desire to learn and explore the\nenvironment, might induce more general behaviours. In this work, we propose a\ncuriosity-based bonus as intrinsic reward for Reinforcement Learning, computed\nas the Bayesian surprise with respect to a latent state variable, learnt by\nreconstructing fixed random features. We extensively evaluate our model by\nmeasuring the agent's performance in terms of environment exploration, for\ncontinuous tasks, and looking at the game scores achieved, for video games. Our\nmodel is computationally cheap and empirically shows state-of-the-art\nperformance on several problems. Furthermore, experimenting on an environment\nwith stochastic actions, our approach emerged to be the most resilient to\nsimple stochasticity. Further visualization is available on the project\nwebpage.(https://lbsexploration.github.io/)\n", "versions": [{"version": "v1", "created": "Thu, 15 Apr 2021 14:40:16 GMT"}], "update_date": "2021-04-16", "authors_parsed": [["Mazzaglia", "Pietro", ""], ["Catal", "Ozan", ""], ["Verbelen", "Tim", ""], ["Dhoedt", "Bart", ""]]}, {"id": "2104.07501", "submitter": "Dezhong Yao", "authors": "Dezhong Yao, Peilin Zhao, Chen Yu, Hai Jin, Bin Li", "title": "Sparse online relative similarity learning", "comments": null, "journal-ref": null, "doi": "10.1109/ICDM.2015.100", "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For many data mining and machine learning tasks, the quality of a similarity\nmeasure is the key for their performance. To automatically find a good\nsimilarity measure from datasets, metric learning and similarity learning are\nproposed and studied extensively. Metric learning will learn a Mahalanobis\ndistance based on positive semi-definite (PSD) matrix, to measure the distances\nbetween objectives, while similarity learning aims to directly learn a\nsimilarity function without PSD constraint so that it is more attractive. Most\nof the existing similarity learning algorithms are online similarity learning\nmethod, since online learning is more scalable than offline learning. However,\nmost existing online similarity learning algorithms learn a full matrix with d\n2 parameters, where d is the dimension of the instances. This is clearly\ninefficient for high dimensional tasks due to its high memory and computational\ncomplexity. To solve this issue, we introduce several Sparse Online Relative\nSimilarity (SORS) learning algorithms, which learn a sparse model during the\nlearning process, so that the memory and computational cost can be\nsignificantly reduced. We theoretically analyze the proposed algorithms, and\nevaluate them on some real-world high dimensional datasets. Encouraging\nempirical results demonstrate the advantages of our approach in terms of\nefficiency and efficacy.\n", "versions": [{"version": "v1", "created": "Thu, 15 Apr 2021 14:50:01 GMT"}], "update_date": "2021-04-16", "authors_parsed": [["Yao", "Dezhong", ""], ["Zhao", "Peilin", ""], ["Yu", "Chen", ""], ["Jin", "Hai", ""], ["Li", "Bin", ""]]}, {"id": "2104.07511", "submitter": "Idan Schwartz", "authors": "Idan Schwartz", "title": "Ensemble of MRR and NDCG models for Visual Dialog", "comments": "Accepted to NAACL2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.CV cs.IR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Assessing an AI agent that can converse in human language and understand\nvisual content is challenging. Generation metrics, such as BLEU scores favor\ncorrect syntax over semantics. Hence a discriminative approach is often used,\nwhere an agent ranks a set of candidate options. The mean reciprocal rank (MRR)\nmetric evaluates the model performance by taking into account the rank of a\nsingle human-derived answer. This approach, however, raises a new challenge:\nthe ambiguity and synonymy of answers, for instance, semantic equivalence\n(e.g., `yeah' and `yes'). To address this, the normalized discounted cumulative\ngain (NDCG) metric has been used to capture the relevance of all the correct\nanswers via dense annotations. However, the NDCG metric favors the usually\napplicable uncertain answers such as `I don't know. Crafting a model that\nexcels on both MRR and NDCG metrics is challenging. Ideally, an AI agent should\nanswer a human-like reply and validate the correctness of any answer. To\naddress this issue, we describe a two-step non-parametric ranking approach that\ncan merge strong MRR and NDCG models. Using our approach, we manage to keep\nmost MRR state-of-the-art performance (70.41% vs. 71.24%) and the NDCG\nstate-of-the-art performance (72.16% vs. 75.35%). Moreover, our approach won\nthe recent Visual Dialog 2020 challenge. Source code is available at\nhttps://github.com/idansc/mrr-ndcg.\n", "versions": [{"version": "v1", "created": "Thu, 15 Apr 2021 15:09:32 GMT"}, {"version": "v2", "created": "Mon, 21 Jun 2021 16:52:11 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Schwartz", "Idan", ""]]}, {"id": "2104.07515", "submitter": "Moming Duan", "authors": "Li Li, Moming Duan, Duo Liu, Yu Zhang, Ao Ren, Xianzhang Chen, Yujuan\n  Tan, Chengliang Wang", "title": "FedSAE: A Novel Self-Adaptive Federated Learning Framework in\n  Heterogeneous Systems", "comments": "This paper will be presented at IJCNN 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Federated Learning (FL) is a novel distributed machine learning which allows\nthousands of edge devices to train model locally without uploading data\nconcentrically to the server. But since real federated settings are\nresource-constrained, FL is encountered with systems heterogeneity which causes\na lot of stragglers directly and then leads to significantly accuracy reduction\nindirectly. To solve the problems caused by systems heterogeneity, we introduce\na novel self-adaptive federated framework FedSAE which adjusts the training\ntask of devices automatically and selects participants actively to alleviate\nthe performance degradation. In this work, we 1) propose FedSAE which leverages\nthe complete information of devices' historical training tasks to predict the\naffordable training workloads for each device. In this way, FedSAE can estimate\nthe reliability of each device and self-adaptively adjust the amount of\ntraining load per client in each round. 2) combine our framework with Active\nLearning to self-adaptively select participants. Then the framework accelerates\nthe convergence of the global model. In our framework, the server evaluates\ndevices' value of training based on their training loss. Then the server\nselects those clients with bigger value for the global model to reduce\ncommunication overhead. The experimental result indicates that in a highly\nheterogeneous system, FedSAE converges faster than FedAvg, the vanilla FL\nframework. Furthermore, FedSAE outperforms than FedAvg on several federated\ndatasets - FedSAE improves test accuracy by 26.7% and reduces stragglers by\n90.3% on average.\n", "versions": [{"version": "v1", "created": "Thu, 15 Apr 2021 15:14:11 GMT"}], "update_date": "2021-04-16", "authors_parsed": [["Li", "Li", ""], ["Duan", "Moming", ""], ["Liu", "Duo", ""], ["Zhang", "Yu", ""], ["Ren", "Ao", ""], ["Chen", "Xianzhang", ""], ["Tan", "Yujuan", ""], ["Wang", "Chengliang", ""]]}, {"id": "2104.07521", "submitter": "Sudeep Pasricha", "authors": "Saideep Tiku, Prathmesh Kale, Sudeep Pasricha", "title": "QuickLoc: Adaptive Deep-Learning for Fast Indoor Localization with\n  Mobile Devices", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG eess.SP", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Indoor localization services are a crucial aspect for the realization of\nsmart cyber-physical systems within cities of the future. Such services are\npoised to reinvent the process of navigation and tracking of people and assets\nin a variety of indoor and subterranean environments. The growing ownership of\ncomputationally capable smartphones has laid the foundations of portable\nfingerprinting-based indoor localization through deep learning. However, as the\ndemand for accurate localization increases, the computational complexity of the\nassociated deep learning models increases as well. We present an approach for\nreducing the computational requirements of a deep learning-based indoor\nlocalization framework while maintaining localization accuracy targets. Our\nproposed methodology is deployed and validated across multiple smartphones and\nis shown to deliver up to 42% reduction in prediction latency and 45% reduction\nin prediction energy as compared to the best-known baseline deep learning-based\nindoor localization model.\n", "versions": [{"version": "v1", "created": "Thu, 15 Apr 2021 15:19:21 GMT"}], "update_date": "2021-04-16", "authors_parsed": [["Tiku", "Saideep", ""], ["Kale", "Prathmesh", ""], ["Pasricha", "Sudeep", ""]]}, {"id": "2104.07531", "submitter": "Carles Domingo-Enrich", "authors": "Carles Domingo-Enrich, Alberto Bietti, Eric Vanden-Eijnden, Joan Bruna", "title": "On Energy-Based Models with Overparametrized Shallow Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Energy-based models (EBMs) are a simple yet powerful framework for generative\nmodeling. They are based on a trainable energy function which defines an\nassociated Gibbs measure, and they can be trained and sampled from via\nwell-established statistical tools, such as MCMC. Neural networks may be used\nas energy function approximators, providing both a rich class of expressive\nmodels as well as a flexible device to incorporate data structure. In this work\nwe focus on shallow neural networks. Building from the incipient theory of\noverparametrized neural networks, we show that models trained in the so-called\n\"active\" regime provide a statistical advantage over their associated \"lazy\" or\nkernel regime, leading to improved adaptivity to hidden low-dimensional\nstructure in the data distribution, as already observed in supervised learning.\nOur study covers both maximum likelihood and Stein Discrepancy estimators, and\nwe validate our theoretical results with numerical experiments on synthetic\ndata.\n", "versions": [{"version": "v1", "created": "Thu, 15 Apr 2021 15:34:58 GMT"}, {"version": "v2", "created": "Wed, 5 May 2021 14:44:39 GMT"}], "update_date": "2021-05-06", "authors_parsed": [["Domingo-Enrich", "Carles", ""], ["Bietti", "Alberto", ""], ["Vanden-Eijnden", "Eric", ""], ["Bruna", "Joan", ""]]}, {"id": "2104.07539", "submitter": "Baoqian Wang", "authors": "Baoqian Wang, Junfei Xie, Kejie Lu, Yan Wan, Shengli Fu", "title": "Multi-Agent Reinforcement Learning Based Coded Computation for Mobile Ad\n  Hoc Computing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Mobile ad hoc computing (MAHC), which allows mobile devices to directly share\ntheir computing resources, is a promising solution to address the growing\ndemands for computing resources required by mobile devices. However, offloading\na computation task from a mobile device to other mobile devices is a\nchallenging task due to frequent topology changes and link failures because of\nnode mobility, unstable and unknown communication environments, and the\nheterogeneous nature of these devices. To address these challenges, in this\npaper, we introduce a novel coded computation scheme based on multi-agent\nreinforcement learning (MARL), which has many promising features such as\nadaptability to network changes, high efficiency and robustness to uncertain\nsystem disturbances, consideration of node heterogeneity, and decentralized\nload allocation. Comprehensive simulation studies demonstrate that the proposed\napproach can outperform state-of-the-art distributed computing schemes.\n", "versions": [{"version": "v1", "created": "Thu, 15 Apr 2021 15:50:57 GMT"}], "update_date": "2021-04-16", "authors_parsed": [["Wang", "Baoqian", ""], ["Xie", "Junfei", ""], ["Lu", "Kejie", ""], ["Wan", "Yan", ""], ["Fu", "Shengli", ""]]}, {"id": "2104.07540", "submitter": "Timo Schick", "authors": "Timo Schick and Hinrich Sch\\\"utze", "title": "Generating Datasets with Pretrained Language Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To obtain high-quality sentence embeddings from pretrained language models\n(PLMs), they must either be augmented with additional pretraining objectives or\nfinetuned on a large set of labeled text pairs. While the latter approach\ntypically outperforms the former, it requires great human effort to generate\nsuitable datasets of sufficient size. In this paper, we show how large PLMs can\nbe leveraged to obtain high-quality embeddings without requiring any labeled\ndata, finetuning or modifications to the pretraining objective: We utilize the\ngenerative abilities of PLMs to generate entire datasets of labeled text pairs\nfrom scratch, which can then be used for regular finetuning of much smaller\nmodels. Our fully unsupervised approach outperforms strong baselines on several\nEnglish semantic textual similarity datasets.\n", "versions": [{"version": "v1", "created": "Thu, 15 Apr 2021 15:51:41 GMT"}, {"version": "v2", "created": "Sat, 17 Apr 2021 16:05:21 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Schick", "Timo", ""], ["Sch\u00fctze", "Hinrich", ""]]}, {"id": "2104.07541", "submitter": "Raphael Shu", "authors": "Raphael Shu, Kang Min Yoo, Jung-Woo Ha", "title": "Reward Optimization for Neural Machine Translation with Learned Metrics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Neural machine translation (NMT) models are conventionally trained with\ntoken-level negative log-likelihood (NLL), which does not guarantee that the\ngenerated translations will be optimized for a selected sequence-level\nevaluation metric. Multiple approaches are proposed to train NMT with BLEU as\nthe reward, in order to directly improve the metric. However, it was reported\nthat the gain in BLEU does not translate to real quality improvement, limiting\nthe application in industry. Recently, it became clear to the community that\nBLEU has a low correlation with human judgment when dealing with\nstate-of-the-art models. This leads to the emerging of model-based evaluation\nmetrics. These new metrics are shown to have a much higher human correlation.\nIn this paper, we investigate whether it is beneficial to optimize NMT models\nwith the state-of-the-art model-based metric, BLEURT. We propose a\ncontrastive-margin loss for fast and stable reward optimization suitable for\nlarge NMT models. In experiments, we perform automatic and human evaluations to\ncompare models trained with smoothed BLEU and BLEURT to the baseline models.\nResults show that the reward optimization with BLEURT is able to increase the\nmetric scores by a large margin, in contrast to limited gain when training with\nsmoothed BLEU. The human evaluation shows that models trained with BLEURT\nimprove adequacy and coverage of translations. Code is available via\nhttps://github.com/naver-ai/MetricMT.\n", "versions": [{"version": "v1", "created": "Thu, 15 Apr 2021 15:53:31 GMT"}], "update_date": "2021-04-16", "authors_parsed": [["Shu", "Raphael", ""], ["Yoo", "Kang Min", ""], ["Ha", "Jung-Woo", ""]]}, {"id": "2104.07551", "submitter": "Anthony Bagnall Dr", "authors": "Matthew Middlehurst, James Large, Michael Flynn, Jason Lines, Aaron\n  Bostrom and Anthony Bagnall", "title": "HIVE-COTE 2.0: a new meta ensemble for time series classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The Hierarchical Vote Collective of Transformation-based Ensembles\n(HIVE-COTE) is a heterogeneous meta ensemble for time series classification.\nHIVE-COTE forms its ensemble from classifiers of multiple domains, including\nphase-independent shapelets, bag-of-words based dictionaries and\nphase-dependent intervals. Since it was first proposed in 2016, the algorithm\nhas remained state of the art for accuracy on the UCR time series\nclassification archive. Over time it has been incrementally updated,\nculminating in its current state, HIVE-COTE 1.0. During this time a number of\nalgorithms have been proposed which match the accuracy of HIVE-COTE. We propose\ncomprehensive changes to the HIVE-COTE algorithm which significantly improve\nits accuracy and usability, presenting this upgrade as HIVE-COTE 2.0. We\nintroduce two novel classifiers, the Temporal Dictionary Ensemble (TDE) and\nDiverse Representation Canonical Interval Forest (DrCIF), which replace\nexisting ensemble members. Additionally, we introduce the Arsenal, an ensemble\nof ROCKET classifiers as a new HIVE-COTE 2.0 constituent. We demonstrate that\nHIVE-COTE 2.0 is significantly more accurate than the current state of the art\non 112 univariate UCR archive datasets and 26 multivariate UEA archive\ndatasets.\n", "versions": [{"version": "v1", "created": "Thu, 15 Apr 2021 16:06:09 GMT"}], "update_date": "2021-04-16", "authors_parsed": [["Middlehurst", "Matthew", ""], ["Large", "James", ""], ["Flynn", "Michael", ""], ["Lines", "Jason", ""], ["Bostrom", "Aaron", ""], ["Bagnall", "Anthony", ""]]}, {"id": "2104.07553", "submitter": "Joonyoung Yi", "authors": "Joonyoung Yi, Buru Chang", "title": "Efficient Click-Through Rate Prediction for Developing Countries via\n  Tabular Learning", "comments": "ICLR 2021 Workshop (PML4DC), 8 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.HC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Despite the rapid growth of online advertisement in developing countries,\nexisting highly over-parameterized Click-Through Rate (CTR) prediction models\nare difficult to be deployed due to the limited computing resources. In this\npaper, by bridging the relationship between CTR prediction task and tabular\nlearning, we present that tabular learning models are more efficient and\neffective in CTR prediction than over-parameterized CTR prediction models.\nExtensive experiments on eight public CTR prediction datasets show that tabular\nlearning models outperform twelve state-of-the-art CTR prediction models.\nFurthermore, compared to over-parameterized CTR prediction models, tabular\nlearning models can be fast trained without expensive computing resources\nincluding high-performance GPUs. Finally, through an A/B test on an actual\nonline application, we show that tabular learning models improve not only\noffline performance but also the CTR of real users.\n", "versions": [{"version": "v1", "created": "Thu, 15 Apr 2021 16:07:25 GMT"}], "update_date": "2021-04-16", "authors_parsed": [["Yi", "Joonyoung", ""], ["Chang", "Buru", ""]]}, {"id": "2104.07557", "submitter": "Yuben Qu", "authors": "Yuben Qu, Haipeng Dai, Yan Zhuang, Jiafa Chen, Chao Dong, Fan Wu, Song\n  Guo", "title": "Serverless Federated Learning for UAV Networks: Architecture,\n  Challenges, and Opportunities", "comments": "7 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Unmanned aerial vehicles (UAVs), or say drones, are envisioned to support\nextensive applications in next-generation wireless networks in both civil and\nmilitary fields. Empowering UAVs networks intelligence by artificial\nintelligence (AI) especially machine learning (ML) techniques is inevitable and\nappealing to enable the aforementioned applications. To solve the problems of\ntraditional cloud-centric ML for UAV networks such as privacy concern,\nunacceptable latency, and resource burden, a distributed ML technique, i.e.,\nfederated learning (FL), has been recently proposed to enable multiple UAVs to\ncollaboratively train ML model without letting out raw data. However, almost\nall existing FL paradigms are server-based, i.e., a central entity is in charge\nof ML model aggregation and fusion over the whole network, which could result\nin the issue of a single point of failure and are inappropriate to UAV networks\nwith both unreliable nodes and links. To address the above issue, in this\narticle, we propose a novel architecture called SELF-UN\n(\\underline{SE}rver\\underline{L}ess \\underline{F}L for \\underline{U}AV\n\\underline{N}etworks), which enables FL within UAV networks without a central\nentity. We also conduct a preliminary simulation study to validate the\nfeasibility and effectiveness of the SELF-UN architecture. Finally, we discuss\nthe main challenges and potential research directions in the SELF-UN.\n", "versions": [{"version": "v1", "created": "Thu, 15 Apr 2021 16:11:13 GMT"}], "update_date": "2021-04-16", "authors_parsed": [["Qu", "Yuben", ""], ["Dai", "Haipeng", ""], ["Zhuang", "Yan", ""], ["Chen", "Jiafa", ""], ["Dong", "Chao", ""], ["Wu", "Fan", ""], ["Guo", "Song", ""]]}, {"id": "2104.07566", "submitter": "Fanyi Wang", "authors": "Fanyi Wang, Haotian Hu, Cheng Shen", "title": "BAM: A Lightweight and Efficient Balanced Attention Mechanism for Single\n  Image Super Resolution", "comments": "13 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Attention mechanism has shown enormous potential for single image\nsuper-resolution (SISR). However, existing works only proposed some attention\nmechanism for a specific network. A universal attention mechanism for SISR,\nwhich could further improve the performance of networks without attention and\nprovide a baseline for networks with attention, is still lacking. To fit this\ngap, we propose a lightweight and efficient Balanced Attention Mechanism (BAM),\nwhich consists of Avgpool Channel Attention Module (ACAM) and Maxpool Spatial\nAttention Module (MSAM) in parallel. The information extraction mechanism of\nACAM and MSAM effectively filters redundant information, making the overall\nstructure of BAM very lightweight. Owing to the parallel structure, during the\ngradient backpropagation process of BAM, ACAM and MSAM not only conduct\nself-optimization, but also mutual optimization so as to generate more balanced\nattention information. To verify the effectiveness and robustness of BAM, we\napplied it to 12 state-ofthe-art SISR networks. The results on 4 benchmark\ndatasets demonstrate that BAM can efficiently improve the networks'\nperformance, and for those with attention, the substitution with BAM further\nreduces the amount of parameters and increase the inference speed. Moreover,\nablation experiments were conducted to prove the minimalism of BAM.\n", "versions": [{"version": "v1", "created": "Thu, 15 Apr 2021 16:22:16 GMT"}, {"version": "v2", "created": "Sat, 26 Jun 2021 08:00:21 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Wang", "Fanyi", ""], ["Hu", "Haotian", ""], ["Shen", "Cheng", ""]]}, {"id": "2104.07576", "submitter": "Samuel Greenbank", "authors": "Samuel Greenbank, and David A. Howey", "title": "Piecewise-linear modelling with feature selection for Li-ion battery end\n  of life prognosis", "comments": "7 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.LG cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The complex nature of lithium-ion battery degradation has led to many machine\nlearning based approaches to health forecasting being proposed in literature.\nHowever, machine learning can be computationally intensive. Linear approaches\nare faster but have previously been too inflexible for successful prognosis.\nFor both techniques, the choice and quality of the inputs is a limiting factor\nof performance. Piecewise-linear models, combined with automated feature\nselection, offer a fast and flexible alternative without being as\ncomputationally intensive as machine learning. Here, a piecewise-linear\napproach to battery health forecasting was compared to a Gaussian process\nregression tool and found to perform equally well. The input feature selection\nprocess demonstrated the benefit of limiting the correlation between inputs.\nFurther trials found that the piecewise-linear approach was robust to changing\ninput size and availability of training data.\n", "versions": [{"version": "v1", "created": "Thu, 15 Apr 2021 16:29:58 GMT"}], "update_date": "2021-04-16", "authors_parsed": [["Greenbank", "Samuel", ""], ["Howey", "David A.", ""]]}, {"id": "2104.07586", "submitter": "Hongxu Yin", "authors": "Hongxu Yin, Arun Mallya, Arash Vahdat, Jose M. Alvarez, Jan Kautz,\n  Pavlo Molchanov", "title": "See through Gradients: Image Batch Recovery via GradInversion", "comments": "CVPR 2021 accepted paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training deep neural networks requires gradient estimation from data batches\nto update parameters. Gradients per parameter are averaged over a set of data\nand this has been presumed to be safe for privacy-preserving training in joint,\ncollaborative, and federated learning applications. Prior work only showed the\npossibility of recovering input data given gradients under very restrictive\nconditions - a single input point, or a network with no non-linearities, or a\nsmall 32x32 px input batch. Therefore, averaging gradients over larger batches\nwas thought to be safe. In this work, we introduce GradInversion, using which\ninput images from a larger batch (8 - 48 images) can also be recovered for\nlarge networks such as ResNets (50 layers), on complex datasets such as\nImageNet (1000 classes, 224x224 px). We formulate an optimization task that\nconverts random noise into natural images, matching gradients while\nregularizing image fidelity. We also propose an algorithm for target class\nlabel recovery given gradients. We further propose a group consistency\nregularization framework, where multiple agents starting from different random\nseeds work together to find an enhanced reconstruction of original data batch.\nWe show that gradients encode a surprisingly large amount of information, such\nthat all the individual images can be recovered with high fidelity via\nGradInversion, even for complex datasets, deep networks, and large batch sizes.\n", "versions": [{"version": "v1", "created": "Thu, 15 Apr 2021 16:43:17 GMT"}], "update_date": "2021-04-16", "authors_parsed": [["Yin", "Hongxu", ""], ["Mallya", "Arun", ""], ["Vahdat", "Arash", ""], ["Alvarez", "Jose M.", ""], ["Kautz", "Jan", ""], ["Molchanov", "Pavlo", ""]]}, {"id": "2104.07620", "submitter": "Thomas Seel", "authors": "Michael Meindl, Fabio Molinari, Dustin Lehmann, Thomas Seel", "title": "Collective Iterative Learning Control: Exploiting Diversity in\n  Multi-Agent Systems for Reference Tracking Tasks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.LG cs.MA cs.RO cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers a group of autonomous agents learning to track the same\ngiven reference trajectory in a possibly small number of trials. We propose a\nnovel collective learning control method (namely, CILC) that combines Iterative\nLearning Control (ILC) with a collective input update strategy. We derive\nconditions for desirable convergence properties of such systems. We show that\nthe proposed method allows the collective to combine the advantages of the\nagents' individual learning strategies and thereby overcomes trade-offs and\nlimitations of single-agent ILC. This benefit is leveraged by designing a\nheterogeneous collective, i.e., a different learning law is assigned to each\nagent. All theoretical results are confirmed in simulations and experiments\nwith two-wheeled-inverted-pendulums robots (TWIPRs) that jointly learn to\nperform a desired maneuver.\n", "versions": [{"version": "v1", "created": "Thu, 15 Apr 2021 17:36:00 GMT"}], "update_date": "2021-04-16", "authors_parsed": [["Meindl", "Michael", ""], ["Molinari", "Fabio", ""], ["Lehmann", "Dustin", ""], ["Seel", "Thomas", ""]]}, {"id": "2104.07635", "submitter": "Hossein Rajaby Faghihi", "authors": "Hossein Rajaby Faghihi and Parisa Kordjamshidi", "title": "Time-Stamped Language Model: Teaching Language Models to Understand the\n  Flow of Events", "comments": "Accepted at NAACL 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tracking entities throughout a procedure described in a text is challenging\ndue to the dynamic nature of the world described in the process. Firstly, we\npropose to formulate this task as a question answering problem. This enables us\nto use pre-trained transformer-based language models on other QA benchmarks by\nadapting those to the procedural text understanding. Secondly, since the\ntransformer-based language models cannot encode the flow of events by\nthemselves, we propose a Time-Stamped Language Model~(TSLM model) to encode\nevent information in LMs architecture by introducing the timestamp encoding.\nOur model evaluated on the Propara dataset shows improvements on the published\nstate-of-the-art results with a $3.1\\%$ increase in F1 score. Moreover, our\nmodel yields better results on the location prediction task on the NPN-Cooking\ndataset. This result indicates that our approach is effective for procedural\ntext understanding in general.\n", "versions": [{"version": "v1", "created": "Thu, 15 Apr 2021 17:50:41 GMT"}], "update_date": "2021-04-16", "authors_parsed": [["Faghihi", "Hossein Rajaby", ""], ["Kordjamshidi", "Parisa", ""]]}, {"id": "2104.07636", "submitter": "Chitwan Saharia", "authors": "Chitwan Saharia, Jonathan Ho, William Chan, Tim Salimans, David J.\n  Fleet, Mohammad Norouzi", "title": "Image Super-Resolution via Iterative Refinement", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present SR3, an approach to image Super-Resolution via Repeated\nRefinement. SR3 adapts denoising diffusion probabilistic models to conditional\nimage generation and performs super-resolution through a stochastic denoising\nprocess. Inference starts with pure Gaussian noise and iteratively refines the\nnoisy output using a U-Net model trained on denoising at various noise levels.\nSR3 exhibits strong performance on super-resolution tasks at different\nmagnification factors, on faces and natural images. We conduct human evaluation\non a standard 8X face super-resolution task on CelebA-HQ, comparing with SOTA\nGAN methods. SR3 achieves a fool rate close to 50%, suggesting photo-realistic\noutputs, while GANs do not exceed a fool rate of 34%. We further show the\neffectiveness of SR3 in cascaded image generation, where generative models are\nchained with super-resolution models, yielding a competitive FID score of 11.3\non ImageNet.\n", "versions": [{"version": "v1", "created": "Thu, 15 Apr 2021 17:50:42 GMT"}, {"version": "v2", "created": "Wed, 30 Jun 2021 07:34:57 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Saharia", "Chitwan", ""], ["Ho", "Jonathan", ""], ["Chan", "William", ""], ["Salimans", "Tim", ""], ["Fleet", "David J.", ""], ["Norouzi", "Mohammad", ""]]}, {"id": "2104.07637", "submitter": "Yuchen Lian", "authors": "Yuchen Lian, Arianna Bisazza and Tessa Verhoef", "title": "The Effect of Efficient Messaging and Input Variability on Neural-Agent\n  Iterated Language Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Natural languages commonly display a trade-off among different strategies to\nconvey constituent roles. A similar trade-off, however, has not been observed\nin recent simulations of iterated language learning with neural network based\nagents (Chaabouni et al., 2019b). In this work, we re-evaluate this result in\nthe light of two important factors, namely: the lack of effort-based pressure\nin the agents and the lack of variability in the initial input language.\n", "versions": [{"version": "v1", "created": "Thu, 15 Apr 2021 17:50:42 GMT"}], "update_date": "2021-04-16", "authors_parsed": [["Lian", "Yuchen", ""], ["Bisazza", "Arianna", ""], ["Verhoef", "Tessa", ""]]}, {"id": "2104.07639", "submitter": "Xian Li", "authors": "Xian Li, Hongyu Gong", "title": "Robust Optimization for Multilingual Translation with Imbalanced Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Multilingual models are parameter-efficient with the prospect improving\nlow-resource languages by leveraging crosslingual transfer. Despite recent\nadvance in massive multilingual translation with ever-growing model and data,\nhow to effectively train multilingual models has not been well understood. In\nthis paper, we show that a common situation in multilingual training, data\nimbalance among languages, poses optimization tension between high resource and\nlow resource languages where the found multilingual solution is often\nsub-optimal for low resources. We show that common training method which\nupsamples low resources can not robustly optimize population loss with risks of\neither underfitting high resource languages or overfitting low resource ones.\nDrawing on recent findings on the geometry of loss landscape and its effect on\ngeneralization, we propose a principled optimization algorithm, Curvature Aware\nTask Scaling (CATS), which adaptively rescales gradients from different tasks\nwith a meta objective of guiding multilingual training to low-curvature\nneighborhoods with uniformly low loss for all languages. We ran experiments on\ncommon benchmarks (TED, WMT and OPUS-100) with varying degrees of data\nimbalance. CATS effectively improved multilingual optimization and as a result\ndemonstrated consistent gains on low resources ( to BLEU) without hurting high\nresources. In addition, CATS is robust to overparameterization and large batch\nsize training, making it a promising training method for massive multilingual\nmodels that truly improve low resource languages.\n", "versions": [{"version": "v1", "created": "Thu, 15 Apr 2021 17:51:03 GMT"}, {"version": "v2", "created": "Tue, 20 Apr 2021 06:40:27 GMT"}, {"version": "v3", "created": "Sun, 13 Jun 2021 00:05:27 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Li", "Xian", ""], ["Gong", "Hongyu", ""]]}, {"id": "2104.07651", "submitter": "Lukas Heumos", "authors": "Lukas Heumos, Philipp Ehmele, Kevin Menden, Luis Kuhn Cuellar, Edmund\n  Miller, Steffen Lemke, Gisela Gabernet and Sven Nahnsen", "title": "mlf-core: a framework for deterministic machine learning", "comments": "https://mlf-core.com and https://github.com/mlf-core/mlf-core", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS cs.LG q-bio.QM stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Machine learning has shown extensive growth in recent years. However,\npreviously existing studies highlighted a reproducibility crisis in machine\nlearning. The reasons for irreproducibility are manifold. Major machine\nlearning libraries default to the usage of non-deterministic algorithms based\non atomic operations. Solely fixing all random seeds is not sufficient for\ndeterministic machine learning. To overcome this shortcoming, various machine\nlearning libraries released deterministic counterparts to the non-deterministic\nalgorithms. We evaluated the effect of these algorithms on determinism and\nruntime. Based on these results, we formulated a set of requirements for\nreproducible machine learning and developed a new software solution, the\nmlf-core ecosystem, which aids machine learning projects to meet and keep these\nrequirements. We applied mlf-core to develop fully reproducible models in\nvarious biomedical fields including a single cell autoencoder with TensorFlow,\na PyTorch-based U-Net model for liver-tumor segmentation in CT scans, and a\nliver cancer classifier based on gene expression profiles with XGBoost.\n", "versions": [{"version": "v1", "created": "Thu, 15 Apr 2021 17:58:03 GMT"}], "update_date": "2021-04-16", "authors_parsed": [["Heumos", "Lukas", ""], ["Ehmele", "Philipp", ""], ["Menden", "Kevin", ""], ["Cuellar", "Luis Kuhn", ""], ["Miller", "Edmund", ""], ["Lemke", "Steffen", ""], ["Gabernet", "Gisela", ""], ["Nahnsen", "Sven", ""]]}, {"id": "2104.07654", "submitter": "Nicha Dvornek", "authors": "Nicha C. Dvornek, Xiaoxiao Li, Juntang Zhuang, Pamela Ventola, and\n  James S. Duncan", "title": "Demographic-Guided Attention in Recurrent Neural Networks for Modeling\n  Neuropathophysiological Heterogeneity", "comments": "MLMI 2020 (MICCAI Workshop)", "journal-ref": null, "doi": "10.1007/978-3-030-59861-7_37", "report-no": null, "categories": "cs.LG cs.CV eess.IV q-bio.QM stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Heterogeneous presentation of a neurological disorder suggests potential\ndifferences in the underlying pathophysiological changes that occur in the\nbrain. We propose to model heterogeneous patterns of functional network\ndifferences using a demographic-guided attention (DGA) mechanism for recurrent\nneural network models for prediction from functional magnetic resonance imaging\n(fMRI) time-series data. The context computed from the DGA head is used to help\nfocus on the appropriate functional networks based on individual demographic\ninformation. We demonstrate improved classification on 3 subsets of the ABIDE I\ndataset used in published studies that have previously produced\nstate-of-the-art results, evaluating performance under a leave-one-site-out\ncross-validation framework for better generalizeability to new data. Finally,\nwe provide examples of interpreting functional network differences based on\nindividual demographic variables.\n", "versions": [{"version": "v1", "created": "Thu, 15 Apr 2021 17:58:36 GMT"}], "update_date": "2021-04-16", "authors_parsed": [["Dvornek", "Nicha C.", ""], ["Li", "Xiaoxiao", ""], ["Zhuang", "Juntang", ""], ["Ventola", "Pamela", ""], ["Duncan", "James S.", ""]]}, {"id": "2104.07658", "submitter": "Weidi Xie", "authors": "Charig Yang, Hala Lamdouar, Erika Lu, Andrew Zisserman, Weidi Xie", "title": "Self-supervised Video Object Segmentation by Motion Grouping", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Animals have evolved highly functional visual systems to understand motion,\nassisting perception even under complex environments. In this paper, we work\ntowards developing a computer vision system able to segment objects by\nexploiting motion cues, i.e. motion segmentation. We make the following\ncontributions: First, we introduce a simple variant of the Transformer to\nsegment optical flow frames into primary objects and the background. Second, we\ntrain the architecture in a self-supervised manner, i.e. without using any\nmanual annotations. Third, we analyze several critical components of our method\nand conduct thorough ablation studies to validate their necessity. Fourth, we\nevaluate the proposed architecture on public benchmarks (DAVIS2016, SegTrackv2,\nand FBMS59). Despite using only optical flow as input, our approach achieves\nsuperior or comparable results to previous state-of-the-art self-supervised\nmethods, while being an order of magnitude faster. We additionally evaluate on\na challenging camouflage dataset (MoCA), significantly outperforming the other\nself-supervised approaches, and comparing favourably to the top supervised\napproach, highlighting the importance of motion cues, and the potential bias\ntowards visual appearance in existing video segmentation models.\n", "versions": [{"version": "v1", "created": "Thu, 15 Apr 2021 17:59:32 GMT"}], "update_date": "2021-04-16", "authors_parsed": [["Yang", "Charig", ""], ["Lamdouar", "Hala", ""], ["Lu", "Erika", ""], ["Zisserman", "Andrew", ""], ["Xie", "Weidi", ""]]}, {"id": "2104.07662", "submitter": "Deepak Pathak", "authors": "Yuqing Du, Olivia Watkins, Trevor Darrell, Pieter Abbeel, Deepak\n  Pathak", "title": "Auto-Tuned Sim-to-Real Transfer", "comments": "ICRA 2021. First two authors contributed equally. Website at\n  https://yuqingd.github.io/autotuned-sim2real/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CV cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Policies trained in simulation often fail when transferred to the real world\ndue to the `reality gap' where the simulator is unable to accurately capture\nthe dynamics and visual properties of the real world. Current approaches to\ntackle this problem, such as domain randomization, require prior knowledge and\nengineering to determine how much to randomize system parameters in order to\nlearn a policy that is robust to sim-to-real transfer while also not being too\nconservative. We propose a method for automatically tuning simulator system\nparameters to match the real world using only raw RGB images of the real world\nwithout the need to define rewards or estimate state. Our key insight is to\nreframe the auto-tuning of parameters as a search problem where we iteratively\nshift the simulation system parameters to approach the real-world system\nparameters. We propose a Search Param Model (SPM) that, given a sequence of\nobservations and actions and a set of system parameters, predicts whether the\ngiven parameters are higher or lower than the true parameters used to generate\nthe observations. We evaluate our method on multiple robotic control tasks in\nboth sim-to-sim and sim-to-real transfer, demonstrating significant improvement\nover naive domain randomization. Project videos and code at\nhttps://yuqingd.github.io/autotuned-sim2real/\n", "versions": [{"version": "v1", "created": "Thu, 15 Apr 2021 17:59:55 GMT"}, {"version": "v2", "created": "Thu, 20 May 2021 17:58:26 GMT"}], "update_date": "2021-05-21", "authors_parsed": [["Du", "Yuqing", ""], ["Watkins", "Olivia", ""], ["Darrell", "Trevor", ""], ["Abbeel", "Pieter", ""], ["Pathak", "Deepak", ""]]}, {"id": "2104.07692", "submitter": "Vasileios Belis", "authors": "Vasileios Belis, Samuel Gonz\\'alez-Castillo, Christina Reissel, Sofia\n  Vallecorsa, El\\'ias F. Combarro, G\\\"unther Dissertori, Florentin Reiter", "title": "Higgs analysis with quantum classifiers", "comments": "Submitted to the 25th International Conference on Computing in\n  High-Energy and Nuclear Physics (vCHEP2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.LG hep-ex physics.data-an", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We have developed two quantum classifier models for the $t\\bar{t}H(b\\bar{b})$\nclassification problem, both of which fall into the category of hybrid\nquantum-classical algorithms for Noisy Intermediate Scale Quantum devices\n(NISQ). Our results, along with other studies, serve as a proof of concept that\nQuantum Machine Learning (QML) methods can have similar or better performance,\nin specific cases of low number of training samples, with respect to\nconventional ML methods even with a limited number of qubits available in\ncurrent hardware. To utilise algorithms with a low number of qubits -- to\naccommodate for limitations in both simulation hardware and real quantum\nhardware -- we investigated different feature reduction methods. Their impact\non the performance of both the classical and quantum models was assessed. We\naddressed different implementations of two QML models, representative of the\ntwo main approaches to supervised quantum machine learning today: a Quantum\nSupport Vector Machine (QSVM), a kernel-based method, and a Variational Quantum\nCircuit (VQC), a variational approach.\n", "versions": [{"version": "v1", "created": "Thu, 15 Apr 2021 18:01:51 GMT"}], "update_date": "2021-04-19", "authors_parsed": [["Belis", "Vasileios", ""], ["Gonz\u00e1lez-Castillo", "Samuel", ""], ["Reissel", "Christina", ""], ["Vallecorsa", "Sofia", ""], ["Combarro", "El\u00edas F.", ""], ["Dissertori", "G\u00fcnther", ""], ["Reiter", "Florentin", ""]]}, {"id": "2104.07705", "submitter": "Peter Izsak", "authors": "Peter Izsak, Moshe Berchansky, Omer Levy", "title": "How to Train BERT with an Academic Budget", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While large language models \\`a la BERT are used ubiquitously in NLP,\npretraining them is considered a luxury that only a few well-funded industry\nlabs can afford. How can one train such models with a more modest budget? We\npresent a recipe for pretraining a masked language model in 24 hours, using\nonly 8 low-range 12GB GPUs. We demonstrate that through a combination of\nsoftware optimizations, design choices, and hyperparameter tuning, it is\npossible to produce models that are competitive with BERT-base on GLUE tasks at\na fraction of the original pretraining cost.\n", "versions": [{"version": "v1", "created": "Thu, 15 Apr 2021 18:17:12 GMT"}], "update_date": "2021-04-19", "authors_parsed": [["Izsak", "Peter", ""], ["Berchansky", "Moshe", ""], ["Levy", "Omer", ""]]}, {"id": "2104.07713", "submitter": "Xiao Wang", "authors": "Xiao Wang, Guo-Jun Qi", "title": "Contrastive Learning with Stronger Augmentations", "comments": "10 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Representation learning has significantly been developed with the advance of\ncontrastive learning methods. Most of those methods have benefited from various\ndata augmentations that are carefully designated to maintain their identities\nso that the images transformed from the same instance can still be retrieved.\nHowever, those carefully designed transformations limited us to further explore\nthe novel patterns exposed by other transformations. Meanwhile, as found in our\nexperiments, the strong augmentations distorted the images' structures,\nresulting in difficult retrieval. Thus, we propose a general framework called\nContrastive Learning with Stronger Augmentations~(CLSA) to complement current\ncontrastive learning approaches. Here, the distribution divergence between the\nweakly and strongly augmented images over the representation bank is adopted to\nsupervise the retrieval of strongly augmented queries from a pool of instances.\nExperiments on the ImageNet dataset and downstream datasets showed the\ninformation from the strongly augmented images can significantly boost the\nperformance. For example, CLSA achieves top-1 accuracy of 76.2% on ImageNet\nwith a standard ResNet-50 architecture with a single-layer classifier\nfine-tuned, which is almost the same level as 76.5% of supervised results. The\ncode and pre-trained models are available in\nhttps://github.com/maple-research-lab/CLSA.\n", "versions": [{"version": "v1", "created": "Thu, 15 Apr 2021 18:40:04 GMT"}], "update_date": "2021-04-19", "authors_parsed": [["Wang", "Xiao", ""], ["Qi", "Guo-Jun", ""]]}, {"id": "2104.07715", "submitter": "Samuel Yen-Chi Chen", "authors": "En-Jui Kuo, Yao-Lung L. Fang, Samuel Yen-Chi Chen", "title": "Quantum Architecture Search via Deep Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in quantum computing have drawn considerable attention to\nbuilding realistic application for and using quantum computers. However,\ndesigning a suitable quantum circuit architecture requires expert knowledge.\nFor example, it is non-trivial to design a quantum gate sequence for generating\na particular quantum state with as fewer gates as possible. We propose a\nquantum architecture search framework with the power of deep reinforcement\nlearning (DRL) to address this challenge. In the proposed framework, the DRL\nagent can only access the Pauli-$X$, $Y$, $Z$ expectation values and a\npredefined set of quantum operations for learning the target quantum state, and\nis optimized by the advantage actor-critic (A2C) and proximal policy\noptimization (PPO) algorithms. We demonstrate a successful generation of\nquantum gate sequences for multi-qubit GHZ states without encoding any\nknowledge of quantum physics in the agent. The design of our framework is\nrather general and can be employed with other DRL architectures or optimization\nmethods to study gate synthesis and compilation for many quantum states.\n", "versions": [{"version": "v1", "created": "Thu, 15 Apr 2021 18:53:26 GMT"}], "update_date": "2021-04-19", "authors_parsed": [["Kuo", "En-Jui", ""], ["Fang", "Yao-Lung L.", ""], ["Chen", "Samuel Yen-Chi", ""]]}, {"id": "2104.07720", "submitter": "Konstantinos Kotis", "authors": "Konstantinos Sikelis, George E Tsekouras, Konstantinos I Kotis", "title": "Ontology-based Feature Selection: A Survey", "comments": "25 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The SemanticWeb emerged as an extension to the traditional Web, towards\nadding meaning to a distributed Web of structured and linked data. At its core,\nthe concept of ontology provides the means to semantically describe and\nstructure information and data and expose it to software and human agents in a\nmachine and human-readable form. For software agents to be realized, it is\ncrucial to develop powerful artificial intelligence and machine learning\ntechniques, able to extract knowledge from information and data sources and\nrepresent it in the underlying ontology. This survey aims to provide insight\ninto key aspects of ontology-based knowledge extraction, from various sources\nsuch as text, images, databases and human expertise, with emphasis on the task\nof feature selection. First, some of the most common classification and feature\nselection algorithms are briefly presented. Then, selected methodologies, which\nutilize ontologies to represent features and perform feature selection and\nclassification, are described. The presented examples span diverse application\ndomains, e.g., medicine, tourism, mechanical and civil engineering, and\ndemonstrate the feasibility and applicability of such methods.\n", "versions": [{"version": "v1", "created": "Thu, 15 Apr 2021 19:03:31 GMT"}, {"version": "v2", "created": "Fri, 30 Apr 2021 14:17:37 GMT"}], "update_date": "2021-05-03", "authors_parsed": [["Sikelis", "Konstantinos", ""], ["Tsekouras", "George E", ""], ["Kotis", "Konstantinos I", ""]]}, {"id": "2104.07737", "submitter": "Farzana Nasrin", "authors": "Farzana Nasrin, Theodore Papamarkou, and Vasileios Maroulas", "title": "Random Persistence Diagram Generation", "comments": "27 pages, 10 figures and 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.AT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Topological data analysis (TDA) studies the shape patterns of data.\nPersistent homology (PH) is a widely used method in TDA that summarizes\nhomological features of data at multiple scales and stores this in persistence\ndiagrams (PDs). As TDA is commonly used in the analysis of high dimensional\ndata sets, a sufficiently large amount of PDs that allow performing statistical\nanalysis is typically unavailable or requires inordinate computational\nresources. In this paper, we propose random persistence diagram generation\n(RPDG), a method that generates a sequence of random PDs from the ones produced\nby the data. RPDG is underpinned (i) by a parametric model based on pairwise\ninteracting point processes for inference of persistence diagrams and (ii) by a\nreversible jump Markov chain Monte Carlo (RJ-MCMC) algorithm for generating\nsamples of PDs. The parametric model combines a Dirichlet partition to capture\nspatial homogeneity of the location of points in a PD and a step function to\ncapture the pairwise interaction between them. The RJ-MCMC algorithm\nincorporates trans-dimensional addition and removal of points and\nsame-dimensional relocation of points across samples of PDs. The efficacy of\nRPDG is demonstrated via an example and a detailed comparison with other\nexisting methods is presented.\n", "versions": [{"version": "v1", "created": "Thu, 15 Apr 2021 19:33:01 GMT"}], "update_date": "2021-04-19", "authors_parsed": [["Nasrin", "Farzana", ""], ["Papamarkou", "Theodore", ""], ["Maroulas", "Vasileios", ""]]}, {"id": "2104.07748", "submitter": "Venugopal Mani", "authors": "Ramasubramanian Balasubramanian, Venugopal Mani, Abhinav Mathur,\n  Sushant Kumar, Kannan Achan", "title": "Variational Inference for Category Recommendation in E-Commerce\n  platforms", "comments": "8 pages, 3 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Category recommendation for users on an e-Commerce platform is an important\ntask as it dictates the flow of traffic through the website. It is therefore\nimportant to surface precise and diverse category recommendations to aid the\nusers' journey through the platform and to help them discover new groups of\nitems. An often understated part in category recommendation is users'\nproclivity to repeat purchases. The structure of this temporal behavior can be\nharvested for better category recommendations and in this work, we attempt to\nharness this through variational inference. Further, to enhance the variational\ninference based optimization, we initialize the optimizer at better starting\npoints through the well known Metapath2Vec algorithm. We demonstrate our\nresults on two real-world datasets and show that our model outperforms standard\nbaseline methods.\n", "versions": [{"version": "v1", "created": "Thu, 15 Apr 2021 20:09:20 GMT"}, {"version": "v2", "created": "Mon, 19 Apr 2021 02:35:14 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Balasubramanian", "Ramasubramanian", ""], ["Mani", "Venugopal", ""], ["Mathur", "Abhinav", ""], ["Kumar", "Sushant", ""], ["Achan", "Kannan", ""]]}, {"id": "2104.07749", "submitter": "Yevgen Chebotar", "authors": "Yevgen Chebotar, Karol Hausman, Yao Lu, Ted Xiao, Dmitry Kalashnikov,\n  Jake Varley, Alex Irpan, Benjamin Eysenbach, Ryan Julian, Chelsea Finn,\n  Sergey Levine", "title": "Actionable Models: Unsupervised Offline Reinforcement Learning of\n  Robotic Skills", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of learning useful robotic skills from previously\ncollected offline data without access to manually specified rewards or\nadditional online exploration, a setting that is becoming increasingly\nimportant for scaling robot learning by reusing past robotic data. In\nparticular, we propose the objective of learning a functional understanding of\nthe environment by learning to reach any goal state in a given dataset. We\nemploy goal-conditioned Q-learning with hindsight relabeling and develop\nseveral techniques that enable training in a particularly challenging offline\nsetting. We find that our method can operate on high-dimensional camera images\nand learn a variety of skills on real robots that generalize to previously\nunseen scenes and objects. We also show that our method can learn to reach\nlong-horizon goals across multiple episodes through goal chaining, and learn\nrich representations that can help with downstream tasks through pre-training\nor auxiliary objectives. The videos of our experiments can be found at\nhttps://actionable-models.github.io\n", "versions": [{"version": "v1", "created": "Thu, 15 Apr 2021 20:10:11 GMT"}, {"version": "v2", "created": "Wed, 28 Apr 2021 04:54:07 GMT"}, {"version": "v3", "created": "Thu, 10 Jun 2021 23:54:34 GMT"}], "update_date": "2021-06-14", "authors_parsed": [["Chebotar", "Yevgen", ""], ["Hausman", "Karol", ""], ["Lu", "Yao", ""], ["Xiao", "Ted", ""], ["Kalashnikov", "Dmitry", ""], ["Varley", "Jake", ""], ["Irpan", "Alex", ""], ["Eysenbach", "Benjamin", ""], ["Julian", "Ryan", ""], ["Finn", "Chelsea", ""], ["Levine", "Sergey", ""]]}, {"id": "2104.07761", "submitter": "Joshua Blumenstock", "authors": "Guanghua Chi, Han Fang, Sourav Chatterjee, Joshua E. Blumenstock", "title": "Micro-Estimates of Wealth for all Low- and Middle-Income Countries", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.GN cs.CY cs.LG q-fin.EC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many critical policy decisions, from strategic investments to the allocation\nof humanitarian aid, rely on data about the geographic distribution of wealth\nand poverty. Yet many poverty maps are out of date or exist only at very coarse\nlevels of granularity. Here we develop the first micro-estimates of wealth and\npoverty that cover the populated surface of all 135 low and middle-income\ncountries (LMICs) at 2.4km resolution. The estimates are built by applying\nmachine learning algorithms to vast and heterogeneous data from satellites,\nmobile phone networks, topographic maps, as well as aggregated and\nde-identified connectivity data from Facebook. We train and calibrate the\nestimates using nationally-representative household survey data from 56 LMICs,\nthen validate their accuracy using four independent sources of household survey\ndata from 18 countries. We also provide confidence intervals for each\nmicro-estimate to facilitate responsible downstream use. These estimates are\nprovided free for public use in the hope that they enable targeted policy\nresponse to the COVID-19 pandemic, provide the foundation for new insights into\nthe causes and consequences of economic development and growth, and promote\nresponsible policymaking in support of the Sustainable Development Goals.\n", "versions": [{"version": "v1", "created": "Thu, 15 Apr 2021 20:37:46 GMT"}], "update_date": "2021-04-19", "authors_parsed": [["Chi", "Guanghua", ""], ["Fang", "Han", ""], ["Chatterjee", "Sourav", ""], ["Blumenstock", "Joshua E.", ""]]}, {"id": "2104.07762", "submitter": "Sarthak Jain", "authors": "Eric Lehman, Sarthak Jain, Karl Pichotta, Yoav Goldberg, Byron C.\n  Wallace", "title": "Does BERT Pretrained on Clinical Notes Reveal Sensitive Data?", "comments": "NAACL Camera Ready Submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large Transformers pretrained over clinical notes from Electronic Health\nRecords (EHR) have afforded substantial gains in performance on predictive\nclinical tasks. The cost of training such models (and the necessity of data\naccess to do so) coupled with their utility motivates parameter sharing, i.e.,\nthe release of pretrained models such as ClinicalBERT. While most efforts have\nused deidentified EHR, many researchers have access to large sets of sensitive,\nnon-deidentified EHR with which they might train a BERT model (or similar).\nWould it be safe to release the weights of such a model if they did? In this\nwork, we design a battery of approaches intended to recover Personal Health\nInformation (PHI) from a trained BERT. Specifically, we attempt to recover\npatient names and conditions with which they are associated. We find that\nsimple probing methods are not able to meaningfully extract sensitive\ninformation from BERT trained over the MIMIC-III corpus of EHR. However, more\nsophisticated \"attacks\" may succeed in doing so: To facilitate such research,\nwe make our experimental setup and baseline probing models available at\nhttps://github.com/elehman16/exposing_patient_data_release\n", "versions": [{"version": "v1", "created": "Thu, 15 Apr 2021 20:40:05 GMT"}, {"version": "v2", "created": "Thu, 22 Apr 2021 22:57:03 GMT"}], "update_date": "2021-04-26", "authors_parsed": [["Lehman", "Eric", ""], ["Jain", "Sarthak", ""], ["Pichotta", "Karl", ""], ["Goldberg", "Yoav", ""], ["Wallace", "Byron C.", ""]]}, {"id": "2104.07767", "submitter": "Menglin Jia", "authors": "Menglin Jia, Zuxuan Wu, Austin Reiter, Claire Cardie, Serge Belongie,\n  Ser-Nam Lim", "title": "Exploring Visual Engagement Signals for Representation Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Visual engagement in social media platforms comprises interactions with photo\nposts including comments, shares, and likes. In this paper, we leverage such\nvisual engagement clues as supervisory signals for representation learning.\nHowever, learning from engagement signals is non-trivial as it is not clear how\nto bridge the gap between low-level visual information and high-level social\ninteractions. We present VisE, a weakly supervised learning approach, which\nmaps social images to pseudo labels derived by clustered engagement signals. We\nthen study how models trained in this way benefit subjective downstream\ncomputer vision tasks such as emotion recognition or political bias detection.\nThrough extensive studies, we empirically demonstrate the effectiveness of VisE\nacross a diverse set of classification tasks beyond the scope of conventional\nrecognition.\n", "versions": [{"version": "v1", "created": "Thu, 15 Apr 2021 20:50:40 GMT"}], "update_date": "2021-04-19", "authors_parsed": [["Jia", "Menglin", ""], ["Wu", "Zuxuan", ""], ["Reiter", "Austin", ""], ["Cardie", "Claire", ""], ["Belongie", "Serge", ""], ["Lim", "Ser-Nam", ""]]}, {"id": "2104.07770", "submitter": "Haojin Yang", "authors": "Haojin Yang, Zhen Shen, Yucheng Zhao", "title": "AsymmNet: Towards ultralight convolution neural networks using\n  asymmetrical bottlenecks", "comments": "MAI@CVPR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deep convolutional neural networks (CNN) have achieved astonishing results in\na large variety of applications. However, using these models on mobile or\nembedded devices is difficult due to the limited memory and computation\nresources. Recently, the inverted residual block becomes the dominating\nsolution for the architecture design of compact CNNs. In this work, we\ncomprehensively investigated the existing design concepts, rethink the\nfunctional characteristics of two pointwise convolutions in the inverted\nresiduals. We propose a novel design, called asymmetrical bottlenecks.\nPrecisely, we adjust the first pointwise convolution dimension, enrich the\ninformation flow by feature reuse, and migrate saved computations to the second\npointwise convolution. By doing so we can further improve the accuracy without\nincreasing the computation overhead. The asymmetrical bottlenecks can be\nadopted as a drop-in replacement for the existing CNN blocks. We can thus\ncreate AsymmNet by easily stack those blocks according to proper depth and\nwidth conditions. Extensive experiments demonstrate that our proposed block\ndesign is more beneficial than the original inverted residual bottlenecks for\nmobile networks, especially useful for those ultralight CNNs within the regime\nof <220M MAdds. Code is available at https://github.com/Spark001/AsymmNet\n", "versions": [{"version": "v1", "created": "Thu, 15 Apr 2021 20:58:39 GMT"}], "update_date": "2021-04-19", "authors_parsed": [["Yang", "Haojin", ""], ["Shen", "Zhen", ""], ["Zhao", "Yucheng", ""]]}, {"id": "2104.07785", "submitter": "A. Ben Hamza", "authors": "Ibrahim Salim and A. Ben Hamza", "title": "Ridge Regression Neural Network for Pediatric Bone Age Assessment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Bone age is an important measure for assessing the skeletal and biological\nmaturity of children. Delayed or increased bone age is a serious concern for\npediatricians, and needs to be accurately assessed in a bid to determine\nwhether bone maturity is occurring at a rate consistent with chronological age.\nIn this paper, we introduce a unified deep learning framework for bone age\nassessment using instance segmentation and ridge regression. The proposed\napproach consists of two integrated stages. In the first stage, we employ an\nimage annotation and segmentation model to annotate and segment the hand from\nthe radiographic image, followed by background removal. In the second stage, we\ndesign a regression neural network architecture composed of a pre-trained\nconvolutional neural network for learning salient features from the segmented\npediatric hand radiographs and a ridge regression output layer for predicting\nthe bone age. Experimental evaluation on a dataset of hand radiographs\ndemonstrates the competitive performance of our approach in comparison with\nexisting deep learning based methods for bone age assessment.\n", "versions": [{"version": "v1", "created": "Thu, 15 Apr 2021 21:38:22 GMT"}], "update_date": "2021-04-19", "authors_parsed": [["Salim", "Ibrahim", ""], ["Hamza", "A. Ben", ""]]}, {"id": "2104.07787", "submitter": "Daniel Hernandez Diaz", "authors": "Daniel Hernandez Diaz, Siyang Qin, Reeve Ingle, Yasuhisa Fujii,\n  Alessandro Bissacco", "title": "Rethinking Text Line Recognition Models", "comments": "11 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we study the problem of text line recognition. Unlike most\napproaches targeting specific domains such as scene-text or handwritten\ndocuments, we investigate the general problem of developing a universal\narchitecture that can extract text from any image, regardless of source or\ninput modality. We consider two decoder families (Connectionist Temporal\nClassification and Transformer) and three encoder modules (Bidirectional LSTMs,\nSelf-Attention, and GRCLs), and conduct extensive experiments to compare their\naccuracy and performance on widely used public datasets of scene and\nhandwritten text. We find that a combination that so far has received little\nattention in the literature, namely a Self-Attention encoder coupled with the\nCTC decoder, when compounded with an external language model and trained on\nboth public and internal data, outperforms all the others in accuracy and\ncomputational complexity. Unlike the more common Transformer-based models, this\narchitecture can handle inputs of arbitrary length, a requirement for universal\nline recognition. Using an internal dataset collected from multiple sources, we\nalso expose the limitations of current public datasets in evaluating the\naccuracy of line recognizers, as the relatively narrow image width and sequence\nlength distributions do not allow to observe the quality degradation of the\nTransformer approach when applied to the transcription of long lines.\n", "versions": [{"version": "v1", "created": "Thu, 15 Apr 2021 21:43:13 GMT"}, {"version": "v2", "created": "Wed, 21 Apr 2021 21:44:58 GMT"}], "update_date": "2021-04-23", "authors_parsed": [["Diaz", "Daniel Hernandez", ""], ["Qin", "Siyang", ""], ["Ingle", "Reeve", ""], ["Fujii", "Yasuhisa", ""], ["Bissacco", "Alessandro", ""]]}, {"id": "2104.07788", "submitter": "Benedek Rozemberczki", "authors": "Benedek Rozemberczki and Paul Scherer and Yixuan He and George\n  Panagopoulos and Alexander Riedel and Maria Astefanoaei and Oliver Kiss and\n  Ferenc Beres and Guzm\\'an L\\'opez and Nicolas Collignon and Rik Sarkar", "title": "PyTorch Geometric Temporal: Spatiotemporal Signal Processing with Neural\n  Machine Learning Models", "comments": "Source code at:\n  https://github.com/benedekrozemberczki/pytorch_geometric_temporal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.SI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present PyTorch Geometric Temporal a deep learning framework combining\nstate-of-the-art machine learning algorithms for neural spatiotemporal signal\nprocessing. The main goal of the library is to make temporal geometric deep\nlearning available for researchers and machine learning practitioners in a\nunified easy-to-use framework. PyTorch Geometric Temporal was created with\nfoundations on existing libraries in the PyTorch eco-system, streamlined neural\nnetwork layer definitions, temporal snapshot generators for batching, and\nintegrated benchmark datasets. These features are illustrated with a\ntutorial-like case study. Experiments demonstrate the predictive performance of\nthe models implemented in the library on real world problems such as\nepidemiological forecasting, ridehail demand prediction and web-traffic\nmanagement. Our sensitivity analysis of runtime shows that the framework can\npotentially operate on web-scale datasets with rich temporal features and\nspatial structure.\n", "versions": [{"version": "v1", "created": "Thu, 15 Apr 2021 21:45:57 GMT"}, {"version": "v2", "created": "Fri, 30 Apr 2021 20:23:20 GMT"}, {"version": "v3", "created": "Thu, 10 Jun 2021 19:58:36 GMT"}], "update_date": "2021-06-14", "authors_parsed": [["Rozemberczki", "Benedek", ""], ["Scherer", "Paul", ""], ["He", "Yixuan", ""], ["Panagopoulos", "George", ""], ["Riedel", "Alexander", ""], ["Astefanoaei", "Maria", ""], ["Kiss", "Oliver", ""], ["Beres", "Ferenc", ""], ["L\u00f3pez", "Guzm\u00e1n", ""], ["Collignon", "Nicolas", ""], ["Sarkar", "Rik", ""]]}, {"id": "2104.07789", "submitter": "Danushka Bollegala", "authors": "Michael Abaho, Danushka Bollegala, Paula Williamson, Susanna Dodd", "title": "Detect and Classify -- Joint Span Detection and Classification for\n  Health Outcomes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A health outcome is a measurement or an observation used to capture and\nassess the effect of a treatment. Automatic detection of health outcomes from\ntext would undoubtedly speed up access to evidence necessary in healthcare\ndecision making. Prior work on outcome detection has modelled this task as\neither (a) a sequence labelling task, where the goal is to detect which text\nspans describe health outcomes or (b) a classification task, where the goal is\nto classify a text into a pre-defined set of categories depending on an outcome\nthat is mentioned somewhere in that text. However, this decoupling of span\ndetection and classification is problematic from a modelling perspective and\nignores global structural correspondences between sentence-level and word-level\ninformation present in a given text. We propose a method that uses both\nword-level and sentence-level information to simultaneously perform outcome\nspan detection and outcome type classification. In addition to injecting\ncontextual information to hidden vectors, we use label attention to\nappropriately weight both word-level and sentence-level information.\nExperimental results on several benchmark datasets for health outcome detection\nshow that our model consistently outperforms decoupled methods, reporting\ncompetitive results.\n", "versions": [{"version": "v1", "created": "Thu, 15 Apr 2021 21:47:15 GMT"}], "update_date": "2021-04-19", "authors_parsed": [["Abaho", "Michael", ""], ["Bollegala", "Danushka", ""], ["Williamson", "Paula", ""], ["Dodd", "Susanna", ""]]}, {"id": "2104.07791", "submitter": "Devis Tuia", "authors": "Devis Tuia, Jordi Munoz-Mari", "title": "Learning User's confidence for active learning", "comments": null, "journal-ref": "IEEE Transactions on Geoscience and Remote Sensing, 51(2): 872 -\n  880, 2013", "doi": "10.1109/TGRS.2012.2203605", "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  In this paper, we study the applicability of active learning in operative\nscenarios: more particularly, we consider the well-known contradiction between\nthe active learning heuristics, which rank the pixels according to their\nuncertainty, and the user's confidence in labeling, which is related to both\nthe homogeneity of the pixel context and user's knowledge of the scene. We\npropose a filtering scheme based on a classifier that learns the confidence of\nthe user in labeling, thus minimizing the queries where the user would not be\nable to provide a class for the pixel. The capacity of a model to learn the\nuser's confidence is studied in detail, also showing the effect of resolution\nis such a learning task. Experiments on two QuickBird images of different\nresolutions (with and without pansharpening) and considering committees of\nusers prove the efficiency of the filtering scheme proposed, which maximizes\nthe number of useful queries with respect to traditional active learning.\n", "versions": [{"version": "v1", "created": "Thu, 15 Apr 2021 21:54:27 GMT"}], "update_date": "2021-04-19", "authors_parsed": [["Tuia", "Devis", ""], ["Munoz-Mari", "Jordi", ""]]}, {"id": "2104.07792", "submitter": "Rishikesh Ranade", "authors": "Amir Maleki, Jan Heyse, Rishikesh Ranade, Haiyang He, Priya Kasimbeg\n  and Jay Pathak", "title": "Geometry encoding for numerical simulations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  We present a notion of geometry encoding suitable for machine learning-based\nnumerical simulation. In particular, we delineate how this notion of encoding\nis different than other encoding algorithms commonly used in other disciplines\nsuch as computer vision and computer graphics. We also present a model\ncomprised of multiple neural networks including a processor, a compressor and\nan evaluator.These parts each satisfy a particular requirement of our encoding.\nWe compare our encoding model with the analogous models in the literature\n", "versions": [{"version": "v1", "created": "Thu, 15 Apr 2021 21:56:28 GMT"}], "update_date": "2021-04-19", "authors_parsed": [["Maleki", "Amir", ""], ["Heyse", "Jan", ""], ["Ranade", "Rishikesh", ""], ["He", "Haiyang", ""], ["Kasimbeg", "Priya", ""], ["Pathak", "Jay", ""]]}, {"id": "2104.07794", "submitter": "Jiequn Han", "authors": "Jihao Long, Jiequn Han, Weinan E", "title": "An $L^2$ Analysis of Reinforcement Learning in High Dimensions with\n  Kernel and Neural Network Approximation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning (RL) algorithms based on high-dimensional function\napproximation have achieved tremendous empirical success in large-scale\nproblems with an enormous number of states. However, most analysis of such\nalgorithms gives rise to error bounds that involve either the number of states\nor the number of features. This paper considers the situation where the\nfunction approximation is made either using the kernel method or the two-layer\nneural network model, in the context of a fitted Q-iteration algorithm with\nexplicit regularization. We establish an $\\tilde{O}(H^3|\\mathcal\n{A}|^{\\frac14}n^{-\\frac14})$ bound for the optimal policy with $Hn$ samples,\nwhere $H$ is the length of each episode and $|\\mathcal {A}|$ is the size of\naction space. Our analysis hinges on analyzing the $L^2$ error of the\napproximated Q-function using $n$ data points. Even though this result still\nrequires a finite-sized action space, the error bound is independent of the\ndimensionality of the state space.\n", "versions": [{"version": "v1", "created": "Thu, 15 Apr 2021 21:59:03 GMT"}, {"version": "v2", "created": "Mon, 19 Apr 2021 00:59:11 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Long", "Jihao", ""], ["Han", "Jiequn", ""], ["E", "Weinan", ""]]}, {"id": "2104.07809", "submitter": "Sobhan Naderian", "authors": "Sobhan Naderian", "title": "A Novel Hybrid Deep Learning Approach for Non-Intrusive Load Monitoring\n  of Residential Appliance Based on Long Short Term Memory and Convolutional\n  Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SY", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Energy disaggregation or nonintrusive load monitoring (NILM), is a\nsingle-input blind source discrimination problem, aims to interpret the mains\nuser electricity consumption into appliance level measurement. This article\npresents a new approach for power disaggregation by using a deep recurrent long\nshort term memory (LSTM) network combined with convolutional neural networks\n(CNN). Deep neural networks have been shown to be a significant way for these\ntypes of problems because of their complexity and huge number of trainable\nparamters. Hybrid method that proposed in the article could significantly\nincrease the overall accuracy of NILM because it benefits from both network\nadvantages. The proposed method used sequence-to-sequence learning, where the\ninput is a window of the mains and the output is a window of the target\nappliance. The proposed deep neural network approach has been applied to\nreal-world household energy dataset \"REFIT\". The REFIT electrical load\nmeasurements dataset described in this paper includes whole house aggregate\nloads and nine individual appliance measurements at 8-second intervals per\nhouse, collected continuously over a period of two years from 20 houses around\nthe UK. The proposed method achieve significant performance, improving accuracy\nand F1-score measures by 95.93% and 80.93% ,respectively which demonstrates the\neffectiveness and superiority of the proposed approach for home energy\nmonitoring. Comparison of proposed method and other recently published method\nhas been presented and discussed based on accuracy, number of considered\nappliances and size of the deep neural network trainable parameters. The\nproposed method shows remarkable performance compare to other previous methods.\n", "versions": [{"version": "v1", "created": "Thu, 15 Apr 2021 22:34:20 GMT"}], "update_date": "2021-04-19", "authors_parsed": [["Naderian", "Sobhan", ""]]}, {"id": "2104.07810", "submitter": "Eddy Hudson", "authors": "Eddy Hudson, Garrett Warnell, Faraz Torabi, Peter Stone", "title": "Skeletal Feature Compensation for Imitation Learning with Embodiment\n  Mismatch", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Learning from demonstrations in the wild (e.g. YouTube videos) is a\ntantalizing goal in imitation learning. However, for this goal to be achieved,\nimitation learning algorithms must deal with the fact that the demonstrators\nand learners may have bodies that differ from one another. This condition --\n\"embodiment mismatch\" -- is ignored by many recent imitation learning\nalgorithms. Our proposed imitation learning technique, SILEM (\\textbf{S}keletal\nfeature compensation for \\textbf{I}mitation \\textbf{L}earning with\n\\textbf{E}mbodiment \\textbf{M}ismatch), addresses a particular type of\nembodiment mismatch by introducing a learned affine transform to compensate for\ndifferences in the skeletal features obtained from the learner and expert. We\ncreate toy domains based on PyBullet's HalfCheetah and Ant to assess SILEM's\nbenefits for this type of embodiment mismatch. We also provide qualitative and\nquantitative results on more realistic problems -- teaching simulated humanoid\nagents, including Atlas from Boston Dynamics, to walk by observing human\ndemonstrations.\n", "versions": [{"version": "v1", "created": "Thu, 15 Apr 2021 22:50:48 GMT"}], "update_date": "2021-04-19", "authors_parsed": [["Hudson", "Eddy", ""], ["Warnell", "Garrett", ""], ["Torabi", "Faraz", ""], ["Stone", "Peter", ""]]}, {"id": "2104.07814", "submitter": "Zihao He", "authors": "Zihao He, Negar Mokhberian, Antonio Camara, Andres Abeliuk, Kristina\n  Lerman", "title": "Detecting Polarized Topics in COVID-19 News Using Partisanship-aware\n  Contextualized Topic Embeddings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Growing polarization of the news media has been blamed for fanning\ndisagreement, controversy and even violence. Early identification of polarized\ntopics is thus an urgent matter that can help mitigate conflict. However,\naccurate measurement of polarization is still an open research challenge. To\naddress this gap, we propose Partisanship-aware Contextualized Topic Embeddings\n(PaCTE), a method to automatically detect polarized topics from partisan news\nsources. Specifically, we represent the ideology of a news source on a topic by\ncorpus-contextualized topic embedding utilizing a language model that has been\nfinetuned on recognizing partisanship of the news articles, and measure the\npolarization between sources using cosine similarity. We apply our method to a\ncorpus of news about COVID-19 pandemic. Extensive experiments on different news\nsources and topics demonstrate the effectiveness of our method to precisely\ncapture the topical polarization and alignment between different news sources.\nTo help clarify and validate results, we explain the polarization using the\nMoral Foundation Theory.\n", "versions": [{"version": "v1", "created": "Thu, 15 Apr 2021 23:05:52 GMT"}], "update_date": "2021-04-19", "authors_parsed": [["He", "Zihao", ""], ["Mokhberian", "Negar", ""], ["Camara", "Antonio", ""], ["Abeliuk", "Andres", ""], ["Lerman", "Kristina", ""]]}, {"id": "2104.07815", "submitter": "Trung Dang", "authors": "Trung Dang, Om Thakkar, Swaroop Ramaswamy, Rajiv Mathews, Peter Chin,\n  Fran\\c{c}oise Beaufays", "title": "A Method to Reveal Speaker Identity in Distributed ASR Training, and How\n  to Counter It", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  End-to-end Automatic Speech Recognition (ASR) models are commonly trained\nover spoken utterances using optimization methods like Stochastic Gradient\nDescent (SGD). In distributed settings like Federated Learning, model training\nrequires transmission of gradients over a network. In this work, we design the\nfirst method for revealing the identity of the speaker of a training utterance\nwith access only to a gradient. We propose Hessian-Free Gradients Matching, an\ninput reconstruction technique that operates without second derivatives of the\nloss function (required in prior works), which can be expensive to compute. We\nshow the effectiveness of our method using the DeepSpeech model architecture,\ndemonstrating that it is possible to reveal the speaker's identity with 34%\ntop-1 accuracy (51% top-5 accuracy) on the LibriSpeech dataset. Further, we\nstudy the effect of two well-known techniques, Differentially Private SGD and\nDropout, on the success of our method. We show that a dropout rate of 0.2 can\nreduce the speaker identity accuracy to 0% top-1 (0.5% top-5).\n", "versions": [{"version": "v1", "created": "Thu, 15 Apr 2021 23:15:12 GMT"}], "update_date": "2021-04-19", "authors_parsed": [["Dang", "Trung", ""], ["Thakkar", "Om", ""], ["Ramaswamy", "Swaroop", ""], ["Mathews", "Rajiv", ""], ["Chin", "Peter", ""], ["Beaufays", "Fran\u00e7oise", ""]]}, {"id": "2104.07819", "submitter": "Mohammadreza Mohseni", "authors": "Mohammadreza Mohseni, Jordan Yap, William Yolland, Majid Razmara, M\n  Stella Atkins", "title": "Out-of-Distribution Detection for Dermoscopic Image Classification", "comments": "10 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Medical image diagnosis can be achieved by deep neural networks, provided\nthere is enough varied training data for each disease class. However, a\nhitherto unknown disease class not encountered during training will inevitably\nbe misclassified, even if predicted with low probability. This problem is\nespecially important for medical image diagnosis, when an image of a hitherto\nunknown disease is presented for diagnosis, especially when the images come\nfrom the same image domain, such as dermoscopic skin images.\n  Current out-of-distribution detection algorithms act unfairly when the\nin-distribution classes are imbalanced, by favouring the most numerous disease\nin the training sets. This could lead to false diagnoses for rare cases which\nare often medically important. We developed a novel yet simple method to train\nneural networks, which enables them to classify in-distribution dermoscopic\nskin disease images and also detect novel diseases from dermoscopic images at\ntest time. We show that our BinaryHeads model not only does not hurt\nclassification balanced accuracy when the data is imbalanced, but also\nconsistently improves the balanced accuracy. We also introduce an important\nmethod to investigate the effectiveness of out-of-distribution detection\nmethods based on presence of varying amounts of out-of-distribution data, which\nmay arise in real-world settings.\n", "versions": [{"version": "v1", "created": "Thu, 15 Apr 2021 23:34:53 GMT"}, {"version": "v2", "created": "Mon, 19 Apr 2021 05:47:57 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Mohseni", "Mohammadreza", ""], ["Yap", "Jordan", ""], ["Yolland", "William", ""], ["Razmara", "Majid", ""], ["Atkins", "M Stella", ""]]}, {"id": "2104.07820", "submitter": "Muhammad Aurangzeb Ahmad", "authors": "Aloysius Lim, Ashish Singh, Jody Chiam, Carly Eckert, Vikas Kumar,\n  Muhammad Aurangzeb Ahmad, Ankur Teredesai", "title": "Machine Learning Approaches for Type 2 Diabetes Prediction and Care\n  Management", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Prediction of diabetes and its various complications has been studied in a\nnumber of settings, but a comprehensive overview of problem setting for\ndiabetes prediction and care management has not been addressed in the\nliterature. In this document we seek to remedy this omission in literature with\nan encompassing overview of diabetes complication prediction as well as\nsituating this problem in the context of real world healthcare management. We\nillustrate various problems encountered in real world clinical scenarios via\nour own experience with building and deploying such models. In this manuscript\nwe illustrate a Machine Learning (ML) framework for addressing the problem of\npredicting Type 2 Diabetes Mellitus (T2DM) together with a solution for risk\nstratification, intervention and management. These ML models align with how\nphysicians think about disease management and mitigation, which comprises these\nfour steps: Identify, Stratify, Engage, Measure.\n", "versions": [{"version": "v1", "created": "Thu, 15 Apr 2021 23:38:39 GMT"}, {"version": "v2", "created": "Thu, 29 Apr 2021 00:11:58 GMT"}], "update_date": "2021-04-30", "authors_parsed": [["Lim", "Aloysius", ""], ["Singh", "Ashish", ""], ["Chiam", "Jody", ""], ["Eckert", "Carly", ""], ["Kumar", "Vikas", ""], ["Ahmad", "Muhammad Aurangzeb", ""], ["Teredesai", "Ankur", ""]]}, {"id": "2104.07822", "submitter": "Bo Zhang", "authors": "Shuxiao Chen, Bo Zhang", "title": "Estimating and Improving Dynamic Treatment Regimes With a Time-Varying\n  Instrumental Variable", "comments": "67 pages, 9 figures, 6 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.LG econ.EM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Estimating dynamic treatment regimes (DTRs) from retrospective observational\ndata is challenging as some degree of unmeasured confounding is often expected.\nIn this work, we develop a framework of estimating properly defined \"optimal\"\nDTRs with a time-varying instrumental variable (IV) when unmeasured covariates\nconfound the treatment and outcome, rendering the potential outcome\ndistributions only partially identified. We derive a novel Bellman equation\nunder partial identification, use it to define a generic class of estimands\n(termed IV-optimal DTRs), and study the associated estimation problem. We then\nextend the IV-optimality framework to tackle the policy improvement problem,\ndelivering IV-improved DTRs that are guaranteed to perform no worse and\npotentially better than a pre-specified baseline DTR. Importantly, our\nIV-improvement framework opens up the possibility of strictly improving upon\nDTRs that are optimal under the no unmeasured confounding assumption (NUCA). We\ndemonstrate via extensive simulations the superior performance of IV-optimal\nand IV-improved DTRs over the DTRs that are optimal only under the NUCA. In a\nreal data example, we embed retrospective observational registry data into a\nnatural, two-stage experiment with noncompliance using a time-varying IV and\nestimate useful IV-optimal DTRs that assign mothers to high-level or low-level\nneonatal intensive care units based on their prognostic variables.\n", "versions": [{"version": "v1", "created": "Thu, 15 Apr 2021 23:44:39 GMT"}], "update_date": "2021-04-19", "authors_parsed": [["Chen", "Shuxiao", ""], ["Zhang", "Bo", ""]]}, {"id": "2104.07824", "submitter": "Shashank Sonkar", "authors": "Shashank Sonkar, Arzoo Katiyar and Richard G. Baraniuk", "title": "NePTuNe: Neural Powered Tucker Network for Knowledge Graph Completion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Knowledge graphs link entities through relations to provide a structured\nrepresentation of real world facts. However, they are often incomplete, because\nthey are based on only a small fraction of all plausible facts. The task of\nknowledge graph completion via link prediction aims to overcome this challenge\nby inferring missing facts represented as links between entities. Current\napproaches to link prediction leverage tensor factorization and/or deep\nlearning. Factorization methods train and deploy rapidly thanks to their small\nnumber of parameters but have limited expressiveness due to their underlying\nlinear methodology. Deep learning methods are more expressive but also\ncomputationally expensive and prone to overfitting due to their large number of\ntrainable parameters. We propose Neural Powered Tucker Network (NePTuNe), a new\nhybrid link prediction model that couples the expressiveness of deep models\nwith the speed and size of linear models. We demonstrate that NePTuNe provides\nstate-of-the-art performance on the FB15K-237 dataset and near state-of-the-art\nperformance on the WN18RR dataset.\n", "versions": [{"version": "v1", "created": "Thu, 15 Apr 2021 23:48:26 GMT"}], "update_date": "2021-04-19", "authors_parsed": [["Sonkar", "Shashank", ""], ["Katiyar", "Arzoo", ""], ["Baraniuk", "Richard G.", ""]]}, {"id": "2104.07853", "submitter": "Nariman Torkzaban", "authors": "Anousheh Gholami, Nariman Torkzaban, John S. Baras", "title": "On the Importance of Trust in Next-Generation Networked CPS Systems: An\n  AI Perspective", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.AI cs.LG cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the increasing scale, complexity, and heterogeneity of the next\ngeneration networked systems, seamless control, management, and security of\nsuch systems becomes increasingly challenging. Many diverse applications have\ndriven interest in networked systems, including large-scale distributed\nlearning, multi-agent optimization, 5G service provisioning, and network\nslicing, etc. In this paper, we propose trust as a measure to evaluate the\nstatus of network agents and improve the decision-making process. We interpret\ntrust as a relation among entities that participate in various protocols. Trust\nrelations are based on evidence created by the interactions of entities within\na protocol and may be a composite of multiple metrics such as availability,\nreliability, resilience, etc. depending on application context. We first\nelaborate on the importance of trust as a metric and then present a\nmathematical framework for trust computation and aggregation within a network.\nThen we show in practice, how trust can be integrated into network\ndecision-making processes by presenting two examples. In the first example, we\nshow how utilizing the trust evidence can improve the performance and the\nsecurity of Federated Learning. Second, we show how a 5G network resource\nprovisioning framework can be improved when augmented with a trust-aware\ndecision-making scheme. We verify the validity of our trust-based approach\nthrough simulations. Finally, we explain the challenges associated with\naggregating the trust evidence and briefly explain our ideas to tackle them.\n", "versions": [{"version": "v1", "created": "Fri, 16 Apr 2021 02:12:13 GMT"}], "update_date": "2021-04-19", "authors_parsed": [["Gholami", "Anousheh", ""], ["Torkzaban", "Nariman", ""], ["Baras", "John S.", ""]]}, {"id": "2104.07855", "submitter": "Rui Liu", "authors": "Rui Liu and Alex Olshevsky", "title": "Distributed TD(0) with Almost No Communication", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide a new non-asymptotic analysis of distributed TD(0) with linear\nfunction approximation. Our approach relies on \"one-shot averaging,\" where $N$\nagents run local copies of TD(0) and average the outcomes only once at the very\nend. We consider two models: one in which the agents interact with an\nenvironment they can observe and whose transitions depends on all of their\nactions (which we call the global state model), and one in which each agent can\nrun a local copy of an identical Markov Decision Process, which we call the\nlocal state model.\n  In the global state model, we show that the convergence rate of our\ndistributed one-shot averaging method matches the known convergence rate of\nTD(0). By contrast, the best convergence rate in the previous literature showed\na rate which, in the worst case, underperformed the non-distributed version by\n$O(N^3)$ in terms of the number of agents $N$. In the local state model, we\ndemonstrate a version of the linear time speedup phenomenon, where the\nconvergence time of the distributed process is a factor of $N$ faster than the\nconvergence time of TD(0). As far as we are aware, this is the first result\nrigorously showing benefits from parallelism for temporal difference methods.\n", "versions": [{"version": "v1", "created": "Fri, 16 Apr 2021 02:21:11 GMT"}], "update_date": "2021-04-19", "authors_parsed": [["Liu", "Rui", ""], ["Olshevsky", "Alex", ""]]}, {"id": "2104.07857", "submitter": "Samyam Rajbhandari", "authors": "Samyam Rajbhandari, Olatunji Ruwase, Jeff Rasley, Shaden Smith,\n  Yuxiong He", "title": "ZeRO-Infinity: Breaking the GPU Memory Wall for Extreme Scale Deep\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AI cs.LG cs.PF", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In the last three years, the largest dense deep learning models have grown\nover 1000x to reach hundreds of billions of parameters, while the GPU memory\nhas only grown by 5x (16 GB to 80 GB). Therefore, the growth in model scale has\nbeen supported primarily though system innovations that allow large models to\nfit in the aggregate GPU memory of multiple GPUs. However, we are getting close\nto the GPU memory wall. It requires 800 NVIDIA V100 GPUs just to fit a trillion\nparameter model for training, and such clusters are simply out of reach for\nmost data scientists. In addition, training models at that scale requires\ncomplex combinations of parallelism techniques that puts a big burden on the\ndata scientists to refactor their model.\n  In this paper we present ZeRO-Infinity, a novel heterogeneous system\ntechnology that leverages GPU, CPU, and NVMe memory to allow for unprecedented\nmodel scale on limited resources without requiring model code refactoring. At\nthe same time it achieves excellent training throughput and scalability,\nunencumbered by the limited CPU or NVMe bandwidth. ZeRO-Infinity can fit models\nwith tens and even hundreds of trillions of parameters for training on current\ngeneration GPU clusters. It can be used to fine-tune trillion parameter models\non a single NVIDIA DGX-2 node, making large models more accessible. In terms of\ntraining throughput and scalability, it sustains over 25 petaflops on 512\nNVIDIA V100 GPUs(40% of peak), while also demonstrating super linear\nscalability. An open source implementation of ZeRO-Infinity is available\nthrough DeepSpeed, a deep learning optimization library that makes distributed\ntraining easy, efficient, and effective.\n", "versions": [{"version": "v1", "created": "Fri, 16 Apr 2021 02:22:12 GMT"}], "update_date": "2021-04-19", "authors_parsed": [["Rajbhandari", "Samyam", ""], ["Ruwase", "Olatunji", ""], ["Rasley", "Jeff", ""], ["Smith", "Shaden", ""], ["He", "Yuxiong", ""]]}, {"id": "2104.07867", "submitter": "Zhuo Feng", "authors": "Zhuo Feng", "title": "SGL: Spectral Graph Learning from Measurements", "comments": "2021 ACM/IEEE Design Automation Conference (DAC)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work introduces a highly scalable spectral graph densification framework\nfor learning resistor networks with linear measurements, such as node voltages\nand currents. We prove that given $O(\\log N)$ pairs of voltage and current\nmeasurements, it is possible to recover ultra-sparse $N$-node resistor networks\nwhich can well preserve the effective resistance distances on the graph. Also,\nthe learned graphs preserve the structural (spectral) properties of the\noriginal graph, which can potentially be leveraged in many circuit design and\noptimization tasks. We show that the proposed graph learning approach is\nequivalent to solving the classical graphical Lasso problems with\nLaplacian-like precision matrices. Through extensive experiments for a variety\nof real-world test cases, we show that the proposed approach is highly scalable\nfor learning ultra-sparse resistor networks without sacrificing solution\nquality.\n", "versions": [{"version": "v1", "created": "Fri, 16 Apr 2021 03:01:15 GMT"}], "update_date": "2021-04-19", "authors_parsed": [["Feng", "Zhuo", ""]]}, {"id": "2104.07876", "submitter": "Xingxuan Zhang", "authors": "Xingxuan Zhang, Peng Cui, Renzhe Xu, Linjun Zhou, Yue He, Zheyan Shen", "title": "Deep Stable Learning for Out-Of-Distribution Generalization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Approaches based on deep neural networks have achieved striking performance\nwhen testing data and training data share similar distribution, but can\nsignificantly fail otherwise. Therefore, eliminating the impact of distribution\nshifts between training and testing data is crucial for building\nperformance-promising deep models. Conventional methods assume either the known\nheterogeneity of training data (e.g. domain labels) or the approximately equal\ncapacities of different domains. In this paper, we consider a more challenging\ncase where neither of the above assumptions holds. We propose to address this\nproblem by removing the dependencies between features via learning weights for\ntraining samples, which helps deep models get rid of spurious correlations and,\nin turn, concentrate more on the true connection between discriminative\nfeatures and labels. Extensive experiments clearly demonstrate the\neffectiveness of our method on multiple distribution generalization benchmarks\ncompared with state-of-the-art counterparts. Through extensive experiments on\ndistribution generalization benchmarks including PACS, VLCS, MNIST-M, and NICO,\nwe show the effectiveness of our method compared with state-of-the-art\ncounterparts.\n", "versions": [{"version": "v1", "created": "Fri, 16 Apr 2021 03:54:21 GMT"}], "update_date": "2021-04-19", "authors_parsed": [["Zhang", "Xingxuan", ""], ["Cui", "Peng", ""], ["Xu", "Renzhe", ""], ["Zhou", "Linjun", ""], ["He", "Yue", ""], ["Shen", "Zheyan", ""]]}, {"id": "2104.07886", "submitter": "Yingtong Dou", "authors": "Hao Peng, Ruitong Zhang, Yingtong Dou, Renyu Yang, Jingyi Zhang,\n  Philip S. Yu", "title": "Reinforced Neighborhood Selection Guided Multi-Relational Graph Neural\n  Networks", "comments": "Under review. 43 pages. Code is available at\n  https://github.com/safe-graph/RioGNN", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Graph Neural Networks (GNNs) have been widely used for the representation\nlearning of various structured graph data, typically through message passing\namong nodes by aggregating their neighborhood information via different\noperations. While promising, most existing GNNs oversimplified the complexity\nand diversity of the edges in the graph, and thus inefficient to cope with\nubiquitous heterogeneous graphs, which are typically in the form of\nmulti-relational graph representations. In this paper, we propose RioGNN, a\nnovel Reinforced, recursive and flexible neighborhood selection guided\nmulti-relational Graph Neural Network architecture, to navigate complexity of\nneural network structures whilst maintaining relation-dependent\nrepresentations. We first construct a multi-relational graph, according to the\npractical task, to reflect the heterogeneity of nodes, edges, attributes and\nlabels. To avoid the embedding over-assimilation among different types of\nnodes, we employ a label-aware neural similarity measure to ascertain the most\nsimilar neighbors based on node attributes. A reinforced relation-aware\nneighbor selection mechanism is developed to choose the most similar neighbors\nof a targeting node within a relation before aggregating all neighborhood\ninformation from different relations to obtain the eventual node embedding.\nParticularly, to improve the efficiency of neighbor selecting, we propose a new\nrecursive and scalable reinforcement learning framework with estimable depth\nand width for different scales of multi-relational graphs. RioGNN can learn\nmore discriminative node embedding with enhanced explainability due to the\nrecognition of individual importance of each relation via the filtering\nthreshold mechanism.\n", "versions": [{"version": "v1", "created": "Fri, 16 Apr 2021 04:30:06 GMT"}], "update_date": "2021-04-19", "authors_parsed": [["Peng", "Hao", ""], ["Zhang", "Ruitong", ""], ["Dou", "Yingtong", ""], ["Yang", "Renyu", ""], ["Zhang", "Jingyi", ""], ["Yu", "Philip S.", ""]]}, {"id": "2104.07892", "submitter": "Yingtong Dou", "authors": "Jianxin Li, Hao Peng, Yuwei Cao, Yingtong Dou, Hekai Zhang, Philip S.\n  Yu, Lifang He", "title": "Higher-Order Attribute-Enhancing Heterogeneous Graph Neural Networks", "comments": "Accepted by IEEE TKDE. Code is available at\n  https://github.com/RingBDStack/HAE", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Graph neural networks (GNNs) have been widely used in deep learning on\ngraphs. They can learn effective node representations that achieve superior\nperformances in graph analysis tasks such as node classification and node\nclustering. However, most methods ignore the heterogeneity in real-world\ngraphs. Methods designed for heterogeneous graphs, on the other hand, fail to\nlearn complex semantic representations because they only use meta-paths instead\nof meta-graphs. Furthermore, they cannot fully capture the content-based\ncorrelations between nodes, as they either do not use the self-attention\nmechanism or only use it to consider the immediate neighbors of each node,\nignoring the higher-order neighbors. We propose a novel Higher-order\nAttribute-Enhancing (HAE) framework that enhances node embedding in a\nlayer-by-layer manner. Under the HAE framework, we propose a Higher-order\nAttribute-Enhancing Graph Neural Network (HAEGNN) for heterogeneous network\nrepresentation learning. HAEGNN simultaneously incorporates meta-paths and\nmeta-graphs for rich, heterogeneous semantics, and leverages the self-attention\nmechanism to explore content-based nodes interactions. The unique higher-order\narchitecture of HAEGNN allows examining the first-order as well as higher-order\nneighborhoods. Moreover, HAEGNN shows good explainability as it learns the\nimportances of different meta-paths and meta-graphs. HAEGNN is also\nmemory-efficient, for it avoids per meta-path based matrix calculation.\nExperimental results not only show HAEGNN superior performance against the\nstate-of-the-art methods in node classification, node clustering, and\nvisualization, but also demonstrate its superiorities in terms of memory\nefficiency and explainability.\n", "versions": [{"version": "v1", "created": "Fri, 16 Apr 2021 04:56:38 GMT"}], "update_date": "2021-04-19", "authors_parsed": [["Li", "Jianxin", ""], ["Peng", "Hao", ""], ["Cao", "Yuwei", ""], ["Dou", "Yingtong", ""], ["Zhang", "Hekai", ""], ["Yu", "Philip S.", ""], ["He", "Lifang", ""]]}, {"id": "2104.07894", "submitter": "Zach Wood-Doughty", "authors": "Zach Wood-Doughty, Isabel Cachola, and Mark Dredze", "title": "Faithful and Plausible Explanations of Medical Code Predictions", "comments": "The first two authors contributed equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Machine learning models that offer excellent predictive performance often\nlack the interpretability necessary to support integrated human machine\ndecision-making. In clinical medicine and other high-risk settings, domain\nexperts may be unwilling to trust model predictions without explanations. Work\nin explainable AI must balance competing objectives along two different axes:\n1) Explanations must balance faithfulness to the model's decision-making with\ntheir plausibility to a domain expert. 2) Domain experts desire local\nexplanations of individual predictions and global explanations of behavior in\naggregate. We propose to train a proxy model that mimics the behavior of the\ntrained model and provides fine-grained control over these trade-offs. We\nevaluate our approach on the task of assigning ICD codes to clinical notes to\ndemonstrate that explanations from the proxy model are faithful and replicate\nthe trained model behavior.\n", "versions": [{"version": "v1", "created": "Fri, 16 Apr 2021 05:13:36 GMT"}], "update_date": "2021-04-19", "authors_parsed": [["Wood-Doughty", "Zach", ""], ["Cachola", "Isabel", ""], ["Dredze", "Mark", ""]]}, {"id": "2104.07908", "submitter": "Guoqing Zheng", "authors": "Mengzhou Xia, Guoqing Zheng, Subhabrata Mukherjee, Milad Shokouhi,\n  Graham Neubig, Ahmed Hassan Awadallah", "title": "MetaXL: Meta Representation Transformation for Low-resource\n  Cross-lingual Learning", "comments": "2021 Annual Conference of the North American Chapter of the\n  Association for Computational Linguistics (NAACL 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The combination of multilingual pre-trained representations and cross-lingual\ntransfer learning is one of the most effective methods for building functional\nNLP systems for low-resource languages. However, for extremely low-resource\nlanguages without large-scale monolingual corpora for pre-training or\nsufficient annotated data for fine-tuning, transfer learning remains an\nunder-studied and challenging task. Moreover, recent work shows that\nmultilingual representations are surprisingly disjoint across languages,\nbringing additional challenges for transfer onto extremely low-resource\nlanguages. In this paper, we propose MetaXL, a meta-learning based framework\nthat learns to transform representations judiciously from auxiliary languages\nto a target one and brings their representation spaces closer for effective\ntransfer. Extensive experiments on real-world low-resource languages - without\naccess to large-scale monolingual corpora or large amounts of labeled data -\nfor tasks like cross-lingual sentiment analysis and named entity recognition\nshow the effectiveness of our approach. Code for MetaXL is publicly available\nat github.com/microsoft/MetaXL.\n", "versions": [{"version": "v1", "created": "Fri, 16 Apr 2021 06:15:52 GMT"}], "update_date": "2021-04-19", "authors_parsed": [["Xia", "Mengzhou", ""], ["Zheng", "Guoqing", ""], ["Mukherjee", "Subhabrata", ""], ["Shokouhi", "Milad", ""], ["Neubig", "Graham", ""], ["Awadallah", "Ahmed Hassan", ""]]}, {"id": "2104.07910", "submitter": "Aashi Jain", "authors": "Aashi Jain and Taylor Berg-Kirkpatrick", "title": "An Empirical Study of Extrapolation in Text Generation with Scalar\n  Control", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We conduct an empirical evaluation of extrapolation performance when\nconditioning on scalar control inputs like desired output length, desired edit\nfrom an input sentence, and desired sentiment across three text generation\ntasks. Specifically, we examine a zero-shot setting where models are asked to\ngeneralize to ranges of control values not seen during training. We focus on\nevaluating popular embedding methods for scalar inputs, including both\nlearnable and sinusoidal embeddings, as well as simpler approaches.\nSurprisingly, our findings indicate that the simplest strategy of using scalar\ninputs directly, without further encoding, most reliably allows for successful\nextrapolation.\n", "versions": [{"version": "v1", "created": "Fri, 16 Apr 2021 06:22:24 GMT"}], "update_date": "2021-04-19", "authors_parsed": [["Jain", "Aashi", ""], ["Berg-Kirkpatrick", "Taylor", ""]]}, {"id": "2104.07917", "submitter": "Tianjin Huang", "authors": "Tianjin Huang, Yulong Pei, Vlado Menkovski and Mykola Pechenizkiy", "title": "Hop-Count Based Self-Supervised Anomaly Detection on Attributed Networks", "comments": "arXiv admin note: text overlap with arXiv:2009.14738", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent years have witnessed an upsurge of interest in the problem of anomaly\ndetection on attributed networks due to its importance in both research and\npractice. Although various approaches have been proposed to solve this problem,\ntwo major limitations exist: (1) unsupervised approaches usually work much less\nefficiently due to the lack of supervisory signal, and (2) existing anomaly\ndetection methods only use local contextual information to detect anomalous\nnodes, e.g., one- or two-hop information, but ignore the global contextual\ninformation. Since anomalous nodes differ from normal nodes in structures and\nattributes, it is intuitive that the distance between anomalous nodes and their\nneighbors should be larger than that between normal nodes and their neighbors\nif we remove the edges connecting anomalous and normal nodes. Thus, hop counts\nbased on both global and local contextual information can be served as the\nindicators of anomaly. Motivated by this intuition, we propose a hop-count\nbased model (HCM) to detect anomalies by modeling both local and global\ncontextual information. To make better use of hop counts for anomaly\nidentification, we propose to use hop counts prediction as a self-supervised\ntask. We design two anomaly scores based on the hop counts prediction via HCM\nmodel to identify anomalies. Besides, we employ Bayesian learning to train HCM\nmodel for capturing uncertainty in learned parameters and avoiding overfitting.\nExtensive experiments on real-world attributed networks demonstrate that our\nproposed model is effective in anomaly detection.\n", "versions": [{"version": "v1", "created": "Fri, 16 Apr 2021 06:43:05 GMT"}, {"version": "v2", "created": "Tue, 25 May 2021 19:14:21 GMT"}], "update_date": "2021-05-27", "authors_parsed": [["Huang", "Tianjin", ""], ["Pei", "Yulong", ""], ["Menkovski", "Vlado", ""], ["Pechenizkiy", "Mykola", ""]]}, {"id": "2104.07921", "submitter": "Hung Le", "authors": "Hung Le, Nancy F. Chen, Steven C.H. Hoi", "title": "VGNMN: Video-grounded Neural Module Network to Video-Grounded Language\n  Tasks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Neural module networks (NMN) have achieved success in image-grounded tasks\nsuch as Visual Question Answering (VQA) on synthetic images. However, very\nlimited work on NMN has been studied in the video-grounded language tasks.\nThese tasks extend the complexity of traditional visual tasks with the\nadditional visual temporal variance. Motivated by recent NMN approaches on\nimage-grounded tasks, we introduce Video-grounded Neural Module Network (VGNMN)\nto model the information retrieval process in video-grounded language tasks as\na pipeline of neural modules. VGNMN first decomposes all language components to\nexplicitly resolve any entity references and detect corresponding action-based\ninputs from the question. The detected entities and actions are used as\nparameters to instantiate neural module networks and extract visual cues from\nthe video. Our experiments show that VGNMN can achieve promising performance on\ntwo video-grounded language tasks: video QA and video-grounded dialogues.\n", "versions": [{"version": "v1", "created": "Fri, 16 Apr 2021 06:47:41 GMT"}], "update_date": "2021-04-19", "authors_parsed": [["Le", "Hung", ""], ["Chen", "Nancy F.", ""], ["Hoi", "Steven C. H.", ""]]}, {"id": "2104.07932", "submitter": "Marian-Andrei Rizoiu", "authors": "Marian-Andrei Rizoiu, Alexander Soen, Shidi Li, Pio Calderon, Leanne\n  Dong, Aditya Krishna Menon and Lexing Xie", "title": "Interval-censored Hawkes processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CE stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This work builds a novel point process and tools to use the Hawkes process\nwith interval-censored data. Such data records the aggregated counts of events\nsolely during specific time intervals -- such as the number of patients\nadmitted to the hospital or the volume of vehicles passing traffic loop\ndetectors -- and not the exact occurrence time of the events. First, we\nestablish the Mean Behavior Poisson (MBP) process, a novel Poisson process with\na direct parameter correspondence to the popular self-exciting Hawkes process.\nThe event intensity function of the MBP is the expected intensity over all\npossible Hawkes realizations with the same parameter set. We fit MBP in the\ninterval-censored setting using an interval-censored Poisson log-likelihood\n(IC-LL). We use the parameter equivalence to uncover the parameters of the\nassociated Hawkes process. Second, we introduce two novel exogenous functions\nto distinguish the exogenous from the endogenous events. We propose the\nmulti-impulse exogenous function when the exogenous events are observed as\nevent time and the latent homogeneous Poisson process exogenous function when\nthe exogenous events are presented as interval-censored volumes. Third, we\nprovide several approximation methods to estimate the intensity and compensator\nfunction of MBP when no analytical solution exists. Fourth and finally, we\nconnect the interval-censored loss of MBP to a broader class of Bregman\ndivergence-based functions. Using the connection, we show that the current\nstate of the art in popularity estimation (Hawkes Intensity Process (HIP)\n(Rizoiu et al.,2017b)) is a particular case of the MBP process. We verify our\nmodels through empirical testing on synthetic data and real-world data. We find\nthat on real-world datasets that our MBP process outperforms HIP for the task\nof popularity prediction.\n", "versions": [{"version": "v1", "created": "Fri, 16 Apr 2021 07:29:04 GMT"}, {"version": "v2", "created": "Wed, 16 Jun 2021 01:58:51 GMT"}, {"version": "v3", "created": "Fri, 23 Jul 2021 00:07:50 GMT"}], "update_date": "2021-07-26", "authors_parsed": [["Rizoiu", "Marian-Andrei", ""], ["Soen", "Alexander", ""], ["Li", "Shidi", ""], ["Calderon", "Pio", ""], ["Dong", "Leanne", ""], ["Menon", "Aditya Krishna", ""], ["Xie", "Lexing", ""]]}, {"id": "2104.07938", "submitter": "Jens Rauch", "authors": "Jens Rauch, Iyiola E. Olatunji and Megha Khosla", "title": "Achieving differential privacy for $k$-nearest neighbors based outlier\n  detection by data partitioning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.AP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  When applying outlier detection in settings where data is sensitive,\nmechanisms which guarantee the privacy of the underlying data are needed. The\n$k$-nearest neighbors ($k$-NN) algorithm is a simple and one of the most\neffective methods for outlier detection. So far, there have been no attempts\nmade to develop a differentially private ($\\epsilon$-DP) approach for $k$-NN\nbased outlier detection. Existing approaches often relax the notion of\n$\\epsilon$-DP and employ other methods than $k$-NN. We propose a method for\n$k$-NN based outlier detection by separating the procedure into a fitting step\non reference inlier data and then apply the outlier classifier to new data. We\nachieve $\\epsilon$-DP for both the fitting algorithm and the outlier classifier\nwith respect to the reference data by partitioning the dataset into a uniform\ngrid, which yields low global sensitivity. Our approach yields nearly optimal\nperformance on real-world data with varying dimensions when compared to the\nnon-private versions of $k$-NN.\n", "versions": [{"version": "v1", "created": "Fri, 16 Apr 2021 07:35:26 GMT"}], "update_date": "2021-04-19", "authors_parsed": [["Rauch", "Jens", ""], ["Olatunji", "Iyiola E.", ""], ["Khosla", "Megha", ""]]}, {"id": "2104.07963", "submitter": "Arthur Gassner", "authors": "Arthur Gassner, Claudiu Musat, Alexandru Rusu and Andreas Burg", "title": "OpenCSI: An Open-Source Dataset for Indoor Localization Using CSI-Based\n  Fingerprinting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Many applications require accurate indoor localization. Fingerprint-based\nlocalization methods propose a solution to this problem, but rely on a radio\nmap that is effort-intensive to acquire. We automate the radio map acquisition\nphase using a software-defined radio (SDR) and a wheeled robot. Furthermore, we\nopen-source a radio map acquired with our automated tool for a 3GPP Long-Term\nEvolution (LTE) wireless link. To the best of our knowledge, this is the first\npublicly available radio map containing channel state information (CSI).\nFinally, we describe first localization experiments on this radio map using a\nconvolutional neural network to regress for location coordinates.\n", "versions": [{"version": "v1", "created": "Fri, 16 Apr 2021 08:31:46 GMT"}], "update_date": "2021-04-19", "authors_parsed": [["Gassner", "Arthur", ""], ["Musat", "Claudiu", ""], ["Rusu", "Alexandru", ""], ["Burg", "Andreas", ""]]}, {"id": "2104.07972", "submitter": "Vincent Micheli", "authors": "Vincent Micheli, Fran\\c{c}ois Fleuret", "title": "Language Models are Few-Shot Butlers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Pretrained language models demonstrate strong performance in most NLP tasks\nwhen fine-tuned on small task-specific datasets. Hence, these autoregressive\nmodels constitute ideal agents to operate in text-based environments where\nlanguage understanding and generative capabilities are essential. Nonetheless,\ncollecting expert demonstrations in such environments is a time-consuming\nendeavour. We introduce a two-stage procedure to learn from a small set of\ndemonstrations and further improve by interacting with an environment. We show\nthat language models fine-tuned with only 1.2% of the expert demonstrations and\na simple reinforcement learning algorithm achieve a 51% absolute improvement in\nsuccess rate over existing methods in the ALFWorld environment.\n", "versions": [{"version": "v1", "created": "Fri, 16 Apr 2021 08:47:07 GMT"}], "update_date": "2021-04-19", "authors_parsed": [["Micheli", "Vincent", ""], ["Fleuret", "Fran\u00e7ois", ""]]}, {"id": "2104.07985", "submitter": "Georgia Papacharalampous", "authors": "Georgia Papacharalampous, Andreas Langousis", "title": "Probabilistic water demand forecasting using quantile regression\n  algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Machine and statistical learning algorithms can be reliably automated and\napplied at scale. Therefore, they can constitute a considerable asset for\ndesigning practical forecasting systems, such as those related to urban water\ndemand. Quantile regression algorithms are statistical and machine learning\nalgorithms that can provide probabilistic forecasts in a straightforward way,\nand have not been applied so far for urban water demand forecasting. In this\nwork, we aim to fill this gap by automating and extensively comparing several\nquantile-regression-based practical systems for probabilistic one-day ahead\nurban water demand forecasting. For designing the practical systems, we use\nfive individual algorithms (i.e., the quantile regression, linear boosting,\ngeneralized random forest, gradient boosting machine and quantile regression\nneural network algorithms), their mean combiner and their median combiner. The\ncomparison is conducted by exploiting a large urban water flow dataset, as well\nas several types of hydrometeorological time series (which are considered as\nexogenous predictor variables in the forecasting setting). The results mostly\nfavour the practical systems designed using the linear boosting algorithm,\nprobably due to the presence of trends in the urban water flow time series. The\nforecasts of the mean and median combiners are also found to be skilful in\ngeneral terms.\n", "versions": [{"version": "v1", "created": "Fri, 16 Apr 2021 09:17:00 GMT"}], "update_date": "2021-04-19", "authors_parsed": [["Papacharalampous", "Georgia", ""], ["Langousis", "Andreas", ""]]}, {"id": "2104.08002", "submitter": "Narendra Chaudhary", "authors": "Narendra Chaudhary, Sanchit Misra, Dhiraj Kalamkar, Alexander\n  Heinecke, Evangelos Georganas, Barukh Ziv, Menachem Adelman, Bharat Kaul", "title": "Efficient and Generic 1D Dilated Convolution Layer for Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Convolutional neural networks (CNNs) have found many applications in tasks\ninvolving two-dimensional (2D) data, such as image classification and image\nprocessing. Therefore, 2D convolution layers have been heavily optimized on\nCPUs and GPUs. However, in many applications - for example genomics and speech\nrecognition, the data can be one-dimensional (1D). Such applications can\nbenefit from optimized 1D convolution layers. In this work, we introduce our\nefficient implementation of a generic 1D convolution layer covering a wide\nrange of parameters. It is optimized for x86 CPU architectures, in particular,\nfor architectures containing Intel AVX-512 and AVX-512 BFloat16 instructions.\nWe use the LIBXSMM library's batch-reduce General Matrix Multiplication\n(BRGEMM) kernel for FP32 and BFloat16 precision. We demonstrate that our\nimplementation can achieve up to 80% efficiency on Intel Xeon Cascade Lake and\nCooper Lake CPUs. Additionally, we show the generalization capability of our\nBRGEMM based approach by achieving high efficiency across a range of\nparameters. We consistently achieve higher efficiency than the 1D convolution\nlayer with Intel oneDNN library backend for varying input tensor widths, filter\nwidths, number of channels, filters, and dilation parameters. Finally, we\ndemonstrate the performance of our optimized 1D convolution layer by utilizing\nit in the end-to-end neural network training with real genomics datasets and\nachieve up to 6.86x speedup over the oneDNN library-based implementation on\nCascade Lake CPUs. We also demonstrate the scaling with 16 sockets of\nCascade/Cooper Lake CPUs and achieve significant speedup over eight V100 GPUs\nusing a similar power envelop. In the end-to-end training, we get a speedup of\n1.41x on Cascade Lake with FP32, 1.57x on Cooper Lake with FP32, and 2.27x on\nCooper Lake with BFloat16 over eight V100 GPUs with FP32.\n", "versions": [{"version": "v1", "created": "Fri, 16 Apr 2021 09:54:30 GMT"}], "update_date": "2021-04-19", "authors_parsed": [["Chaudhary", "Narendra", ""], ["Misra", "Sanchit", ""], ["Kalamkar", "Dhiraj", ""], ["Heinecke", "Alexander", ""], ["Georganas", "Evangelos", ""], ["Ziv", "Barukh", ""], ["Adelman", "Menachem", ""], ["Kaul", "Bharat", ""]]}, {"id": "2104.08009", "submitter": "Andreas Kurth", "authors": "Andreas Kurth, Fabian Schuiki, Luca Benini", "title": "Implementing CNN Layers on the Manticore Cluster-Based Many-Core\n  Architecture", "comments": "Technical report. 18 pages, 4 figures, 5 algorithms", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AR cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This document presents implementations of fundamental convolutional neural\nnetwork (CNN) layers on the Manticore cluster-based many-core architecture and\ndiscusses their characteristics and trade-offs.\n", "versions": [{"version": "v1", "created": "Fri, 16 Apr 2021 10:07:28 GMT"}], "update_date": "2021-04-19", "authors_parsed": [["Kurth", "Andreas", ""], ["Schuiki", "Fabian", ""], ["Benini", "Luca", ""]]}, {"id": "2104.08020", "submitter": "Bo Zhao", "authors": "Bo Zhao, Peng Sun, Liming Fang, Tao Wang, Keyu Jiang", "title": "FedCom: A Byzantine-Robust Local Model Aggregation Rule Using Data\n  Commitment for Federated Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Federated learning (FL) is a promising privacy-preserving distributed machine\nlearning methodology that allows multiple clients (i.e., workers) to\ncollaboratively train statistical models without disclosing private training\ndata. Due to the characteristics of data remaining localized and the\nuninspected on-device training process, there may exist Byzantine workers\nlaunching data poisoning and model poisoning attacks, which would seriously\ndeteriorate model performance or prevent the model from convergence. Most of\nthe existing Byzantine-robust FL schemes are either ineffective against several\nadvanced poisoning attacks or need to centralize a public validation dataset,\nwhich is intractable in FL. Moreover, to the best of our knowledge, none of the\nexisting Byzantine-robust distributed learning methods could well exert its\npower in Non-Independent and Identically distributed (Non-IID) data among\nclients. To address these issues, we propose FedCom, a novel Byzantine-robust\nfederated learning framework by incorporating the idea of commitment from\ncryptography, which could achieve both data poisoning and model poisoning\ntolerant FL under practical Non-IID data partitions. Specifically, in FedCom,\neach client is first required to make a commitment to its local training data\ndistribution. Then, we identify poisoned datasets by comparing the Wasserstein\ndistance among commitments submitted by different clients. Furthermore, we\ndistinguish abnormal local model updates from benign ones by testing each local\nmodel's behavior on its corresponding data commitment. We conduct an extensive\nperformance evaluation of FedCom. The results demonstrate its effectiveness and\nsuperior performance compared to the state-of-the-art Byzantine-robust schemes\nin defending against typical data poisoning and model poisoning attacks under\npractical Non-IID data distributions.\n", "versions": [{"version": "v1", "created": "Fri, 16 Apr 2021 10:29:26 GMT"}], "update_date": "2021-04-19", "authors_parsed": [["Zhao", "Bo", ""], ["Sun", "Peng", ""], ["Fang", "Liming", ""], ["Wang", "Tao", ""], ["Jiang", "Keyu", ""]]}, {"id": "2104.08026", "submitter": "Dong Hu", "authors": "Dong Hu, Alex Gittens, and Malik Magdon-Ismail", "title": "NoisyCUR: An algorithm for two-cost budgeted matrix completion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Matrix completion is a ubiquitous tool in machine learning and data analysis.\nMost work in this area has focused on the number of observations necessary to\nobtain an accurate low-rank approximation. In practice, however, the cost of\nobservations is an important limiting factor, and experimentalists may have on\nhand multiple modes of observation with differing noise-vs-cost trade-offs.\nThis paper considers matrix completion subject to such constraints: a budget is\nimposed and the experimentalist's goal is to allocate this budget between two\nsampling modalities in order to recover an accurate low-rank approximation.\nSpecifically, we consider that it is possible to obtain low noise, high cost\nobservations of individual entries or high noise, low cost observations of\nentire columns. We introduce a regression-based completion algorithm for this\nsetting and experimentally verify the performance of our approach on both\nsynthetic and real data sets. When the budget is low, our algorithm outperforms\nstandard completion algorithms. When the budget is high, our algorithm has\ncomparable error to standard nuclear norm completion algorithms and requires\nmuch less computational effort.\n", "versions": [{"version": "v1", "created": "Fri, 16 Apr 2021 10:39:56 GMT"}], "update_date": "2021-04-19", "authors_parsed": [["Hu", "Dong", ""], ["Gittens", "Alex", ""], ["Magdon-Ismail", "Malik", ""]]}, {"id": "2104.08027", "submitter": "Fangyu Liu", "authors": "Fangyu Liu, Ivan Vuli\\'c, Anna Korhonen, Nigel Collier", "title": "Fast, Effective and Self-Supervised: Transforming Masked LanguageModels\n  into Universal Lexical and Sentence Encoders", "comments": "11 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Pretrained Masked Language Models (MLMs) have revolutionised NLP in recent\nyears. However, previous work has indicated that off-the-shelf MLMs are not\neffective as universal lexical or sentence encoders without further\ntask-specific fine-tuning on NLI, sentence similarity, or paraphrasing tasks\nusing annotated task data. In this work, we demonstrate that it is possible to\nturn MLMs into effective universal lexical and sentence encoders even without\nany additional data and without any supervision. We propose an extremely\nsimple, fast and effective contrastive learning technique, termed Mirror-BERT,\nwhich converts MLMs (e.g., BERT and RoBERTa) into such encoders in less than a\nminute without any additional external knowledge. Mirror-BERT relies on fully\nidentical or slightly modified string pairs as positive (i.e., synonymous)\nfine-tuning examples, and aims to maximise their similarity during identity\nfine-tuning. We report huge gains over off-the-shelf MLMs with Mirror-BERT in\nboth lexical-level and sentence-level tasks, across different domains and\ndifferent languages. Notably, in the standard sentence semantic similarity\n(STS) tasks, our self-supervised Mirror-BERT model even matches the performance\nof the task-tuned Sentence-BERT models from prior work. Finally, we delve\ndeeper into the inner workings of MLMs, and suggest some evidence on why this\nsimple approach can yield effective univeral lexical and sentence encoders.\n", "versions": [{"version": "v1", "created": "Fri, 16 Apr 2021 10:49:56 GMT"}], "update_date": "2021-04-19", "authors_parsed": [["Liu", "Fangyu", ""], ["Vuli\u0107", "Ivan", ""], ["Korhonen", "Anna", ""], ["Collier", "Nigel", ""]]}, {"id": "2104.08028", "submitter": "Asahi Ushio", "authors": "Asahi Ushio and Federico Liberatore and Jose Camacho-Collados", "title": "Back to the Basics: A Quantitative Analysis of Statistical and\n  Graph-Based Term Weighting Schemes for Keyword Extraction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Term weighting schemes are widely used in Natural Language Processing and\nInformation Retrieval. In particular, term weighting is the basis for keyword\nextraction. However, there are relatively few evaluation studies that shed\nlight about the strengths and shortcomings of each weighting scheme. In fact,\nin most cases researchers and practitioners resort to the well-known tf-idf as\ndefault, despite the existence of other suitable alternatives, including\ngraph-based models. In this paper, we perform an exhaustive and large-scale\nempirical comparison of both statistical and graph-based term weighting methods\nin the context of keyword extraction. Our analysis reveals some interesting\nfindings such as the advantages of the less-known lexical specificity with\nrespect to tf-idf, or the qualitative differences between statistical and\ngraph-based methods. Finally, based on our findings we discuss and devise some\nsuggestions for practitioners. We release our code at\nhttps://github.com/asahi417/kex .\n", "versions": [{"version": "v1", "created": "Fri, 16 Apr 2021 10:49:58 GMT"}], "update_date": "2021-04-19", "authors_parsed": [["Ushio", "Asahi", ""], ["Liberatore", "Federico", ""], ["Camacho-Collados", "Jose", ""]]}, {"id": "2104.08038", "submitter": "Iuri Frosio", "authors": "Ekta Prashnani, Orazio Gallo, Joohwan Kim, Josef Spjut, Pradeep Sen,\n  Iuri Frosio", "title": "Noise-Aware Saliency Prediction for Videos with Incomplete Gaze Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep-learning-based algorithms have led to impressive results in\nvisual-saliency prediction, but the impact of noise in training gaze data has\nbeen largely overlooked. This issue is especially relevant for videos, where\nthe gaze data tends to be incomplete, and thus noisier, compared to images.\nTherefore, we propose a noise-aware training (NAT) paradigm for visual-saliency\nprediction that quantifies the uncertainty arising from gaze data\nincompleteness and inaccuracy, and accounts for it in training. We demonstrate\nthe advantage of NAT independently of the adopted model architecture, loss\nfunction, or training dataset. Given its robustness to the noise in incomplete\ntraining datasets, NAT ushers in the possibility of designing gaze datasets\nwith fewer human subjects. We also introduce the first dataset that offers a\nvideo-game context for video-saliency research, with rich temporal semantics,\nand multiple gaze attractors per frame.\n", "versions": [{"version": "v1", "created": "Fri, 16 Apr 2021 11:32:46 GMT"}], "update_date": "2021-04-19", "authors_parsed": [["Prashnani", "Ekta", ""], ["Gallo", "Orazio", ""], ["Kim", "Joohwan", ""], ["Spjut", "Josef", ""], ["Sen", "Pradeep", ""], ["Frosio", "Iuri", ""]]}, {"id": "2104.08043", "submitter": "Andrew Lawrence", "authors": "Andrew R. Lawrence, Marcus Kaiser, Rui Sampaio, Maksim Sipos", "title": "Data Generating Process to Evaluate Causal Discovery Techniques for Time\n  Series Data", "comments": "17 pages, 9 figures, for associated code and data sets, see\n  https://github.com/causalens/cdml-neurips2020", "journal-ref": "Causal Discovery & Causality-Inspired Machine Learning Workshop at\n  Neural Information Processing Systems, 2020", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Going beyond correlations, the understanding and identification of causal\nrelationships in observational time series, an important subfield of Causal\nDiscovery, poses a major challenge. The lack of access to a well-defined ground\ntruth for real-world data creates the need to rely on synthetic data for the\nevaluation of these methods. Existing benchmarks are limited in their scope, as\nthey either are restricted to a \"static\" selection of data sets, or do not\nallow for a granular assessment of the methods' performance when commonly made\nassumptions are violated. We propose a flexible and simple to use framework for\ngenerating time series data, which is aimed at developing, evaluating, and\nbenchmarking time series causal discovery methods. In particular, the framework\ncan be used to fine tune novel methods on vast amounts of data, without\n\"overfitting\" them to a benchmark, but rather so they perform well in\nreal-world use cases. Using our framework, we evaluate prominent time series\ncausal discovery methods and demonstrate a notable degradation in performance\nwhen their assumptions are invalidated and their sensitivity to choice of\nhyperparameters. Finally, we propose future research directions and how our\nframework can support both researchers and practitioners.\n", "versions": [{"version": "v1", "created": "Fri, 16 Apr 2021 11:38:29 GMT"}], "update_date": "2021-04-19", "authors_parsed": [["Lawrence", "Andrew R.", ""], ["Kaiser", "Marcus", ""], ["Sampaio", "Rui", ""], ["Sipos", "Maksim", ""]]}, {"id": "2104.08044", "submitter": "Peilun Wu", "authors": "Peilun Wu, Fan Yan, Hui Guo", "title": "Holmes: An Efficient and Lightweight Semantic Based Anomalous Email\n  Detector", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Email threat is a serious issue for enterprise security, which consists of\nvarious malicious scenarios, such as phishing, fraud, blackmail and\nmalvertisement. Traditional anti-spam gateway commonly requires to maintain a\ngreylist to filter out unexpected emails based on suspicious vocabularies\nexisted in the mail subject and content. However, the signature-based approach\ncannot effectively discover novel and unknown suspicious emails that utilize\nvarious hot topics at present, such as COVID-19 and US election. To address the\nproblem, in this paper, we present Holmes, an efficient and lightweight\nsemantic based engine for anomalous email detection. Holmes can convert each\nevent log of email to a sentence through word embedding then extract\ninteresting items among them by novelty detection. Based on our observations,\nwe claim that, in an enterprise environment, there is a stable relation between\nsenders and receivers, but suspicious emails are commonly from unusual sources,\nwhich can be detected through the rareness selection. We evaluate the\nperformance of Holmes in a real-world enterprise environment, in which it sends\nand receives around 5,000 emails each day. As a result, Holmes can achieve a\nhigh detection rate (output around 200 suspicious emails per day) and maintain\na low false alarm rate for anomaly detection.\n", "versions": [{"version": "v1", "created": "Fri, 16 Apr 2021 11:42:10 GMT"}, {"version": "v2", "created": "Sun, 25 Apr 2021 09:23:18 GMT"}, {"version": "v3", "created": "Fri, 7 May 2021 06:47:56 GMT"}, {"version": "v4", "created": "Wed, 12 May 2021 07:24:49 GMT"}, {"version": "v5", "created": "Wed, 19 May 2021 06:51:54 GMT"}, {"version": "v6", "created": "Sat, 29 May 2021 13:35:32 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Wu", "Peilun", ""], ["Yan", "Fan", ""], ["Guo", "Hui", ""]]}, {"id": "2104.08048", "submitter": "Arkadiy Dushatskiy", "authors": "Arkadiy Dushatskiy, Tanja Alderliesten, Peter A. N. Bosman", "title": "A Novel Surrogate-assisted Evolutionary Algorithm Applied to\n  Partition-based Ensemble Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel surrogate-assisted Evolutionary Algorithm for solving\nexpensive combinatorial optimization problems. We integrate a surrogate model,\nwhich is used for fitness value estimation, into a state-of-the-art P3-like\nvariant of the Gene-Pool Optimal Mixing Algorithm (GOMEA) and adapt the\nresulting algorithm for solving non-binary combinatorial problems. We test the\nproposed algorithm on an ensemble learning problem. Ensembling several models\nis a common Machine Learning technique to achieve better performance. We\nconsider ensembles of several models trained on disjoint subsets of a dataset.\nFinding the best dataset partitioning is naturally a combinatorial non-binary\noptimization problem. Fitness function evaluations can be extremely expensive\nif complex models, such as Deep Neural Networks, are used as learners in an\nensemble. Therefore, the number of fitness function evaluations is typically\nlimited, necessitating expensive optimization techniques. In our experiments we\nuse five classification datasets from the OpenML-CC18 benchmark and\nSupport-vector Machines as learners in an ensemble. The proposed algorithm\ndemonstrates better performance than alternative approaches, including Bayesian\noptimization algorithms. It manages to find better solutions using just several\nthousand fitness function evaluations for an ensemble learning problem with up\nto 500 variables.\n", "versions": [{"version": "v1", "created": "Fri, 16 Apr 2021 11:51:18 GMT"}], "update_date": "2021-04-19", "authors_parsed": [["Dushatskiy", "Arkadiy", ""], ["Alderliesten", "Tanja", ""], ["Bosman", "Peter A. N.", ""]]}, {"id": "2104.08060", "submitter": "Danilo Numeroso", "authors": "Danilo Numeroso, Davide Bacciu", "title": "MEG: Generating Molecular Counterfactual Explanations for Deep Graph\n  Networks", "comments": "8 pages, 5 figures, to appear in the Proceedings of the 2021\n  International Joint Conference on Neural Networks (IJCNN 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Explainable AI (XAI) is a research area whose objective is to increase\ntrustworthiness and to enlighten the hidden mechanism of opaque machine\nlearning techniques. This becomes increasingly important in case such models\nare applied to the chemistry domain, for its potential impact on humans'\nhealth, e.g, toxicity analysis in pharmacology. In this paper, we present a\nnovel approach to tackle explainability of deep graph networks in the context\nof molecule property prediction t asks, named MEG (Molecular Explanation\nGenerator). We generate informative counterfactual explanations for a specific\nprediction under the form of (valid) compounds with high structural similarity\nand different predicted properties. Given a trained DGN, we train a\nreinforcement learning based generator to output counterfactual explanations.\nAt each step, MEG feeds the current candidate counterfactual into the DGN,\ncollects the prediction and uses it to reward the RL agent to guide the\nexploration. Furthermore, we restrict the action space of the agent in order to\nonly keep actions that maintain the molecule in a valid state. We discuss the\nresults showing how the model can convey non-ML experts with key insights into\nthe learning model focus in the neighbourhood of a molecule.\n", "versions": [{"version": "v1", "created": "Fri, 16 Apr 2021 12:17:19 GMT"}], "update_date": "2021-04-19", "authors_parsed": [["Numeroso", "Danilo", ""], ["Bacciu", "Davide", ""]]}, {"id": "2104.08072", "submitter": "Thomas Booth", "authors": "Thomas Booth, Bernice Akpinar, Andrei Roman, Haris Shuaib, Aysha Luis,\n  Alysha Chelliah, Ayisha Al Busaidi, Ayesha Mirchandani, Burcu Alparslan, Nina\n  Mansoor, Keyoumars Ashkan, Sebastien Ourselin, Marc Modat", "title": "Machine Learning and Glioblastoma: Treatment Response Monitoring\n  Biomarkers in 2021", "comments": null, "journal-ref": "Kia S.M. et al. (eds) Machine Learning in Clinical Neuroimaging\n  and Radiogenomics in Neuro-oncology. MLCN 2020, RNO-AI 2020. Lecture Notes in\n  Computer Science, vol 12449", "doi": "10.1007/978-3-030-66843-3_21", "report-no": null, "categories": "q-bio.QM cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The aim of the systematic review was to assess recently published studies on\ndiagnostic test accuracy of glioblastoma treatment response monitoring\nbiomarkers in adults, developed through machine learning (ML). Articles were\nsearched for using MEDLINE, EMBASE, and the Cochrane Register. Included study\nparticipants were adult patients with high grade glioma who had undergone\nstandard treatment (maximal resection, radiotherapy with concomitant and\nadjuvant temozolomide) and subsequently underwent follow-up imaging to\ndetermine treatment response status. Risk of bias and applicability was\nassessed with QUADAS 2 methodology. Contingency tables were created for\nhold-out test sets and recall, specificity, precision, F1-score, balanced\naccuracy calculated. Fifteen studies were included with 1038 patients in\ntraining sets and 233 in test sets. To determine whether there was progression\nor a mimic, the reference standard combination of follow-up imaging and\nhistopathology at re-operation was applied in 67% of studies. The small numbers\nof patient included in studies, the high risk of bias and concerns of\napplicability in the study designs (particularly in relation to the reference\nstandard and patient selection due to confounding), and the low level of\nevidence, suggest that limited conclusions can be drawn from the data. There is\nlikely good diagnostic performance of machine learning models that use MRI\nfeatures to distinguish between progression and mimics. The diagnostic\nperformance of ML using implicit features did not appear to be superior to ML\nusing explicit features. There are a range of ML-based solutions poised to\nbecome treatment response monitoring biomarkers for glioblastoma. To achieve\nthis, the development and validation of ML models require large, well-annotated\ndatasets where the potential for confounding in the study design has been\ncarefully considered.\n", "versions": [{"version": "v1", "created": "Thu, 15 Apr 2021 10:49:34 GMT"}], "update_date": "2021-04-19", "authors_parsed": [["Booth", "Thomas", ""], ["Akpinar", "Bernice", ""], ["Roman", "Andrei", ""], ["Shuaib", "Haris", ""], ["Luis", "Aysha", ""], ["Chelliah", "Alysha", ""], ["Busaidi", "Ayisha Al", ""], ["Mirchandani", "Ayesha", ""], ["Alparslan", "Burcu", ""], ["Mansoor", "Nina", ""], ["Ashkan", "Keyoumars", ""], ["Ourselin", "Sebastien", ""], ["Modat", "Marc", ""]]}, {"id": "2104.08078", "submitter": "Lukas Lange", "authors": "Lukas Lange, Jannik Str\\\"otgen, Heike Adel, Dietrich Klakow", "title": "To Share or not to Share: Predicting Sets of Sources for Model Transfer\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In low-resource settings, model transfer can help to overcome a lack of\nlabeled data for many tasks and domains. However, predicting useful transfer\nsources is a challenging problem, as even the most similar sources might lead\nto unexpected negative transfer results. Thus, ranking methods based on task\nand text similarity may not be sufficient to identify promising sources. To\ntackle this problem, we propose a method to automatically determine which and\nhow many sources should be exploited. For this, we study the effects of model\ntransfer on sequence labeling across various domains and tasks and show that\nour methods based on model similarity and support vector machines are able to\npredict promising sources, resulting in performance increases of up to 24 F1\npoints.\n", "versions": [{"version": "v1", "created": "Fri, 16 Apr 2021 12:44:40 GMT"}], "update_date": "2021-04-19", "authors_parsed": [["Lange", "Lukas", ""], ["Str\u00f6tgen", "Jannik", ""], ["Adel", "Heike", ""], ["Klakow", "Dietrich", ""]]}, {"id": "2104.08080", "submitter": "Iqbal H. Sarker", "authors": "Iqbal H. Sarker", "title": "CyberLearning: Effectiveness Analysis of Machine Learning Security\n  Modeling to Detect Cyber-Anomalies and Multi-Attacks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Detecting cyber-anomalies and attacks are becoming a rising concern these\ndays in the domain of cybersecurity. The knowledge of artificial intelligence,\nparticularly, the machine learning techniques can be used to tackle these\nissues. However, the effectiveness of a learning-based security model may vary\ndepending on the security features and the data characteristics. In this paper,\nwe present \"CyberLearning\", a machine learning-based cybersecurity modeling\nwith correlated-feature selection, and a comprehensive empirical analysis on\nthe effectiveness of various machine learning based security models. In our\nCyberLearning modeling, we take into account a binary classification model for\ndetecting anomalies, and multi-class classification model for various types of\ncyber-attacks. To build the security model, we first employ the popular ten\nmachine learning classification techniques, such as naive Bayes, Logistic\nregression, Stochastic gradient descent, K-nearest neighbors, Support vector\nmachine, Decision Tree, Random Forest, Adaptive Boosting, eXtreme Gradient\nBoosting, as well as Linear discriminant analysis. We then present the\nartificial neural network-based security model considering multiple hidden\nlayers. The effectiveness of these learning-based security models is examined\nby conducting a range of experiments utilizing the two most popular security\ndatasets, UNSW-NB15 and NSL-KDD. Overall, this paper aims to serve as a\nreference point for data-driven security modeling through our experimental\nanalysis and findings in the context of cybersecurity.\n", "versions": [{"version": "v1", "created": "Sun, 28 Mar 2021 18:47:16 GMT"}], "update_date": "2021-04-19", "authors_parsed": [["Sarker", "Iqbal H.", ""]]}, {"id": "2104.08094", "submitter": "Riccardo Presotto Mr", "authors": "Claudio Bettini, Gabriele Civitarese, Riccardo Presotto", "title": "Personalized Semi-Supervised Federated Learning for Human Activity\n  Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The most effective data-driven methods for human activities recognition (HAR)\nare based on supervised learning applied to the continuous stream of sensors\ndata. However, these methods perform well on restricted sets of activities in\ndomains for which there is a fully labeled dataset. It is still a challenge to\ncope with the intra- and inter-variability of activity execution among\ndifferent subjects in large scale real world deployment. Semi-supervised\nlearning approaches for HAR have been proposed to address the challenge of\nacquiring the large amount of labeled data that is necessary in realistic\nsettings. However, their centralised architecture incurs in the scalability and\nprivacy problems when the process involves a large number of users. Federated\nLearning (FL) is a promising paradigm to address these problems. However, the\nFL methods that have been proposed for HAR assume that the participating users\ncan always obtain labels to train their local models. In this work, we propose\nFedHAR: a novel hybrid method for HAR that combines semi-supervised and\nfederated learning. Indeed, FedHAR combines active learning and label\npropagation to semi-automatically annotate the local streams of unlabeled\nsensor data, and it relies on FL to build a global activity model in a scalable\nand privacy-aware fashion. FedHAR also includes a transfer learning strategy to\npersonalize the global model on each user. We evaluated our method on two\npublic datasets, showing that FedHAR reaches recognition rates and\npersonalization capabilities similar to state-of-the-art FL supervised\napproaches. As a major advantage, FedHAR only requires a very limited number of\nannotated data to populate a pre-trained model and a small number of active\nlearning questions that quickly decrease while using the system, leading to an\neffective and scalable solution for the data scarcity problem of HAR.\n", "versions": [{"version": "v1", "created": "Thu, 15 Apr 2021 10:24:18 GMT"}, {"version": "v2", "created": "Mon, 19 Apr 2021 12:56:03 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Bettini", "Claudio", ""], ["Civitarese", "Gabriele", ""], ["Presotto", "Riccardo", ""]]}, {"id": "2104.08096", "submitter": "Tianping Li", "authors": "Tianping Li, Zhifeng Liu, Jianping Qiao", "title": "Multiple feature fusion-based video face tracking for IoT big data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  With the advancement of IoT and artificial intelligence technologies, and the\nneed for rapid application growth in fields such as security entrance control\nand financial business trade, facial information processing has become an\nimportant means for achieving identity authentication and information security.\nIn this paper, we propose a multi-feature fusion algorithm based on integral\nhistograms and a real-time update tracking particle filtering module. First,\nedge and colour features are extracted, weighting methods are used to weight\nthe colour histogram and edge features to describe facial features, and fusion\nof colour and edge features is made adaptive by using fusion coefficients to\nimprove face tracking reliability. Then, the integral histogram is integrated\ninto the particle filtering algorithm to simplify the calculation steps of\ncomplex particles. Finally, the tracking window size is adjusted in real time\naccording to the change in the average distance from the particle centre to the\nedge of the current model and the initial model to reduce the drift problem and\nachieve stable tracking with significant changes in the target dimension. The\nresults show that the algorithm improves video tracking accuracy, simplifies\nparticle operation complexity, improves the speed, and has good\nanti-interference ability and robustness.\n", "versions": [{"version": "v1", "created": "Thu, 15 Apr 2021 07:10:13 GMT"}], "update_date": "2021-04-19", "authors_parsed": [["Li", "Tianping", ""], ["Liu", "Zhifeng", ""], ["Qiao", "Jianping", ""]]}, {"id": "2104.08100", "submitter": "Yifan Hu", "authors": "Zhao Wang, Yifan Hu, Jun Xiao, Chao Wu", "title": "Efficient Ring-topology Decentralized Federated Learning with Deep\n  Generative Models for Industrial Artificial Intelligent", "comments": "arXiv admin note: text overlap with arXiv:2010.10996", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  By leveraging deep learning based technologies, the data-driven based\napproaches have reached great success with the rapid increase of data generated\nof Industrial Indernet of Things(IIot). However, security and privacy concerns\nare obstacles for data providers in many sensitive data-driven industrial\nscenarios, such as healthcare and auto-driving. Many Federated Learning(FL)\napproaches have been proposed with DNNs for IIoT applications, these works\nstill suffer from low usability of data due to data incompleteness, low\nquality, insufficient quantity, sensitivity, etc. Therefore, we propose a\nring-topogy based decentralized federated learning(RDFL) scheme for Deep\nGenerative Models(DGMs), where DGMs is a promising solution for solving the\naforementioned data usability issues. Compare with existing IIoT FL works, our\nRDFL schemes provides communication efficiency and maintain training\nperformance to boost DGMs in target IIoT tasks. A novel ring FL topology as\nwell as a map-reduce based synchronizing method are designed in the proposed\nRDFL to improve decentralized FL performance and bandwidth utilization. In\naddition, InterPlanetary File System(IPFS) is introduced to further improve\ncommunication efficiency and FL security. Extensive experiments have been taken\nto demonstate the superiority of RDFL with either independent and identically\ndistributed(IID) datasets or non-independent and identically\ndistributed(Non-IID) datasets.\n", "versions": [{"version": "v1", "created": "Thu, 15 Apr 2021 08:09:54 GMT"}], "update_date": "2021-04-19", "authors_parsed": [["Wang", "Zhao", ""], ["Hu", "Yifan", ""], ["Xiao", "Jun", ""], ["Wu", "Chao", ""]]}, {"id": "2104.08109", "submitter": "Abanoub M. Girgis", "authors": "Abanoub M. Girgis, Hyowoon Seo, Jihong Park, Mehdi Bennis, and Jinho\n  Choi", "title": "Split Learning Meets Koopman Theory for Wireless Remote Monitoring and\n  Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Remote state monitoring over wireless is envisaged to play a pivotal role in\nenabling beyond 5G applications ranging from remote drone control to remote\nsurgery. One key challenge is to identify the system dynamics that is\nnon-linear with a large dimensional state. To obviate this issue, in this\narticle we propose to train an autoencoder whose encoder and decoder are split\nand stored at a state sensor and its remote observer, respectively. This\nautoencoder not only decreases the remote monitoring payload size by reducing\nthe state representation dimension, but also learns the system dynamics by\nlifting it via a Koopman operator, thereby allowing the observer to locally\npredict future states after training convergence. Numerical results under a\nnon-linear cart-pole environment demonstrate that the proposed split learning\nof a Koopman autoencoder can locally predict future states, and the prediction\naccuracy increases with the representation dimension and transmission power.\n", "versions": [{"version": "v1", "created": "Fri, 16 Apr 2021 13:34:01 GMT"}], "update_date": "2021-04-19", "authors_parsed": [["Girgis", "Abanoub M.", ""], ["Seo", "Hyowoon", ""], ["Park", "Jihong", ""], ["Bennis", "Mehdi", ""], ["Choi", "Jinho", ""]]}, {"id": "2104.08120", "submitter": "Subham Nagar", "authors": "Subham Nagar and Ahlad Kumar", "title": "Orthogonal Features Based EEG Signals Denoising Using Fractional and\n  Compressed One-Dimensional CNN AutoEncoder", "comments": "13 pages, 9 figures, 37 references", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a fractional one-dimensional convolutional neural network\n(CNN) autoencoder for denoising the Electroencephalogram (EEG) signals which\noften get contaminated with noise during the recording process, mostly due to\nmuscle artifacts (MA), introduced by the movement of muscles. The existing EEG\ndenoising methods make use of decomposition, thresholding and filtering\ntechniques. In the proposed approach, EEG signals are first transformed to\northogonal domain using Tchebichef moments before feeding to the proposed\narchitecture. A new hyper-parameter ($\\alpha$) is introduced which refers to\nthe fractional order with respect to which gradients are calculated during\nback-propagation. It is observed that by tuning $\\alpha$, the quality of the\nrestored signal improves significantly. Motivated by the high usage of portable\nlow energy devices which make use of compressed deep learning architectures,\nthe trainable parameters of the proposed architecture are compressed using\nrandomized singular value decomposition (RSVD) algorithm. The experiments are\nperformed on the standard EEG datasets, namely, Mendeley and Bonn. The study\nshows that the proposed fractional and compressed architecture performs better\nthan existing state-of-the-art signal denoising methods.\n", "versions": [{"version": "v1", "created": "Fri, 16 Apr 2021 13:58:05 GMT"}], "update_date": "2021-04-19", "authors_parsed": [["Nagar", "Subham", ""], ["Kumar", "Ahlad", ""]]}, {"id": "2104.08134", "submitter": "Daniel Heestermans Svendsen", "authors": "Daniel Heestermans Svendsen, Maria Piles, Jordi Mu\\~noz-Mar\\'i, David\n  Luengo, Luca Martino and Gustau Camps-Valls", "title": "Integrating Domain Knowledge in Data-driven Earth Observation with\n  Process Convolutions", "comments": null, "journal-ref": null, "doi": "10.1109/TGRS.2021.3059550", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  The modelling of Earth observation data is a challenging problem, typically\napproached by either purely mechanistic or purely data-driven methods.\nMechanistic models encode the domain knowledge and physical rules governing the\nsystem. Such models, however, need the correct specification of all\ninteractions between variables in the problem and the appropriate\nparameterization is a challenge in itself. On the other hand, machine learning\napproaches are flexible data-driven tools, able to approximate arbitrarily\ncomplex functions, but lack interpretability and struggle when data is scarce\nor in extrapolation regimes. In this paper, we argue that hybrid learning\nschemes that combine both approaches can address all these issues efficiently.\nWe introduce Gaussian process (GP) convolution models for hybrid modelling in\nEarth observation (EO) problems. We specifically propose the use of a class of\nGP convolution models called latent force models (LFMs) for EO time series\nmodelling, analysis and understanding. LFMs are hybrid models that incorporate\nphysical knowledge encoded in differential equations into a multioutput GP\nmodel. LFMs can transfer information across time-series, cope with missing\nobservations, infer explicit latent functions forcing the system, and learn\nparameterizations which are very helpful for system analysis and\ninterpretability. We consider time series of soil moisture from active (ASCAT)\nand passive (SMOS, AMSR2) microwave satellites. We show how assuming a first\norder differential equation as governing equation, the model automatically\nestimates the e-folding time or decay rate related to soil moisture persistence\nand discovers latent forces related to precipitation. The proposed hybrid\nmethodology reconciles the two main approaches in remote sensing parameter\nestimation by blending statistical learning and mechanistic modeling.\n", "versions": [{"version": "v1", "created": "Fri, 16 Apr 2021 14:30:40 GMT"}], "update_date": "2021-04-19", "authors_parsed": [["Svendsen", "Daniel Heestermans", ""], ["Piles", "Maria", ""], ["Mu\u00f1oz-Mar\u00ed", "Jordi", ""], ["Luengo", "David", ""], ["Martino", "Luca", ""], ["Camps-Valls", "Gustau", ""]]}, {"id": "2104.08135", "submitter": "Yue Ren", "authors": "Guido Mont\\'ufar and Yue Ren and Leon Zhang", "title": "Sharp bounds for the number of regions of maxout networks and vertices\n  of Minkowski sums", "comments": "25 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.DM cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present results on the number of linear regions of the functions that can\nbe represented by artificial feedforward neural networks with maxout units. A\nrank-k maxout unit is a function computing the maximum of $k$ linear functions.\nFor networks with a single layer of maxout units, the linear regions correspond\nto the upper vertices of a Minkowski sum of polytopes. We obtain face counting\nformulas in terms of the intersection posets of tropical hypersurfaces or the\nnumber of upper faces of partial Minkowski sums, along with explicit sharp\nupper bounds for the number of regions for any input dimension, any number of\nunits, and any ranks, in the cases with and without biases. Based on these\nresults we also obtain asymptotically sharp upper bounds for networks with\nmultiple layers.\n", "versions": [{"version": "v1", "created": "Fri, 16 Apr 2021 14:33:21 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Mont\u00fafar", "Guido", ""], ["Ren", "Yue", ""], ["Zhang", "Leon", ""]]}, {"id": "2104.08142", "submitter": "Joe Stacey", "authors": "Joe Stacey, Yonatan Belinkov and Marek Rei", "title": "Natural Language Inference with a Human Touch: Using Human Explanations\n  to Guide Model Attention", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Natural Language Inference (NLI) models are known to learn from biases and\nartefacts within their training data, impacting how well the models generalise\nto other unseen datasets. While previous de-biasing approaches focus on\npreventing models learning from these biases, we instead provide models with\ninformation about how a human would approach the task, with the aim of\nencouraging the model to learn features that will generalise better to\nout-of-domain datasets. Using natural language explanations, we supervise a\nmodel's attention weights to encourage more attention to be paid to the words\npresent in these explanations. For the first time, we show that training with\nhuman generated explanations can simultaneously improve performance both\nin-distribution and out-of-distribution for NLI, whereas most related work on\nrobustness involves a trade-off between the two. Training with the human\nexplanations encourages models to attend more broadly across the sentences,\npaying more attention to words in the premise and less attention to stop-words\nand punctuation. The supervised models attend to words humans believe are\nimportant, creating more robust and better performing NLI models.\n", "versions": [{"version": "v1", "created": "Fri, 16 Apr 2021 14:45:35 GMT"}], "update_date": "2021-04-19", "authors_parsed": [["Stacey", "Joe", ""], ["Belinkov", "Yonatan", ""], ["Rei", "Marek", ""]]}, {"id": "2104.08145", "submitter": "Keyur Faldu", "authors": "Keyur Faldu, Amit Sheth, Prashant Kikani, Hemang Akabari", "title": "KI-BERT: Infusing Knowledge Context for Better Language and Domain\n  Understanding", "comments": "10 pages, 4 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Contextualized entity representations learned by state-of-the-art deep\nlearning models (BERT, GPT, T5, etc) leverage the attention mechanism to learn\nthe data context. However, these models are still blind to leverage the\nknowledge context present in the knowledge graph. Knowledge context can be\nunderstood as semantics about entities, and their relationship with neighboring\nentities in knowledge graphs. We propose a novel and effective technique to\ninfuse knowledge context from knowledge graphs for conceptual and ambiguous\nentities into models based on transformer architecture. Our novel technique\nproject knowledge graph embedding in the homogeneous vector-space, introduces\nnew token-types for entities, align entity position ids, and a selective\nattention mechanism. We take BERT as a baseline model and implement\n\"KnowledgeInfused BERT\" by infusing knowledge context from ConceptNet and\nWordNet, which significantly outperforms BERT over a wide range of NLP tasks\nover eight different GLUE datasets. KI-BERT-base model even outperforms\nBERT-large for domain-specific tasks like SciTail and academic subsets of QQP,\nQNLI, and MNLI.\n", "versions": [{"version": "v1", "created": "Fri, 9 Apr 2021 16:15:31 GMT"}], "update_date": "2021-04-19", "authors_parsed": [["Faldu", "Keyur", ""], ["Sheth", "Amit", ""], ["Kikani", "Prashant", ""], ["Akabari", "Hemang", ""]]}, {"id": "2104.08147", "submitter": "Natasa Tagasovska", "authors": "Radhakrishna Achanta, Natasa Tagasovska", "title": "Uncertainty Surrogates for Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper we introduce a novel way of estimating prediction uncertainty\nin deep networks through the use of uncertainty surrogates. These surrogates\nare features of the penultimate layer of a deep network that are forced to\nmatch predefined patterns. The patterns themselves can be, among other\npossibilities, a known visual symbol. We show how our approach can be used for\nestimating uncertainty in prediction and out-of-distribution detection.\nAdditionally, the surrogates allow for interpretability of the ability of the\ndeep network to learn and at the same time lend robustness against adversarial\nattacks. Despite its simplicity, our approach is superior to the\nstate-of-the-art approaches on standard metrics as well as computational\nefficiency and ease of implementation. A wide range of experiments are\nperformed on standard datasets to prove the efficacy of our approach.\n", "versions": [{"version": "v1", "created": "Fri, 16 Apr 2021 14:50:28 GMT"}], "update_date": "2021-04-19", "authors_parsed": [["Achanta", "Radhakrishna", ""], ["Tagasovska", "Natasa", ""]]}, {"id": "2104.08153", "submitter": "Martin Stoll", "authors": "Dominik Alfke, Miriam Gondos, Lucile Peroche, Martin Stoll", "title": "An Empirical Study of Graph-Based Approaches for Semi-Supervised Time\n  Series Classification", "comments": "28 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA math.NA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Time series data play an important role in many applications and their\nanalysis reveals crucial information for understanding the underlying\nprocesses. Among the many time series learning tasks of great importance, we\nhere focus on semi-supervised learning based on a graph representation of the\ndata. Two main aspects are involved in this task. A suitable distance measure\nto evaluate the similarities between time series, and a learning method to make\npredictions based on these distances. However, the relationship between the two\naspects has never been studied systematically in the context of graph-based\nlearning. We describe four different distance measures, including (Soft) DTW\nand MPDist, a distance measure based on the Matrix Profile, as well as four\nsuccessful semi-supervised learning methods, including the graph Allen--Cahn\nmethod and a Graph Convolutional Neural Network. We then compare the\nperformance of the algorithms on binary classification data sets. In our\nfindings we compare the chosen graph-based methods using all distance measures\nand observe that the results vary strongly with respect to the accuracy. As\npredicted by the ``no free lunch'' theorem, no clear best combination to employ\nin all cases is found. Our study provides a reproducible framework for future\nwork in the direction of semi-supervised learning for time series with a focus\non graph representations.\n", "versions": [{"version": "v1", "created": "Fri, 16 Apr 2021 14:57:41 GMT"}, {"version": "v2", "created": "Thu, 24 Jun 2021 19:01:18 GMT"}], "update_date": "2021-06-28", "authors_parsed": [["Alfke", "Dominik", ""], ["Gondos", "Miriam", ""], ["Peroche", "Lucile", ""], ["Stoll", "Martin", ""]]}, {"id": "2104.08156", "submitter": "Eliane Maalouf", "authors": "Eliane Maalouf, David Ginsbourger and Niklas Linde", "title": "Fast ABC with joint generative modelling and subset simulation", "comments": "13 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel approach for solving inverse-problems with\nhigh-dimensional inputs and an expensive forward mapping. It leverages joint\ndeep generative modelling to transfer the original problem spaces to a lower\ndimensional latent space. By jointly modelling input and output variables and\nendowing the latent with a prior distribution, the fitted probabilistic model\nindirectly gives access to the approximate conditional distributions of\ninterest. Since model error and observational noise with unknown distributions\nare common in practice, we resort to likelihood-free inference with Approximate\nBayesian Computation (ABC). Our method calls on ABC by Subset Simulation to\nexplore the regions of the latent space with dissimilarities between generated\nand observed outputs below prescribed thresholds. We diagnose the diversity of\napproximate posterior solutions by monitoring the probability content of these\nregions as a function of the threshold. We further analyze the curvature of the\nresulting diagnostic curve to propose an adequate ABC threshold. When applied\nto a cross-borehole tomography example from geophysics, our approach delivers\npromising performance without using prior knowledge of the forward nor of the\nnoise distribution.\n", "versions": [{"version": "v1", "created": "Fri, 16 Apr 2021 15:03:23 GMT"}], "update_date": "2021-04-19", "authors_parsed": [["Maalouf", "Eliane", ""], ["Ginsbourger", "David", ""], ["Linde", "Niklas", ""]]}, {"id": "2104.08157", "submitter": "Robin Tu", "authors": "Robin Tu, Alexander H. Foss, Sihai D. Zhao", "title": "Capturing patterns of variation unique to a specific dataset", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ME", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Capturing patterns of variation present in a dataset is important in\nexploratory data analysis and unsupervised learning. Contrastive dimension\nreduction methods, such as contrastive principal component analysis (cPCA),\nfind patterns unique to a target dataset of interest by contrasting with a\ncarefully chosen background dataset representing unwanted or uninteresting\nvariation. However, such methods typically require a tuning parameter that\ngoverns the level of contrast, and it is unclear how to choose this parameter\nobjectively. Furthermore, it is frequently of interest to contrast against\nmultiple backgrounds, which is difficult to accomplish with existing methods.\nWe propose unique component analysis (UCA), a tuning-free method that\nidentifies low-dimensional representations of a target dataset relative to one\nor more comparison datasets. It is computationally efficient even with large\nnumbers of features. We show in several experiments that UCA with a single\nbackground dataset achieves similar results compared to cPCA with various\ntuning parameters, and that UCA with multiple individual background datasets is\nsuperior to both cPCA with any single background data and cPCA with a pooled\nbackground dataset.\n", "versions": [{"version": "v1", "created": "Fri, 16 Apr 2021 15:07:32 GMT"}], "update_date": "2021-04-19", "authors_parsed": [["Tu", "Robin", ""], ["Foss", "Alexander H.", ""], ["Zhao", "Sihai D.", ""]]}, {"id": "2104.08163", "submitter": "Peter Bloem", "authors": "Peter Bloem", "title": "Finding Motifs in Knowledge Graphs using Compression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.DS cs.LG cs.SI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We introduce a method to find network motifs in knowledge graphs. Network\nmotifs are useful patterns or meaningful subunits of the graph that recur\nfrequently. We extend the common definition of a network motif to coincide with\na basic graph pattern. We introduce an approach, inspired by recent work for\nsimple graphs, to induce these from a given knowledge graph, and show that the\nmotifs found reflect the basic structure of the graph. Specifically, we show\nthat in random graphs, no motifs are found, and that when we insert a motif\nartificially, it can be detected. Finally, we show the results of motif\ninduction on three real-world knowledge graphs.\n", "versions": [{"version": "v1", "created": "Fri, 16 Apr 2021 15:20:44 GMT"}], "update_date": "2021-04-19", "authors_parsed": [["Bloem", "Peter", ""]]}, {"id": "2104.08164", "submitter": "Nicola De Cao", "authors": "Nicola De Cao, Wilker Aziz, Ivan Titov", "title": "Editing Factual Knowledge in Language Models", "comments": "15 pages, 6 figures, 2 tables. Code at\n  https://github.com/nicola-decao/KnowledgeEditor", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The factual knowledge acquired during pretraining and stored in the\nparameters of Language Models (LM) can be useful in downstream tasks (e.g.,\nquestion answering or textual inference). However, some facts can be\nincorrectly induced or become obsolete over time. We present KnowledgeEditor, a\nmethod that can be used to edit this knowledge and, thus, fix 'bugs' or\nunexpected predictions without the need for expensive re-training or\nfine-tuning. Besides being computationally efficient, KnowledgeEditor does not\nrequire any modifications in LM pre-training (e.g., the use of meta-learning).\nIn our approach, we train a hyper-network with constrained optimization to\nmodify a fact without affecting the rest of the knowledge; the trained\nhyper-network is then used to predict the weight update at test time. We show\nKnowledgeEditor's efficacy with two popular architectures and\nknowledge-intensive tasks: i) a BERT model fine-tuned for fact-checking, and\nii) a sequence-to-sequence BART model for question answering. With our method,\nchanging a prediction on the specific wording of a query tends to result in a\nconsistent change in predictions also for its paraphrases. We show that this\ncan be further encouraged by exploiting (e.g., automatically-generated)\nparaphrases during training. Interestingly, our hyper-network can be regarded\nas a 'probe' revealing which components of a model need to be changed to\nmanipulate factual knowledge; our analysis shows that the updates tend to be\nconcentrated on a small subset of components. Code at\nhttps://github.com/nicola-decao/KnowledgeEditor\n", "versions": [{"version": "v1", "created": "Fri, 16 Apr 2021 15:24:42 GMT"}], "update_date": "2021-04-19", "authors_parsed": [["De Cao", "Nicola", ""], ["Aziz", "Wilker", ""], ["Titov", "Ivan", ""]]}, {"id": "2104.08166", "submitter": "Huibin Shen", "authors": "Anastasia Makarova, Huibin Shen, Valerio Perrone, Aaron Klein, Jean\n  Baptiste Faddoul, Andreas Krause, Matthias Seeger, Cedric Archambeau", "title": "Overfitting in Bayesian Optimization: an empirical study and\n  early-stopping solution", "comments": "Under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Tuning machine learning models with Bayesian optimization (BO) is a\nsuccessful strategy to find good hyperparameters. BO defines an iterative\nprocedure where a cross-validated metric is evaluated on promising\nhyperparameters. In practice, however, an improvement of the validation metric\nmay not translate in better predictive performance on a test set, especially\nwhen tuning models trained on small datasets. In other words, unlike\nconventional wisdom dictates, BO can overfit. In this paper, we carry out the\nfirst systematic investigation of overfitting in BO and demonstrate that this\nissue is serious, yet often overlooked in practice. We propose a novel\ncriterion to early stop BO, which aims to maintain the solution quality while\nsaving the unnecessary iterations that can lead to overfitting. Experiments on\nreal-world hyperparameter optimization problems show that our approach\neffectively meets these goals and is more adaptive comparing to baselines.\n", "versions": [{"version": "v1", "created": "Fri, 16 Apr 2021 15:26:23 GMT"}, {"version": "v2", "created": "Fri, 11 Jun 2021 14:25:25 GMT"}], "update_date": "2021-06-14", "authors_parsed": [["Makarova", "Anastasia", ""], ["Shen", "Huibin", ""], ["Perrone", "Valerio", ""], ["Klein", "Aaron", ""], ["Faddoul", "Jean Baptiste", ""], ["Krause", "Andreas", ""], ["Seeger", "Matthias", ""], ["Archambeau", "Cedric", ""]]}, {"id": "2104.08167", "submitter": "Donghan Yu", "authors": "Donghan Yu and Yiming Yang", "title": "Improving Hyper-Relational Knowledge Graph Completion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Different from traditional knowledge graphs (KGs) where facts are represented\nas entity-relation-entity triplets, hyper-relational KGs (HKGs) allow triplets\nto be associated with additional relation-entity pairs (a.k.a qualifiers) to\nconvey more complex information. How to effectively and efficiently model the\ntriplet-qualifier relationship for prediction tasks such as HKG completion is\nan open challenge for research. This paper proposes to improve the\nbest-performing method in HKG completion, namely STARE, by introducing two\nnovel revisions: (1) Replacing the computation-heavy graph neural network\nmodule with light-weight entity/relation embedding processing techniques for\nefficiency improvement without sacrificing effectiveness; (2) Adding a\nqualifier-oriented auxiliary training task for boosting the prediction power of\nour approach on HKG completion. The proposed approach consistently outperforms\nSTARE in our experiments on three benchmark datasets, with significantly\nimproved computational efficiency.\n", "versions": [{"version": "v1", "created": "Fri, 16 Apr 2021 15:26:41 GMT"}], "update_date": "2021-04-19", "authors_parsed": [["Yu", "Donghan", ""], ["Yang", "Yiming", ""]]}, {"id": "2104.08171", "submitter": "Max Cohen", "authors": "Max H. Cohen and Calin Belta", "title": "Safe Exploration in Model-based Reinforcement Learning using Control\n  Barrier Functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies the problem of developing an approximate dynamic\nprogramming (ADP) framework for learning online the value function of an\ninfinite-horizon optimal problem while obeying safety constraints expressed as\ncontrol barrier functions (CBFs). Our approach is facilitated by the\ndevelopment of a novel class of CBFs, termed Lyapunov-like CBFs (LCBFs), that\nretain the beneficial properties of CBFs for developing minimally-invasive safe\ncontrol policies while also possessing desirable Lyapunov-like qualities such\nas positive semi-definiteness. We show how these LCBFs can be used to augment a\nlearning-based control policy so as to guarantee safety and then leverage this\napproach to develop a safe exploration framework in a model-based reinforcement\nlearning setting. We demonstrate that our developed approach can handle more\ngeneral safety constraints than state-of-the-art safe ADP methods through a\nvariety of numerical examples.\n", "versions": [{"version": "v1", "created": "Fri, 16 Apr 2021 15:29:58 GMT"}], "update_date": "2021-04-19", "authors_parsed": [["Cohen", "Max H.", ""], ["Belta", "Calin", ""]]}, {"id": "2104.08178", "submitter": "Arastu Sharma", "authors": "Arastu Sharma, Rakesh Jain", "title": "Design of an Efficient, Ease-of-use and Affordable Artificial\n  Intelligence based Nucleic Acid Amplification Diagnosis Technology for\n  Tuberculosis and Multi-drug Resistant Tuberculosis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.med-ph cs.LG eess.IV physics.bio-ph physics.ins-det q-bio.QM", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Current technologies that facilitate diagnosis for simultaneous detection of\nMycobacterium tuberculosis and its resistance to first-line anti-tuberculosis\ndrugs (Isoniazid and Rifampicim) are designed for lab-based settings and are\nunaffordable for large scale testing implementations. The suitability of a TB\ndiagnosis instrument, generally required in low-resource settings, to be\nimplementable in point-of-care last mile public health centres depends on\nmanufacturing cost, ease-of-use, automation and portability. This paper\ndiscusses a portable, low-cost, machine learning automated Nucleic acid\namplification testing (NAAT) device that employs the use of a smartphone-based\nfluorescence detection using novel image processing and chromaticity detection\nalgorithms. To test the instrument, real time polymerase chain reaction (qPCR)\nexperiment on cDNA dilution spanning over two concentrations (40 ng/uL and 200\nng/uL) was performed and sensitive detection of multiplexed positive control\nassay was verified.\n", "versions": [{"version": "v1", "created": "Wed, 14 Apr 2021 20:32:39 GMT"}], "update_date": "2021-04-19", "authors_parsed": [["Sharma", "Arastu", ""], ["Jain", "Rakesh", ""]]}, {"id": "2104.08184", "submitter": "Moming Duan", "authors": "Yu Zhang, Moming Duan, Duo Liu, Li Li, Ao Ren, Xianzhang Chen, Yujuan\n  Tan, Chengliang Wang", "title": "CSAFL: A Clustered Semi-Asynchronous Federated Learning Framework", "comments": "This paper will be presented at IJCNN 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Federated learning (FL) is an emerging distributed machine learning paradigm\nthat protects privacy and tackles the problem of isolated data islands. At\npresent, there are two main communication strategies of FL: synchronous FL and\nasynchronous FL. The advantages of synchronous FL are that the model has high\nprecision and fast convergence speed. However, this synchronous communication\nstrategy has the risk that the central server waits too long for the devices,\nnamely, the straggler effect which has a negative impact on some time-critical\napplications. Asynchronous FL has a natural advantage in mitigating the\nstraggler effect, but there are threats of model quality degradation and server\ncrash. Therefore, we combine the advantages of these two strategies to propose\na clustered semi-asynchronous federated learning (CSAFL) framework. We evaluate\nCSAFL based on four imbalanced federated datasets in a non-IID setting and\ncompare CSAFL to the baseline methods. The experimental results show that CSAFL\nsignificantly improves test accuracy by more than +5% on the four datasets\ncompared to TA-FedAvg. In particular, CSAFL improves absolute test accuracy by\n+34.4% on non-IID FEMNIST compared to TA-FedAvg.\n", "versions": [{"version": "v1", "created": "Fri, 16 Apr 2021 15:51:02 GMT"}], "update_date": "2021-04-19", "authors_parsed": [["Zhang", "Yu", ""], ["Duan", "Moming", ""], ["Liu", "Duo", ""], ["Li", "Li", ""], ["Ren", "Ao", ""], ["Chen", "Xianzhang", ""], ["Tan", "Yujuan", ""], ["Wang", "Chengliang", ""]]}, {"id": "2104.08188", "submitter": "Matias Valdenegro-Toro", "authors": "Matias Valdenegro-Toro", "title": "I Find Your Lack of Uncertainty in Computer Vision Disturbing", "comments": "LatinX in CV Workshop @ CVPR 2021, full paper track, camera ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks are used for many real world applications, but often they\nhave problems estimating their own confidence. This is particularly problematic\nfor computer vision applications aimed at making high stakes decisions with\nhumans and their lives. In this paper we make a meta-analysis of the\nliterature, showing that most if not all computer vision applications do not\nuse proper epistemic uncertainty quantification, which means that these models\nignore their own limitations. We describe the consequences of using models\nwithout proper uncertainty quantification, and motivate the community to adopt\nversions of the models they use that have proper calibrated epistemic\nuncertainty, in order to enable out of distribution detection. We close the\npaper with a summary of challenges on estimating uncertainty for computer\nvision applications and recommendations.\n", "versions": [{"version": "v1", "created": "Fri, 16 Apr 2021 15:58:27 GMT"}], "update_date": "2021-04-19", "authors_parsed": [["Valdenegro-Toro", "Matias", ""]]}, {"id": "2104.08191", "submitter": "The Tien Mai", "authors": "The Tien Mai", "title": "Bayesian matrix completion with a spectral scaled Student prior:\n  theoretical guarantee and efficient sampling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study the problem of matrix completion in this paper. A spectral scaled\nStudent prior is exploited to favour the underlying low-rank structure of the\ndata matrix. Importantly, we provide a thorough theoretical investigation for\nour approach, while such an analysis is hard to obtain and limited in\ntheoretical understanding of Bayesian matrix completion. More precisely, we\nshow that our Bayesian approach enjoys a minimax-optimal oracle inequality\nwhich guarantees that our method works well under model misspecification and\nunder general sampling distribution. Interestingly, we also provide efficient\ngradient-based sampling implementations for our approach by using Langevin\nMonte Carlo which is novel in Bayesian matrix completion. More specifically, we\nshow that our algorithms are significantly faster than Gibbs sampler in this\nproblem. To illustrate the attractive features of our inference strategy, some\nnumerical simulations are conducted and an application to image inpainting is\ndemonstrated.\n", "versions": [{"version": "v1", "created": "Fri, 16 Apr 2021 16:03:43 GMT"}], "update_date": "2021-04-19", "authors_parsed": [["Mai", "The Tien", ""]]}, {"id": "2104.08194", "submitter": "Salman Khan", "authors": "Salman Khan and Fabio Cuzzolin", "title": "Spatiotemporal Deformable Models for Long-Term Complex Activity\n  Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Long-term complex activity recognition and localisation can be crucial for\nthe decision-making process of several autonomous systems, such as smart cars\nand surgical robots. Nonetheless, most current methods are designed to merely\nlocalise short-term action/activities or combinations of atomic actions that\nonly last for a few frames or seconds. In this paper, we address the problem of\nlong-term complex activity detection via a novel deformable, spatiotemporal\nparts-based model. Our framework consists of three main building blocks: (i)\naction tube detection, (ii) the modelling of the deformable geometry of parts,\nand (iii) a sparsity mechanism. Firstly, action tubes are detected in a series\nof snippets using an action tube detector. Next, a new 3D deformable RoI\npooling layer is designed for learning the flexible, deformable geometry of the\nconstellation of parts. Finally, a sparsity strategy differentiates between\nactivated and deactivate features. We also provide temporal complex activity\nannotation for the recently released ROAD autonomous driving dataset and the\nSARAS-ESAD surgical action dataset, to validate our method and show the\nadaptability of our framework to different domains. As they both contain long\nvideos portraying long-term activities they can be used as benchmarks for\nfuture work in this area.\n", "versions": [{"version": "v1", "created": "Fri, 16 Apr 2021 16:05:34 GMT"}], "update_date": "2021-04-19", "authors_parsed": [["Khan", "Salman", ""], ["Cuzzolin", "Fabio", ""]]}, {"id": "2104.08196", "submitter": "Alexandru Rinciog", "authors": "Alexandru Rinciog and Anne Meyer", "title": "Towards Standardizing Reinforcement Learning Approaches for Stochastic\n  Production Scheduling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent years have seen a rise in interest in terms of using machine learning,\nparticularly reinforcement learning (RL), for production scheduling problems of\nvarying degrees of complexity. The general approach is to break down the\nscheduling problem into a Markov Decision Process (MDP), whereupon a simulation\nimplementing the MDP is used to train an RL agent. Since existing studies rely\non (sometimes) complex simulations for which the code is unavailable, the\nexperiments presented are hard, or, in the case of stochastic environments,\nimpossible to reproduce accurately. Furthermore, there is a vast array of RL\ndesigns to choose from. To make RL methods widely applicable in production\nscheduling and work out their strength for the industry, the standardization of\nmodel descriptions - both production setup and RL design - and validation\nscheme are a prerequisite. Our contribution is threefold: First, we standardize\nthe description of production setups used in RL studies based on established\nnomenclature. Secondly, we classify RL design choices from existing\npublications. Lastly, we propose recommendations for a validation scheme\nfocusing on reproducibility and sufficient benchmarking.\n", "versions": [{"version": "v1", "created": "Fri, 16 Apr 2021 16:07:10 GMT"}], "update_date": "2021-04-19", "authors_parsed": [["Rinciog", "Alexandru", ""], ["Meyer", "Anne", ""]]}, {"id": "2104.08197", "submitter": "Anna Ivanova", "authors": "Anna A. Ivanova, John Hewitt, Noga Zaslavsky", "title": "Probing artificial neural networks: insights from neuroscience", "comments": "ICLR 2021 Workshop: How Can Findings About The Brain Improve AI\n  Systems?", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A major challenge in both neuroscience and machine learning is the\ndevelopment of useful tools for understanding complex information processing\nsystems. One such tool is probes, i.e., supervised models that relate features\nof interest to activation patterns arising in biological or artificial neural\nnetworks. Neuroscience has paved the way in using such models through numerous\nstudies conducted in recent decades. In this work, we draw insights from\nneuroscience to help guide probing research in machine learning. We highlight\ntwo important design choices for probes $-$ direction and expressivity $-$ and\nrelate these choices to research goals. We argue that specific research goals\nplay a paramount role when designing a probe and encourage future probing\nstudies to be explicit in stating these goals.\n", "versions": [{"version": "v1", "created": "Fri, 16 Apr 2021 16:13:23 GMT"}], "update_date": "2021-04-19", "authors_parsed": [["Ivanova", "Anna A.", ""], ["Hewitt", "John", ""], ["Zaslavsky", "Noga", ""]]}, {"id": "2104.08203", "submitter": "Tesfamariam M Abuhay", "authors": "Tesfamariam M. Abuhay, Adane Mamuye, Stewart Robinson, Sergey V.\n  Kovalchuk", "title": "Why Machine Learning Integrated Patient Flow Simulation?", "comments": "Proceedings of the Operational Research Society Simulation Workshop\n  2021 (SW21)", "journal-ref": "Proceedings of the Operational Research Society Simulation\n  Workshop 2021 (SW21)", "doi": "10.36819/SW21.041", "report-no": null, "categories": "cs.LG cs.AI cs.MA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Patient flow analysis can be studied from a clinical and or operational\nperspective using simulation. Traditional statistical methods such as\nstochastic distribution methods have been used to construct patient flow\nsimulation submodels such as patient inflow, Length of Stay (LoS), Cost of\nTreatment (CoT) and Clinical Pathway (CP) models. However, patient inflow\ndemonstrates seasonality, trend and variation over time. LoS, CoT and CP are\nsignificantly determined by attributes of patients and clinical and laboratory\ntest results. For this reason, patient flow simulation models constructed using\ntraditional statistical methods are criticized for ignoring heterogeneity and\ntheir contribution to personalized and value based healthcare. On the other\nhand, machine learning methods have proven to be efficient to study and predict\nadmission rate, LoS, CoT, and CP. This paper, hence, describes why coupling\nmachine learning with patient flow simulation is important and proposes a\nconceptual architecture that shows how to integrate machine learning with\npatient flow simulation.\n", "versions": [{"version": "v1", "created": "Fri, 16 Apr 2021 16:23:17 GMT"}], "update_date": "2021-04-19", "authors_parsed": [["Abuhay", "Tesfamariam M.", ""], ["Mamuye", "Adane", ""], ["Robinson", "Stewart", ""], ["Kovalchuk", "Sergey V.", ""]]}, {"id": "2104.08212", "submitter": "Karol Hausman", "authors": "Dmitry Kalashnikov, Jacob Varley, Yevgen Chebotar, Benjamin Swanson,\n  Rico Jonschkowski, Chelsea Finn, Sergey Levine, Karol Hausman", "title": "MT-Opt: Continuous Multi-Task Robotic Reinforcement Learning at Scale", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  General-purpose robotic systems must master a large repertoire of diverse\nskills to be useful in a range of daily tasks. While reinforcement learning\nprovides a powerful framework for acquiring individual behaviors, the time\nneeded to acquire each skill makes the prospect of a generalist robot trained\nwith RL daunting. In this paper, we study how a large-scale collective robotic\nlearning system can acquire a repertoire of behaviors simultaneously, sharing\nexploration, experience, and representations across tasks. In this framework\nnew tasks can be continuously instantiated from previously learned tasks\nimproving overall performance and capabilities of the system. To instantiate\nthis system, we develop a scalable and intuitive framework for specifying new\ntasks through user-provided examples of desired outcomes, devise a multi-robot\ncollective learning system for data collection that simultaneously collects\nexperience for multiple tasks, and develop a scalable and generalizable\nmulti-task deep reinforcement learning method, which we call MT-Opt. We\ndemonstrate how MT-Opt can learn a wide range of skills, including semantic\npicking (i.e., picking an object from a particular category), placing into\nvarious fixtures (e.g., placing a food item onto a plate), covering, aligning,\nand rearranging. We train and evaluate our system on a set of 12 real-world\ntasks with data collected from 7 robots, and demonstrate the performance of our\nsystem both in terms of its ability to generalize to structurally similar new\ntasks, and acquire distinct new tasks more quickly by leveraging past\nexperience. We recommend viewing the videos at\nhttps://karolhausman.github.io/mt-opt/\n", "versions": [{"version": "v1", "created": "Fri, 16 Apr 2021 16:38:02 GMT"}, {"version": "v2", "created": "Tue, 27 Apr 2021 20:06:33 GMT"}], "update_date": "2021-04-29", "authors_parsed": [["Kalashnikov", "Dmitry", ""], ["Varley", "Jacob", ""], ["Chebotar", "Yevgen", ""], ["Swanson", "Benjamin", ""], ["Jonschkowski", "Rico", ""], ["Finn", "Chelsea", ""], ["Levine", "Sergey", ""], ["Hausman", "Karol", ""]]}, {"id": "2104.08215", "submitter": "Tianlong Chen", "authors": "Tianlong Chen, Zhenyu Zhang, Xu Ouyang, Zechun Liu, Zhiqiang Shen,\n  Zhangyang Wang", "title": "\"BNN - BN = ?\": Training Binary Neural Networks without Batch\n  Normalization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Batch normalization (BN) is a key facilitator and considered essential for\nstate-of-the-art binary neural networks (BNN). However, the BN layer is costly\nto calculate and is typically implemented with non-binary parameters, leaving a\nhurdle for the efficient implementation of BNN training. It also introduces\nundesirable dependence between samples within each batch. Inspired by the\nlatest advance on Batch Normalization Free (BN-Free) training, we extend their\nframework to training BNNs, and for the first time demonstrate that BNs can be\ncompleted removed from BNN training and inference regimes. By plugging in and\ncustomizing techniques including adaptive gradient clipping, scale weight\nstandardization, and specialized bottleneck block, a BN-free BNN is capable of\nmaintaining competitive accuracy compared to its BN-based counterpart.\nExtensive experiments validate the effectiveness of our proposal across diverse\nBNN backbones and datasets. For example, after removing BNs from the\nstate-of-the-art ReActNets, it can still be trained with our proposed\nmethodology to achieve 92.08%, 68.34%, and 68.0% accuracy on CIFAR-10,\nCIFAR-100, and ImageNet respectively, with marginal performance drop\n(0.23%~0.44% on CIFAR and 1.40% on ImageNet). Codes and pre-trained models are\navailable at: https://github.com/VITA-Group/BNN_NoBN.\n", "versions": [{"version": "v1", "created": "Fri, 16 Apr 2021 16:46:57 GMT"}], "update_date": "2021-04-19", "authors_parsed": [["Chen", "Tianlong", ""], ["Zhang", "Zhenyu", ""], ["Ouyang", "Xu", ""], ["Liu", "Zechun", ""], ["Shen", "Zhiqiang", ""], ["Wang", "Zhangyang", ""]]}, {"id": "2104.08236", "submitter": "Elizabeth Barnes", "authors": "Elizabeth A. Barnes and Randal J. Barnes", "title": "Controlled abstention neural networks for identifying skillful\n  predictions for regression problems", "comments": "submitted to the Journal of Advances of Earth System Modeling", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG physics.ao-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The earth system is exceedingly complex and often chaotic in nature, making\nprediction incredibly challenging: we cannot expect to make perfect predictions\nall of the time. Instead, we look for specific states of the system that lead\nto more predictable behavior than others, often termed \"forecasts of\nopportunity\". When these opportunities are not present, scientists need\nprediction systems that are capable of saying \"I don't know.\" We introduce a\nnovel loss function, termed \"abstention loss\", that allows neural networks to\nidentify forecasts of opportunity for regression problems. The abstention loss\nworks by incorporating uncertainty in the network's prediction to identify the\nmore confident samples and abstain (say \"I don't know\") on the less confident\nsamples. The abstention loss is designed to determine the optimal abstention\nfraction, or abstain on a user-defined fraction via a PID controller. Unlike\nmany methods for attaching uncertainty to neural network predictions\npost-training, the abstention loss is applied during training to preferentially\nlearn from the more confident samples. The abstention loss is built upon a\nstandard computer science method. While the standard approach is itself a\nsimple yet powerful tool for incorporating uncertainty in regression problems,\nwe demonstrate that the abstention loss outperforms this more standard method\nfor the synthetic climate use cases explored here. The implementation of\nproposed loss function is straightforward in most network architectures\ndesigned for regression, as it only requires modification of the output layer\nand loss function.\n", "versions": [{"version": "v1", "created": "Fri, 16 Apr 2021 17:16:32 GMT"}], "update_date": "2021-04-19", "authors_parsed": [["Barnes", "Elizabeth A.", ""], ["Barnes", "Randal J.", ""]]}, {"id": "2104.08237", "submitter": "Johanna Vielhaben", "authors": "Johanna Vielhaben, Markus Wenzel, Eva Weicken, Nils Strodthoff", "title": "Predicting the Binding of SARS-CoV-2 Peptides to the Major\n  Histocompatibility Complex with Recurrent Neural Networks", "comments": "Accepted at ICLR 2021 Workshop: Machine Learning for Preventing and\n  Combating Pandemics; code available at https://github.com/nstrodt/USMPep", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predicting the binding of viral peptides to the major histocompatibility\ncomplex with machine learning can potentially extend the computational\nimmunology toolkit for vaccine development, and serve as a key component in the\nfight against a pandemic. In this work, we adapt and extend USMPep, a recently\nproposed, conceptually simple prediction algorithm based on recurrent neural\nnetworks. Most notably, we combine regressors (binding affinity data) and\nclassifiers (mass spectrometry data) from qualitatively different data sources\nto obtain a more comprehensive prediction tool. We evaluate the performance on\na recently released SARS-CoV-2 dataset with binding stability measurements.\nUSMPep not only sets new benchmarks on selected single alleles, but\nconsistently turns out to be among the best-performing methods or, for some\nmetrics, to be even the overall best-performing method for this task.\n", "versions": [{"version": "v1", "created": "Fri, 16 Apr 2021 17:16:35 GMT"}], "update_date": "2021-04-19", "authors_parsed": [["Vielhaben", "Johanna", ""], ["Wenzel", "Markus", ""], ["Weicken", "Eva", ""], ["Strodthoff", "Nils", ""]]}, {"id": "2104.08261", "submitter": "Rohan Sinha", "authors": "Rohan Sinha, James Harrison, Spencer M. Richards, Marco Pavone", "title": "Adaptive Robust Model Predictive Control with Matched and Unmatched\n  Uncertainty", "comments": "Fixed some typos", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.LG cs.RO cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a learning-based robust predictive control algorithm that can\nhandle large uncertainty in the dynamics for a class of discrete-time systems\nthat are nominally linear with an additive nonlinear dynamics component. Such\nsystems commonly model the nonlinear effects of an unknown environment on a\nnominal system. Motivated by an inability of existing learning-based predictive\ncontrol algorithms to achieve safety guarantees in the presence of\nuncertainties of large magnitude in this setting, we achieve significant\nperformance improvements by optimizing over a novel class of nonlinear feedback\npolicies inspired by certainty equivalent \"estimate-and-cancel\" control laws\npioneered in classical adaptive control. In contrast with previous work in\nrobust adaptive MPC, this allows us to take advantage of the structure in the a\npriori unknown dynamics that are learned online through function approximation.\nOur approach also extends typical nonlinear adaptive control methods to systems\nwith state and input constraints even when an additive uncertain function\ncannot directly be canceled from the dynamics. Moreover, our approach allows us\nto apply contemporary statistical estimation techniques to certify the safety\nof the system through persistent constraint satisfaction with high probability.\nWe show that our method allows us to consider larger unknown terms in the\ndynamics than existing methods through simulated examples.\n", "versions": [{"version": "v1", "created": "Fri, 16 Apr 2021 17:47:02 GMT"}, {"version": "v2", "created": "Thu, 13 May 2021 20:55:31 GMT"}], "update_date": "2021-05-17", "authors_parsed": [["Sinha", "Rohan", ""], ["Harrison", "James", ""], ["Richards", "Spencer M.", ""], ["Pavone", "Marco", ""]]}, {"id": "2104.08268", "submitter": "Akhila Yerukola", "authors": "Akhila Yerukola, Mason Bretan and Hongxia Jin", "title": "Data Augmentation for Voice-Assistant NLU using BERT-based\n  Interchangeable Rephrase", "comments": "Accepted at EACL'21", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a data augmentation technique based on byte pair encoding and a\nBERT-like self-attention model to boost performance on spoken language\nunderstanding tasks. We compare and evaluate this method with a range of\naugmentation techniques encompassing generative models such as VAEs and\nperformance-boosting techniques such as synonym replacement and\nback-translation. We show our method performs strongly on domain and intent\nclassification tasks for a voice assistant and in a user-study focused on\nutterance naturalness and semantic similarity.\n", "versions": [{"version": "v1", "created": "Fri, 16 Apr 2021 17:53:58 GMT"}], "update_date": "2021-04-19", "authors_parsed": [["Yerukola", "Akhila", ""], ["Bretan", "Mason", ""], ["Jin", "Hongxia", ""]]}, {"id": "2104.08274", "submitter": "Matthias Hofer", "authors": "Matthias Hofer, Tuan Anh Le, Roger Levy, Josh Tenenbaum", "title": "Learning Evolved Combinatorial Symbols with a Neuro-symbolic Generative\n  Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humans have the ability to rapidly understand rich combinatorial concepts\nfrom limited data. Here we investigate this ability in the context of auditory\nsignals, which have been evolved in a cultural transmission experiment to study\nthe emergence of combinatorial structure in language. We propose a\nneuro-symbolic generative model which combines the strengths of previous\napproaches to concept learning. Our model performs fast inference drawing on\nneural network methods, while still retaining the interpretability and\ngeneralization from limited data seen in structured generative approaches. This\nmodel outperforms a purely neural network-based approach on classification as\nevaluated against both ground truth and human experimental classification\npreferences, and produces superior reproductions of observed signals as well.\nOur results demonstrate the power of flexible combined neural-symbolic\narchitectures for human-like generalization in raw perceptual domains and\noffers a step towards developing precise computational models of inductive\nbiases in language evolution.\n", "versions": [{"version": "v1", "created": "Fri, 16 Apr 2021 17:57:51 GMT"}], "update_date": "2021-04-19", "authors_parsed": [["Hofer", "Matthias", ""], ["Le", "Tuan Anh", ""], ["Levy", "Roger", ""], ["Tenenbaum", "Josh", ""]]}, {"id": "2104.08281", "submitter": "Elizabeth Barnes", "authors": "Elizabeth A. Barnes and Randal J. Barnes", "title": "Controlled abstention neural networks for identifying skillful\n  predictions for classification problems", "comments": "submitted to the Journal of Advances in Earth System Modeling. arXiv\n  admin note: substantial text overlap with arXiv:2104.08236", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.ao-ph cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The earth system is exceedingly complex and often chaotic in nature, making\nprediction incredibly challenging: we cannot expect to make perfect predictions\nall of the time. Instead, we look for specific states of the system that lead\nto more predictable behavior than others, often termed \"forecasts of\nopportunity.\" When these opportunities are not present, scientists need\nprediction systems that are capable of saying \"I don't know.\" We introduce a\nnovel loss function, termed the \"NotWrong loss\", that allows neural networks to\nidentify forecasts of opportunity for classification problems. The NotWrong\nloss introduces an abstention class that allows the network to identify the\nmore confident samples and abstain (say \"I don't know\") on the less confident\nsamples. The abstention loss is designed to abstain on a user-defined fraction\nof the samples via a PID controller. Unlike many machine learning methods used\nto reject samples post-training, the NotWrong loss is applied during training\nto preferentially learn from the more confident samples. We show that the\nNotWrong loss outperforms other existing loss functions for multiple climate\nuse cases. The implementation of the proposed loss function is straightforward\nin most network architectures designed for classification as it only requires\nthe addition of an abstention class to the output layer and modification of the\nloss function.\n", "versions": [{"version": "v1", "created": "Fri, 16 Apr 2021 17:18:32 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Barnes", "Elizabeth A.", ""], ["Barnes", "Randal J.", ""]]}, {"id": "2104.08291", "submitter": "Barry Dillon", "authors": "Barry M. Dillon, Tilman Plehn, Christof Sauer, Peter Sorrenson", "title": "Better Latent Spaces for Better Autoencoders", "comments": "25 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "hep-ph cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autoencoders as tools behind anomaly searches at the LHC have the structural\nproblem that they only work in one direction, extracting jets with higher\ncomplexity but not the other way around. To address this, we derive classifiers\nfrom the latent space of (variational) autoencoders, specifically in Gaussian\nmixture and Dirichlet latent spaces. In particular, the Dirichlet setup solves\nthe problem and improves both the performance and the interpretability of the\nnetworks.\n", "versions": [{"version": "v1", "created": "Fri, 16 Apr 2021 18:00:05 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Dillon", "Barry M.", ""], ["Plehn", "Tilman", ""], ["Sauer", "Christof", ""], ["Sorrenson", "Peter", ""]]}, {"id": "2104.08308", "submitter": "Zimin Chen", "authors": "Zimin Chen, Steve Kommrusch and Martin Monperrus", "title": "Neural Transfer Learning for Repairing Security Vulnerabilities in C\n  Code", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we address the problem of automatic repair of software\nvulnerabilities with deep learning. The major problem with data-driven\nvulnerability repair is that the few existing datasets of known confirmed\nvulnerabilities consist of only a few thousand examples. However, training a\ndeep learning model often requires hundreds of thousands of examples. In this\nwork, we leverage the intuition that the bug fixing task and the vulnerability\nfixing task are related, and the knowledge learned from bug fixes can be\ntransferred to fixing vulnerabilities. In the machine learning community, this\ntechnique is called transfer learning. In this paper, we propose an approach\nfor repairing security vulnerabilities named VRepair which is based on transfer\nlearning. VRepair is first trained on a large bug fix corpus, and is then tuned\non a vulnerability fix dataset, which is an order of magnitudes smaller. In our\nexperiments, we show that a model trained only on a bug fix corpus can already\nfix some vulnerabilities. Then, we demonstrate that transfer learning improves\nthe ability to repair vulnerable C functions. In the end, we present evidence\nthat transfer learning produces more stable and superior neural models for\nvulnerability repair.\n", "versions": [{"version": "v1", "created": "Fri, 16 Apr 2021 18:32:51 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Chen", "Zimin", ""], ["Kommrusch", "Steve", ""], ["Monperrus", "Martin", ""]]}, {"id": "2104.08312", "submitter": "Amirata Ghorbani", "authors": "Amirata Ghorbani, James Zou, Andre Esteva", "title": "Data Shapley Valuation for Efficient Batch Active Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Annotating the right set of data amongst all available data points is a key\nchallenge in many machine learning applications. Batch active learning is a\npopular approach to address this, in which batches of unlabeled data points are\nselected for annotation, while an underlying learning algorithm gets\nsubsequently updated. Increasingly larger batches are particularly appealing in\nsettings where data can be annotated in parallel, and model training is\ncomputationally expensive. A key challenge here is scale - typical active\nlearning methods rely on diversity techniques, which select a diverse set of\ndata points to annotate, from an unlabeled pool. In this work, we introduce\nActive Data Shapley (ADS) -- a filtering layer for batch active learning that\nsignificantly increases the efficiency of active learning by pre-selecting,\nusing a linear time computation, the highest-value points from an unlabeled\ndataset. Using the notion of the Shapley value of data, our method estimates\nthe value of unlabeled data points with regards to the prediction task at hand.\nWe show that ADS is particularly effective when the pool of unlabeled data\nexhibits real-world caveats: noise, heterogeneity, and domain shift. We run\nexperiments demonstrating that when ADS is used to pre-select the\nhighest-ranking portion of an unlabeled dataset, the efficiency of\nstate-of-the-art batch active learning methods increases by an average factor\nof 6x, while preserving performance effectiveness.\n", "versions": [{"version": "v1", "created": "Fri, 16 Apr 2021 18:53:42 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Ghorbani", "Amirata", ""], ["Zou", "James", ""], ["Esteva", "Andre", ""]]}, {"id": "2104.08318", "submitter": "Gregory Teichert", "authors": "Gregory H. Teichert, Sambit Das, Muratahan Aykol, Chirranjeevi Gopal,\n  Vikram Gavini and Krishna Garikipati", "title": "Li$_x$CoO$_2$ phase stability studied by machine learning-enabled scale\n  bridging between electronic structure, statistical mechanics and phase field\n  theories", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cond-mat.mtrl-sci cs.LG physics.comp-ph", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Li$_xTM$O$_2$ (TM={Ni, Co, Mn}) are promising cathodes for Li-ion batteries,\nwhose electrochemical cycling performance is strongly governed by crystal\nstructure and phase stability as a function of Li content at the atomistic\nscale. Here, we use Li$_x$CoO$_2$ (LCO) as a model system to benchmark a\nscale-bridging framework that combines density functional theory (DFT)\ncalculations at the atomistic scale with phase field modeling at the continuum\nscale to understand the impact of phase stability on microstructure evolution.\nThis scale bridging is accomplished by incorporating traditional statistical\nmechanics methods with integrable deep neural networks, which allows formation\nenergies for specific atomic configurations to be coarse-grained and\nincorporated in a neural network description of the free energy of the\nmaterial. The resulting realistic free energy functions enable atomistically\ninformed phase-field simulations. These computational results allow us to make\nconnections to experimental work on LCO cathode degradation as a function of\ntemperature, morphology and particle size.\n", "versions": [{"version": "v1", "created": "Fri, 16 Apr 2021 19:00:59 GMT"}, {"version": "v2", "created": "Thu, 22 Apr 2021 20:33:53 GMT"}], "update_date": "2021-04-26", "authors_parsed": [["Teichert", "Gregory H.", ""], ["Das", "Sambit", ""], ["Aykol", "Muratahan", ""], ["Gopal", "Chirranjeevi", ""], ["Gavini", "Vikram", ""], ["Garikipati", "Krishna", ""]]}, {"id": "2104.08323", "submitter": "David Stutz", "authors": "David Stutz, Nandhini Chandramoorthy, Matthias Hein, Bernt Schiele", "title": "Random and Adversarial Bit Error Robustness: Energy-Efficient and Secure\n  DNN Accelerators", "comments": "arXiv admin note: substantial text overlap with arXiv:2006.13977", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AR cs.CR cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural network (DNN) accelerators received considerable attention in\nrecent years due to the potential to save energy compared to mainstream\nhardware. Low-voltage operation of DNN accelerators allows to further reduce\nenergy consumption significantly, however, causes bit-level failures in the\nmemory storing the quantized DNN weights. Furthermore, DNN accelerators have\nbeen shown to be vulnerable to adversarial attacks on voltage controllers or\nindividual bits. In this paper, we show that a combination of robust\nfixed-point quantization, weight clipping, as well as random bit error training\n(RandBET) or adversarial bit error training (AdvBET) improves robustness\nagainst random or adversarial bit errors in quantized DNN weights\nsignificantly. This leads not only to high energy savings for low-voltage\noperation as well as low-precision quantization, but also improves security of\nDNN accelerators. Our approach generalizes across operating voltages and\naccelerators, as demonstrated on bit errors from profiled SRAM arrays, and\nachieves robustness against both targeted and untargeted bit-level attacks.\nWithout losing more than 0.8%/2% in test accuracy, we can reduce energy\nconsumption on CIFAR10 by 20%/30% for 8/4-bit quantization using RandBET.\nAllowing up to 320 adversarial bit errors, AdvBET reduces test error from above\n90% (chance level) to 26.22% on CIFAR10.\n", "versions": [{"version": "v1", "created": "Fri, 16 Apr 2021 19:11:14 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Stutz", "David", ""], ["Chandramoorthy", "Nandhini", ""], ["Hein", "Matthias", ""], ["Schiele", "Bernt", ""]]}, {"id": "2104.08324", "submitter": "Cynthia Rush", "authors": "Marco Avella Medina and Jos\\'e Luis Montiel Olea and Cynthia Rush and\n  Amilcar Velez", "title": "On the Robustness to Misspecification of $\\alpha$-Posteriors and Their\n  Variational Approximations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  $\\alpha$-posteriors and their variational approximations distort standard\nposterior inference by downweighting the likelihood and introducing variational\napproximation errors. We show that such distortions, if tuned appropriately,\nreduce the Kullback-Leibler (KL) divergence from the true, but perhaps\ninfeasible, posterior distribution when there is potential parametric model\nmisspecification. To make this point, we derive a Bernstein-von Mises theorem\nshowing convergence in total variation distance of $\\alpha$-posteriors and\ntheir variational approximations to limiting Gaussian distributions. We use\nthese distributions to evaluate the KL divergence between true and reported\nposteriors. We show this divergence is minimized by choosing $\\alpha$ strictly\nsmaller than one, assuming there is a vanishingly small probability of model\nmisspecification. The optimized value becomes smaller as the the\nmisspecification becomes more severe. The optimized KL divergence increases\nlogarithmically in the degree of misspecification and not linearly as with the\nusual posterior.\n", "versions": [{"version": "v1", "created": "Fri, 16 Apr 2021 19:11:53 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Medina", "Marco Avella", ""], ["Olea", "Jos\u00e9 Luis Montiel", ""], ["Rush", "Cynthia", ""], ["Velez", "Amilcar", ""]]}, {"id": "2104.08335", "submitter": "Suchita Pati", "authors": "Suchita Pati, Shaizeen Aga, Nuwan Jayasena, Matthew D. Sinclair", "title": "Demystifying BERT: Implications for Accelerator Design", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transfer learning in natural language processing (NLP), as realized using\nmodels like BERT (Bi-directional Encoder Representation from Transformer), has\nsignificantly improved language representation with models that can tackle\nchallenging language problems. Consequently, these applications are driving the\nrequirements of future systems. Thus, we focus on BERT, one of the most popular\nNLP transfer learning algorithms, to identify how its algorithmic behavior can\nguide future accelerator design. To this end, we carefully profile BERT\ntraining and identify key algorithmic behaviors which are worthy of attention\nin accelerator design.\n  We observe that while computations which manifest as matrix multiplication\ndominate BERT's overall runtime, as in many convolutional neural networks,\nmemory-intensive computations also feature prominently. We characterize these\ncomputations, which have received little attention so far. Further, we also\nidentify heterogeneity in compute-intensive BERT computations and discuss\nsoftware and possible hardware mechanisms to further optimize these\ncomputations. Finally, we discuss implications of these behaviors as networks\nget larger and use distributed training environments, and how techniques such\nas micro-batching and mixed-precision training scale. Overall, our analysis\nidentifies holistic solutions to optimize systems for BERT-like models.\n", "versions": [{"version": "v1", "created": "Wed, 14 Apr 2021 01:06:49 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Pati", "Suchita", ""], ["Aga", "Shaizeen", ""], ["Jayasena", "Nuwan", ""], ["Sinclair", "Matthew D.", ""]]}, {"id": "2104.08336", "submitter": "Siyi Tang", "authors": "Siyi Tang, Jared A. Dunnmon, Khaled Saab, Xuan Zhang, Qianying Huang,\n  Florian Dubost, Daniel L. Rubin, Christopher Lee-Messer", "title": "Automated Seizure Detection and Seizure Type Classification From\n  Electroencephalography With a Graph Neural Network and Self-Supervised\n  Pre-Training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automated seizure detection and classification from electroencephalography\n(EEG) can greatly improve the diagnosis and treatment of seizures. While prior\nstudies mainly used convolutional neural networks (CNNs) that assume image-like\nstructure in EEG signals or spectrograms, this modeling choice does not reflect\nthe natural geometry of or connectivity between EEG electrodes. In this study,\nwe propose modeling EEGs as graphs and present a graph neural network for\nautomated seizure detection and classification. In addition, we leverage\nunlabeled EEG data using a self-supervised pre-training strategy. Our graph\nmodel with self-supervised pre-training significantly outperforms previous\nstate-of-the-art CNN and Long Short-Term Memory (LSTM) models by 6.3 points\n(7.8%) in Area Under the Receiver Operating Characteristic curve (AUROC) for\nseizure detection and 6.3 points (9.2%) in weighted F1-score for seizure type\nclassification. Ablation studies show that our graph-based modeling approach\nsignificantly outperforms existing CNN or LSTM models, and that\nself-supervision helps further improve the model performance. Moreover, we find\nthat self-supervised pre-training substantially improves model performance on\ncombined tonic seizures, a low-prevalence seizure type. Furthermore, our model\ninterpretability analysis suggests that our model is better at identifying\nseizure regions compared to an existing CNN. In summary, our graph-based\nmodeling approach integrates domain knowledge about EEG, sets a new\nstate-of-the-art for seizure detection and classification on a large public\ndataset (5,499 EEG files), and provides better ability to identify seizure\nregions.\n", "versions": [{"version": "v1", "created": "Fri, 16 Apr 2021 20:32:10 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Tang", "Siyi", ""], ["Dunnmon", "Jared A.", ""], ["Saab", "Khaled", ""], ["Zhang", "Xuan", ""], ["Huang", "Qianying", ""], ["Dubost", "Florian", ""], ["Rubin", "Daniel L.", ""], ["Lee-Messer", "Christopher", ""]]}, {"id": "2104.08337", "submitter": "Chunhua Ye", "authors": "Chunhua Ye, Zhong Yin, Chenxi Wu, Xiayidai Abulaiti, Yixing Zhang,\n  Zhenqi Sun, and Jianhua Zhang", "title": "Identification of mental fatigue in language comprehension tasks based\n  on EEG and deep learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG eess.SP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Mental fatigue increases the risk of operator error in language comprehension\ntasks. In order to prevent operator performance degradation, we used EEG\nsignals to assess the mental fatigue of operators in human-computer systems.\nThis study presents an experimental design for fatigue detection in language\ncomprehension tasks. We obtained EEG signals from a 14-channel wireless EEG\ndetector in 15 healthy participants. Each participant was given a cognitive\ntest of a language comprehension task, in the form of multiple choice\nquestions, in which pronoun references were selected between nominal and\nsurrogate sentences. In this paper, the 2400 EEG fragments collected are\ndivided into three data sets according to different utilization rates, namely\n1200s data set with 50% utilization rate, 1500s data set with 62.5% utilization\nrate, and 1800s data set with 75% utilization rate. In the aspect of feature\nextraction, different EEG features were extracted, including time domain\nfeatures, frequency domain features and entropy features, and the effects of\ndifferent features and feature combinations on classification accuracy were\nexplored. In terms of classification, we introduced the Convolutional Neural\nNetwork (CNN) method as the preferred method, It was compared with Least\nSquares Support Vector Machines(LSSVM),Support Vector Machines(SVM),Logistic\nRegression (LR), Random Forest(RF), Naive Bayes (NB), K-Nearest Neighbor (KNN)\nand Decision Tree(DT).According to the results, the classification accuracy of\nconvolutional neural network (CNN) is higher than that of other classification\nmethods. The classification results show that the classification accuracy of\n1200S dataset is higher than the other two datasets. The combination of\nFrequency and entropy feature and CNN has the highest classification accuracy,\nwhich is 85.34%.\n", "versions": [{"version": "v1", "created": "Wed, 14 Apr 2021 14:00:57 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Ye", "Chunhua", ""], ["Yin", "Zhong", ""], ["Wu", "Chenxi", ""], ["Abulaiti", "Xiayidai", ""], ["Zhang", "Yixing", ""], ["Sun", "Zhenqi", ""], ["Zhang", "Jianhua", ""]]}, {"id": "2104.08340", "submitter": "Alexandros Ioannidis Mr", "authors": "Alexandros Ioannidis", "title": "An Analysis of a BERT Deep Learning Strategy on a Technology Assisted\n  Review Task", "comments": "14 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Document screening is a central task within Evidenced Based Medicine, which\nis a clinical discipline that supplements scientific proof to back medical\ndecisions. Given the recent advances in DL (Deep Learning) methods applied to\nInformation Retrieval tasks, I propose a DL document classification approach\nwith BERT or PubMedBERT embeddings and a DL similarity search path using SBERT\nembeddings to reduce physicians' tasks of screening and classifying immense\namounts of documents to answer clinical queries. I test and evaluate the\nretrieval effectiveness of my DL strategy on the 2017 and 2018 CLEF eHealth\ncollections. I find that the proposed DL strategy works, I compare it to the\nrecently successful BM25 plus RM3 model, and conclude that the suggested method\naccomplishes advanced retrieval performance in the initial ranking of the\narticles with the aforementioned datasets, for the CLEF eHealth Technologically\nAssisted Reviews in Empirical Medicine Task.\n", "versions": [{"version": "v1", "created": "Fri, 16 Apr 2021 19:45:27 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Ioannidis", "Alexandros", ""]]}, {"id": "2104.08359", "submitter": "Owen Lockwood", "authors": "Owen Lockwood", "title": "In Defense of the Paper", "comments": "Accepted (oral) to Rethinking ML Papers - ICLR 2021 Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The machine learning publication process is broken, of that there can be no\ndoubt. Many of these flaws are attributed to the current workflow: LaTeX to PDF\nto reviewers to camera ready PDF. This has understandably resulted in the\ndesire for new forms of publications; ones that can increase inclusively,\naccessibility and pedagogical strength. However, this venture fails to address\nthe origins of these inadequacies in the contemporary paper workflow. The\npaper, being the basic unit of academic research, is merely how problems in the\npublication and research ecosystem manifest; but is not itself responsible for\nthem. Not only will simply replacing or augmenting papers with different\nformats not fix existing problems; when used as a band-aid without systemic\nchanges, will likely exacerbate the existing inequities. In this work, we argue\nthat the root cause of hindrances in the accessibility of machine learning\nresearch lies not in the paper workflow but within the misaligned incentives\nbehind the publishing and research processes. We discuss these problems and\nargue that the paper is the optimal workflow. We also highlight some potential\nsolutions for the incentivization problems.\n", "versions": [{"version": "v1", "created": "Fri, 16 Apr 2021 20:26:23 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Lockwood", "Owen", ""]]}, {"id": "2104.08364", "submitter": "Shijian Li", "authors": "Shijian Li, Oren Mangoubi, Lijie Xu, Tian Guo", "title": "Sync-Switch: Hybrid Parameter Synchronization for Distributed Deep\n  Learning", "comments": "15 pages, 16 figures, 6 tables, ICDCS'21", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG cs.PF", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Stochastic Gradient Descent (SGD) has become the de facto way to train deep\nneural networks in distributed clusters. A critical factor in determining the\ntraining throughput and model accuracy is the choice of the parameter\nsynchronization protocol. For example, while Bulk Synchronous Parallel (BSP)\noften achieves better converged accuracy, the corresponding training throughput\ncan be negatively impacted by stragglers. In contrast, Asynchronous Parallel\n(ASP) can have higher throughput, but its convergence and accuracy can be\nimpacted by stale gradients. To improve the performance of synchronization\nprotocol, recent work often focuses on designing new protocols with a heavy\nreliance on hard-to-tune hyper-parameters. In this paper, we design a hybrid\nsynchronization approach that exploits the benefits of both BSP and ASP, i.e.,\nreducing training time while simultaneously maintaining the converged accuracy.\nBased on extensive empirical profiling, we devise a collection of adaptive\npolicies that determine how and when to switch between synchronization\nprotocols. Our policies include both offline ones that target recurring jobs\nand online ones for handling transient stragglers. We implement the proposed\npolicies in a prototype system, called Sync-Switch, on top of TensorFlow, and\nevaluate the training performance with popular deep learning models and\ndatasets. Our experiments show that Sync-Switch achieves up to 5.13X throughput\nspeedup and similar converged accuracy when comparing to BSP. Further, we\nobserve that Sync-Switch achieves 3.8% higher converged accuracy with just\n1.23X the training time compared to training with ASP. Moreover, Sync-Switch\ncan be used in settings when training with ASP leads to divergence errors.\nSync-Switch achieves all of these benefits with very low overhead, e.g., the\nframework overhead can be as low as 1.7% of the total training time.\n", "versions": [{"version": "v1", "created": "Fri, 16 Apr 2021 20:49:28 GMT"}, {"version": "v2", "created": "Tue, 20 Apr 2021 00:25:37 GMT"}], "update_date": "2021-04-21", "authors_parsed": [["Li", "Shijian", ""], ["Mangoubi", "Oren", ""], ["Xu", "Lijie", ""], ["Guo", "Tian", ""]]}, {"id": "2104.08378", "submitter": "Jeff Pool", "authors": "Asit Mishra, Jorge Albericio Latorre, Jeff Pool, Darko Stosic, Dusan\n  Stosic, Ganesh Venkatesh, Chong Yu, Paulius Micikevicius", "title": "Accelerating Sparse Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As neural network model sizes have dramatically increased, so has the\ninterest in various techniques to reduce their parameter counts and accelerate\ntheir execution. An active area of research in this field is sparsity -\nencouraging zero values in parameters that can then be discarded from storage\nor computations. While most research focuses on high levels of sparsity, there\nare challenges in universally maintaining model accuracy as well as achieving\nsignificant speedups over modern matrix-math hardware. To make sparsity\nadoption practical, the NVIDIA Ampere GPU architecture introduces sparsity\nsupport in its matrix-math units, Tensor Cores. We present the design and\nbehavior of Sparse Tensor Cores, which exploit a 2:4 (50%) sparsity pattern\nthat leads to twice the math throughput of dense matrix units. We also describe\na simple workflow for training networks that both satisfy 2:4 sparsity pattern\nrequirements and maintain accuracy, verifying it on a wide range of common\ntasks and model architectures. This workflow makes it easy to prepare accurate\nmodels for efficient deployment on Sparse Tensor Cores.\n", "versions": [{"version": "v1", "created": "Fri, 16 Apr 2021 21:27:32 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Mishra", "Asit", ""], ["Latorre", "Jorge Albericio", ""], ["Pool", "Jeff", ""], ["Stosic", "Darko", ""], ["Stosic", "Dusan", ""], ["Venkatesh", "Ganesh", ""], ["Yu", "Chong", ""], ["Micikevicius", "Paulius", ""]]}, {"id": "2104.08382", "submitter": "Arjun Nitin Bhagoji", "authors": "Arjun Nitin Bhagoji, Daniel Cullina, Vikash Sehwag, Prateek Mittal", "title": "Lower Bounds on Cross-Entropy Loss in the Presence of Test-time\n  Adversaries", "comments": "16 pages, 12 figures; Accepted to ICML 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding the fundamental limits of robust supervised learning has\nemerged as a problem of immense interest, from both practical and theoretical\nstandpoints. In particular, it is critical to determine classifier-agnostic\nbounds on the training loss to establish when learning is possible. In this\npaper, we determine optimal lower bounds on the cross-entropy loss in the\npresence of test-time adversaries, along with the corresponding optimal\nclassification outputs. Our formulation of the bound as a solution to an\noptimization problem is general enough to encompass any loss function depending\non soft classifier outputs. We also propose and provide a proof of correctness\nfor a bespoke algorithm to compute this lower bound efficiently, allowing us to\ndetermine lower bounds for multiple practical datasets of interest. We use our\nlower bounds as a diagnostic tool to determine the effectiveness of current\nrobust training methods and find a gap from optimality at larger budgets.\nFinally, we investigate the possibility of using of optimal classification\noutputs as soft labels to empirically improve robust training.\n", "versions": [{"version": "v1", "created": "Fri, 16 Apr 2021 21:41:28 GMT"}, {"version": "v2", "created": "Fri, 4 Jun 2021 20:47:26 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Bhagoji", "Arjun Nitin", ""], ["Cullina", "Daniel", ""], ["Sehwag", "Vikash", ""], ["Mittal", "Prateek", ""]]}, {"id": "2104.08388", "submitter": "Jind\\v{r}ich Libovick\\'y", "authors": "Jind\\v{r}ich Libovick\\'y, Alexander Fraser", "title": "Neural String Edit Distance", "comments": "14 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose the neural string edit distance model for string-pair\nclassification and sequence generation based on learned string edit distance.\nWe modify the original expectation-maximization learned edit distance algorithm\ninto a differentiable loss function, allowing us to integrate it into a neural\nnetwork providing a contextual representation of the input. We test the method\non cognate detection, transliteration, and grapheme-to-phoneme conversion. We\nshow that we can trade off between performance and interpretability in a single\nframework. Using contextual representations, which are difficult to interpret,\nwe can match the performance of state-of-the-art string-pair classification\nmodels. Using static embeddings and a minor modification of the loss function,\nwe can force interpretability, at the expense of an accuracy drop.\n", "versions": [{"version": "v1", "created": "Fri, 16 Apr 2021 22:16:47 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Libovick\u00fd", "Jind\u0159ich", ""], ["Fraser", "Alexander", ""]]}, {"id": "2104.08409", "submitter": "Ricardo Borsoi", "authors": "Haoqing Li, Ricardo Augusto Borsoi, Tales Imbiriba, Pau Closas, Jos\\'e\n  Carlos Moreira Bermudez, Deniz Erdo\\u{g}mu\\c{s}", "title": "Model-Based Deep Autoencoder Networks for Nonlinear Hyperspectral\n  Unmixing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autoencoder (AEC) networks have recently emerged as a promising approach to\nperform unsupervised hyperspectral unmixing (HU) by associating the latent\nrepresentations with the abundances, the decoder with the mixing model and the\nencoder with its inverse. AECs are especially appealing for nonlinear HU since\nthey lead to unsupervised and model-free algorithms. However, existing\napproaches fail to explore the fact that the encoder should invert the mixing\nprocess, which might reduce their robustness. In this paper, we propose a\nmodel-based AEC for nonlinear HU by considering the mixing model a nonlinear\nfluctuation over a linear mixture. Differently from previous works, we show\nthat this restriction naturally imposes a particular structure to both the\nencoder and to the decoder networks. This introduces prior information in the\nAEC without reducing the flexibility of the mixing model. Simulations with\nsynthetic and real data indicate that the proposed strategy improves nonlinear\nHU.\n", "versions": [{"version": "v1", "created": "Sat, 17 Apr 2021 00:14:11 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Li", "Haoqing", ""], ["Borsoi", "Ricardo Augusto", ""], ["Imbiriba", "Tales", ""], ["Closas", "Pau", ""], ["Bermudez", "Jos\u00e9 Carlos Moreira", ""], ["Erdo\u011fmu\u015f", "Deniz", ""]]}, {"id": "2104.08415", "submitter": "Kevin Murphy", "authors": "Kevin Murphy and Abhishek Kumar and Stylianos Serghiou", "title": "Risk score learning for COVID-19 contact tracing apps", "comments": "13 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Digital contact tracing apps for COVID, such as the one developed by Google\nand Apple, need to estimate the risk that a user was infected during a\nparticular exposure, in order to decide whether to notify the user to take\nprecautions, such as entering into quarantine, or requesting a test. Such risk\nscore models contain numerous parameters that must be set by the public health\nauthority. In this paper, we show how to automatically learn these parameters\nfrom data.\n  Our method needs access to exposure and outcome data. Although this data is\nalready being collected (in an aggregated, privacy-preserving way) by several\nhealth authorities, in this paper we limit ourselves to simulated data, so that\nwe can systematically study the different factors that affect the feasibility\nof the approach. In particular, we show that the parameters become harder to\nestimate when there is more missing data (e.g., due to infections which were\nnot recorded by the app), and when there is model misspecification.\nNevertheless, the learning approach outperforms a strong manually designed\nbaseline. Furthermore, the learning approach can adapt even when the risk\nfactors of the disease change, e.g., due to the evolution of new variants, or\nthe adoption of vaccines.\n", "versions": [{"version": "v1", "created": "Sat, 17 Apr 2021 00:55:36 GMT"}, {"version": "v2", "created": "Wed, 21 Jul 2021 20:15:06 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Murphy", "Kevin", ""], ["Kumar", "Abhishek", ""], ["Serghiou", "Stylianos", ""]]}, {"id": "2104.08420", "submitter": "Kira Selby", "authors": "Kira A. Selby (1), Yinong Wang (1), Ruizhe Wang (1), Peyman Passban\n  (2), Ahmad Rashid (2), Mehdi Rezagholizadeh (2) and Pascal Poupart (1) ((1)\n  University of Waterloo, (2) Huawei Noah's Ark Lab)", "title": "Robust Embeddings Via Distributions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Despite recent monumental advances in the field, many Natural Language\nProcessing (NLP) models still struggle to perform adequately on noisy domains.\nWe propose a novel probabilistic embedding-level method to improve the\nrobustness of NLP models. Our method, Robust Embeddings via Distributions\n(RED), incorporates information from both noisy tokens and surrounding context\nto obtain distributions over embedding vectors that can express uncertainty in\nsemantic space more fully than any deterministic method. We evaluate our method\non a number of downstream tasks using existing state-of-the-art models in the\npresence of both natural and synthetic noise, and demonstrate a clear\nimprovement over other embedding approaches to robustness from the literature.\n", "versions": [{"version": "v1", "created": "Sat, 17 Apr 2021 02:02:36 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Selby", "Kira A.", ""], ["Wang", "Yinong", ""], ["Wang", "Ruizhe", ""], ["Passban", "Peyman", ""], ["Rashid", "Ahmad", ""], ["Rezagholizadeh", "Mehdi", ""], ["Poupart", "Pascal", ""]]}, {"id": "2104.08438", "submitter": "Rohitash Chandra", "authors": "Rohitash Chandra, Ayush Bhagat, Manavendra Maharana and Pavel N.\n  Krivitsky", "title": "Bayesian graph convolutional neural networks via tempered MCMC", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deep learning models, such as convolutional neural networks, have long been\napplied to image and multi-media tasks, particularly those with structured\ndata. More recently, there has been more attention to unstructured data that\ncan be represented via graphs. These types of data are often found in health\nand medicine, social networks, and research data repositories. Graph\nconvolutional neural networks have recently gained attention in the field of\ndeep learning that takes advantage of graph-based data representation with\nautomatic feature extraction via convolutions. Given the popularity of these\nmethods in a wide range of applications, robust uncertainty quantification is\nvital. This remains a challenge for large models and unstructured datasets.\nBayesian inference provides a principled and robust approach to uncertainty\nquantification of model parameters for deep learning models. Although Bayesian\ninference has been used extensively elsewhere, its application to deep learning\nremains limited due to the computational requirements of the Markov Chain Monte\nCarlo (MCMC) methods. Recent advances in parallel computing and advanced\nproposal schemes in sampling, such as incorporating gradients has allowed\nBayesian deep learning methods to be implemented. In this paper, we present\nBayesian graph deep learning techniques that employ state-of-art methods such\nas tempered MCMC sampling and advanced proposal schemes. Our results show that\nBayesian graph convolutional methods can provide accuracy similar to advanced\nlearning methods while providing a better alternative for robust uncertainty\nquantification for key benchmark problems.\n", "versions": [{"version": "v1", "created": "Sat, 17 Apr 2021 04:03:25 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Chandra", "Rohitash", ""], ["Bhagat", "Ayush", ""], ["Maharana", "Manavendra", ""], ["Krivitsky", "Pavel N.", ""]]}, {"id": "2104.08440", "submitter": "Ercument Ilhan", "authors": "Ercument Ilhan, Jeremy Gow and Diego Perez-Liebana", "title": "Learning on a Budget via Teacher Imitation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deep Reinforcement Learning (RL) techniques can benefit greatly from\nleveraging prior experience, which can be either self-generated or acquired\nfrom other entities. Action advising is a framework that provides a flexible\nway to transfer such knowledge in the form of actions between teacher-student\npeers. However, due to the realistic concerns, the number of these interactions\nis limited with a budget; therefore, it is crucial to perform these in the most\nappropriate moments. There have been several promising studies recently that\naddress this problem setting especially from the student's perspective. Despite\ntheir success, they have some shortcomings when it comes to the practical\napplicability and integrity as an overall solution to the learning from advice\nchallenge. In this paper, we extend the idea of advice reusing via teacher\nimitation to construct a unified approach that addresses both advice collection\nand advice utilisation problems. We also propose a method to automatically tune\nthe relevant hyperparameters of these components on-the-fly to make it able to\nadapt to any task with minimal human intervention. The experiments we performed\nin 5 different Atari games verify that our algorithm either surpasses or\nperforms on-par with its top competitors while being far simpler to be\nemployed. Furthermore, its individual components are also found to be providing\nsignificant advantages alone.\n", "versions": [{"version": "v1", "created": "Sat, 17 Apr 2021 04:15:00 GMT"}, {"version": "v2", "created": "Fri, 18 Jun 2021 22:15:43 GMT"}, {"version": "v3", "created": "Wed, 30 Jun 2021 04:31:58 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Ilhan", "Ercument", ""], ["Gow", "Jeremy", ""], ["Perez-Liebana", "Diego", ""]]}, {"id": "2104.08441", "submitter": "Ercument Ilhan", "authors": "Ercument Ilhan, Jeremy Gow and Diego Perez-Liebana", "title": "Action Advising with Advice Imitation in Deep Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Action advising is a peer-to-peer knowledge exchange technique built on the\nteacher-student paradigm to alleviate the sample inefficiency problem in deep\nreinforcement learning. Recently proposed student-initiated approaches have\nobtained promising results. However, due to being in the early stages of\ndevelopment, these also have some substantial shortcomings. One of the\nabilities that are absent in the current methods is further utilising advice by\nreusing, which is especially crucial in the practical settings considering the\nbudget and cost constraints in peer-to-peer. In this study, we present an\napproach to enable the student agent to imitate previously acquired advice to\nreuse them directly in its exploration policy, without any interventions in the\nlearning mechanism itself. In particular, we employ a behavioural cloning\nmodule to imitate the teacher policy and use dropout regularisation to have a\nnotion of epistemic uncertainty to keep track of which state-advice pairs are\nactually collected. As the results of experiments we conducted in three Atari\ngames show, advice reusing via generalisation is indeed a feasible option in\ndeep RL and our approach can successfully achieve this while significantly\nimproving the learning performance, even when paired with a simple early\nadvising heuristic.\n", "versions": [{"version": "v1", "created": "Sat, 17 Apr 2021 04:24:04 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Ilhan", "Ercument", ""], ["Gow", "Jeremy", ""], ["Perez-Liebana", "Diego", ""]]}, {"id": "2104.08472", "submitter": "Haibin Yu", "authors": "Haibin Yu, Dapeng Liu, Yizhou Chen, Bryan Kian Hsiang Low, Patrick\n  Jaillet", "title": "Convolutional Normalizing Flows for Deep Gaussian Processes", "comments": "To appear in Proceedings of the International Joint Conference on\n  Neural Networks 2021 (IJCNN'21). arXiv admin note: text overlap with\n  arXiv:1910.11998", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Deep Gaussian processes (DGPs), a hierarchical composition of GP models, have\nsuccessfully boosted the expressive power of their single-layer counterpart.\nHowever, it is impossible to perform exact inference in DGPs, which has\nmotivated the recent development of variational inference-based methods.\nUnfortunately, either these methods yield a biased posterior belief or it is\ndifficult to evaluate their convergence. This paper introduces a new approach\nfor specifying flexible, arbitrarily complex, and scalable approximate\nposterior distributions. The posterior distribution is constructed through a\nnormalizing flow (NF) which transforms a simple initial probability into a more\ncomplex one through a sequence of invertible transformations. Moreover, a novel\nconvolutional normalizing flow (CNF) is developed to improve the time\nefficiency and capture dependency between layers. Empirical evaluation shows\nthat CNF DGP outperforms the state-of-the-art approximation methods for DGPs.\n", "versions": [{"version": "v1", "created": "Sat, 17 Apr 2021 07:25:25 GMT"}, {"version": "v2", "created": "Fri, 23 Apr 2021 02:56:27 GMT"}, {"version": "v3", "created": "Wed, 26 May 2021 11:26:29 GMT"}], "update_date": "2021-05-27", "authors_parsed": [["Yu", "Haibin", ""], ["Liu", "Dapeng", ""], ["Chen", "Yizhou", ""], ["Low", "Bryan Kian Hsiang", ""], ["Jaillet", "Patrick", ""]]}, {"id": "2104.08474", "submitter": "Yibo Li", "authors": "Yibo Li, Jianfeng Pei and Luhua Lai", "title": "Learning to design drug-like molecules in three-dimensional space using\n  deep generative models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, deep generative models for molecular graphs are gaining more and\nmore attention in the field of de novo drug design. A variety of models have\nbeen developed to generate topological structures of drug-like molecules, but\nexplorations in generating three-dimensional structures are still limited.\nExisting methods have either focused on low molecular weight compounds without\nconsidering drug-likeness or generate 3D structures indirectly using atom\ndensity maps. In this work, we introduce Ligand Neural Network (L-Net), a novel\ngraph generative model for designing drug-like molecules with high-quality 3D\nstructures. L-Net directly outputs the topological and 3D structure of\nmolecules (including hydrogen atoms), without the need for additional atom\nplacement or bond order inference algorithm. The architecture of L-Net is\nspecifically optimized for drug-like molecules, and a set of metrics is\nassembled to comprehensively evaluate its performance. The results show that\nL-Net is capable of generating chemically correct, conformationally valid, and\nhighly druglike molecules. Finally, to demonstrate its potential in\nstructure-based molecular design, we combine L-Net with MCTS and test its\nability to generate potential inhibitors targeting ABL1 kinase.\n", "versions": [{"version": "v1", "created": "Sat, 17 Apr 2021 07:30:23 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Li", "Yibo", ""], ["Pei", "Jianfeng", ""], ["Lai", "Luhua", ""]]}, {"id": "2104.08482", "submitter": "Kush Bhatia", "authors": "Kush Bhatia, Peter L. Bartlett, Anca D. Dragan, Jacob Steinhardt", "title": "Agnostic learning with unknown utilities", "comments": "30 pages; published as a conference paper at ITCS 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional learning approaches for classification implicitly assume that\neach mistake has the same cost. In many real-world problems though, the utility\nof a decision depends on the underlying context $x$ and decision $y$. However,\ndirectly incorporating these utilities into the learning objective is often\ninfeasible since these can be quite complex and difficult for humans to\nspecify.\n  We formally study this as agnostic learning with unknown utilities: given a\ndataset $S = \\{x_1, \\ldots, x_n\\}$ where each data point $x_i \\sim\n\\mathcal{D}$, the objective of the learner is to output a function $f$ in some\nclass of decision functions $\\mathcal{F}$ with small excess risk. This risk\nmeasures the performance of the output predictor $f$ with respect to the best\npredictor in the class $\\mathcal{F}$ on the unknown underlying utility $u^*$.\nThis utility $u^*$ is not assumed to have any specific structure. This raises\nan interesting question whether learning is even possible in our setup, given\nthat obtaining a generalizable estimate of utility $u^*$ might not be possible\nfrom finitely many samples. Surprisingly, we show that estimating the utilities\nof only the sampled points~$S$ suffices to learn a decision function which\ngeneralizes well.\n  We study mechanisms for eliciting information which allow a learner to\nestimate the utilities $u^*$ on the set $S$. We introduce a family of\nelicitation mechanisms by generalizing comparisons, called the $k$-comparison\noracle, which enables the learner to ask for comparisons across $k$ different\ninputs $x$ at once. We show that the excess risk in our agnostic learning\nframework decreases at a rate of $O\\left(\\frac{1}{k} \\right)$. This result\nbrings out an interesting accuracy-elicitation trade-off -- as the order $k$ of\nthe oracle increases, the comparative queries become harder to elicit from\nhumans but allow for more accurate learning.\n", "versions": [{"version": "v1", "created": "Sat, 17 Apr 2021 08:22:04 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Bhatia", "Kush", ""], ["Bartlett", "Peter L.", ""], ["Dragan", "Anca D.", ""], ["Steinhardt", "Jacob", ""]]}, {"id": "2104.08489", "submitter": "Yang Yang", "authors": "Yang Yang, Zhao-Yang Fu, De-Chuan Zhan, Zhi-Bin Liu, and Yuan Jiang", "title": "Semi-Supervised Multi-Modal Multi-Instance Multi-Label Deep Network with\n  Optimal Transport", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Complex objects are usually with multiple labels, and can be represented by\nmultiple modal representations, e.g., the complex articles contain text and\nimage information as well as multiple annotations. Previous methods assume that\nthe homogeneous multi-modal data are consistent, while in real applications,\nthe raw data are disordered, e.g., the article constitutes with variable number\nof inconsistent text and image instances. Therefore, Multi-modal Multi-instance\nMulti-label (M3) learning provides a framework for handling such task and has\nexhibited excellent performance. However, M3 learning is facing two main\nchallenges: 1) how to effectively utilize label correlation; 2) how to take\nadvantage of multi-modal learning to process unlabeled instances. To solve\nthese problems, we first propose a novel Multi-modal Multi-instance Multi-label\nDeep Network (M3DN), which considers M3 learning in an end-to-end multi-modal\ndeep network and utilizes consistency principle among different modal bag-level\npredictions. Based on the M3DN, we learn the latent ground label metric with\nthe optimal transport. Moreover, we introduce the extrinsic unlabeled\nmulti-modal multi-instance data, and propose the M3DNS, which considers the\ninstance-level auto-encoder for single modality and modified bag-level optimal\ntransport to strengthen the consistency among modalities. Thereby M3DNS can\nbetter predict label and exploit label correlation simultaneously. Experiments\non benchmark datasets and real world WKG Game-Hub dataset validate the\neffectiveness of the proposed methods.\n", "versions": [{"version": "v1", "created": "Sat, 17 Apr 2021 09:18:28 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Yang", "Yang", ""], ["Fu", "Zhao-Yang", ""], ["Zhan", "De-Chuan", ""], ["Liu", "Zhi-Bin", ""], ["Jiang", "Yuan", ""]]}, {"id": "2104.08490", "submitter": "Pan Li", "authors": "Pan Li and Alexander Tuzhilin", "title": "Dual Metric Learning for Effective and Efficient Cross-Domain\n  Recommendations", "comments": "Accepted to IEEE TKDE. arXiv admin note: text overlap with\n  arXiv:1910.05189", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Cross domain recommender systems have been increasingly valuable for helping\nconsumers identify useful items in different applications. However, existing\ncross-domain models typically require large number of overlap users, which can\nbe difficult to obtain in some applications. In addition, they did not consider\nthe duality structure of cross-domain recommendation tasks, thus failing to\ntake into account bidirectional latent relations between users and items and\nachieve optimal recommendation performance. To address these issues, in this\npaper we propose a novel cross-domain recommendation model based on dual\nlearning that transfers information between two related domains in an iterative\nmanner until the learning process stabilizes. We develop a novel latent\northogonal mapping to extract user preferences over multiple domains while\npreserving relations between users across different latent spaces. Furthermore,\nwe combine the dual learning method with the metric learning approach, which\nallows us to significantly reduce the required common user overlap across the\ntwo domains and leads to even better cross-domain recommendation performance.\nWe test the proposed model on two large-scale industrial datasets and six\ndomain pairs, demonstrating that it consistently and significantly outperforms\nall the state-of-the-art baselines. We also show that the proposed model works\nwell with very few overlap users to obtain satisfying recommendation\nperformance comparable to the state-of-the-art baselines that use many overlap\nusers.\n", "versions": [{"version": "v1", "created": "Sat, 17 Apr 2021 09:18:59 GMT"}, {"version": "v2", "created": "Tue, 20 Apr 2021 01:12:23 GMT"}], "update_date": "2021-04-21", "authors_parsed": [["Li", "Pan", ""], ["Tuzhilin", "Alexander", ""]]}, {"id": "2104.08492", "submitter": "Eltayeb Ahmed", "authors": "Eltayeb Ahmed, Luisa Zintgraf, Christian A. Schroeder de Witt and\n  Nicolas Usunier", "title": "A Self-Supervised Auxiliary Loss for Deep RL in Partially Observable\n  Settings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this work we explore an auxiliary loss useful for reinforcement learning\nin environments where strong performing agents are required to be able to\nnavigate a spatial environment. The auxiliary loss proposed is to minimize the\nclassification error of a neural network classifier that predicts whether or\nnot a pair of states sampled from the agents current episode trajectory are in\norder. The classifier takes as input a pair of states as well as the agent's\nmemory. The motivation for this auxiliary loss is that there is a strong\ncorrelation with which of a pair of states is more recent in the agents episode\ntrajectory and which of the two states is spatially closer to the agent. Our\nhypothesis is that learning features to answer this question encourages the\nagent to learn and internalize in memory representations of states that\nfacilitate spatial reasoning. We tested this auxiliary loss on a navigation\ntask in a gridworld and achieved 9.6% increase in accumulative episode reward\ncompared to a strong baseline approach.\n", "versions": [{"version": "v1", "created": "Sat, 17 Apr 2021 09:28:17 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Ahmed", "Eltayeb", ""], ["Zintgraf", "Luisa", ""], ["de Witt", "Christian A. Schroeder", ""], ["Usunier", "Nicolas", ""]]}, {"id": "2104.08519", "submitter": "Shanmukh Reddy Manne", "authors": "Shanmukh Reddy Manne, Kiran Kumar Vupparaboina, Gowtham Chowdary\n  Gudapati, Ram Anudeep Peddoju, Chandra Prakash Konkimalla, Abhilash Goud,\n  Sarforaz Bin Bashar, Jay Chhablani, Soumya Jana", "title": "Efficient Screening of Diseased Eyes based on Fundus Autofluorescence\n  Images using Support Vector Machine", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  A variety of vision ailments are associated with geographic atrophy (GA) in\nthe foveal region of the eye. In current clinical practice, the ophthalmologist\nmanually detects potential presence of such GA based on fundus autofluorescence\n(FAF) images, and hence diagnoses the disease, when relevant. However, in view\nof the general scarcity of ophthalmologists relative to the large number of\nsubjects seeking eyecare, especially in remote regions, it becomes imperative\nto develop methods to direct expert time and effort to medically significant\ncases. Further, subjects from either disadvantaged background or remote\nlocalities, who face considerable economic/physical barrier in consulting\ntrained ophthalmologists, tend to seek medical attention only after being\nreasonably certain that an adverse condition exists. To serve the interest of\nboth the ophthalmologist and the potential patient, we plan a screening step,\nwhere healthy and diseased eyes are algorithmically differentiated with limited\ninput from only optometrists who are relatively more abundant in number.\nSpecifically, an early treatment diabetic retinopathy study (ETDRS) grid is\nplaced by an optometrist on each FAF image, based on which sectoral statistics\nare automatically collected. Using such statistics as features, healthy and\ndiseased eyes are proposed to be classified by training an algorithm using\navailable medical records. In this connection, we demonstrate the efficacy of\nsupport vector machines (SVM). Specifically, we consider SVM with linear as\nwell as radial basis function (RBF) kernel, and observe satisfactory\nperformance of both variants. Among those, we recommend the latter in view of\nits slight superiority in terms of classification accuracy (90.55% at a\nstandard training-to-test ratio of 80:20), and practical class-conditional\ncosts.\n", "versions": [{"version": "v1", "created": "Sat, 17 Apr 2021 11:54:34 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Manne", "Shanmukh Reddy", ""], ["Vupparaboina", "Kiran Kumar", ""], ["Gudapati", "Gowtham Chowdary", ""], ["Peddoju", "Ram Anudeep", ""], ["Konkimalla", "Chandra Prakash", ""], ["Goud", "Abhilash", ""], ["Bashar", "Sarforaz Bin", ""], ["Chhablani", "Jay", ""], ["Jana", "Soumya", ""]]}, {"id": "2104.08521", "submitter": "Minori Toyoda", "authors": "Minori Toyoda, Kanata Suzuki, Hiroki Mori, Yoshihiko Hayashi, Tetsuya\n  Ogata", "title": "Embodying Pre-Trained Word Embeddings Through Robot Actions", "comments": "To appear in IEEE Robotics and Automation Letters (RA-L) and IEEE\n  International Conference on Robotics and Automation (ICRA 2021)", "journal-ref": "IEEE Robotics and Automation Letters, vol. 6, no. 2, pp.\n  4225-4232, 2021", "doi": "10.1109/LRA.2021.3067862", "report-no": null, "categories": "cs.RO cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a promising neural network model with which to acquire a grounded\nrepresentation of robot actions and the linguistic descriptions thereof.\nProperly responding to various linguistic expressions, including polysemous\nwords, is an important ability for robots that interact with people via\nlinguistic dialogue. Previous studies have shown that robots can use words that\nare not included in the action-description paired datasets by using pre-trained\nword embeddings. However, the word embeddings trained under the distributional\nhypothesis are not grounded, as they are derived purely from a text corpus. In\nthis letter, we transform the pre-trained word embeddings to embodied ones by\nusing the robot's sensory-motor experiences. We extend a bidirectional\ntranslation model for actions and descriptions by incorporating non-linear\nlayers that retrofit the word embeddings. By training the retrofit layer and\nthe bidirectional translation model alternately, our proposed model is able to\ntransform the pre-trained word embeddings to adapt to a paired\naction-description dataset. Our results demonstrate that the embeddings of\nsynonyms form a semantic cluster by reflecting the experiences (actions and\nenvironments) of a robot. These embeddings allow the robot to properly generate\nactions from unseen words that are not paired with actions in a dataset.\n", "versions": [{"version": "v1", "created": "Sat, 17 Apr 2021 12:04:49 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Toyoda", "Minori", ""], ["Suzuki", "Kanata", ""], ["Mori", "Hiroki", ""], ["Hayashi", "Yoshihiko", ""], ["Ogata", "Tetsuya", ""]]}, {"id": "2104.08538", "submitter": "Jong Chul Ye", "authors": "Taesung Kwon, Jong Chul Ye", "title": "Cycle-free CycleGAN using Invertible Generator for Unsupervised Low-Dose\n  CT Denoising", "comments": "12 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recently, CycleGAN was shown to provide high-performance, ultra-fast\ndenoising for low-dose X-ray computed tomography (CT) without the need for a\npaired training dataset. Although this was possible thanks to cycle\nconsistency, CycleGAN requires two generators and two discriminators to enforce\ncycle consistency, demanding significant GPU resources and technical skills for\ntraining. A recent proposal of tunable CycleGAN with Adaptive Instance\nNormalization (AdaIN) alleviates the problem in part by using a single\ngenerator. However, two discriminators and an additional AdaIN code generator\nare still required for training. To solve this problem, here we present a novel\ncycle-free Cycle-GAN architecture, which consists of a single generator and a\ndiscriminator but still guarantees cycle consistency. The main innovation comes\nfrom the observation that the use of an invertible generator automatically\nfulfills the cycle consistency condition and eliminates the additional\ndiscriminator in the CycleGAN formulation. To make the invertible generator\nmore effective, our network is implemented in the wavelet residual domain.\nExtensive experiments using various levels of low-dose CT images confirm that\nour method can significantly improve denoising performance using only 10% of\nlearnable parameters and faster training time compared to the conventional\nCycleGAN.\n", "versions": [{"version": "v1", "created": "Sat, 17 Apr 2021 13:23:36 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Kwon", "Taesung", ""], ["Ye", "Jong Chul", ""]]}, {"id": "2104.08542", "submitter": "Huifeng Guo", "authors": "Huifeng Guo, Wei Guo, Yong Gao, Ruiming Tang, Xiuqiang He, Wenzhi Liu", "title": "ScaleFreeCTR: MixCache-based Distributed Training System for CTR Models\n  with Huge Embedding Table", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Because of the superior feature representation ability of deep learning,\nvarious deep Click-Through Rate (CTR) models are deployed in the commercial\nsystems by industrial companies. To achieve better performance, it is necessary\nto train the deep CTR models on huge volume of training data efficiently, which\nmakes speeding up the training process an essential problem. Different from the\nmodels with dense training data, the training data for CTR models is usually\nhigh-dimensional and sparse. To transform the high-dimensional sparse input\ninto low-dimensional dense real-value vectors, almost all deep CTR models adopt\nthe embedding layer, which easily reaches hundreds of GB or even TB. Since a\nsingle GPU cannot afford to accommodate all the embedding parameters, when\nperforming distributed training, it is not reasonable to conduct the\ndata-parallelism only. Therefore, existing distributed training platforms for\nrecommendation adopt model-parallelism. Specifically, they use CPU (Host)\nmemory of servers to maintain and update the embedding parameters and utilize\nGPU worker to conduct forward and backward computations. Unfortunately, these\nplatforms suffer from two bottlenecks: (1) the latency of pull \\& push\noperations between Host and GPU; (2) parameters update and synchronization in\nthe CPU servers. To address such bottlenecks, in this paper, we propose the\nScaleFreeCTR: a MixCache-based distributed training system for CTR models.\nSpecifically, in SFCTR, we also store huge embedding table in CPU but utilize\nGPU instead of CPU to conduct embedding synchronization efficiently. To reduce\nthe latency of data transfer between both GPU-Host and GPU-GPU, the MixCache\nmechanism and Virtual Sparse Id operation are proposed. Comprehensive\nexperiments and ablation studies are conducted to demonstrate the effectiveness\nand efficiency of SFCTR.\n", "versions": [{"version": "v1", "created": "Sat, 17 Apr 2021 13:36:19 GMT"}, {"version": "v2", "created": "Tue, 11 May 2021 14:11:46 GMT"}], "update_date": "2021-05-12", "authors_parsed": [["Guo", "Huifeng", ""], ["Guo", "Wei", ""], ["Gao", "Yong", ""], ["Tang", "Ruiming", ""], ["He", "Xiuqiang", ""], ["Liu", "Wenzhi", ""]]}, {"id": "2104.08546", "submitter": "Zhen Wang", "authors": "Zhen Wang, Shan-Shan Wang, Lan Bai, Wen-Si Wang, Yuan-Hai Shao", "title": "Fuzzy Discriminant Clustering with Fuzzy Pairwise Constraints", "comments": "15 pages,41 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In semi-supervised fuzzy clustering, this paper extends the traditional\npairwise constraint (i.e., must-link or cannot-link) to fuzzy pairwise\nconstraint. The fuzzy pairwise constraint allows a supervisor to provide the\ngrade of similarity or dissimilarity between the implicit fuzzy vectors of a\npair of samples. This constraint can present more complicated relationship\nbetween the pair of samples and avoid eliminating the fuzzy characteristics. We\npropose a fuzzy discriminant clustering model (FDC) to fuse the fuzzy pairwise\nconstraints. The nonconvex optimization problem in our FDC is solved by a\nmodified expectation-maximization algorithm, involving to solve several\nindefinite quadratic programming problems (IQPPs). Further, a diagonal block\ncoordinate decent (DBCD) algorithm is proposed for these IQPPs, whose\nstationary points are guaranteed, and the global solutions can be obtained\nunder certain conditions. To suit for different applications, the FDC is\nextended into various metric spaces, e.g., the Reproducing Kernel Hilbert\nSpace. Experimental results on several benchmark datasets and facial expression\ndatabase demonstrate the outperformance of our FDC compared with some\nstate-of-the-art clustering models.\n", "versions": [{"version": "v1", "created": "Sat, 17 Apr 2021 13:58:10 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Wang", "Zhen", ""], ["Wang", "Shan-Shan", ""], ["Bai", "Lan", ""], ["Wang", "Wen-Si", ""], ["Shao", "Yuan-Hai", ""]]}, {"id": "2104.08548", "submitter": "Micha{\\l} Koziarski", "authors": "Micha{\\l} Koziarski", "title": "Potential Anchoring for imbalanced data classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data imbalance remains one of the factors negatively affecting the\nperformance of contemporary machine learning algorithms. One of the most common\napproaches to reducing the negative impact of data imbalance is preprocessing\nthe original dataset with data-level strategies. In this paper we propose a\nunified framework for imbalanced data over- and undersampling. The proposed\napproach utilizes radial basis functions to preserve the original shape of the\nunderlying class distributions during the resampling process. This is done by\noptimizing the positions of generated synthetic observations with respect to\nthe potential resemblance loss. The final Potential Anchoring algorithm\ncombines over- and undersampling within the proposed framework. The results of\nthe experiments conducted on 60 imbalanced datasets show outperformance of\nPotential Anchoring over state-of-the-art resampling algorithms, including\npreviously proposed methods that utilize radial basis functions to model class\npotential. Furthermore, the results of the analysis based on the proposed data\ncomplexity index show that Potential Anchoring is particularly well suited for\nhandling naturally complex (i.e. not affected by the presence of noise)\ndatasets.\n", "versions": [{"version": "v1", "created": "Sat, 17 Apr 2021 14:00:16 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Koziarski", "Micha\u0142", ""]]}, {"id": "2104.08551", "submitter": "Yatin Chaudhary", "authors": "Pankaj Gupta, Yatin Chaudhary, Hinrich Sch\\\"utze", "title": "Multi-source Neural Topic Modeling in Multi-view Embedding Spaces", "comments": "NAACL2021, 13 pages, 14 tables, 2 figures. arXiv admin note:\n  substantial text overlap with arXiv:1909.06563", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Though word embeddings and topics are complementary representations, several\npast works have only used pretrained word embeddings in (neural) topic modeling\nto address data sparsity in short-text or small collection of documents. This\nwork presents a novel neural topic modeling framework using multi-view\nembedding spaces: (1) pretrained topic-embeddings, and (2) pretrained\nword-embeddings (context insensitive from Glove and context-sensitive from BERT\nmodels) jointly from one or many sources to improve topic quality and better\ndeal with polysemy. In doing so, we first build respective pools of pretrained\ntopic (i.e., TopicPool) and word embeddings (i.e., WordPool). We then identify\none or more relevant source domain(s) and transfer knowledge to guide\nmeaningful learning in the sparse target domain. Within neural topic modeling,\nwe quantify the quality of topics and document representations via\ngeneralization (perplexity), interpretability (topic coherence) and information\nretrieval (IR) using short-text, long-text, small and large document\ncollections from news and medical domains. Introducing the multi-source\nmulti-view embedding spaces, we have shown state-of-the-art neural topic\nmodeling using 6 source (high-resource) and 5 target (low-resource) corpora.\n", "versions": [{"version": "v1", "created": "Sat, 17 Apr 2021 14:08:00 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Gupta", "Pankaj", ""], ["Chaudhary", "Yatin", ""], ["Sch\u00fctze", "Hinrich", ""]]}, {"id": "2104.08556", "submitter": "Alberto Garcia-Duran", "authors": "Alberto Garc\\'ia-Dur\\'an, Robert West", "title": "Recursive input and state estimation: A general framework for learning\n  from time series with missing data", "comments": "Published at ICASSP 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Time series with missing data are signals encountered in important settings\nfor machine learning. Some of the most successful prior approaches for modeling\nsuch time series are based on recurrent neural networks that transform the\ninput and previous state to account for the missing observations, and then\ntreat the transformed signal in a standard manner.\n  In this paper, we introduce a single unifying framework, Recursive Input and\nState Estimation (RISE), for this general approach and reformulate existing\nmodels as specific instances of this framework. We then explore additional\nnovel variations within the RISE framework to improve the performance of any\ninstance. We exploit representation learning techniques to learn latent\nrepresentations of the signals used by RISE instances. We discuss and develop\nvarious encoding techniques to learn latent signal representations. We\nbenchmark instances of the framework with various encoding functions on three\ndata imputation datasets, observing that RISE instances always benefit from\nencoders that learn representations for numerical values from the digits into\nwhich they can be decomposed.\n", "versions": [{"version": "v1", "created": "Sat, 17 Apr 2021 14:43:33 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Garc\u00eda-Dur\u00e1n", "Alberto", ""], ["West", "Robert", ""]]}, {"id": "2104.08572", "submitter": "Christian Simon", "authors": "Christian Simon, Piotr Koniusz, Mehrtash Harandi", "title": "On Learning the Geodesic Path for Incremental Learning", "comments": "Accepted to CVPR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks notoriously suffer from the problem of catastrophic\nforgetting, the phenomenon of forgetting the past knowledge when acquiring new\nknowledge. Overcoming catastrophic forgetting is of significant importance to\nemulate the process of \"incremental learning\", where the model is capable of\nlearning from sequential experience in an efficient and robust way.\nState-of-the-art techniques for incremental learning make use of knowledge\ndistillation towards preventing catastrophic forgetting. Therein, one updates\nthe network while ensuring that the network's responses to previously seen\nconcepts remain stable throughout updates. This in practice is done by\nminimizing the dissimilarity between current and previous responses of the\nnetwork one way or another. Our work contributes a novel method to the arsenal\nof distillation techniques. In contrast to the previous state of the art, we\npropose to firstly construct low-dimensional manifolds for previous and current\nresponses and minimize the dissimilarity between the responses along the\ngeodesic connecting the manifolds. This induces a more formidable knowledge\ndistillation with smooth properties which preserves the past knowledge more\nefficiently as observed by our comprehensive empirical study.\n", "versions": [{"version": "v1", "created": "Sat, 17 Apr 2021 15:26:34 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Simon", "Christian", ""], ["Koniusz", "Piotr", ""], ["Harandi", "Mehrtash", ""]]}, {"id": "2104.08580", "submitter": "Axel Marmoret", "authors": "Axel Marmoret (1), J\\'er\\'emy E. Cohen (1), Nancy Bertin (1),\n  Fr\\'ed\\'eric Bimbot (1) ((1) Univ Rennes, Inria, CNRS, IRISA, France.)", "title": "Uncovering audio patterns in music with Nonnegative Tucker Decomposition\n  for structural segmentation", "comments": "7 pages, 6 figures; Code and experiments details available at\n  https://gitlab.inria.fr/amarmore/musicntd/-/tree/0.1.0; Experiments details\n  available at\n  https://ax-le.github.io/resources/ISMIR2020/Notebooks_mainpage.html", "journal-ref": "21st International Society for Music Information Retrieval\n  Conference (ISMIR), Montr\\'eal, Canada, 2020, 788-794", "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recent work has proposed the use of tensor decomposition to model repetitions\nand to separate tracks in loop-based electronic music. The present work\ninvestigates further on the ability of Nonnegative Tucker Decompositon (NTD) to\nuncover musical patterns and structure in pop songs in their audio form.\nExploiting the fact that NTD tends to express the content of bars as linear\ncombinations of a few patterns, we illustrate the ability of the decomposition\nto capture and single out repeated motifs in the corresponding compressed\nspace, which can be interpreted from a musical viewpoint. The resulting\nfeatures also turn out to be efficient for structural segmentation, leading to\nexperimental results on the RWC Pop data set which are potentially challenging\nstate-of-the-art approaches that rely on extensive example-based learning\nschemes.\n", "versions": [{"version": "v1", "created": "Sat, 17 Apr 2021 15:48:24 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Marmoret", "Axel", "", "Univ Rennes, Inria, CNRS, IRISA, France"], ["Cohen", "J\u00e9r\u00e9my E.", "", "Univ Rennes, Inria, CNRS, IRISA, France"], ["Bertin", "Nancy", "", "Univ Rennes, Inria, CNRS, IRISA, France"], ["Bimbot", "Fr\u00e9d\u00e9ric", "", "Univ Rennes, Inria, CNRS, IRISA, France"]]}, {"id": "2104.08581", "submitter": "Ujjal Kr Dutta", "authors": "Ujjal Kr Dutta, Sandeep Repakula, Maulik Parmar, Abhinav Ravi", "title": "Color Variants Identification in Fashion e-commerce via Contrastive\n  Self-Supervised Representation Learning", "comments": "Accepted In IJCAI-21 Weakly Supervised Representation Learning (WSRL)\n  workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  In this paper, we utilize deep visual Representation Learning to address an\nimportant problem in fashion e-commerce: color variants identification, i.e.,\nidentifying fashion products that match exactly in their design (or style), but\nonly to differ in their color. At first we attempt to tackle the problem by\nobtaining manual annotations (depicting whether two products are color\nvariants), and train a supervised triplet loss based neural network model to\nlearn representations of fashion products. However, for large scale real-world\nindustrial datasets such as addressed in our paper, it is infeasible to obtain\nannotations for the entire dataset, while capturing all the difficult corner\ncases. Interestingly, we observed that color variants are essentially\nmanifestations of color jitter based augmentations. Thus, we instead explore\nSelf-Supervised Learning (SSL) to solve this problem. We observed that existing\nstate-of-the-art SSL methods perform poor, for our problem. To address this, we\npropose a novel SSL based color variants model that simultaneously focuses on\ndifferent parts of an apparel. Quantitative and qualitative evaluation shows\nthat our method outperforms existing SSL methods, and at times, the supervised\nmodel.\n", "versions": [{"version": "v1", "created": "Sat, 17 Apr 2021 15:51:56 GMT"}, {"version": "v2", "created": "Wed, 30 Jun 2021 22:07:44 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Dutta", "Ujjal Kr", ""], ["Repakula", "Sandeep", ""], ["Parmar", "Maulik", ""], ["Ravi", "Abhinav", ""]]}, {"id": "2104.08604", "submitter": "Jingfeng Wu", "authors": "Haoran Li, Aditya Krishnan, Jingfeng Wu, Soheil Kolouri, Praveen K.\n  Pilly, Vladimir Braverman", "title": "Lifelong Learning with Sketched Structural Regularization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Preventing catastrophic forgetting while continually learning new tasks is an\nessential problem in lifelong learning. Structural regularization (SR) refers\nto a family of algorithms that mitigate catastrophic forgetting by penalizing\nthe network for changing its \"critical parameters\" from previous tasks while\nlearning a new one. The penalty is often induced via a quadratic regularizer\ndefined by an \\emph{importance matrix}, e.g., the (empirical) Fisher\ninformation matrix in the Elastic Weight Consolidation framework. In practice\nand due to computational constraints, most SR methods crudely approximate the\nimportance matrix by its diagonal. In this paper, we propose \\emph{Sketched\nStructural Regularization} (Sketched SR) as an alternative approach to compress\nthe importance matrices used for regularizing in SR methods. Specifically, we\napply \\emph{linear sketching methods} to better approximate the importance\nmatrices in SR algorithms. We show that sketched SR: (i) is computationally\nefficient and straightforward to implement, (ii) provides an approximation\nerror that is justified in theory, and (iii) is method oblivious by\nconstruction and can be adapted to any method that belongs to the structural\nregularization class. We show that our proposed approach consistently improves\nvarious SR algorithms' performance on both synthetic experiments and benchmark\ncontinual learning tasks, including permuted-MNIST and CIFAR-100.\n", "versions": [{"version": "v1", "created": "Sat, 17 Apr 2021 18:07:23 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Li", "Haoran", ""], ["Krishnan", "Aditya", ""], ["Wu", "Jingfeng", ""], ["Kolouri", "Soheil", ""], ["Pilly", "Praveen K.", ""], ["Braverman", "Vladimir", ""]]}, {"id": "2104.08614", "submitter": "Michael Bronstein", "authors": "Jacob Andreas, Ga\\v{s}per Begu\\v{s}, Michael M. Bronstein, Roee\n  Diamant, Denley Delaney, Shane Gero, Shafi Goldwasser, David F. Gruber, Sarah\n  de Haas, Peter Malkin, Roger Payne, Giovanni Petri, Daniela Rus, Pratyusha\n  Sharma, Dan Tchernov, Pernille T{\\o}nnesen, Antonio Torralba, Daniel Vogt,\n  Robert J. Wood", "title": "Cetacean Translation Initiative: a roadmap to deciphering the\n  communication of sperm whales", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.AI cs.CL cs.LG cs.RO eess.AS", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  The past decade has witnessed a groundbreaking rise of machine learning for\nhuman language analysis, with current methods capable of automatically\naccurately recovering various aspects of syntax and semantics - including\nsentence structure and grounded word meaning - from large data collections.\nRecent research showed the promise of such tools for analyzing acoustic\ncommunication in nonhuman species. We posit that machine learning will be the\ncornerstone of future collection, processing, and analysis of multimodal\nstreams of data in animal communication studies, including bioacoustic,\nbehavioral, biological, and environmental data. Cetaceans are unique non-human\nmodel species as they possess sophisticated acoustic communications, but\nutilize a very different encoding system that evolved in an aquatic rather than\nterrestrial medium. Sperm whales, in particular, with their highly-developed\nneuroanatomical features, cognitive abilities, social structures, and discrete\nclick-based encoding make for an excellent starting point for advanced machine\nlearning tools that can be applied to other animals in the future. This paper\ndetails a roadmap toward this goal based on currently existing technology and\nmultidisciplinary scientific community effort. We outline the key elements\nrequired for the collection and processing of massive bioacoustic data of sperm\nwhales, detecting their basic communication units and language-like\nhigher-level structures, and validating these models through interactive\nplayback experiments. The technological capabilities developed by such an\nundertaking are likely to yield cross-applications and advancements in broader\ncommunities investigating non-human communication and animal behavioral\nresearch.\n", "versions": [{"version": "v1", "created": "Sat, 17 Apr 2021 18:39:22 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Andreas", "Jacob", ""], ["Begu\u0161", "Ga\u0161per", ""], ["Bronstein", "Michael M.", ""], ["Diamant", "Roee", ""], ["Delaney", "Denley", ""], ["Gero", "Shane", ""], ["Goldwasser", "Shafi", ""], ["Gruber", "David F.", ""], ["de Haas", "Sarah", ""], ["Malkin", "Peter", ""], ["Payne", "Roger", ""], ["Petri", "Giovanni", ""], ["Rus", "Daniela", ""], ["Sharma", "Pratyusha", ""], ["Tchernov", "Dan", ""], ["T\u00f8nnesen", "Pernille", ""], ["Torralba", "Antonio", ""], ["Vogt", "Daniel", ""], ["Wood", "Robert J.", ""]]}, {"id": "2104.08615", "submitter": "Kun Wang", "authors": "Kun Wang, Canzhe Zhao, Shuai Li, Shuo Shao", "title": "Conservative Contextual Combinatorial Cascading Bandit", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Conservative mechanism is a desirable property in decision-making problems\nwhich balance the tradeoff between the exploration and exploitation. We propose\nthe novel \\emph{conservative contextual combinatorial cascading bandit\n($C^4$-bandit)}, a cascading online learning game which incorporates the\nconservative mechanism. At each time step, the learning agent is given some\ncontexts and has to recommend a list of items but not worse than the base\nstrategy and then observes the reward by some stopping rules. We design the\n$C^4$-UCB algorithm to solve the problem and prove its n-step upper regret\nbound for two situations: known baseline reward and unknown baseline reward.\nThe regret in both situations can be decomposed into two terms: (a) the upper\nbound for the general contextual combinatorial cascading bandit; and (b) a\nconstant term for the regret from the conservative mechanism. We also improve\nthe bound of the conservative contextual combinatorial bandit as a by-product.\nExperiments on synthetic data demonstrate its advantages and validate our\ntheoretical analysis.\n", "versions": [{"version": "v1", "created": "Sat, 17 Apr 2021 18:42:28 GMT"}, {"version": "v2", "created": "Fri, 23 Apr 2021 05:59:29 GMT"}], "update_date": "2021-04-26", "authors_parsed": [["Wang", "Kun", ""], ["Zhao", "Canzhe", ""], ["Li", "Shuai", ""], ["Shao", "Shuo", ""]]}, {"id": "2104.08619", "submitter": "Guillermo Navas Palencia", "authors": "Guillermo Navas-Palencia", "title": "Optimal Counterfactual Explanations for Scorecard modelling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Counterfactual explanations is one of the post-hoc methods used to provide\nexplainability to machine learning models that have been attracting attention\nin recent years. Most examples in the literature, address the problem of\ngenerating post-hoc explanations for black-box machine learning models after\nthe rejection of a loan application. In contrast, in this work, we investigate\nmathematical programming formulations for scorecard models, a type of\ninterpretable model predominant within the banking industry for lending. The\nproposed mixed-integer programming formulations combine objective functions to\nensure close, realistic and sparse counterfactuals using multi-objective\noptimization techniques for a binary, probability or continuous outcome.\nMoreover, we extend these formulations to generate multiple optimal\ncounterfactuals simultaneously while guaranteeing diversity. Experiments on two\nreal-world datasets confirm that the presented approach can generate optimal\ndiverse counterfactuals addressing desired properties with assumable CPU times\nfor practice use.\n", "versions": [{"version": "v1", "created": "Sat, 17 Apr 2021 18:51:50 GMT"}, {"version": "v2", "created": "Sun, 9 May 2021 17:20:17 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Navas-Palencia", "Guillermo", ""]]}, {"id": "2104.08633", "submitter": "Caroline Pacheco Do Espirito Silva", "authors": "Caroline Pacheco do Esp\\'irito Silva, Jos\\'e A. M. Felippe De Souza,\n  Antoine Vacavant, Thierry Bouwmans, Andrews Cordolino Sobral", "title": "Automated Mathematical Equation Structure Discovery for Visual Analysis", "comments": "25 pages, 8 figures, submitted to JMLR", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Finding the best mathematical equation to deal with the different challenges\nfound in complex scenarios requires a thorough understanding of the scenario\nand a trial and error process carried out by experts. In recent years, most\nstate-of-the-art equation discovery methods have been widely applied in\nmodeling and identification systems. However, equation discovery approaches can\nbe very useful in computer vision, particularly in the field of feature\nextraction. In this paper, we focus on recent AI advances to present a novel\nframework for automatically discovering equations from scratch with little\nhuman intervention to deal with the different challenges encountered in\nreal-world scenarios. In addition, our proposal can reduce human bias by\nproposing a search space design through generative network instead of\nhand-designed. As a proof of concept, the equations discovered by our framework\nare used to distinguish moving objects from the background in video sequences.\nExperimental results show the potential of the proposed approach and its\neffectiveness in discovering the best equation in video sequences. The code and\ndata are available at:\nhttps://github.com/carolinepacheco/equation-discovery-scene-analysis\n", "versions": [{"version": "v1", "created": "Sat, 17 Apr 2021 19:42:06 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Silva", "Caroline Pacheco do Esp\u00edrito", ""], ["De Souza", "Jos\u00e9 A. M. Felippe", ""], ["Vacavant", "Antoine", ""], ["Bouwmans", "Thierry", ""], ["Sobral", "Andrews Cordolino", ""]]}, {"id": "2104.08647", "submitter": "Matan Hasson", "authors": "Matan Hasson and Jonathan Berant", "title": "Question Decomposition with Dependency Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  QDMR is a meaning representation for complex questions, which decomposes\nquestions into a sequence of atomic steps. While state-of-the-art QDMR parsers\nuse the common sequence-to-sequence (seq2seq) approach, a QDMR structure\nfundamentally describes labeled relations between spans in the input question,\nand thus dependency-based approaches seem appropriate for this task. In this\nwork, we present a QDMR parser that is based on dependency graphs (DGs), where\nnodes in the graph are words and edges describe logical relations that\ncorrespond to the different computation steps. We propose (a) a\nnon-autoregressive graph parser, where all graph edges are computed\nsimultaneously, and (b) a seq2seq parser that uses gold graph as auxiliary\nsupervision. We find that a graph parser leads to a moderate reduction in\nperformance (0.47 to 0.44), but to a 16x speed-up in inference time due to the\nnon-autoregressive nature of the parser, and to improved sample complexity\ncompared to a seq2seq model. Second, a seq2seq model trained with auxiliary\ngraph supervision has better generalization to new domains compared to a\nseq2seq model, and also performs better on questions with long sequences of\ncomputation steps.\n", "versions": [{"version": "v1", "created": "Sat, 17 Apr 2021 21:35:31 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Hasson", "Matan", ""], ["Berant", "Jonathan", ""]]}, {"id": "2104.08655", "submitter": "Abhyuday Bhartiya", "authors": "Abhyuday Bhartiya, Kartikeya Badola, Mausam", "title": "DiS-ReX: A Multilingual Dataset for Distantly Supervised Relation\n  Extraction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distant supervision (DS) is a well established technique for creating\nlarge-scale datasets for relation extraction (RE) without using human\nannotations. However, research in DS-RE has been mostly limited to the English\nlanguage. Constraining RE to a single language inhibits utilization of large\namounts of data in other languages which could allow extraction of more diverse\nfacts. Very recently, a dataset for multilingual DS-RE has been released.\nHowever, our analysis reveals that the proposed dataset exhibits unrealistic\ncharacteristics such as 1) lack of sentences that do not express any relation,\nand 2) all sentences for a given entity pair expressing exactly one relation.\nWe show that these characteristics lead to a gross overestimation of the model\nperformance. In response, we propose a new dataset, DiS-ReX, which alleviates\nthese issues. Our dataset has more than 1.5 million sentences, spanning across\n4 languages with 36 relation classes + 1 no relation (NA) class. We also modify\nthe widely used bag attention models by encoding sentences using mBERT and\nprovide the first benchmark results on multilingual DS-RE. Unlike the competing\ndataset, we show that our dataset is challenging and leaves enough room for\nfuture research to take place in this field.\n", "versions": [{"version": "v1", "created": "Sat, 17 Apr 2021 22:44:38 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Bhartiya", "Abhyuday", ""], ["Badola", "Kartikeya", ""], ["Mausam", "", ""]]}, {"id": "2104.08673", "submitter": "Zihan Wang", "authors": "Zihan Wang and Chengyu Dong and Jingbo Shang", "title": "\"Average\" Approximates \"First Principal Component\"? An Empirical\n  Analysis on Representations from Neural Language Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Contextualized representations based on neural language models have furthered\nthe state of the art in various NLP tasks. Despite its great success, the\nnature of such representations remains a mystery. In this paper, we present an\nempirical property of these representations -- \"average\" approximates \"first\nprincipal component\". Specifically, experiments show that the average of these\nrepresentations shares almost the same direction as the first principal\ncomponent of the matrix whose columns are these representations. We believe\nthis explains why the average representation is always a simple yet strong\nbaseline. Our further examinations show that this property also holds in more\nchallenging scenarios, for example, when the representations are from a model\nright after its random initialization. Therefore, we conjecture that this\nproperty is intrinsic to the distribution of representations and not\nnecessarily related to the input structure. We realize that these\nrepresentations empirically follow a normal distribution for each dimension,\nand by assuming this is true, we demonstrate that the empirical property can be\nin fact derived mathematically.\n", "versions": [{"version": "v1", "created": "Sun, 18 Apr 2021 01:15:40 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Wang", "Zihan", ""], ["Dong", "Chengyu", ""], ["Shang", "Jingbo", ""]]}, {"id": "2104.08676", "submitter": "Xiang Zhou", "authors": "Xiang Zhou, Yixin Nie, Mohit Bansal", "title": "Distributed NLI: Learning to Predict Human Opinion Distributions for\n  Language Reasoning", "comments": "13 pages, 2 figures, 8 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce distributed NLI, a new NLU task with a goal to predict the\ndistribution of human judgements for natural language inference. We show that\nmodels can capture human judgement distribution by applying additional\ndistribution estimation methods, namely, Monte Carlo (MC) Dropout, Deep\nEnsemble, Re-Calibration, and Distribution Distillation. All four of these\nmethods substantially outperform the softmax baseline. We show that MC Dropout\nis able to achieve decent performance without any distribution annotations\nwhile Re-Calibration can further give substantial improvements when extra\ndistribution annotations are provided, suggesting the value of multiple\nannotations for the example in modeling the distribution of human judgements.\nMoreover, MC Dropout and Re-Calibration can achieve decent transfer performance\non out-of-domain data. Despite these improvements, the best results are still\nfar below estimated human upper-bound, indicating that the task of predicting\nthe distribution of human judgements is still an open, challenging problem with\nlarge room for future improvements. We showcase the common errors for MC\nDropout and Re-Calibration. Finally, we give guidelines on the usage of these\nmethods with different levels of data availability and encourage future work on\nmodeling the human opinion distribution for language reasoning.\n", "versions": [{"version": "v1", "created": "Sun, 18 Apr 2021 01:25:19 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Zhou", "Xiang", ""], ["Nie", "Yixin", ""], ["Bansal", "Mohit", ""]]}, {"id": "2104.08677", "submitter": "Mehdi Rezagholizadeh", "authors": "Krtin Kumar, Mehdi Rezagholizadeh, Yiu Sing Lau, Qun Liu", "title": "Improving Neural Machine Translation with Compact Word Embedding Tables", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Embedding matrices are key components in neural natural language processing\n(NLP) models that are responsible to provide numerical representations of input\ntokens.\\footnote{In this paper words and subwords are referred to as\n\\textit{tokens} and the term \\textit{embedding} only refers to embeddings of\ninputs.} In this paper, we analyze the impact and utility of such matrices in\nthe context of neural machine translation (NMT). We show that detracting\nsyntactic and semantic information from word embeddings and running NMT systems\nwith random embeddings is not as damaging as it initially sounds. We also show\nhow incorporating only a limited amount of task-specific knowledge from\nfully-trained embeddings can boost the performance NMT systems. Our findings\ndemonstrate that in exchange for negligible deterioration in performance, any\nNMT model can be run with partially random embeddings. Working with such\nstructures means a minimal memory requirement as there is no longer need to\nstore large embedding tables, which is a significant gain in industrial and\non-device settings. We evaluated our embeddings in translating {English} into\n{German} and {French} and achieved a $5.3$x compression rate. Despite having a\nconsiderably smaller architecture, our models in some cases are even able to\noutperform state-of-the-art baselines.\n", "versions": [{"version": "v1", "created": "Sun, 18 Apr 2021 01:57:38 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Kumar", "Krtin", ""], ["Rezagholizadeh", "Mehdi", ""], ["Lau", "Yiu Sing", ""], ["Liu", "Qun", ""]]}, {"id": "2104.08678", "submitter": "Max Bartolo", "authors": "Max Bartolo, Tristan Thrush, Robin Jia, Sebastian Riedel, Pontus\n  Stenetorp, Douwe Kiela", "title": "Improving Question Answering Model Robustness with Synthetic Adversarial\n  Data Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Despite the availability of very large datasets and pretrained models,\nstate-of-the-art question answering models remain susceptible to a variety of\nadversarial attacks and are still far from obtaining human-level language\nunderstanding. One proposed way forward is dynamic adversarial data collection,\nin which a human annotator attempts to create examples for which a\nmodel-in-the-loop fails. However, this approach comes at a higher cost per\nsample and slower pace of annotation, as model-adversarial data requires more\nannotator effort to generate. In this work, we investigate several answer\nselection, question generation, and filtering methods that form a synthetic\nadversarial data generation pipeline that takes human-generated adversarial\nsamples and unannotated text to create synthetic question-answer pairs. Models\ntrained on both synthetic and human-generated data outperform models not\ntrained on synthetic adversarial data, and obtain state-of-the-art results on\nthe AdversarialQA dataset with overall performance gains of 3.7F1. Furthermore,\nwe find that training on the synthetic adversarial data improves model\ngeneralisation across domains for non-adversarial data, demonstrating gains on\n9 of the 12 datasets for MRQA. Lastly, we find that our models become\nconsiderably more difficult to beat by human adversaries, with a drop in\nmacro-averaged validated model error rate from 17.6% to 8.8% when compared to\nnon-augmented models.\n", "versions": [{"version": "v1", "created": "Sun, 18 Apr 2021 02:00:06 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Bartolo", "Max", ""], ["Thrush", "Tristan", ""], ["Jia", "Robin", ""], ["Riedel", "Sebastian", ""], ["Stenetorp", "Pontus", ""], ["Kiela", "Douwe", ""]]}, {"id": "2104.08690", "submitter": "Yue Gao", "authors": "Yue Gao, Kassem Fawaz", "title": "Scale-Adv: A Joint Attack on Image-Scaling and Machine Learning\n  Classifiers", "comments": "32 pages, 16 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  As real-world images come in varying sizes, the machine learning model is\npart of a larger system that includes an upstream image scaling algorithm. In\nthis system, the model and the scaling algorithm have become attractive targets\nfor numerous attacks, such as adversarial examples and the recent image-scaling\nattack. In response to these attacks, researchers have developed defense\napproaches that are tailored to attacks at each processing stage. As these\ndefenses are developed in isolation, their underlying assumptions become\nquestionable when viewing them from the perspective of an end-to-end machine\nlearning system. In this paper, we investigate whether defenses against scaling\nattacks and adversarial examples are still robust when an adversary targets the\nentire machine learning system. In particular, we propose Scale-Adv, a novel\nattack framework that jointly targets the image-scaling and classification\nstages. This framework packs several novel techniques, including novel\nrepresentations of the scaling defenses. It also defines two integrations that\nallow for attacking the machine learning system pipeline in the white-box and\nblack-box settings. Based on this framework, we evaluate cutting-edge defenses\nat each processing stage. For scaling attacks, we show that Scale-Adv can evade\nfour out of five state-of-the-art defenses by incorporating adversarial\nexamples. For classification, we show that Scale-Adv can significantly improve\nthe performance of machine learning attacks by leveraging weaknesses in the\nscaling algorithm. We empirically observe that Scale-Adv can produce\nadversarial examples with less perturbation and higher confidence than vanilla\nblack-box and white-box attacks. We further demonstrate the transferability of\nScale-Adv on a commercial online API.\n", "versions": [{"version": "v1", "created": "Sun, 18 Apr 2021 03:19:15 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Gao", "Yue", ""], ["Fawaz", "Kassem", ""]]}, {"id": "2104.08695", "submitter": "Glen Chou", "authors": "Glen Chou, Necmiye Ozay, and Dmitry Berenson", "title": "Model Error Propagation via Learned Contraction Metrics for Safe\n  Feedback Motion Planning of Unknown Systems", "comments": "10 pages, 5 figures, abridged version under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG cs.SY eess.SY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present a method for contraction-based feedback motion planning of locally\nincrementally exponentially stabilizable systems with unknown dynamics that\nprovides probabilistic safety and reachability guarantees. Given a dynamics\ndataset, our method learns a deep control-affine approximation of the dynamics.\nTo find a trusted domain where this model can be used for planning, we obtain\nan estimate of the Lipschitz constant of the model error, which is valid with a\ngiven probability, in a region around the training data, providing a local,\nspatially-varying model error bound. We derive a trajectory tracking error\nbound for a contraction-based controller that is subjected to this model error,\nand then learn a controller that optimizes this tracking bound. With a given\nprobability, we verify the correctness of the controller and tracking error\nbound in the trusted domain. We then use the trajectory error bound together\nwith the trusted domain to guide a sampling-based planner to return\ntrajectories that can be robustly tracked in execution. We show results on a 4D\ncar, a 6D quadrotor, and a 22D deformable object manipulation task, showing our\nmethod plans safely with learned models of high-dimensional underactuated\nsystems, while baselines that plan without considering the tracking error bound\nor the trusted domain can fail to stabilize the system and become unsafe.\n", "versions": [{"version": "v1", "created": "Sun, 18 Apr 2021 03:34:00 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Chou", "Glen", ""], ["Ozay", "Necmiye", ""], ["Berenson", "Dmitry", ""]]}, {"id": "2104.08698", "submitter": "Pu-Chin Chen", "authors": "Pu-Chin Chen, Henry Tsai, Srinadh Bhojanapalli, Hyung Won Chung,\n  Yin-Wen Chang, Chun-Sung Ferng", "title": "Demystifying the Better Performance of Position Encoding Variants for\n  Transformer", "comments": "17 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transformers are state of the art models in NLP that map a given input\nsequence of vectors to an output sequence of vectors. However these models are\npermutation equivariant, and additive position embeddings to the input are used\nto supply the information about the order of the input tokens. Further, for\nsome tasks, additional additive segment embeddings are used to denote different\ntypes of input sentences. Recent works proposed variations of positional\nencodings with relative position encodings achieving better performance. In\nthis work, we do a systematic study comparing different position encodings and\nunderstanding the reasons for differences in their performance. We demonstrate\na simple yet effective way to encode position and segment into the Transformer\nmodels. The proposed method performs on par with SOTA on GLUE, XTREME and WMT\nbenchmarks while saving computation costs.\n", "versions": [{"version": "v1", "created": "Sun, 18 Apr 2021 03:44:57 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Chen", "Pu-Chin", ""], ["Tsai", "Henry", ""], ["Bhojanapalli", "Srinadh", ""], ["Chung", "Hyung Won", ""], ["Chang", "Yin-Wen", ""], ["Ferng", "Chun-Sung", ""]]}, {"id": "2104.08708", "submitter": "Haochuan Li", "authors": "Haochuan Li, Yi Tian, Jingzhao Zhang, Ali Jadbabaie", "title": "Complexity Lower Bounds for Nonconvex-Strongly-Concave Min-Max\n  Optimization", "comments": "20 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide a first-order oracle complexity lower bound for finding stationary\npoints of min-max optimization problems where the objective function is smooth,\nnonconvex in the minimization variable, and strongly concave in the\nmaximization variable. We establish a lower bound of\n$\\Omega\\left(\\sqrt{\\kappa}\\epsilon^{-2}\\right)$ for deterministic oracles,\nwhere $\\epsilon$ defines the level of approximate stationarity and $\\kappa$ is\nthe condition number. Our analysis shows that the upper bound achieved in (Lin\net al., 2020b) is optimal in the $\\epsilon$ and $\\kappa$ dependence up to\nlogarithmic factors. For stochastic oracles, we provide a lower bound of\n$\\Omega\\left(\\sqrt{\\kappa}\\epsilon^{-2} + \\kappa^{1/3}\\epsilon^{-4}\\right)$. It\nsuggests that there is a significant gap between the upper bound\n$\\mathcal{O}(\\kappa^3 \\epsilon^{-4})$ in (Lin et al., 2020a) and our lower\nbound in the condition number dependence.\n", "versions": [{"version": "v1", "created": "Sun, 18 Apr 2021 04:30:01 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Li", "Haochuan", ""], ["Tian", "Yi", ""], ["Zhang", "Jingzhao", ""], ["Jadbabaie", "Ali", ""]]}, {"id": "2104.08729", "submitter": "Xianjie Shen", "authors": "Xianjie Shen, Yinghan Wang, Rui Meng, Jingbo Shang", "title": "Unsupervised Deep Keyphrase Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Keyphrase generation aims to summarize long documents with a collection of\nsalient phrases. Deep neural models have demonstrated a remarkable success in\nthis task, capable of predicting keyphrases that are even absent from a\ndocument. However, such abstractiveness is acquired at the expense of a\nsubstantial amount of annotated data. In this paper, we present a novel method\nfor keyphrase generation, AutoKeyGen, without the supervision of any human\nannotation. Motivated by the observation that an absent keyphrase in one\ndocument can appear in other places, in whole or in part, we first construct a\nphrase bank by pooling all phrases in a corpus. With this phrase bank, we then\ndraw candidate absent keyphrases for each document through a partial matching\nprocess. To rank both types of candidates, we combine their lexical- and\nsemantic-level similarities to the input document. Moreover, we utilize these\ntop-ranked candidates as to train a deep generative model for more absent\nkeyphrases. Extensive experiments demonstrate that AutoKeyGen outperforms all\nunsupervised baselines and can even beat strong supervised methods in certain\ncases.\n", "versions": [{"version": "v1", "created": "Sun, 18 Apr 2021 05:53:19 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Shen", "Xianjie", ""], ["Wang", "Yinghan", ""], ["Meng", "Rui", ""], ["Shang", "Jingbo", ""]]}, {"id": "2104.08736", "submitter": "Qi Qi", "authors": "Qi Qi, Youzhi Luo, Zhao Xu, Shuiwang Ji, Tianbao Yang", "title": "Stochastic Optimization of Areas Under Precision-Recall Curves with\n  Provable Convergence", "comments": "24 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Areas under ROC (AUROC) and precision-recall curves (AUPRC) are common\nmetrics for evaluating classification performance for imbalanced problems.\nCompared with AUROC, AUPRC is a more appropriate metric for highly imbalanced\ndatasets. While stochastic optimization of AUROC has been studied extensively,\nprincipled stochastic optimization of AUPRC has been rarely explored. In this\nwork, we propose a principled technical method to optimize AUPRC for deep\nlearning. Our approach is based on maximizing the averaged precision (AP),\nwhich is an unbiased point estimator of AUPRC. We cast the objective into a sum\nof {\\it dependent compositional functions} with inner functions dependent on\nrandom variables of the outer level. We propose efficient adaptive and\nnon-adaptive stochastic algorithms with {\\it provable convergence guarantee\nunder mild conditions} by leveraging recent advances in stochastic\ncompositional optimization. Extensive experimental results on image and graph\ndatasets demonstrate that our proposed method outperforms prior methods on\nimbalanced problems in terms of AUPRC. To the best of our knowledge, our work\nrepresents the first attempt to optimize AUPRC with provable convergence.\n", "versions": [{"version": "v1", "created": "Sun, 18 Apr 2021 06:22:21 GMT"}, {"version": "v2", "created": "Wed, 2 Jun 2021 05:06:40 GMT"}, {"version": "v3", "created": "Sun, 6 Jun 2021 15:20:25 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Qi", "Qi", ""], ["Luo", "Youzhi", ""], ["Xu", "Zhao", ""], ["Ji", "Shuiwang", ""], ["Yang", "Tianbao", ""]]}, {"id": "2104.08737", "submitter": "Akhil Arora", "authors": "Akhil Arora, Alberto Garcia-Duran, Robert West", "title": "Low-rank Subspaces for Unsupervised Entity Linking", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Entity linking is an important problem with many applications. Most previous\nsolutions were designed for settings where annotated training data is\navailable, which is, however, not the case in numerous domains. We propose a\nlight-weight and scalable entity linking method, Eigenthemes, that relies\nsolely on the availability of entity names and a referent knowledge base.\nEigenthemes exploits the fact that the entities that are truly mentioned in a\ndocument (the \"gold entities\") tend to form a semantically dense subset of the\nset of all candidate entities in the document. Geometrically speaking, when\nrepresenting entities as vectors via some given embedding, the gold entities\ntend to lie in a low-rank subspace of the full embedding space. Eigenthemes\nidentifies this subspace using the singular value decomposition and scores\ncandidate entities according to their proximity to the subspace. On the\nempirical front, we introduce multiple strong baselines that compare favorably\nto the existing state of the art. Extensive experiments on benchmark datasets\nfrom a variety of real-world domains showcase the effectiveness of our\napproach.\n", "versions": [{"version": "v1", "created": "Sun, 18 Apr 2021 06:24:48 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Arora", "Akhil", ""], ["Garcia-Duran", "Alberto", ""], ["West", "Robert", ""]]}, {"id": "2104.08760", "submitter": "Guangrun Wang", "authors": "Guangrun Wang, Keze Wang, Guangcong Wang, Philip H.S. Torr, Liang Lin", "title": "Towards Solving Inefficiency of Self-supervised Representation Learning", "comments": "12 pages, 5 figures, 8 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Self-supervised learning (especially contrastive learning) has attracted\ngreat interest due to its tremendous potentials in learning discriminative\nrepresentations in an unsupervised manner. Despite the acknowledged successes,\nexisting contrastive learning methods suffer from very low learning efficiency,\ne.g., taking about ten times more training epochs than supervised learning for\ncomparable recognition accuracy. In this paper, we discover two contradictory\nphenomena in contrastive learning that we call under-clustering and\nover-clustering problems, which are major obstacles to learning efficiency.\nUnder-clustering means that the model cannot efficiently learn to discover the\ndissimilarity between inter-class samples when the negative sample pairs for\ncontrastive learning are insufficient to differentiate all the actual object\ncategories. Over-clustering implies that the model cannot efficiently learn the\nfeature representation from excessive negative sample pairs, which enforces the\nmodel to over-cluster samples of the same actual categories into different\nclusters. To simultaneously overcome these two problems, we propose a novel\nself-supervised learning framework using a median triplet loss. Precisely, we\nemploy a triplet loss tending to maximize the relative distance between the\npositive pair and negative pairs to address the under-clustering problem; and\nwe construct the negative pair by selecting the negative sample of a median\nsimilarity score from all negative samples to avoid the over-clustering\nproblem, guaranteed by the Bernoulli Distribution model. We extensively\nevaluate our proposed framework in several large-scale benchmarks (e.g.,\nImageNet, SYSU-30k, and COCO). The results demonstrate the superior performance\n(e.g., the learning efficiency) of our model over the latest state-of-the-art\nmethods by a clear margin. Codes available at:\nhttps://github.com/wanggrun/triplet.\n", "versions": [{"version": "v1", "created": "Sun, 18 Apr 2021 07:47:10 GMT"}, {"version": "v2", "created": "Tue, 22 Jun 2021 10:30:49 GMT"}], "update_date": "2021-06-23", "authors_parsed": [["Wang", "Guangrun", ""], ["Wang", "Keze", ""], ["Wang", "Guangcong", ""], ["Torr", "Philip H. S.", ""], ["Lin", "Liang", ""]]}, {"id": "2104.08762", "submitter": "Rajarshi Das", "authors": "Rajarshi Das, Manzil Zaheer, Dung Thai, Ameya Godbole, Ethan Perez,\n  Jay-Yoon Lee, Lizhen Tan, Lazaros Polymenakos, Andrew McCallum", "title": "Case-based Reasoning for Natural Language Queries over Knowledge Bases", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is often challenging for a system to solve a new complex problem from\nscratch, but much easier if the system can access other similar problems and\ndescription of their solutions -- a paradigm known as case-based reasoning\n(CBR). We propose a neuro-symbolic CBR approach for question answering over\nlarge knowledge bases (CBR-KBQA). While the idea of CBR is tempting, composing\na solution from cases is nontrivial, when individual cases only contain partial\nlogic to the full solution. To resolve this, CBR-KBQA consists of two modules:\na non-parametric memory that stores cases (question and logical forms) and a\nparametric model which can generate logical forms by retrieving relevant cases\nfrom memory. Through experiments, we show that CBR-KBQA can effectively derive\nnovel combination of relations not presented in case memory that is required to\nanswer compositional questions. On several KBQA datasets that test\ncompositional generalization, CBR-KBQA achieves competitive performance. For\nexample, on the challenging ComplexWebQuestions dataset, CBR-KBQA outperforms\nthe current state of the art by 11% accuracy. Furthermore, we show that\nCBR-KBQA is capable of using new cases \\emph{without} any further training.\nJust by incorporating few human-labeled examples in the non-parametric case\nmemory, CBR-KBQA is able to successfully generate queries containing unseen KB\nrelations.\n", "versions": [{"version": "v1", "created": "Sun, 18 Apr 2021 07:50:31 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Das", "Rajarshi", ""], ["Zaheer", "Manzil", ""], ["Thai", "Dung", ""], ["Godbole", "Ameya", ""], ["Perez", "Ethan", ""], ["Lee", "Jay-Yoon", ""], ["Tan", "Lizhen", ""], ["Polymenakos", "Lazaros", ""], ["McCallum", "Andrew", ""]]}, {"id": "2104.08767", "submitter": "Jinhuan Wang", "authors": "Jinhuan Wang and Pengtao Chen and Shanqing Yu and Qi Xuan", "title": "TSGN: Transaction Subgraph Networks for Identifying Ethereum Phishing\n  Accounts", "comments": "14 pages, 2 fihures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Blockchain technology and, in particular, blockchain-based transaction offers\nus information that has never been seen before in the financial world. In\ncontrast to fiat currencies, transactions through virtual currencies like\nBitcoin are completely public. And these transactions of cryptocurrencies are\npermanently recorded on Blockchain and are available at any time. Therefore,\nthis allows us to build transaction networks (TN) to analyze illegal\nphenomenons such as phishing scams in blockchain from a network perspective. In\nthis paper, we propose a Transaction SubGraph Network (TSGN) based\nclassification model to identify phishing accounts in Ethereum. Firstly we\nextract transaction subgraphs for each address and then expand these subgraphs\ninto corresponding TSGNs based on the different mapping mechanisms. We find\nthat TSGNs can provide more potential information to benefit the identification\nof phishing accounts. Moreover, Directed-TSGNs, by introducing direction\nattributes, can retain the transaction flow information that captures the\nsignificant topological pattern of phishing scams. By comparing with the TSGN,\nDirected-TSGN indeed has much lower time complexity, benefiting the graph\nrepresentation learning. Experimental results demonstrate that, combined with\nnetwork representation algorithms, the TSGN model can capture more features to\nenhance the classification algorithm and improve phishing nodes' identification\naccuracy in the Ethereum networks.\n", "versions": [{"version": "v1", "created": "Sun, 18 Apr 2021 08:12:51 GMT"}, {"version": "v2", "created": "Tue, 20 Apr 2021 13:48:30 GMT"}], "update_date": "2021-04-21", "authors_parsed": [["Wang", "Jinhuan", ""], ["Chen", "Pengtao", ""], ["Yu", "Shanqing", ""], ["Xuan", "Qi", ""]]}, {"id": "2104.08773", "submitter": "Swaroop Mishra", "authors": "Swaroop Mishra, Daniel Khashabi, Chitta Baral, Hannaneh Hajishirzi", "title": "Natural Instructions: Benchmarking Generalization to New Tasks from\n  Natural Language Instructions", "comments": "18 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Can we enable NLP models to appropriately respond to instructional prompts\nand consequently generalize to new tasks? To study this question, we leverage\nthe existing NLP datasets and the instructions that were used to crowdsource\nthem to create NATURAL INSTRUCTIONS, a dataset of instructions and\ntask-specific input/output data. This dataset consists of 61 distinct language\ninstructions and about 600k task instances, and is used to evaluate existing\nstate-of-the-art language-models (LMs) in addressing new tasks by few-shot\nprompting of GPT3 and fine-tuning BART. Our analysis indicates that: (a) the\nexisting models indeed benefit from instructions and hence, show improved\ngeneralization to new tasks; (b) while models like GPT-3 generally benefit from\ninstructions, the extent of their gains varies across different fields of\ninstructions and also depends on the task being solved; (c) generalization to\nunseen tasks in NATURAL INSTRUCTIONS remains far from perfect for the\nstate-of-the-art, indicating significant room for more progress in this\ndirection.\n", "versions": [{"version": "v1", "created": "Sun, 18 Apr 2021 08:44:56 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Mishra", "Swaroop", ""], ["Khashabi", "Daniel", ""], ["Baral", "Chitta", ""], ["Hajishirzi", "Hannaneh", ""]]}, {"id": "2104.08776", "submitter": "Hossein Hosseini", "authors": "Hossein Hosseini, Hyunsin Park, Sungrack Yun, Christos Louizos, Joseph\n  Soriaga, Max Welling", "title": "Federated Learning of User Verification Models Without Sharing\n  Embeddings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We consider the problem of training User Verification (UV) models in\nfederated setting, where each user has access to the data of only one class and\nuser embeddings cannot be shared with the server or other users. To address\nthis problem, we propose Federated User Verification (FedUV), a framework in\nwhich users jointly learn a set of vectors and maximize the correlation of\ntheir instance embeddings with a secret linear combination of those vectors. We\nshow that choosing the linear combinations from the codewords of an\nerror-correcting code allows users to collaboratively train the model without\nrevealing their embedding vectors. We present the experimental results for user\nverification with voice, face, and handwriting data and show that FedUV is on\npar with existing approaches, while not sharing the embeddings with other users\nor the server.\n", "versions": [{"version": "v1", "created": "Sun, 18 Apr 2021 08:51:39 GMT"}, {"version": "v2", "created": "Mon, 7 Jun 2021 17:32:41 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Hosseini", "Hossein", ""], ["Park", "Hyunsin", ""], ["Yun", "Sungrack", ""], ["Louizos", "Christos", ""], ["Soriaga", "Joseph", ""], ["Welling", "Max", ""]]}, {"id": "2104.08795", "submitter": "Buddhika Semage", "authors": "Buddhika Laknath Semage, Thommen George Karimpanal, Santu Rana, Svetha\n  Venkatesh", "title": "Intuitive Physics Guided Exploration for Sample Efficient Sim2real\n  Transfer", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Physics-based reinforcement learning tasks can benefit from simplified\nphysics simulators as they potentially allow near-optimal policies to be\nlearned in simulation. However, such simulators require the latent factors\n(e.g. mass, friction coefficient etc.) of the associated objects and other\nenvironment-specific factors (e.g. wind speed, air density etc.) to be\naccurately specified, without which, it could take considerable additional\nlearning effort to adapt the learned simulation policy to the real environment.\nAs such a complete specification can be impractical, in this paper, we instead,\nfocus on learning task-specific estimates of latent factors which allow the\napproximation of real world trajectories in an ideal simulation environment.\nSpecifically, we propose two new concepts: a) action grouping - the idea that\ncertain types of actions are closely associated with the estimation of certain\nlatent factors, and; b) partial grounding - the idea that simulation of\ntask-specific dynamics may not need precise estimation of all the latent\nfactors. We first introduce intuitive action groupings based on human physics\nknowledge and experience, which is then used to design novel strategies for\ninteracting with the real environment. Next, we describe how prior knowledge of\na task in a given environment can be used to extract the relative importance of\ndifferent latent factors, and how this can be used to inform partial grounding,\nwhich enables efficient learning of the task in any arbitrary environment. We\ndemonstrate our approach in a range of physics based tasks, and show that it\nachieves superior performance relative to other baselines, using only a limited\nnumber of real-world interactions.\n", "versions": [{"version": "v1", "created": "Sun, 18 Apr 2021 10:03:26 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Semage", "Buddhika Laknath", ""], ["Karimpanal", "Thommen George", ""], ["Rana", "Santu", ""], ["Venkatesh", "Svetha", ""]]}, {"id": "2104.08801", "submitter": "Devang Kulshreshtha", "authors": "Devang Kulshreshtha, Robert Belfer, Iulian Vlad Serban, Siva Reddy", "title": "Back-Training excels Self-Training at Unsupervised Domain Adaptation of\n  Question Generation and Passage Retrieval", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we propose a new domain adaptation method called\n$\\textit{back-training}$, a superior alternative to self-training. While\nself-training results in synthetic training data of the form quality inputs\naligned with noisy outputs, back-training results in noisy inputs aligned with\nquality outputs. Our experimental results on unsupervised domain adaptation of\nquestion generation and passage retrieval models from $\\textit{Natural\nQuestions}$ domain to the machine learning domain show that back-training\noutperforms self-training by a large margin: 9.3 BLEU-1 points on generation,\nand 7.9 accuracy points on top-1 retrieval. We release $\\textit{MLQuestions}$,\na domain-adaptation dataset for the machine learning domain containing 50K\nunaligned passages and 35K unaligned questions, and 3K aligned passage and\nquestion pairs. Our data and code are available at\nhttps://github.com/McGill-NLP/MLQuestions\n", "versions": [{"version": "v1", "created": "Sun, 18 Apr 2021 10:20:07 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Kulshreshtha", "Devang", ""], ["Belfer", "Robert", ""], ["Serban", "Iulian Vlad", ""], ["Reddy", "Siva", ""]]}, {"id": "2104.08803", "submitter": "Tal Schuster", "authors": "Tal Schuster, Adam Fisch, Tommi Jaakkola, Regina Barzilay", "title": "Consistent Accelerated Inference via Confident Adaptive Transformers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a novel approach for confidently accelerating inference in the\nlarge and expensive multilayer Transformers that are now ubiquitous in natural\nlanguage processing (NLP). Amortized or approximate computational methods\nincrease efficiency, but can come with unpredictable performance costs. In this\nwork, we present CATs -- Confident Adaptive Transformers -- in which we\nsimultaneously increase computational efficiency, while guaranteeing a\nspecifiable degree of consistency with the original model with high confidence.\nOur method trains additional prediction heads on top of intermediate layers,\nand dynamically decides when to stop allocating computational effort to each\ninput using a meta consistency classifier. To calibrate our early prediction\nstopping rule, we formulate a unique extension of conformal prediction. We\ndemonstrate the effectiveness of this approach on four classification and\nregression tasks.\n", "versions": [{"version": "v1", "created": "Sun, 18 Apr 2021 10:22:28 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Schuster", "Tal", ""], ["Fisch", "Adam", ""], ["Jaakkola", "Tommi", ""], ["Barzilay", "Regina", ""]]}, {"id": "2104.08804", "submitter": "Harkanwar Singh", "authors": "Harkanwar Singh, Prachi Jain, Mausam, Soumen Chakrabarti", "title": "Multilingual Knowledge Graph Completion with Joint Relation and Entity\n  Alignment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge Graph Completion (KGC) predicts missing facts in an incomplete\nKnowledge Graph. Almost all of existing KGC research is applicable to only one\nKG at a time, and in one language only. However, different language speakers\nmay maintain separate KGs in their language and no individual KG is expected to\nbe complete. Moreover, common entities or relations in these KGs have different\nsurface forms and IDs, leading to ID proliferation. Entity alignment (EA) and\nrelation alignment (RA) tasks resolve this by recognizing pairs of entity\n(relation) IDs in different KGs that represent the same entity (relation). This\ncan further help prediction of missing facts, since knowledge from one KG is\nlikely to benefit completion of another. High confidence predictions may also\nadd valuable information for the alignment tasks. In response, we study the\nnovel task of jointly training multilingual KGC, relation alignment and entity\nalignment models. We present ALIGNKGC, which uses some seed alignments to\njointly optimize all three of KGC, EA and RA losses. A key component of\nALIGNKGC is an embedding based soft notion of asymmetric overlap defined on the\n(subject, object) set signatures of relations this aids in better predicting\nrelations that are equivalent to or implied by other relations. Extensive\nexperiments with DBPedia in five languages establish the benefits of joint\ntraining for all tasks, achieving 10-32 MRR improvements of ALIGNKGC over a\nstrong state-of-the-art single-KGC system completion model over each\nmonolingual KG . Further, ALIGNKGC achieves reasonable gains in EA and RA tasks\nover a vanilla completion model over a KG that combines all facts without\nalignment, underscoring the value of joint training for these tasks.\n", "versions": [{"version": "v1", "created": "Sun, 18 Apr 2021 10:27:44 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Singh", "Harkanwar", ""], ["Jain", "Prachi", ""], ["Mausam", "", ""], ["Chakrabarti", "Soumen", ""]]}, {"id": "2104.08806", "submitter": "Mimansa Jaiswal", "authors": "Mimansa Jaiswal, Emily Mower Provost", "title": "Best Practices for Noise-Based Augmentation to Improve the Performance\n  of Emotion Recognition \"In the Wild\"", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Emotion recognition as a key component of high-stake downstream applications\nhas been shown to be effective, such as classroom engagement or mental health\nassessments. These systems are generally trained on small datasets collected in\nsingle laboratory environments, and hence falter when tested on data that has\ndifferent noise characteristics. Multiple noise-based data augmentation\napproaches have been proposed to counteract this challenge in other speech\ndomains. But, unlike speech recognition and speaker verification, in emotion\nrecognition, noise-based data augmentation may change the underlying label of\nthe original emotional sample. In this work, we generate realistic noisy\nsamples of a well known emotion dataset (IEMOCAP) using multiple categories of\nenvironmental and synthetic noise. We evaluate how both human and machine\nemotion perception changes when noise is introduced. We find that some commonly\nused augmentation techniques for emotion recognition significantly change human\nperception, which may lead to unreliable evaluation metrics such as evaluating\nefficiency of adversarial attack. We also find that the trained\nstate-of-the-art emotion recognition models fail to classify unseen\nnoise-augmented samples, even when trained on noise augmented datasets. This\nfinding demonstrates the brittleness of these systems in real-world conditions.\nWe propose a set of recommendations for noise-based augmentation of emotion\ndatasets and for how to deploy these emotion recognition systems \"in the wild\".\n", "versions": [{"version": "v1", "created": "Sun, 18 Apr 2021 10:33:38 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Jaiswal", "Mimansa", ""], ["Provost", "Emily Mower", ""]]}, {"id": "2104.08809", "submitter": "Arie Cattan", "authors": "Arie Cattan, Sophie Johnson, Daniel Weld, Ido Dagan, Iz Beltagy, Doug\n  Downey, Tom Hope", "title": "SciCo: Hierarchical Cross-Document Coreference for Scientific Concepts", "comments": "Data and code available at https://github.com/ariecattan/SciCo", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Determining coreference of concept mentions across multiple documents is\nfundamental for natural language understanding. Work on cross-document\ncoreference resolution (CDCR) typically considers mentions of events in the\nnews, which do not often involve abstract technical concepts that are prevalent\nin science and technology. These complex concepts take diverse or ambiguous\nforms and have many hierarchical levels of granularity (e.g., tasks and\nsubtasks), posing challenges for CDCR. We present a new task of hierarchical\nCDCR for concepts in scientific papers, with the goal of jointly inferring\ncoreference clusters and hierarchy between them. We create SciCo, an\nexpert-annotated dataset for this task, which is 3X larger than the prominent\nECB+ resource. We find that tackling both coreference and hierarchy at once\noutperforms disjoint models, which we hope will spur development of joint\nmodels for SciCo.\n", "versions": [{"version": "v1", "created": "Sun, 18 Apr 2021 10:42:20 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Cattan", "Arie", ""], ["Johnson", "Sophie", ""], ["Weld", "Daniel", ""], ["Dagan", "Ido", ""], ["Beltagy", "Iz", ""], ["Downey", "Doug", ""], ["Hope", "Tom", ""]]}, {"id": "2104.08815", "submitter": "Bill Yuchen Lin", "authors": "Bill Yuchen Lin, Chaoyang He, Zihang Zeng, Hulin Wang, Yufen Huang,\n  Mahdi Soltanolkotabi, Xiang Ren, Salman Avestimehr", "title": "FedNLP: A Research Platform for Federated Learning in Natural Language\n  Processing", "comments": "Github link: https://github.com/FedML-AI/FedNLP", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Increasing concerns and regulations about data privacy, necessitate the study\nof privacy-preserving methods for natural language processing (NLP)\napplications. Federated learning (FL) provides promising methods for a large\nnumber of clients (i.e., personal devices or organizations) to collaboratively\nlearn a shared global model to benefit all clients, while allowing users to\nkeep their data locally. To facilitate FL research in NLP, we present the\nFedNLP, a research platform for federated learning in NLP. FedNLP supports\nvarious popular task formulations in NLP such as text classification, sequence\ntagging, question answering, seq2seq generation, and language modeling. We also\nimplement an interface between Transformer language models (e.g., BERT) and FL\nmethods (e.g., FedAvg, FedOpt, etc.) for distributed training. The evaluation\nprotocol of this interface supports a comprehensive collection of non-IID\npartitioning strategies. Our preliminary experiments with FedNLP reveal that\nthere exists a large performance gap between learning on decentralized and\ncentralized datasets -- opening intriguing and exciting future research\ndirections aimed at developing FL methods suited to NLP tasks.\n", "versions": [{"version": "v1", "created": "Sun, 18 Apr 2021 11:04:49 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Lin", "Bill Yuchen", ""], ["He", "Chaoyang", ""], ["Zeng", "Zihang", ""], ["Wang", "Hulin", ""], ["Huang", "Yufen", ""], ["Soltanolkotabi", "Mahdi", ""], ["Ren", "Xiang", ""], ["Avestimehr", "Salman", ""]]}, {"id": "2104.08821", "submitter": "Tianyu Gao", "authors": "Tianyu Gao, Xingcheng Yao, Danqi Chen", "title": "SimCSE: Simple Contrastive Learning of Sentence Embeddings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents SimCSE, a simple contrastive learning framework that\ngreatly advances the state-of-the-art sentence embeddings. We first describe an\nunsupervised approach, which takes an input sentence and predicts itself in a\ncontrastive objective, with only standard dropout used as noise. This simple\nmethod works surprisingly well, performing on par with previous supervised\ncounterparts. We hypothesize that dropout acts as minimal data augmentation and\nremoving it leads to a representation collapse. Then, we draw inspiration from\nthe recent success of learning sentence embeddings from natural language\ninference (NLI) datasets and incorporate annotated pairs from NLI datasets into\ncontrastive learning by using \"entailment\" pairs as positives and\n\"contradiction\" pairs as hard negatives. We evaluate SimCSE on standard\nsemantic textual similarity (STS) tasks, and our unsupervised and supervised\nmodels using BERT-base achieve an average of 74.5% and 81.6% Spearman's\ncorrelation respectively, a 7.9 and 4.6 points improvement compared to previous\nbest results. We also show that contrastive learning theoretically regularizes\npre-trained embeddings' anisotropic space to be more uniform, and it better\naligns positive pairs when supervised signals are available.\n", "versions": [{"version": "v1", "created": "Sun, 18 Apr 2021 11:27:08 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Gao", "Tianyu", ""], ["Yao", "Xingcheng", ""], ["Chen", "Danqi", ""]]}, {"id": "2104.08835", "submitter": "Qinyuan Ye", "authors": "Qinyuan Ye, Bill Yuchen Lin, Xiang Ren", "title": "CrossFit: A Few-shot Learning Challenge for Cross-task Generalization in\n  NLP", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Humans can learn a new language task more efficiently than machines,\nconceivably by leveraging their prior experience and knowledge in learning\nother tasks. In this paper, we explore whether such cross-task generalization\nability can be acquired, and further applied to build better few-shot learners\nacross diverse NLP tasks. We introduce CrossFit, a task setup for studying\ncross-task few-shot learning ability, which standardizes seen/unseen task\nsplits, data access during different learning stages, and the evaluation\nprotocols. In addition, we present NLP Few-shot Gym, a repository of 160\nfew-shot NLP tasks, covering diverse task categories and applications, and\nconverted to a unified text-to-text format. Our empirical analysis reveals that\nthe few-shot learning ability on unseen tasks can be improved via an upstream\nlearning stage using a set of seen tasks. Additionally, the advantage lasts\ninto medium-resource scenarios when thousands of training examples are\navailable. We also observe that selection of upstream learning tasks can\nsignificantly influence few-shot performance on unseen tasks, asking further\nanalysis on task similarity and transferability.\n", "versions": [{"version": "v1", "created": "Sun, 18 Apr 2021 12:14:46 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Ye", "Qinyuan", ""], ["Lin", "Bill Yuchen", ""], ["Ren", "Xiang", ""]]}, {"id": "2104.08840", "submitter": "Qinyuan Ye", "authors": "Qinyuan Ye, Belinda Z. Li, Sinong Wang, Benjamin Bolte, Hao Ma,\n  Wen-tau Yih, Xiang Ren, Madian Khabsa", "title": "On the Influence of Masking Policies in Intermediate Pre-training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Current NLP models are predominantly trained through a pretrain-then-finetune\npipeline, where models are first pretrained on a large text corpus with a\nmasked-language-modelling (MLM) objective, then finetuned on the downstream\ntask. Prior work has shown that inserting an intermediate pre-training phase,\nwith heuristic MLM objectives that resemble downstream tasks, can significantly\nimprove final performance. However, it is still unclear (1) in what cases such\nintermediate pre-training is helpful, (2) whether hand-crafted heuristic\nobjectives are optimal for a given task, and (3) whether a MLM policy designed\nfor one task is generalizable beyond that task. In this paper, we perform a\nlarge-scale empirical study to investigate the effect of various MLM policies\nin intermediate pre-training. Crucially, we introduce methods to automate\ndiscovery of optimal MLM policies, by learning a masking model through either\ndirect supervision or meta-learning on the downstream task. We investigate the\neffects of using heuristic, directly supervised, and meta-learned MLM policies\nfor intermediate pretraining, on eight selected tasks across three categories\n(closed-book QA, knowledge-intensive language tasks, and abstractive\nsummarization). Most notably, we show that learned masking policies outperform\nthe heuristic of masking named entities on TriviaQA, and masking policies\nlearned on one task can positively transfer to other tasks in certain cases.\n", "versions": [{"version": "v1", "created": "Sun, 18 Apr 2021 12:32:23 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Ye", "Qinyuan", ""], ["Li", "Belinda Z.", ""], ["Wang", "Sinong", ""], ["Bolte", "Benjamin", ""], ["Ma", "Hao", ""], ["Yih", "Wen-tau", ""], ["Ren", "Xiang", ""], ["Khabsa", "Madian", ""]]}, {"id": "2104.08850", "submitter": "Kemal Tugrul Yesilbek", "authors": "Kemal Tugrul Yesilbek, T. Metin Sezgin", "title": "On Training Sketch Recognizers for New Domains", "comments": "Accepted for The 1st Workshop on Sketch-Oriented Deep Learning\n  (SketchDL) @ CVPR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sketch recognition algorithms are engineered and evaluated using publicly\navailable datasets contributed by the sketch recognition community over the\nyears. While existing datasets contain sketches of a limited set of generic\nobjects, each new domain inevitably requires collecting new data for training\ndomain specific recognizers. This gives rise to two fundamental concerns:\nFirst, will the data collection protocol yield ecologically valid data? Second,\nwill the amount of collected data suffice to train sufficiently accurate\nclassifiers? In this paper, we draw attention to these two concerns. We show\nthat the ecological validity of the data collection protocol and the ability to\naccommodate small datasets are significant factors impacting recognizer\naccuracy in realistic scenarios. More specifically, using sketch-based gaming\nas a use case, we show that deep learning methods, as well as more traditional\nmethods, suffer significantly from dataset shift. Furthermore, we demonstrate\nthat in realistic scenarios where data is scarce and expensive, standard\nmeasures taken for adapting deep learners to small datasets fall short of\ncomparing favorably with alternatives. Although transfer learning, and\nextensive data augmentation help deep learners, they still perform\nsignificantly worse compared to standard setups (e.g., SVMs and GBMs with\nstandard feature representations). We pose learning from small datasets as a\nkey problem for the deep sketch recognition field, one which has been ignored\nin the bulk of the existing literature.\n", "versions": [{"version": "v1", "created": "Sun, 18 Apr 2021 13:24:49 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Yesilbek", "Kemal Tugrul", ""], ["Sezgin", "T. Metin", ""]]}, {"id": "2104.08869", "submitter": "Clemens Damke", "authors": "Clemens Damke and Eyke H\\\"ullermeier", "title": "Ranking Structured Objects with Graph Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Graph neural networks (GNNs) have been successfully applied in many\nstructured data domains, with applications ranging from molecular property\nprediction to the analysis of social networks. Motivated by the broad\napplicability of GNNs, we propose the family of so-called RankGNNs, a\ncombination of neural Learning to Rank (LtR) methods and GNNs. RankGNNs are\ntrained with a set of pair-wise preferences between graphs, suggesting that one\nof them is preferred over the other. One practical application of this problem\nis drug screening, where an expert wants to find the most promising molecules\nin a large collection of drug candidates. We empirically demonstrate that our\nproposed pair-wise RankGNN approach either significantly outperforms or at\nleast matches the ranking performance of the naive point-wise baseline\napproach, in which the LtR problem is solved via GNN-based graph regression.\n", "versions": [{"version": "v1", "created": "Sun, 18 Apr 2021 14:40:59 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Damke", "Clemens", ""], ["H\u00fcllermeier", "Eyke", ""]]}, {"id": "2104.08876", "submitter": "Songan Zhang", "authors": "Songan Zhang, Lu Wen, Huei Peng, H. Eric Tseng", "title": "Quick Learner Automated Vehicle Adapting its Roadmanship to Varying\n  Traffic Cultures with Meta Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is essential for an automated vehicle in the field to perform\ndiscretionary lane changes with appropriate roadmanship - driving safely and\nefficiently without annoying or endangering other road users - under a wide\nrange of traffic cultures and driving conditions. While deep reinforcement\nlearning methods have excelled in recent years and been applied to automated\nvehicle driving policy, there are concerns about their capability to quickly\nadapt to unseen traffic with new environment dynamics. We formulate this\nchallenge as a multi-Markov Decision Processes (MDPs) adaptation problem and\ndeveloped Meta Reinforcement Learning (MRL) driving policies to showcase their\nquick learning capability. Two types of distribution variation in environments\nwere designed and simulated to validate the fast adaptation capability of\nresulting MRL driving policies which significantly outperform a baseline RL.\n", "versions": [{"version": "v1", "created": "Sun, 18 Apr 2021 15:04:37 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Zhang", "Songan", ""], ["Wen", "Lu", ""], ["Peng", "Huei", ""], ["Tseng", "H. Eric", ""]]}, {"id": "2104.08878", "submitter": "Samuel Bell", "authors": "Samuel J. Bell and Onno P. Kampman", "title": "Perspectives on Machine Learning from Psychology's Reproducibility\n  Crisis", "comments": "Added acknowledgements; assorted minor edits", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the early 2010s, a crisis of reproducibility rocked the field of\npsychology. Following a period of reflection, the field has responded with\nradical reform of its scientific practices. More recently, similar questions\nabout the reproducibility of machine learning research have also come to the\nfore. In this short paper, we present select ideas from psychology's\nreformation, translating them into relevance for a machine learning audience.\n", "versions": [{"version": "v1", "created": "Sun, 18 Apr 2021 15:17:35 GMT"}, {"version": "v2", "created": "Fri, 23 Apr 2021 11:44:47 GMT"}], "update_date": "2021-04-26", "authors_parsed": [["Bell", "Samuel J.", ""], ["Kampman", "Onno P.", ""]]}, {"id": "2104.08885", "submitter": "Patrick Zschech", "authors": "Christoph Sager, Christian Janiesch, Patrick Zschech", "title": "A survey of image labelling for computer vision applications", "comments": "Published online first in Journal of Business Analytics", "journal-ref": null, "doi": "10.1080/2573234X.2021.1908861", "report-no": null, "categories": "cs.CV cs.HC cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Supervised machine learning methods for image analysis require large amounts\nof labelled training data to solve computer vision problems. The recent rise of\ndeep learning algorithms for recognising image content has led to the emergence\nof many ad-hoc labelling tools. With this survey, we capture and systematise\nthe commonalities as well as the distinctions between existing image labelling\nsoftware. We perform a structured literature review to compile the underlying\nconcepts and features of image labelling software such as annotation\nexpressiveness and degree of automation. We structure the manual labelling task\nby its organisation of work, user interface design options, and user support\ntechniques to derive a systematisation schema for this survey. Applying it to\navailable software and the body of literature, enabled us to uncover several\napplication archetypes and key domains such as image retrieval or instance\nidentification in healthcare or television.\n", "versions": [{"version": "v1", "created": "Sun, 18 Apr 2021 16:01:55 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Sager", "Christoph", ""], ["Janiesch", "Christian", ""], ["Zschech", "Patrick", ""]]}, {"id": "2104.08894", "submitter": "Ahmed Abdelkader", "authors": "Phillip Pope, Chen Zhu, Ahmed Abdelkader, Micah Goldblum, Tom\n  Goldstein", "title": "The Intrinsic Dimension of Images and Its Impact on Learning", "comments": "To appear at ICLR 2021 (spotlight), 17 pages with appendix, 15\n  figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  It is widely believed that natural image data exhibits low-dimensional\nstructure despite the high dimensionality of conventional pixel\nrepresentations. This idea underlies a common intuition for the remarkable\nsuccess of deep learning in computer vision. In this work, we apply dimension\nestimation tools to popular datasets and investigate the role of\nlow-dimensional structure in deep learning. We find that common natural image\ndatasets indeed have very low intrinsic dimension relative to the high number\nof pixels in the images. Additionally, we find that low dimensional datasets\nare easier for neural networks to learn, and models solving these tasks\ngeneralize better from training to test data. Along the way, we develop a\ntechnique for validating our dimension estimation tools on synthetic data\ngenerated by GANs allowing us to actively manipulate the intrinsic dimension by\ncontrolling the image generation process. Code for our experiments may be found\nhere https://github.com/ppope/dimensions.\n", "versions": [{"version": "v1", "created": "Sun, 18 Apr 2021 16:29:23 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Pope", "Phillip", ""], ["Zhu", "Chen", ""], ["Abdelkader", "Ahmed", ""], ["Goldblum", "Micah", ""], ["Goldstein", "Tom", ""]]}, {"id": "2104.08896", "submitter": "Weiye Zhao", "authors": "Weiye Zhao, Suqin He, and Changliu Liu", "title": "Provably Safe Tolerance Estimation for Robot Arms via Sum-of-Squares\n  Programming", "comments": "the first version of draft, currently working on some extensions for\n  journal submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tolerance estimation problems are prevailing in engineering applications. For\nexample, in modern robotics, it remains challenging to efficiently estimate\njoint tolerance, \\ie the maximal allowable deviation from a reference robot\nstate such that safety constraints are still satisfied. This paper presented an\nefficient algorithm to estimate the joint tolerance using sum-of-squares\nprogramming. It is theoretically proved that the algorithm provides a tight\nlower bound of the joint tolerance. Extensive numerical studies demonstrate\nthat the proposed method is computationally efficient and near optimal. The\nalgorithm is implemented in the JTE toolbox and is available at\n\\url{https://github.com/intelligent-control-lab/Sum-of-Square-Safety-Optimization}.\n", "versions": [{"version": "v1", "created": "Sun, 18 Apr 2021 16:32:29 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Zhao", "Weiye", ""], ["He", "Suqin", ""], ["Liu", "Changliu", ""]]}, {"id": "2104.08903", "submitter": "Lev Utkin", "authors": "Lev V. Utkin and Egor D. Satyukov and Andrei V. Konstantinov", "title": "SurvNAM: The machine learning survival model explanation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new modification of the Neural Additive Model (NAM) called SurvNAM and its\nmodifications are proposed to explain predictions of the black-box machine\nlearning survival model. The method is based on applying the original NAM to\nsolving the explanation problem in the framework of survival analysis. The\nbasic idea behind SurvNAM is to train the network by means of a specific\nexpected loss function which takes into account peculiarities of the survival\nmodel predictions and is based on approximating the black-box model by the\nextension of the Cox proportional hazards model which uses the well-known\nGeneralized Additive Model (GAM) in place of the simple linear relationship of\ncovariates. The proposed method SurvNAM allows performing the local and global\nexplanation. A set of examples around the explained example is randomly\ngenerated for the local explanation. The global explanation uses the whole\ntraining dataset. The proposed modifications of SurvNAM are based on using the\nLasso-based regularization for functions from GAM and for a special\nrepresentation of the GAM functions using their weighted linear and non-linear\nparts, which is implemented as a shortcut connection. A lot of numerical\nexperiments illustrate the SurvNAM efficiency.\n", "versions": [{"version": "v1", "created": "Sun, 18 Apr 2021 16:40:56 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Utkin", "Lev V.", ""], ["Satyukov", "Egor D.", ""], ["Konstantinov", "Andrei V.", ""]]}, {"id": "2104.08928", "submitter": "Kan Xu", "authors": "Kan Xu, Xuanyi Zhao, Hamsa Bastani, Osbert Bastani", "title": "Group-Sparse Matrix Factorization for Transfer Learning of Word\n  Embeddings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Sparse regression has recently been applied to enable transfer learning from\nvery limited data. We study an extension of this approach to unsupervised\nlearning -- in particular, learning word embeddings from unstructured text\ncorpora using low-rank matrix factorization. Intuitively, when transferring\nword embeddings to a new domain, we expect that the embeddings change for only\na small number of words -- e.g., the ones with novel meanings in that domain.\nWe propose a novel group-sparse penalty that exploits this sparsity to perform\ntransfer learning when there is very little text data available in the target\ndomain -- e.g., a single article of text. We prove generalization bounds for\nour algorithm. Furthermore, we empirically evaluate its effectiveness, both in\nterms of prediction accuracy in downstream tasks as well as the\ninterpretability of the results.\n", "versions": [{"version": "v1", "created": "Sun, 18 Apr 2021 18:19:03 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Xu", "Kan", ""], ["Zhao", "Xuanyi", ""], ["Bastani", "Hamsa", ""], ["Bastani", "Osbert", ""]]}, {"id": "2104.08938", "submitter": "Tim De Ryck", "authors": "Tim De Ryck, Samuel Lanthaler and Siddhartha Mishra", "title": "On the approximation of functions by tanh neural networks", "comments": null, "journal-ref": null, "doi": null, "report-no": "ETH - SAM report 2021-14", "categories": "math.NA cs.LG cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We derive bounds on the error, in high-order Sobolev norms, incurred in the\napproximation of Sobolev-regular as well as analytic functions by neural\nnetworks with the hyperbolic tangent activation function. These bounds provide\nexplicit estimates on the approximation error with respect to the size of the\nneural networks. We show that tanh neural networks with only two hidden layers\nsuffice to approximate functions at comparable or better rates than much deeper\nReLU neural networks.\n", "versions": [{"version": "v1", "created": "Sun, 18 Apr 2021 19:30:45 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["De Ryck", "Tim", ""], ["Lanthaler", "Samuel", ""], ["Mishra", "Siddhartha", ""]]}, {"id": "2104.08942", "submitter": "Neel Kanwal", "authors": "Neel Kanwal, Giuseppe Rizzo", "title": "Attention-based Clinical Note Summarization", "comments": "9 Pages, 6 Figure, 2 Tables, Conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The trend of deploying digital systems in numerous industries has induced a\nhike in recording digital information. The health sector has observed a large\nadoption of digital devices and systems generating large volumes of personal\nmedical health records. Electronic health records contain valuable information\nfor retrospective and prospective analysis that is often not entirely exploited\nbecause of the dense information storage. The crude purpose of condensing\nhealth records is to select the information that holds most characteristics of\nthe original documents based on reported disease. These summaries may boost\ndiagnosis and extend a doctor's interaction time with the patient during a high\nworkload situation like the COVID-19 pandemic. In this paper, we propose a\nmulti-head attention-based mechanism to perform extractive summarization of\nmeaningful phrases in clinical notes. This method finds major sentences for a\nsummary by correlating tokens, segments and positional embeddings. The model\noutputs attention scores that are statistically transformed to extract key\nphrases and can be used for a projection on the heat-mapping tool for visual\nand human use.\n", "versions": [{"version": "v1", "created": "Sun, 18 Apr 2021 19:40:26 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Kanwal", "Neel", ""], ["Rizzo", "Giuseppe", ""]]}, {"id": "2104.08952", "submitter": "Maleakhi Wijaya", "authors": "Maleakhi A. Wijaya, Dmitry Kazhdan, Botty Dimanov and Mateja Jamnik", "title": "Failing Conceptually: Concept-Based Explanations of Dataset Shift", "comments": "ICLR 2021 Workshop (RobustML), 16 pages, 14 figures; typos corrected", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Despite their remarkable performance on a wide range of visual tasks, machine\nlearning technologies often succumb to data distribution shifts. Consequently,\na range of recent work explores techniques for detecting these shifts.\nUnfortunately, current techniques offer no explanations about what triggers the\ndetection of shifts, thus limiting their utility to provide actionable\ninsights. In this work, we present Concept Bottleneck Shift Detection (CBSD): a\nnovel explainable shift detection method. CBSD provides explanations by\nidentifying and ranking the degree to which high-level human-understandable\nconcepts are affected by shifts. Using two case studies (dSprites and\n3dshapes), we demonstrate how CBSD can accurately detect underlying concepts\nthat are affected by shifts and achieve higher detection accuracy compared to\nstate-of-the-art shift detection methods.\n", "versions": [{"version": "v1", "created": "Sun, 18 Apr 2021 20:17:29 GMT"}, {"version": "v2", "created": "Sat, 1 May 2021 19:43:45 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Wijaya", "Maleakhi A.", ""], ["Kazhdan", "Dmitry", ""], ["Dimanov", "Botty", ""], ["Jamnik", "Mateja", ""]]}, {"id": "2104.08955", "submitter": "Eliya Nachmani", "authors": "Shaked Dovrat, Eliya Nachmani, Lior Wolf", "title": "Many-Speakers Single Channel Speech Separation with Optimal Permutation\n  Training", "comments": "Accepted to Interspeech 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.AI cs.LG eess.AS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Single channel speech separation has experienced great progress in the last\nfew years. However, training neural speech separation for a large number of\nspeakers (e.g., more than 10 speakers) is out of reach for the current methods,\nwhich rely on the Permutation Invariant Loss (PIT). In this work, we present a\npermutation invariant training that employs the Hungarian algorithm in order to\ntrain with an $O(C^3)$ time complexity, where $C$ is the number of speakers, in\ncomparison to $O(C!)$ of PIT based methods. Furthermore, we present a modified\narchitecture that can handle the increased number of speakers. Our approach\nseparates up to $20$ speakers and improves the previous results for large $C$\nby a wide margin.\n", "versions": [{"version": "v1", "created": "Sun, 18 Apr 2021 20:56:12 GMT"}, {"version": "v2", "created": "Mon, 7 Jun 2021 18:42:04 GMT"}, {"version": "v3", "created": "Fri, 2 Jul 2021 10:57:33 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Dovrat", "Shaked", ""], ["Nachmani", "Eliya", ""], ["Wolf", "Lior", ""]]}, {"id": "2104.08959", "submitter": "TrungTin Nguyen", "authors": "TrungTin Nguyen, Faicel Chamroukhi, Hien Duy Nguyen, Florence Forbes", "title": "Non-asymptotic model selection in block-diagonal mixture of polynomial\n  experts models", "comments": "Corrected typos. Extended results from arXiv:2104.02640. arXiv admin\n  note: substantial text overlap with arXiv:2104.02640", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.AI cs.LG stat.ME stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model selection, via penalized likelihood type criteria, is a standard task\nin many statistical inference and machine learning problems. Progress has led\nto deriving criteria with asymptotic consistency results and an increasing\nemphasis on introducing non-asymptotic criteria. We focus on the problem of\nmodeling non-linear relationships in regression data with potential hidden\ngraph-structured interactions between the high-dimensional predictors, within\nthe mixture of experts modeling framework. In order to deal with such a complex\nsituation, we investigate a block-diagonal localized mixture of polynomial\nexperts (BLoMPE) regression model, which is constructed upon an inverse\nregression and block-diagonal structures of the Gaussian expert covariance\nmatrices. We introduce a penalized maximum likelihood selection criterion to\nestimate the unknown conditional density of the regression model. This model\nselection criterion allows us to handle the challenging problem of inferring\nthe number of mixture components, the degree of polynomial mean functions, and\nthe hidden block-diagonal structures of the covariance matrices, which reduces\nthe number of parameters to be estimated and leads to a trade-off between\ncomplexity and sparsity in the model. In particular, we provide a strong\ntheoretical guarantee: a finite-sample oracle inequality satisfied by the\npenalized maximum likelihood estimator with a Jensen-Kullback-Leibler type\nloss, to support the introduced non-asymptotic model selection criterion. The\npenalty shape of this criterion depends on the complexity of the considered\nrandom subcollection of BLoMPE models, including the relevant graph structures,\nthe degree of polynomial mean functions, and the number of mixture components.\n", "versions": [{"version": "v1", "created": "Sun, 18 Apr 2021 21:32:20 GMT"}, {"version": "v2", "created": "Mon, 10 May 2021 21:05:06 GMT"}], "update_date": "2021-05-12", "authors_parsed": [["Nguyen", "TrungTin", ""], ["Chamroukhi", "Faicel", ""], ["Nguyen", "Hien Duy", ""], ["Forbes", "Florence", ""]]}, {"id": "2104.08962", "submitter": "Rakesh Gosangi", "authors": "Rakesh Gosangi, Ravneet Arora, Mohsen Gheisarieha, Debanjan Mahata,\n  Haimin Zhang", "title": "On the Use of Context for Predicting Citation Worthiness of Sentences in\n  Scholarly Articles", "comments": "To be published in the proceedings of NAACL 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  In this paper, we study the importance of context in predicting the citation\nworthiness of sentences in scholarly articles. We formulate this problem as a\nsequence labeling task solved using a hierarchical BiLSTM model. We contribute\na new benchmark dataset containing over two million sentences and their\ncorresponding labels. We preserve the sentence order in this dataset and\nperform document-level train/test splits, which importantly allows\nincorporating contextual information in the modeling process. We evaluate the\nproposed approach on three benchmark datasets. Our results quantify the\nbenefits of using context and contextual embeddings for citation worthiness.\nLastly, through error analysis, we provide insights into cases where context\nplays an essential role in predicting citation worthiness.\n", "versions": [{"version": "v1", "created": "Sun, 18 Apr 2021 21:47:30 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Gosangi", "Rakesh", ""], ["Arora", "Ravneet", ""], ["Gheisarieha", "Mohsen", ""], ["Mahata", "Debanjan", ""], ["Zhang", "Haimin", ""]]}, {"id": "2104.08967", "submitter": "Badrinath Jayakumar", "authors": "Minhua Chen, Badrinath Jayakumar, Padmasundari Gopalakrishnan, Qiming\n  Huang, Michael Johnston, and Patrick Haffner", "title": "Deep Clustering with Measure Propagation", "comments": "This work was presented as a poster in 14th Annual Machine Learning\n  Symposium in The New York Academy of Sciences", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep models have improved state-of-the-art for both supervised and\nunsupervised learning. For example, deep embedded clustering (DEC) has greatly\nimproved the unsupervised clustering performance, by using stacked autoencoders\nfor representation learning. However, one weakness of deep modeling is that the\nlocal neighborhood structure in the original space is not necessarily preserved\nin the latent space. To preserve local geometry, various methods have been\nproposed in the supervised and semi-supervised learning literature (e.g.,\nspectral clustering and label propagation) using graph Laplacian\nregularization. In this paper, we combine the strength of deep representation\nlearning with measure propagation (MP), a KL-divergence based graph\nregularization method originally used in the semi-supervised scenario. The main\nassumption of MP is that if two data points are close in the original space,\nthey are likely to belong to the same class, measured by KL-divergence of class\nmembership distribution. By taking the same assumption in the unsupervised\nlearning scenario, we propose our Deep Embedded Clustering Aided by Measure\nPropagation (DECAMP) model. We evaluate DECAMP on short text clustering tasks.\nOn three public datasets, DECAMP performs competitively with other\nstate-of-the-art baselines, including baselines using additional data to\ngenerate word embeddings used in the clustering process. As an example, on the\nStackoverflow dataset, DECAMP achieved a clustering accuracy of 79%, which is\nabout 5% higher than all existing baselines. These empirical results suggest\nthat DECAMP is a very effective method for unsupervised learning.\n", "versions": [{"version": "v1", "created": "Sun, 18 Apr 2021 22:02:43 GMT"}, {"version": "v2", "created": "Tue, 20 Apr 2021 02:42:42 GMT"}, {"version": "v3", "created": "Mon, 26 Apr 2021 14:32:28 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Chen", "Minhua", ""], ["Jayakumar", "Badrinath", ""], ["Gopalakrishnan", "Padmasundari", ""], ["Huang", "Qiming", ""], ["Johnston", "Michael", ""], ["Haffner", "Patrick", ""]]}, {"id": "2104.08969", "submitter": "Ethan Moyer", "authors": "Ethan Moyer, Jeff Winchell, Isamu Isozaki, Yigit Alparslan, Mali\n  Halac, and Edward Kim", "title": "Functional Protein Structure Annotation Using a Deep Convolutional\n  Generative Adversarial Network", "comments": "4 pages, 1 figure, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.BM cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Identifying novel functional protein structures is at the heart of molecular\nengineering and molecular biology, requiring an often computationally\nexhaustive search. We introduce the use of a Deep Convolutional Generative\nAdversarial Network (DCGAN) to classify protein structures based on their\nfunctionality by encoding each sample in a grid object structure using three\nfeatures in each object: the generic atom type, the position atom type, and its\noccupancy relative to a given atom. We train DCGAN on 3-dimensional (3D) decoy\nand native protein structures in order to generate and discriminate 3D protein\nstructures. At the end of our training, loss converges to a local minimum and\nour DCGAN can annotate functional proteins robustly against adversarial protein\nsamples. In the future we hope to extend the novel structures we found from the\ngenerator in our DCGAN with more samples to explore more granular functionality\nwith varying functions. We hope that our effort will advance the field of\nprotein structure prediction.\n", "versions": [{"version": "v1", "created": "Sun, 18 Apr 2021 22:18:52 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Moyer", "Ethan", ""], ["Winchell", "Jeff", ""], ["Isozaki", "Isamu", ""], ["Alparslan", "Yigit", ""], ["Halac", "Mali", ""], ["Kim", "Edward", ""]]}, {"id": "2104.08977", "submitter": "Audrey Huang", "authors": "Audrey Huang, Liu Leqi, Zachary C. Lipton, Kamyar Azizzadenesheli", "title": "Off-Policy Risk Assessment in Contextual Bandits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Even when unable to run experiments, practitioners can evaluate prospective\npolicies, using previously logged data. However, while the bandits literature\nhas adopted a diverse set of objectives, most research on off-policy evaluation\nto date focuses on the expected reward. In this paper, we introduce Lipschitz\nrisk functionals, a broad class of objectives that subsumes conditional\nvalue-at-risk (CVaR), variance, mean-variance, many distorted risks, and CPT\nrisks, among others. We propose Off-Policy Risk Assessment (OPRA), a framework\nthat first estimates a target policy's CDF and then generates plugin estimates\nfor any collection of Lipschitz risks, providing finite sample guarantees that\nhold simultaneously over the entire class. We instantiate OPRA with both\nimportance sampling and doubly robust estimators. Our primary theoretical\ncontributions are (i) the first uniform concentration inequalities for both CDF\nestimators in contextual bandits and (ii) error bounds on our Lipschitz risk\nestimates, which all converge at a rate of $O(1/\\sqrt{n})$.\n", "versions": [{"version": "v1", "created": "Sun, 18 Apr 2021 23:27:40 GMT"}, {"version": "v2", "created": "Tue, 29 Jun 2021 14:55:52 GMT"}], "update_date": "2021-06-30", "authors_parsed": [["Huang", "Audrey", ""], ["Leqi", "Liu", ""], ["Lipton", "Zachary C.", ""], ["Azizzadenesheli", "Kamyar", ""]]}, {"id": "2104.08984", "submitter": "Aritra Ghosh", "authors": "Aritra Ghosh and Andrew Lan", "title": "Contrastive Learning Improves Model Robustness Under Label Noise", "comments": "Learning from Limited or Imperfect Data (L^2ID) Workshop @ CVPR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural network-based classifiers trained with the categorical\ncross-entropy (CCE) loss are sensitive to label noise in the training data. One\ncommon type of method that can mitigate the impact of label noise can be viewed\nas supervised robust methods; one can simply replace the CCE loss with a loss\nthat is robust to label noise, or re-weight training samples and down-weight\nthose with higher loss values. Recently, another type of method using\nsemi-supervised learning (SSL) has been proposed, which augments these\nsupervised robust methods to exploit (possibly) noisy samples more effectively.\nAlthough supervised robust methods perform well across different data types,\nthey have been shown to be inferior to the SSL methods on image classification\ntasks under label noise. Therefore, it remains to be seen that whether these\nsupervised robust methods can also perform well if they can utilize the\nunlabeled samples more effectively. In this paper, we show that by initializing\nsupervised robust methods using representations learned through contrastive\nlearning leads to significantly improved performance under label noise.\nSurprisingly, even the simplest method (training a classifier with the CCE\nloss) can outperform the state-of-the-art SSL method by more than 50\\% under\nhigh label noise when initialized with contrastive learning. Our implementation\nwill be publicly available at\n{\\url{https://github.com/arghosh/noisy_label_pretrain}}.\n", "versions": [{"version": "v1", "created": "Mon, 19 Apr 2021 00:27:58 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Ghosh", "Aritra", ""], ["Lan", "Andrew", ""]]}, {"id": "2104.08987", "submitter": "Armando Bellante", "authors": "Armando Bellante, Alessandro Luongo, Stefano Zanero", "title": "Quantum Algorithms for Data Representation and Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We narrow the gap between previous literature on quantum linear algebra and\nuseful data analysis on a quantum computer, providing quantum procedures that\nspeed-up the solution of eigenproblems for data representation in machine\nlearning. The power and practical use of these subroutines is shown through new\nquantum algorithms, sublinear in the input matrix's size, for principal\ncomponent analysis, correspondence analysis, and latent semantic analysis. We\nprovide a theoretical analysis of the run-time and prove tight bounds on the\nrandomized algorithms' error. We run experiments on multiple datasets,\nsimulating PCA's dimensionality reduction for image classification with the\nnovel routines. The results show that the run-time parameters that do not\ndepend on the input's size are reasonable and that the error on the computed\nmodel is small, allowing for competitive classification performances.\n", "versions": [{"version": "v1", "created": "Mon, 19 Apr 2021 00:41:43 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Bellante", "Armando", ""], ["Luongo", "Alessandro", ""], ["Zanero", "Stefano", ""]]}, {"id": "2104.09005", "submitter": "Sam Maksoud", "authors": "Sam Maksoud, Kun Zhao, Can Peng, Brian C. Lovell", "title": "Scalable Bayesian Deep Learning with Kernel Seed Networks", "comments": "Under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  This paper addresses the scalability problem of Bayesian deep neural\nnetworks. The performance of deep neural networks is undermined by the fact\nthat these algorithms have poorly calibrated measures of uncertainty. This\nrestricts their application in high risk domains such as computer aided\ndiagnosis and autonomous vehicle navigation. Bayesian Deep Learning (BDL)\noffers a promising method for representing uncertainty in neural network.\nHowever, BDL requires a separate set of parameters to store the mean and\nstandard deviation of model weights to learn a distribution. This results in a\nprohibitive 2-fold increase in the number of model parameters. To address this\nproblem we present a method for performing BDL, namely Kernel Seed Networks\n(KSN), which does not require a 2-fold increase in the number of parameters.\nKSNs use 1x1 Convolution operations to learn a compressed latent space\nrepresentation of the parameter distribution. In this paper we show how this\nallows KSNs to outperform conventional BDL methods while reducing the number of\nrequired parameters by up to a factor of 6.6.\n", "versions": [{"version": "v1", "created": "Mon, 19 Apr 2021 01:42:34 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Maksoud", "Sam", ""], ["Zhao", "Kun", ""], ["Peng", "Can", ""], ["Lovell", "Brian C.", ""]]}, {"id": "2104.09011", "submitter": "Tomoharu Iwata", "authors": "Tomoharu Iwata", "title": "Few-shot Learning for Topic Modeling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Topic models have been successfully used for analyzing text documents.\nHowever, with existing topic models, many documents are required for training.\nIn this paper, we propose a neural network-based few-shot learning method that\ncan learn a topic model from just a few documents. The neural networks in our\nmodel take a small number of documents as inputs, and output topic model\npriors. The proposed method trains the neural networks such that the expected\ntest likelihood is improved when topic model parameters are estimated by\nmaximizing the posterior probability using the priors based on the EM\nalgorithm. Since each step in the EM algorithm is differentiable, the proposed\nmethod can backpropagate the loss through the EM algorithm to train the neural\nnetworks. The expected test likelihood is maximized by a stochastic gradient\ndescent method using a set of multiple text corpora with an episodic training\nframework. In our experiments, we demonstrate that the proposed method achieves\nbetter perplexity than existing methods using three real-world text document\nsets.\n", "versions": [{"version": "v1", "created": "Mon, 19 Apr 2021 01:56:48 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Iwata", "Tomoharu", ""]]}, {"id": "2104.09015", "submitter": "Shiyu Duan", "authors": "Shiyu Duan and Jose C. Principe", "title": "Labels, Information, and Computation: Efficient, Privacy-Preserving\n  Learning Using Sufficient Labels", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In supervised learning, obtaining a large set of fully-labeled training data\nis expensive. We show that we do not always need full label information on\nevery single training example to train a competent classifier. Specifically,\ninspired by the principle of sufficiency in statistics, we present a statistic\n(a summary) of the fully-labeled training set that captures almost all the\nrelevant information for classification but at the same time is easier to\nobtain directly. We call this statistic \"sufficiently-labeled data\" and prove\nits sufficiency and efficiency for finding the optimal hidden representations,\non which competent classifier heads can be trained using as few as a single\nrandomly-chosen fully-labeled example per class. Sufficiently-labeled data can\nbe obtained from annotators directly without collecting the fully-labeled data\nfirst. And we prove that it is easier to directly obtain sufficiently-labeled\ndata than obtaining fully-labeled data. Furthermore, sufficiently-labeled data\nnaturally preserves user privacy by storing relative, instead of absolute,\ninformation. Extensive experimental results are provided to support our theory.\n", "versions": [{"version": "v1", "created": "Mon, 19 Apr 2021 02:15:25 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Duan", "Shiyu", ""], ["Principe", "Jose C.", ""]]}, {"id": "2104.09027", "submitter": "Mengyuan Lee", "authors": "Mengyuan Lee, Guanding Yu, and Huaiyu Dai", "title": "Decentralized Inference with Graph Neural Networks in Wireless\n  Communication Systems", "comments": "The paper was submitted to TMC", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG math.IT", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Graph neural network (GNN) is an efficient neural network model for graph\ndata and is widely used in different fields, including wireless communications.\nDifferent from other neural network models, GNN can be implemented in a\ndecentralized manner with information exchanges among neighbors, making it a\npotentially powerful tool for decentralized control in wireless communication\nsystems. The main bottleneck, however, is wireless channel impairments that\ndeteriorate the prediction robustness of GNN. To overcome this obstacle, we\nanalyze and enhance the robustness of the decentralized GNN in different\nwireless communication systems in this paper. Specifically, using a GNN binary\nclassifier as an example, we first develop a methodology to verify whether the\npredictions are robust. Then, we analyze the performance of the decentralized\nGNN binary classifier in both uncoded and coded wireless communication systems.\nTo remedy imperfect wireless transmission and enhance the prediction\nrobustness, we further propose novel retransmission mechanisms for the above\ntwo communication systems, respectively. Through simulations on the synthetic\ngraph data, we validate our analysis, verify the effectiveness of the proposed\nretransmission mechanisms, and provide some insights for practical\nimplementation.\n", "versions": [{"version": "v1", "created": "Mon, 19 Apr 2021 03:12:24 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Lee", "Mengyuan", ""], ["Yu", "Guanding", ""], ["Dai", "Huaiyu", ""]]}, {"id": "2104.09029", "submitter": "Siamak Layeghy", "authors": "Siamak Layeghy, Marcus Gallagher, Marius Portmann", "title": "Benchmarking the Benchmark -- Analysis of Synthetic NIDS Datasets", "comments": "25 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Network Intrusion Detection Systems (NIDSs) are an increasingly important\ntool for the prevention and mitigation of cyber attacks. A number of labelled\nsynthetic datasets generated have been generated and made publicly available by\nresearchers, and they have become the benchmarks via which new ML-based NIDS\nclassifiers are being evaluated. Recently published results show excellent\nclassification performance with these datasets, increasingly approaching 100\npercent performance across key evaluation metrics such as accuracy, F1 score,\netc. Unfortunately, we have not yet seen these excellent academic research\nresults translated into practical NIDS systems with such near-perfect\nperformance. This motivated our research presented in this paper, where we\nanalyse the statistical properties of the benign traffic in three of the more\nrecent and relevant NIDS datasets, (CIC, UNSW, ...). As a comparison, we\nconsider two datasets obtained from real-world production networks, one from a\nuniversity network and one from a medium size Internet Service Provider (ISP).\nOur results show that the two real-world datasets are quite similar among\nthemselves in regards to most of the considered statistical features. Equally,\nthe three synthetic datasets are also relatively similar within their group.\nHowever, and most importantly, our results show a distinct difference of most\nof the considered statistical features between the three synthetic datasets and\nthe two real-world datasets. Since ML relies on the basic assumption of\ntraining and test datasets being sampled from the same distribution, this\nraises the question of how well the performance results of ML-classifiers\ntrained on the considered synthetic datasets can translate and generalise to\nreal-world networks. We believe this is an interesting and relevant question\nwhich provides motivation for further research in this space.\n", "versions": [{"version": "v1", "created": "Mon, 19 Apr 2021 03:17:37 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Layeghy", "Siamak", ""], ["Gallagher", "Marcus", ""], ["Portmann", "Marius", ""]]}, {"id": "2104.09034", "submitter": "Liyuan Wang", "authors": "Liyuan Wang, Qian Li, Yi Zhong and Jun Zhu", "title": "Few-shot Continual Learning: a Brain-inspired Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is an important yet challenging setting to continually learn new tasks\nfrom a few examples. Although numerous efforts have been devoted to either\ncontinual learning or few-shot learning, little work has considered this new\nsetting of few-shot continual learning (FSCL), which needs to minimize the\ncatastrophic forgetting to the old tasks and gradually improve the ability of\nfew-shot generalization. In this paper, we provide a first systematic study on\nFSCL and present an effective solution with deep neural networks. Our solution\nis based on the observation that continual learning of a task sequence\ninevitably interferes few-shot generalization, which makes it highly nontrivial\nto extend few-shot learning strategies to continual learning scenarios. We draw\ninspirations from the robust brain system and develop a method that (1)\ninterdependently updates a pair of fast / slow weights for continual learning\nand few-shot learning to disentangle their divergent objectives, inspired by\nthe biological model of meta-plasticity and fast / slow synapse; and (2)\napplies a brain-inspired two-step consolidation strategy to learn a task\nsequence without forgetting in the fast weights while improve generalization\nwithout overfitting in the slow weights. Extensive results on various\nbenchmarks show that our method achieves a better performance than joint\ntraining of all the tasks ever seen. The ability of few-shot generalization is\nalso substantially improved from incoming tasks and examples.\n", "versions": [{"version": "v1", "created": "Mon, 19 Apr 2021 03:40:48 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Wang", "Liyuan", ""], ["Li", "Qian", ""], ["Zhong", "Yi", ""], ["Zhu", "Jun", ""]]}, {"id": "2104.09036", "submitter": "Yanqiao Zhu", "authors": "Jinghao Zhang, Yanqiao Zhu, Qiang Liu, Shu Wu, Shuhui Wang, Liang Wang", "title": "Mining Latent Structures for Multimedia Recommendation", "comments": "Accepted to ACM Multimedia 2021. Authors' version", "journal-ref": null, "doi": "10.1145/3474085.3475259", "report-no": null, "categories": "cs.IR cs.LG cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multimedia content is of predominance in the modern Web era. Investigating\nhow users interact with multimodal items is a continuing concern within the\nrapid development of recommender systems. The majority of previous work focuses\non modeling user-item interactions with multimodal features included as side\ninformation. However, this scheme is not well-designed for multimedia\nrecommendation. Specifically, only collaborative item-item relationships are\nimplicitly modeled through high-order item-user-item relations. Considering\nthat items are associated with rich contents in multiple modalities, we argue\nthat the latent semantic item-item structures underlying these multimodal\ncontents could be beneficial for learning better item representations and\nfurther boosting recommendation. To this end, we propose a LATent sTructure\nmining method for multImodal reCommEndation, which we term LATTICE for brevity.\nTo be specific, in the proposed LATTICE model, we devise a novel modality-aware\nstructure learning layer, which learns item-item structures for each modality\nand aggregates multiple modalities to obtain latent item graphs. Based on the\nlearned latent graphs, we perform graph convolutions to explicitly inject\nhigh-order item affinities into item representations. These enriched item\nrepresentations can then be plugged into existing collaborative filtering\nmethods to make more accurate recommendations. Extensive experiments on three\nreal-world datasets demonstrate the superiority of our method over\nstate-of-the-art multimedia recommendation methods and validate the efficacy of\nmining latent item-item relationships from multimodal features.\n", "versions": [{"version": "v1", "created": "Mon, 19 Apr 2021 03:50:24 GMT"}, {"version": "v2", "created": "Wed, 21 Jul 2021 02:27:33 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Zhang", "Jinghao", ""], ["Zhu", "Yanqiao", ""], ["Liu", "Qiang", ""], ["Wu", "Shu", ""], ["Wang", "Shuhui", ""], ["Wang", "Liang", ""]]}, {"id": "2104.09043", "submitter": "Aritra Ghosh", "authors": "Aritra Ghosh, Jay Raspat, Andrew Lan", "title": "Option Tracing: Beyond Correctness Analysis in Knowledge Tracing", "comments": "AIED 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge tracing refers to a family of methods that estimate each student's\nknowledge component/skill mastery level from their past responses to questions.\nOne key limitation of most existing knowledge tracing methods is that they can\nonly estimate an \\emph{overall} knowledge level of a student per knowledge\ncomponent/skill since they analyze only the (usually binary-valued) correctness\nof student responses. Therefore, it is hard to use them to diagnose specific\nstudent errors. In this paper, we extend existing knowledge tracing methods\nbeyond correctness prediction to the task of predicting the exact option\nstudents select in multiple choice questions. We quantitatively evaluate the\nperformance of our option tracing methods on two large-scale student response\ndatasets. We also qualitatively evaluate their ability in identifying common\nstudent errors in the form of clusters of incorrect options across different\nquestions that correspond to the same error.\n", "versions": [{"version": "v1", "created": "Mon, 19 Apr 2021 04:28:34 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Ghosh", "Aritra", ""], ["Raspat", "Jay", ""], ["Lan", "Andrew", ""]]}, {"id": "2104.09045", "submitter": "Aritra Ghosh", "authors": "Aritra Ghosh, Andrew Lan", "title": "Do We Really Need Gold Samples for Sample Weighting Under Label Noise?", "comments": "WACV 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning with labels noise has gained significant traction recently due to\nthe sensitivity of deep neural networks under label noise under common loss\nfunctions. Losses that are theoretically robust to label noise, however, often\nmakes training difficult. Consequently, several recently proposed methods, such\nas Meta-Weight-Net (MW-Net), use a small number of unbiased, clean samples to\nlearn a weighting function that downweights samples that are likely to have\ncorrupted labels under the meta-learning framework. However, obtaining such a\nset of clean samples is not always feasible in practice. In this paper, we\nanalytically show that one can easily train MW-Net without access to clean\nsamples simply by using a loss function that is robust to label noise, such as\nmean absolute error, as the meta objective to train the weighting network. We\nexperimentally show that our method beats all existing methods that do not use\nclean samples and performs on-par with methods that use gold samples on\nbenchmark datasets across various noise types and noise rates.\n", "versions": [{"version": "v1", "created": "Mon, 19 Apr 2021 04:36:51 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Ghosh", "Aritra", ""], ["Lan", "Andrew", ""]]}, {"id": "2104.09051", "submitter": "Alessandro Morandini", "authors": "Thorben Finke, Michael Kr\\\"amer, Alessandro Morandini, Alexander\n  M\\\"uck, Ivan Oleksiyuk", "title": "Autoencoders for unsupervised anomaly detection in high energy physics", "comments": "32 pages, 20 figures", "journal-ref": "JHEP 06 (2021) 161", "doi": "10.1007/JHEP06(2021)161", "report-no": "TTK-21-12", "categories": "hep-ph cs.LG physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autoencoders are widely used in machine learning applications, in particular\nfor anomaly detection. Hence, they have been introduced in high energy physics\nas a promising tool for model-independent new physics searches. We scrutinize\nthe usage of autoencoders for unsupervised anomaly detection based on\nreconstruction loss to show their capabilities, but also their limitations. As\na particle physics benchmark scenario, we study the tagging of top jet images\nin a background of QCD jet images. Although we reproduce the positive results\nfrom the literature, we show that the standard autoencoder setup cannot be\nconsidered as a model-independent anomaly tagger by inverting the task: due to\nthe sparsity and the specific structure of the jet images, the autoencoder\nfails to tag QCD jets if it is trained on top jets even in a semi-supervised\nsetup. Since the same autoencoder architecture can be a good tagger for a\nspecific example of an anomaly and a bad tagger for a different example, we\nsuggest improved performance measures for the task of model-independent anomaly\ndetection. We also improve the capability of the autoencoder to learn\nnon-trivial features of the jet images, such that it is able to achieve both\ntop jet tagging and the inverse task of QCD jet tagging with the same setup.\nHowever, we want to stress that a truly model-independent and powerful\nautoencoder-based unsupervised jet tagger still needs to be developed.\n", "versions": [{"version": "v1", "created": "Mon, 19 Apr 2021 05:06:57 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Finke", "Thorben", ""], ["Kr\u00e4mer", "Michael", ""], ["Morandini", "Alessandro", ""], ["M\u00fcck", "Alexander", ""], ["Oleksiyuk", "Ivan", ""]]}, {"id": "2104.09052", "submitter": "Mandy Lu", "authors": "Mandy Lu, Qingyu Zhao, Jiequan Zhang, Kilian M. Pohl, Li Fei-Fei, Juan\n  Carlos Niebles, Ehsan Adeli", "title": "Metadata Normalization", "comments": "Accepted to CVPR 2021. Project page: https://mml.stanford.edu/MDN/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Batch Normalization (BN) and its variants have delivered tremendous success\nin combating the covariate shift induced by the training step of deep learning\nmethods. While these techniques normalize feature distributions by\nstandardizing with batch statistics, they do not correct the influence on\nfeatures from extraneous variables or multiple distributions. Such extra\nvariables, referred to as metadata here, may create bias or confounding effects\n(e.g., race when classifying gender from face images). We introduce the\nMetadata Normalization (MDN) layer, a new batch-level operation which can be\nused end-to-end within the training framework, to correct the influence of\nmetadata on feature distributions. MDN adopts a regression analysis technique\ntraditionally used for preprocessing to remove (regress out) the metadata\neffects on model features during training. We utilize a metric based on\ndistance correlation to quantify the distribution bias from the metadata and\ndemonstrate that our method successfully removes metadata effects on four\ndiverse settings: one synthetic, one 2D image, one video, and one 3D medical\nimage dataset.\n", "versions": [{"version": "v1", "created": "Mon, 19 Apr 2021 05:10:26 GMT"}, {"version": "v2", "created": "Wed, 5 May 2021 10:14:26 GMT"}], "update_date": "2021-05-06", "authors_parsed": [["Lu", "Mandy", ""], ["Zhao", "Qingyu", ""], ["Zhang", "Jiequan", ""], ["Pohl", "Kilian M.", ""], ["Fei-Fei", "Li", ""], ["Niebles", "Juan Carlos", ""], ["Adeli", "Ehsan", ""]]}, {"id": "2104.09056", "submitter": "Chao-Tsung Huang", "authors": "Chao-Tsung Huang", "title": "RingCNN: Exploiting Algebraically-Sparse Ring Tensors for\n  Energy-Efficient CNN-Based Computational Imaging", "comments": "To Appear in 2021 ACM/IEEE 48th Annual International Symposium on\n  Computer Architecture (ISCA)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the era of artificial intelligence, convolutional neural networks (CNNs)\nare emerging as a powerful technique for computational imaging. They have shown\nsuperior quality for reconstructing fine textures from badly-distorted images\nand have potential to bring next-generation cameras and displays to our daily\nlife. However, CNNs demand intensive computing power for generating\nhigh-resolution videos and defy conventional sparsity techniques when rendering\ndense details. Therefore, finding new possibilities in regular sparsity is\ncrucial to enable large-scale deployment of CNN-based computational imaging.\n  In this paper, we consider a fundamental but yet well-explored approach --\nalgebraic sparsity -- for energy-efficient CNN acceleration. We propose to\nbuild CNN models based on ring algebra that defines multiplication, addition,\nand non-linearity for n-tuples properly. Then the essential sparsity will\nimmediately follow, e.g. n-times reduction for the number of real-valued\nweights. We define and unify several variants of ring algebras into a modeling\nframework, RingCNN, and make comparisons in terms of image quality and hardware\ncomplexity. On top of that, we further devise a novel ring algebra which\nminimizes complexity with component-wise product and achieves the best quality\nusing directional ReLU. Finally, we implement an accelerator, eRingCNN, in two\nsettings, n=2 and 4 (50% and 75% sparsity), with 40 nm technology to support\nadvanced denoising and super-resolution at up to 4K UHD 30 fps. Layout results\nshow that they can deliver equivalent 41 TOPS using 3.76 W and 2.22 W,\nrespectively. Compared to the real-valued counterpart, our ring convolution\nengines for n=2 achieve 2.00x energy efficiency and 2.08x area efficiency with\nsimilar or even better image quality. With n=4, the efficiency gains of energy\nand area are further increased to 3.84x and 3.77x with 0.11 dB drop of PSNR.\n", "versions": [{"version": "v1", "created": "Mon, 19 Apr 2021 05:26:11 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Huang", "Chao-Tsung", ""]]}, {"id": "2104.09062", "submitter": "Jokin Labaien Soto", "authors": "Jokin Labaien, Ekhi Zugasti, Xabier De Carlos", "title": "DA-DGCEx: Ensuring Validity of Deep Guided Counterfactual Explanations\n  With Distribution-Aware Autoencoder Loss", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Learning has become a very valuable tool in different fields, and no one\ndoubts the learning capacity of these models. Nevertheless, since Deep Learning\nmodels are often seen as black boxes due to their lack of interpretability,\nthere is a general mistrust in their decision-making process. To find a balance\nbetween effectiveness and interpretability, Explainable Artificial Intelligence\n(XAI) is gaining popularity in recent years, and some of the methods within\nthis area are used to generate counterfactual explanations. The process of\ngenerating these explanations generally consists of solving an optimization\nproblem for each input to be explained, which is unfeasible when real-time\nfeedback is needed. To speed up this process, some methods have made use of\nautoencoders to generate instant counterfactual explanations. Recently, a\nmethod called Deep Guided Counterfactual Explanations (DGCEx) has been\nproposed, which trains an autoencoder attached to a classification model, in\norder to generate straightforward counterfactual explanations. However, this\nmethod does not ensure that the generated counterfactual instances are close to\nthe data manifold, so unrealistic counterfactual instances may be generated. To\novercome this issue, this paper presents Distribution Aware Deep Guided\nCounterfactual Explanations (DA-DGCEx), which adds a term to the DGCEx cost\nfunction that penalizes out of distribution counterfactual instances.\n", "versions": [{"version": "v1", "created": "Mon, 19 Apr 2021 05:44:18 GMT"}, {"version": "v2", "created": "Tue, 20 Apr 2021 05:59:49 GMT"}, {"version": "v3", "created": "Thu, 22 Apr 2021 06:41:30 GMT"}], "update_date": "2021-04-23", "authors_parsed": [["Labaien", "Jokin", ""], ["Zugasti", "Ekhi", ""], ["De Carlos", "Xabier", ""]]}, {"id": "2104.09069", "submitter": "Hongyuan You", "authors": "Hongyuan You, Sikun Lin, Ambuj K. Singh", "title": "Learning Interpretable Models for Coupled Networks Under Domain\n  Constraints", "comments": "10 pages, Thirty-Fifth AAAI Conference on Artificial Intelligence\n  (AAAI-2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modeling the behavior of coupled networks is challenging due to their\nintricate dynamics. For example in neuroscience, it is of critical importance\nto understand the relationship between the functional neural processes and\nanatomical connectivities. Modern neuroimaging techniques allow us to\nseparately measure functional connectivity through fMRI imaging and the\nunderlying white matter wiring through diffusion imaging. Previous studies have\nshown that structural edges in brain networks improve the inference of\nfunctional edges and vice versa. In this paper, we investigate the idea of\ncoupled networks through an optimization framework by focusing on interactions\nbetween structural edges and functional edges of brain networks. We consider\nboth types of edges as observed instances of random variables that represent\ndifferent underlying network processes. The proposed framework does not depend\non Gaussian assumptions and achieves a more robust performance on general data\ncompared with existing approaches. To incorporate existing domain knowledge\ninto such studies, we propose a novel formulation to place hard network\nconstraints on the noise term while estimating interactions. This not only\nleads to a cleaner way of applying network constraints but also provides a more\nscalable solution when network connectivity is sparse. We validate our method\non multishell diffusion and task-evoked fMRI datasets from the Human Connectome\nProject, leading to both important insights on structural backbones that\nsupport various types of task activities as well as general solutions to the\nstudy of coupled networks.\n", "versions": [{"version": "v1", "created": "Mon, 19 Apr 2021 06:23:31 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["You", "Hongyuan", ""], ["Lin", "Sikun", ""], ["Singh", "Ambuj K.", ""]]}, {"id": "2104.09072", "submitter": "Ryan McConville", "authors": "Hok-Shing Lau, Ryan McConville, Mohammud J. Bocus, Robert J.\n  Piechocki, Raul Santos-Rodriguez", "title": "Self-Supervised WiFi-Based Activity Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Traditional approaches to activity recognition involve the use of wearable\nsensors or cameras in order to recognise human activities. In this work, we\nextract fine-grained physical layer information from WiFi devices for the\npurpose of passive activity recognition in indoor environments. While such data\nis ubiquitous, few approaches are designed to utilise large amounts of\nunlabelled WiFi data. We propose the use of self-supervised contrastive\nlearning to improve activity recognition performance when using multiple views\nof the transmitted WiFi signal captured by different synchronised receivers. We\nconduct experiments where the transmitters and receivers are arranged in\ndifferent physical layouts so as to cover both Line-of-Sight (LoS) and non LoS\n(NLoS) conditions. We compare the proposed contrastive learning system with\nnon-contrastive systems and observe a 17.7% increase in macro averaged F1 score\non the task of WiFi based activity recognition, as well as significant\nimprovements in one- and few-shot learning scenarios.\n", "versions": [{"version": "v1", "created": "Mon, 19 Apr 2021 06:40:21 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Lau", "Hok-Shing", ""], ["McConville", "Ryan", ""], ["Bocus", "Mohammud J.", ""], ["Piechocki", "Robert J.", ""], ["Santos-Rodriguez", "Raul", ""]]}, {"id": "2104.09073", "submitter": "Piyushi Manupriya", "authors": "Piyushi Manupriya, Saketha Nath Jagarlapudi, Tarun Ram Menta, Vineeth\n  N Balasubramanian", "title": "Improving Attribution Methods by Learning Submodular Functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This work explores the novel idea of learning a submodular scoring function\nto improve the specificity/selectivity of existing feature attribution methods.\nSubmodular scores are natural for attribution as they are known to accurately\nmodel the principle of diminishing returns. A new formulation for learning a\ndeep submodular set function that is consistent with the real-valued\nattribution maps obtained by existing attribution methods is proposed. This\nformulation not only ensures that the scores for the heat maps that include the\nhighly attributed features across the existing methods are high, but also that\nthe score saturates even for the most specific heat map. The final attribution\nvalue of a feature is then defined as the marginal gain in the induced\nsubmodular score of the feature in the context of other highly attributed\nfeatures, thus decreasing the attribution of redundant yet discriminatory\nfeatures. Experiments on multiple datasets illustrate that the proposed\nattribution method achieves higher specificity while not degrading the\ndiscriminative power.\n", "versions": [{"version": "v1", "created": "Mon, 19 Apr 2021 06:40:34 GMT"}, {"version": "v2", "created": "Tue, 27 Apr 2021 03:41:32 GMT"}], "update_date": "2021-04-28", "authors_parsed": [["Manupriya", "Piyushi", ""], ["Jagarlapudi", "Saketha Nath", ""], ["Menta", "Tarun Ram", ""], ["Balasubramanian", "Vineeth N", ""]]}, {"id": "2104.09075", "submitter": "Mohamed Wahib", "authors": "Albert Njoroge Kahira, Truong Thao Nguyen, Leonardo Bautista Gomez,\n  Ryousei Takano, Rosa M Badia, Mohamed Wahib", "title": "An Oracle for Guiding Large-Scale Model/Hybrid Parallel Training of\n  Convolutional Neural Networks", "comments": "The International ACM Symposium on High-Performance Parallel and\n  Distributed Computing 2021 (HPDC'21)", "journal-ref": null, "doi": "10.1145/3431379.3460644", "report-no": null, "categories": "cs.DC cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deep Neural Network (DNN) frameworks use distributed training to enable\nfaster time to convergence and alleviate memory capacity limitations when\ntraining large models and/or using high dimension inputs. With the steady\nincrease in datasets and model sizes, model/hybrid parallelism is deemed to\nhave an important role in the future of distributed training of DNNs. We\nanalyze the compute, communication, and memory requirements of Convolutional\nNeural Networks (CNNs) to understand the trade-offs between different\nparallelism approaches on performance and scalability. We leverage our\nmodel-driven analysis to be the basis for an oracle utility which can help in\ndetecting the limitations and bottlenecks of different parallelism approaches\nat scale. We evaluate the oracle on six parallelization strategies, with four\nCNN models and multiple datasets (2D and 3D), on up to 1024 GPUs. The results\ndemonstrate that the oracle has an average accuracy of about 86.74% when\ncompared to empirical results, and as high as 97.57% for data parallelism.\n", "versions": [{"version": "v1", "created": "Mon, 19 Apr 2021 06:45:51 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Kahira", "Albert Njoroge", ""], ["Nguyen", "Truong Thao", ""], ["Gomez", "Leonardo Bautista", ""], ["Takano", "Ryousei", ""], ["Badia", "Rosa M", ""], ["Wahib", "Mohamed", ""]]}, {"id": "2104.09079", "submitter": "Yifei Ding", "authors": "Yifei Ding, Minping Jia, Qiuhua Miao, Yudong Cao", "title": "A novel Time-frequency Transformer and its Application in Fault\n  Diagnosis of Rolling Bearings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The scope of data-driven fault diagnosis models is greatly improved through\ndeep learning (DL). However, the classical convolution and recurrent structure\nhave their defects in computational efficiency and feature representation,\nwhile the latest Transformer architecture based on attention mechanism has not\nbeen applied in this field. To solve these problems, we propose a novel\ntime-frequency Transformer (TFT) model inspired by the massive success of\nstandard Transformer in sequence processing. Specially, we design a fresh\ntokenizer and encoder module to extract effective abstractions from the\ntime-frequency representation (TFR) of vibration signals. On this basis, a new\nend-to-end fault diagnosis framework based on time-frequency Transformer is\npresented in this paper. Through the case studies on bearing experimental\ndatasets, we constructed the optimal Transformer structure and verified the\nperformance of the diagnostic method. The superiority of the proposed method is\ndemonstrated in comparison with the benchmark model and other state-of-the-art\nmethods.\n", "versions": [{"version": "v1", "created": "Mon, 19 Apr 2021 06:53:31 GMT"}, {"version": "v2", "created": "Wed, 28 Jul 2021 05:29:19 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Ding", "Yifei", ""], ["Jia", "Minping", ""], ["Miao", "Qiuhua", ""], ["Cao", "Yudong", ""]]}, {"id": "2104.09082", "submitter": "Xianghao Zhan", "authors": "Xianghao Zhan, Yiheng Li, Yuzhe Liu, Nicholas J. Cecchi, Samuel J.\n  Raymond, Zhou Zhou, Hossein Vahid Alizadeh, Jesse Ruan, Saeed Barbat, Stephen\n  Tiernan, Olivier Gevaert, Michael M. Zeineh, Gerald A. Grant, David B.\n  Camarillo", "title": "Classification of head impacts based on the spectral density of\n  measurable kinematics", "comments": "16 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.LG physics.bio-ph", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Traumatic brain injury can be caused by head impacts, but many brain injury\nrisk estimation models are less accurate across the variety of impacts that\npatients may undergo. We investigated the spectral characteristics of different\nhead impact types with kinematics classification. Data was analyzed from 3,262\nhead impacts from lab reconstruction, American football, mixed martial arts,\nand publicly available car crash data. A random forest classifier with spectral\ndensities of linear acceleration and angular velocity was built to classify\nhead impact types (e.g., football), reaching a median accuracy of 96% over\n1,000 random partitions of training and test sets. To test the classifier on\ndata from different measurement devices, another 271 lab-reconstructed impacts\nwere obtained from 5 other instrumented mouthguards with the classifier\nreaching over 96% accuracy. The most important features in the classification\nincluded both low-frequency and high-frequency features, both linear\nacceleration features and angular velocity features. Different head impact\ntypes had different distributions of spectral densities in low-frequency and\nhigh-frequency ranges (e.g., the spectral densities of MMA impacts were higher\nin high-frequency range than in the low-frequency range). Finally, with the\nclassifier, type-specific, nearest-neighbor regression models were built for\n95th percentile maximum principal strain, 95th percentile maximum principal\nstrain in corpus callosum, and cumulative strain damage (15th percentile). This\nshowed a generally higher R2-value than baseline models. The classifier enables\na better understanding of the impact kinematics in different sports, and it can\nbe applied to evaluate the quality of impact-simulation systems and on-field\ndata augmentation. Key words: traumatic brain injury, head impacts,\nclassification, impact kinematics\n", "versions": [{"version": "v1", "created": "Mon, 19 Apr 2021 06:58:43 GMT"}, {"version": "v2", "created": "Thu, 10 Jun 2021 16:23:17 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["Zhan", "Xianghao", ""], ["Li", "Yiheng", ""], ["Liu", "Yuzhe", ""], ["Cecchi", "Nicholas J.", ""], ["Raymond", "Samuel J.", ""], ["Zhou", "Zhou", ""], ["Alizadeh", "Hossein Vahid", ""], ["Ruan", "Jesse", ""], ["Barbat", "Saeed", ""], ["Tiernan", "Stephen", ""], ["Gevaert", "Olivier", ""], ["Zeineh", "Michael M.", ""], ["Grant", "Gerald A.", ""], ["Camarillo", "David B.", ""]]}, {"id": "2104.09083", "submitter": "Yidan Sun", "authors": "Yidan Sun, Guiyuan Jiang, Siew-Kei Lam, Peilan He, Fangxin Ning", "title": "Multi-fold Correlation Attention Network for Predicting Traffic Speeds\n  with Heterogeneous Frequency", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Substantial efforts have been devoted to the investigation of spatiotemporal\ncorrelations for improving traffic speed prediction accuracy. However, existing\nworks typically model the correlations based solely on the observed traffic\nstate (e.g. traffic speed) without due consideration that different correlation\nmeasurements of the traffic data could exhibit a diverse set of patterns under\ndifferent traffic situations. In addition, the existing works assume that all\nroad segments can employ the same sampling frequency of traffic states, which\nis impractical. In this paper, we propose new measurements to model the spatial\ncorrelations among traffic data and show that the resulting correlation\npatterns vary significantly under various traffic situations. We propose a\nHeterogeneous Spatial Correlation (HSC) model to capture the spatial\ncorrelation based on a specific measurement, where the traffic data of varying\nroad segments can be heterogeneous (i.e. obtained with different sampling\nfrequency). We propose a Multi-fold Correlation Attention Network (MCAN), which\nrelies on the HSC model to explore multi-fold spatial correlations and leverage\nLSTM networks to capture multi-fold temporal correlations to provide\ndiscriminating features in order to achieve accurate traffic prediction. The\nlearned multi-fold spatiotemporal correlations together with contextual factors\nare fused with attention mechanism to make the final predictions. Experiments\non real-world datasets demonstrate that the proposed MCAN model outperforms the\nstate-of-the-art baselines.\n", "versions": [{"version": "v1", "created": "Mon, 19 Apr 2021 06:58:51 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Sun", "Yidan", ""], ["Jiang", "Guiyuan", ""], ["Lam", "Siew-Kei", ""], ["He", "Peilan", ""], ["Ning", "Fangxin", ""]]}, {"id": "2104.09088", "submitter": "Sanchit Agarwal", "authors": "Anish Acharya, Suranjit Adhikari, Sanchit Agarwal, Vincent Auvray,\n  Nehal Belgamwar, Arijit Biswas, Shubhra Chandra, Tagyoung Chung, Maryam\n  Fazel-Zarandi, Raefer Gabriel, Shuyang Gao, Rahul Goel, Dilek Hakkani-Tur,\n  Jan Jezabek, Abhay Jha, Jiun-Yu Kao, Prakash Krishnan, Peter Ku, Anuj Goyal,\n  Chien-Wei Lin, Qing Liu, Arindam Mandal, Angeliki Metallinou, Vishal Naik, Yi\n  Pan, Shachi Paul, Vittorio Perera, Abhishek Sethi, Minmin Shen, Nikko Strom,\n  Eddie Wang", "title": "Alexa Conversations: An Extensible Data-driven Approach for Building\n  Task-oriented Dialogue Systems", "comments": null, "journal-ref": "NAACL 2021 System Demonstrations Track", "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional goal-oriented dialogue systems rely on various components such as\nnatural language understanding, dialogue state tracking, policy learning and\nresponse generation. Training each component requires annotations which are\nhard to obtain for every new domain, limiting scalability of such systems.\nSimilarly, rule-based dialogue systems require extensive writing and\nmaintenance of rules and do not scale either. End-to-End dialogue systems, on\nthe other hand, do not require module-specific annotations but need a large\namount of data for training. To overcome these problems, in this demo, we\npresent Alexa Conversations, a new approach for building goal-oriented dialogue\nsystems that is scalable, extensible as well as data efficient. The components\nof this system are trained in a data-driven manner, but instead of collecting\nannotated conversations for training, we generate them using a novel dialogue\nsimulator based on a few seed dialogues and specifications of APIs and entities\nprovided by the developer. Our approach provides out-of-the-box support for\nnatural conversational phenomena like entity sharing across turns or users\nchanging their mind during conversation without requiring developers to provide\nany such dialogue flows. We exemplify our approach using a simple pizza\nordering task and showcase its value in reducing the developer burden for\ncreating a robust experience. Finally, we evaluate our system using a typical\nmovie ticket booking task and show that the dialogue simulator is an essential\ncomponent of the system that leads to over $50\\%$ improvement in turn-level\naction signature prediction accuracy.\n", "versions": [{"version": "v1", "created": "Mon, 19 Apr 2021 07:09:27 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Acharya", "Anish", ""], ["Adhikari", "Suranjit", ""], ["Agarwal", "Sanchit", ""], ["Auvray", "Vincent", ""], ["Belgamwar", "Nehal", ""], ["Biswas", "Arijit", ""], ["Chandra", "Shubhra", ""], ["Chung", "Tagyoung", ""], ["Fazel-Zarandi", "Maryam", ""], ["Gabriel", "Raefer", ""], ["Gao", "Shuyang", ""], ["Goel", "Rahul", ""], ["Hakkani-Tur", "Dilek", ""], ["Jezabek", "Jan", ""], ["Jha", "Abhay", ""], ["Kao", "Jiun-Yu", ""], ["Krishnan", "Prakash", ""], ["Ku", "Peter", ""], ["Goyal", "Anuj", ""], ["Lin", "Chien-Wei", ""], ["Liu", "Qing", ""], ["Mandal", "Arindam", ""], ["Metallinou", "Angeliki", ""], ["Naik", "Vishal", ""], ["Pan", "Yi", ""], ["Paul", "Shachi", ""], ["Perera", "Vittorio", ""], ["Sethi", "Abhishek", ""], ["Shen", "Minmin", ""], ["Strom", "Nikko", ""], ["Wang", "Eddie", ""]]}, {"id": "2104.09120", "submitter": "Ziyuan Wang", "authors": "Ziyuan Wang, Feiming Yang, Rui Fan", "title": "SAS: A Simple, Accurate and Scalable Node Classification Algorithm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph neural networks have achieved state-of-the-art accuracy for graph node\nclassification. However, GNNs are difficult to scale to large graphs, for\nexample frequently encountering out-of-memory errors on even moderate size\ngraphs. Recent works have sought to address this problem using a two-stage\napproach, which first aggregates data along graph edges, then trains a\nclassifier without using additional graph information. These methods can run on\nmuch larger graphs and are orders of magnitude faster than GNNs, but achieve\nlower classification accuracy. We propose a novel two-stage algorithm based on\na simple but effective observation: we should first train a classifier then\naggregate, rather than the other way around. We show our algorithm is faster\nand can handle larger graphs than existing two-stage algorithms, while\nachieving comparable or higher accuracy than popular GNNs. We also present a\ntheoretical basis to explain our algorithm's improved accuracy, by giving a\nsynthetic nonlinear dataset in which performing aggregation before\nclassification actually decreases accuracy compared to doing classification\nalone, while our classify then aggregate approach substantially improves\naccuracy compared to classification alone.\n", "versions": [{"version": "v1", "created": "Mon, 19 Apr 2021 08:17:35 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Wang", "Ziyuan", ""], ["Yang", "Feiming", ""], ["Fan", "Rui", ""]]}, {"id": "2104.09122", "submitter": "Zihan Ding", "authors": "Jie Ren, Yewen Li, Zihan Ding, Wei Pan and Hao Dong", "title": "Probabilistic Mixture-of-Experts for Efficient Deep Reinforcement\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deep reinforcement learning (DRL) has successfully solved various problems\nrecently, typically with a unimodal policy representation. However, grasping\ndistinguishable skills for some tasks with non-unique optima can be essential\nfor further improving its learning efficiency and performance, which may lead\nto a multimodal policy represented as a mixture-of-experts (MOE). To our best\nknowledge, present DRL algorithms for general utility do not deploy this method\nas policy function approximators due to the potential challenge in its\ndifferentiability for policy learning. In this work, we propose a probabilistic\nmixture-of-experts (PMOE) implemented with a Gaussian mixture model (GMM) for\nmultimodal policy, together with a novel gradient estimator for the\nindifferentiability problem, which can be applied in generic off-policy and\non-policy DRL algorithms using stochastic policies, e.g., Soft Actor-Critic\n(SAC) and Proximal Policy Optimisation (PPO). Experimental results testify the\nadvantage of our method over unimodal polices and two different MOE methods, as\nwell as a method of option frameworks, based on the above two types of DRL\nalgorithms, on six MuJoCo tasks. Different gradient estimations for GMM like\nthe reparameterisation trick (Gumbel-Softmax) and the score-ratio trick are\nalso compared with our method. We further empirically demonstrate the\ndistinguishable primitives learned with PMOE and show the benefits of our\nmethod in terms of exploration.\n", "versions": [{"version": "v1", "created": "Mon, 19 Apr 2021 08:21:56 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Ren", "Jie", ""], ["Li", "Yewen", ""], ["Ding", "Zihan", ""], ["Pan", "Wei", ""], ["Dong", "Hao", ""]]}, {"id": "2104.09123", "submitter": "Laura D\\\"orr", "authors": "Laura D\\\"orr, Felix Brandt, Alexander Naumann, Martin Pouls", "title": "TetraPackNet: Four-Corner-Based Object Detection in Logistics Use-Cases", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  While common image object detection tasks focus on bounding boxes or\nsegmentation masks as object representations, we consider the problem of\nfinding objects based on four arbitrary vertices. We propose a novel model,\nnamed TetraPackNet, to tackle this problem. TetraPackNet is based on CornerNet\nand uses similar algorithms and ideas. It is designated for applications\nrequiring high-accuracy detection of regularly shaped objects, which is the\ncase in the logistics use-case of packaging structure recognition. We evaluate\nour model on our specific real-world dataset for this use-case. Baselined\nagainst a previous solution, consisting of a Mask R-CNN model and suitable\npost-processing steps, TetraPackNet achieves superior results (9% higher in\naccuracy) in the sub-task of four-corner based transport unit side detection.\n", "versions": [{"version": "v1", "created": "Mon, 19 Apr 2021 08:22:14 GMT"}, {"version": "v2", "created": "Wed, 23 Jun 2021 08:52:49 GMT"}], "update_date": "2021-06-24", "authors_parsed": [["D\u00f6rr", "Laura", ""], ["Brandt", "Felix", ""], ["Naumann", "Alexander", ""], ["Pouls", "Martin", ""]]}, {"id": "2104.09125", "submitter": "Amir Hertz", "authors": "Amir Hertz, Or Perel, Raja Giryes, Olga Sorkine-Hornung and Daniel\n  Cohen-Or", "title": "SAPE: Spatially-Adaptive Progressive Encoding for Neural Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.GR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Multilayer-perceptrons (MLP) are known to struggle with learning functions of\nhigh-frequencies, and in particular cases with wide frequency bands. We present\na spatially adaptive progressive encoding (SAPE) scheme for input signals of\nMLP networks, which enables them to better fit a wide range of frequencies\nwithout sacrificing training stability or requiring any domain specific\npreprocessing. SAPE gradually unmasks signal components with increasing\nfrequencies as a function of time and space. The progressive exposure of\nfrequencies is monitored by a feedback loop throughout the neural optimization\nprocess, allowing changes to propagate at different rates among local spatial\nportions of the signal space. We demonstrate the advantage of SAPE on a variety\nof domains and applications, including regression of low dimensional signals\nand images, representation learning of occupancy networks, and a geometric task\nof mesh transfer between 3D shapes.\n", "versions": [{"version": "v1", "created": "Mon, 19 Apr 2021 08:22:55 GMT"}, {"version": "v2", "created": "Fri, 28 May 2021 15:46:32 GMT"}], "update_date": "2021-05-31", "authors_parsed": [["Hertz", "Amir", ""], ["Perel", "Or", ""], ["Giryes", "Raja", ""], ["Sorkine-Hornung", "Olga", ""], ["Cohen-Or", "Daniel", ""]]}, {"id": "2104.09163", "submitter": "Louis Annabi", "authors": "Louis Annabi, Alexandre Pitti, Mathias Quoy", "title": "Bidirectional Interaction between Visual and Motor Generative Models\n  using Predictive Coding and Active Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  In this work, we build upon the Active Inference (AIF) and Predictive Coding\n(PC) frameworks to propose a neural architecture comprising a generative model\nfor sensory prediction, and a distinct generative model for motor trajectories.\nWe highlight how sequences of sensory predictions can act as rails guiding\nlearning, control and online adaptation of motor trajectories. We furthermore\ninquire the effects of bidirectional interactions between the motor and the\nvisual modules. The architecture is tested on the control of a simulated\nrobotic arm learning to reproduce handwritten letters.\n", "versions": [{"version": "v1", "created": "Mon, 19 Apr 2021 09:41:31 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Annabi", "Louis", ""], ["Pitti", "Alexandre", ""], ["Quoy", "Mathias", ""]]}, {"id": "2104.09172", "submitter": "Tianjin Huang", "authors": "Tianjin Huang, Vlado Menkovski, Yulong Pei, YuHao Wang and Mykola\n  Pechenizkiy", "title": "Direction-Aggregated Attack for Transferable Adversarial Examples", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks are vulnerable to adversarial examples that are crafted\nby imposing imperceptible changes to the inputs. However, these adversarial\nexamples are most successful in white-box settings where the model and its\nparameters are available. Finding adversarial examples that are transferable to\nother models or developed in a black-box setting is significantly more\ndifficult. In this paper, we propose the Direction-Aggregated adversarial\nattacks that deliver transferable adversarial examples. Our method utilizes\naggregated direction during the attack process for avoiding the generated\nadversarial examples overfitting to the white-box model. Extensive experiments\non ImageNet show that our proposed method improves the transferability of\nadversarial examples significantly and outperforms state-of-the-art attacks,\nespecially against adversarial robust models. The best averaged attack success\nrates of our proposed method reaches 94.6\\% against three adversarial trained\nmodels and 94.8\\% against five defense methods. It also reveals that current\ndefense approaches do not prevent transferable adversarial attacks.\n", "versions": [{"version": "v1", "created": "Mon, 19 Apr 2021 09:54:56 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Huang", "Tianjin", ""], ["Menkovski", "Vlado", ""], ["Pei", "Yulong", ""], ["Wang", "YuHao", ""], ["Pechenizkiy", "Mykola", ""]]}, {"id": "2104.09176", "submitter": "Stefan Zernetsch", "authors": "Stefan Zernetsch, Hannes Reichert, Viktor Kress, Konrad Doll, Bernhard\n  Sick", "title": "Cyclist Intention Detection: A Probabilistic Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This article presents a holistic approach for probabilistic cyclist intention\ndetection. A basic movement detection based on motion history images (MHI) and\na residual convolutional neural network (ResNet) are used to estimate\nprobabilities for the current cyclist motion state. These probabilities are\nused as weights in a probabilistic ensemble trajectory forecast. The ensemble\nconsists of specialized models, which produce individual forecasts in the form\nof Gaussian distributions under the assumption of a certain motion state of the\ncyclist (e.g. cyclist is starting or turning left). By weighting the\nspecialized models, we create forecasts in the from of Gaussian mixtures that\ndefine regions within which the cyclists will reside with a certain\nprobability. To evaluate our method, we rate the reliability, sharpness, and\npositional accuracy of our forecasted distributions. We compare our method to a\nsingle model approach which produces forecasts in the form of Gaussian\ndistributions and show that our method is able to produce more reliable and\nsharper outputs while retaining comparable positional accuracy. Both methods\nare evaluated using a dataset created at a public traffic intersection. Our\ncode and the dataset are made publicly available.\n", "versions": [{"version": "v1", "created": "Mon, 19 Apr 2021 09:59:04 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Zernetsch", "Stefan", ""], ["Reichert", "Hannes", ""], ["Kress", "Viktor", ""], ["Doll", "Konrad", ""], ["Sick", "Bernhard", ""]]}, {"id": "2104.09185", "submitter": "Sarem Seitz", "authors": "Sarem Seitz", "title": "Mixtures of Gaussian Processes for regression under multiple prior\n  distributions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  When constructing a Bayesian Machine Learning model, we might be faced with\nmultiple different prior distributions and thus are required to properly\nconsider them in a sensible manner in our model. While this situation is\nreasonably well explored for classical Bayesian Statistics, it appears useful\nto develop a corresponding method for complex Machine Learning problems. Given\ntheir underlying Bayesian framework and their widespread popularity, Gaussian\nProcesses are a good candidate to tackle this task. We therefore extend the\nidea of Mixture models for Gaussian Process regression in order to work with\nmultiple prior beliefs at once - both a analytical regression formula and a\nSparse Variational approach are considered. In addition, we consider the usage\nof our approach to additionally account for the problem of prior\nmisspecification in functional regression problems.\n", "versions": [{"version": "v1", "created": "Mon, 19 Apr 2021 10:19:14 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Seitz", "Sarem", ""]]}, {"id": "2104.09197", "submitter": "Dawei Zhou", "authors": "Dawei Zhou, Nannan Wang, Chunlei Peng, Xinbo Gao, Xiaoyu Wang, Jun Yu,\n  Tongliang Liu", "title": "Removing Adversarial Noise in Class Activation Feature Space", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) are vulnerable to adversarial noise.\nPreprocessing based defenses could largely remove adversarial noise by\nprocessing inputs. However, they are typically affected by the error\namplification effect, especially in the front of continuously evolving attacks.\nTo solve this problem, in this paper, we propose to remove adversarial noise by\nimplementing a self-supervised adversarial training mechanism in a class\nactivation feature space. To be specific, we first maximize the disruptions to\nclass activation features of natural examples to craft adversarial examples.\nThen, we train a denoising model to minimize the distances between the\nadversarial examples and the natural examples in the class activation feature\nspace. Empirical evaluations demonstrate that our method could significantly\nenhance adversarial robustness in comparison to previous state-of-the-art\napproaches, especially against unseen adversarial attacks and adaptive attacks.\n", "versions": [{"version": "v1", "created": "Mon, 19 Apr 2021 10:42:24 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Zhou", "Dawei", ""], ["Wang", "Nannan", ""], ["Peng", "Chunlei", ""], ["Gao", "Xinbo", ""], ["Wang", "Xiaoyu", ""], ["Yu", "Jun", ""], ["Liu", "Tongliang", ""]]}, {"id": "2104.09220", "submitter": "Benedikt Pf\\\"ulb", "authors": "Benedikt Pf\\\"ulb, Alexander Gepperth", "title": "Overcoming Catastrophic Forgetting with Gaussian Mixture Replay", "comments": "accepted at IJCNN2021, 9 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present Gaussian Mixture Replay (GMR), a rehearsal-based approach for\ncontinual learning (CL) based on Gaussian Mixture Models (GMM). CL approaches\nare intended to tackle the problem of catastrophic forgetting (CF), which\noccurs for Deep Neural Networks (DNNs) when sequentially training them on\nsuccessive sub-tasks. GMR mitigates CF by generating samples from previous\ntasks and merging them with current training data. GMMs serve several purposes\nhere: sample generation, density estimation (e.g., for detecting outliers or\nrecognizing task boundaries) and providing a high-level feature representation\nfor classification. GMR has several conceptual advantages over existing\nreplay-based CL approaches. First of all, GMR achieves sample generation,\nclassification and density estimation in a single network structure with\nstrongly reduced memory requirements. Secondly, it can be trained at constant\ntime complexity w.r.t. the number of sub-tasks, making it particularly suitable\nfor life-long learning. Furthermore, GMR minimizes a differentiable loss\nfunction and seems to avoid mode collapse. In addition, task boundaries can be\ndetected by applying GMM density estimation. Lastly, GMR does not require\naccess to sub-tasks lying in the future for hyper-parameter tuning, allowing CL\nunder real-world constraints. We evaluate GMR on multiple image datasets, which\nare divided into class-disjoint sub-tasks.\n", "versions": [{"version": "v1", "created": "Mon, 19 Apr 2021 11:41:34 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Pf\u00fclb", "Benedikt", ""], ["Gepperth", "Alexander", ""]]}, {"id": "2104.09224", "submitter": "Aditya Prakash", "authors": "Aditya Prakash, Kashyap Chitta, Andreas Geiger", "title": "Multi-Modal Fusion Transformer for End-to-End Autonomous Driving", "comments": "CVPR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How should representations from complementary sensors be integrated for\nautonomous driving? Geometry-based sensor fusion has shown great promise for\nperception tasks such as object detection and motion forecasting. However, for\nthe actual driving task, the global context of the 3D scene is key, e.g. a\nchange in traffic light state can affect the behavior of a vehicle\ngeometrically distant from that traffic light. Geometry alone may therefore be\ninsufficient for effectively fusing representations in end-to-end driving\nmodels. In this work, we demonstrate that imitation learning policies based on\nexisting sensor fusion methods under-perform in the presence of a high density\nof dynamic agents and complex scenarios, which require global contextual\nreasoning, such as handling traffic oncoming from multiple directions at\nuncontrolled intersections. Therefore, we propose TransFuser, a novel\nMulti-Modal Fusion Transformer, to integrate image and LiDAR representations\nusing attention. We experimentally validate the efficacy of our approach in\nurban settings involving complex scenarios using the CARLA urban driving\nsimulator. Our approach achieves state-of-the-art driving performance while\nreducing collisions by 76% compared to geometry-based fusion.\n", "versions": [{"version": "v1", "created": "Mon, 19 Apr 2021 11:48:13 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Prakash", "Aditya", ""], ["Chitta", "Kashyap", ""], ["Geiger", "Andreas", ""]]}, {"id": "2104.09226", "submitter": "David Plans Dr.", "authors": "Mohammad A. Dabbah, Angus B. Reed, Adam T.C. Booth, Arrash Yassaee,\n  Alex Despotovic, Benjamin Klasmer, Emily Binning, Mert Aral, David Plans,\n  Alain B. Labrique, Diwakar Mohan", "title": "Machine learning approach to dynamic risk modeling of mortality in\n  COVID-19: a UK Biobank study", "comments": "20 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  The COVID-19 pandemic has created an urgent need for robust, scalable\nmonitoring tools supporting stratification of high-risk patients. This research\naims to develop and validate prediction models, using the UK Biobank, to\nestimate COVID-19 mortality risk in confirmed cases. From the 11,245\nparticipants testing positive for COVID-19, we develop a data-driven random\nforest classification model with excellent performance (AUC: 0.91), using\nbaseline characteristics, pre-existing conditions, symptoms, and vital signs,\nsuch that the score could dynamically assess mortality risk with disease\ndeterioration. We also identify several significant novel predictors of\nCOVID-19 mortality with equivalent or greater predictive value than established\nhigh-risk comorbidities, such as detailed anthropometrics and prior acute\nkidney failure, urinary tract infection, and pneumonias. The model design and\nfeature selection enables utility in outpatient settings. Possible applications\ninclude supporting individual-level risk profiling and monitoring disease\nprogression across patients with COVID-19 at-scale, especially in\nhospital-at-home settings.\n", "versions": [{"version": "v1", "created": "Mon, 19 Apr 2021 11:51:20 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Dabbah", "Mohammad A.", ""], ["Reed", "Angus B.", ""], ["Booth", "Adam T. C.", ""], ["Yassaee", "Arrash", ""], ["Despotovic", "Alex", ""], ["Klasmer", "Benjamin", ""], ["Binning", "Emily", ""], ["Aral", "Mert", ""], ["Plans", "David", ""], ["Labrique", "Alain B.", ""], ["Mohan", "Diwakar", ""]]}, {"id": "2104.09231", "submitter": "Ryuji Watanabe", "authors": "Ryuji Watanabe, Hideaki Ishibashi, Tetsuo Furukawa", "title": "Visual analytics of set data for knowledge discovery and member\n  selection support", "comments": "This is accepted manuscript in Decision Support Systems. The codes of\n  prototype system are available on\n  https://github.com/furukawa-laboratory/demo-visual-analytics-set-data", "journal-ref": null, "doi": "10.1016/j.dss.2021.113635", "report-no": null, "categories": "cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Visual analytics (VA) is a visually assisted exploratory analysis approach in\nwhich knowledge discovery is executed interactively between the user and system\nin a human-centered manner. The purpose of this study is to develop a method\nfor the VA of set data aimed at supporting knowledge discovery and member\nselection. A typical target application is a visual support system for team\nanalysis and member selection, by which users can analyze past teams and\nexamine candidate lineups for new teams. Because there are several\ndifficulties, such as the combinatorial explosion problem, developing a VA\nsystem of set data is challenging. In this study, we first define the\nrequirements that the target system should satisfy and clarify the accompanying\nchallenges. Then we propose a method for the VA of set data, which satisfies\nthe requirements. The key idea is to model the generation process of sets and\ntheir outputs using a manifold network model. The proposed method visualizes\nthe relevant factors as a set of topographic maps on which various information\nis visualized. Furthermore, using the topographic maps as a bidirectional\ninterface, users can indicate their targets of interest in the system on these\nmaps. We demonstrate the proposed method by applying it to basketball teams,\nand compare with a benchmark system for outcome prediction and lineup\nreconstruction tasks. Because the method can be adapted to individual\napplication cases by extending the network structure, it can be a general\nmethod by which practical systems can be built.\n", "versions": [{"version": "v1", "created": "Sun, 4 Apr 2021 08:22:01 GMT"}, {"version": "v2", "created": "Sat, 24 Jul 2021 06:44:39 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Watanabe", "Ryuji", ""], ["Ishibashi", "Hideaki", ""], ["Furukawa", "Tetsuo", ""]]}, {"id": "2104.09237", "submitter": "Nathan Sandholtz", "authors": "Nathan Sandholtz, Yohsuke Miyamoto, Luke Bornn, Maurice Smith", "title": "Inverse Bayesian Optimization: Learning Human Search Strategies in a\n  Sequential Optimization Task", "comments": "24 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.LG math.OC stat.AP stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian optimization is a popular algorithm for sequential optimization of a\nlatent objective function when sampling from the objective is costly. The\nsearch path of the algorithm is governed by the acquisition function, which\ndefines the agent's search strategy. Conceptually, the acquisition function\ncharacterizes how the optimizer balances exploration and exploitation when\nsearching for the optimum of the latent objective. In this paper, we explore\nthe inverse problem of Bayesian optimization; we seek to estimate the agent's\nlatent acquisition function based on observed search paths. We introduce a\nprobabilistic solution framework for the inverse problem which provides a\nprincipled framework to quantify both the variability with which the agent\nperforms the optimization task as well as the uncertainty around their\nestimated acquisition function.\n  We illustrate our methods by analyzing human behavior from an experiment\nwhich was designed to force subjects to balance exploration and exploitation in\nsearch of an invisible target location. We find that while most subjects\ndemonstrate clear trends in their search behavior, there is significant\nvariation around these trends from round to round. A wide range of search\nstrategies are exhibited across the subjects in our study, but upper confidence\nbound acquisition functions offer the best fit for the majority of subjects.\nFinally, some subjects do not map well to any of the acquisition functions we\ninitially consider; these subjects tend to exhibit exploration preferences\nbeyond that of standard acquisition functions to capture. Guided by the model\ndiscrepancies, we augment the candidate acquisition functions to yield a\nsuperior fit to the human behavior in this task.\n", "versions": [{"version": "v1", "created": "Fri, 16 Apr 2021 15:40:34 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Sandholtz", "Nathan", ""], ["Miyamoto", "Yohsuke", ""], ["Bornn", "Luke", ""], ["Smith", "Maurice", ""]]}, {"id": "2104.09240", "submitter": "Benedikt Pf\\\"ulb", "authors": "Benedikt Pf\\\"ulb, Alexander Gepperth, Benedikt Bagus", "title": "Continual Learning with Fully Probabilistic Models", "comments": "Accepted as Findings at the CLVISION2021 workshop, 11 pages, 6\n  figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an approach for continual learning (CL) that is based on fully\nprobabilistic (or generative) models of machine learning. In contrast to, e.g.,\nGANs that are \"generative\" in the sense that they can generate samples, fully\nprobabilistic models aim at modeling the data distribution directly.\nConsequently, they provide functionalities that are highly relevant for\ncontinual learning, such as density estimation (outlier detection) and sample\ngeneration. As a concrete realization of generative continual learning, we\npropose Gaussian Mixture Replay (GMR). GMR is a pseudo-rehearsal approach using\na Gaussian Mixture Model (GMM) instance for both generator and classifier\nfunctionalities. Relying on the MNIST, FashionMNIST and Devanagari benchmarks,\nwe first demonstrate unsupervised task boundary detection by GMM density\nestimation, which we also use to reject untypical generated samples. In\naddition, we show that GMR is capable of class-conditional sampling in the way\nof a cGAN. Lastly, we verify that GMR, despite its simple structure, achieves\nstate-of-the-art performance on common class-incremental learning problems at\nvery competitive time and memory complexity.\n", "versions": [{"version": "v1", "created": "Mon, 19 Apr 2021 12:26:26 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Pf\u00fclb", "Benedikt", ""], ["Gepperth", "Alexander", ""], ["Bagus", "Benedikt", ""]]}, {"id": "2104.09248", "submitter": "Albert Garcia", "authors": "Albert Garcia, Mohamed Adel Musallam, Vincent Gaudilliere, Enjie\n  Ghorbel, Kassem Al Ismaeil, Marcos Perez, Djamila Aouada", "title": "LSPnet: A 2D Localization-oriented Spacecraft Pose Estimation Neural\n  Network", "comments": "9 pages, 5 figures, to be published at AI4Space 2021 IEEE/CVF\n  Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Being capable of estimating the pose of uncooperative objects in space has\nbeen proposed as a key asset for enabling safe close-proximity operations such\nas space rendezvous, in-orbit servicing and active debris removal. Usual\napproaches for pose estimation involve classical computer vision-based\nsolutions or the application of Deep Learning (DL) techniques. This work\nexplores a novel DL-based methodology, using Convolutional Neural Networks\n(CNNs), for estimating the pose of uncooperative spacecrafts. Contrary to other\napproaches, the proposed CNN directly regresses poses without needing any prior\n3D information. Moreover, bounding boxes of the spacecraft in the image are\npredicted in a simple, yet efficient manner. The performed experiments show how\nthis work competes with the state-of-the-art in uncooperative spacecraft pose\nestimation, including works which require 3D information as well as works which\npredict bounding boxes through sophisticated CNNs.\n", "versions": [{"version": "v1", "created": "Mon, 19 Apr 2021 12:46:05 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Garcia", "Albert", ""], ["Musallam", "Mohamed Adel", ""], ["Gaudilliere", "Vincent", ""], ["Ghorbel", "Enjie", ""], ["Ismaeil", "Kassem Al", ""], ["Perez", "Marcos", ""], ["Aouada", "Djamila", ""]]}, {"id": "2104.09252", "submitter": "Nima TaheriNejad", "authors": "Lukas Baischer, Matthias Wess, Nima TaheriNejad", "title": "Learning on Hardware: A Tutorial on Neural Network Accelerators and\n  Co-Processors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AR cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) have the advantage that they can take into\naccount a large number of parameters, which enables them to solve complex\ntasks. In computer vision and speech recognition, they have a better accuracy\nthan common algorithms, and in some tasks, they boast an even higher accuracy\nthan human experts. With the progress of DNNs in recent years, many other\nfields of application such as diagnosis of diseases and autonomous driving are\ntaking advantage of them. The trend at DNNs is clear: The network size is\ngrowing exponentially, which leads to an exponential increase in computational\neffort and required memory size. For this reason, optimized hardware\naccelerators are used to increase the performance of the inference of neuronal\nnetworks. However, there are various neural network hardware accelerator\nplatforms, such as graphics processing units (GPUs), application specific\nintegrated circuits (ASICs) and field programmable gate arrays (FPGAs). Each of\nthese platforms offer certain advantages and disadvantages. Also, there are\nvarious methods for reducing the computational effort of DNNs, which are\ndifferently suitable for each hardware accelerator. In this article an overview\nof existing neural network hardware accelerators and acceleration methods is\ngiven. Their strengths and weaknesses are shown and a recommendation of\nsuitable applications is given. In particular, we focus on acceleration of the\ninference of convolutional neural networks (CNNs) used for image recognition\ntasks. Given that there exist many different hardware architectures. FPGA-based\nimplementations are well-suited to show the effect of DNN optimization methods\non accuracy and throughput. For this reason, the focus of this work is more on\nFPGA-based implementations.\n", "versions": [{"version": "v1", "created": "Mon, 19 Apr 2021 12:50:27 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Baischer", "Lukas", ""], ["Wess", "Matthias", ""], ["TaheriNejad", "Nima", ""]]}, {"id": "2104.09255", "submitter": "Zongmo Huang", "authors": "Zongmo Huang, Yazhou Ren, Xiaorong Pu, Lifang He", "title": "Non-Linear Fusion for Self-Paced Multi-View Clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the advance of the multi-media and multi-modal data, multi-view\nclustering (MVC) has drawn increasing attentions recently. In this field, one\nof the most crucial challenges is that the characteristics and qualities of\ndifferent views usually vary extensively. Therefore, it is essential for MVC\nmethods to find an effective approach that handles the diversity of multiple\nviews appropriately. To this end, a series of MVC methods focusing on how to\nintegrate the loss from each view have been proposed in the past few years.\nAmong these methods, the mainstream idea is assigning weights to each view and\nthen combining them linearly. In this paper, inspired by the effectiveness of\nnon-linear combination in instance learning and the auto-weighted approaches,\nwe propose Non-Linear Fusion for Self-Paced Multi-View Clustering (NSMVC),\nwhich is totally different from the the conventional linear-weighting\nalgorithms. In NSMVC, we directly assign different exponents to different views\naccording to their qualities. By this way, the negative impact from the corrupt\nviews can be significantly reduced. Meanwhile, to address the non-convex issue\nof the MVC model, we further define a novel regularizer-free modality of\nSelf-Paced Learning (SPL), which fits the proposed non-linear model perfectly.\nExperimental results on various real-world data sets demonstrate the\neffectiveness of the proposed method.\n", "versions": [{"version": "v1", "created": "Mon, 19 Apr 2021 12:53:23 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Huang", "Zongmo", ""], ["Ren", "Yazhou", ""], ["Pu", "Xiaorong", ""], ["He", "Lifang", ""]]}, {"id": "2104.09261", "submitter": "Xu Guo", "authors": "Xu Guo, Boyang Li, Han Yu and Chunyan Miao", "title": "Latent-Optimized Adversarial Neural Transfer for Sarcasm Detection", "comments": "14 pages, 5 figures, published at NAACL-HLT 2021 conference, see\n  https://www.aclweb.org/anthology/2021.naacl-main.425/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The existence of multiple datasets for sarcasm detection prompts us to apply\ntransfer learning to exploit their commonality. The adversarial neural transfer\n(ANT) framework utilizes multiple loss terms that encourage the source-domain\nand the target-domain feature distributions to be similar while optimizing for\ndomain-specific performance. However, these objectives may be in conflict,\nwhich can lead to optimization difficulties and sometimes diminished transfer.\nWe propose a generalized latent optimization strategy that allows different\nlosses to accommodate each other and improves training dynamics. The proposed\nmethod outperforms transfer learning and meta-learning baselines. In\nparticular, we achieve 10.02% absolute performance gain over the previous state\nof the art on the iSarcasm dataset.\n", "versions": [{"version": "v1", "created": "Mon, 19 Apr 2021 13:07:52 GMT"}, {"version": "v2", "created": "Sat, 12 Jun 2021 09:33:22 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Guo", "Xu", ""], ["Li", "Boyang", ""], ["Yu", "Han", ""], ["Miao", "Chunyan", ""]]}, {"id": "2104.09263", "submitter": "Shuo Liu", "authors": "Shuo Liu, Jing Han, Estela Laporta Puyal, Spyridon Kontaxis, Shaoxiong\n  Sun, Patrick Locatelli, Judith Dineley, Florian B. Pokorny, Gloria Dalla\n  Costa, Letizia Leocan, Ana Isabel Guerrero, Carlos Nos, Ana Zabalza, Per\n  Soelberg S{\\o}rensen, Mathias Buron, Melinda Magyari, Yatharth Ranjan,\n  Zulqarnain Rashid, Pauline Conde, Callum Stewart, Amos A Folarin, Richard JB\n  Dobson, Raquel Bail\\'on, Srinivasan Vairavan, Nicholas Cummins, Vaibhav A\n  Narayan, Matthew Hotopf, Giancarlo Comi, Bj\\\"orn Schuller", "title": "Fitbeat: COVID-19 Estimation based on Wristband Heart Rate", "comments": "34pages, 4figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This study investigates the potential of deep learning methods to identify\nindividuals with suspected COVID-19 infection using remotely collected\nheart-rate data. The study utilises data from the ongoing EU IMI RADAR-CNS\nresearch project that is investigating the feasibility of wearable devices and\nsmart phones to monitor individuals with multiple sclerosis (MS), depression or\nepilepsy. Aspart of the project protocol, heart-rate data was collected from\nparticipants using a Fitbit wristband. The presence of COVID-19 in the cohort\nin this work was either confirmed through a positive swab test, or inferred\nthrough the self-reporting of a combination of symptoms including fever,\nrespiratory symptoms, loss of smell or taste, tiredness and gastrointestinal\nsymptoms. Experimental results indicate that our proposed contrastive\nconvolutional auto-encoder (contrastive CAE), i. e., a combined architecture of\nan auto-encoder and contrastive loss, outperforms a conventional convolutional\nneural network (CNN), as well as a convolutional auto-encoder (CAE) without\nusing contrastive loss. Our final contrastive CAE achieves 95.3% unweighted\naverage recall, 86.4% precision, anF1 measure of 88.2%, a sensitivity of 100%\nand a specificity of 90.6% on a testset of 19 participants with MS who reported\nsymptoms of COVID-19. Each of these participants was paired with a participant\nwith MS with no COVID-19 symptoms.\n", "versions": [{"version": "v1", "created": "Mon, 19 Apr 2021 13:08:53 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Liu", "Shuo", ""], ["Han", "Jing", ""], ["Puyal", "Estela Laporta", ""], ["Kontaxis", "Spyridon", ""], ["Sun", "Shaoxiong", ""], ["Locatelli", "Patrick", ""], ["Dineley", "Judith", ""], ["Pokorny", "Florian B.", ""], ["Costa", "Gloria Dalla", ""], ["Leocan", "Letizia", ""], ["Guerrero", "Ana Isabel", ""], ["Nos", "Carlos", ""], ["Zabalza", "Ana", ""], ["S\u00f8rensen", "Per Soelberg", ""], ["Buron", "Mathias", ""], ["Magyari", "Melinda", ""], ["Ranjan", "Yatharth", ""], ["Rashid", "Zulqarnain", ""], ["Conde", "Pauline", ""], ["Stewart", "Callum", ""], ["Folarin", "Amos A", ""], ["Dobson", "Richard JB", ""], ["Bail\u00f3n", "Raquel", ""], ["Vairavan", "Srinivasan", ""], ["Cummins", "Nicholas", ""], ["Narayan", "Vaibhav A", ""], ["Hotopf", "Matthew", ""], ["Comi", "Giancarlo", ""], ["Schuller", "Bj\u00f6rn", ""]]}, {"id": "2104.09276", "submitter": "Zhenguo Nie", "authors": "Qingfeng Xu, Zhenguo Nie, Handing Xu, Haosu Zhou, Xinjun Liu", "title": "SuperMeshing: A New Deep Learning Architecture for Increasing the Mesh\n  Density of Metal Forming Stress Field with Attention Mechanism and Perceptual\n  Features", "comments": "15 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In stress field analysis, the finite element analysis is a crucial approach,\nin which the mesh-density has a significant impact on the results. High mesh\ndensity usually contributes authentic to simulation results but costs more\ncomputing resources, leading to curtailing efficiency during the design\nprocess. To eliminate this drawback, we propose a new data-driven mesh-density\nboost model named SuperMeshingNet that strengthens the advantages of finite\nelement analysis (FEA) with low mesh-density as inputs to the deep learning\nmodel, which consisting of Res-UNet architecture, to acquire high-density\nstress field instantaneously, shortening computing time and cost automatically.\nMoreover, the attention mechanism and the perceptual features are utilized,\nenhancing the performance of SuperMeshingNet. Compared to the baseline that\napplied the linear interpolation method, SuperMeshingNet achieves a prominent\nreduction in the mean squared error (MSE) and mean absolute error (MAE) on test\ndata, which contains prior unseen cases. Based on the data set of metal\nforming, the comparable experiments are proceeded to demonstrate the high\nquality and superior precision of the reconstructed results generated by our\nmodel. The well-trained model can successfully show more excellent performance\nthan the baseline and other methods on the multiple scaled mesh-density,\nincluding $2\\times$, $4\\times$, and $8\\times$. With the refined result owning\nbroaden scaling of mesh density and high precision, the FEA process can be\naccelerated with seldom cost on computation resources. We publicly share our\nwork with full detail of implementation at\nhttps://github.com/zhenguonie/2021_SuperMeshing_2D_Metal_Forming\n", "versions": [{"version": "v1", "created": "Fri, 12 Mar 2021 06:02:30 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Xu", "Qingfeng", ""], ["Nie", "Zhenguo", ""], ["Xu", "Handing", ""], ["Zhou", "Haosu", ""], ["Liu", "Xinjun", ""]]}, {"id": "2104.09277", "submitter": "Amir Geranmayeh Dr.-Ing.", "authors": "Amir Geranmayeh", "title": "Machine-Learning Classification of Closed and Open Radiating Wires from\n  Near Magnetic or Electric Field Scan Images", "comments": "4 pages, 128 subfigures, 1 table explaining how the near-field data\n  of a scan table can be used as the training set to automatically detect and\n  distinct the radiating open endings from closed routings without using any\n  feature descriptor. The averaged F1 score of almost 90 percent implies the\n  possibility of categorising the type of radiators from their magnitude only\n  emitted near-field pattern", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG physics.app-ph physics.ins-det", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Sets of intelligent classifiers are applied to the near-field scan-data in\norder to automatically classify the shape of radiating wirings. The support\nvector machine, k-nearest neighbors algorithm, and Gaussian process\nclassifications are trained using the near-field radiation pattern of diverse\nradiating wire configurations. Leave-one-out cross-validation is used for\nestimating the performance of the predictive models. The output of this\nresearch is a software package well-suited to be retrained based on any\nmeasured near-field databank to automate the identification of magnetic-type or\nelectric-type of the radiating coupling sources.\n", "versions": [{"version": "v1", "created": "Tue, 16 Mar 2021 06:08:35 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Geranmayeh", "Amir", ""]]}, {"id": "2104.09284", "submitter": "Xitong Gao", "authors": "Yunrui Yu, Xitong Gao, Cheng-Zhong Xu", "title": "LAFEAT: Piercing Through Adversarial Defenses with Latent Features", "comments": "Accepted as an oral paper in Conference on Computer Vision and\n  Pattern Recognition (CVPR) 2021. 11 pages, 6 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Deep convolutional neural networks are susceptible to adversarial attacks.\nThey can be easily deceived to give an incorrect output by adding a tiny\nperturbation to the input. This presents a great challenge in making CNNs\nrobust against such attacks. An influx of new defense techniques have been\nproposed to this end. In this paper, we show that latent features in certain\n\"robust\" models are surprisingly susceptible to adversarial attacks. On top of\nthis, we introduce a unified $\\ell_\\infty$-norm white-box attack algorithm\nwhich harnesses latent features in its gradient descent steps, namely LAFEAT.\nWe show that not only is it computationally much more efficient for successful\nattacks, but it is also a stronger adversary than the current state-of-the-art\nacross a wide range of defense mechanisms. This suggests that model robustness\ncould be contingent on the effective use of the defender's hidden components,\nand it should no longer be viewed from a holistic perspective.\n", "versions": [{"version": "v1", "created": "Mon, 19 Apr 2021 13:22:20 GMT"}, {"version": "v2", "created": "Tue, 20 Apr 2021 07:35:16 GMT"}], "update_date": "2021-04-21", "authors_parsed": [["Yu", "Yunrui", ""], ["Gao", "Xitong", ""], ["Xu", "Cheng-Zhong", ""]]}, {"id": "2104.09286", "submitter": "Shohei Enomoto", "authors": "Shohei Enomoto, Takeharu Eda", "title": "Learning to Cascade: Confidence Calibration for Improving the Accuracy\n  and Computational Cost of Cascade Inference Systems", "comments": "AAAI2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, deep neural networks have become to be used in a variety of\napplications. While the accuracy of deep neural networks is increasing, the\nconfidence score, which indicates the reliability of the prediction results, is\nbecoming more important. Deep neural networks are seen as highly accurate but\nknown to be overconfident, making it important to calibrate the confidence\nscore. Many studies have been conducted on confidence calibration. They\ncalibrate the confidence score of the model to match its accuracy, but it is\nnot clear whether these confidence scores can improve the performance of\nsystems that use confidence scores. This paper focuses on cascade inference\nsystems, one kind of systems using confidence scores, and discusses the desired\nconfidence score to improve system performance in terms of inference accuracy\nand computational cost. Based on the discussion, we propose a new confidence\ncalibration method, Learning to Cascade. Learning to Cascade is a simple but\nnovel method that optimizes the loss term for confidence calibration\nsimultaneously with the original loss term. Experiments are conducted using two\ndatasets, CIFAR-100 and ImageNet, in two system settings, and show that naive\napplication of existing calibration methods to cascade inference systems\nsometimes performs worse. However, Learning to Cascade always achieves a better\ntrade-off between inference accuracy and computational cost. The simplicity of\nLearning to Cascade allows it to be easily applied to improve the performance\nof existing systems.\n", "versions": [{"version": "v1", "created": "Thu, 15 Apr 2021 07:09:09 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Enomoto", "Shohei", ""], ["Eda", "Takeharu", ""]]}, {"id": "2104.09304", "submitter": "Kohei Watabe", "authors": "Shohei Nakazawa, Yoshiki Sato, Kenji Nakagawa, Sho Tsugawa, Kohei\n  Watabe", "title": "A Tunable Model for Graph Generation Using LSTM and Conditional VAE", "comments": "Accepted at the 41st IEEE International Conference on Distributed\n  Computing Systems (ICDCS 2021) Poster Track. 2 pages, 3 pdf figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NI cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the development of graph applications, generative models for graphs have\nbeen more crucial. Classically, stochastic models that generate graphs with a\npre-defined probability of edges and nodes have been studied. Recently, some\nmodels that reproduce the structural features of graphs by learning from actual\ngraph data using machine learning have been studied. However, in these\nconventional studies based on machine learning, structural features of graphs\ncan be learned from data, but it is not possible to tune features and generate\ngraphs with specific features. In this paper, we propose a generative model\nthat can tune specific features, while learning structural features of a graph\nfrom data. With a dataset of graphs with various features generated by a\nstochastic model, we confirm that our model can generate a graph with specific\nfeatures.\n", "versions": [{"version": "v1", "created": "Thu, 15 Apr 2021 06:47:14 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Nakazawa", "Shohei", ""], ["Sato", "Yoshiki", ""], ["Nakagawa", "Kenji", ""], ["Tsugawa", "Sho", ""], ["Watabe", "Kohei", ""]]}, {"id": "2104.09305", "submitter": "Shehroz Khan", "authors": "Shehroz S. Khan, Thaejaesh Sooriyakumaran, Katherine Rich, Sofija\n  Spasojevic, Bing Ye, Kristine Newman, Andrea Iaboni, Alex Mihailidis", "title": "Tracking agitation in people living with dementia in a care environment", "comments": "12 pages, 9 figures, 2 Tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Agitation is a symptom that communicates distress in people living with\ndementia (PwD), and that can place them and others at risk. In a long term care\n(LTC) environment, care staff track and document these symptoms as a way to\ndetect when there has been a change in resident status to assess risk, and to\nmonitor for response to interventions. However, this documentation can be\ntime-consuming, and due to staffing constraints, episodes of agitation may go\nunobserved. This brings into question the reliability of these assessments, and\npresents an opportunity for technology to help track and monitor behavioural\nsymptoms in dementia. In this paper, we present the outcomes of a 2 year\nreal-world study performed in a dementia unit, where a multi-modal wearable\ndevice was worn by $20$ PwD. In line with a commonly used clinical\ndocumentation tool, this large multi-modal time-series data was analyzed to\ntrack the presence of episodes of agitation in 8-hour nursing shifts. The\ndevelopment of a baseline classification model (AUC=0.717) on this dataset and\nsubsequent improvement (AUC= 0.779) lays the groundwork for automating the\nprocess of annotating agitation events in nursing charts.\n", "versions": [{"version": "v1", "created": "Thu, 15 Apr 2021 06:21:29 GMT"}, {"version": "v2", "created": "Mon, 26 Apr 2021 03:54:08 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Khan", "Shehroz S.", ""], ["Sooriyakumaran", "Thaejaesh", ""], ["Rich", "Katherine", ""], ["Spasojevic", "Sofija", ""], ["Ye", "Bing", ""], ["Newman", "Kristine", ""], ["Iaboni", "Andrea", ""], ["Mihailidis", "Alex", ""]]}, {"id": "2104.09311", "submitter": "Yufei Zhang", "authors": "Xin Guo, Anran Hu, Yufei Zhang", "title": "Reinforcement learning for linear-convex models with jumps via stability\n  analysis of feedback controls", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study finite-time horizon continuous-time linear-convex reinforcement\nlearning problems in an episodic setting. In this problem, the unknown linear\njump-diffusion process is controlled subject to nonsmooth convex costs. We show\nthat the associated linear-convex control problems admit Lipchitz continuous\noptimal feedback controls and further prove the Lipschitz stability of the\nfeedback controls, i.e., the performance gap between applying feedback controls\nfor an incorrect model and for the true model depends Lipschitz-continuously on\nthe magnitude of perturbations in the model coefficients; the proof relies on a\nstability analysis of the associated forward-backward stochastic differential\nequation. We then propose a novel least-squares algorithm which achieves a\nregret of the order $O(\\sqrt{N\\ln N})$ on linear-convex learning problems with\njumps, where $N$ is the number of learning episodes; the analysis leverages the\nLipschitz stability of feedback controls and concentration properties of\nsub-Weibull random variables.\n", "versions": [{"version": "v1", "created": "Mon, 19 Apr 2021 13:50:52 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Guo", "Xin", ""], ["Hu", "Anran", ""], ["Zhang", "Yufei", ""]]}, {"id": "2104.09313", "submitter": "Fabian Schrumpf", "authors": "Fabian Schrumpf, Patrick Frenzel, Christoph Aust, Georg Osterhoff,\n  Mirco Fuchs", "title": "Assessment of deep learning based blood pressure prediction from PPG and\n  rPPG signals", "comments": "(Accepted / In press) 2021 IEEE/CVF Conference on Computer Vision and\n  Pattern Recognition Workshop (CVPRW)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Exploiting photoplethysmography signals (PPG) for non-invasive blood pressure\n(BP) measurement is interesting for various reasons. First, PPG can easily be\nmeasured using fingerclip sensors. Second, camera-based approaches allow to\nderive remote PPG (rPPG) signals similar to PPG and therefore provide the\nopportunity for non-invasive measurements of BP. Various methods relying on\nmachine learning techniques have recently been published. Performances are\noften reported as the mean average error (MAE) on the data which is\nproblematic. This work aims to analyze the PPG- and rPPG-based BP prediction\nerror with respect to the underlying data distribution. First, we train\nestablished neural network (NN) architectures and derive an appropriate\nparameterization of input segments drawn from continuous PPG signals. Second,\nwe apply this parameterization to a larger PPG dataset and train NNs to predict\nBP. The resulting prediction errors increase towards less frequent BP values.\nThird, we use transfer learning to train the NNs for rPPG based BP prediction.\nThe resulting performances are similar to the PPG-only case. Finally, we apply\na personalization technique and retrain our NNs with subject-specific data.\nThis slightly reduces the prediction errors.\n", "versions": [{"version": "v1", "created": "Thu, 15 Apr 2021 15:56:58 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Schrumpf", "Fabian", ""], ["Frenzel", "Patrick", ""], ["Aust", "Christoph", ""], ["Osterhoff", "Georg", ""], ["Fuchs", "Mirco", ""]]}, {"id": "2104.09315", "submitter": "Megh Shukla", "authors": "Megh Shukla, Shuaib Ahmed", "title": "A Mathematical Analysis of Learning Loss for Active Learning in\n  Regression", "comments": "Accepted: 2021 IEEE CVPR Workshop on Fair, Data Efficient and Trusted\n  Computer Vision", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Active learning continues to remain significant in the industry since it is\ndata efficient. Not only is it cost effective on a constrained budget,\ncontinuous refinement of the model allows for early detection and resolution of\nfailure scenarios during the model development stage. Identifying and fixing\nfailures with the model is crucial as industrial applications demand that the\nunderlying model performs accurately in all foreseeable use cases. One popular\nstate-of-the-art technique that specializes in continuously refining the model\nvia failure identification is Learning Loss. Although simple and elegant, this\napproach is empirically motivated. Our paper develops a foundation for Learning\nLoss which enables us to propose a novel modification we call LearningLoss++.\nWe show that gradients are crucial in interpreting how Learning Loss works,\nwith rigorous analysis and comparison of the gradients between Learning Loss\nand LearningLoss++. We also propose a convolutional architecture that combines\nfeatures at different scales to predict the loss. We validate LearningLoss++\nfor regression on the task of human pose estimation (using MPII and LSP\ndatasets), as done in Learning Loss. We show that LearningLoss++ outperforms in\nidentifying scenarios where the model is likely to perform poorly, which on\nmodel refinement translates into reliable performance in the open world.\n", "versions": [{"version": "v1", "created": "Mon, 19 Apr 2021 13:54:20 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Shukla", "Megh", ""], ["Ahmed", "Shuaib", ""]]}, {"id": "2104.09323", "submitter": "Tobias Hatt", "authors": "Tobias Hatt, Stefan Feuerriegel", "title": "Sequential Deconfounding for Causal Inference with Unobserved\n  Confounders", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Using observational data to estimate the effect of a treatment is a powerful\ntool for decision-making when randomized experiments are infeasible or costly.\nHowever, observational data often yields biased estimates of treatment effects,\nsince treatment assignment can be confounded by unobserved variables. A remedy\nis offered by deconfounding methods that adjust for such unobserved\nconfounders. In this paper, we develop the Sequential Deconfounder, a method\nthat enables estimating individualized treatment effects over time in presence\nof unobserved confounders. This is the first deconfounding method that can be\nused in a general sequential setting (i.e., with one or more treatments\nassigned at each timestep). The Sequential Deconfounder uses a novel Gaussian\nprocess latent variable model to infer substitutes for the unobserved\nconfounders, which are then used in conjunction with an outcome model to\nestimate treatment effects over time. We prove that using our method yields\nunbiased estimates of individualized treatment responses over time. Using\nsimulated and real medical data, we demonstrate the efficacy of our method in\ndeconfounding the estimation of treatment responses over time.\n", "versions": [{"version": "v1", "created": "Fri, 16 Apr 2021 09:56:39 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Hatt", "Tobias", ""], ["Feuerriegel", "Stefan", ""]]}, {"id": "2104.09325", "submitter": "Luis Miralles", "authors": "Andr\\'es L. Su\\'arez-Cetrulo and Ankit Kumar and Luis\n  Miralles-Pechu\\'an", "title": "Modelling the COVID-19 virus evolution with Incremental Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The investment of time and resources for better strategies and methodologies\nto tackle a potential pandemic is key to deal with potential outbreaks of new\nvariants or other viruses in the future. In this work, we recreated the scene\nof a year ago, 2020, when the pandemic erupted across the world for the fifty\ncountries with more COVID-19 cases reported. We performed some experiments in\nwhich we compare state-of-the-art machine learning algorithms, such as LSTM,\nagainst online incremental machine learning algorithms to adapt them to the\ndaily changes in the spread of the disease and predict future COVID-19 cases.\nTo compare the methods, we performed three experiments: In the first one, we\ntrained the models using only data from the country we predicted. In the second\none, we use data from all fifty countries to train and predict each of them. In\nthe first and second experiment, we used a static hold-out approach for all\nmethods. In the third experiment, we trained the incremental methods\nsequentially, using a prequential evaluation. This scheme is not suitable for\nmost state-of-the-art machine learning algorithms because they need to be\nretrained from scratch for every batch of predictions, causing a computational\nburden. Results show that incremental methods are a promising approach to adapt\nto changes of the disease over time; they are always up to date with the last\nstate of the data distribution, and they have a significantly lower\ncomputational cost than other techniques such as LSTMs.\n", "versions": [{"version": "v1", "created": "Wed, 14 Apr 2021 16:08:35 GMT"}, {"version": "v2", "created": "Wed, 21 Apr 2021 09:13:06 GMT"}], "update_date": "2021-04-22", "authors_parsed": [["Su\u00e1rez-Cetrulo", "Andr\u00e9s L.", ""], ["Kumar", "Ankit", ""], ["Miralles-Pechu\u00e1n", "Luis", ""]]}, {"id": "2104.09327", "submitter": "Michael Hughes", "authors": "Alexandra Hope Lee, Panagiotis Lymperopoulos, Joshua T. Cohen, John B.\n  Wong, and Michael C. Hughes", "title": "Forecasting COVID-19 Counts At A Single Hospital: A Hierarchical\n  Bayesian Approach", "comments": "In ICLR 2021 Workshop on Machine Learning for Preventing and\n  Combating Pandemics", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We consider the problem of forecasting the daily number of hospitalized\nCOVID-19 patients at a single hospital site, in order to help administrators\nwith logistics and planning. We develop several candidate hierarchical Bayesian\nmodels which directly capture the count nature of data via a generalized\nPoisson likelihood, model time-series dependencies via autoregressive and\nGaussian process latent processes, and share statistical strength across\nrelated sites. We demonstrate our approach on public datasets for 8 hospitals\nin Massachusetts, U.S.A. and 10 hospitals in the United Kingdom. Further\nprospective evaluation compares our approach favorably to baselines currently\nused by stakeholders at 3 related hospitals to forecast 2-week-ahead demand by\nrescaling state-level forecasts.\n", "versions": [{"version": "v1", "created": "Wed, 14 Apr 2021 11:58:54 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Lee", "Alexandra Hope", ""], ["Lymperopoulos", "Panagiotis", ""], ["Cohen", "Joshua T.", ""], ["Wong", "John B.", ""], ["Hughes", "Michael C.", ""]]}, {"id": "2104.09342", "submitter": "Grigory Malinovsky", "authors": "Grigory Malinovsky, Alibek Sailanbayev, Peter Richt\\'arik", "title": "Random Reshuffling with Variance Reduction: New Analysis and Better\n  Rates", "comments": "24 pages, 5 figures, 4 algorithms, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Virtually all state-of-the-art methods for training supervised machine\nlearning models are variants of SGD enhanced with a number of additional\ntricks, such as minibatching, momentum, and adaptive stepsizes. One of the\ntricks that works so well in practice that it is used as default in virtually\nall widely used machine learning software is {\\em random reshuffling (RR)}.\nHowever, the practical benefits of RR have until very recently been eluding\nattempts at being satisfactorily explained using theory. Motivated by recent\ndevelopment due to Mishchenko, Khaled and Richt\\'{a}rik (2020), in this work we\nprovide the first analysis of SVRG under Random Reshuffling (RR-SVRG) for\ngeneral finite-sum problems. First, we show that RR-SVRG converges linearly\nwith the rate $\\mathcal{O}(\\kappa^{3/2})$ in the strongly-convex case, and can\nbe improved further to $\\mathcal{O}(\\kappa)$ in the big data regime (when $n >\n\\mathcal{O}(\\kappa)$), where $\\kappa$ is the condition number. This improves\nupon the previous best rate $\\mathcal{O}(\\kappa^2)$ known for a variance\nreduced RR method in the strongly-convex case due to Ying, Yuan and Sayed\n(2020). Second, we obtain the first sublinear rate for general convex problems.\nThird, we establish similar fast rates for Cyclic-SVRG and Shuffle-Once-SVRG.\nFinally, we develop and analyze a more general variance reduction scheme for\nRR, which allows for less frequent updates of the control variate. We\ncorroborate our theoretical results with suitably chosen experiments on\nsynthetic and real datasets.\n", "versions": [{"version": "v1", "created": "Mon, 19 Apr 2021 14:30:10 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Malinovsky", "Grigory", ""], ["Sailanbayev", "Alibek", ""], ["Richt\u00e1rik", "Peter", ""]]}, {"id": "2104.09343", "submitter": "Antoine Lesage-Landry", "authors": "Antoine Lesage-Landry and Duncan S. Callaway", "title": "Approximate Multi-Agent Fitted Q Iteration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We formulate an efficient approximation for multi-agent batch reinforcement\nlearning, the approximate multi-agent fitted Q iteration (AMAFQI). We present a\ndetailed derivation of our approach. We propose an iterative policy search and\nshow that it yields a greedy policy with respect to multiple approximations of\nthe centralized, standard Q-function. In each iteration and policy evaluation,\nAMAFQI requires a number of computations that scales linearly with the number\nof agents whereas the analogous number of computations increase exponentially\nfor the fitted Q iteration (FQI), one of the most commonly used approaches in\nbatch reinforcement learning. This property of AMAFQI is fundamental for the\ndesign of a tractable multi-agent approach. We evaluate the performance of\nAMAFQI and compare it to FQI in numerical simulations. Numerical examples\nillustrate the significant computation time reduction when using AMAFQI instead\nof FQI in multi-agent problems and corroborate the similar decision-making\nperformance of both approaches.\n", "versions": [{"version": "v1", "created": "Mon, 19 Apr 2021 14:30:22 GMT"}, {"version": "v2", "created": "Wed, 7 Jul 2021 15:38:35 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Lesage-Landry", "Antoine", ""], ["Callaway", "Duncan S.", ""]]}, {"id": "2104.09345", "submitter": "James Fitzpatrick", "authors": "James Fitzpatrick, Deepak Ajwani and Paula Carroll", "title": "Learning to Sparsify Travelling Salesman Problem Instances", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In order to deal with the high development time of exact and approximation\nalgorithms for NP-hard combinatorial optimisation problems and the high running\ntime of exact solvers, deep learning techniques have been used in recent years\nas an end-to-end approach to find solutions. However, there are issues of\nrepresentation, generalisation, complex architectures, interpretability of\nmodels for mathematical analysis etc. using deep learning techniques. As a\ncompromise, machine learning can be used to improve the run time performance of\nexact algorithms in a matheuristics framework. In this paper, we use a pruning\nheuristic leveraging machine learning as a pre-processing step followed by an\nexact Integer Programming approach. We apply this approach to sparsify\ninstances of the classical travelling salesman problem. Our approach learns\nwhich edges in the underlying graph are unlikely to belong to an optimal\nsolution and removes them, thus sparsifying the graph and significantly\nreducing the number of decision variables. We use carefully selected features\nderived from linear programming relaxation, cutting planes exploration,\nminimum-weight spanning tree heuristics and various other local and statistical\nanalysis of the graph. Our learning approach requires very little training data\nand is amenable to mathematical analysis. We demonstrate that our approach can\nreliably prune a large fraction of the variables in TSP instances from\nTSPLIB/MATILDA (>85%$) while preserving most of the optimal tour edges. Our\napproach can successfully prune problem instances even if they lie outside the\ntraining distribution, resulting in small optimality gaps between the pruned\nand original problems in most cases. Using our learning technique, we discover\nnovel heuristics for sparsifying TSP instances, that may be of independent\ninterest for variants of the vehicle routing problem.\n", "versions": [{"version": "v1", "created": "Mon, 19 Apr 2021 14:35:14 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Fitzpatrick", "James", ""], ["Ajwani", "Deepak", ""], ["Carroll", "Paula", ""]]}, {"id": "2104.09355", "submitter": "Sam Partee", "authors": "Sam Partee, Matthew Ellis, Alessandro Rigazzi, Scott Bachman, Gustavo\n  Marques, Andrew Shao, Benjamin Robbins", "title": "Using Machine Learning at Scale in HPC Simulations with SmartSim: An\n  Application to Ocean Climate Modeling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.DC cs.LG physics.ao-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We demonstrate the first climate-scale, numerical ocean simulations improved\nthrough distributed, online inference of Deep Neural Networks (DNN) using\nSmartSim. SmartSim is a library dedicated to enabling online analysis and\nMachine Learning (ML) for traditional HPC simulations. In this paper, we detail\nthe SmartSim architecture and provide benchmarks including online inference\nwith a shared ML model on heterogeneous HPC systems. We demonstrate the\ncapability of SmartSim by using it to run a 12-member ensemble of global-scale,\nhigh-resolution ocean simulations, each spanning 19 compute nodes, all\ncommunicating with the same ML architecture at each simulation timestep. In\ntotal, 970 billion inferences are collectively served by running the ensemble\nfor a total of 120 simulated years. Finally, we show our solution is stable\nover the full duration of the model integrations, and that the inclusion of\nmachine learning has minimal impact on the simulation runtimes.\n", "versions": [{"version": "v1", "created": "Tue, 13 Apr 2021 19:27:28 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Partee", "Sam", ""], ["Ellis", "Matthew", ""], ["Rigazzi", "Alessandro", ""], ["Bachman", "Scott", ""], ["Marques", "Gustavo", ""], ["Shao", "Andrew", ""], ["Robbins", "Benjamin", ""]]}, {"id": "2104.09356", "submitter": "Saturnino Luz", "authors": "Saturnino Luz, Fasih Haider, Sofia de la Fuente, Davida Fromm, Brian\n  MacWhinney", "title": "Detecting cognitive decline using speech only: The ADReSSo Challenge", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Building on the success of the ADReSS Challenge at Interspeech 2020, which\nattracted the participation of 34 teams from across the world, the ADReSSo\nChallenge targets three difficult automatic prediction problems of societal and\nmedical relevance, namely: detection of Alzheimer's Dementia, inference of\ncognitive testing scores, and prediction of cognitive decline. This paper\npresents these prediction tasks in detail, describes the datasets used, and\nreports the results of the baseline classification and regression models we\ndeveloped for each task. A combination of acoustic and linguistic features\nextracted directly from audio recordings, without human intervention, yielded a\nbaseline accuracy of 78.87% for the AD classification task, an MMSE prediction\nroot mean squared (RMSE) error of 5.28, and 68.75% accuracy for the cognitive\ndecline prediction task.\n", "versions": [{"version": "v1", "created": "Tue, 23 Mar 2021 01:09:38 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Luz", "Saturnino", ""], ["Haider", "Fasih", ""], ["de la Fuente", "Sofia", ""], ["Fromm", "Davida", ""], ["MacWhinney", "Brian", ""]]}, {"id": "2104.09369", "submitter": "Lyuyi Zhu", "authors": "Lyuyi Zhu, Kairui Feng, Ziyuan Pu, Wei Ma", "title": "Adversarial Diffusion Attacks on Graph-based Traffic Prediction Models", "comments": "Our code is available at\n  https://github.com/LYZ98/Adversarial-Diffusion-Attacks-on-Graph-based-Traffic-Prediction-Models", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Real-time traffic prediction models play a pivotal role in smart mobility\nsystems and have been widely used in route guidance, emerging mobility\nservices, and advanced traffic management systems. With the availability of\nmassive traffic data, neural network-based deep learning methods, especially\nthe graph convolutional networks (GCN) have demonstrated outstanding\nperformance in mining spatio-temporal information and achieving high prediction\naccuracy. Recent studies reveal the vulnerability of GCN under adversarial\nattacks, while there is a lack of studies to understand the vulnerability\nissues of the GCN-based traffic prediction models. Given this, this paper\nproposes a new task -- diffusion attack, to study the robustness of GCN-based\ntraffic prediction models. The diffusion attack aims to select and attack a\nsmall set of nodes to degrade the performance of the entire prediction model.\nTo conduct the diffusion attack, we propose a novel attack algorithm, which\nconsists of two major components: 1) approximating the gradient of the\nblack-box prediction model with Simultaneous Perturbation Stochastic\nApproximation (SPSA); 2) adapting the knapsack greedy algorithm to select the\nattack nodes. The proposed algorithm is examined with three GCN-based traffic\nprediction models: St-Gcn, T-Gcn, and A3t-Gcn on two cities. The proposed\nalgorithm demonstrates high efficiency in the adversarial attack tasks under\nvarious scenarios, and it can still generate adversarial samples under the drop\nregularization such as DropOut, DropNode, and DropEdge. The research outcomes\ncould help to improve the robustness of the GCN-based traffic prediction models\nand better protect the smart mobility systems. Our code is available at\nhttps://github.com/LYZ98/Adversarial-Diffusion-Attacks-on-Graph-based-Traffic-Prediction-Models\n", "versions": [{"version": "v1", "created": "Mon, 19 Apr 2021 14:57:25 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Zhu", "Lyuyi", ""], ["Feng", "Kairui", ""], ["Pu", "Ziyuan", ""], ["Ma", "Wei", ""]]}, {"id": "2104.09371", "submitter": "Aniruddha Rajendra Rao", "authors": "Aniruddha Rajendra Rao and Matthew Reimherr", "title": "Non-linear Functional Modeling using Neural Networks", "comments": "3 figures, 8 tables (including supplementary material), 13 pages\n  (including supplementary material)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ME stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We introduce a new class of non-linear models for functional data based on\nneural networks. Deep learning has been very successful in non-linear modeling,\nbut there has been little work done in the functional data setting. We propose\ntwo variations of our framework: a functional neural network with continuous\nhidden layers, called the Functional Direct Neural Network (FDNN), and a second\nversion that utilizes basis expansions and continuous hidden layers, called the\nFunctional Basis Neural Network (FBNN). Both are designed explicitly to exploit\nthe structure inherent in functional data. To fit these models we derive a\nfunctional gradient based optimization algorithm. The effectiveness of the\nproposed methods in handling complex functional models is demonstrated by\ncomprehensive simulation studies and real data examples.\n", "versions": [{"version": "v1", "created": "Mon, 19 Apr 2021 14:59:55 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Rao", "Aniruddha Rajendra", ""], ["Reimherr", "Matthew", ""]]}, {"id": "2104.09376", "submitter": "Chuxiong Sun", "authors": "Chuxiong Sun, Hongming Gu, Jie Hu", "title": "Scalable and Adaptive Graph Neural Networks with Self-Label-Enhanced\n  training", "comments": "23 pages, 13 figures, fixed typos, add authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is hard to directly implement Graph Neural Networks (GNNs) on large scaled\ngraphs. Besides of existed neighbor sampling techniques, scalable methods\ndecoupling graph convolutions and other learnable transformations into\npreprocessing and post classifier allow normal minibatch training. By replacing\nredundant concatenation operation with attention mechanism in SIGN, we propose\nScalable and Adaptive Graph Neural Networks (SAGN). SAGN can adaptively gather\nneighborhood information among different hops. To further improve scalable\nmodels on semi-supervised learning tasks, we propose Self-Label-Enhance (SLE)\nframework combining self-training approach and label propagation in depth. We\nadd base model with a scalable node label module. Then we iteratively train\nmodels and enhance train set in several stages. To generate input of node label\nmodule, we directly apply label propagation based on one-hot encoded label\nvectors without inner random masking. We find out that empirically the label\nleakage has been effectively alleviated after graph convolutions. The hard\npseudo labels in enhanced train set participate in label propagation with true\nlabels. Experiments on both inductive and transductive datasets demonstrate\nthat, compared with other sampling-based and sampling-free methods, SAGN\nachieves better or comparable results and SLE can further improve performance.\n", "versions": [{"version": "v1", "created": "Mon, 19 Apr 2021 15:08:06 GMT"}, {"version": "v2", "created": "Thu, 29 Apr 2021 07:18:50 GMT"}, {"version": "v3", "created": "Thu, 1 Jul 2021 10:08:16 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Sun", "Chuxiong", ""], ["Gu", "Hongming", ""], ["Hu", "Jie", ""]]}, {"id": "2104.09379", "submitter": "Yihang Yin", "authors": "Yihang Yin, Siyu Huang, Xiang Zhang, Dejing Dou", "title": "BM-NAS: Bilevel Multimodal Neural Architecture Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) have shown superior performances on various\nmultimodal learning problems. However, it often requires huge efforts to adapt\nDNNs to individual multimodal tasks by manually engineering unimodal features\nand designing multimodal feature fusion strategies. This paper proposes Bilevel\nMultimodal Neural Architecture Search (BM-NAS) framework, which makes the\narchitecture of multimodal fusion models fully searchable via a bilevel\nsearching scheme. At the upper level, BM-NAS selects the inter/intra-modal\nfeature pairs from the pretrained unimodal backbones. At the lower level,\nBM-NAS learns the fusion strategy for each feature pair, which is a combination\nof predefined primitive operations. The primitive operations are elaborately\ndesigned and they can be flexibly combined to accommodate various effective\nfeature fusion modules such as multi-head attention (Transformer) and Attention\non Attention (AoA). Experimental results on three multimodal tasks demonstrate\nthe effectiveness and efficiency of the proposed BM-NAS framework. BM-NAS\nachieves competitive performances with much less search time and fewer model\nparameters in comparison with the existing generalized multimodal NAS methods.\n", "versions": [{"version": "v1", "created": "Mon, 19 Apr 2021 15:09:49 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Yin", "Yihang", ""], ["Huang", "Siyu", ""], ["Zhang", "Xiang", ""], ["Dou", "Dejing", ""]]}, {"id": "2104.09382", "submitter": "Bo Yang", "authors": "Bo Yang, Omobayode Fagbohungbe, Xuelin Cao, Chau Yuen, Lijun Qian,\n  Dusit Niyato, and Yan Zhang", "title": "A Joint Energy and Latency Framework for Transfer Learning over 5G\n  Industrial Edge Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a transfer learning (TL)-enabled edge-CNN framework\nfor 5G industrial edge networks with privacy-preserving characteristic. In\nparticular, the edge server can use the existing image dataset to train the CNN\nin advance, which is further fine-tuned based on the limited datasets uploaded\nfrom the devices. With the aid of TL, the devices that are not participating in\nthe training only need to fine-tune the trained edge-CNN model without training\nfrom scratch. Due to the energy budget of the devices and the limited\ncommunication bandwidth, a joint energy and latency problem is formulated,\nwhich is solved by decomposing the original problem into an uploading decision\nsubproblem and a wireless bandwidth allocation subproblem. Experiments using\nImageNet demonstrate that the proposed TL-enabled edge-CNN framework can\nachieve almost 85% prediction accuracy of the baseline by uploading only about\n1% model parameters, for a compression ratio of 32 of the autoencoder.\n", "versions": [{"version": "v1", "created": "Mon, 19 Apr 2021 15:13:16 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Yang", "Bo", ""], ["Fagbohungbe", "Omobayode", ""], ["Cao", "Xuelin", ""], ["Yuen", "Chau", ""], ["Qian", "Lijun", ""], ["Niyato", "Dusit", ""], ["Zhang", "Yan", ""]]}, {"id": "2104.09393", "submitter": "Bhaskar Mitra", "authors": "Bhaskar Mitra, Sebastian Hofstatter, Hamed Zamani and Nick Craswell", "title": "Improving Transformer-Kernel Ranking Model Using Conformer and Query\n  Term Independence", "comments": "arXiv admin note: substantial text overlap with arXiv:2007.10434", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Transformer-Kernel (TK) model has demonstrated strong reranking\nperformance on the TREC Deep Learning benchmark -- and can be considered to be\nan efficient (but slightly less effective) alternative to other\nTransformer-based architectures that employ (i) large-scale pretraining (high\ntraining cost), (ii) joint encoding of query and document (high inference\ncost), and (iii) larger number of Transformer layers (both high training and\nhigh inference costs). Since, a variant of the TK model -- called TKL -- has\nbeen developed that incorporates local self-attention to efficiently process\nlonger input sequences in the context of document ranking. In this work, we\npropose a novel Conformer layer as an alternative approach to scale TK to\nlonger input sequences. Furthermore, we incorporate query term independence and\nexplicit term matching to extend the model to the full retrieval setting. We\nbenchmark our models under the strictly blind evaluation setting of the TREC\n2020 Deep Learning track and find that our proposed architecture changes lead\nto improved retrieval quality over TKL. Our best model also outperforms all\nnon-neural runs (\"trad\") and two-thirds of the pretrained Transformer-based\nruns (\"nnlm\") on NDCG@10.\n", "versions": [{"version": "v1", "created": "Mon, 19 Apr 2021 15:32:34 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Mitra", "Bhaskar", ""], ["Hofstatter", "Sebastian", ""], ["Zamani", "Hamed", ""], ["Craswell", "Nick", ""]]}, {"id": "2104.09395", "submitter": "Li Wang", "authors": "Marta Li Wang", "title": "Algoritmos de miner\\'ia de datos en la industria sanitaria", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  In this paper, we review data mining approaches for health applications. Our\nfocus is on hardware-centric approaches. Modern computers consist of multiple\nprocessors, each equipped with multiple cores, each with a set of\narithmetic/logical units. Thus, a modern computer may be composed of several\nthousand units capable of doing arithmetic operations like addition and\nmultiplication. Graphic processors, in addition may offer some thousand such\nunits. In both cases, single instruction multiple data and multiple instruction\nmultiple data parallelism must be exploited. We review the principles of\nalgorithms which exploit this parallelism and focus also on the memory issues\nwhen multiple processing units access main memory through caches. This is\nimportant for many applications of health, such as ECG, EEG, CT, SPECT, fMRI,\nDTI, ultrasound, microscopy, dermascopy, etc.\n", "versions": [{"version": "v1", "created": "Mon, 19 Apr 2021 15:36:13 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Wang", "Marta Li", ""]]}, {"id": "2104.09396", "submitter": "Saurav Jha", "authors": "Saurav Jha, Martin Schiemer, Franco Zambonelli and Juan Ye", "title": "Continual Learning in Sensor-based Human Activity Recognition: an\n  Empirical Benchmark Analysis", "comments": "Accepted in the Information Sciences journal", "journal-ref": null, "doi": "10.1016/j.ins.2021.04.062", "report-no": null, "categories": "eess.SP cs.HC cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Sensor-based human activity recognition (HAR), i.e., the ability to discover\nhuman daily activity patterns from wearable or embedded sensors, is a key\nenabler for many real-world applications in smart homes, personal healthcare,\nand urban planning. However, with an increasing number of applications being\ndeployed, an important question arises: how can a HAR system autonomously learn\nnew activities over a long period of time without being re-engineered from\nscratch? This problem is known as continual learning and has been particularly\npopular in the domain of computer vision, where several techniques to attack it\nhave been developed. This paper aims to assess to what extent such continual\nlearning techniques can be applied to the HAR domain. To this end, we propose a\ngeneral framework to evaluate the performance of such techniques on various\ntypes of commonly used HAR datasets. We then present a comprehensive empirical\nanalysis of their computational cost and effectiveness of tackling HAR-specific\nchallenges (i.e., sensor noise and labels' scarcity). The presented results\nuncover useful insights on their applicability and suggest future research\ndirections for HAR systems. Our code, models and data are available at\nhttps://github.com/srvCodes/continual-learning-benchmark.\n", "versions": [{"version": "v1", "created": "Mon, 19 Apr 2021 15:38:22 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Jha", "Saurav", ""], ["Schiemer", "Martin", ""], ["Zambonelli", "Franco", ""], ["Ye", "Juan", ""]]}, {"id": "2104.09399", "submitter": "Bhaskar Mitra", "authors": "Nick Craswell, Bhaskar Mitra, Emine Yilmaz, Daniel Campos, Ellen M.\n  Voorhees and Ian Soboroff", "title": "TREC Deep Learning Track: Reusable Test Collections in the Large Data\n  Regime", "comments": "arXiv admin note: text overlap with arXiv:2003.07820", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The TREC Deep Learning (DL) Track studies ad hoc search in the large data\nregime, meaning that a large set of human-labeled training data is available.\nResults so far indicate that the best models with large data may be deep neural\nnetworks. This paper supports the reuse of the TREC DL test collections in\nthree ways. First we describe the data sets in detail, documenting clearly and\nin one place some details that are otherwise scattered in track guidelines,\noverview papers and in our associated MS MARCO leaderboard pages. We intend\nthis description to make it easy for newcomers to use the TREC DL data. Second,\nbecause there is some risk of iteration and selection bias when reusing a data\nset, we describe the best practices for writing a paper using TREC DL data,\nwithout overfitting. We provide some illustrative analysis. Finally we address\na number of issues around the TREC DL data, including an analysis of\nreusability.\n", "versions": [{"version": "v1", "created": "Mon, 19 Apr 2021 15:41:28 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Craswell", "Nick", ""], ["Mitra", "Bhaskar", ""], ["Yilmaz", "Emine", ""], ["Campos", "Daniel", ""], ["Voorhees", "Ellen M.", ""], ["Soboroff", "Ian", ""]]}, {"id": "2104.09402", "submitter": "Wenling Shang", "authors": "Wenling Shang, Lasse Espeholt, Anton Raichuk, Tim Salimans", "title": "Agent-Centric Representations for Multi-Agent Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Object-centric representations have recently enabled significant progress in\ntackling relational reasoning tasks. By building a strong object-centric\ninductive bias into neural architectures, recent efforts have improved\ngeneralization and data efficiency of machine learning algorithms for these\nproblems. One problem class involving relational reasoning that still remains\nunder-explored is multi-agent reinforcement learning (MARL). Here we\ninvestigate whether object-centric representations are also beneficial in the\nfully cooperative MARL setting. Specifically, we study two ways of\nincorporating an agent-centric inductive bias into our RL algorithm: 1.\nIntroducing an agent-centric attention module with explicit connections across\nagents 2. Adding an agent-centric unsupervised predictive objective (i.e. not\nusing action labels), to be used as an auxiliary loss for MARL, or as the basis\nof a pre-training step. We evaluate these approaches on the Google Research\nFootball environment as well as DeepMind Lab 2D. Empirically, agent-centric\nrepresentation learning leads to the emergence of more complex cooperation\nstrategies between agents as well as enhanced sample efficiency and\ngeneralization.\n", "versions": [{"version": "v1", "created": "Mon, 19 Apr 2021 15:43:40 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Shang", "Wenling", ""], ["Espeholt", "Lasse", ""], ["Raichuk", "Anton", ""], ["Salimans", "Tim", ""]]}, {"id": "2104.09420", "submitter": "Xiao Liu", "authors": "Xiao Liu, Da Yin, Yansong Feng, Yuting Wu, Dongyan Zhao", "title": "Everything Has a Cause: Leveraging Causal Inference in Legal Text\n  Analysis", "comments": "Accepted by NAACL 2021. Code is available at\n  https://github.com/xxxiaol/GCI", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Causal inference is the process of capturing cause-effect relationship among\nvariables. Most existing works focus on dealing with structured data, while\nmining causal relationship among factors from unstructured data, like text, has\nbeen less examined, but is of great importance, especially in the legal domain.\n  In this paper, we propose a novel Graph-based Causal Inference (GCI)\nframework, which builds causal graphs from fact descriptions without much human\ninvolvement and enables causal inference to facilitate legal practitioners to\nmake proper decisions. We evaluate the framework on a challenging similar\ncharge disambiguation task. Experimental results show that GCI can capture the\nnuance from fact descriptions among multiple confusing charges and provide\nexplainable discrimination, especially in few-shot settings. We also observe\nthat the causal knowledge contained in GCI can be effectively injected into\npowerful neural networks for better performance and interpretability.\n", "versions": [{"version": "v1", "created": "Mon, 19 Apr 2021 16:13:10 GMT"}, {"version": "v2", "created": "Wed, 21 Apr 2021 07:33:20 GMT"}], "update_date": "2021-04-22", "authors_parsed": [["Liu", "Xiao", ""], ["Yin", "Da", ""], ["Feng", "Yansong", ""], ["Wu", "Yuting", ""], ["Zhao", "Dongyan", ""]]}, {"id": "2104.09425", "submitter": "Vikash Sehwag", "authors": "Vikash Sehwag, Saeed Mahloujifar, Tinashe Handina, Sihui Dai, Chong\n  Xiang, Mung Chiang, Prateek Mittal", "title": "Improving Adversarial Robustness Using Proxy Distributions", "comments": "24 pages, 5 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We focus on the use of proxy distributions, i.e., approximations of the\nunderlying distribution of the training dataset, in both understanding and\nimproving the adversarial robustness in image classification. While additional\ntraining data helps in adversarial training, curating a very large number of\nreal-world images is challenging. In contrast, proxy distributions enable us to\nsample a potentially unlimited number of images and improve adversarial\nrobustness using these samples. We first ask the question: when does\nadversarial robustness benefit from incorporating additional samples from the\nproxy distribution in the training stage? We prove that the difference between\nthe robustness of a classifier on the proxy and original training dataset\ndistribution is upper bounded by the conditional Wasserstein distance between\nthem. Our result confirms the intuition that samples from a proxy distribution\nthat closely approximates training dataset distribution should be able to boost\nadversarial robustness. Motivated by this finding, we leverage samples from\nstate-of-the-art generative models, which can closely approximate training data\ndistribution, to improve robustness. In particular, we improve robust accuracy\nby up to 6.1% and 5.7% in $l_{\\infty}$ and $l_2$ threat model, and certified\nrobust accuracy by 6.7% over baselines not using proxy distributions on the\nCIFAR-10 dataset. Since we can sample an unlimited number of images from a\nproxy distribution, it also allows us to investigate the effect of an\nincreasing number of training samples on adversarial robustness. Here we\nprovide the first large scale empirical investigation of accuracy vs robustness\ntrade-off and sample complexity of adversarial training by training deep neural\nnetworks on 2K to 10M images.\n", "versions": [{"version": "v1", "created": "Mon, 19 Apr 2021 16:17:12 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Sehwag", "Vikash", ""], ["Mahloujifar", "Saeed", ""], ["Handina", "Tinashe", ""], ["Dai", "Sihui", ""], ["Xiang", "Chong", ""], ["Chiang", "Mung", ""], ["Mittal", "Prateek", ""]]}, {"id": "2104.09428", "submitter": "Jamal Al Qundus", "authors": "Jamal Al Qundus, Silvio Peikert, Adrian Paschke", "title": "AI supported Topic Modeling using KNIME-Workflows", "comments": "7 pages, 7 figures. Qurator2020 - Conference on Digital Curation\n  Technologies", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Topic modeling algorithms traditionally model topics as list of weighted\nterms. These topic models can be used effectively to classify texts or to\nsupport text mining tasks such as text summarization or fact extraction. The\ngeneral procedure relies on statistical analysis of term frequencies. The focus\nof this work is on the implementation of the knowledge-based topic modelling\nservices in a KNIME workflow. A brief description and evaluation of the\nDBPedia-based enrichment approach and the comparative evaluation of enriched\ntopic models will be outlined based on our previous work. DBpedia-Spotlight is\nused to identify entities in the input text and information from DBpedia is\nused to extend these entities. We provide a workflow developed in KNIME\nimplementing this approach and perform a result comparison of topic modeling\nsupported by knowledge base information to traditional LDA. This topic modeling\napproach allows semantic interpretation both by algorithms and by humans.\n", "versions": [{"version": "v1", "created": "Thu, 15 Apr 2021 10:19:58 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Qundus", "Jamal Al", ""], ["Peikert", "Silvio", ""], ["Paschke", "Adrian", ""]]}, {"id": "2104.09435", "submitter": "Jong Chul Ye", "authors": "Hyoungjun Park, Myeongsu Na, Bumju Kim, Soohyun Park, Ki Hean Kim,\n  Sunghoe Chang, and Jong Chul Ye", "title": "Deep learning enables reference-free isotropic super-resolution for\n  volumetric fluorescence microscopy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Volumetric imaging by fluorescence microscopy is often limited by anisotropic\nspatial resolution from inferior axial resolution compared to the lateral\nresolution. To address this problem, here we present a deep-learning-enabled\nunsupervised super-resolution technique that enhances anisotropic images in\nvolumetric fluorescence microscopy. In contrast to the existing deep learning\napproaches that require matched high-resolution target volume images, our\nmethod greatly reduces the effort to put into practice as the training of a\nnetwork requires as little as a single 3D image stack, without a priori\nknowledge of the image formation process, registration of training data, or\nseparate acquisition of target data. This is achieved based on the optimal\ntransport driven cycle-consistent generative adversarial network that learns\nfrom an unpaired matching between high-resolution 2D images in lateral image\nplane and low-resolution 2D images in the other planes. Using fluorescence\nconfocal microscopy and light-sheet microscopy, we demonstrate that the trained\nnetwork not only enhances axial resolution, but also restores suppressed visual\ndetails between the imaging planes and removes imaging artifacts.\n", "versions": [{"version": "v1", "created": "Mon, 19 Apr 2021 16:31:12 GMT"}, {"version": "v2", "created": "Mon, 7 Jun 2021 02:45:47 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Park", "Hyoungjun", ""], ["Na", "Myeongsu", ""], ["Kim", "Bumju", ""], ["Park", "Soohyun", ""], ["Kim", "Ki Hean", ""], ["Chang", "Sunghoe", ""], ["Ye", "Jong Chul", ""]]}, {"id": "2104.09437", "submitter": "Quanquan Gu", "authors": "Difan Zou and Spencer Frei and Quanquan Gu", "title": "Provable Robustness of Adversarial Training for Learning Halfspaces with\n  Noise", "comments": "42 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyze the properties of adversarial training for learning adversarially\nrobust halfspaces in the presence of agnostic label noise. Denoting\n$\\mathsf{OPT}_{p,r}$ as the best robust classification error achieved by a\nhalfspace that is robust to perturbations of $\\ell_{p}$ balls of radius $r$, we\nshow that adversarial training on the standard binary cross-entropy loss yields\nadversarially robust halfspaces up to (robust) classification error $\\tilde\nO(\\sqrt{\\mathsf{OPT}_{2,r}})$ for $p=2$, and $\\tilde O(d^{1/4}\n\\sqrt{\\mathsf{OPT}_{\\infty, r}} + d^{1/2} \\mathsf{OPT}_{\\infty,r})$ when\n$p=\\infty$. Our results hold for distributions satisfying anti-concentration\nproperties enjoyed by log-concave isotropic distributions among others. We\nadditionally show that if one instead uses a nonconvex sigmoidal loss,\nadversarial training yields halfspaces with an improved robust classification\nerror of $O(\\mathsf{OPT}_{2,r})$ for $p=2$, and $O(d^{1/4}\\mathsf{OPT}_{\\infty,\nr})$ when $p=\\infty$. To the best of our knowledge, this is the first work to\nshow that adversarial training provably yields robust classifiers in the\npresence of noise.\n", "versions": [{"version": "v1", "created": "Mon, 19 Apr 2021 16:35:38 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Zou", "Difan", ""], ["Frei", "Spencer", ""], ["Gu", "Quanquan", ""]]}, {"id": "2104.09439", "submitter": "Rajesh N Rao", "authors": "Rajesh N Rao, Manojit Chakraborty", "title": "Vec2GC -- A Graph Based Clustering Method for Text Representations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  NLP pipelines with limited or no labeled data, rely on unsupervised methods\nfor document processing. Unsupervised approaches typically depend on clustering\nof terms or documents. In this paper, we introduce a novel clustering\nalgorithm, Vec2GC (Vector to Graph Communities), an end-to-end pipeline to\ncluster terms or documents for any given text corpus. Our method uses community\ndetection on a weighted graph of the terms or documents, created using text\nrepresentation learning. Vec2GC clustering algorithm is a density based\napproach, that supports hierarchical clustering as well.\n", "versions": [{"version": "v1", "created": "Thu, 15 Apr 2021 12:52:30 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Rao", "Rajesh N", ""], ["Chakraborty", "Manojit", ""]]}, {"id": "2104.09452", "submitter": "Vincent Pisztora", "authors": "Vincent Pisztora, Yanglan Ou, Xiaolei Huang, Francesca Chiaromonte,\n  Jia Li", "title": "Epsilon Consistent Mixup: An Adaptive Consistency-Interpolation Tradeoff", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose $\\epsilon$-Consistent Mixup ($\\epsilon$mu).\n$\\epsilon$mu is a data-based structural regularization technique that combines\nMixup's linear interpolation with consistency regularization in the Mixup\ndirection, by compelling a simple adaptive tradeoff between the two. This\nlearnable combination of consistency and interpolation induces a more flexible\nstructure on the evolution of the response across the feature space and is\nshown to improve semi-supervised classification accuracy on the SVHN and\nCIFAR10 benchmark datasets, yielding the largest gains in the most challenging\nlow label-availability scenarios. Empirical studies comparing $\\epsilon$mu and\nMixup are presented and provide insight into the mechanisms behind\n$\\epsilon$mu's effectiveness. In particular, $\\epsilon$mu is found to produce\nmore accurate synthetic labels and more confident predictions than Mixup.\n", "versions": [{"version": "v1", "created": "Mon, 19 Apr 2021 17:10:31 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Pisztora", "Vincent", ""], ["Ou", "Yanglan", ""], ["Huang", "Xiaolei", ""], ["Chiaromonte", "Francesca", ""], ["Li", "Jia", ""]]}, {"id": "2104.09455", "submitter": "Jack Kosaian", "authors": "Jack Kosaian, K. V. Rashmi", "title": "Arithmetic-Intensity-Guided Fault Tolerance for Neural Network Inference\n  on GPUs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks (NNs) are increasingly employed in domains that require high\nreliability, such as scientific computing and safety-critical systems, as well\nas in environments more prone to unreliability (e.g., soft errors), such as on\nspacecraft. As recent work has shown that faults in NN inference can lead to\nmispredictions and safety hazards, it is critical to impart fault tolerance to\nNN inference. Algorithm-based fault tolerance (ABFT) is emerging as an\nappealing approach for efficient fault tolerance in NNs.\n  In this work, we identify new, unexploited opportunities for low-overhead\nABFT for NN inference: current inference-optimized GPUs have high\ncompute-to-memory-bandwidth ratios, while many layers of current and emerging\nNNs have low arithmetic intensity. This leaves many convolutional and\nfully-connected layers in NNs memory-bandwidth-bound. These layers thus exhibit\nstalls in computation that could be filled by redundant execution, but that\ncurrent approaches to ABFT for NN inference cannot exploit.\n  To reduce execution-time overhead for such memory-bandwidth-bound layers, we\nfirst investigate thread-level ABFT schemes for inference-optimized GPUs that\nexploit this fine-grained compute underutilization. We then propose\nintensity-guided ABFT, an adaptive, arithmetic-intensity-guided approach to\nABFT that selects the best ABFT scheme for each individual layer between\ntraditional approaches to ABFT, which are suitable for compute-bound layers,\nand thread-level ABFT, which is suitable for memory-bandwidth-bound layers.\nThrough this adaptive approach, intensity-guided ABFT reduces execution-time\noverhead by 1.09--5.3$\\times$ across a variety of NNs, lowering the cost of\nfault tolerance for current and future NN inference workloads.\n", "versions": [{"version": "v1", "created": "Mon, 19 Apr 2021 17:13:04 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Kosaian", "Jack", ""], ["Rashmi", "K. V.", ""]]}, {"id": "2104.09459", "submitter": "Andrew Wilson", "authors": "Marc Finzi, Max Welling, Andrew Gordon Wilson", "title": "A Practical Method for Constructing Equivariant Multilayer Perceptrons\n  for Arbitrary Matrix Groups", "comments": "Library: https://github.com/mfinzi/equivariant-MLP, Documentation:\n  https://emlp.readthedocs.io/en/latest/, Examples:\n  https://colab.research.google.com/github/mfinzi/equivariant-MLP/blob/master/docs/notebooks/colabs/all.ipynb", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Symmetries and equivariance are fundamental to the generalization of neural\nnetworks on domains such as images, graphs, and point clouds. Existing work has\nprimarily focused on a small number of groups, such as the translation,\nrotation, and permutation groups. In this work we provide a completely general\nalgorithm for solving for the equivariant layers of matrix groups. In addition\nto recovering solutions from other works as special cases, we construct\nmultilayer perceptrons equivariant to multiple groups that have never been\ntackled before, including $\\mathrm{O}(1,3)$, $\\mathrm{O}(5)$, $\\mathrm{Sp}(n)$,\nand the Rubik's cube group. Our approach outperforms non-equivariant baselines,\nwith applications to particle physics and dynamical systems. We release our\nsoftware library to enable researchers to construct equivariant layers for\narbitrary matrix groups.\n", "versions": [{"version": "v1", "created": "Mon, 19 Apr 2021 17:21:54 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Finzi", "Marc", ""], ["Welling", "Max", ""], ["Wilson", "Andrew Gordon", ""]]}, {"id": "2104.09460", "submitter": "Willie Neiswanger", "authors": "Willie Neiswanger, Ke Alexander Wang, Stefano Ermon", "title": "Bayesian Algorithm Execution: Estimating Computable Properties of\n  Black-box Functions Using Mutual Information", "comments": "Appears in Proceedings of the 38th International Conference on\n  Machine Learning (ICML), 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.IT cs.LG cs.NE math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many real-world problems, we want to infer some property of an expensive\nblack-box function $f$, given a budget of $T$ function evaluations. One example\nis budget constrained global optimization of $f$, for which Bayesian\noptimization is a popular method. Other properties of interest include local\noptima, level sets, integrals, or graph-structured information induced by $f$.\nOften, we can find an algorithm $\\mathcal{A}$ to compute the desired property,\nbut it may require far more than $T$ queries to execute. Given such an\n$\\mathcal{A}$, and a prior distribution over $f$, we refer to the problem of\ninferring the output of $\\mathcal{A}$ using $T$ evaluations as Bayesian\nAlgorithm Execution (BAX). To tackle this problem, we present a procedure,\nInfoBAX, that sequentially chooses queries that maximize mutual information\nwith respect to the algorithm's output. Applying this to Dijkstra's algorithm,\nfor instance, we infer shortest paths in synthetic and real-world graphs with\nblack-box edge costs. Using evolution strategies, we yield variants of Bayesian\noptimization that target local, rather than global, optima. On these problems,\nInfoBAX uses up to 500 times fewer queries to $f$ than required by the original\nalgorithm. Our method is closely connected to other Bayesian optimal\nexperimental design procedures such as entropy search methods and optimal\nsensor placement using Gaussian processes.\n", "versions": [{"version": "v1", "created": "Mon, 19 Apr 2021 17:22:11 GMT"}, {"version": "v2", "created": "Tue, 6 Jul 2021 17:56:46 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Neiswanger", "Willie", ""], ["Wang", "Ke Alexander", ""], ["Ermon", "Stefano", ""]]}, {"id": "2104.09469", "submitter": "Spencer Frazier", "authors": "Md Sultan Al Nahian, Spencer Frazier, Brent Harrison, Mark Riedl", "title": "Training Value-Aligned Reinforcement Learning Agents Using a Normative\n  Prior", "comments": "(Nahian and Frazier contributed equally to this work)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.HC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  As more machine learning agents interact with humans, it is increasingly a\nprospect that an agent trained to perform a task optimally, using only a\nmeasure of task performance as feedback, can violate societal norms for\nacceptable behavior or cause harm. Value alignment is a property of intelligent\nagents wherein they solely pursue non-harmful behaviors or human-beneficial\ngoals. We introduce an approach to value-aligned reinforcement learning, in\nwhich we train an agent with two reward signals: a standard task performance\nreward, plus a normative behavior reward. The normative behavior reward is\nderived from a value-aligned prior model previously shown to classify text as\nnormative or non-normative. We show how variations on a policy shaping\ntechnique can balance these two sources of reward and produce policies that are\nboth effective and perceived as being more normative. We test our\nvalue-alignment technique on three interactive text-based worlds; each world is\ndesigned specifically to challenge agents with a task as well as provide\nopportunities to deviate from the task to engage in normative and/or altruistic\nbehavior.\n", "versions": [{"version": "v1", "created": "Mon, 19 Apr 2021 17:33:07 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Nahian", "Md Sultan Al", ""], ["Frazier", "Spencer", ""], ["Harrison", "Brent", ""], ["Riedl", "Mark", ""]]}, {"id": "2104.09476", "submitter": "Andrea Pallavicini Mr", "authors": "Damiano Brigo, Xiaoshan Huang, Andrea Pallavicini, Haitz Saez de\n  Ocariz Borde", "title": "Interpretability in deep learning for finance: a case study for the\n  Heston model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.PR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning is a powerful tool whose applications in quantitative finance\nare growing every day. Yet, artificial neural networks behave as black boxes\nand this hinders validation and accountability processes. Being able to\ninterpret the inner functioning and the input-output relationship of these\nnetworks has become key for the acceptance of such tools. In this paper we\nfocus on the calibration process of a stochastic volatility model, a subject\nrecently tackled by deep learning algorithms. We analyze the Heston model in\nparticular, as this model's properties are well known, resulting in an ideal\nbenchmark case. We investigate the capability of local strategies and global\nstrategies coming from cooperative game theory to explain the trained neural\nnetworks, and we find that global strategies such as Shapley values can be\neffectively used in practice. Our analysis also highlights that Shapley values\nmay help choose the network architecture, as we find that fully-connected\nneural networks perform better than convolutional neural networks in predicting\nand interpreting the Heston model prices to parameters relationship.\n", "versions": [{"version": "v1", "created": "Mon, 19 Apr 2021 17:37:17 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Brigo", "Damiano", ""], ["Huang", "Xiaoshan", ""], ["Pallavicini", "Andrea", ""], ["Borde", "Haitz Saez de Ocariz", ""]]}, {"id": "2104.09493", "submitter": "Megh Shukla", "authors": "Megh Shukla", "title": "EGL++: Extending Expected Gradient Length to Active Learning for Human\n  Pose Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  State of the art human pose estimation models continue to rely on large\nquantities of labelled data for robust performance. Since labelling budget is\noften constrained, active learning algorithms are important in retaining the\noverall performance of the model at a lower cost. Although active learning has\nbeen well studied in literature, few techniques are reported for human pose\nestimation. In this paper, we theoretically derive expected gradient length for\nregression, and propose EGL++, a novel heuristic algorithm that extends\nexpected gradient length to tasks where discrete labels are not available. We\nachieve this by computing low dimensional representations of the original\nimages which are then used to form a neighborhood graph. We use this graph to:\n1) Obtain a set of neighbors for a given sample, with each neighbor iteratively\nassumed to represent the ground truth for gradient calculation 2) Quantify the\nprobability of each sample being a neighbor in the above set, facilitating the\nexpected gradient step. Such an approach allows us to provide an approximate\nsolution to the otherwise intractable task of integrating over the continuous\noutput domain. To validate EGL++, we use the same datasets (Leeds Sports Pose,\nMPII) and experimental design as suggested by previous literature, achieving\ncompetitive results in comparison to these methods.\n", "versions": [{"version": "v1", "created": "Mon, 19 Apr 2021 17:56:59 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Shukla", "Megh", ""]]}, {"id": "2104.09494", "submitter": "Gabriel Mittag", "authors": "Gabriel Mittag, Babak Naderi, Assmaa Chehadi, Sebastian M\\\"oller", "title": "NISQA: A Deep CNN-Self-Attention Model for Multidimensional Speech\n  Quality Prediction with Crowdsourced Datasets", "comments": "Submitted to Interspeech 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.AI cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present an update to the NISQA speech quality prediction\nmodel that is focused on distortions that occur in communication networks. In\ncontrast to the previous version, the model is trained end-to-end and the\ntime-dependency modelling and time-pooling is achieved through a Self-Attention\nmechanism. Besides overall speech quality, the model also predicts the four\nspeech quality dimensions Noisiness, Coloration, Discontinuity, and Loudness,\nand in this way gives more insight into the cause of a quality degradation.\nFurthermore, new datasets with over 13,000 speech files were created for\ntraining and validation of the model. The model was finally tested on a new,\nlive-talking test dataset that contains recordings of real telephone calls.\nOverall, NISQA was trained and evaluated on 81 datasets from different sources\nand showed to provide reliable predictions also for unknown speech samples. The\ncode, model weights, and datasets are open-sourced.\n", "versions": [{"version": "v1", "created": "Mon, 19 Apr 2021 17:56:59 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Mittag", "Gabriel", ""], ["Naderi", "Babak", ""], ["Chehadi", "Assmaa", ""], ["M\u00f6ller", "Sebastian", ""]]}, {"id": "2104.09498", "submitter": "Daniel Geng", "authors": "Daniel Geng, Andrew Owens", "title": "Comparing Correspondences: Video Prediction with Correspondence-wise\n  Losses", "comments": "Website at http://dangeng.github.io/CorrWiseLosses", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Today's image prediction methods struggle to change the locations of objects\nin a scene, producing blurry images that average over the many positions they\nmight occupy. In this paper, we propose a simple change to existing image\nsimilarity metrics that makes them more robust to positional errors: we match\nthe images using optical flow, then measure the visual similarity of\ncorresponding pixels. This change leads to crisper and more perceptually\naccurate predictions, and can be used with any image prediction network. We\napply our method to predicting future frames of a video, where it obtains\nstrong performance with simple, off-the-shelf architectures.\n", "versions": [{"version": "v1", "created": "Mon, 19 Apr 2021 17:59:29 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Geng", "Daniel", ""], ["Owens", "Andrew", ""]]}, {"id": "2104.09499", "submitter": "Yifeng Che", "authors": "Yifeng Che, Joseph Yurko, Koroush Shirvan", "title": "Machine learning-assisted surrogate construction for full-core fuel\n  performance analysis", "comments": "31 pages, 16 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurately predicting the behavior of a nuclear reactor requires multiphysics\nsimulation of coupled neutronics, thermal-hydraulics and fuel thermo-mechanics.\nThe fuel thermo-mechanical response provides essential information for\noperational limits and safety analysis. Traditionally, fuel performance\nanalysis is performed standalone, using calculated spatial-temporal power\ndistribution and thermal boundary conditions from the coupled\nneutronics-thermal-hydraulics simulation as input. Such one-way coupling is\nresult of the high cost induced by the full-core fuel performance analysis,\nwhich provides more realistic and accurate prediction of the core-wide response\nthan the \"peak rod\" analysis. It is therefore desirable to improve the\ncomputational efficiency of full-core fuel performance modeling by constructing\nfast-running surrogate, such that fuel performance modeling can be utilized in\nthe core reload design optimization. This work presents methodologies for\nfull-core surrogate construction based on several realistic equilibrium PWR\ncore designs. As a fast and conventional approach, look-up tables are only\neffective for certain fuel performance quantities of interest (QoIs). Several\nrepresentative machine-learning algorithms are introduced to capture the\ncomplicated physics for other fuel performance QoIs. Rule-based model is useful\nas a feature extraction technique to account for the spatial-temporal\ncomplexity of operating conditions. Constructed surrogates achieve at least ten\nthousand time acceleration with satisfying prediction accuracy. Current work\nlays foundation for tighter coupling of fuel performance modeling into the core\ndesign optimization framework. It also sets stage for full-core fuel\nperformance analysis with BISON where the computational cost becomes more\nburdensome.\n", "versions": [{"version": "v1", "created": "Sat, 17 Apr 2021 17:02:50 GMT"}], "update_date": "2021-04-21", "authors_parsed": [["Che", "Yifeng", ""], ["Yurko", "Joseph", ""], ["Shirvan", "Koroush", ""]]}, {"id": "2104.09500", "submitter": "Arthur Bra\\v{z}inskas", "authors": "Arthur Bra\\v{z}inskas, Mengwen Liu, Ramesh Nallapati, Sujith Ravi,\n  Markus Dreyer", "title": "Transductive Learning for Abstractive News Summarization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Pre-trained language models have recently advanced abstractive summarization.\nThese models are further fine-tuned on human-written references before summary\ngeneration in test time. In this work, we propose the first application of\ntransductive learning to summarization. In this paradigm, a model can learn\nfrom the test set's input before inference. To perform transduction, we propose\nto utilize input document summarizing sentences to construct references for\nlearning in test time. These sentences are often compressed and fused to form\nabstractive summaries and provide omitted details and additional context to the\nreader. We show that our approach yields state-of-the-art results on CNN/DM and\nNYT datasets. For instance, we achieve over 1 ROUGE-L point improvement on\nCNN/DM. Further, we show the benefits of transduction from older to more recent\nnews. Finally, through human and automatic evaluation, we show that our\nsummaries become more abstractive and coherent.\n", "versions": [{"version": "v1", "created": "Sat, 17 Apr 2021 17:33:12 GMT"}], "update_date": "2021-04-21", "authors_parsed": [["Bra\u017einskas", "Arthur", ""], ["Liu", "Mengwen", ""], ["Nallapati", "Ramesh", ""], ["Ravi", "Sujith", ""], ["Dreyer", "Markus", ""]]}, {"id": "2104.09554", "submitter": "Lior Vassertail", "authors": "Adi Haviv, Lior Vassertail and Omer Levy", "title": "Can Latent Alignments Improve Autoregressive Machine Translation?", "comments": "Accepted to NAACL 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Latent alignment objectives such as CTC and AXE significantly improve\nnon-autoregressive machine translation models. Can they improve autoregressive\nmodels as well? We explore the possibility of training autoregressive machine\ntranslation models with latent alignment objectives, and observe that, in\npractice, this approach results in degenerate models. We provide a theoretical\nexplanation for these empirical results, and prove that latent alignment\nobjectives are incompatible with teacher forcing.\n", "versions": [{"version": "v1", "created": "Mon, 19 Apr 2021 18:31:56 GMT"}], "update_date": "2021-04-21", "authors_parsed": [["Haviv", "Adi", ""], ["Vassertail", "Lior", ""], ["Levy", "Omer", ""]]}, {"id": "2104.09557", "submitter": "Dylan Cope", "authors": "Dylan Cope and Nandi Schoots", "title": "Learning to Communicate with Strangers via Channel Randomisation Methods", "comments": null, "journal-ref": "4th Workshop on Emergent Communication at NeurIPS 2020", "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We introduce two methods for improving the performance of agents meeting for\nthe first time to accomplish a communicative task. The methods are: (1)\n`message mutation' during the generation of the communication protocol; and (2)\nrandom permutations of the communication channel. These proposals are tested\nusing a simple two-player game involving a `teacher' who generates a\ncommunication protocol and sends a message, and a `student' who interprets the\nmessage. After training multiple agents via self-play we analyse the\nperformance of these agents when they are matched with a stranger, i.e. their\nzero-shot communication performance. We find that both message mutation and\nchannel permutation positively influence performance, and we discuss their\neffects.\n", "versions": [{"version": "v1", "created": "Mon, 19 Apr 2021 18:42:48 GMT"}], "update_date": "2021-04-21", "authors_parsed": [["Cope", "Dylan", ""], ["Schoots", "Nandi", ""]]}, {"id": "2104.09563", "submitter": "Romain Dupuis", "authors": "Madalina Ciortan, Romain Dupuis, Thomas Peel", "title": "A Framework using Contrastive Learning for Classification with Noisy\n  Labels", "comments": "22 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose a framework using contrastive learning as a pre-training task to\nperform image classification in the presence of noisy labels. Recent strategies\nsuch as pseudo-labeling, sample selection with Gaussian Mixture models,\nweighted supervised contrastive learning have been combined into a fine-tuning\nphase following the pre-training. This paper provides an extensive empirical\nstudy showing that a preliminary contrastive learning step brings a significant\ngain in performance when using different loss functions: non-robust, robust,\nand early-learning regularized. Our experiments performed on standard\nbenchmarks and real-world datasets demonstrate that: i) the contrastive\npre-training increases the robustness of any loss function to noisy labels and\nii) the additional fine-tuning phase can further improve accuracy but at the\ncost of additional complexity.\n", "versions": [{"version": "v1", "created": "Mon, 19 Apr 2021 18:51:22 GMT"}], "update_date": "2021-04-21", "authors_parsed": [["Ciortan", "Madalina", ""], ["Dupuis", "Romain", ""], ["Peel", "Thomas", ""]]}, {"id": "2104.09574", "submitter": "Pei Zhou", "authors": "Pei Zhou, Pegah Jandaghi, Bill Yuchen Lin, Justin Cho, Jay Pujara,\n  Xiang Ren", "title": "Probing Causal Common Sense in Dialogue Response Generation", "comments": "This article has been withdrawn by the authors. The submitted version\n  was an early draft that has errors in the results which renders the analysis\n  invalid", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Communication is a cooperative effort that requires reaching mutual\nunderstanding among the participants. Humans use commonsense reasoning\nimplicitly to produce natural and logically-coherent responses. As a step\ntowards fluid human-AI communication, we study if response generation (RG)\nmodels can emulate human reasoning process and use common sense to help produce\nbetter-quality responses. We aim to tackle two research questions: how to\nformalize conversational common sense and how to examine RG models capability\nto use common sense? We first propose a task, CEDAR: Causal common sEnse in\nDiAlogue Response generation, that concretizes common sense as textual\nexplanations for what might lead to the response and evaluates RG models\nbehavior by comparing the modeling loss given a valid explanation with an\ninvalid one. Then we introduce a process that automatically generates such\nexplanations and ask humans to verify them. Finally, we design two probing\nsettings for RG models targeting two reasoning capabilities using verified\nexplanations. We find that RG models have a hard time determining the logical\nvalidity of explanations but can identify grammatical naturalness of the\nexplanation easily.\n", "versions": [{"version": "v1", "created": "Mon, 19 Apr 2021 19:10:05 GMT"}, {"version": "v2", "created": "Wed, 21 Apr 2021 20:00:17 GMT"}], "update_date": "2021-04-23", "authors_parsed": [["Zhou", "Pei", ""], ["Jandaghi", "Pegah", ""], ["Lin", "Bill Yuchen", ""], ["Cho", "Justin", ""], ["Pujara", "Jay", ""], ["Ren", "Xiang", ""]]}, {"id": "2104.09576", "submitter": "Kartik Mehta", "authors": "Kartik Mehta, Ioana Oprea and Nikhil Rasiwasia", "title": "LaTeX-Numeric: Language-agnostic Text attribute eXtraction for\n  E-commerce Numeric Attributes", "comments": "NAACL 2021 Industry Track", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present LaTeX-Numeric - a high-precision fully-automated\nscalable framework for extracting E-commerce numeric attributes from product\ntext like product description. Most of the past work on attribute extraction is\nnot scalable as they rely on manually curated training data, either with or\nwithout the use of active learning. We rely on distant supervision for training\ndata generation, removing dependency on manual labels. One issue with distant\nsupervision is that it leads to incomplete training annotation due to missing\nattribute values while matching. We propose a multi-task learning architecture\nto deal with missing labels in the training data, leading to F1 improvement of\n9.2% for numeric attributes over single-task architecture. While multi-task\narchitecture benefits both numeric and non-numeric attributes, we present\nautomated techniques to further improve the numeric attributes extraction\nmodels. Numeric attributes require a list of units (or aliases) for better\nmatching with distant supervision. We propose an automated algorithm for alias\ncreation using product text and attribute values, leading to a 20.2% F1\nimprovement. Extensive experiments on real world dataset for 20 numeric\nattributes across 5 product categories and 3 English marketplaces show that\nLaTeX-Numeric achieves a high F1-score, without any manual intervention, making\nit suitable for practical applications. Finally, we show that the improvements\nare language-agnostic and LaTeX-Numeric achieves 13.9% F1 improvement for 3\nRomance languages.\n", "versions": [{"version": "v1", "created": "Mon, 19 Apr 2021 19:14:32 GMT"}, {"version": "v2", "created": "Fri, 23 Apr 2021 08:05:46 GMT"}], "update_date": "2021-04-26", "authors_parsed": [["Mehta", "Kartik", ""], ["Oprea", "Ioana", ""], ["Rasiwasia", "Nikhil", ""]]}, {"id": "2104.09582", "submitter": "Emilio Maddalena", "authors": "Paul Scharnhorst, Emilio T. Maddalena, Yuning Jiang, Colin N. Jones", "title": "Robust Uncertainty Bounds in Reproducing Kernel Hilbert Spaces: A Convex\n  Optimization Approach", "comments": "19 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let a labeled dataset be given with scattered samples and consider the\nhypothesis of the ground-truth belonging to the reproducing kernel Hilbert\nspace (RKHS) of a known positive-definite kernel. It is known that\nout-of-sample bounds can be established at unseen input locations, thus\nlimiting the risk associated with learning this function. We show how computing\ntight, finite-sample uncertainty bounds amounts to solving parametric\nquadratically constrained linear programs. In our setting, the outputs are\nassumed to be contaminated by bounded measurement noise that can otherwise\noriginate from any compactly supported distribution. No independence\nassumptions are made on the available data. Numerical experiments are presented\nto compare the present results with other closed-form alternatives.\n", "versions": [{"version": "v1", "created": "Mon, 19 Apr 2021 19:27:52 GMT"}, {"version": "v2", "created": "Wed, 21 Apr 2021 11:20:26 GMT"}], "update_date": "2021-04-22", "authors_parsed": [["Scharnhorst", "Paul", ""], ["Maddalena", "Emilio T.", ""], ["Jiang", "Yuning", ""], ["Jones", "Colin N.", ""]]}, {"id": "2104.09612", "submitter": "Ronal Singh", "authors": "Ronal Singh, Upol Ehsan, Marc Cheong, Mark O. Riedl, Tim Miller", "title": "LEx: A Framework for Operationalising Layers of Machine Learning\n  Explanations", "comments": "6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Several social factors impact how people respond to AI explanations used to\njustify AI decisions affecting them personally. In this position paper, we\ndefine a framework called the \\textit{layers of explanation} (LEx), a lens\nthrough which we can assess the appropriateness of different types of\nexplanations. The framework uses the notions of \\textit{sensitivity} (emotional\nresponsiveness) of features and the level of \\textit{stakes} (decision's\nconsequence) in a domain to determine whether different types of explanations\nare \\textit{appropriate} in a given context. We demonstrate how to use the\nframework to assess the appropriateness of different types of explanations in\ndifferent domains.\n", "versions": [{"version": "v1", "created": "Thu, 15 Apr 2021 23:31:04 GMT"}], "update_date": "2021-04-21", "authors_parsed": [["Singh", "Ronal", ""], ["Ehsan", "Upol", ""], ["Cheong", "Marc", ""], ["Riedl", "Mark O.", ""], ["Miller", "Tim", ""]]}, {"id": "2104.09620", "submitter": "Caleb Bowyer", "authors": "Caleb Bowyer", "title": "Predictor-Corrector(PC) Temporal Difference(TD) Learning (PCTD)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Using insight from numerical approximation of ODEs and the problem\nformulation and solution methodology of TD learning through a Galerkin\nrelaxation, I propose a new class of TD learning algorithms. After applying the\nimproved numerical methods, the parameter being approximated has a guaranteed\norder of magnitude reduction in the Taylor Series error of the solution to the\nODE for the parameter $\\theta(t)$ that is used in constructing the linearly\nparameterized value function. Predictor-Corrector Temporal Difference (PCTD) is\nwhat I call the translated discrete time Reinforcement Learning(RL) algorithm\nfrom the continuous time ODE using the theory of Stochastic Approximation(SA).\nBoth causal and non-causal implementations of the algorithm are provided, and\nsimulation results are listed for an infinite horizon task to compare the\noriginal TD(0) algorithm against both versions of PCTD(0).\n", "versions": [{"version": "v1", "created": "Thu, 15 Apr 2021 18:54:16 GMT"}], "update_date": "2021-04-21", "authors_parsed": [["Bowyer", "Caleb", ""]]}, {"id": "2104.09621", "submitter": "Karl Willis", "authors": "Karl D.D. Willis, Pradeep Kumar Jayaraman, Joseph G. Lambourne, Hang\n  Chu, Yewen Pu", "title": "Engineering Sketch Generation for Computer-Aided Design", "comments": "The 1st Workshop on Sketch-Oriented Deep Learning @ CVPR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Engineering sketches form the 2D basis of parametric Computer-Aided Design\n(CAD), the foremost modeling paradigm for manufactured objects. In this paper\nwe tackle the problem of learning based engineering sketch generation as a\nfirst step towards synthesis and composition of parametric CAD models. We\npropose two generative models, CurveGen and TurtleGen, for engineering sketch\ngeneration. Both models generate curve primitives without the need for a sketch\nconstraint solver and explicitly consider topology for downstream use with\nconstraints and 3D CAD modeling operations. We find in our perceptual\nevaluation using human subjects that both CurveGen and TurtleGen produce more\nrealistic engineering sketches when compared with the current state-of-the-art\nfor engineering sketch generation.\n", "versions": [{"version": "v1", "created": "Mon, 19 Apr 2021 20:38:36 GMT"}], "update_date": "2021-04-21", "authors_parsed": [["Willis", "Karl D. D.", ""], ["Jayaraman", "Pradeep Kumar", ""], ["Lambourne", "Joseph G.", ""], ["Chu", "Hang", ""], ["Pu", "Yewen", ""]]}, {"id": "2104.09623", "submitter": "Jan N. Fuhg", "authors": "Jan N. Fuhg, Nikolaos Bouklas", "title": "The mixed deep energy method for resolving concentration features in\n  finite strain hyperelasticity", "comments": "17 pages, 15 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  The introduction of Physics-informed Neural Networks (PINNs) has led to an\nincreased interest in deep neural networks as universal approximators of PDEs\nin the solid mechanics community. Recently, the Deep Energy Method (DEM) has\nbeen proposed. DEM is based on energy minimization principles, contrary to PINN\nwhich is based on the residual of the PDEs. A significant advantage of DEM, is\nthat it requires the approximation of lower order derivatives compared to\nformulations that are based on strong form residuals. However both DEM and\nclassical PINN formulations struggle to resolve fine features of the stress and\ndisplacement fields, for example concentration features in solid mechanics\napplications. We propose an extension to the Deep Energy Method (DEM) to\nresolve these features for finite strain hyperelasticity. The developed\nframework termed mixed Deep Energy Method (mDEM) introduces stress measures as\nan additional output of the NN to the recently introduced pure displacement\nformulation. Using this approach, Neumann boundary conditions are approximated\nmore accurately and the accuracy around spatial features which are typically\nresponsible for high concentrations is increased. In order to make the proposed\napproach more versatile, we introduce a numerical integration scheme based on\nDelaunay integration, which enables the mDEM framework to be used for random\ntraining point position sets commonly needed for computational domains with\nstress concentrations. We highlight the advantages of the proposed approach\nwhile showing the shortcomings of classical PINN and DEM formulations. The\nmethod is offering comparable results to Finite-Element Method (FEM) on the\nforward calculation of challenging computational experiments involving domains\nwith fine geometric features and concentrated loads.\n", "versions": [{"version": "v1", "created": "Thu, 15 Apr 2021 22:43:23 GMT"}], "update_date": "2021-04-21", "authors_parsed": [["Fuhg", "Jan N.", ""], ["Bouklas", "Nikolaos", ""]]}, {"id": "2104.09630", "submitter": "Danilo Comminiello", "authors": "Eleonora Grassucci, Edoardo Cicero, Danilo Comminiello", "title": "Quaternion Generative Adversarial Networks", "comments": "Accepted as a Chapter for the SPRINGER book \"Generative Adversarial\n  Learning: Architectures and Applications\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Latest Generative Adversarial Networks (GANs) are gathering outstanding\nresults through a large-scale training, thus employing models composed of\nmillions of parameters requiring extensive computational capabilities. Building\nsuch huge models undermines their replicability and increases the training\ninstability. Moreover, multi-channel data, such as images or audio, are usually\nprocessed by realvalued convolutional networks that flatten and concatenate the\ninput, often losing intra-channel spatial relations. To address these issues\nrelated to complexity and information loss, we propose a family of\nquaternion-valued generative adversarial networks (QGANs). QGANs exploit the\nproperties of quaternion algebra, e.g., the Hamilton product, that allows to\nprocess channels as a single entity and capture internal latent relations,\nwhile reducing by a factor of 4 the overall number of parameters. We show how\nto design QGANs and to extend the proposed approach even to advanced models.We\ncompare the proposed QGANs with real-valued counterparts on several image\ngeneration benchmarks. Results show that QGANs are able to obtain better FID\nscores than real-valued GANs and to generate visually pleasing images.\nFurthermore, QGANs save up to 75% of the training parameters. We believe these\nresults may pave the way to novel, more accessible, GANs capable of improving\nperformance and saving computational resources.\n", "versions": [{"version": "v1", "created": "Mon, 19 Apr 2021 20:46:18 GMT"}, {"version": "v2", "created": "Tue, 27 Jul 2021 15:30:42 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Grassucci", "Eleonora", ""], ["Cicero", "Edoardo", ""], ["Comminiello", "Danilo", ""]]}, {"id": "2104.09641", "submitter": "Danilo Comminiello", "authors": "Danilo Comminiello, Alireza Nezamdoust, Simone Scardapane, Michele\n  Scarpiniti, Amir Hussain, Aurelio Uncini", "title": "A New Class of Efficient Adaptive Filters for Online Nonlinear Modeling", "comments": "This work has been submitted to the IEEE Transactions on Systems,\n  Man, and Cybernetics: Systems for possible publication. Copyright may be\n  transferred without notice, after which this version may no longer be\n  accessible", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SD cs.SY eess.AS eess.SP eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nonlinear models are known to provide excellent performance in real-world\napplications that often operate in non-ideal conditions. However, such\napplications often require online processing to be performed with limited\ncomputational resources. In this paper, we propose a new efficient nonlinear\nmodel for online applications. The proposed algorithm is based on the\nlinear-in-the-parameters (LIP) nonlinear filters and their implementation as\nfunctional link adaptive filters (FLAFs). We focus here on a new effective and\nefficient approach for FLAFs based on frequency-domain adaptive filters. We\nintroduce the class of frequency-domain functional link adaptive filters\n(FD-FLAFs) and propose a partitioned block approach for their implementation.\nWe also investigate on the functional link expansions that provide the most\nsignificant benefits operating with limited resources in the frequency-domain.\nWe present and compare FD-FLAFs with different expansions to identify the LIP\nnonlinear filters showing the best tradeoff between performance and\ncomputational complexity. Experimental results prove that the frequency domain\nLIP nonlinear filters can be considered as an efficient and effective solution\nfor online applications, like the nonlinear acoustic echo cancellation.\n", "versions": [{"version": "v1", "created": "Mon, 19 Apr 2021 21:07:22 GMT"}], "update_date": "2021-04-21", "authors_parsed": [["Comminiello", "Danilo", ""], ["Nezamdoust", "Alireza", ""], ["Scardapane", "Simone", ""], ["Scarpiniti", "Michele", ""], ["Hussain", "Amir", ""], ["Uncini", "Aurelio", ""]]}, {"id": "2104.09648", "submitter": "Joel Hestness", "authors": "Mihir Pendse, Vithursan Thangarasa, Vitaliy Chiley, Ryan Holmdahl,\n  Joel Hestness, Dennis DeCoste", "title": "Memory Efficient 3D U-Net with Reversible Mobile Inverted Bottlenecks\n  for Brain Tumor Segmentation", "comments": "11 pages, 5 figures, Published at MICCAI Brainles 2020", "journal-ref": "Brainlesion: Glioma, Multiple Sclerosis, Stroke and Traumatic\n  Brain Injuries (2021) 388-397", "doi": "10.1007/978-3-030-72087-2_34", "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose combining memory saving techniques with traditional U-Net\narchitectures to increase the complexity of the models on the Brain Tumor\nSegmentation (BraTS) challenge. The BraTS challenge consists of a 3D\nsegmentation of a 240x240x155x4 input image into a set of tumor classes.\nBecause of the large volume and need for 3D convolutional layers, this task is\nvery memory intensive. To address this, prior approaches use smaller cropped\nimages while constraining the model's depth and width. Our 3D U-Net uses a\nreversible version of the mobile inverted bottleneck block defined in\nMobileNetV2, MnasNet and the more recent EfficientNet architectures to save\nactivation memory during training. Using reversible layers enables the model to\nrecompute input activations given the outputs of that layer, saving memory by\neliminating the need to store activations during the forward pass. The inverted\nresidual bottleneck block uses lightweight depthwise separable convolutions to\nreduce computation by decomposing convolutions into a pointwise convolution and\na depthwise convolution. Further, this block inverts traditional bottleneck\nblocks by placing an intermediate expansion layer between the input and output\nlinear 1x1 convolution, reducing the total number of channels. Given a fixed\nmemory budget, with these memory saving techniques, we are able to train image\nvolumes up to 3x larger, models with 25% more depth, or models with up to 2x\nthe number of channels than a corresponding non-reversible network.\n", "versions": [{"version": "v1", "created": "Mon, 19 Apr 2021 21:23:55 GMT"}, {"version": "v2", "created": "Wed, 21 Apr 2021 01:02:05 GMT"}], "update_date": "2021-04-22", "authors_parsed": [["Pendse", "Mihir", ""], ["Thangarasa", "Vithursan", ""], ["Chiley", "Vitaliy", ""], ["Holmdahl", "Ryan", ""], ["Hestness", "Joel", ""], ["DeCoste", "Dennis", ""]]}, {"id": "2104.09650", "submitter": "\\v{S}imon Mandl\\'ik", "authors": "\\v{S}imon Mandl\\'ik and Tom\\'a\\v{s} Pevn\\'y", "title": "Mapping the Internet: Modelling Entity Interactions in Complex\n  Heterogeneous Networks", "comments": "Master thesis, 108 page, 56 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Even though machine learning algorithms already play a significant role in\ndata science, many current methods pose unrealistic assumptions on input data.\nThe application of such methods is difficult due to incompatible data formats,\nor heterogeneous, hierarchical or entirely missing data fragments in the\ndataset. As a solution, we propose a versatile, unified framework called\n`HMill' for sample representation, model definition and training. We review in\ndepth a multi-instance paradigm for machine learning that the framework builds\non and extends. To theoretically justify the design of key components of HMill,\nwe show an extension of the universal approximation theorem to the set of all\nfunctions realized by models implemented in the framework. The text also\ncontains a detailed discussion on technicalities and performance improvements\nin our implementation, which is published for download under the MIT License.\nThe main asset of the framework is its flexibility, which makes modelling of\ndiverse real-world data sources with the same tool possible. Additionally to\nthe standard setting in which a set of attributes is observed for each object\nindividually, we explain how message-passing inference in graphs that represent\nwhole systems of objects can be implemented in the framework. To support our\nclaims, we solve three different problems from the cybersecurity domain using\nthe framework. The first use case concerns IoT device identification from raw\nnetwork observations. In the second problem, we study how malicious binary\nfiles can be classified using a snapshot of the operating system represented as\na directed graph. The last provided example is a task of domain blacklist\nextension through modelling interactions between entities in the network. In\nall three problems, the solution based on the proposed framework achieves\nperformance comparable to specialized approaches.\n", "versions": [{"version": "v1", "created": "Mon, 19 Apr 2021 21:32:44 GMT"}], "update_date": "2021-04-21", "authors_parsed": [["Mandl\u00edk", "\u0160imon", ""], ["Pevn\u00fd", "Tom\u00e1\u0161", ""]]}, {"id": "2104.09658", "submitter": "Yutao Zhong", "authors": "Pranjal Awasthi and Natalie Frank and Anqi Mao and Mehryar Mohri and\n  Yutao Zhong", "title": "Calibration and Consistency of Adversarial Surrogate Losses", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial robustness is an increasingly critical property of classifiers in\napplications. The design of robust algorithms relies on surrogate losses since\nthe optimization of the adversarial loss with most hypothesis sets is NP-hard.\nBut which surrogate losses should be used and when do they benefit from\ntheoretical guarantees? We present an extensive study of this question,\nincluding a detailed analysis of the H-calibration and H-consistency of\nadversarial surrogate losses. We show that, under some general assumptions,\nconvex loss functions, or the supremum-based convex losses often used in\napplications, are not H-calibrated for important hypothesis sets such as\ngeneralized linear models or one-layer neural networks. We then give a\ncharacterization of H-calibration and prove that some surrogate losses are\nindeed H-calibrated for the adversarial loss, with these hypothesis sets. Next,\nwe show that H-calibration is not sufficient to guarantee consistency and prove\nthat, in the absence of any distributional assumption, no continuous surrogate\nloss is consistent in the adversarial setting. This, in particular, proves that\na claim presented in a COLT 2020 publication is inaccurate. (Calibration\nresults there are correct modulo subtle definition differences, but the\nconsistency claim does not hold.) Next, we identify natural conditions under\nwhich some surrogate losses that we describe in detail are H-consistent for\nhypothesis sets such as generalized linear models and one-layer neural\nnetworks. We also report a series of empirical results with simulated data,\nwhich show that many H-calibrated surrogate losses are indeed not H-consistent,\nand validate our theoretical assumptions.\n", "versions": [{"version": "v1", "created": "Mon, 19 Apr 2021 21:58:52 GMT"}, {"version": "v2", "created": "Tue, 4 May 2021 14:21:13 GMT"}], "update_date": "2021-05-05", "authors_parsed": [["Awasthi", "Pranjal", ""], ["Frank", "Natalie", ""], ["Mao", "Anqi", ""], ["Mohri", "Mehryar", ""], ["Zhong", "Yutao", ""]]}, {"id": "2104.09665", "submitter": "Allen Liu", "authors": "Allen Liu, Ankur Moitra", "title": "Learning GMMs with Nearly Optimal Robustness Guarantees", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we solve the problem of robustly learning a high-dimensional\nGaussian mixture model with $k$ components from $\\epsilon$-corrupted samples up\nto accuracy $\\widetilde{O}(\\epsilon)$ in total variation distance for any\nconstant $k$ and with mild assumptions on the mixture. This robustness\nguarantee is optimal up to polylogarithmic factors. At the heart of our\nalgorithm is a new way to relax a system of polynomial equations which\ncorresponds to solving an improper learning problem where we are allowed to\noutput a Gaussian mixture model whose weights are low-degree polynomials.\n", "versions": [{"version": "v1", "created": "Mon, 19 Apr 2021 22:14:54 GMT"}], "update_date": "2021-04-21", "authors_parsed": [["Liu", "Allen", ""], ["Moitra", "Ankur", ""]]}, {"id": "2104.09667", "submitter": "Ilia Shumailov", "authors": "Ilia Shumailov, Zakhar Shumaylov, Dmitry Kazhdan, Yiren Zhao, Nicolas\n  Papernot, Murat A. Erdogdu, Ross Anderson", "title": "Manipulating SGD with Data Ordering Attacks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR cs.CV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Machine learning is vulnerable to a wide variety of attacks. It is now well\nunderstood that by changing the underlying data distribution, an adversary can\npoison the model trained with it or introduce backdoors. In this paper we\npresent a novel class of training-time attacks that require no changes to the\nunderlying dataset or model architecture, but instead only change the order in\nwhich data are supplied to the model. In particular, we find that the attacker\ncan either prevent the model from learning, or poison it to learn behaviours\nspecified by the attacker. Furthermore, we find that even a single\nadversarially-ordered epoch can be enough to slow down model learning, or even\nto reset all of the learning progress. Indeed, the attacks presented here are\nnot specific to the model or dataset, but rather target the stochastic nature\nof modern learning procedures. We extensively evaluate our attacks on computer\nvision and natural language benchmarks to find that the adversary can disrupt\nmodel training and even introduce backdoors.\n", "versions": [{"version": "v1", "created": "Mon, 19 Apr 2021 22:17:27 GMT"}, {"version": "v2", "created": "Sat, 5 Jun 2021 10:22:15 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Shumailov", "Ilia", ""], ["Shumaylov", "Zakhar", ""], ["Kazhdan", "Dmitry", ""], ["Zhao", "Yiren", ""], ["Papernot", "Nicolas", ""], ["Erdogdu", "Murat A.", ""], ["Anderson", "Ross", ""]]}, {"id": "2104.09683", "submitter": "Pierre Lison", "authors": "Pierre Lison and Jeremy Barnes and Aliaksandr Hubin", "title": "skweak: Weak Supervision Made Easy for NLP", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present skweak, a versatile, Python-based software toolkit enabling NLP\ndevelopers to apply weak supervision to a wide range of NLP tasks. Weak\nsupervision is an emerging machine learning paradigm based on a simple idea:\ninstead of labelling data points by hand, we use labelling functions derived\nfrom domain knowledge to automatically obtain annotations for a given dataset.\nThe resulting labels are then aggregated with a generative model that estimates\nthe accuracy (and possible confusions) of each labelling function. The skweak\ntoolkit makes it easy to implement a large spectrum of labelling functions\n(such as heuristics, gazetteers, neural models or linguistic constraints) on\ntext data, apply them on a corpus, and aggregate their results in a fully\nunsupervised fashion. skweak is especially designed to facilitate the use of\nweak supervision for NLP tasks such as text classification and sequence\nlabelling. We illustrate the use of skweak for NER and sentiment analysis.\nskweak is released under an open-source license and is available at:\nhttps://github.com/NorskRegnesentral/skweak\n", "versions": [{"version": "v1", "created": "Mon, 19 Apr 2021 23:26:51 GMT"}], "update_date": "2021-04-21", "authors_parsed": [["Lison", "Pierre", ""], ["Barnes", "Jeremy", ""], ["Hubin", "Aliaksandr", ""]]}, {"id": "2104.09684", "submitter": "Bogdan Kustowski", "authors": "Bogdan Kustowski, Jim A. Gaffney, Brian K. Spears, Gemma J. Anderson,\n  Rushil Anirudh, Peer-Timo Bremer, Jayaraman J. Thiagarajan (Lawrence\n  Livermore National Laboratory, Livermore, CA)", "title": "Transfer learning suppresses simulation bias in predictive models built\n  from sparse, multi-modal data", "comments": "13 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": "LLNL-JRNL-821489-DRAFT", "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Many problems in science, engineering, and business require making\npredictions based on very few observations. To build a robust predictive model,\nthese sparse data may need to be augmented with simulated data, especially when\nthe design space is multidimensional. Simulations, however, often suffer from\nan inherent bias. Estimation of this bias may be poorly constrained not only\nbecause of data sparsity, but also because traditional predictive models fit\nonly one type of observations, such as scalars or images, instead of all\navailable data modalities, which might have been acquired and simulated at\ngreat cost. We combine recent developments in deep learning to build more\nrobust predictive models from multimodal data with a recent, novel technique to\nsuppress the bias, and extend it to take into account multiple data modalities.\nFirst, an initial, simulation-trained, neural network surrogate model learns\nimportant correlations between different data modalities and between simulation\ninputs and outputs. Then, the model is partially retrained, or transfer\nlearned, to fit the observations. Using fewer than 10 inertial confinement\nfusion experiments for retraining, we demonstrate that this technique\nsystematically improves simulation predictions while a simple output\ncalibration makes predictions worse. We also offer extensive cross-validation\nwith real and synthetic data to support our findings. The transfer learning\nmethod can be applied to other problems that require transferring knowledge\nfrom simulations to the domain of real observations. This paper opens up the\npath to model calibration using multiple data types, which have traditionally\nbeen ignored in predictive models.\n", "versions": [{"version": "v1", "created": "Mon, 19 Apr 2021 23:28:32 GMT"}], "update_date": "2021-04-21", "authors_parsed": [["Kustowski", "Bogdan", "", "Lawrence\n  Livermore National Laboratory, Livermore, CA"], ["Gaffney", "Jim A.", "", "Lawrence\n  Livermore National Laboratory, Livermore, CA"], ["Spears", "Brian K.", "", "Lawrence\n  Livermore National Laboratory, Livermore, CA"], ["Anderson", "Gemma J.", "", "Lawrence\n  Livermore National Laboratory, Livermore, CA"], ["Anirudh", "Rushil", "", "Lawrence\n  Livermore National Laboratory, Livermore, CA"], ["Bremer", "Peer-Timo", "", "Lawrence\n  Livermore National Laboratory, Livermore, CA"], ["Thiagarajan", "Jayaraman J.", "", "Lawrence\n  Livermore National Laboratory, Livermore, CA"]]}, {"id": "2104.09686", "submitter": "Felix Rempe Dr.", "authors": "Felix Rempe, Philipp Franeck, Klaus Bogenberger", "title": "Estimating Traffic Speeds using Probe Data: A Deep Neural Network\n  Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  This paper presents a dedicated Deep Neural Network (DNN) architecture that\nreconstructs space-time traffic speeds on freeways given sparse data. The DNN\nis constructed in such a way, that it learns heterogeneous congestion patterns\nusing a large dataset of sparse speed data, in particular from probe vehicles.\nInput to the DNN are two equally sized input matrices: one containing raw\nmeasurement data, and the other indicates the cells occupied with data. The\nDNN, comprising multiple stacked convolutional layers with an encoding-decoding\nstructure and feed-forward paths, transforms the input into a full matrix of\ntraffic speeds. The proposed DNN architecture is evaluated with respect to its\nability to accurately reconstruct heterogeneous congestion patterns under\nvarying input data sparsity. Therefore, a large set of empirical Floating-Car\nData (FCD) collected on German freeway A9 during two months is utilized. In\ntotal, 43 congestion distinct scenarios are observed which comprise moving and\nstationary congestion patterns. A data augmentation technique is applied to\ngenerate input-output samples of the data, which makes the DNN shift-invariant\nas well as capable of managing varying data sparsities. The DNN is trained and\nsubsequently applied to sparse data of an unseen congestion scenario. The\nresults show that the DNN is able to apply learned patterns, and reconstructs\nmoving as well as stationary congested traffic with high accuracy; even given\nhighly sparse input data. Reconstructed speeds are compared qualitatively and\nquantitatively with the results of several state-of-the-art methods such as the\nAdaptive Smoothing Method (ASM), the Phase-Based Smoothing Method (PSM) and a\nstandard Convolutional Neural Network (CNN) architecture. As a result, the DNN\noutperforms the other methods significantly.\n", "versions": [{"version": "v1", "created": "Mon, 19 Apr 2021 23:32:12 GMT"}], "update_date": "2021-04-21", "authors_parsed": [["Rempe", "Felix", ""], ["Franeck", "Philipp", ""], ["Bogenberger", "Klaus", ""]]}, {"id": "2104.09694", "submitter": "Luca Di Liello", "authors": "Luca Di Liello, Matteo Gabburo, Alessandro Moschitti", "title": "Efficient pre-training objectives for Transformers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The Transformer architecture deeply changed the natural language processing,\noutperforming all previous state-of-the-art models. However, well-known\nTransformer models like BERT, RoBERTa, and GPT-2 require a huge compute budget\nto create a high quality contextualised representation. In this paper, we study\nseveral efficient pre-training objectives for Transformers-based models. By\ntesting these objectives on different tasks, we determine which of the ELECTRA\nmodel's new features is the most relevant. We confirm that Transformers\npre-training is improved when the input does not contain masked tokens and that\nthe usage of the whole output to compute the loss reduces training time.\nMoreover, inspired by ELECTRA, we study a model composed of two blocks; a\ndiscriminator and a simple generator based on a statistical model with no\nimpact on the computational performances. Besides, we prove that eliminating\nthe MASK token and considering the whole output during the loss computation are\nessential choices to improve performance. Furthermore, we show that it is\npossible to efficiently train BERT-like models using a discriminative approach\nas in ELECTRA but without a complex generator, which is expensive. Finally, we\nshow that ELECTRA benefits heavily from a state-of-the-art hyper-parameters\nsearch.\n", "versions": [{"version": "v1", "created": "Tue, 20 Apr 2021 00:09:37 GMT"}], "update_date": "2021-04-21", "authors_parsed": [["Di Liello", "Luca", ""], ["Gabburo", "Matteo", ""], ["Moschitti", "Alessandro", ""]]}, {"id": "2104.09700", "submitter": "Jinge Wu", "authors": "Mingwen Liu, Junbang Huo, Yulin Wu, Jinge Wu", "title": "Stock Market Trend Analysis Using Hidden Markov Model and Long Short\n  Term Memory", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.PR cs.LG q-fin.CP q-fin.PM q-fin.TR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper intends to apply the Hidden Markov Model into stock market and and\nmake predictions. Moreover, four different methods of improvement, which are\nGMM-HMM, XGB-HMM, GMM-HMM+LSTM and XGB-HMM+LSTM, will be discussed later with\nthe results of experiment respectively. After that we will analyze the pros and\ncons of different models. And finally, one of the best will be used into stock\nmarket for timing strategy.\n", "versions": [{"version": "v1", "created": "Tue, 20 Apr 2021 00:49:13 GMT"}], "update_date": "2021-04-21", "authors_parsed": [["Liu", "Mingwen", ""], ["Huo", "Junbang", ""], ["Wu", "Yulin", ""], ["Wu", "Jinge", ""]]}, {"id": "2104.09703", "submitter": "Katsuyuki Hagiwara", "authors": "Katsuyuki Hagiwara", "title": "Bridging between soft and hard thresholding by scaling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article, we developed and analyzed a thresholding method in which\nsoft thresholding estimators are independently expanded by empirical scaling\nvalues. The scaling values have a common hyper-parameter that is an order of\nexpansion of an ideal scaling value that achieves hard thresholding. We simply\ncall this estimator a scaled soft thresholding estimator. The scaled soft\nthresholding is a general method that includes the soft thresholding and\nnon-negative garrote as special cases and gives an another derivation of\nadaptive LASSO. We then derived the degree of freedom of the scaled soft\nthresholding by means of the Stein's unbiased risk estimate and found that it\nis decomposed into the degree of freedom of soft thresholding and the reminder\nconnecting to hard thresholding. In this meaning, the scaled soft thresholding\ngives a natural bridge between soft and hard thresholding methods. Since the\ndegree of freedom represents the degree of over-fitting, this result implies\nthat there are two sources of over-fitting in the scaled soft thresholding. The\nfirst source originated from soft thresholding is determined by the number of\nun-removed coefficients and is a natural measure of the degree of over-fitting.\nWe analyzed the second source in a particular case of the scaled soft\nthresholding by referring a known result for hard thresholding. We then found\nthat, in a sparse, large sample and non-parametric setting, the second source\nis largely determined by coefficient estimates whose true values are zeros and\nhas an influence on over-fitting when threshold levels are around noise levels\nin those coefficient estimates. In a simple numerical example, these\ntheoretical implications has well explained the behavior of the degree of\nfreedom. Moreover, based on the results here and some known facts, we explained\nthe behaviors of risks of soft, hard and scaled soft thresholding methods.\n", "versions": [{"version": "v1", "created": "Tue, 20 Apr 2021 00:58:05 GMT"}], "update_date": "2021-04-21", "authors_parsed": [["Hagiwara", "Katsuyuki", ""]]}, {"id": "2104.09713", "submitter": "Jing Zhang", "authors": "Hong Wen and Jing Zhang and Fuyu Lv and Wentian Bao and Tianyi Wang\n  and Zulong Chen", "title": "Hierarchically Modeling Micro and Macro Behaviors via Multi-Task\n  Learning for Conversion Rate Prediction", "comments": "Accepted as SIGIR 2021 short paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conversion Rate (\\emph{CVR}) prediction in modern industrial e-commerce\nplatforms is becoming increasingly important, which directly contributes to the\nfinal revenue. In order to address the well-known sample selection bias\n(\\emph{SSB}) and data sparsity (\\emph{DS}) issues encountered during CVR\nmodeling, the abundant labeled macro behaviors ($i.e.$, user's interactions\nwith items) are used. Nonetheless, we observe that several purchase-related\nmicro behaviors ($i.e.$, user's interactions with specific components on the\nitem detail page) can supplement fine-grained cues for \\emph{CVR} prediction.\nMotivated by this observation, we propose a novel \\emph{CVR} prediction method\nby Hierarchically Modeling both Micro and Macro behaviors ($HM^3$).\nSpecifically, we first construct a complete user sequential behavior graph to\nhierarchically represent micro behaviors and macro behaviors as one-hop and\ntwo-hop post-click nodes. Then, we embody $HM^3$ as a multi-head deep neural\nnetwork, which predicts six probability variables corresponding to explicit\nsub-paths in the graph. They are further combined into the prediction targets\nof four auxiliary tasks as well as the final $CVR$ according to the conditional\nprobability rule defined on the graph. By employing multi-task learning and\nleveraging the abundant supervisory labels from micro and macro behaviors,\n$HM^3$ can be trained end-to-end and address the \\emph{SSB} and \\emph{DS}\nissues. Extensive experiments on both offline and online settings demonstrate\nthe superiority of the proposed $HM^3$ over representative state-of-the-art\nmethods.\n", "versions": [{"version": "v1", "created": "Tue, 20 Apr 2021 01:45:06 GMT"}], "update_date": "2021-04-21", "authors_parsed": [["Wen", "Hong", ""], ["Zhang", "Jing", ""], ["Lv", "Fuyu", ""], ["Bao", "Wentian", ""], ["Wang", "Tianyi", ""], ["Chen", "Zulong", ""]]}, {"id": "2104.09732", "submitter": "Lester Mackey", "authors": "Tri Dao, Govinda M Kamath, Vasilis Syrgkanis, Lester Mackey", "title": "Knowledge Distillation as Semiparametric Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A popular approach to model compression is to train an inexpensive student\nmodel to mimic the class probabilities of a highly accurate but cumbersome\nteacher model. Surprisingly, this two-step knowledge distillation process often\nleads to higher accuracy than training the student directly on labeled data. To\nexplain and enhance this phenomenon, we cast knowledge distillation as a\nsemiparametric inference problem with the optimal student model as the target,\nthe unknown Bayes class probabilities as nuisance, and the teacher\nprobabilities as a plug-in nuisance estimate. By adapting modern semiparametric\ntools, we derive new guarantees for the prediction error of standard\ndistillation and develop two enhancements -- cross-fitting and loss correction\n-- to mitigate the impact of teacher overfitting and underfitting on student\nperformance. We validate our findings empirically on both tabular and image\ndata and observe consistent improvements from our knowledge distillation\nenhancements.\n", "versions": [{"version": "v1", "created": "Tue, 20 Apr 2021 03:00:45 GMT"}], "update_date": "2021-04-21", "authors_parsed": [["Dao", "Tri", ""], ["Kamath", "Govinda M", ""], ["Syrgkanis", "Vasilis", ""], ["Mackey", "Lester", ""]]}, {"id": "2104.09734", "submitter": "Pasin Manurangsi", "authors": "Alisa Chang, Badih Ghazi, Ravi Kumar, Pasin Manurangsi", "title": "Locally Private k-Means in One Round", "comments": "35 pages. To appear in ICML'21", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide an approximation algorithm for k-means clustering in the one-round\n(aka non-interactive) local model of differential privacy (DP). This algorithm\nachieves an approximation ratio arbitrarily close to the best non private\napproximation algorithm, improving upon previously known algorithms that only\nguarantee large (constant) approximation ratios. Furthermore, this is the first\nconstant-factor approximation algorithm for k-means that requires only one\nround of communication in the local DP model, positively resolving an open\nquestion of Stemmer (SODA 2020). Our algorithmic framework is quite flexible;\nwe demonstrate this by showing that it also yields a similar near-optimal\napproximation algorithm in the (one-round) shuffle DP model.\n", "versions": [{"version": "v1", "created": "Tue, 20 Apr 2021 03:07:31 GMT"}, {"version": "v2", "created": "Sat, 15 May 2021 05:27:59 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Chang", "Alisa", ""], ["Ghazi", "Badih", ""], ["Kumar", "Ravi", ""], ["Manurangsi", "Pasin", ""]]}, {"id": "2104.09750", "submitter": "Alfonso Lobos Mr.", "authors": "Alfonso Lobos, Paul Grigas, Zheng Wen", "title": "Joint Online Learning and Decision-making via Dual Mirror Descent", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider an online revenue maximization problem over a finite time horizon\nsubject to lower and upper bounds on cost. At each period, an agent receives a\ncontext vector sampled i.i.d. from an unknown distribution and needs to make a\ndecision adaptively. The revenue and cost functions depend on the context\nvector as well as some fixed but possibly unknown parameter vector to be\nlearned. We propose a novel offline benchmark and a new algorithm that mixes an\nonline dual mirror descent scheme with a generic parameter learning process.\nWhen the parameter vector is known, we demonstrate an $O(\\sqrt{T})$ regret\nresult as well an $O(\\sqrt{T})$ bound on the possible constraint violations.\nWhen the parameter is not known and must be learned, we demonstrate that the\nregret and constraint violations are the sums of the previous $O(\\sqrt{T})$\nterms plus terms that directly depend on the convergence of the learning\nprocess.\n", "versions": [{"version": "v1", "created": "Tue, 20 Apr 2021 04:02:07 GMT"}], "update_date": "2021-04-21", "authors_parsed": [["Lobos", "Alfonso", ""], ["Grigas", "Paul", ""], ["Wen", "Zheng", ""]]}, {"id": "2104.09771", "submitter": "Zhaoming Xie", "authors": "Zhaoming Xie, Xingye Da, Buck Babich, Animesh Garg, Michiel van de\n  Panne", "title": "GLiDE: Generalizable Quadrupedal Locomotion in Diverse Environments with\n  a Centroidal Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Model-free reinforcement learning (RL) for legged locomotion commonly relies\non a physics simulator that can accurately predict the behaviors of every\ndegree of freedom of the robot. In contrast, approximate reduced-order models\nare often sufficient for many model-based control strategies. In this work we\nexplore how RL can be effectively used with a centroidal model to generate\nrobust control policies for quadrupedal locomotion. Advantages over RL with a\nfull-order model include a simple reward structure, reduced computational\ncosts, and robust sim-to-real transfer. We further show the potential of the\nmethod by demonstrating stepping-stone locomotion, two-legged in-place balance,\nbalance beam locomotion, and sim-to-real transfer without further adaptations.\nAdditional Results: https://www.pair.toronto.edu/glide-quadruped/.\n", "versions": [{"version": "v1", "created": "Tue, 20 Apr 2021 05:55:13 GMT"}, {"version": "v2", "created": "Thu, 22 Apr 2021 03:40:44 GMT"}], "update_date": "2021-04-23", "authors_parsed": [["Xie", "Zhaoming", ""], ["Da", "Xingye", ""], ["Babich", "Buck", ""], ["Garg", "Animesh", ""], ["van de Panne", "Michiel", ""]]}, {"id": "2104.09785", "submitter": "Glenn Ceusters", "authors": "Glenn Ceusters, Rom\\'an Cant\\'u Rodr\\'iguez, Alberte Bouso Garc\\'ia,\n  R\\\"udiger Franke, Geert Deconinck, Lieve Helsen, Ann Now\\'e, Maarten\n  Messagie, Luis Ramirez Camargo", "title": "Model-predictive control and reinforcement learning in multi-energy\n  system case studies", "comments": "35 pages, 27 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.AI cs.LG cs.SY math.OC", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Model-predictive-control (MPC) offers an optimal control technique to\nestablish and ensure that the total operation cost of multi-energy systems\nremains at a minimum while fulfilling all system constraints. However, this\nmethod presumes an adequate model of the underlying system dynamics, which is\nprone to modelling errors and is not necessarily adaptive. This has an\nassociated initial and ongoing project-specific engineering cost. In this\npaper, we present an on- and off-policy multi-objective reinforcement learning\n(RL) approach, that does not assume a model a priori, benchmarking this against\na linear MPC (LMPC - to reflect current practice, though non-linear MPC\nperforms better) - both derived from the general optimal control problem,\nhighlighting their differences and similarities. In a simple multi-energy\nsystem (MES) configuration case study, we show that a twin delayed deep\ndeterministic policy gradient (TD3) RL agent offers potential to match and\noutperform the perfect foresight LMPC benchmark (101.5%). This while the\nrealistic LMPC, i.e. imperfect predictions, only achieves 98%. While in a more\ncomplex MES system configuration, the RL agent's performance is generally lower\n(94.6%), yet still better than the realistic LMPC (88.9%). In both case\nstudies, the RL agents outperformed the realistic LMPC after a training period\nof 2 years using quarterly interactions with the environment. We conclude that\nreinforcement learning is a viable optimal control technique for multi-energy\nsystems given adequate constraint handling and pre-training, to avoid unsafe\ninteractions and long training periods, as is proposed in fundamental future\nwork.\n", "versions": [{"version": "v1", "created": "Tue, 20 Apr 2021 06:51:50 GMT"}], "update_date": "2021-04-21", "authors_parsed": [["Ceusters", "Glenn", ""], ["Rodr\u00edguez", "Rom\u00e1n Cant\u00fa", ""], ["Garc\u00eda", "Alberte Bouso", ""], ["Franke", "R\u00fcdiger", ""], ["Deconinck", "Geert", ""], ["Helsen", "Lieve", ""], ["Now\u00e9", "Ann", ""], ["Messagie", "Maarten", ""], ["Camargo", "Luis Ramirez", ""]]}, {"id": "2104.09792", "submitter": "Gilad Kutiel", "authors": "Iftah Gamzu, Hila Gonen, Gilad Kutiel, Ran Levy, Eugene Agichtein", "title": "Identifying Helpful Sentences in Product Reviews", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In recent years online shopping has gained momentum and became an important\nvenue for customers wishing to save time and simplify their shopping process. A\nkey advantage of shopping online is the ability to read what other customers\nare saying about products of interest. In this work, we aim to maintain this\nadvantage in situations where extreme brevity is needed, for example, when\nshopping by voice. We suggest a novel task of extracting a single\nrepresentative helpful sentence from a set of reviews for a given product. The\nselected sentence should meet two conditions: first, it should be helpful for a\npurchase decision and second, the opinion it expresses should be supported by\nmultiple reviewers. This task is closely related to the task of Multi Document\nSummarization in the product reviews domain but differs in its objective and\nits level of conciseness. We collect a dataset in English of sentence\nhelpfulness scores via crowd-sourcing and demonstrate its reliability despite\nthe inherent subjectivity involved. Next, we describe a complete model that\nextracts representative helpful sentences with positive and negative sentiment\ntowards the product and demonstrate that it outperforms several baselines.\n", "versions": [{"version": "v1", "created": "Tue, 20 Apr 2021 07:09:22 GMT"}, {"version": "v2", "created": "Wed, 5 May 2021 06:36:15 GMT"}, {"version": "v3", "created": "Sun, 11 Jul 2021 08:37:56 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Gamzu", "Iftah", ""], ["Gonen", "Hila", ""], ["Kutiel", "Gilad", ""], ["Levy", "Ran", ""], ["Agichtein", "Eugene", ""]]}, {"id": "2104.09793", "submitter": "JuneKyu Park", "authors": "JuneKyu Park, Jeong-Hyeon Moon, Namhyuk Ahn and Kyung-Ah Sohn", "title": "What is Wrong with One-Class Anomaly Detection?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  From a safety perspective, a machine learning method embedded in real-world\napplications is required to distinguish irregular situations. For this reason,\nthere has been a growing interest in the anomaly detection (AD) task. Since we\ncannot observe abnormal samples for most of the cases, recent AD methods\nattempt to formulate it as a task of classifying whether the sample is normal\nor not. However, they potentially fail when the given normal samples are\ninherited from diverse semantic labels. To tackle this problem, we introduce a\nlatent class-condition-based AD scenario. In addition, we propose a\nconfidence-based self-labeling AD framework tailored to our proposed scenario.\nSince our method leverages the hidden class information, it successfully avoids\ngenerating the undesirable loose decision region that one-class methods suffer.\nOur proposed framework outperforms the recent one-class AD methods in the\nlatent multi-class scenarios.\n", "versions": [{"version": "v1", "created": "Tue, 20 Apr 2021 07:10:00 GMT"}], "update_date": "2021-04-21", "authors_parsed": [["Park", "JuneKyu", ""], ["Moon", "Jeong-Hyeon", ""], ["Ahn", "Namhyuk", ""], ["Sohn", "Kyung-Ah", ""]]}, {"id": "2104.09798", "submitter": "Alireza Khadem", "authors": "Alireza Khadem, Haojie Ye, Trevor Mudge", "title": "CoDR: Computation and Data Reuse Aware CNN Accelerator", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR cs.AI cs.LG cs.NE cs.SY eess.SY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Computation and Data Reuse is critical for the resource-limited Convolutional\nNeural Network (CNN) accelerators. This paper presents Universal Computation\nReuse to exploit weight sparsity, repetition, and similarity simultaneously in\na convolutional layer. Moreover, CoDR decreases the cost of weight memory\naccess by proposing a customized Run-Length Encoding scheme and the number of\nmemory accesses to the intermediate results by introducing an input and output\nstationary dataflow. Compared to two recent compressed CNN accelerators with\nthe same area of 2.85 mm^2, CoDR decreases SRAM access by 5.08x and 7.99x, and\nconsumes 3.76x and 6.84x less energy.\n", "versions": [{"version": "v1", "created": "Tue, 20 Apr 2021 07:20:17 GMT"}], "update_date": "2021-04-21", "authors_parsed": [["Khadem", "Alireza", ""], ["Ye", "Haojie", ""], ["Mudge", "Trevor", ""]]}, {"id": "2104.09807", "submitter": "Bar Mayo", "authors": "Bar Mayo, Tamir Hazan and Ayellet Tal", "title": "Visual Navigation with Spatial Attention", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work focuses on object goal visual navigation, aiming at finding the\nlocation of an object from a given class, where in each step the agent is\nprovided with an egocentric RGB image of the scene. We propose to learn the\nagent's policy using a reinforcement learning algorithm. Our key contribution\nis a novel attention probability model for visual navigation tasks. This\nattention encodes semantic information about observed objects, as well as\nspatial information about their place. This combination of the \"what\" and the\n\"where\" allows the agent to navigate toward the sought-after object\neffectively. The attention model is shown to improve the agent's policy and to\nachieve state-of-the-art results on commonly-used datasets.\n", "versions": [{"version": "v1", "created": "Tue, 20 Apr 2021 07:39:52 GMT"}], "update_date": "2021-04-21", "authors_parsed": [["Mayo", "Bar", ""], ["Hazan", "Tamir", ""], ["Tal", "Ayellet", ""]]}, {"id": "2104.09839", "submitter": "Marco Forgione", "authors": "Dario Piga, Marco Forgione, Manas Mejari", "title": "Deep learning with transfer functions: new applications in system\n  identification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a linear dynamical operator described in terms of a\nrational transfer function, endowed with a well-defined and efficient\nback-propagation behavior for automatic derivatives computation. The operator\nenables end-to-end training of structured networks containing linear transfer\nfunctions and other differentiable units {by} exploiting standard deep learning\nsoftware.\n  Two relevant applications of the operator in system identification are\npresented. The first one consists in the integration of {prediction error\nmethods} in deep learning. The dynamical operator is included as {the} last\nlayer of a neural network in order to obtain the optimal one-step-ahead\nprediction error.\n  The second one considers identification of general block-oriented models from\nquantized data. These block-oriented models are constructed by combining linear\ndynamical operators with static nonlinearities described as standard\nfeed-forward neural networks. A custom loss function corresponding to the\nlog-likelihood of quantized output observations is defined. For gradient-based\noptimization, the derivatives of the log-likelihood are computed by applying\nthe back-propagation algorithm through the whole network. Two system\nidentification benchmarks are used to show the effectiveness of the proposed\nmethodologies.\n", "versions": [{"version": "v1", "created": "Tue, 20 Apr 2021 08:58:55 GMT"}], "update_date": "2021-04-21", "authors_parsed": [["Piga", "Dario", ""], ["Forgione", "Marco", ""], ["Mejari", "Manas", ""]]}, {"id": "2104.09852", "submitter": "Islam Debicha", "authors": "Islam Debicha, Thibault Debatty, Jean-Michel Dricot, Wim Mees", "title": "Adversarial Training for Deep Learning-based Intrusion Detection Systems", "comments": "Already published in The Sixteenth International Conference on\n  Systems (ICONS 2021)", "journal-ref": "The Sixteenth International Conference on Systems (ICONS 2021),\n  pp. 45-49, 2021", "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays, Deep Neural Networks (DNNs) report state-of-the-art results in many\nmachine learning areas, including intrusion detection. Nevertheless, recent\nstudies in computer vision have shown that DNNs can be vulnerable to\nadversarial attacks that are capable of deceiving them into misclassification\nby injecting specially crafted data. In security-critical areas, such attacks\ncan cause serious damage; therefore, in this paper, we examine the effect of\nadversarial attacks on deep learning-based intrusion detection. In addition, we\ninvestigate the effectiveness of adversarial training as a defense against such\nattacks. Experimental results show that with sufficient distortion, adversarial\nexamples are able to mislead the detector and that the use of adversarial\ntraining can improve the robustness of intrusion detection.\n", "versions": [{"version": "v1", "created": "Tue, 20 Apr 2021 09:36:24 GMT"}], "update_date": "2021-04-21", "authors_parsed": [["Debicha", "Islam", ""], ["Debatty", "Thibault", ""], ["Dricot", "Jean-Michel", ""], ["Mees", "Wim", ""]]}, {"id": "2104.09855", "submitter": "Rendani Mbuvha", "authors": "Adam Balusik, Jared de Magalhaes and Rendani Mbuvha", "title": "Forecasting The JSE Top 40 Using Long Short-Term Memory Networks", "comments": "17 Pages, 5 Figures, 4 Tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  As a result of the greater availability of big data, as well as the\ndecreasing costs and increasing power of modern computing, the use of\nartificial neural networks for financial time series forecasting is once again\na major topic of discussion and research in the financial world. Despite this\nacademic focus, there are still contrasting opinions and bodies of literature\non which artificial neural networks perform the best and whether or not they\noutperform the forecasting capabilities of conventional time series models.\nThis paper uses a long-short term memory network to perform financial time\nseries forecasting on the return data of the JSE Top 40 index. Furthermore, the\nforecasting performance of the long-short term memory network is compared to\nthe forecasting performance of a seasonal autoregressive integrated moving\naverage model. This paper evaluates the varying approaches presented in the\nexisting literature and ultimately, compares the results to that existing\nliterature. The paper concludes that the long short-term memory network\noutperforms the seasonal autoregressive integrated moving average model when\nforecasting intraday directional movements as well as when forecasting the\nindex close price.\n", "versions": [{"version": "v1", "created": "Tue, 20 Apr 2021 09:39:38 GMT"}], "update_date": "2021-04-21", "authors_parsed": [["Balusik", "Adam", ""], ["de Magalhaes", "Jared", ""], ["Mbuvha", "Rendani", ""]]}, {"id": "2104.09856", "submitter": "Robin Winter", "authors": "Robin Winter, Frank No\\'e, Djork-Arn\\'e Clevert", "title": "Permutation-Invariant Variational Autoencoder for Graph-Level\n  Representation Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recently, there has been great success in applying deep neural networks on\ngraph structured data. Most work, however, focuses on either node- or\ngraph-level supervised learning, such as node, link or graph classification or\nnode-level unsupervised learning (e.g. node clustering). Despite its wide range\nof possible applications, graph-level unsupervised learning has not received\nmuch attention yet. This might be mainly attributed to the high representation\ncomplexity of graphs, which can be represented by n! equivalent adjacency\nmatrices, where n is the number of nodes. In this work we address this issue by\nproposing a permutation-invariant variational autoencoder for graph structured\ndata. Our proposed model indirectly learns to match the node ordering of input\nand output graph, without imposing a particular node ordering or performing\nexpensive graph matching. We demonstrate the effectiveness of our proposed\nmodel on various graph reconstruction and generation tasks and evaluate the\nexpressive power of extracted representations for downstream graph-level\nclassification and regression.\n", "versions": [{"version": "v1", "created": "Tue, 20 Apr 2021 09:44:41 GMT"}], "update_date": "2021-04-21", "authors_parsed": [["Winter", "Robin", ""], ["No\u00e9", "Frank", ""], ["Clevert", "Djork-Arn\u00e9", ""]]}, {"id": "2104.09859", "submitter": "Dat Nguyen Thanh", "authors": "Dat Thanh Nguyen, Maurice Quach, Giuseppe Valenzise, Pierre Duhamel", "title": "Multiscale deep context modeling for lossless point cloud geometry\n  compression", "comments": "6 pages, accepted paper at ICME workshop 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a practical deep generative approach for lossless point cloud\ngeometry compression, called MSVoxelDNN, and show that it significantly reduces\nthe rate compared to the MPEG G-PCC codec. Our previous work based on\nautoregressive models (VoxelDNN) has a fast training phase, however, inference\nis slow as the occupancy probabilities are predicted sequentially, voxel by\nvoxel. In this work, we employ a multiscale architecture which models voxel\noccupancy in coarse-to-fine order. At each scale, MSVoxelDNN divides voxels\ninto eight conditionally independent groups, thus requiring a single network\nevaluation per group instead of one per voxel. We evaluate the performance of\nMSVoxelDNN on a set of point clouds from Microsoft Voxelized Upper Bodies\n(MVUB) and MPEG, showing that the current method speeds up encoding/decoding\ntimes significantly compared to the previous VoxelDNN, while having average\nrate saving over G-PCC of 17.5%. The implementation is available at\nhttps://github.com/Weafre/MSVoxelDNN.\n", "versions": [{"version": "v1", "created": "Tue, 20 Apr 2021 09:48:12 GMT"}], "update_date": "2021-04-21", "authors_parsed": [["Nguyen", "Dat Thanh", ""], ["Quach", "Maurice", ""], ["Valenzise", "Giuseppe", ""], ["Duhamel", "Pierre", ""]]}, {"id": "2104.09864", "submitter": "Jianlin Su", "authors": "Jianlin Su, Yu Lu, Shengfeng Pan, Bo Wen, Yunfeng Liu", "title": "RoFormer: Enhanced Transformer with Rotary Position Embedding", "comments": "Preprint. English experiments are coming", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Position encoding in transformer architecture provides supervision for\ndependency modeling between elements at different positions in the sequence. We\ninvestigate various methods to encode positional information in\ntransformer-based language models and propose a novel implementation named\nRotary Position Embedding(RoPE). The proposed RoPE encodes absolute positional\ninformation with rotation matrix and naturally incorporates explicit relative\nposition dependency in self-attention formulation. Notably, RoPE comes with\nvaluable properties such as flexibility of being expand to any sequence\nlengths, decaying inter-token dependency with increasing relative distances,\nand capability of equipping the linear self-attention with relative position\nencoding. As a result, the enhanced transformer with rotary position embedding,\nor RoFormer, achieves superior performance in tasks with long texts. We release\nthe theoretical analysis along with some preliminary experiment results on\nChinese data. The undergoing experiment for English benchmark will soon be\nupdated.\n", "versions": [{"version": "v1", "created": "Tue, 20 Apr 2021 09:54:06 GMT"}], "update_date": "2021-04-21", "authors_parsed": [["Su", "Jianlin", ""], ["Lu", "Yu", ""], ["Pan", "Shengfeng", ""], ["Wen", "Bo", ""], ["Liu", "Yunfeng", ""]]}, {"id": "2104.09866", "submitter": "Elahe Arani", "authors": "Prashant Bhat, Elahe Arani, and Bahram Zonooz", "title": "Distill on the Go: Online knowledge distillation in self-supervised\n  learning", "comments": "Spotlight @ Learning from Limited or Imperfect Data (L2ID) Workshop -\n  CVPR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Self-supervised learning solves pretext prediction tasks that do not require\nannotations to learn feature representations. For vision tasks, pretext tasks\nsuch as predicting rotation, solving jigsaw are solely created from the input\ndata. Yet, predicting this known information helps in learning representations\nuseful for downstream tasks. However, recent works have shown that wider and\ndeeper models benefit more from self-supervised learning than smaller models.\nTo address the issue of self-supervised pre-training of smaller models, we\npropose Distill-on-the-Go (DoGo), a self-supervised learning paradigm using\nsingle-stage online knowledge distillation to improve the representation\nquality of the smaller models. We employ deep mutual learning strategy in which\ntwo models collaboratively learn from each other to improve one another.\nSpecifically, each model is trained using self-supervised learning along with\ndistillation that aligns each model's softmax probabilities of similarity\nscores with that of the peer model. We conduct extensive experiments on\nmultiple benchmark datasets, learning objectives, and architectures to\ndemonstrate the potential of our proposed method. Our results show significant\nperformance gain in the presence of noisy and limited labels and generalization\nto out-of-distribution data.\n", "versions": [{"version": "v1", "created": "Tue, 20 Apr 2021 09:59:23 GMT"}, {"version": "v2", "created": "Wed, 30 Jun 2021 13:03:14 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Bhat", "Prashant", ""], ["Arani", "Elahe", ""], ["Zonooz", "Bahram", ""]]}, {"id": "2104.09872", "submitter": "Jiwei Guan", "authors": "Jiwei Guan, Xi Zheng, Chen Wang, Yipeng Zhou and Alireza Jolfa", "title": "Robust Sensor Fusion Algorithms Against Voice Command Attacks in\n  Autonomous Vehicles", "comments": "8 pages, 2 tables, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With recent advances in autonomous driving, Voice Control Systems have become\nincreasingly adopted as human-vehicle interaction methods. This technology\nenables drivers to use voice commands to control the vehicle and will be soon\navailable in Advanced Driver Assistance Systems (ADAS). Prior work has shown\nthat Siri, Alexa and Cortana, are highly vulnerable to inaudible command\nattacks. This could be extended to ADAS in real-world applications and such\ninaudible command threat is difficult to detect due to microphone\nnonlinearities. In this paper, we aim to develop a more practical solution by\nusing camera views to defend against inaudible command attacks where ADAS are\ncapable of detecting their environment via multi-sensors. To this end, we\npropose a novel multimodal deep learning classification system to defend\nagainst inaudible command attacks. Our experimental results confirm the\nfeasibility of the proposed defense methods and the best classification\naccuracy reaches 89.2%. Code is available at\nhttps://github.com/ITSEG-MQ/Sensor-Fusion-Against-VoiceCommand-Attacks.\n", "versions": [{"version": "v1", "created": "Tue, 20 Apr 2021 10:08:46 GMT"}, {"version": "v2", "created": "Fri, 9 Jul 2021 01:47:53 GMT"}], "update_date": "2021-07-12", "authors_parsed": [["Guan", "Jiwei", ""], ["Zheng", "Xi", ""], ["Wang", "Chen", ""], ["Zhou", "Yipeng", ""], ["Jolfa", "Alireza", ""]]}, {"id": "2104.09874", "submitter": "David Montero", "authors": "David Montero, Marcos Nieto, Peter Leskovsky and Naiara Aginako", "title": "Boosting Masked Face Recognition with Multi-Task ArcFace", "comments": "6 pages, 4 figures. The paper is under consideration at Pattern\n  Recognition Letters", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  In this paper, we address the problem of face recognition with masks. Given\nthe global health crisis caused by COVID-19, mouth and nose-covering masks have\nbecome an essential everyday-clothing-accessory. This sanitary measure has put\nthe state-of-the-art face recognition models on the ropes since they have not\nbeen designed to work with masked faces. In addition, the need has arisen for\napplications capable of detecting whether the subjects are wearing masks to\ncontrol the spread of the virus. To overcome these problems a full training\npipeline is presented based on the ArcFace work, with several modifications for\nthe backbone and the loss function. From the original face-recognition dataset,\na masked version is generated using data augmentation, and both datasets are\ncombined during the training process. The selected network, based on ResNet-50,\nis modified to also output the probability of mask usage without adding any\ncomputational cost. Furthermore, the ArcFace loss is combined with the\nmask-usage classification loss, resulting in a new function named Multi-Task\nArcFace (MTArcFace). Experimental results show that the proposed approach\nhighly boosts the original model accuracy when dealing with masked faces, while\npreserving almost the same accuracy on the original non-masked datasets.\nFurthermore, it achieves an average accuracy of 99.78% in mask-usage\nclassification.\n", "versions": [{"version": "v1", "created": "Tue, 20 Apr 2021 10:12:04 GMT"}, {"version": "v2", "created": "Wed, 21 Apr 2021 06:54:29 GMT"}], "update_date": "2021-04-22", "authors_parsed": [["Montero", "David", ""], ["Nieto", "Marcos", ""], ["Leskovsky", "Peter", ""], ["Aginako", "Naiara", ""]]}, {"id": "2104.09876", "submitter": "Yan Qin", "authors": "Yan Qin, Wen-tai Li, Chau Yuen, Wayes Tushar, and Tapan Kumar Saha", "title": "IIoT-Enabled Health Monitoring for Integrated Heat Pump System Using\n  Mixture Slow Feature Analysis", "comments": "This paper has been accepted by IEEE Transaction on Industrial\n  informatics 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The sustaining evolution of sensing and advancement in communications\ntechnologies have revolutionized prognostics and health management for various\nelectrical equipment towards data-driven ways. This revolution delivers a\npromising solution for the health monitoring problem of heat pump (HP) system,\na vital device widely deployed in modern buildings for heating use, to timely\nevaluate its operation status to avoid unexpected downtime. Many HPs were\npractically manufactured and installed many years ago, resulting in fewer\nsensors available due to technology limitations and cost control at that time.\nIt raises a dilemma to safeguard HPs at an affordable cost. We propose a hybrid\nscheme by integrating industrial Internet-of-Things (IIoT) and intelligent\nhealth monitoring algorithms to handle this challenge. To start with, an IIoT\nnetwork is constructed to sense and store measurements. Specifically,\ntemperature sensors are properly chosen and deployed at the inlet and outlet of\nthe water tank to measure water temperature. Second, with temperature\ninformation, we propose an unsupervised learning algorithm named mixture slow\nfeature analysis (MSFA) to timely evaluate the health status of the integrated\nHP. Characterized by frequent operation switches of different HPs due to the\nvariable demand for hot water, various heating patterns with different heating\nspeeds are observed. Slowness, a kind of dynamics to measure the varying speed\nof steady distribution, is properly considered in MSFA for both heating pattern\ndivision and health evaluation. Finally, the efficacy of the proposed method is\nverified through a real integrated HP with five connected HPs installed ten\nyears ago. The experimental results show that MSFA is capable of accurately\nidentifying health status of the system, especially failure at a preliminary\nstage compared to its competing algorithms.\n", "versions": [{"version": "v1", "created": "Tue, 20 Apr 2021 10:16:04 GMT"}], "update_date": "2021-04-21", "authors_parsed": [["Qin", "Yan", ""], ["Li", "Wen-tai", ""], ["Yuen", "Chau", ""], ["Tushar", "Wayes", ""], ["Saha", "Tapan Kumar", ""]]}, {"id": "2104.09878", "submitter": "Roc\\'io", "authors": "Roc\\'io del Amor, La\\\"etitia Launet, Adri\\'an Colomer, Ana\\\"is\n  Moscard\\'o, Andr\\'es Mosquera-Zamudio, Carlos Monteagudo and Valery Naranjo", "title": "An Attention-based Weakly Supervised framework for Spitzoid Melanocytic\n  Lesion Diagnosis in WSI", "comments": "16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Melanoma is an aggressive neoplasm responsible for the majority of deaths\nfrom skin cancer. Specifically, spitzoid melanocytic tumors are one of the most\nchallenging melanocytic lesions due to their ambiguous morphological features.\nThe gold standard for its diagnosis and prognosis is the analysis of skin\nbiopsies. In this process, dermatopathologists visualize skin histology slides\nunder a microscope, in a high time-consuming and subjective task. In the last\nyears, computer-aided diagnosis (CAD) systems have emerged as a promising tool\nthat could support pathologists in daily clinical practice. Nevertheless, no\nautomatic CAD systems have yet been proposed for the analysis of spitzoid\nlesions. Regarding common melanoma, no proposed system allows both the\nselection of the tumoral region and the prediction of the diagnosis as benign\nor malignant. Motivated by this, we propose a novel end-to-end\nweakly-supervised deep learning model, based on inductive transfer learning\nwith an improved convolutional neural network (CNN) to refine the embedding\nfeatures of the latent space. The framework is composed of a source model in\ncharge of finding the tumor patch-level patterns, and a target model focuses on\nthe specific diagnosis of a biopsy. The latter retrains the backbone of the\nsource model through a multiple instance learning workflow to obtain the\nbiopsy-level scoring. To evaluate the performance of the proposed methods, we\nperform extensive experiments on a private skin database with spitzoid lesions.\nTest results reach an accuracy of 0.9231 and 0.80 for the source and the target\nmodels, respectively. Besides, the heat map findings are directly in line with\nthe clinicians' medical decision and even highlight, in some cases, patterns of\ninterest that were overlooked by the pathologist due to the huge workload.\n", "versions": [{"version": "v1", "created": "Tue, 20 Apr 2021 10:18:57 GMT"}], "update_date": "2021-04-21", "authors_parsed": [["del Amor", "Roc\u00edo", ""], ["Launet", "La\u00ebtitia", ""], ["Colomer", "Adri\u00e1n", ""], ["Moscard\u00f3", "Ana\u00efs", ""], ["Mosquera-Zamudio", "Andr\u00e9s", ""], ["Monteagudo", "Carlos", ""], ["Naranjo", "Valery", ""]]}, {"id": "2104.09880", "submitter": "Yu Shen", "authors": "Wentao Zhang, Yu Shen, Zheyu Lin, Yang Li, Xiaosen Li, Wen Ouyang,\n  Yangyu Tao, Zhi Yang, and Bin Cui", "title": "GMLP: Building Scalable and Flexible Graph Neural Networks with\n  Feature-Message Passing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent studies, neural message passing has proved to be an effective way\nto design graph neural networks (GNNs), which have achieved state-of-the-art\nperformance in many graph-based tasks. However, current neural-message passing\narchitectures typically need to perform an expensive recursive neighborhood\nexpansion in multiple rounds and consequently suffer from a scalability issue.\nMoreover, most existing neural-message passing schemes are inflexible since\nthey are restricted to fixed-hop neighborhoods and insensitive to the actual\ndemands of different nodes. We circumvent these limitations by a novel\nfeature-message passing framework, called Graph Multi-layer Perceptron (GMLP),\nwhich separates the neural update from the message passing. With such\nseparation, GMLP significantly improves the scalability and efficiency by\nperforming the message passing procedure in a pre-compute manner, and is\nflexible and adaptive in leveraging node feature messages over various levels\nof localities. We further derive novel variants of scalable GNNs under this\nframework to achieve the best of both worlds in terms of performance and\nefficiency. We conduct extensive evaluations on 11 benchmark datasets,\nincluding large-scale datasets like ogbn-products and an industrial dataset,\ndemonstrating that GMLP achieves not only the state-of-art performance, but\nalso high training scalability and efficiency.\n", "versions": [{"version": "v1", "created": "Tue, 20 Apr 2021 10:19:21 GMT"}], "update_date": "2021-04-21", "authors_parsed": [["Zhang", "Wentao", ""], ["Shen", "Yu", ""], ["Lin", "Zheyu", ""], ["Li", "Yang", ""], ["Li", "Xiaosen", ""], ["Ouyang", "Wen", ""], ["Tao", "Yangyu", ""], ["Yang", "Zhi", ""], ["Cui", "Bin", ""]]}, {"id": "2104.09907", "submitter": "Kaustubh Kulkarni", "authors": "Kaustubh Milind Kulkarni and Sucheth Shenoy", "title": "Table Tennis Stroke Recognition Using Two-Dimensional Human Pose\n  Estimation", "comments": "Accepted at CVPR Sports Workshop 2021 (7th International Workshop on\n  Computer Vision in Sports) (CVSports)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  We introduce a novel method for collecting table tennis video data and\nperform stroke detection and classification. A diverse dataset containing video\ndata of 11 basic strokes obtained from 14 professional table tennis players,\nsumming up to a total of 22111 videos has been collected using the proposed\nsetup. The temporal convolutional neural network model developed using 2D pose\nestimation performs multiclass classification of these 11 table tennis strokes\nwith a validation accuracy of 99.37%. Moreover, the neural network generalizes\nwell over the data of a player excluded from the training and validation\ndataset, classifying the fresh strokes with an overall best accuracy of 98.72%.\nVarious model architectures using machine learning and deep learning based\napproaches have been trained for stroke recognition and their performances have\nbeen compared and benchmarked. Inferences such as performance monitoring and\nstroke comparison of the players using the model have been discussed.\nTherefore, we are contributing to the development of a computer vision based\nsports analytics system for the sport of table tennis that focuses on the\npreviously unexploited aspect of the sport i.e., a player's strokes, which is\nextremely insightful for performance improvement.\n", "versions": [{"version": "v1", "created": "Tue, 20 Apr 2021 11:32:43 GMT"}, {"version": "v2", "created": "Mon, 31 May 2021 18:59:57 GMT"}], "update_date": "2021-06-02", "authors_parsed": [["Kulkarni", "Kaustubh Milind", ""], ["Shenoy", "Sucheth", ""]]}, {"id": "2104.09918", "submitter": "Ushasi Chaudhuri", "authors": "Ushasi Chaudhuri, Biplab Banerjee, Avik Bhattacharya, Mihai Datcu", "title": "CrossATNet - A Novel Cross-Attention Based Framework for Sketch-Based\n  Image Retrieval", "comments": "Accepted in Journal of Image and Vision Computing", "journal-ref": null, "doi": "10.1016/j.imavis.2020.104003", "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose a novel framework for cross-modal zero-shot learning (ZSL) in the\ncontext of sketch-based image retrieval (SBIR). Conventionally, the SBIR schema\nmainly considers simultaneous mappings among the two image views and the\nsemantic side information. Therefore, it is desirable to consider fine-grained\nclasses mainly in the sketch domain using highly discriminative and\nsemantically rich feature space. However, the existing deep generative\nmodeling-based SBIR approaches majorly focus on bridging the gaps between the\nseen and unseen classes by generating pseudo-unseen-class samples. Besides,\nviolating the ZSL protocol by not utilizing any unseen-class information during\ntraining, such techniques do not pay explicit attention to modeling the\ndiscriminative nature of the shared space. Also, we note that learning a\nunified feature space for both the multi-view visual data is a tedious task\nconsidering the significant domain difference between sketches and color\nimages. In this respect, as a remedy, we introduce a novel framework for\nzero-shot SBIR. While we define a cross-modal triplet loss to ensure the\ndiscriminative nature of the shared space, an innovative cross-modal attention\nlearning strategy is also proposed to guide feature extraction from the image\ndomain exploiting information from the respective sketch counterpart. In order\nto preserve the semantic consistency of the shared space, we consider a graph\nCNN-based module that propagates the semantic class topology to the shared\nspace. To ensure an improved response time during inference, we further explore\nthe possibility of representing the shared space in terms of hash codes.\nExperimental results obtained on the benchmark TU-Berlin and the Sketchy\ndatasets confirm the superiority of CrossATNet in yielding state-of-the-art\nresults.\n", "versions": [{"version": "v1", "created": "Tue, 20 Apr 2021 12:11:12 GMT"}], "update_date": "2021-04-22", "authors_parsed": [["Chaudhuri", "Ushasi", ""], ["Banerjee", "Biplab", ""], ["Bhattacharya", "Avik", ""], ["Datcu", "Mihai", ""]]}, {"id": "2104.09919", "submitter": "Oliver Hope", "authors": "Oliver Hope, Eiko Yoneki", "title": "GDDR: GNN-based Data-Driven Routing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We explore the feasibility of combining Graph Neural Network-based policy\narchitectures with Deep Reinforcement Learning as an approach to problems in\nsystems. This fits particularly well with operations on networks, which\nnaturally take the form of graphs. As a case study, we take the idea of\ndata-driven routing in intradomain traffic engineering, whereby the routing of\ndata in a network can be managed taking into account the data itself. The\nparticular subproblem which we examine is minimising link congestion in\nnetworks using knowledge of historic traffic flows. We show through experiments\nthat an approach using Graph Neural Networks (GNNs) performs at least as well\nas previous work using Multilayer Perceptron architectures. GNNs have the added\nbenefit that they allow for the generalisation of trained agents to different\nnetwork topologies with no extra work. Furthermore, we believe that this\ntechnique is applicable to a far wider selection of problems in systems\nresearch.\n", "versions": [{"version": "v1", "created": "Tue, 20 Apr 2021 12:12:17 GMT"}], "update_date": "2021-04-21", "authors_parsed": [["Hope", "Oliver", ""], ["Yoneki", "Eiko", ""]]}, {"id": "2104.09937", "submitter": "Yuge Shi", "authors": "Yuge Shi, Jeffrey Seely, Philip H.S. Torr, N. Siddharth, Awni Hannun,\n  Nicolas Usunier, Gabriel Synnaeve", "title": "Gradient Matching for Domain Generalization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Machine learning systems typically assume that the distributions of training\nand test sets match closely. However, a critical requirement of such systems in\nthe real world is their ability to generalize to unseen domains. Here, we\npropose an inter-domain gradient matching objective that targets domain\ngeneralization by maximizing the inner product between gradients from different\ndomains. Since direct optimization of the gradient inner product can be\ncomputationally prohibitive -- requires computation of second-order derivatives\n-- we derive a simpler first-order algorithm named Fish that approximates its\noptimization. We demonstrate the efficacy of Fish on 6 datasets from the Wilds\nbenchmark, which captures distribution shift across a diverse range of\nmodalities. Our method produces competitive results on these datasets and\nsurpasses all baselines on 4 of them. We perform experiments on both the Wilds\nbenchmark, which captures distribution shift in the real world, as well as\ndatasets in DomainBed benchmark that focuses more on synthetic-to-real\ntransfer. Our method produces competitive results on both benchmarks,\ndemonstrating its effectiveness across a wide range of domain generalization\ntasks.\n", "versions": [{"version": "v1", "created": "Tue, 20 Apr 2021 12:55:37 GMT"}, {"version": "v2", "created": "Sun, 11 Jul 2021 16:05:22 GMT"}, {"version": "v3", "created": "Wed, 14 Jul 2021 00:07:51 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Shi", "Yuge", ""], ["Seely", "Jeffrey", ""], ["Torr", "Philip H. S.", ""], ["Siddharth", "N.", ""], ["Hannun", "Awni", ""], ["Usunier", "Nicolas", ""], ["Synnaeve", "Gabriel", ""]]}, {"id": "2104.09940", "submitter": "Paul Piho", "authors": "Paul Piho, Jane Hillston", "title": "Active and sparse methods in smoothed model checking", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.LO cs.SY eess.SY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Smoothed model checking based on Gaussian process classification provides a\npowerful approach for statistical model checking of parametric continuous time\nMarkov chain models. The method constructs a model for the functional\ndependence of satisfaction probability on the Markov chain parameters. This is\ndone via Gaussian process inference methods from a limited number of\nobservations for different parameter combinations. In this work we consider\nextensions to smoothed model checking based on sparse variational methods and\nactive learning. Both are used successfully to improve the scalability of\nsmoothed model checking. In particular, we see that active learning-based ideas\nfor iteratively querying the simulation model for observations can be used to\nsteer the model-checking to more informative areas of the parameter space and\nthus improve sample efficiency. Online extensions of sparse variational\nGaussian process inference algorithms are demonstrated to provide a scalable\nmethod for implementing active learning approaches for smoothed model checking.\n", "versions": [{"version": "v1", "created": "Tue, 20 Apr 2021 13:03:25 GMT"}], "update_date": "2021-04-21", "authors_parsed": [["Piho", "Paul", ""], ["Hillston", "Jane", ""]]}, {"id": "2104.09943", "submitter": "Olga Lukyanova", "authors": "Oleg Nikitin, Olga Lukyanova, Alex Kunin", "title": "The principle of weight divergence facilitation for unsupervised pattern\n  recognition in spiking neural networks", "comments": "9 pages, 5 figures, submitted to the conference ICANN 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.AI cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Parallels between the signal processing tasks and biological neurons lead to\nan understanding of the principles of self-organized optimization of input\nsignal recognition. In the present paper, we discuss such similarities among\nbiological and technical systems. We propose the addition to the well-known\nSTDP synaptic plasticity rule to directs the weight modification towards the\nstate associated with the maximal difference between the background noise and\ncorrelated signals. The principle of physically constrained weight growth is\nused as a basis for such control of the modification of the weights. It is\nproposed, that biological synaptic straight modification is restricted by the\nexistence and production of bio-chemical 'substances' needed for plasticity\ndevelopment. In this paper, the information about the noise-to-signal ratio is\nused to control such a substances' production and storage and to drive the\nneuron's synaptic pressures towards the state with the best signal-to-noise\nratio. Several experiments with different input signal regimes are considered\nto understand the functioning of the proposed approach.\n", "versions": [{"version": "v1", "created": "Tue, 20 Apr 2021 13:11:15 GMT"}], "update_date": "2021-04-21", "authors_parsed": [["Nikitin", "Oleg", ""], ["Lukyanova", "Olga", ""], ["Kunin", "Alex", ""]]}, {"id": "2104.09946", "submitter": "Juan F. Montesinos", "authors": "Juan F. Montesinos and Venkatesh S. Kadandale and Gloria Haro", "title": "A cappella: Audio-visual Singing Voice Separation", "comments": "Extended version of Estimating Individual A Cappella Voices in Music\n  Videos with Singing Faces from Sight and Sound workshop, CVPR21", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Music source separation can be interpreted as the estimation of the\nconstituent music sources that a music clip is composed of. In this work, we\nexplore the single-channel singing voice separation problem from a multimodal\nperspective, by jointly learning from audio and visual modalities. To do so, we\npresent Acappella, a dataset spanning around 46 hours of a cappella solo\nsinging videos sourced from YouTube. We propose Y-Net, an audio-visual\nconvolutional neural network which achieves state-of-the-art singing voice\nseparation results on the Acappella dataset and compare it against its\naudio-only counterpart, U-Net, and a state-of-the-art audio-visual speech\nseparation model. Singing voice separation can be particularly challenging when\nthe audio mixture also comprises of other accompaniment voices and background\nsounds along with the target voice of interest. We demonstrate that our model\ncan outperform the baseline models in the singing voice separation task in such\nchallenging scenarios. The code, the pre-trained models and the dataset will be\npublicly available at https://ipcv.github.io/Acappella/\n", "versions": [{"version": "v1", "created": "Tue, 20 Apr 2021 13:17:06 GMT"}, {"version": "v2", "created": "Sun, 20 Jun 2021 12:33:34 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Montesinos", "Juan F.", ""], ["Kadandale", "Venkatesh S.", ""], ["Haro", "Gloria", ""]]}, {"id": "2104.09949", "submitter": "Stylianos Venieris", "authors": "Mario Almeida, Stefanos Laskaridis, Stylianos I. Venieris, Ilias\n  Leontiadis, Nicholas D. Lane", "title": "DynO: Dynamic Onloading of Deep Neural Networks from Cloud to Device", "comments": "Under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, there has been an explosive growth of mobile and embedded\napplications using convolutional neural networks(CNNs). To alleviate their\nexcessive computational demands, developers have traditionally resorted to\ncloud offloading, inducing high infrastructure costs and a strong dependence on\nnetworking conditions. On the other end, the emergence of powerful SoCs is\ngradually enabling on-device execution. Nonetheless, low- and mid-tier\nplatforms still struggle to run state-of-the-art CNNs sufficiently. In this\npaper, we present DynO, a distributed inference framework that combines the\nbest of both worlds to address several challenges, such as device\nheterogeneity, varying bandwidth and multi-objective requirements. Key\ncomponents that enable this are its novel CNN-specific data packing method,\nwhich exploits the variability of precision needs in different parts of the CNN\nwhen onloading computation, and its novel scheduler that jointly tunes the\npartition point and transferred data precision at run time to adapt inference\nto its execution environment. Quantitative evaluation shows that DynO\noutperforms the current state-of-the-art, improving throughput by over an order\nof magnitude over device-only execution and up to 7.9x over competing CNN\noffloading systems, with up to 60x less data transferred.\n", "versions": [{"version": "v1", "created": "Tue, 20 Apr 2021 13:20:15 GMT"}], "update_date": "2021-04-21", "authors_parsed": [["Almeida", "Mario", ""], ["Laskaridis", "Stefanos", ""], ["Venieris", "Stylianos I.", ""], ["Leontiadis", "Ilias", ""], ["Lane", "Nicholas D.", ""]]}, {"id": "2104.09958", "submitter": "Martin Engelcke", "authors": "Martin Engelcke, Oiwi Parker Jones, Ingmar Posner", "title": "GENESIS-V2: Inferring Unordered Object Representations without Iterative\n  Refinement", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Advances in object-centric generative models (OCGMs) have culminated in the\ndevelopment of a broad range of methods for unsupervised object segmentation\nand interpretable object-centric scene generation. These methods, however, are\nlimited to simulated and real-world datasets with limited visual complexity.\nMoreover, object representations are often inferred using RNNs which do not\nscale well to large images or iterative refinement which avoids imposing an\nunnatural ordering on objects in an image but requires the a priori\ninitialisation of a fixed number of object representations. In contrast to\nestablished paradigms, this work proposes an embedding-based approach in which\nembeddings of pixels are clustered in a differentiable fashion using a\nstochastic, non-parametric stick-breaking process. Similar to iterative\nrefinement, this clustering procedure also leads to randomly ordered object\nrepresentations, but without the need of initialising a fixed number of\nclusters a priori. This is used to develop a new model, GENESIS-V2, which can\ninfer a variable number of object representations without using RNNs or\niterative refinement. We show that GENESIS-V2 outperforms previous methods for\nunsupervised image segmentation and object-centric scene generation on\nestablished synthetic datasets as well as more complex real-world datasets.\n", "versions": [{"version": "v1", "created": "Tue, 20 Apr 2021 14:59:27 GMT"}, {"version": "v2", "created": "Wed, 21 Apr 2021 14:52:11 GMT"}], "update_date": "2021-04-22", "authors_parsed": [["Engelcke", "Martin", ""], ["Jones", "Oiwi Parker", ""], ["Posner", "Ingmar", ""]]}, {"id": "2104.09967", "submitter": "Dimitrios Iliadis", "authors": "Dimitrios Iliadis, Bernard De Baets, Willem Waegeman", "title": "Automated problem setting selection in multi-target prediction with\n  AutoMTP", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Algorithm Selection (AS) is concerned with the selection of the best-suited\nalgorithm out of a set of candidates for a given problem. The area of AS has\nreceived a lot of attention from machine learning researchers and\npractitioners, as positive results along this line of research can make\nexpertise in ML more readily accessible to experts in other domains as well as\nto the general public. Another quickly expanding area is that of Multi-Target\nPrediction (MTP). The ability to simultaneously predict multiple target\nvariables of diverse types makes MTP of interest for a plethora of\napplications. MTP embraces several subfields of machine learning, such as\nmulti-label classification, multi-target regression, multi-task learning,\ndyadic prediction, zero-shot learning, network inference, and matrix\ncompletion. This work combines the two above-mentioned areas by proposing\nAutoMTP, an automated framework that performs algorithm selection for MTP.\nAutoMTP is realized by adopting a rule-based system for the algorithm selection\nstep and a flexible neural network architecture that can be used for the\nseveral subfields of MTP.\n", "versions": [{"version": "v1", "created": "Mon, 19 Apr 2021 12:44:20 GMT"}], "update_date": "2021-04-21", "authors_parsed": [["Iliadis", "Dimitrios", ""], ["De Baets", "Bernard", ""], ["Waegeman", "Willem", ""]]}, {"id": "2104.09968", "submitter": "Ming-Chang Lee", "authors": "Ming-Chang Lee, Jia-Chun Lin, and Ernst Gunnar Gran", "title": "SALAD: Self-Adaptive Lightweight Anomaly Detection for Real-time\n  Recurrent Time Series", "comments": "11 pages, 10 figures, and 7 tables. In Proceedings of the 45th IEEE\n  Computer Society Signature Conference on Computers, Software, and\n  Applications (COMPSAC 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Real-world time series data often present recurrent or repetitive patterns\nand it is often generated in real time, such as transportation passenger\nvolume, network traffic, system resource consumption, energy usage, and human\ngait. Detecting anomalous events based on machine learning approaches in such\ntime series data has been an active research topic in many different areas.\nHowever, most machine learning approaches require labeled datasets, offline\ntraining, and may suffer from high computation complexity, consequently\nhindering their applicability. Providing a lightweight self-adaptive approach\nthat does not need offline training in advance and meanwhile is able to detect\nanomalies in real time could be highly beneficial. Such an approach could be\nimmediately applied and deployed on any commodity machine to provide timely\nanomaly alerts. To facilitate such an approach, this paper introduces SALAD,\nwhich is a Self-Adaptive Lightweight Anomaly Detection approach based on a\nspecial type of recurrent neural networks called Long Short-Term Memory (LSTM).\nInstead of using offline training, SALAD converts a target time series into a\nseries of average absolute relative error (AARE) values on the fly and predicts\nan AARE value for every upcoming data point based on short-term historical AARE\nvalues. If the difference between a calculated AARE value and its corresponding\nforecast AARE value is higher than a self-adaptive detection threshold, the\ncorresponding data point is considered anomalous. Otherwise, the data point is\nconsidered normal. Experiments based on two real-world open-source time series\ndatasets demonstrate that SALAD outperforms five other state-of-the-art anomaly\ndetection approaches in terms of detection accuracy. In addition, the results\nalso show that SALAD is lightweight and can be deployed on a commodity machine.\n", "versions": [{"version": "v1", "created": "Mon, 19 Apr 2021 10:36:23 GMT"}, {"version": "v2", "created": "Fri, 23 Apr 2021 00:19:52 GMT"}, {"version": "v3", "created": "Tue, 4 May 2021 12:10:54 GMT"}], "update_date": "2021-05-05", "authors_parsed": [["Lee", "Ming-Chang", ""], ["Lin", "Jia-Chun", ""], ["Gran", "Ernst Gunnar", ""]]}, {"id": "2104.09970", "submitter": "Claire Theobald", "authors": "Claire Theobald, Bastien Arcelin, Fr\\'ed\\'eric Pennerath, Brieuc\n  Conan-Guez, Miguel Couceiro, Amedeo Napoli", "title": "A Bayesian Convolutional Neural Network for Robust Galaxy Ellipticity\n  Regression", "comments": "17 pages, 12 figures, submitted to ECML-PKDD 2021 in the Applied Data\n  Science track", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Cosmic shear estimation is an essential scientific goal for large galaxy\nsurveys. It refers to the coherent distortion of distant galaxy images due to\nweak gravitational lensing along the line of sight. It can be used as a tracer\nof the matter distribution in the Universe. The unbiased estimation of the\nlocal value of the cosmic shear can be obtained via Bayesian analysis which\nrelies on robust estimation of the galaxies ellipticity (shape) posterior\ndistribution. This is not a simple problem as, among other things, the images\nmay be corrupted with strong background noise. For current and coming surveys,\nanother central issue in galaxy shape determination is the treatment of\nstatistically dominant overlapping (blended) objects. We propose a Bayesian\nConvolutional Neural Network based on Monte-Carlo Dropout to reliably estimate\nthe ellipticity of galaxies and the corresponding measurement uncertainties. We\nshow that while a convolutional network can be trained to correctly estimate\nwell calibrated aleatoric uncertainty, -- the uncertainty due to the presence\nof noise in the images -- it is unable to generate a trustworthy ellipticity\ndistribution when exposed to previously unseen data (i.e. here, blended\nscenes). By introducing a Bayesian Neural Network, we show how to reliably\nestimate the posterior predictive distribution of ellipticities along with\nrobust estimation of epistemic uncertainties. Experiments also show that\nepistemic uncertainty can detect inconsistent predictions due to unknown\nblended scenes.\n", "versions": [{"version": "v1", "created": "Tue, 20 Apr 2021 14:01:57 GMT"}], "update_date": "2021-04-21", "authors_parsed": [["Theobald", "Claire", ""], ["Arcelin", "Bastien", ""], ["Pennerath", "Fr\u00e9d\u00e9ric", ""], ["Conan-Guez", "Brieuc", ""], ["Couceiro", "Miguel", ""], ["Napoli", "Amedeo", ""]]}, {"id": "2104.09978", "submitter": "Karan Jindal", "authors": "Rahul Singh, Karan Jindal, Yufei Yu, Hanyu Yang, Tarun Joshi, Matthew\n  A. Campbell, Wayne B. Shoumaker", "title": "Robustness Tests of NLP Machine Learning Models: Search and Semantically\n  Replace", "comments": "18 pages, 2 figures, 18 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a strategy to assess the robustness of different machine\nlearning models that involve natural language processing (NLP). The overall\napproach relies upon a Search and Semantically Replace strategy that consists\nof two steps: (1) Search, which identifies important parts in the text; (2)\nSemantically Replace, which finds replacements for the important parts, and\nconstrains the replaced tokens with semantically similar words. We introduce\ndifferent types of Search and Semantically Replace methods designed\nspecifically for particular types of machine learning models. We also\ninvestigate the effectiveness of this strategy and provide a general framework\nto assess a variety of machine learning models. Finally, an empirical\ncomparison is provided of robustness performance among three different model\ntypes, each with a different text representation.\n", "versions": [{"version": "v1", "created": "Tue, 20 Apr 2021 14:05:36 GMT"}], "update_date": "2021-04-21", "authors_parsed": [["Singh", "Rahul", ""], ["Jindal", "Karan", ""], ["Yu", "Yufei", ""], ["Yang", "Hanyu", ""], ["Joshi", "Tarun", ""], ["Campbell", "Matthew A.", ""], ["Shoumaker", "Wayne B.", ""]]}, {"id": "2104.09981", "submitter": "Neil Dhir", "authors": "Neil Dhir, Henrique Hoeltgebaum, Niall Adams, Mark Briers, Anthony\n  Burke, Paul Jones", "title": "Prospective Artificial Intelligence Approaches for Active Cyber Defence", "comments": "5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Cybercriminals are rapidly developing new malicious tools that leverage\nartificial intelligence (AI) to enable new classes of adaptive and stealthy\nattacks. New defensive methods need to be developed to counter these threats.\nSome cybersecurity professionals are speculating AI will enable corresponding\nnew classes of active cyber defence measures -- is this realistic, or currently\nmostly hype? The Alan Turing Institute, with expert guidance from the UK\nNational Cyber Security Centre and Defence Science Technology Laboratory,\npublished a research roadmap for AI for ACD last year. This position paper\nupdates the roadmap for two of the most promising AI approaches --\nreinforcement learning and causal inference - and describes why they could help\ntip the balance back towards defenders.\n", "versions": [{"version": "v1", "created": "Tue, 20 Apr 2021 14:07:34 GMT"}], "update_date": "2021-04-21", "authors_parsed": [["Dhir", "Neil", ""], ["Hoeltgebaum", "Henrique", ""], ["Adams", "Niall", ""], ["Briers", "Mark", ""], ["Burke", "Anthony", ""], ["Jones", "Paul", ""]]}, {"id": "2104.09987", "submitter": "Alexandre Defossez", "authors": "Alexandre D\\'efossez, Yossi Adi, Gabriel Synnaeve", "title": "Differentiable Model Compression via Pseudo Quantization Noise", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose to add independent pseudo quantization noise to model parameters\nduring training to approximate the effect of a quantization operator. This\nmethod, DiffQ, is differentiable both with respect to the unquantized\nparameters, and the number of bits used. Given a single hyper-parameter\nexpressing the desired balance between the quantized model size and accuracy,\nDiffQ can optimize the number of bits used per individual weight or groups of\nweights, in a single training. We experimentally verify that our method\noutperforms state-of-the-art quantization techniques on several benchmarks and\narchitectures for image classification, language modeling, and audio source\nseparation. For instance, on the Wikitext-103 language modeling benchmark,\nDiffQ compresses a 16 layers transformer model by a factor of 8, equivalent to\n4 bits precision, while losing only 0.5 points of perplexity. Code is available\nat: https://github.com/facebookresearch/diffq\n", "versions": [{"version": "v1", "created": "Tue, 20 Apr 2021 14:14:03 GMT"}], "update_date": "2021-04-21", "authors_parsed": [["D\u00e9fossez", "Alexandre", ""], ["Adi", "Yossi", ""], ["Synnaeve", "Gabriel", ""]]}, {"id": "2104.09994", "submitter": "Pedro Miguel Sanchez Sanchez", "authors": "Valerian Rey, Pedro Miguel S\\'anchez S\\'anchez, Alberto Huertas\n  Celdr\\'an, G\\'er\\^ome Bovet, Martin Jaggi", "title": "Federated Learning for Malware Detection in IoT Devices", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This work investigates the possibilities enabled by federated learning\nconcerning IoT malware detection and studies security issues inherent to this\nnew learning paradigm. In this context, a framework that uses federated\nlearning to detect malware affecting IoT devices is presented. N-BaIoT, a\ndataset modeling network traffic of several real IoT devices while affected by\nmalware, has been used to evaluate the proposed framework. Both supervised and\nunsupervised federated models (multi-layer perceptron and autoencoder) able to\ndetect malware affecting seen and unseen IoT devices of N-BaIoT have been\ntrained and evaluated. Furthermore, their performance has been compared to two\ntraditional approaches. The first one lets each participant locally train a\nmodel using only its own data, while the second consists of making the\nparticipants share their data with a central entity in charge of training a\nglobal model. This comparison has shown that the use of more diverse and large\ndata, as done in the federated and centralized methods, has a considerable\npositive impact on the model performance. Besides, the federated models, while\npreserving the participant's privacy, show similar results as the centralized\nones. As an additional contribution and to measure the robustness of the\nfederated approach, an adversarial setup with several malicious participants\npoisoning the federated model has been considered. The baseline model\naggregation averaging step used in most federated learning algorithms appears\nhighly vulnerable to different attacks, even with a single adversary. The\nperformance of other model aggregation functions acting as countermeasures is\nthus evaluated under the same attack scenarios. These functions provide a\nsignificant improvement against malicious participants, but more efforts are\nstill needed to make federated approaches robust.\n", "versions": [{"version": "v1", "created": "Thu, 15 Apr 2021 13:14:22 GMT"}], "update_date": "2021-04-21", "authors_parsed": [["Rey", "Valerian", ""], ["S\u00e1nchez", "Pedro Miguel S\u00e1nchez", ""], ["Celdr\u00e1n", "Alberto Huertas", ""], ["Bovet", "G\u00e9r\u00f4me", ""], ["Jaggi", "Martin", ""]]}, {"id": "2104.10010", "submitter": "Olga Lukyanova", "authors": "Olga Lukyanova, Oleg Nikitin, Alex Kunin", "title": "BraidNet: procedural generation of neural networks for image\n  classification problems using braid theory", "comments": "9 pages, 8 figures, submitted to the conference ICANN 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.IT cs.LG math.GT math.IT", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  In this article, we propose the approach to procedural optimization of a\nneural network, based on the combination of information theory and braid\ntheory. The network studied in the article implemented with the intersections\nbetween the braid strands, as well as simplified networks (a network with\nstrands without intersections and a simple convolutional deep neural network),\nare used to solve various problems of multiclass image classification that\nallow us to analyze the comparative effectiveness of the proposed architecture.\nThe simulation results showed BraidNet's comparative advantage in learning\nspeed and classification accuracy.\n", "versions": [{"version": "v1", "created": "Tue, 20 Apr 2021 14:40:30 GMT"}], "update_date": "2021-04-21", "authors_parsed": [["Lukyanova", "Olga", ""], ["Nikitin", "Oleg", ""], ["Kunin", "Alex", ""]]}, {"id": "2104.10011", "submitter": "Daniel Koguciuk M.Sc.Eng.", "authors": "Daniel Koguciuk, Elahe Arani, Bahram Zonooz", "title": "Perceptual Loss for Robust Unsupervised Homography Estimation", "comments": "Accepted at Image Matching: Local Features & Beyond (CVPR 2021\n  Workshop)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Homography estimation is often an indispensable step in many computer vision\ntasks. The existing approaches, however, are not robust to illumination and/or\nlarger viewpoint changes. In this paper, we propose bidirectional implicit\nHomography Estimation (biHomE) loss for unsupervised homography estimation.\nbiHomE minimizes the distance in the feature space between the warped image\nfrom the source viewpoint and the corresponding image from the target\nviewpoint. Since we use a fixed pre-trained feature extractor and the only\nlearnable component of our framework is the homography network, we effectively\ndecouple the homography estimation from representation learning. We use an\nadditional photometric distortion step in the synthetic COCO dataset generation\nto better represent the illumination variation of the real-world scenarios. We\nshow that biHomE achieves state-of-the-art performance on synthetic COCO\ndataset, which is also comparable or better compared to supervised approaches.\nFurthermore, the empirical results demonstrate the robustness of our approach\nto illumination variation compared to existing methods.\n", "versions": [{"version": "v1", "created": "Tue, 20 Apr 2021 14:41:54 GMT"}], "update_date": "2021-04-21", "authors_parsed": [["Koguciuk", "Daniel", ""], ["Arani", "Elahe", ""], ["Zonooz", "Bahram", ""]]}, {"id": "2104.10036", "submitter": "Pankaj Mishra", "authors": "Pankaj Mishra, Riccardo Verk, Daniele Fornasier, Claudio Piciarelli,\n  Gian Luca Foresti", "title": "VT-ADL: A Vision Transformer Network for Image Anomaly Detection and\n  Localization", "comments": "6 Pages, 4 images, conference published paper", "journal-ref": "IEEE ISIE 2021", "doi": null, "report-no": "KD-003638", "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a transformer-based image anomaly detection and localization\nnetwork. Our proposed model is a combination of a reconstruction-based approach\nand patch embedding. The use of transformer networks helps to preserve the\nspatial information of the embedded patches, which are later processed by a\nGaussian mixture density network to localize the anomalous areas. In addition,\nwe also publish BTAD, a real-world industrial anomaly dataset. Our results are\ncompared with other state-of-the-art algorithms using publicly available\ndatasets like MNIST and MVTec.\n", "versions": [{"version": "v1", "created": "Tue, 20 Apr 2021 15:12:30 GMT"}], "update_date": "2021-04-21", "authors_parsed": [["Mishra", "Pankaj", ""], ["Verk", "Riccardo", ""], ["Fornasier", "Daniele", ""], ["Piciarelli", "Claudio", ""], ["Foresti", "Gian Luca", ""]]}, {"id": "2104.10044", "submitter": "Ang Li", "authors": "Yanfei Li, Tong Geng, Ang Li, Huimin Yu", "title": "BCNN: Binary Complex Neural Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Binarized neural networks, or BNNs, show great promise in edge-side\napplications with resource limited hardware, but raise the concerns of reduced\naccuracy. Motivated by the complex neural networks, in this paper we introduce\ncomplex representation into the BNNs and propose Binary complex neural network\n-- a novel network design that processes binary complex inputs and weights\nthrough complex convolution, but still can harvest the extraordinary\ncomputation efficiency of BNNs. To ensure fast convergence rate, we propose\nnovel BCNN based batch normalization function and weight initialization\nfunction. Experimental results on Cifar10 and ImageNet using state-of-the-art\nnetwork models (e.g., ResNet, ResNetE and NIN) show that BCNN can achieve\nbetter accuracy compared to the original BNN models. BCNN improves BNN by\nstrengthening its learning capability through complex representation and\nextending its applicability to complex-valued input data. The source code of\nBCNN will be released on GitHub.\n", "versions": [{"version": "v1", "created": "Sun, 28 Mar 2021 03:35:24 GMT"}], "update_date": "2021-04-21", "authors_parsed": [["Li", "Yanfei", ""], ["Geng", "Tong", ""], ["Li", "Ang", ""], ["Yu", "Huimin", ""]]}, {"id": "2104.10047", "submitter": "Ignacio Sarasua", "authors": "Ignacio Sarasua, Jonwong Lee, Christian Wachinger", "title": "Geometric Deep Learning on Anatomical Meshes for the Prediction of\n  Alzheimer's Disease", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV eess.IV", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Geometric deep learning can find representations that are optimal for a given\ntask and therefore improve the performance over pre-defined representations.\n  While current work has mainly focused on point representations, meshes also\ncontain connectivity information and are therefore a more comprehensive\ncharacterization of the underlying anatomical surface.\n  In this work, we evaluate four recent geometric deep learning approaches that\noperate on mesh representations.\n  These approaches can be grouped into template-free and template-based\napproaches, where the template-based methods need a more elaborate\npre-processing step with the definition of a common reference template and\ncorrespondences.\n  We compare the different networks for the prediction of Alzheimer's disease\nbased on the meshes of the hippocampus.\n  Our results show advantages for template-based methods in terms of accuracy,\nnumber of learnable parameters, and training speed.\n  While the template creation may be limiting for some applications,\nneuroimaging has a long history of building templates with automated tools\nreadily available.\n  Overall, working with meshes is more involved than working with simplistic\npoint clouds, but they also offer new avenues for designing geometric deep\nlearning architectures.\n", "versions": [{"version": "v1", "created": "Tue, 20 Apr 2021 15:17:13 GMT"}], "update_date": "2021-04-21", "authors_parsed": [["Sarasua", "Ignacio", ""], ["Lee", "Jonwong", ""], ["Wachinger", "Christian", ""]]}, {"id": "2104.10051", "submitter": "Steffen Czolbe", "authors": "Steffen Czolbe, Oswin Krause and Aasa Feragen", "title": "Semantic similarity metrics for learned image registration", "comments": "Published at MIDL 2021 (Oral). Reviews and discussion on Open Review:\n  https://openreview.net/forum?id=9M5cH--UdcC. arXiv admin note: text overlap\n  with arXiv:2011.05735", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose a semantic similarity metric for image registration. Existing\nmetrics like Euclidean Distance or Normalized Cross-Correlation focus on\naligning intensity values, giving difficulties with low intensity contrast or\nnoise. Our approach learns dataset-specific features that drive the\noptimization of a learning-based registration model. We train both an\nunsupervised approach using an auto-encoder, and a semi-supervised approach\nusing supplemental segmentation data to extract semantic features for image\nregistration. Comparing to existing methods across multiple image modalities\nand applications, we achieve consistently high registration accuracy. A learned\ninvariance to noise gives smoother transformations on low-quality images.\n", "versions": [{"version": "v1", "created": "Tue, 20 Apr 2021 15:23:58 GMT"}], "update_date": "2021-04-21", "authors_parsed": [["Czolbe", "Steffen", ""], ["Krause", "Oswin", ""], ["Feragen", "Aasa", ""]]}, {"id": "2104.10061", "submitter": "Vincent Schellekens", "authors": "Vincent Schellekens and Laurent Jacques", "title": "Asymmetric compressive learning guarantees with applications to\n  quantized sketches", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The compressive learning framework reduces the computational cost of training\non large-scale datasets. In a sketching phase, the data is first compressed to\na lightweight sketch vector, obtained by mapping the data samples through a\nwell-chosen feature map, and averaging those contributions. In a learning\nphase, the desired model parameters are then extracted from this sketch by\nsolving an optimization problem, which also involves a feature map. When the\nfeature map is identical during the sketching and learning phases, formal\nstatistical guarantees (excess risk bounds) have been proven.\n  However, the desirable properties of the feature map are different during\nsketching and learning (e.g. quantized outputs, and differentiability,\nrespectively). We thus study the relaxation where this map is allowed to be\ndifferent for each phase. First, we prove that the existing guarantees carry\nover to this asymmetric scheme, up to a controlled error term, provided some\nLimited Projected Distortion (LPD) property holds. We then instantiate this\nframework to the setting of quantized sketches, by proving that the LPD indeed\nholds for binary sketch contributions. Finally, we further validate the\napproach with numerical simulations, including a large-scale application in\naudio event classification.\n", "versions": [{"version": "v1", "created": "Tue, 20 Apr 2021 15:37:59 GMT"}], "update_date": "2021-04-21", "authors_parsed": [["Schellekens", "Vincent", ""], ["Jacques", "Laurent", ""]]}, {"id": "2104.10066", "submitter": "Christian Requena-Mesa", "authors": "Christian Requena-Mesa, Vitus Benson, Markus Reichstein, Jakob Runge,\n  Joachim Denzler", "title": "EarthNet2021: A large-scale dataset and challenge for Earth surface\n  forecasting as a guided video prediction task", "comments": "8 pages, 8 figures, accepted at CVPR2021 workshop EarthVision", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Satellite images are snapshots of the Earth surface. We propose to forecast\nthem. We frame Earth surface forecasting as the task of predicting satellite\nimagery conditioned on future weather. EarthNet2021 is a large dataset suitable\nfor training deep neural networks on the task. It contains Sentinel 2 satellite\nimagery at 20m resolution, matching topography and mesoscale (1.28km)\nmeteorological variables packaged into 32000 samples. Additionally we frame\nEarthNet2021 as a challenge allowing for model intercomparison. Resulting\nforecasts will greatly improve (>x50) over the spatial resolution found in\nnumerical models. This allows localized impacts from extreme weather to be\npredicted, thus supporting downstream applications such as crop yield\nprediction, forest health assessments or biodiversity monitoring. Find data,\ncode, and how to participate at www.earthnet.tech\n", "versions": [{"version": "v1", "created": "Fri, 16 Apr 2021 09:47:30 GMT"}], "update_date": "2021-04-21", "authors_parsed": [["Requena-Mesa", "Christian", ""], ["Benson", "Vitus", ""], ["Reichstein", "Markus", ""], ["Runge", "Jakob", ""], ["Denzler", "Joachim", ""]]}, {"id": "2104.10079", "submitter": "David Plans Dr.", "authors": "Nikola Dolezalova, Angus B. Reed, Alex Despotovic, Bernard Dillon\n  Obika, Davide Morelli, Mert Aral, David Plans", "title": "Development of an accessible 10-year Digital CArdioVAscular (DiCAVA)\n  risk assessment: a UK Biobank study", "comments": "28 pages, 3 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Background: Cardiovascular diseases (CVDs) are among the leading causes of\ndeath worldwide. Predictive scores providing personalised risk of developing\nCVD are increasingly used in clinical practice. Most scores, however, utilise a\nhomogenous set of features and require the presence of a physician.\n  Objective: The aim was to develop a new risk model (DiCAVA) using statistical\nand machine learning techniques that could be applied in a remote setting. A\nsecondary goal was to identify new patient-centric variables that could be\nincorporated into CVD risk assessments.\n  Methods: Across 466,052 participants, Cox proportional hazards (CPH) and\nDeepSurv models were trained using 608 variables derived from the UK Biobank to\ninvestigate the 10-year risk of developing a CVD. Data-driven feature selection\nreduced the number of features to 47, after which reduced models were trained.\nBoth models were compared to the Framingham score.\n  Results: The reduced CPH model achieved a c-index of 0.7443, whereas DeepSurv\nachieved a c-index of 0.7446. Both CPH and DeepSurv were superior in\ndetermining the CVD risk compared to Framingham score. Minimal difference was\nobserved when cholesterol and blood pressure were excluded from the models\n(CPH: 0.741, DeepSurv: 0.739). The models show very good calibration and\ndiscrimination on the test data.\n  Conclusion: We developed a cardiovascular risk model that has very good\npredictive capacity and encompasses new variables. The score could be\nincorporated into clinical practice and utilised in a remote setting, without\nthe need of including cholesterol. Future studies will focus on external\nvalidation across heterogeneous samples.\n", "versions": [{"version": "v1", "created": "Tue, 20 Apr 2021 16:01:50 GMT"}], "update_date": "2021-04-21", "authors_parsed": [["Dolezalova", "Nikola", ""], ["Reed", "Angus B.", ""], ["Despotovic", "Alex", ""], ["Obika", "Bernard Dillon", ""], ["Morelli", "Davide", ""], ["Aral", "Mert", ""], ["Plans", "David", ""]]}, {"id": "2104.10085", "submitter": "Kordian Gontarska", "authors": "Kordian Gontarska and Weronika Wrazen and Jossekin Beilharz and Robert\n  Schmid and Lauritz Thamsen and Andreas Polze", "title": "Predicting Medical Interventions from Vital Parameters: Towards a\n  Decision Support System for Remote Patient Monitoring", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cardiovascular diseases and heart failures in particular are the main cause\nof non-communicable disease mortality in the world. Constant patient monitoring\nenables better medical treatment as it allows practitioners to react on time\nand provide the appropriate treatment. Telemedicine can provide constant remote\nmonitoring so patients can stay in their homes, only requiring medical sensing\nequipment and network connections. A limiting factor for telemedical centers is\nthe amount of patients that can be monitored simultaneously. We aim to increase\nthis amount by implementing a decision support system. This paper investigates\na machine learning model to estimate a risk score based on patient vital\nparameters that allows sorting all cases every day to help practitioners focus\ntheir limited capacities on the most severe cases. The model we propose reaches\nan AUCROC of 0.84, whereas the baseline rule-based model reaches an AUCROC of\n0.73. Our results indicate that the usage of deep learning to improve the\nefficiency of telemedical centers is feasible. This way more patients could\nbenefit from better health-care through remote monitoring.\n", "versions": [{"version": "v1", "created": "Tue, 20 Apr 2021 16:13:37 GMT"}], "update_date": "2021-04-21", "authors_parsed": [["Gontarska", "Kordian", ""], ["Wrazen", "Weronika", ""], ["Beilharz", "Jossekin", ""], ["Schmid", "Robert", ""], ["Thamsen", "Lauritz", ""], ["Polze", "Andreas", ""]]}, {"id": "2104.10087", "submitter": "David Plans Dr.", "authors": "D. Morelli, N. Dolezalova, S. Ponzo, M. Colombo and D. Plans", "title": "Development of digitally obtainable 10-year risk scores for depression\n  and anxiety in the general population", "comments": "13 pages, 2 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  The burden of depression and anxiety in the world is rising. Identification\nof individuals at increased risk of developing these conditions would help to\ntarget them for prevention and ultimately reduce the healthcare burden. We\ndeveloped a 10-year predictive algorithm for depression and anxiety using the\nfull cohort of over 400,000 UK Biobank (UKB) participants without pre-existing\ndepression or anxiety using digitally obtainable information. From the initial\n204 variables selected from UKB, processed into > 520 features, iterative\nbackward elimination using Cox proportional hazards model was performed to\nselect predictors which account for the majority of its predictive capability.\nBaseline and reduced models were then trained for depression and anxiety using\nboth Cox and DeepSurv, a deep neural network approach to survival analysis. The\nbaseline Cox model achieved concordance of 0.813 and 0.778 on the validation\ndataset for depression and anxiety, respectively. For the DeepSurv model,\nrespective concordance indices were 0.805 and 0.774. After feature selection,\nthe depression model contained 43 predictors and the concordance index was\n0.801 for both Cox and DeepSurv. The reduced anxiety model, with 27 predictors,\nachieved concordance of 0.770 in both models. The final models showed good\ndiscrimination and calibration in the test datasets.We developed predictive\nrisk scores with high discrimination for depression and anxiety using the UKB\ncohort, incorporating predictors which are easily obtainable via smartphone. If\ndeployed in a digital solution, it would allow individuals to track their risk,\nas well as provide some pointers to how to decrease it through lifestyle\nchanges.\n", "versions": [{"version": "v1", "created": "Tue, 20 Apr 2021 16:16:56 GMT"}], "update_date": "2021-04-21", "authors_parsed": [["Morelli", "D.", ""], ["Dolezalova", "N.", ""], ["Ponzo", "S.", ""], ["Colombo", "M.", ""], ["Plans", "D.", ""]]}, {"id": "2104.10093", "submitter": "Gido van de Ven", "authors": "Gido M. van de Ven, Zhe Li, Andreas S. Tolias", "title": "Class-Incremental Learning with Generative Classifiers", "comments": "To appear in the IEEE Conference on Computer Vision and Pattern\n  Recognition Workshop (CVPR-W) on Continual Learning in Computer Vision\n  (CLVision) 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Incrementally training deep neural networks to recognize new classes is a\nchallenging problem. Most existing class-incremental learning methods store\ndata or use generative replay, both of which have drawbacks, while\n'rehearsal-free' alternatives such as parameter regularization or\nbias-correction methods do not consistently achieve high performance. Here, we\nput forward a new strategy for class-incremental learning: generative\nclassification. Rather than directly learning the conditional distribution\np(y|x), our proposal is to learn the joint distribution p(x,y), factorized as\np(x|y)p(y), and to perform classification using Bayes' rule. As a\nproof-of-principle, here we implement this strategy by training a variational\nautoencoder for each class to be learned and by using importance sampling to\nestimate the likelihoods p(x|y). This simple approach performs very well on a\ndiverse set of continual learning benchmarks, outperforming generative replay\nand other existing baselines that do not store data.\n", "versions": [{"version": "v1", "created": "Tue, 20 Apr 2021 16:26:14 GMT"}, {"version": "v2", "created": "Wed, 28 Apr 2021 09:19:48 GMT"}], "update_date": "2021-04-29", "authors_parsed": [["van de Ven", "Gido M.", ""], ["Li", "Zhe", ""], ["Tolias", "Andreas S.", ""]]}, {"id": "2104.10095", "submitter": "Zezhong Zhang", "authors": "Zezhong Zhang, Guangxu Zhu, Rui Wang, Vincent K. N. Lau, and Kaibin\n  Huang", "title": "Turning Channel Noise into an Accelerator for Over-the-Air Principal\n  Component Analysis", "comments": "30 pages,9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.DC cs.LG cs.NI eess.SP math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently years, the attempts on distilling mobile data into useful knowledge\nhas been led to the deployment of machine learning algorithms at the network\nedge. Principal component analysis (PCA) is a classic technique for extracting\nthe linear structure of a dataset, which is useful for feature extraction and\ndata compression. In this work, we propose the deployment of distributed PCA\nover a multi-access channel based on the algorithm of stochastic gradient\ndescent to learn the dominant feature space of a distributed dataset at\nmultiple devices. Over-the-air aggregation is adopted to reduce the\nmulti-access latency, giving the name over-the-air PCA. The novelty of this\ndesign lies in exploiting channel noise to accelerate the descent in the region\naround each saddle point encountered by gradient descent, thereby increasing\nthe convergence speed of over-the-air PCA. The idea is materialized by\nproposing a power-control scheme which detects the type of descent region and\ncontrolling the level of channel noise accordingly. The scheme is proved to\nachieve a faster convergence rate than in the case without power control.\n", "versions": [{"version": "v1", "created": "Tue, 20 Apr 2021 16:28:33 GMT"}, {"version": "v2", "created": "Wed, 21 Apr 2021 02:21:15 GMT"}], "update_date": "2021-04-22", "authors_parsed": [["Zhang", "Zezhong", ""], ["Zhu", "Guangxu", ""], ["Wang", "Rui", ""], ["Lau", "Vincent K. N.", ""], ["Huang", "Kaibin", ""]]}, {"id": "2104.10103", "submitter": "Wanli Qiao", "authors": "Wanli Qiao and Amarda Shehu", "title": "Space Partitioning and Regression Mode Seeking via a Mean-Shift-Inspired\n  Algorithm", "comments": "44 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The mean shift (MS) algorithm is a nonparametric method used to cluster\nsample points and find the local modes of kernel density estimates, using an\nidea based on iterative gradient ascent. In this paper we develop a\nmean-shift-inspired algorithm to estimate the modes of regression functions and\npartition the sample points in the input space. We prove convergence of the\nsequences generated by the algorithm and derive the non-asymptotic rates of\nconvergence of the estimated local modes for the underlying regression model.\nWe also demonstrate the utility of the algorithm for data-enabled discovery\nthrough an application on biomolecular structure data. An extension to subspace\nconstrained mean shift (SCMS) algorithm used to extract ridges of regression\nfunctions is briefly discussed.\n", "versions": [{"version": "v1", "created": "Tue, 20 Apr 2021 16:35:17 GMT"}], "update_date": "2021-04-21", "authors_parsed": [["Qiao", "Wanli", ""], ["Shehu", "Amarda", ""]]}, {"id": "2104.10105", "submitter": "S Chandra Mouli", "authors": "S Chandra Mouli and Bruno Ribeiro", "title": "Neural Networks for Learning Counterfactual G-Invariances from Single\n  Environments", "comments": "ICLR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite -- or maybe because of -- their astonishing capacity to fit data,\nneural networks are believed to have difficulties extrapolating beyond training\ndata distribution. This work shows that, for extrapolations based on finite\ntransformation groups, a model's inability to extrapolate is unrelated to its\ncapacity. Rather, the shortcoming is inherited from a learning hypothesis:\nExamples not explicitly observed with infinitely many training examples have\nunderspecified outcomes in the learner's model. In order to endow neural\nnetworks with the ability to extrapolate over group transformations, we\nintroduce a learning framework counterfactually-guided by the learning\nhypothesis that any group invariance to (known) transformation groups is\nmandatory even without evidence, unless the learner deems it inconsistent with\nthe training data. Unlike existing invariance-driven methods for\n(counterfactual) extrapolations, this framework allows extrapolations from a\nsingle environment. Finally, we introduce sequence and image extrapolation\ntasks that validate our framework and showcase the shortcomings of traditional\napproaches.\n", "versions": [{"version": "v1", "created": "Tue, 20 Apr 2021 16:35:35 GMT"}], "update_date": "2021-04-21", "authors_parsed": [["Mouli", "S Chandra", ""], ["Ribeiro", "Bruno", ""]]}, {"id": "2104.10108", "submitter": "David Plans Dr.", "authors": "Nikola Dolezalova, Massimo Cairo, Alex Despotovic, Adam T.C. Booth,\n  Angus B. Reed, Davide Morelli, David Plans", "title": "Development of a dynamic type 2 diabetes risk prediction tool: a UK\n  Biobank study", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Diabetes affects over 400 million people and is among the leading causes of\nmorbidity worldwide. Identification of high-risk individuals can support early\ndiagnosis and prevention of disease development through lifestyle changes.\nHowever, the majority of existing risk scores require information about\nblood-based factors which are not obtainable outside of the clinic. Here, we\naimed to develop an accessible solution that could be deployed digitally and at\nscale. We developed a predictive 10-year type 2 diabetes risk score using 301\nfeatures derived from 472,830 participants in the UK Biobank dataset while\nexcluding any features which are not easily obtainable by a smartphone. Using a\ndata-driven feature selection process, 19 features were included in the final\nreduced model. A Cox proportional hazards model slightly overperformed a\nDeepSurv model trained using the same features, achieving a concordance index\nof 0.818 (95% CI: 0.812-0.823), compared to 0.811 (95% CI: 0.806-0.815). The\nfinal model showed good calibration. This tool can be used for clinical\nscreening of individuals at risk of developing type 2 diabetes and to foster\npatient empowerment by broadening their knowledge of the factors affecting\ntheir personal risk.\n", "versions": [{"version": "v1", "created": "Tue, 20 Apr 2021 16:37:26 GMT"}], "update_date": "2021-04-21", "authors_parsed": [["Dolezalova", "Nikola", ""], ["Cairo", "Massimo", ""], ["Despotovic", "Alex", ""], ["Booth", "Adam T. C.", ""], ["Reed", "Angus B.", ""], ["Morelli", "Davide", ""], ["Plans", "David", ""]]}, {"id": "2104.10132", "submitter": "Claudio Gallicchio", "authors": "Claudio Gallicchio, Alessio Micheli, Luca Silvestri", "title": "Phase Transition Adaptation", "comments": "Accepted at IJCNN 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Artificial Recurrent Neural Networks are a powerful information processing\nabstraction, and Reservoir Computing provides an efficient strategy to build\nrobust implementations by projecting external inputs into high dimensional\ndynamical system trajectories. In this paper, we propose an extension of the\noriginal approach, a local unsupervised learning mechanism we call Phase\nTransition Adaptation, designed to drive the system dynamics towards the `edge\nof stability'. Here, the complex behavior exhibited by the system elicits an\nenhancement in its overall computational capacity. We show experimentally that\nour approach consistently achieves its purpose over several datasets.\n", "versions": [{"version": "v1", "created": "Tue, 20 Apr 2021 17:18:34 GMT"}], "update_date": "2021-04-21", "authors_parsed": [["Gallicchio", "Claudio", ""], ["Micheli", "Alessio", ""], ["Silvestri", "Luca", ""]]}, {"id": "2104.10133", "submitter": "Scott Ettinger", "authors": "Scott Ettinger, Shuyang Cheng, Benjamin Caine, Chenxi Liu, Hang Zhao,\n  Sabeek Pradhan, Yuning Chai, Ben Sapp, Charles Qi, Yin Zhou, Zoey Yang,\n  Aurelien Chouard, Pei Sun, Jiquan Ngiam, Vijay Vasudevan, Alexander McCauley,\n  Jonathon Shlens, Dragomir Anguelov", "title": "Large Scale Interactive Motion Forecasting for Autonomous Driving : The\n  Waymo Open Motion Dataset", "comments": "15 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As autonomous driving systems mature, motion forecasting has received\nincreasing attention as a critical requirement for planning. Of particular\nimportance are interactive situations such as merges, unprotected turns, etc.,\nwhere predicting individual object motion is not sufficient. Joint predictions\nof multiple objects are required for effective route planning. There has been a\ncritical need for high-quality motion data that is rich in both interactions\nand annotation to develop motion planning models. In this work, we introduce\nthe most diverse interactive motion dataset to our knowledge, and provide\nspecific labels for interacting objects suitable for developing joint\nprediction models. With over 100,000 scenes, each 20 seconds long at 10 Hz, our\nnew dataset contains more than 570 hours of unique data over 1750 km of\nroadways. It was collected by mining for interesting interactions between\nvehicles, pedestrians, and cyclists across six cities within the United States.\nWe use a high-accuracy 3D auto-labeling system to generate high quality 3D\nbounding boxes for each road agent, and provide corresponding high definition\n3D maps for each scene. Furthermore, we introduce a new set of metrics that\nprovides a comprehensive evaluation of both single agent and joint agent\ninteraction motion forecasting models. Finally, we provide strong baseline\nmodels for individual-agent prediction and joint-prediction. We hope that this\nnew large-scale interactive motion dataset will provide new opportunities for\nadvancing motion forecasting models.\n", "versions": [{"version": "v1", "created": "Tue, 20 Apr 2021 17:19:05 GMT"}], "update_date": "2021-04-21", "authors_parsed": [["Ettinger", "Scott", ""], ["Cheng", "Shuyang", ""], ["Caine", "Benjamin", ""], ["Liu", "Chenxi", ""], ["Zhao", "Hang", ""], ["Pradhan", "Sabeek", ""], ["Chai", "Yuning", ""], ["Sapp", "Ben", ""], ["Qi", "Charles", ""], ["Zhou", "Yin", ""], ["Yang", "Zoey", ""], ["Chouard", "Aurelien", ""], ["Sun", "Pei", ""], ["Ngiam", "Jiquan", ""], ["Vasudevan", "Vijay", ""], ["McCauley", "Alexander", ""], ["Shlens", "Jonathon", ""], ["Anguelov", "Dragomir", ""]]}, {"id": "2104.10150", "submitter": "Daniel Kowal", "authors": "Daniel R. Kowal", "title": "Bayesian subset selection and variable importance for interpretable\n  prediction and classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP stat.CO stat.ME", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Subset selection is a valuable tool for interpretable learning, scientific\ndiscovery, and data compression. However, classical subset selection is often\neschewed due to selection instability, computational bottlenecks, and lack of\npost-selection inference. We address these challenges from a Bayesian\nperspective. Given any Bayesian predictive model $\\mathcal{M}$, we elicit\npredictively-competitive subsets using linear decision analysis. The approach\nis customizable for (local) prediction or classification and provides\ninterpretable summaries of $\\mathcal{M}$. A key quantity is the acceptable\nfamily of subsets, which leverages the predictive distribution from\n$\\mathcal{M}$ to identify subsets that offer nearly-optimal prediction. The\nacceptable family spawns new (co-) variable importance metrics based on whether\nvariables (co-) appear in all, some, or no acceptable subsets. Crucially, the\nlinear coefficients for any subset inherit regularization and predictive\nuncertainty quantification via $\\mathcal{M}$. The proposed approach exhibits\nexcellent prediction, interval estimation, and variable selection for simulated\ndata, including $p=400 > n$. These tools are applied to a large education\ndataset with highly correlated covariates, where the acceptable family is\nespecially useful. Our analysis provides unique insights into the combination\nof environmental, socioeconomic, and demographic factors that predict\neducational outcomes, and features highly competitive prediction with\nremarkable stability.\n", "versions": [{"version": "v1", "created": "Tue, 20 Apr 2021 17:48:34 GMT"}], "update_date": "2021-04-21", "authors_parsed": [["Kowal", "Daniel R.", ""]]}, {"id": "2104.10154", "submitter": "Liang Pan", "authors": "Liang Pan, Xinyi Chen, Zhongang Cai, Junzhe Zhang, Haiyu Zhao, Shuai\n  Yi, Ziwei Liu", "title": "Variational Relational Point Completion Network", "comments": "15 pages, 13 figures, accepted to CVPR 2021 (Oral), project webpage:\n  https://paul007pl.github.io/projects/VRCNet.html", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Real-scanned point clouds are often incomplete due to viewpoint, occlusion,\nand noise. Existing point cloud completion methods tend to generate global\nshape skeletons and hence lack fine local details. Furthermore, they mostly\nlearn a deterministic partial-to-complete mapping, but overlook structural\nrelations in man-made objects. To tackle these challenges, this paper proposes\na variational framework, Variational Relational point Completion network\n(VRCNet) with two appealing properties: 1) Probabilistic Modeling. In\nparticular, we propose a dual-path architecture to enable principled\nprobabilistic modeling across partial and complete clouds. One path consumes\ncomplete point clouds for reconstruction by learning a point VAE. The other\npath generates complete shapes for partial point clouds, whose embedded\ndistribution is guided by distribution obtained from the reconstruction path\nduring training. 2) Relational Enhancement. Specifically, we carefully design\npoint self-attention kernel and point selective kernel module to exploit\nrelational point features, which refines local shape details conditioned on the\ncoarse completion. In addition, we contribute a multi-view partial point cloud\ndataset (MVP dataset) containing over 100,000 high-quality scans, which renders\npartial 3D shapes from 26 uniformly distributed camera poses for each 3D CAD\nmodel. Extensive experiments demonstrate that VRCNet outperforms\nstate-of-theart methods on all standard point cloud completion benchmarks.\nNotably, VRCNet shows great generalizability and robustness on real-world point\ncloud scans.\n", "versions": [{"version": "v1", "created": "Tue, 20 Apr 2021 17:53:40 GMT"}], "update_date": "2021-04-21", "authors_parsed": [["Pan", "Liang", ""], ["Chen", "Xinyi", ""], ["Cai", "Zhongang", ""], ["Zhang", "Junzhe", ""], ["Zhao", "Haiyu", ""], ["Yi", "Shuai", ""], ["Liu", "Ziwei", ""]]}, {"id": "2104.10157", "submitter": "Wilson Yan", "authors": "Wilson Yan, Yunzhi Zhang, Pieter Abbeel, Aravind Srinivas", "title": "VideoGPT: Video Generation using VQ-VAE and Transformers", "comments": "Project website: https://wilson1yan.github.io/videogpt/index.html", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present VideoGPT: a conceptually simple architecture for scaling\nlikelihood based generative modeling to natural videos. VideoGPT uses VQ-VAE\nthat learns downsampled discrete latent representations of a raw video by\nemploying 3D convolutions and axial self-attention. A simple GPT-like\narchitecture is then used to autoregressively model the discrete latents using\nspatio-temporal position encodings. Despite the simplicity in formulation and\nease of training, our architecture is able to generate samples competitive with\nstate-of-the-art GAN models for video generation on the BAIR Robot dataset, and\ngenerate high fidelity natural images from UCF-101 and Tumbler GIF Dataset\n(TGIF). We hope our proposed architecture serves as a reproducible reference\nfor a minimalistic implementation of transformer based video generation models.\nSamples and code are available at\nhttps://wilson1yan.github.io/videogpt/index.html\n", "versions": [{"version": "v1", "created": "Tue, 20 Apr 2021 17:58:03 GMT"}], "update_date": "2021-04-21", "authors_parsed": [["Yan", "Wilson", ""], ["Zhang", "Yunzhi", ""], ["Abbeel", "Pieter", ""], ["Srinivas", "Aravind", ""]]}, {"id": "2104.10180", "submitter": "Maxim Ziatdinov", "authors": "Maxim Ziatdinov, Sergei Kalinin", "title": "Robust Feature Disentanglement in Imaging Data via Joint Invariant\n  Variational Autoencoders: from Cards to Atoms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.data-an cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in imaging from celestial objects in astronomy visualized via\noptical and radio telescopes to atoms and molecules resolved via electron and\nprobe microscopes are generating immense volumes of imaging data, containing\ninformation about the structure of the universe from atomic to astronomic\nlevels. The classical deep convolutional neural network architectures\ntraditionally perform poorly on the data sets having a significant\norientational disorder, that is, having multiple copies of the same or similar\nobject in arbitrary orientation in the image plane. Similarly, while clustering\nmethods are well suited for classification into discrete classes and manifold\nlearning and variational autoencoders methods can disentangle representations\nof the data, the combined problem is ill-suited to a classical non-supervised\nlearning paradigm. Here we introduce a joint rotationally (and translationally)\ninvariant variational autoencoder (j-trVAE) that is ideally suited to the\nsolution of such a problem. The performance of this method is validated on\nseveral synthetic data sets and extended to high-resolution imaging data of\nelectron and scanning probe microscopy. We show that latent space behaviors\ndirectly comport to the known physics of ferroelectric materials and quantum\nsystems. We further note that the engineering of the latent space structure via\nimposed topological structure or directed graph relationship allows for\napplications in topological discovery and causal physical learning.\n", "versions": [{"version": "v1", "created": "Tue, 20 Apr 2021 18:01:55 GMT"}], "update_date": "2021-04-22", "authors_parsed": [["Ziatdinov", "Maxim", ""], ["Kalinin", "Sergei", ""]]}, {"id": "2104.10190", "submitter": "Tim G. J. Rudner", "authors": "Tim G. J. Rudner and Vitchyr H. Pong and Rowan McAllister and Yarin\n  Gal and Sergey Levine", "title": "Outcome-Driven Reinforcement Learning via Variational Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While reinforcement learning algorithms provide automated acquisition of\noptimal policies, practical application of such methods requires a number of\ndesign decisions, such as manually designing reward functions that not only\ndefine the task, but also provide sufficient shaping to accomplish it. In this\npaper, we discuss a new perspective on reinforcement learning, recasting it as\nthe problem of inferring actions that achieve desired outcomes, rather than a\nproblem of maximizing rewards. To solve the resulting outcome-directed\ninference problem, we establish a novel variational inference formulation that\nallows us to derive a well-shaped reward function which can be learned directly\nfrom environment interactions. From the corresponding variational objective, we\nalso derive a new probabilistic Bellman backup operator reminiscent of the\nstandard Bellman backup operator and use it to develop an off-policy algorithm\nto solve goal-directed tasks. We empirically demonstrate that this method\neliminates the need to design reward functions and leads to effective\ngoal-directed behaviors.\n", "versions": [{"version": "v1", "created": "Tue, 20 Apr 2021 18:16:21 GMT"}], "update_date": "2021-04-22", "authors_parsed": [["Rudner", "Tim G. J.", ""], ["Pong", "Vitchyr H.", ""], ["McAllister", "Rowan", ""], ["Gal", "Yarin", ""], ["Levine", "Sergey", ""]]}, {"id": "2104.10201", "submitter": "David Eriksson", "authors": "Ryan Turner, David Eriksson, Michael McCourt, Juha Kiili, Eero\n  Laaksonen, Zhen Xu, Isabelle Guyon", "title": "Bayesian Optimization is Superior to Random Search for Machine Learning\n  Hyperparameter Tuning: Analysis of the Black-Box Optimization Challenge 2020", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents the results and insights from the black-box optimization\n(BBO) challenge at NeurIPS 2020 which ran from July-October, 2020. The\nchallenge emphasized the importance of evaluating derivative-free optimizers\nfor tuning the hyperparameters of machine learning models. This was the first\nblack-box optimization challenge with a machine learning emphasis. It was based\non tuning (validation set) performance of standard machine learning models on\nreal datasets. This competition has widespread impact as black-box optimization\n(e.g., Bayesian optimization) is relevant for hyperparameter tuning in almost\nevery machine learning project as well as many applications outside of machine\nlearning. The final leaderboard was determined using the optimization\nperformance on held-out (hidden) objective functions, where the optimizers ran\nwithout human intervention. Baselines were set using the default settings of\nseveral open-source black-box optimization packages as well as random search.\n", "versions": [{"version": "v1", "created": "Tue, 20 Apr 2021 18:44:59 GMT"}], "update_date": "2021-04-22", "authors_parsed": [["Turner", "Ryan", ""], ["Eriksson", "David", ""], ["McCourt", "Michael", ""], ["Kiili", "Juha", ""], ["Laaksonen", "Eero", ""], ["Xu", "Zhen", ""], ["Guyon", "Isabelle", ""]]}, {"id": "2104.10207", "submitter": "Yongtao Liu", "authors": "Yongtao Liu, Rama K. Vasudevan, Kyle Kelley, Dohyung Kim, Yogesh\n  Sharma, Mahshid Ahmadi, Sergei V. Kalinin, and Maxim Ziatdinov", "title": "Decoding the shift-invariant data: applications for band-excitation\n  scanning probe microscopy", "comments": "17 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cond-mat.dis-nn cs.LG eess.IV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A shift-invariant variational autoencoder (shift-VAE) is developed as an\nunsupervised method for the analysis of spectral data in the presence of shifts\nalong the parameter axis, disentangling the physically-relevant shifts from\nother latent variables. Using synthetic data sets, we show that the shift-VAE\nlatent variables closely match the ground truth parameters. The shift VAE is\nextended towards the analysis of band-excitation piezoresponse force microscopy\n(BE-PFM) data, disentangling the resonance frequency shifts from the peak shape\nparameters in a model-free unsupervised manner. The extensions of this approach\ntowards denoising of data and model-free dimensionality reduction in imaging\nand spectroscopic data are further demonstrated. This approach is universal and\ncan also be extended to analysis of X-ray diffraction, photoluminescence, Raman\nspectra, and other data sets.\n", "versions": [{"version": "v1", "created": "Tue, 20 Apr 2021 18:54:51 GMT"}], "update_date": "2021-04-22", "authors_parsed": [["Liu", "Yongtao", ""], ["Vasudevan", "Rama K.", ""], ["Kelley", "Kyle", ""], ["Kim", "Dohyung", ""], ["Sharma", "Yogesh", ""], ["Ahmadi", "Mahshid", ""], ["Kalinin", "Sergei V.", ""], ["Ziatdinov", "Maxim", ""]]}, {"id": "2104.10213", "submitter": "George Papakostas Prof.", "authors": "N.-I. Galanis, P. Vafiadis, K.-G. Mirzaev, G.A. Papakostas", "title": "Machine Learning Meets Natural Language Processing -- The story so far", "comments": "13 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Natural Language Processing (NLP) has evolved significantly over the last\ndecade. This paper highlights the most important milestones of this period\nwhile trying to pinpoint the contribution of each individual model and\nalgorithm to the overall progress. Furthermore, it focuses on issues still\nremaining to be solved, emphasizing the groundbreaking proposals of\nTransformers, BERT, and all the similar attention-based models.\n", "versions": [{"version": "v1", "created": "Sat, 27 Mar 2021 16:41:34 GMT"}], "update_date": "2021-04-22", "authors_parsed": [["Galanis", "N. -I.", ""], ["Vafiadis", "P.", ""], ["Mirzaev", "K. -G.", ""], ["Papakostas", "G. A.", ""]]}, {"id": "2104.10215", "submitter": "Sopan Khosla", "authors": "Sopan Khosla, James Fiacco, Carolyn Rose", "title": "Evaluating the Impact of a Hierarchical Discourse Representation on\n  Entity Coreference Resolution Performance", "comments": "Also contains the Appendix. Accepted to NAACL 2021 as a short paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recent work on entity coreference resolution (CR) follows current trends in\nDeep Learning applied to embeddings and relatively simple task-related\nfeatures. SOTA models do not make use of hierarchical representations of\ndiscourse structure. In this work, we leverage automatically constructed\ndiscourse parse trees within a neural approach and demonstrate a significant\nimprovement on two benchmark entity coreference-resolution datasets. We explore\nhow the impact varies depending upon the type of mention.\n", "versions": [{"version": "v1", "created": "Tue, 20 Apr 2021 19:14:57 GMT"}], "update_date": "2021-04-22", "authors_parsed": [["Khosla", "Sopan", ""], ["Fiacco", "James", ""], ["Rose", "Carolyn", ""]]}, {"id": "2104.10217", "submitter": "Gabriel Mittag", "authors": "Gabriel Mittag, Saman Zadtootaghaj, Thilo Michael, Babak Naderi,\n  Sebastian M\\\"oller", "title": "Bias-Aware Loss for Training Image and Speech Quality Prediction Models\n  from Multiple Datasets", "comments": "Accepted at QoMEX 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ground truth used for training image, video, or speech quality prediction\nmodels is based on the Mean Opinion Scores (MOS) obtained from subjective\nexperiments. Usually, it is necessary to conduct multiple experiments, mostly\nwith different test participants, to obtain enough data to train quality models\nbased on machine learning. Each of these experiments is subject to an\nexperiment-specific bias, where the rating of the same file may be\nsubstantially different in two experiments (e.g. depending on the overall\nquality distribution). These different ratings for the same distortion levels\nconfuse neural networks during training and lead to lower performance. To\novercome this problem, we propose a bias-aware loss function that estimates\neach dataset's biases during training with a linear function and considers it\nwhile optimising the network weights. We prove the efficiency of the proposed\nmethod by training and validating quality prediction models on synthetic and\nsubjective image and speech quality datasets.\n", "versions": [{"version": "v1", "created": "Tue, 20 Apr 2021 19:20:11 GMT"}], "update_date": "2021-04-22", "authors_parsed": [["Mittag", "Gabriel", ""], ["Zadtootaghaj", "Saman", ""], ["Michael", "Thilo", ""], ["Naderi", "Babak", ""], ["M\u00f6ller", "Sebastian", ""]]}, {"id": "2104.10219", "submitter": "Zikang Xiong", "authors": "Zikang Xiong and Suresh Jagannathan", "title": "Scalable Synthesis of Verified Controllers in Deep Reinforcement\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.LG cs.SY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  There has been significant recent interest in devising verification\ntechniques for learning-enabled controllers (LECs) that manage safety-critical\nsystems. Given the opacity and lack of interpretability of the neural policies\nthat govern the behavior of such controllers, many existing approaches enforce\nsafety properties through the use of shields, a dynamic monitoring and repair\nmechanism that ensures a LEC does not emit actions that would violate desired\nsafety conditions. These methods, however, have shown to have significant\nscalability limitations because verification costs grow as problem\ndimensionality and objective complexity increase. In this paper, we propose a\nnew automated verification pipeline capable of synthesizing high-quality safety\nshields even when the problem domain involves hundreds of dimensions, or when\nthe desired objective involves stochastic perturbations, liveness\nconsiderations, and other complex non-functional properties. Our key insight\ninvolves separating safety verification from neural controller, using\npre-computed verified safety shields to constrain neural controller training\nwhich does not only focus on safety. Experimental results over a range of\nrealistic high-dimensional deep RL benchmarks demonstrate the effectiveness of\nour approach.\n", "versions": [{"version": "v1", "created": "Tue, 20 Apr 2021 19:30:29 GMT"}], "update_date": "2021-04-22", "authors_parsed": [["Xiong", "Zikang", ""], ["Jagannathan", "Suresh", ""]]}, {"id": "2104.10223", "submitter": "Luis Oala", "authors": "Saul Calderon-Ramirez and Luis Oala", "title": "More Than Meets The Eye: Semi-supervised Learning Under Non-IID Data", "comments": "Presented as a RobustML workshop paper at ICLR 2021. Both authors\n  contributed equally. This article extends arXiv:2006.07767", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A common heuristic in semi-supervised deep learning (SSDL) is to select\nunlabelled data based on a notion of semantic similarity to the labelled data.\nFor example, labelled images of numbers should be paired with unlabelled images\nof numbers instead of, say, unlabelled images of cars. We refer to this\npractice as semantic data set matching. In this work, we demonstrate the limits\nof semantic data set matching. We show that it can sometimes even degrade the\nperformance for a state of the art SSDL algorithm. We present and make\navailable a comprehensive simulation sandbox, called non-IID-SSDL, for stress\ntesting an SSDL algorithm under different degrees of distribution mismatch\nbetween the labelled and unlabelled data sets. In addition, we demonstrate that\nsimple density based dissimilarity measures in the feature space of a generic\nclassifier offer a promising and more reliable quantitative matching criterion\nto select unlabelled data before SSDL training.\n", "versions": [{"version": "v1", "created": "Tue, 20 Apr 2021 19:51:10 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Calderon-Ramirez", "Saul", ""], ["Oala", "Luis", ""]]}, {"id": "2104.10228", "submitter": "Lukasz Korycki", "authors": "{\\L}ukasz Korycki, Bartosz Krawczyk", "title": "Concept Drift Detection from Multi-Class Imbalanced Data Streams", "comments": "37th IEEE International Conference on Data Engineering (ICDE), 2021.\n  arXiv admin note: text overlap with arXiv:2009.09497", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Continual learning from data streams is among the most important topics in\ncontemporary machine learning. One of the biggest challenges in this domain\nlies in creating algorithms that can continuously adapt to arriving data.\nHowever, previously learned knowledge may become outdated, as streams evolve\nover time. This phenomenon is known as concept drift and must be detected to\nfacilitate efficient adaptation of the learning model. While there exists a\nplethora of drift detectors, all of them assume that we are dealing with\nroughly balanced classes. In the case of imbalanced data streams, those\ndetectors will be biased towards the majority classes, ignoring changes\nhappening in the minority ones. Furthermore, class imbalance may evolve over\ntime and classes may change their roles (majority becoming minority and vice\nversa). This is especially challenging in the multi-class setting, where\nrelationships among classes become complex. In this paper, we propose a\ndetailed taxonomy of challenges posed by concept drift in multi-class\nimbalanced data streams, as well as a novel trainable concept drift detector\nbased on Restricted Boltzmann Machine. It is capable of monitoring multiple\nclasses at once and using reconstruction error to detect changes in each of\nthem independently. Our detector utilizes a skew-insensitive loss function that\nallows it to handle multiple imbalanced distributions. Due to its trainable\nnature, it is capable of following changes in a stream and evolving class\nroles, as well as it can deal with local concept drift occurring in minority\nclasses. Extensive experimental study on multi-class drifting data streams,\nenriched with a detailed analysis of the impact of local drifts and changing\nimbalance ratios, confirms the high efficacy of our approach.\n", "versions": [{"version": "v1", "created": "Tue, 20 Apr 2021 20:03:54 GMT"}], "update_date": "2021-04-22", "authors_parsed": [["Korycki", "\u0141ukasz", ""], ["Krawczyk", "Bartosz", ""]]}, {"id": "2104.10241", "submitter": "Dapeng Zhao", "authors": "Dapeng Zhao", "title": "Predicting Human Trajectories by Learning and Matching Patterns", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Thesis document of the degree of Master of Science in Robotics of Carnegie\nMellon University School of Computer Science.\n", "versions": [{"version": "v1", "created": "Tue, 20 Apr 2021 20:36:27 GMT"}, {"version": "v2", "created": "Thu, 20 May 2021 16:07:52 GMT"}], "update_date": "2021-05-21", "authors_parsed": [["Zhao", "Dapeng", ""]]}, {"id": "2104.10249", "submitter": "Saba Dadsetan", "authors": "Saba Dadsetan, David Pichler, David Wilson, Naira Hovakimyan, Jennifer\n  Hobbs", "title": "Superpixels and Graph Convolutional Neural Networks for Efficient\n  Detection of Nutrient Deficiency Stress from Aerial Imagery", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Advances in remote sensing technology have led to the capture of massive\namounts of data. Increased image resolution, more frequent revisit times, and\nadditional spectral channels have created an explosion in the amount of data\nthat is available to provide analyses and intelligence across domains,\nincluding agriculture. However, the processing of this data comes with a cost\nin terms of computation time and money, both of which must be considered when\nthe goal of an algorithm is to provide real-time intelligence to improve\nefficiencies. Specifically, we seek to identify nutrient deficient areas from\nremotely sensed data to alert farmers to regions that require attention;\ndetection of nutrient deficient areas is a key task in precision agriculture as\nfarmers must quickly respond to struggling areas to protect their harvests.\nPast methods have focused on pixel-level classification (i.e. semantic\nsegmentation) of the field to achieve these tasks, often using deep learning\nmodels with tens-of-millions of parameters. In contrast, we propose a much\nlighter graph-based method to perform node-based classification. We first use\nSimple Linear Iterative Cluster (SLIC) to produce superpixels across the field.\nThen, to perform segmentation across the non-Euclidean domain of superpixels,\nwe leverage a Graph Convolutional Neural Network (GCN). This model has\n4-orders-of-magnitude fewer parameters than a CNN model and trains in a matter\nof minutes.\n", "versions": [{"version": "v1", "created": "Tue, 20 Apr 2021 21:18:16 GMT"}, {"version": "v2", "created": "Thu, 22 Apr 2021 00:44:11 GMT"}], "update_date": "2021-04-23", "authors_parsed": [["Dadsetan", "Saba", ""], ["Pichler", "David", ""], ["Wilson", "David", ""], ["Hovakimyan", "Naira", ""], ["Hobbs", "Jennifer", ""]]}, {"id": "2104.10255", "submitter": "Dushyant Sahoo", "authors": "Dushyant Sahoo and Christos Davatzikos", "title": "Extraction of Hierarchical Functional Connectivity Components in human\n  brain using Adversarial Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-bio.NC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The estimation of sparse hierarchical components reflecting patterns of the\nbrain's functional connectivity from rsfMRI data can contribute to our\nunderstanding of the brain's functional organization, and can lead to\nbiomarkers of diseases. However, inter-scanner variations and other confounding\nfactors pose a challenge to the robust and reproducible estimation of\nfunctionally-interpretable brain networks, and especially to reproducible\nbiomarkers. Moreover, the brain is believed to be organized hierarchically, and\nhence single-scale decompositions miss this hierarchy. The paper aims to use\ncurrent advancements in adversarial learning to estimate interpretable\nhierarchical patterns in the human brain using rsfMRI data, which are robust to\n\"adversarial effects\" such as inter-scanner variations. We write the estimation\nproblem as a minimization problem and solve it using alternating updates.\nExtensive experiments on simulation and a real-world dataset show high\nreproducibility of the components compared to other well-known methods.\n", "versions": [{"version": "v1", "created": "Tue, 20 Apr 2021 21:38:55 GMT"}], "update_date": "2021-04-22", "authors_parsed": [["Sahoo", "Dushyant", ""], ["Davatzikos", "Christos", ""]]}, {"id": "2104.10258", "submitter": "Leandro De Lima", "authors": "Leandro M. de Lima, Renato A. Krohling", "title": "Discovering an Aid Policy to Minimize Student Evasion Using Offline\n  Reinforcement Learning", "comments": "8 pages, 6 figures, accepted for publication in 2021 International\n  Joint Conference on Neural Networks (IJCNN 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  High dropout rates in tertiary education expose a lack of efficiency that\ncauses frustration of expectations and financial waste. Predicting students at\nrisk is not enough to avoid student dropout. Usually, an appropriate aid action\nmust be discovered and applied in the proper time for each student. To tackle\nthis sequential decision-making problem, we propose a decision support method\nto the selection of aid actions for students using offline reinforcement\nlearning to support decision-makers effectively avoid student dropout.\nAdditionally, a discretization of student's state space applying two different\nclustering methods is evaluated. Our experiments using logged data of real\nstudents shows, through off-policy evaluation, that the method should achieve\nroughly 1.0 to 1.5 times as much cumulative reward as the logged policy. So, it\nis feasible to help decision-makers apply appropriate aid actions and,\npossibly, reduce student dropout.\n", "versions": [{"version": "v1", "created": "Tue, 20 Apr 2021 21:45:19 GMT"}], "update_date": "2021-04-22", "authors_parsed": [["de Lima", "Leandro M.", ""], ["Krohling", "Renato A.", ""]]}, {"id": "2104.10289", "submitter": "Tanvir Ferdousi", "authors": "Tanvir Ferdousi, Lee W. Cohnstaedt, and Caterina M. Scoglio", "title": "A windowed correlation based feature selection method to improve time\n  series prediction of dengue fever cases", "comments": "13 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The performance of data-driven prediction models depends on the availability\nof data samples for model training. A model that learns about dengue fever\nincidence in a population uses historical data from that corresponding\nlocation. Poor performance in prediction can result in places with inadequate\ndata. This work aims to enhance temporally limited dengue case data by\nmethodological addition of epidemically relevant data from nearby locations as\npredictors (features). A novel framework is presented for windowing incidence\ndata and computing time-shifted correlation-based metrics to quantify feature\nrelevance. The framework ranks incidence data of adjacent locations around a\ntarget location by combining the correlation metric with two other metrics:\nspatial distance and local prevalence. Recurrent neural network-based\nprediction models achieve up to 33.6% accuracy improvement on average using the\nproposed method compared to using training data from the target location only.\nThese models achieved mean absolute error (MAE) values as low as 0.128 on [0,1]\nnormalized incidence data for a municipality with the highest dengue prevalence\nin Brazil's Espirito Santo. When predicting cases aggregated over geographical\necoregions, the models achieved accuracy improvements up to 16.5%, using only\n6.5% of incidence data from ranked feature sets. The paper also includes two\ntechniques for windowing time series data: fixed-sized windows and outbreak\ndetection windows. Both of these techniques perform comparably, while the\nwindow detection method uses less data for computations. The framework\npresented in this paper is application-independent, and it could improve the\nperformances of prediction models where data from spatially adjacent locations\nare available.\n", "versions": [{"version": "v1", "created": "Wed, 21 Apr 2021 00:28:28 GMT"}], "update_date": "2021-04-22", "authors_parsed": [["Ferdousi", "Tanvir", ""], ["Cohnstaedt", "Lee W.", ""], ["Scoglio", "Caterina M.", ""]]}, {"id": "2104.10299", "submitter": "Cho-Ying Wu", "authors": "Cho-Ying Wu, Ke Xu, Chin-Cheng Hsu, Ulrich Neumann", "title": "Voice2Mesh: Cross-Modal 3D Face Model Generation from Voices", "comments": "Project page: https://choyingw.github.io/works/Voice2Mesh/index.html", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GR cs.CV cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work focuses on the analysis that whether 3D face models can be learned\nfrom only the speech inputs of speakers. Previous works for cross-modal face\nsynthesis study image generation from voices. However, image synthesis includes\nvariations such as hairstyles, backgrounds, and facial textures, that are\narguably irrelevant to voice or without direct studies to show correlations. We\ninstead investigate the ability to reconstruct 3D faces to concentrate on only\ngeometry, which is more physiologically grounded. We propose both the\nsupervised learning and unsupervised learning frameworks. Especially we\ndemonstrate how unsupervised learning is possible in the absence of a direct\nvoice-to-3D-face dataset under limited availability of 3D face scans when the\nmodel is equipped with knowledge distillation. To evaluate the performance, we\nalso propose several metrics to measure the geometric fitness of two 3D faces\nbased on points, lines, and regions. We find that 3D face shapes can be\nreconstructed from voices. Experimental results suggest that 3D faces can be\nreconstructed from voices, and our method can improve the performance over the\nbaseline. The best performance gains (15% - 20%) on ear-to-ear distance ratio\nmetric (ER) coincides with the intuition that one can roughly envision whether\na speaker's face is overall wider or thinner only from a person's voice. See\nour project page for codes and data.\n", "versions": [{"version": "v1", "created": "Wed, 21 Apr 2021 01:14:50 GMT"}], "update_date": "2021-04-22", "authors_parsed": [["Wu", "Cho-Ying", ""], ["Xu", "Ke", ""], ["Hsu", "Chin-Cheng", ""], ["Neumann", "Ulrich", ""]]}, {"id": "2104.10314", "submitter": "Ye Xue", "authors": "Ye Xue, Vincent Lau, and Songfu Cai", "title": "Efficient Sparse Coding using Hierarchical Riemannian Pursuit", "comments": "This paper has been accepted by IEEE Transactions on Signal\n  Processing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT eess.SP math.IT", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Sparse coding is a class of unsupervised methods for learning a sparse\nrepresentation of the input data in the form of a linear combination of a\ndictionary and a sparse code. This learning framework has led to\nstate-of-the-art results in various image and video processing tasks. However,\nclassical methods learn the dictionary and the sparse code based on alternating\noptimizations, usually without theoretical guarantees for either optimality or\nconvergence due to non-convexity of the problem. Recent works on sparse coding\nwith a complete dictionary provide strong theoretical guarantees thanks to the\ndevelopment of the non-convex optimization. However, initial non-convex\napproaches learn the dictionary in the sparse coding problem sequentially in an\natom-by-atom manner, which leads to a long execution time. More recent works\nseek to directly learn the entire dictionary at once, which substantially\nreduces the execution time. However, the associated recovery performance is\ndegraded with a finite number of data samples. In this paper, we propose an\nefficient sparse coding scheme with a two-stage optimization. The proposed\nscheme leverages the global and local Riemannian geometry of the two-stage\noptimization problem and facilitates fast implementation for superb dictionary\nrecovery performance by a finite number of samples without atom-by-atom\ncalculation. We further prove that, with high probability, the proposed scheme\ncan exactly recover any atom in the target dictionary with a finite number of\nsamples if it is adopted to recover one atom of the dictionary. An application\non wireless sensor data compression is also proposed. Experiments on both\nsynthetic and real-world data verify the efficiency and effectiveness of the\nproposed scheme.\n", "versions": [{"version": "v1", "created": "Wed, 21 Apr 2021 02:16:44 GMT"}, {"version": "v2", "created": "Sat, 26 Jun 2021 12:25:53 GMT"}, {"version": "v3", "created": "Sun, 4 Jul 2021 12:03:45 GMT"}, {"version": "v4", "created": "Tue, 20 Jul 2021 06:49:48 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Xue", "Ye", ""], ["Lau", "Vincent", ""], ["Cai", "Songfu", ""]]}, {"id": "2104.10322", "submitter": "Sreya Francis", "authors": "Irene Tenison, Sreya Francis, Irina Rish", "title": "Gradient Masked Federated Optimization", "comments": null, "journal-ref": "ICLR 2021 Distributed and Private Machine Learning(DPML) Workshop", "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated Averaging (FedAVG) has become the most popular federated learning\nalgorithm due to its simplicity and low communication overhead. We use simple\nexamples to show that FedAVG has the tendency to sew together the optima across\nthe participating clients. These sewed optima exhibit poor generalization when\nused on a new client with new data distribution. Inspired by the invariance\nprinciples in (Arjovsky et al., 2019; Parascandolo et al., 2020), we focus on\nlearning a model that is locally optimal across the different clients\nsimultaneously. We propose a modification to FedAVG algorithm to include masked\ngradients (AND-mask from (Parascandolo et al., 2020)) across the clients and\nuses them to carry out an additional server model update. We show that this\nalgorithm achieves better accuracy (out-of-distribution) than FedAVG,\nespecially when the data is non-identically distributed across clients.\n", "versions": [{"version": "v1", "created": "Wed, 21 Apr 2021 02:45:47 GMT"}], "update_date": "2021-04-22", "authors_parsed": [["Tenison", "Irene", ""], ["Francis", "Sreya", ""], ["Rish", "Irina", ""]]}, {"id": "2104.10328", "submitter": "Yusuke Kida", "authors": "Yusuke Kida, Tatsuya Komatsu, Masahito Togami", "title": "Label-Synchronous Speech-to-Text Alignment for ASR Using Forward and\n  Backward Transformers", "comments": "Submitted to INTERSPEECH 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a novel label-synchronous speech-to-text alignment\ntechnique for automatic speech recognition (ASR). The speech-to-text alignment\nis a problem of splitting long audio recordings with un-aligned transcripts\ninto utterance-wise pairs of speech and text. Unlike conventional methods based\non frame-synchronous prediction, the proposed method re-defines the\nspeech-to-text alignment as a label-synchronous text mapping problem. This\nenables an accurate alignment benefiting from the strong inference ability of\nthe state-of-the-art attention-based encoder-decoder models, which cannot be\napplied to the conventional methods. Two different Transformer models named\nforward Transformer and backward Transformer are respectively used for\nestimating an initial and final tokens of a given speech segment based on\nend-of-sentence prediction with teacher-forcing. Experiments using the corpus\nof spontaneous Japanese (CSJ) demonstrate that the proposed method provides an\naccurate utterance-wise alignment, that matches the manually annotated\nalignment with as few as 0.2% errors. It is also confirmed that a\nTransformer-based hybrid CTC/Attention ASR model using the aligned speech and\ntext pairs as an additional training data reduces character error rates\nrelatively up to 59.0%, which is significantly better than 39.0% reduction by a\nconventional alignment method based on connectionist temporal classification\nmodel.\n", "versions": [{"version": "v1", "created": "Wed, 21 Apr 2021 03:05:12 GMT"}], "update_date": "2021-04-22", "authors_parsed": [["Kida", "Yusuke", ""], ["Komatsu", "Tatsuya", ""], ["Togami", "Masahito", ""]]}, {"id": "2104.10329", "submitter": "Wen Tang", "authors": "Wen Tang, Emilie Chouzenoux, Jean-Christophe Pesquet, and Hamid Krim", "title": "Deep Transform and Metric Learning Networks", "comments": "Accepted by ICASSP 2021. arXiv admin note: substantial text overlap\n  with arXiv:2002.07898", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Based on its great successes in inference and denosing tasks, Dictionary\nLearning (DL) and its related sparse optimization formulations have garnered a\nlot of research interest. While most solutions have focused on single layer\ndictionaries, the recently improved Deep DL methods have also fallen short on a\nnumber of issues. We hence propose a novel Deep DL approach where each DL layer\ncan be formulated and solved as a combination of one linear layer and a\nRecurrent Neural Network, where the RNN is flexibly regraded as a\nlayer-associated learned metric. Our proposed work unveils new insights between\nthe Neural Networks and Deep DL, and provides a novel, efficient and\ncompetitive approach to jointly learn the deep transforms and metrics.\nExtensive experiments are carried out to demonstrate that the proposed method\ncan not only outperform existing Deep DL, but also state-of-the-art generic\nConvolutional Neural Networks.\n", "versions": [{"version": "v1", "created": "Wed, 21 Apr 2021 03:10:15 GMT"}], "update_date": "2021-04-22", "authors_parsed": [["Tang", "Wen", ""], ["Chouzenoux", "Emilie", ""], ["Pesquet", "Jean-Christophe", ""], ["Krim", "Hamid", ""]]}, {"id": "2104.10340", "submitter": "Wangzhi Li", "authors": "Wangzhi Li, Yaxing Cai, Ujwal Dinesha, Yongjie Fu, Xuan Di", "title": "CVLight: Deep Reinforcement Learning for Adaptive Traffic Signal Control\n  with Connected Vehicles", "comments": "27 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.SY eess.SY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper develops a reinforcement learning (RL) scheme for adaptive traffic\nsignal control (ATSC), called \"CVLight\", that leverages data collected only\nfrom connected vehicles (CV). Seven types of RL models are proposed within this\nscheme that contain various state and reward representations, including\nincorporation of CV delay and green light duration into state and the usage of\nCV delay as reward. To further incorporate information of both CV and non-CV\ninto CVLight, an algorithm based on actor-critic, A2C-Full, is proposed where\nboth CV and non-CV information is used to train the critic network, while only\nCV information is used to update the policy network and execute optimal signal\ntiming. These models are compared at an isolated intersection under various CV\nmarket penetration rates. A full model with the best performance (i.e., minimum\naverage travel delay per vehicle) is then selected and applied to compare with\nstate-of-the-art benchmarks under different levels of traffic demands, turning\nproportions, and dynamic traffic demands, respectively. Two case studies are\nperformed on an isolated intersection and a corridor with three consecutive\nintersections located in Manhattan, New York, to further demonstrate the\neffectiveness of the proposed algorithm under real-world scenarios. Compared to\nother baseline models that use all vehicle information, the trained CVLight\nagent can efficiently control multiple intersections solely based on CV data\nand can achieve a similar or even greater performance when the CV penetration\nrate is no less than 20%.\n", "versions": [{"version": "v1", "created": "Wed, 21 Apr 2021 03:38:11 GMT"}], "update_date": "2021-04-22", "authors_parsed": [["Li", "Wangzhi", ""], ["Cai", "Yaxing", ""], ["Dinesha", "Ujwal", ""], ["Fu", "Yongjie", ""], ["Di", "Xuan", ""]]}, {"id": "2104.10343", "submitter": "Michael Hahn", "authors": "Michael Hahn, Dan Jurafsky, Richard Futrell", "title": "Sensitivity as a Complexity Measure for Sequence Classification Tasks", "comments": "Accepted by TACL. This is a pre-MIT Press publication version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a theoretical framework for understanding and predicting the\ncomplexity of sequence classification tasks, using a novel extension of the\ntheory of Boolean function sensitivity. The sensitivity of a function, given a\ndistribution over input sequences, quantifies the number of disjoint subsets of\nthe input sequence that can each be individually changed to change the output.\nWe argue that standard sequence classification methods are biased towards\nlearning low-sensitivity functions, so that tasks requiring high sensitivity\nare more difficult. To that end, we show analytically that simple lexical\nclassifiers can only express functions of bounded sensitivity, and we show\nempirically that low-sensitivity functions are easier to learn for LSTMs. We\nthen estimate sensitivity on 15 NLP tasks, finding that sensitivity is higher\non challenging tasks collected in GLUE than on simple text classification\ntasks, and that sensitivity predicts the performance both of simple lexical\nclassifiers and of vanilla BiLSTMs without pretrained contextualized\nembeddings. Within a task, sensitivity predicts which inputs are hard for such\nsimple models. Our results suggest that the success of massively pretrained\ncontextual representations stems in part because they provide representations\nfrom which information can be extracted by low-sensitivity decoders.\n", "versions": [{"version": "v1", "created": "Wed, 21 Apr 2021 03:56:59 GMT"}], "update_date": "2021-04-22", "authors_parsed": [["Hahn", "Michael", ""], ["Jurafsky", "Dan", ""], ["Futrell", "Richard", ""]]}, {"id": "2104.10347", "submitter": "Yali Wan", "authors": "Yali Wan and Marina Meila", "title": "A class of network models recoverable by spectral clustering", "comments": "15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Finding communities in networks is a problem that remains difficult, in spite\nof the amount of attention it has recently received. The Stochastic Block-Model\n(SBM) is a generative model for graphs with \"communities\" for which, because of\nits simplicity, the theoretical understanding has advanced fast in recent\nyears. In particular, there have been various results showing that simple\nversions of spectral clustering using the Normalized Laplacian of the graph can\nrecover the communities almost perfectly with high probability. Here we show\nthat essentially the same algorithm used for the SBM and for its extension\ncalled Degree-Corrected SBM, works on a wider class of Block-Models, which we\ncall Preference Frame Models, with essentially the same guarantees. Moreover,\nthe parametrization we introduce clearly exhibits the free parameters needed to\nspecify this class of models, and results in bounds that expose with more\nclarity the parameters that control the recovery error in this model class.\n", "versions": [{"version": "v1", "created": "Wed, 21 Apr 2021 04:22:18 GMT"}], "update_date": "2021-04-22", "authors_parsed": [["Wan", "Yali", ""], ["Meila", "Marina", ""]]}, {"id": "2104.10350", "submitter": "Chen Liang", "authors": "David Patterson, Joseph Gonzalez, Quoc Le, Chen Liang, Lluis-Miquel\n  Munguia, Daniel Rothchild, David So, Maud Texier, Jeff Dean", "title": "Carbon Emissions and Large Neural Network Training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The computation demand for machine learning (ML) has grown rapidly recently,\nwhich comes with a number of costs. Estimating the energy cost helps measure\nits environmental impact and finding greener strategies, yet it is challenging\nwithout detailed information. We calculate the energy use and carbon footprint\nof several recent large models-T5, Meena, GShard, Switch Transformer, and\nGPT-3-and refine earlier estimates for the neural architecture search that\nfound Evolved Transformer. We highlight the following opportunities to improve\nenergy efficiency and CO2 equivalent emissions (CO2e): Large but sparsely\nactivated DNNs can consume <1/10th the energy of large, dense DNNs without\nsacrificing accuracy despite using as many or even more parameters. Geographic\nlocation matters for ML workload scheduling since the fraction of carbon-free\nenergy and resulting CO2e vary ~5X-10X, even within the same country and the\nsame organization. We are now optimizing where and when large models are\ntrained. Specific datacenter infrastructure matters, as Cloud datacenters can\nbe ~1.4-2X more energy efficient than typical datacenters, and the ML-oriented\naccelerators inside them can be ~2-5X more effective than off-the-shelf\nsystems. Remarkably, the choice of DNN, datacenter, and processor can reduce\nthe carbon footprint up to ~100-1000X. These large factors also make\nretroactive estimates of energy cost difficult. To avoid miscalculations, we\nbelieve ML papers requiring large computational resources should make energy\nconsumption and CO2e explicit when practical. We are working to be more\ntransparent about energy use and CO2e in our future research. To help reduce\nthe carbon footprint of ML, we believe energy usage and CO2e should be a key\nmetric in evaluating models, and we are collaborating with MLPerf developers to\ninclude energy usage during training and inference in this industry standard\nbenchmark.\n", "versions": [{"version": "v1", "created": "Wed, 21 Apr 2021 04:44:25 GMT"}, {"version": "v2", "created": "Thu, 22 Apr 2021 17:57:23 GMT"}, {"version": "v3", "created": "Fri, 23 Apr 2021 14:26:29 GMT"}], "update_date": "2021-04-26", "authors_parsed": [["Patterson", "David", ""], ["Gonzalez", "Joseph", ""], ["Le", "Quoc", ""], ["Liang", "Chen", ""], ["Munguia", "Lluis-Miquel", ""], ["Rothchild", "Daniel", ""], ["So", "David", ""], ["Texier", "Maud", ""], ["Dean", "Jeff", ""]]}, {"id": "2104.10376", "submitter": "Kekai Sheng", "authors": "Yifan Xu, Kekai Sheng, Weiming Dong, Baoyuan Wu, Changsheng Xu,\n  Bao-Gang Hu", "title": "Towards Corruption-Agnostic Robust Domain Adaptation", "comments": "The first literature to investigate the topic of corruption-agnostic\n  robust domain adaptation, a new practical and challenging domain adaptation\n  setting", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Big progress has been achieved in domain adaptation in decades. Existing\nworks are always based on an ideal assumption that testing target domain are\ni.i.d. with training target domains. However, due to unpredictable corruptions\n(e.g., noise and blur) in real data like web images, domain adaptation methods\nare increasingly required to be corruption robust on target domains. In this\npaper, we investigate a new task, Corruption-agnostic Robust Domain Adaptation\n(CRDA): to be accurate on original data and robust against\nunavailable-for-training corruptions on target domains. This task is\nnon-trivial due to large domain discrepancy and unsupervised target domains. We\nobserve that simple combinations of popular methods of domain adaptation and\ncorruption robustness have sub-optimal CRDA results. We propose a new approach\nbased on two technical insights into CRDA: 1) an easy-to-plug module called\nDomain Discrepancy Generator (DDG) that generates samples that enlarge domain\ndiscrepancy to mimic unpredictable corruptions; 2) a simple but effective\nteacher-student scheme with contrastive loss to enhance the constraints on\ntarget domains. Experiments verify that DDG keeps or even improves performance\non original data and achieves better corruption robustness that baselines.\n", "versions": [{"version": "v1", "created": "Wed, 21 Apr 2021 06:27:48 GMT"}], "update_date": "2021-04-22", "authors_parsed": [["Xu", "Yifan", ""], ["Sheng", "Kekai", ""], ["Dong", "Weiming", ""], ["Wu", "Baoyuan", ""], ["Xu", "Changsheng", ""], ["Hu", "Bao-Gang", ""]]}, {"id": "2104.10377", "submitter": "Yujing Jiang", "authors": "Yujing Jiang, Xingjun Ma, Sarah Monazam Erfani and James Bailey", "title": "Dual Head Adversarial Training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) are known to be vulnerable to adversarial\nexamples/attacks, raising concerns about their reliability in safety-critical\napplications. A number of defense methods have been proposed to train robust\nDNNs resistant to adversarial attacks, among which adversarial training has so\nfar demonstrated the most promising results. However, recent studies have shown\nthat there exists an inherent tradeoff between accuracy and robustness in\nadversarially-trained DNNs. In this paper, we propose a novel technique Dual\nHead Adversarial Training (DH-AT) to further improve the robustness of existing\nadversarial training methods. Different from existing improved variants of\nadversarial training, DH-AT modifies both the architecture of the network and\nthe training strategy to seek more robustness. Specifically, DH-AT first\nattaches a second network head (or branch) to one intermediate layer of the\nnetwork, then uses a lightweight convolutional neural network (CNN) to\naggregate the outputs of the two heads. The training strategy is also adapted\nto reflect the relative importance of the two heads. We empirically show, on\nmultiple benchmark datasets, that DH-AT can bring notable robustness\nimprovements to existing adversarial training methods. Compared with TRADES,\none state-of-the-art adversarial training method, our DH-AT can improve the\nrobustness by 3.4% against PGD40 and 2.3% against AutoAttack, and also improve\nthe clean accuracy by 1.8%.\n", "versions": [{"version": "v1", "created": "Wed, 21 Apr 2021 06:31:33 GMT"}, {"version": "v2", "created": "Thu, 22 Apr 2021 06:01:25 GMT"}], "update_date": "2021-04-23", "authors_parsed": [["Jiang", "Yujing", ""], ["Ma", "Xingjun", ""], ["Erfani", "Sarah Monazam", ""], ["Bailey", "James", ""]]}, {"id": "2104.10378", "submitter": "Shuai Wang", "authors": "Guoliang Li, Shuai Wang, Jie Li, Rui Wang, Xiaohui Peng, and Tony Xiao\n  Han", "title": "Wireless Sensing With Deep Spectrogram Network and Primitive Based\n  Autoregressive Hybrid Channel Model", "comments": "12 pages, 5 pages, submitted to IEEE SPAWC 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG eess.SP math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human motion recognition (HMR) based on wireless sensing is a low-cost\ntechnique for scene understanding. Current HMR systems adopt support vector\nmachines (SVMs) and convolutional neural networks (CNNs) to classify radar\nsignals. However, whether a deeper learning model could improve the system\nperformance is currently not known. On the other hand, training a machine\nlearning model requires a large dataset, but data gathering from experiment is\ncost-expensive and time-consuming. Although wireless channel models can be\nadopted for dataset generation, current channel models are mostly designed for\ncommunication rather than sensing. To address the above problems, this paper\nproposes a deep spectrogram network (DSN) by leveraging the residual mapping\ntechnique to enhance the HMR performance. Furthermore, a primitive based\nautoregressive hybrid (PBAH) channel model is developed, which facilitates\nefficient training and testing dataset generation for HMR in a virtual\nenvironment. Experimental results demonstrate that the proposed PBAH channel\nmodel matches the actual experimental data very well and the proposed DSN\nachieves significantly smaller recognition error than that of CNN.\n", "versions": [{"version": "v1", "created": "Wed, 21 Apr 2021 06:33:01 GMT"}], "update_date": "2021-04-22", "authors_parsed": [["Li", "Guoliang", ""], ["Wang", "Shuai", ""], ["Li", "Jie", ""], ["Wang", "Rui", ""], ["Peng", "Xiaohui", ""], ["Han", "Tony Xiao", ""]]}, {"id": "2104.10398", "submitter": "Gian Maria Campedelli", "authors": "Gian Maria Campedelli, Mihovil Bartulovic, Kathleen M. Carley", "title": "Learning future terrorist targets through temporal meta-graphs", "comments": "19 pages, 18 figures", "journal-ref": "Sci Rep 11, 8533 (2021)", "doi": "10.1038/s41598-021-87709-7", "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In the last 20 years, terrorism has led to hundreds of thousands of deaths\nand massive economic, political, and humanitarian crises in several regions of\nthe world. Using real-world data on attacks occurred in Afghanistan and Iraq\nfrom 2001 to 2018, we propose the use of temporal meta-graphs and deep learning\nto forecast future terrorist targets. Focusing on three event dimensions, i.e.,\nemployed weapons, deployed tactics and chosen targets, meta-graphs map the\nconnections among temporally close attacks, capturing their operational\nsimilarities and dependencies. From these temporal meta-graphs, we derive\n2-day-based time series that measure the centrality of each feature within each\ndimension over time. Formulating the problem in the context of the strategic\nbehavior of terrorist actors, these multivariate temporal sequences are then\nutilized to learn what target types are at the highest risk of being chosen.\nThe paper makes two contributions. First, it demonstrates that engineering the\nfeature space via temporal meta-graphs produces richer knowledge than shallow\ntime-series that only rely on frequency of feature occurrences. Second, the\nperformed experiments reveal that bi-directional LSTM networks achieve superior\nforecasting performance compared to other algorithms, calling for future\nresearch aiming at fully discovering the potential of artificial intelligence\nto counter terrorist violence.\n", "versions": [{"version": "v1", "created": "Wed, 21 Apr 2021 08:09:57 GMT"}], "update_date": "2021-04-22", "authors_parsed": [["Campedelli", "Gian Maria", ""], ["Bartulovic", "Mihovil", ""], ["Carley", "Kathleen M.", ""]]}, {"id": "2104.10400", "submitter": "Xu Chenxin", "authors": "Chenxin Xu, Rong Xia, Yong Xiao, Yingyu Li, Guangming Shi, Kwang-cheng\n  Chen", "title": "Federated Traffic Synthesizing and Classification Using Generative\n  Adversarial Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  With the fast growing demand on new services and applications as well as the\nincreasing awareness of data protection, traditional centralized traffic\nclassification approaches are facing unprecedented challenges. This paper\nintroduces a novel framework, Federated Generative Adversarial Networks and\nAutomatic Classification (FGAN-AC), which integrates decentralized data\nsynthesizing with traffic classification. FGAN-AC is able to synthesize and\nclassify multiple types of service data traffic from decentralized local\ndatasets without requiring a large volume of manually labeled dataset or\ncausing any data leakage. Two types of data synthesizing approaches have been\nproposed and compared: computation-efficient FGAN\n(FGAN-\\uppercase\\expandafter{\\romannumeral1}) and communication-efficient FGAN\n(FGAN-\\uppercase\\expandafter{\\romannumeral2}). The former only implements a\nsingle CNN model for processing each local dataset and the later only requires\ncoordination of intermediate model training parameters. An automatic data\nclassification and model updating framework has been proposed to automatically\nidentify unknown traffic from the synthesized data samples and create new\npseudo-labels for model training. Numerical results show that our proposed\nframework has the ability to synthesize highly mixed service data traffic and\ncan significantly improve the traffic classification performance compared to\nexisting solutions.\n", "versions": [{"version": "v1", "created": "Wed, 21 Apr 2021 08:10:46 GMT"}], "update_date": "2021-04-22", "authors_parsed": [["Xu", "Chenxin", ""], ["Xia", "Rong", ""], ["Xiao", "Yong", ""], ["Li", "Yingyu", ""], ["Shi", "Guangming", ""], ["Chen", "Kwang-cheng", ""]]}, {"id": "2104.10401", "submitter": "Sang Hun Lee", "authors": "Sangrok Lee, Taekang Woo, Sang Hun Lee", "title": "Multi-Attention-Based Soft Partition Network for Vehicle\n  Re-Identification", "comments": "10 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Vehicle re-identification (Re-ID) distinguishes between the same vehicle and\nother vehicles in images. It is challenging due to significant intra-instance\ndifferences between identical vehicles from different views and subtle\ninter-instance differences of similar vehicles. Researchers have tried to\naddress this problem by extracting features robust to variations of viewpoints\nand environments. More recently, they tried to improve performance by using\nadditional metadata such as key points, orientation, and temporal information.\nAlthough these attempts have been relatively successful, they all require\nexpensive annotations. Therefore, this paper proposes a novel deep neural\nnetwork called a multi-attention-based soft partition (MUSP) network to solve\nthis problem. This network does not use metadata and only uses multiple soft\nattentions to identify a specific vehicle area. This function was performed by\nmetadata in previous studies. Experiments verified that MUSP achieved\nstate-of-the-art (SOTA) performance for the VehicleID dataset without any\nadditional annotations and was comparable to VeRi-776 and VERI-Wild.\n", "versions": [{"version": "v1", "created": "Wed, 21 Apr 2021 08:13:17 GMT"}], "update_date": "2021-04-22", "authors_parsed": [["Lee", "Sangrok", ""], ["Woo", "Taekang", ""], ["Lee", "Sang Hun", ""]]}, {"id": "2104.10403", "submitter": "Omid Esrafilian", "authors": "Omid Esrafilian, Harald Bayerlein, and David Gesbert", "title": "Model-aided Deep Reinforcement Learning for Sample-efficient UAV\n  Trajectory Design in IoT Networks", "comments": "6 pages, 2 figures, submitted to GLOBECOM 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Reinforcement Learning (DRL) is gaining attention as a potential\napproach to design trajectories for autonomous unmanned aerial vehicles (UAV)\nused as flying access points in the context of cellular or Internet of Things\n(IoT) connectivity. DRL solutions offer the advantage of on-the-go learning\nhence relying on very little prior contextual information. A corresponding\ndrawback however lies in the need for many learning episodes which severely\nrestricts the applicability of such approach in real-world time- and\nenergy-constrained missions. Here, we propose a model-aided deep Q-learning\napproach that, in contrast to previous work, considerably reduces the need for\nextensive training data samples, while still achieving the overarching goal of\nDRL, i.e to guide a battery-limited UAV towards an efficient data harvesting\ntrajectory, without prior knowledge of wireless channel characteristics and\nlimited knowledge of wireless node locations. The key idea consists in using a\nsmall subset of nodes as anchors (i.e. with known location) and learning a\nmodel of the propagation environment while implicitly estimating the positions\nof regular nodes. Interaction with the model allows us to train a deep\nQ-network (DQN) to approximate the optimal UAV control policy. We show that in\ncomparison with standard DRL approaches, the proposed model-aided approach\nrequires at least one order of magnitude less training data samples to reach\nidentical data collection performance, hence offering a first step towards\nmaking DRL a viable solution to the problem.\n", "versions": [{"version": "v1", "created": "Wed, 21 Apr 2021 08:25:11 GMT"}, {"version": "v2", "created": "Mon, 3 May 2021 07:54:33 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Esrafilian", "Omid", ""], ["Bayerlein", "Harald", ""], ["Gesbert", "David", ""]]}, {"id": "2104.10410", "submitter": "Manuel Dahmen", "authors": "Eike Cramer, Alexander Mitsos, Raul Tempone, Manuel Dahmen", "title": "Principal Component Density Estimation for Scenario Generation Using\n  Normalizing Flows", "comments": "15 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Neural networks-based learning of the distribution of non-dispatchable\nrenewable electricity generation from sources such as photovoltaics (PV) and\nwind as well as load demands has recently gained attention. Normalizing flow\ndensity models have performed particularly well in this task due to the\ntraining through direct log-likelihood maximization. However, research from the\nfield of image generation has shown that standard normalizing flows can only\nlearn smeared-out versions of manifold distributions and can result in the\ngeneration of noisy data. To avoid the generation of time series data with\nunrealistic noise, we propose a dimensionality-reducing flow layer based on the\nlinear principal component analysis (PCA) that sets up the normalizing flow in\na lower-dimensional space. We train the resulting principal component flow\n(PCF) on data of PV and wind power generation as well as load demand in Germany\nin the years 2013 to 2015. The results of this investigation show that the PCF\npreserves critical features of the original distributions, such as the\nprobability density and frequency behavior of the time series. The application\nof the PCF is, however, not limited to renewable power generation but rather\nextends to any data set, time series, or otherwise, which can be efficiently\nreduced using PCA.\n", "versions": [{"version": "v1", "created": "Wed, 21 Apr 2021 08:42:54 GMT"}], "update_date": "2021-04-22", "authors_parsed": [["Cramer", "Eike", ""], ["Mitsos", "Alexander", ""], ["Tempone", "Raul", ""], ["Dahmen", "Manuel", ""]]}, {"id": "2104.10415", "submitter": "YUqiong Qi", "authors": "Yuqiong Qi and Yang Hu and Haibin Wu and Shen Li and Haiyu Mao and\n  Xiaochun Ye and Dongrui Fan and Ninghui Sun", "title": "Tackling Variabilities in Autonomous Driving", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  The state-of-the-art driving automation system demands extreme computational\nresources to meet rigorous accuracy and latency requirements. Though emerging\ndriving automation computing platforms are based on ASIC to provide better\nperformance and power guarantee, building such an accelerator-based computing\nplatform for driving automation still present challenges. First, the workloads\nmix and performance requirements exposed to driving automation system present\nsignificant variability. Second, with more cameras/sensors integrated in a\nfuture fully autonomous driving vehicle, a heterogeneous multi-accelerator\narchitecture substrate is needed that requires a design space exploration for a\nnew form of parallelism. In this work, we aim to extensively explore the above\nsystem design challenges and these challenges motivate us to propose a\ncomprehensive framework that synergistically handles the heterogeneous hardware\naccelerator design principles, system design criteria, and task scheduling\nmechanism. Specifically, we propose a novel heterogeneous multi-core AI\naccelerator (HMAI) to provide the hardware substrate for the driving automation\ntasks with variability. We also define system design criteria to better utilize\nhardware resources and achieve increased throughput while satisfying the\nperformance and energy restrictions. Finally, we propose a deep reinforcement\nlearning (RL)-based task scheduling mechanism FlexAI, to resolve task mapping\nissue. Experimental results show that with FlexAI scheduling, basically 100%\ntasks in each driving route can be processed by HMAI within their required\nperiod to ensure safety, and FlexAI can also maximally reduce the breaking\ndistance up to 96% as compared to typical heuristics and guided\nrandom-search-based algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 21 Apr 2021 08:51:40 GMT"}], "update_date": "2021-04-22", "authors_parsed": [["Qi", "Yuqiong", ""], ["Hu", "Yang", ""], ["Wu", "Haibin", ""], ["Li", "Shen", ""], ["Mao", "Haiyu", ""], ["Ye", "Xiaochun", ""], ["Fan", "Dongrui", ""], ["Sun", "Ninghui", ""]]}, {"id": "2104.10424", "submitter": "Saiping Guan", "authors": "Saiping Guan, Xiaolong Jin, Jiafeng Guo, Yuanzhuo Wang, Xueqi Cheng", "title": "Link Prediction on N-ary Relational Data Based on Relatedness Evaluation", "comments": "Accepted to TKDE 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the overwhelming popularity of Knowledge Graphs (KGs), researchers have\npoured attention to link prediction to fill in missing facts for a long time.\nHowever, they mainly focus on link prediction on binary relational data, where\nfacts are usually represented as triples in the form of (head entity, relation,\ntail entity). In practice, n-ary relational facts are also ubiquitous. When\nencountering such facts, existing studies usually decompose them into triples\nby introducing a multitude of auxiliary virtual entities and additional\ntriples. These conversions result in the complexity of carrying out link\nprediction on n-ary relational data. It has even proven that they may cause\nloss of structure information. To overcome these problems, in this paper, we\nrepresent each n-ary relational fact as a set of its role and role-value pairs.\nWe then propose a method called NaLP to conduct link prediction on n-ary\nrelational data, which explicitly models the relatedness of all the role and\nrole-value pairs in an n-ary relational fact. We further extend NaLP by\nintroducing type constraints of roles and role-values without any external\ntype-specific supervision, and proposing a more reasonable negative sampling\nmechanism. Experimental results validate the effectiveness and merits of the\nproposed methods.\n", "versions": [{"version": "v1", "created": "Wed, 21 Apr 2021 09:06:54 GMT"}], "update_date": "2021-04-22", "authors_parsed": [["Guan", "Saiping", ""], ["Jin", "Xiaolong", ""], ["Guo", "Jiafeng", ""], ["Wang", "Yuanzhuo", ""], ["Cheng", "Xueqi", ""]]}, {"id": "2104.10425", "submitter": "Andreas Panteli", "authors": "Andreas Panteli, Jonas Teuwen, Hugo Horlings, Efstratios Gavves", "title": "Sparse-Shot Learning for Extremely Many Localisations", "comments": "14 pages, 7 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Object localisation is typically considered in the context of regular images,\nfor instance depicting objects like people or cars. In these images there is\ntypically a relatively small number of instances per image per class, which\nusually is manageable to annotate. However, outside the realm of regular images\nwe are often confronted with a different situation. In computational pathology\ndigitised tissue sections are extremely large images, whose dimensions quickly\nexceed 250'000x250'000 pixels, where relevant objects, such as tumour cells or\nlymphocytes can quickly number in the millions. Annotating them all is\npractically impossible and annotating sparsely a few, out of many more, is the\nonly possibility. Unfortunately, learning from sparse annotations, or\nsparse-shot learning, clashes with standard supervised learning because what is\nnot annotated is treated as a negative. However, assigning negative labels to\nwhat are true positives leads to confusion in the gradients and biased\nlearning. To this end, we present exclusive cross entropy, which slows down the\nbiased learning by examining the second-order loss derivatives in order to drop\nthe loss terms corresponding to likely biased terms. Experiments on nine\ndatasets and two different localisation tasks, detection with YOLLO and\nsegmentation with Unet, show that we obtain considerable improvements compared\nto cross entropy or focal loss, while often reaching the best possible\nperformance for the model with only 10-40 of annotations.\n", "versions": [{"version": "v1", "created": "Wed, 21 Apr 2021 09:09:54 GMT"}], "update_date": "2021-04-22", "authors_parsed": [["Panteli", "Andreas", ""], ["Teuwen", "Jonas", ""], ["Horlings", "Hugo", ""], ["Gavves", "Efstratios", ""]]}, {"id": "2104.10441", "submitter": "Tim Isbister", "authors": "Tim Isbister, Fredrik Carlsson, Magnus Sahlgren", "title": "Should we Stop Training More Monolingual Models, and Simply Use Machine\n  Translation Instead?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Most work in NLP makes the assumption that it is desirable to develop\nsolutions in the native language in question. There is consequently a strong\ntrend towards building native language models even for low-resource languages.\nThis paper questions this development, and explores the idea of simply\ntranslating the data into English, thereby enabling the use of pretrained, and\nlarge-scale, English language models. We demonstrate empirically that a large\nEnglish language model coupled with modern machine translation outperforms\nnative language models in most Scandinavian languages. The exception to this is\nFinnish, which we assume is due to inferior translation quality. Our results\nsuggest that machine translation is a mature technology, which raises a serious\ncounter-argument for training native language models for low-resource\nlanguages. This paper therefore strives to make a provocative but important\npoint. As English language models are improving at an unprecedented pace, which\nin turn improves machine translation, it is from an empirical and environmental\nstand-point more effective to translate data from low-resource languages into\nEnglish, than to build language models for such languages.\n", "versions": [{"version": "v1", "created": "Wed, 21 Apr 2021 10:21:24 GMT"}], "update_date": "2021-04-22", "authors_parsed": [["Isbister", "Tim", ""], ["Carlsson", "Fredrik", ""], ["Sahlgren", "Magnus", ""]]}, {"id": "2104.10450", "submitter": "Erik Bodin", "authors": "Erik Bodin, Federico Tomasi, Zhenwen Dai", "title": "Making Differentiable Architecture Search less local", "comments": "ICLR 2021 Workshop on Neural Architecture Search", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural architecture search (NAS) is a recent methodology for automating the\ndesign of neural network architectures. Differentiable neural architecture\nsearch (DARTS) is a promising NAS approach that dramatically increases search\nefficiency. However, it has been shown to suffer from performance collapse,\nwhere the search often leads to detrimental architectures. Many recent works\ntry to address this issue of DARTS by identifying indicators for early\nstopping, regularising the search objective to reduce the dominance of some\noperations, or changing the parameterisation of the search problem. In this\nwork, we hypothesise that performance collapses can arise from poor local\noptima around typical initial architectures and weights. We address this issue\nby developing a more global optimisation scheme that is able to better explore\nthe space without changing the DARTS problem formulation. Our experiments show\nthat our changes in the search algorithm allow the discovery of architectures\nwith both better test performance and fewer parameters.\n", "versions": [{"version": "v1", "created": "Wed, 21 Apr 2021 10:36:43 GMT"}], "update_date": "2021-04-22", "authors_parsed": [["Bodin", "Erik", ""], ["Tomasi", "Federico", ""], ["Dai", "Zhenwen", ""]]}, {"id": "2104.10453", "submitter": "Kimberly Mai", "authors": "Kimberly T. Mai, Toby Davies, Lewis D. Griffin", "title": "Brittle Features May Help Anomaly Detection", "comments": "Accepted to Women in Computer Vision workshop at CVPR (2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  One-class anomaly detection is challenging. A representation that clearly\ndistinguishes anomalies from normal data is ideal, but arriving at this\nrepresentation is difficult since only normal data is available at training\ntime. We examine the performance of representations, transferred from auxiliary\ntasks, for anomaly detection. Our results suggest that the choice of\nrepresentation is more important than the anomaly detector used with these\nrepresentations, although knowledge distillation can work better than using the\nrepresentations directly. In addition, separability between anomalies and\nnormal data is important but not the sole factor for a good representation, as\nanomaly detection performance is also correlated with more adversarially\nbrittle features in the representation space. Finally, we show our\nconfiguration can detect 96.4% of anomalies in a genuine X-ray security\ndataset, outperforming previous results.\n", "versions": [{"version": "v1", "created": "Wed, 21 Apr 2021 10:46:58 GMT"}], "update_date": "2021-04-22", "authors_parsed": [["Mai", "Kimberly T.", ""], ["Davies", "Toby", ""], ["Griffin", "Lewis D.", ""]]}, {"id": "2104.10454", "submitter": "Petr Marek", "authors": "Petr Marek, \\v{S}t\\v{e}p\\'an M\\\"uller, Jakub Konr\\'ad, Petr Lorenc,\n  Jan Pichl and Jan \\v{S}ediv\\'y", "title": "Text Summarization of Czech News Articles Using Named Entities", "comments": null, "journal-ref": "The Prague Bulletin of Mathematical Linguistics 2021 116", "doi": "10.14712/00326585.012", "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The foundation for the research of summarization in the Czech language was\nlaid by the work of Straka et al. (2018). They published the SumeCzech, a large\nCzech news-based summarization dataset, and proposed several baseline\napproaches. However, it is clear from the achieved results that there is a\nlarge space for improvement. In our work, we focus on the impact of named\nentities on the summarization of Czech news articles. First, we annotate\nSumeCzech with named entities. We propose a new metric ROUGE_NE that measures\nthe overlap of named entities between the true and generated summaries, and we\nshow that it is still challenging for summarization systems to reach a high\nscore in it. We propose an extractive summarization approach Named Entity\nDensity that selects a sentence with the highest ratio between a number of\nentities and the length of the sentence as the summary of the article. The\nexperiments show that the proposed approach reached results close to the solid\nbaseline in the domain of news articles selecting the first sentence. Moreover,\nwe demonstrate that the selected sentence reflects the style of reports\nconcisely identifying to whom, when, where, and what happened. We propose that\nsuch a summary is beneficial in combination with the first sentence of an\narticle in voice applications presenting news articles. We propose two\nabstractive summarization approaches based on Seq2Seq architecture. The first\napproach uses the tokens of the article. The second approach has access to the\nnamed entity annotations. The experiments show that both approaches exceed\nstate-of-the-art results previously reported by Straka et al. (2018), with the\nlatter achieving slightly better results on SumeCzech's out-of-domain testing\nset.\n", "versions": [{"version": "v1", "created": "Wed, 21 Apr 2021 10:48:14 GMT"}], "update_date": "2021-04-22", "authors_parsed": [["Marek", "Petr", ""], ["M\u00fcller", "\u0160t\u011bp\u00e1n", ""], ["Konr\u00e1d", "Jakub", ""], ["Lorenc", "Petr", ""], ["Pichl", "Jan", ""], ["\u0160ediv\u00fd", "Jan", ""]]}, {"id": "2104.10455", "submitter": "Alvaro Cabrejas Egea", "authors": "Alvaro Cabrejas-Egea, Raymond Zhang, Neil Walton", "title": "Reinforcement Learning for Traffic Signal Control: Comparison with\n  Commercial Systems", "comments": "8 pages, 13 figures, 3 tables, conference paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.SY eess.SY", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Recently, Intelligent Transportation Systems are leveraging the power of\nincreased sensory coverage and computing power to deliver data-intensive\nsolutions achieving higher levels of performance than traditional systems.\nWithin Traffic Signal Control (TSC), this has allowed the emergence of Machine\nLearning (ML) based systems. Among this group, Reinforcement Learning (RL)\napproaches have performed particularly well. Given the lack of industry\nstandards in ML for TSC, literature exploring RL often lacks comparison against\ncommercially available systems and straightforward formulations of how the\nagents operate. Here we attempt to bridge that gap. We propose three different\narchitectures for TSC RL agents and compare them against the currently used\ncommercial systems MOVA, SurTrac and Cyclic controllers and provide pseudo-code\nfor them. The agents use variations of Deep Q-Learning and Actor Critic, using\nstates and rewards based on queue lengths. Their performance is compared in\nacross different map scenarios with variable demand, assessing them in terms of\nthe global delay and average queue length. We find that the RL-based systems\ncan significantly and consistently achieve lower delays when compared with\nexisting commercial systems.\n", "versions": [{"version": "v1", "created": "Wed, 21 Apr 2021 10:48:48 GMT"}, {"version": "v2", "created": "Fri, 30 Apr 2021 11:40:14 GMT"}], "update_date": "2021-05-03", "authors_parsed": [["Cabrejas-Egea", "Alvaro", ""], ["Zhang", "Raymond", ""], ["Walton", "Neil", ""]]}, {"id": "2104.10459", "submitter": "Kenneth Co", "authors": "Kenneth T. Co, David Martinez Rego, Emil C. Lupu", "title": "Jacobian Regularization for Mitigating Universal Adversarial\n  Perturbations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR cs.CV", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Universal Adversarial Perturbations (UAPs) are input perturbations that can\nfool a neural network on large sets of data. They are a class of attacks that\nrepresents a significant threat as they facilitate realistic, practical, and\nlow-cost attacks on neural networks. In this work, we derive upper bounds for\nthe effectiveness of UAPs based on norms of data-dependent Jacobians. We\nempirically verify that Jacobian regularization greatly increases model\nrobustness to UAPs by up to four times whilst maintaining clean performance.\nOur theoretical analysis also allows us to formulate a metric for the strength\nof shared adversarial perturbations between pairs of inputs. We apply this\nmetric to benchmark datasets and show that it is highly correlated with the\nactual observed robustness. This suggests that realistic and practical\nuniversal attacks can be reliably mitigated without sacrificing clean accuracy,\nwhich shows promise for the robustness of machine learning systems.\n", "versions": [{"version": "v1", "created": "Wed, 21 Apr 2021 11:00:21 GMT"}], "update_date": "2021-04-22", "authors_parsed": [["Co", "Kenneth T.", ""], ["Rego", "David Martinez", ""], ["Lupu", "Emil C.", ""]]}, {"id": "2104.10461", "submitter": "Arian Bakhtiarnia", "authors": "Arian Bakhtiarnia, Qi Zhang and Alexandros Iosifidis", "title": "Improving the Accuracy of Early Exits in Multi-Exit Architectures via\n  Curriculum Learning", "comments": "Accepted by the 2021 International Joint Conference on Neural\n  Networks (IJCNN 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deploying deep learning services for time-sensitive and resource-constrained\nsettings such as IoT using edge computing systems is a challenging task that\nrequires dynamic adjustment of inference time. Multi-exit architectures allow\ndeep neural networks to terminate their execution early in order to adhere to\ntight deadlines at the cost of accuracy. To mitigate this cost, in this paper\nwe introduce a novel method called Multi-Exit Curriculum Learning that utilizes\ncurriculum learning, a training strategy for neural networks that imitates\nhuman learning by sorting the training samples based on their difficulty and\ngradually introducing them to the network. Experiments on CIFAR-10 and\nCIFAR-100 datasets and various configurations of multi-exit architectures show\nthat our method consistently improves the accuracy of early exits compared to\nthe standard training approach.\n", "versions": [{"version": "v1", "created": "Wed, 21 Apr 2021 11:12:35 GMT"}, {"version": "v2", "created": "Thu, 22 Apr 2021 07:45:31 GMT"}], "update_date": "2021-04-23", "authors_parsed": [["Bakhtiarnia", "Arian", ""], ["Zhang", "Qi", ""], ["Iosifidis", "Alexandros", ""]]}, {"id": "2104.10481", "submitter": "Siladittya Manna", "authors": "Siladittya Manna, Saumik Bhattacharya, Umapada Pal", "title": "SSLM: Self-Supervised Learning for Medical Diagnosis from MR Video", "comments": "This work has been submitted to the IEEE for possible publication.\n  Copyright may be transferred without notice, which this version may no longer\n  be accessible", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In medical image analysis, the cost of acquiring high-quality data and their\nannotation by experts is a barrier in many medical applications. Most of the\ntechniques used are based on supervised learning framework and need a large\namount of annotated data to achieve satisfactory performance. As an\nalternative, in this paper, we propose a self-supervised learning approach to\nlearn the spatial anatomical representations from the frames of magnetic\nresonance (MR) video clips for the diagnosis of knee medical conditions. The\npretext model learns meaningful spatial context-invariant representations. The\ndownstream task in our paper is a class imbalanced multi-label classification.\nDifferent experiments show that the features learnt by the pretext model\nprovide explainable performance in the downstream task. Moreover, the\nefficiency and reliability of the proposed pretext model in learning\nrepresentations of minority classes without applying any strategy towards\nimbalance in the dataset can be seen from the results. To the best of our\nknowledge, this work is the first work of its kind in showing the effectiveness\nand reliability of self-supervised learning algorithms in class imbalanced\nmulti-label classification tasks on MR video.\n  The code for evaluation of the proposed work is available at\nhttps://github.com/sadimanna/sslm\n", "versions": [{"version": "v1", "created": "Wed, 21 Apr 2021 12:01:49 GMT"}, {"version": "v2", "created": "Thu, 22 Apr 2021 05:05:22 GMT"}], "update_date": "2021-04-23", "authors_parsed": [["Manna", "Siladittya", ""], ["Bhattacharya", "Saumik", ""], ["Pal", "Umapada", ""]]}, {"id": "2104.10482", "submitter": "Alexandre Duval", "authors": "Alexandre Duval and Fragkiskos D. Malliaros", "title": "GraphSVX: Shapley Value Explanations for Graph Neural Networks", "comments": "ECML PKDD 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph Neural Networks (GNNs) achieve significant performance for various\nlearning tasks on geometric data due to the incorporation of graph structure\ninto the learning of node representations, which renders their comprehension\nchallenging. In this paper, we first propose a unified framework satisfied by\nmost existing GNN explainers. Then, we introduce GraphSVX, a post hoc local\nmodel-agnostic explanation method specifically designed for GNNs. GraphSVX is a\ndecomposition technique that captures the \"fair\" contribution of each feature\nand node towards the explained prediction by constructing a surrogate model on\na perturbed dataset. It extends to graphs and ultimately provides as\nexplanation the Shapley Values from game theory. Experiments on real-world and\nsynthetic datasets demonstrate that GraphSVX achieves state-of-the-art\nperformance compared to baseline models while presenting core theoretical and\nhuman-centric properties.\n", "versions": [{"version": "v1", "created": "Sun, 18 Apr 2021 10:40:37 GMT"}, {"version": "v2", "created": "Tue, 13 Jul 2021 07:33:30 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Duval", "Alexandre", ""], ["Malliaros", "Fragkiskos D.", ""]]}, {"id": "2104.10483", "submitter": "Eric Benhamou", "authors": "Eric Benhamou and David Saltiel and Serge Tabachnik and Sui Kai Wong\n  and Fran\\c{c}ois Chareyron", "title": "Adaptive learning for financial markets mixing model-based and\n  model-free RL for volatility targeting", "comments": "8 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-fin.MF q-fin.PM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model-Free Reinforcement Learning has achieved meaningful results in stable\nenvironments but, to this day, it remains problematic in regime changing\nenvironments like financial markets. In contrast, model-based RL is able to\ncapture some fundamental and dynamical concepts of the environment but suffer\nfrom cognitive bias. In this work, we propose to combine the best of the two\ntechniques by selecting various model-based approaches thanks to Model-Free\nDeep Reinforcement Learning. Using not only past performance and volatility, we\ninclude additional contextual information such as macro and risk appetite\nsignals to account for implicit regime changes. We also adapt traditional RL\nmethods to real-life situations by considering only past data for the training\nsets. Hence, we cannot use future information in our training data set as\nimplied by K-fold cross validation. Building on traditional statistical\nmethods, we use the traditional \"walk-forward analysis\", which is defined by\nsuccessive training and testing based on expanding periods, to assert the\nrobustness of the resulting agent.\n  Finally, we present the concept of statistical difference's significance\nbased on a two-tailed T-test, to highlight the ways in which our models differ\nfrom more traditional ones. Our experimental results show that our approach\noutperforms traditional financial baseline portfolio models such as the\nMarkowitz model in almost all evaluation metrics commonly used in financial\nmathematics, namely net performance, Sharpe and Sortino ratios, maximum\ndrawdown, maximum drawdown over volatility.\n", "versions": [{"version": "v1", "created": "Mon, 19 Apr 2021 19:20:22 GMT"}, {"version": "v2", "created": "Thu, 22 Apr 2021 09:15:21 GMT"}], "update_date": "2021-04-23", "authors_parsed": [["Benhamou", "Eric", ""], ["Saltiel", "David", ""], ["Tabachnik", "Serge", ""], ["Wong", "Sui Kai", ""], ["Chareyron", "Fran\u00e7ois", ""]]}, {"id": "2104.10488", "submitter": "Jiqing Zhang", "authors": "Jiqing Zhang, Chengjiang Long, Yuxin Wang, Haiyin Piao, Haiyang Mei,\n  Xin Yang, Baocai Yin", "title": "A Two-Stage Attentive Network for Single Image Super-Resolution", "comments": null, "journal-ref": null, "doi": "10.1109/TCSVT.2021.3071191", "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, deep convolutional neural networks (CNNs) have been widely explored\nin single image super-resolution (SISR) and contribute remarkable progress.\nHowever, most of the existing CNNs-based SISR methods do not adequately explore\ncontextual information in the feature extraction stage and pay little attention\nto the final high-resolution (HR) image reconstruction step, hence hindering\nthe desired SR performance. To address the above two issues, in this paper, we\npropose a two-stage attentive network (TSAN) for accurate SISR in a\ncoarse-to-fine manner. Specifically, we design a novel multi-context attentive\nblock (MCAB) to make the network focus on more informative contextual features.\nMoreover, we present an essential refined attention block (RAB) which could\nexplore useful cues in HR space for reconstructing fine-detailed HR image.\nExtensive evaluations on four benchmark datasets demonstrate the efficacy of\nour proposed TSAN in terms of quantitative metrics and visual effects. Code is\navailable at https://github.com/Jee-King/TSAN.\n", "versions": [{"version": "v1", "created": "Wed, 21 Apr 2021 12:20:24 GMT"}], "update_date": "2021-04-22", "authors_parsed": [["Zhang", "Jiqing", ""], ["Long", "Chengjiang", ""], ["Wang", "Yuxin", ""], ["Piao", "Haiyin", ""], ["Mei", "Haiyang", ""], ["Yang", "Xin", ""], ["Yin", "Baocai", ""]]}, {"id": "2104.10489", "submitter": "Dillon Lohr", "authors": "Dillon Lohr, Henry Griffith, and Oleg V Komogortsev", "title": "Eye Know You: Metric Learning for End-to-end Biometric Authentication\n  Using Eye Movements from a Longitudinal Dataset", "comments": "This work has been submitted to the IEEE for possible publication.\n  Copyright may be transferred without notice, after which this version may no\n  longer be accessible", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While numerous studies have explored eye movement biometrics since the\nmodality's inception in 2004, the permanence of eye movements remains largely\nunexplored as most studies utilize datasets collected within a short time\nframe. This paper presents a convolutional neural network for authenticating\nusers using their eye movements. The network is trained with an established\nmetric learning loss function, multi-similarity loss, which seeks to form a\nwell-clustered embedding space and directly enables the enrollment and\nauthentication of out-of-sample users. Performance measures are computed on\nGazeBase, a task-diverse and publicly-available dataset collected over a\n37-month period. This study includes an exhaustive analysis of the effects of\ntraining on various tasks and downsampling from 1000 Hz to several lower\nsampling rates. Our results reveal that reasonable authentication accuracy may\nbe achieved even during a low-cognitive-load task or at low sampling rates.\nMoreover, we find that eye movements are quite resilient against template aging\nafter 3 years.\n", "versions": [{"version": "v1", "created": "Wed, 21 Apr 2021 12:21:28 GMT"}], "update_date": "2021-04-22", "authors_parsed": [["Lohr", "Dillon", ""], ["Griffith", "Henry", ""], ["Komogortsev", "Oleg V", ""]]}, {"id": "2104.10496", "submitter": "Aravinda Ramakrishnan Srinivasan", "authors": "Aravinda Ramakrishnan Srinivasan, Mohamed Hasan, Yi-Shin Lin, Matteo\n  Leonetti, Jac Billington, Richard Romano, Gustav Markkula", "title": "Comparing merging behaviors observed in naturalistic data with behaviors\n  generated by a machine learned model", "comments": "This paper has been submitted to 24th IEEE International Conference\n  on Intelligent Transportation - ITSC2021, September 19-22, 2021 Indianapolis,\n  IN, United States", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  There is quickly growing literature on machine-learned models that predict\nhuman driving trajectories in road traffic. These models focus their learning\non low-dimensional error metrics, for example average distance between\nmodel-generated and observed trajectories. Such metrics permit relative\ncomparison of models, but do not provide clearly interpretable information on\nhow close to human behavior the models actually come, for example in terms of\nhigher-level behavior phenomena that are known to be present in human driving.\nWe study highway driving as an example scenario, and introduce metrics to\nquantitatively demonstrate the presence, in a naturalistic dataset, of two\nfamiliar behavioral phenomena: (1) The kinematics-dependent contest, between\non-highway and on-ramp vehicles, of who passes the merging point first. (2)\nCourtesy lane changes away from the outermost lane, to leave space for a\nmerging vehicle. Applying the exact same metrics to the output of a\nstate-of-the-art machine-learned model, we show that the model is capable of\nreproducing the former phenomenon, but not the latter. We argue that this type\nof behavioral analysis provides information that is not available from\nconventional model-fitting metrics, and that it may be useful to analyze (and\npossibly fit) models also based on these types of behavioral criteria.\n", "versions": [{"version": "v1", "created": "Wed, 21 Apr 2021 12:31:29 GMT"}], "update_date": "2021-04-22", "authors_parsed": [["Srinivasan", "Aravinda Ramakrishnan", ""], ["Hasan", "Mohamed", ""], ["Lin", "Yi-Shin", ""], ["Leonetti", "Matteo", ""], ["Billington", "Jac", ""], ["Romano", "Richard", ""], ["Markkula", "Gustav", ""]]}, {"id": "2104.10501", "submitter": "Shouhua Zhang", "authors": "Jiehan Zhou, Shouhua Zhang, Qinghua Lu, Wenbin Dai, Min Chen, Xin Liu,\n  Susanna Pirttikangas, Yang Shi, Weishan Zhang, Enrique Herrera-Viedma", "title": "A Survey on Federated Learning and its Applications for Accelerating\n  Industrial Internet of Things", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning (FL) brings collaborative intelligence into industries\nwithout centralized training data to accelerate the process of Industry 4.0 on\nthe edge computing level. FL solves the dilemma in which enterprises wish to\nmake the use of data intelligence with security concerns. To accelerate\nindustrial Internet of things with the further leverage of FL, existing\nachievements on FL are developed from three aspects: 1) define terminologies\nand elaborate a general framework of FL for accommodating various scenarios; 2)\ndiscuss the state-of-the-art of FL on fundamental researches including data\npartitioning, privacy preservation, model optimization, local model\ntransportation, personalization, motivation mechanism, platform & tools, and\nbenchmark; 3) discuss the impacts of FL from the economic perspective. To\nattract more attention from industrial academia and practice, a FL-transformed\nmanufacturing paradigm is presented, and future research directions of FL are\ngiven and possible immediate applications in Industry 4.0 domain are also\nproposed.\n", "versions": [{"version": "v1", "created": "Wed, 21 Apr 2021 12:40:11 GMT"}], "update_date": "2021-04-22", "authors_parsed": [["Zhou", "Jiehan", ""], ["Zhang", "Shouhua", ""], ["Lu", "Qinghua", ""], ["Dai", "Wenbin", ""], ["Chen", "Min", ""], ["Liu", "Xin", ""], ["Pirttikangas", "Susanna", ""], ["Shi", "Yang", ""], ["Zhang", "Weishan", ""], ["Herrera-Viedma", "Enrique", ""]]}, {"id": "2104.10505", "submitter": "Shikun Chen", "authors": "Shikun Chen", "title": "Interpretation of multi-label classification models using shapley values", "comments": "11 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Multi-label classification is a type of classification task, it is used when\nthere are two or more classes, and the data point we want to predict may belong\nto none of the classes or all of them at the same time. In the real world, many\napplications are actually multi-label involved, including information\nretrieval, multimedia content annotation, web mining, and so on. A game\ntheory-based framework known as SHapley Additive exPlanations (SHAP) has been\napplied to explain various supervised learning models without being aware of\nthe exact model. Herein, this work further extends the explanation of\nmulti-label classification task by using the SHAP methodology. The experiment\ndemonstrates a comprehensive comparision of different algorithms on well known\nmulti-label datasets and shows the usefulness of the interpretation.\n", "versions": [{"version": "v1", "created": "Wed, 21 Apr 2021 12:51:12 GMT"}], "update_date": "2021-04-26", "authors_parsed": [["Chen", "Shikun", ""]]}, {"id": "2104.10511", "submitter": "Manh Duong Phung", "authors": "Qiuchen Zhu, Tran Hiep Dinh, Manh Duong Phung, Quang Phuc Ha", "title": "Hierarchical Convolutional Neural Network with Feature Preservation and\n  Autotuned Thresholding for Crack Detection", "comments": null, "journal-ref": "IEEE Access, 2021", "doi": "10.1109/ACCESS.2021.3073921", "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Drone imagery is increasingly used in automated inspection for infrastructure\nsurface defects, especially in hazardous or unreachable environments. In\nmachine vision, the key to crack detection rests with robust and accurate\nalgorithms for image processing. To this end, this paper proposes a deep\nlearning approach using hierarchical convolutional neural networks with feature\npreservation (HCNNFP) and an intercontrast iterative thresholding algorithm for\nimage binarization. First, a set of branch networks is proposed, wherein the\noutput of previous convolutional blocks is half-sizedly concatenated to the\ncurrent ones to reduce the obscuration in the down-sampling stage taking into\naccount the overall information loss. Next, to extract the feature map\ngenerated from the enhanced HCNN, a binary contrast-based autotuned\nthresholding (CBAT) approach is developed at the post-processing step, where\npatterns of interest are clustered within the probability map of the identified\nfeatures. The proposed technique is then applied to identify surface cracks on\nthe surface of roads, bridges or pavements. An extensive comparison with\nexisting techniques is conducted on various datasets and subject to a number of\nevaluation criteria including the average F-measure (AF\\b{eta}) introduced here\nfor dynamic quantification of the performance. Experiments on crack images,\nincluding those captured by unmanned aerial vehicles inspecting a monorail\nbridge. The proposed technique outperforms the existing methods on various\ntested datasets especially for GAPs dataset with an increase of about 1.4% in\nterms of AF\\b{eta} while the mean percentage error drops by 2.2%. Such\nperformance demonstrates the merits of the proposed HCNNFP architecture for\nsurface defect inspection.\n", "versions": [{"version": "v1", "created": "Wed, 21 Apr 2021 13:07:58 GMT"}], "update_date": "2021-04-22", "authors_parsed": [["Zhu", "Qiuchen", ""], ["Dinh", "Tran Hiep", ""], ["Phung", "Manh Duong", ""], ["Ha", "Quang Phuc", ""]]}, {"id": "2104.10513", "submitter": "Soroosh Tayebi Arasteh", "authors": "Soroosh Tayebi Arasteh, Mehrpad Monajem, Vincent Christlein, Philipp\n  Heinrich, Anguelos Nicolaou, Hamidreza Naderi Boldaji, Mahshad Lotfinia,\n  Stefan Evert", "title": "How Will Your Tweet Be Received? Predicting the Sentiment Polarity of\n  Tweet Replies", "comments": "Published in 2021 IEEE 15th International Conference on Semantic\n  Computing (ICSC)", "journal-ref": "2021 IEEE 15th International Conference on Semantic Computing\n  (ICSC), Laguna Hills, CA, USA, 2021, pp. 356-359", "doi": "10.1109/ICSC50631.2021.00068", "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Twitter sentiment analysis, which often focuses on predicting the polarity of\ntweets, has attracted increasing attention over the last years, in particular\nwith the rise of deep learning (DL). In this paper, we propose a new task:\npredicting the predominant sentiment among (first-order) replies to a given\ntweet. Therefore, we created RETWEET, a large dataset of tweets and replies\nmanually annotated with sentiment labels. As a strong baseline, we propose a\ntwo-stage DL-based method: first, we create automatically labeled training data\nby applying a standard sentiment classifier to tweet replies and aggregating\nits predictions for each original tweet; our rationale is that individual\nerrors made by the classifier are likely to cancel out in the aggregation step.\nSecond, we use the automatically labeled data for supervised training of a\nneural network to predict reply sentiment from the original tweets. The\nresulting classifier is evaluated on the new RETWEET dataset, showing promising\nresults, especially considering that it has been trained without any manually\nlabeled data. Both the dataset and the baseline implementation are publicly\navailable.\n", "versions": [{"version": "v1", "created": "Wed, 21 Apr 2021 13:08:45 GMT"}], "update_date": "2021-04-22", "authors_parsed": [["Arasteh", "Soroosh Tayebi", ""], ["Monajem", "Mehrpad", ""], ["Christlein", "Vincent", ""], ["Heinrich", "Philipp", ""], ["Nicolaou", "Anguelos", ""], ["Boldaji", "Hamidreza Naderi", ""], ["Lotfinia", "Mahshad", ""], ["Evert", "Stefan", ""]]}, {"id": "2104.10516", "submitter": "Konstantinos Kogkalidis", "authors": "Giorgos Tziafas, Konstantinos Kogkalidis, Gijs Wijnholds, Michael\n  Moortgat", "title": "Improving BERT Pretraining with Syntactic Supervision", "comments": "4 pages, rejected by IWCS due to \"not fitting the conference theme\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Bidirectional masked Transformers have become the core theme in the current\nNLP landscape. Despite their impressive benchmarks, a recurring theme in recent\nresearch has been to question such models' capacity for syntactic\ngeneralization. In this work, we seek to address this question by adding a\nsupervised, token-level supertagging objective to standard unsupervised\npretraining, enabling the explicit incorporation of syntactic biases into the\nnetwork's training dynamics. Our approach is straightforward to implement,\ninduces a marginal computational overhead and is general enough to adapt to a\nvariety of settings. We apply our methodology on Lassy Large, an automatically\nannotated corpus of written Dutch. Our experiments suggest that our\nsyntax-aware model performs on par with established baselines, despite Lassy\nLarge being one order of magnitude smaller than commonly used corpora.\n", "versions": [{"version": "v1", "created": "Wed, 21 Apr 2021 13:15:58 GMT"}], "update_date": "2021-04-22", "authors_parsed": [["Tziafas", "Giorgos", ""], ["Kogkalidis", "Konstantinos", ""], ["Wijnholds", "Gijs", ""], ["Moortgat", "Michael", ""]]}, {"id": "2104.10519", "submitter": "Walid Gomaa", "authors": "Akthem Rehab, Islam Ali, Walid Gomaa, M. Nashat Fors", "title": "Bearings Fault Detection Using Hidden Markov Models and Principal\n  Component Analysis Enhanced Features", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.LO", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Asset health monitoring continues to be of increasing importance on\nproductivity, reliability, and cost reduction. Early Fault detection is a\nkeystone of health management as part of the emerging Prognostics and Health\nManagement (PHM) philosophy. This paper proposes a Hidden Markov Model (HMM) to\nassess the machine health degradation. using Principal Component Analysis (PCA)\nto enhance features extracted from vibration signals is considered. The\nenhanced features capture the second order structure of the data. The\nexperimental results based on a bearing test bed show the plausibility of the\nproposed method.\n", "versions": [{"version": "v1", "created": "Wed, 21 Apr 2021 13:20:06 GMT"}], "update_date": "2021-04-22", "authors_parsed": [["Rehab", "Akthem", ""], ["Ali", "Islam", ""], ["Gomaa", "Walid", ""], ["Fors", "M. Nashat", ""]]}, {"id": "2104.10527", "submitter": "Mike Huisman", "authors": "Mike Huisman and Aske Plaat and Jan N. van Rijn", "title": "Stateless Neural Meta-Learning using Second-Order Gradients", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning typically requires large data sets and much compute power for\neach new problem that is learned. Meta-learning can be used to learn a good\nprior that facilitates quick learning, thereby relaxing these requirements so\nthat new tasks can be learned quicker; two popular approaches are MAML and the\nmeta-learner LSTM. In this work, we compare the two and formally show that the\nmeta-learner LSTM subsumes MAML. Combining this insight with recent empirical\nfindings, we construct a new algorithm (dubbed TURTLE) which is simpler than\nthe meta-learner LSTM yet more expressive than MAML. TURTLE outperforms both\ntechniques at few-shot sine wave regression and image classification on\nminiImageNet and CUB without any additional hyperparameter tuning, at a\ncomputational cost that is comparable with second-order MAML. The key to\nTURTLE's success lies in the use of second-order gradients, which also\nsignificantly increases the performance of the meta-learner LSTM by 1-6%\naccuracy.\n", "versions": [{"version": "v1", "created": "Wed, 21 Apr 2021 13:34:31 GMT"}], "update_date": "2021-04-22", "authors_parsed": [["Huisman", "Mike", ""], ["Plaat", "Aske", ""], ["van Rijn", "Jan N.", ""]]}, {"id": "2104.10529", "submitter": "Li Yang", "authors": "Li Yang, Abdallah Shami", "title": "A Lightweight Concept Drift Detection and Adaptation Framework for IoT\n  Data Streams", "comments": "Accepted and to appear in IEEE Internet of Things Magazine; Code is\n  available at Github\n  link:https://github.com/Western-OC2-Lab/OASW-Concept-Drift-Detection-and-Adaptation", "journal-ref": null, "doi": "10.1109/IOTM.0001.2100012", "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, with the increasing popularity of \"Smart Technology\", the\nnumber of Internet of Things (IoT) devices and systems have surged\nsignificantly. Various IoT services and functionalities are based on the\nanalytics of IoT streaming data. However, IoT data analytics faces concept\ndrift challenges due to the dynamic nature of IoT systems and the ever-changing\npatterns of IoT data streams. In this article, we propose an adaptive IoT\nstreaming data analytics framework for anomaly detection use cases based on\noptimized LightGBM and concept drift adaptation. A novel drift adaptation\nmethod named Optimized Adaptive and Sliding Windowing (OASW) is proposed to\nadapt to the pattern changes of online IoT data streams. Experiments on two\npublic datasets show the high accuracy and efficiency of our proposed adaptive\nLightGBM model compared against other state-of-the-art approaches. The proposed\nadaptive LightGBM model can perform continuous learning and drift adaptation on\nIoT data streams without human intervention.\n", "versions": [{"version": "v1", "created": "Wed, 21 Apr 2021 13:41:41 GMT"}], "update_date": "2021-05-27", "authors_parsed": [["Yang", "Li", ""], ["Shami", "Abdallah", ""]]}, {"id": "2104.10544", "submitter": "James Townsend", "authors": "James Townsend", "title": "Lossless Compression with Latent Variable Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.IT math.IT stat.CO stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  We develop a simple and elegant method for lossless compression using latent\nvariable models, which we call 'bits back with asymmetric numeral systems'\n(BB-ANS). The method involves interleaving encode and decode steps, and\nachieves an optimal rate when compressing batches of data. We demonstrate it\nfirstly on the MNIST test set, showing that state-of-the-art lossless\ncompression is possible using a small variational autoencoder (VAE) model. We\nthen make use of a novel empirical insight, that fully convolutional generative\nmodels, trained on small images, are able to generalize to images of arbitrary\nsize, and extend BB-ANS to hierarchical latent variable models, enabling\nstate-of-the-art lossless compression of full-size colour images from the\nImageNet dataset. We describe 'Craystack', a modular software framework which\nwe have developed for rapid prototyping of compression using deep generative\nmodels.\n", "versions": [{"version": "v1", "created": "Wed, 21 Apr 2021 14:03:05 GMT"}, {"version": "v2", "created": "Thu, 22 Apr 2021 09:28:41 GMT"}], "update_date": "2021-04-23", "authors_parsed": [["Townsend", "James", ""]]}, {"id": "2104.10555", "submitter": "John Clemens", "authors": "John Clemens", "title": "MLDS: A Dataset for Weight-Space Analysis of Neural Networks", "comments": "For further information and download links, see\n  https://www.mlcathome.org/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks are powerful models that solve a variety of complex\nreal-world problems. However, the stochastic nature of training and large\nnumber of parameters in a typical neural model makes them difficult to evaluate\nvia inspection. Research shows this opacity can hide latent undesirable\nbehavior, be it from poorly representative training data or via malicious\nintent to subvert the behavior of the network, and that this behavior is\ndifficult to detect via traditional indirect evaluation criteria such as loss.\nTherefore, it is time to explore direct ways to evaluate a trained neural model\nvia its structure and weights. In this paper we present MLDS, a new dataset\nconsisting of thousands of trained neural networks with carefully controlled\nparameters and generated via a global volunteer-based distributed computing\nplatform. This dataset enables new insights into both model-to-model and\nmodel-to-training-data relationships. We use this dataset to show clustering of\nmodels in weight-space with identical training data and meaningful divergence\nin weight-space with even a small change to the training data, suggesting that\nweight-space analysis is a viable and effective alternative to loss for\nevaluating neural networks.\n", "versions": [{"version": "v1", "created": "Wed, 21 Apr 2021 14:24:26 GMT"}], "update_date": "2021-04-22", "authors_parsed": [["Clemens", "John", ""]]}, {"id": "2104.10558", "submitter": "Nicholas Rhinehart", "authors": "Nicholas Rhinehart, Jeff He, Charles Packer, Matthew A. Wright, Rowan\n  McAllister, Joseph E. Gonzalez, Sergey Levine", "title": "Contingencies from Observations: Tractable Contingency Planning with\n  Learned Behavior Models", "comments": "To be published at ICRA 2021. Project page:\n  https://sites.google.com/view/contingency-planning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Humans have a remarkable ability to make decisions by accurately reasoning\nabout future events, including the future behaviors and states of mind of other\nagents. Consider driving a car through a busy intersection: it is necessary to\nreason about the physics of the vehicle, the intentions of other drivers, and\ntheir beliefs about your own intentions. If you signal a turn, another driver\nmight yield to you, or if you enter the passing lane, another driver might\ndecelerate to give you room to merge in front. Competent drivers must plan how\nthey can safely react to a variety of potential future behaviors of other\nagents before they make their next move. This requires contingency planning:\nexplicitly planning a set of conditional actions that depend on the stochastic\noutcome of future events. In this work, we develop a general-purpose\ncontingency planner that is learned end-to-end using high-dimensional scene\nobservations and low-dimensional behavioral observations. We use a conditional\nautoregressive flow model to create a compact contingency planning space, and\nshow how this model can tractably learn contingencies from behavioral\nobservations. We developed a closed-loop control benchmark of realistic\nmulti-agent scenarios in a driving simulator (CARLA), on which we compare our\nmethod to various noncontingent methods that reason about multi-agent future\nbehavior, including several state-of-the-art deep learning-based planning\napproaches. We illustrate that these noncontingent planning methods\nfundamentally fail on this benchmark, and find that our deep contingency\nplanning method achieves significantly superior performance. Code to run our\nbenchmark and reproduce our results is available at\nhttps://sites.google.com/view/contingency-planning\n", "versions": [{"version": "v1", "created": "Wed, 21 Apr 2021 14:30:20 GMT"}], "update_date": "2021-04-22", "authors_parsed": [["Rhinehart", "Nicholas", ""], ["He", "Jeff", ""], ["Packer", "Charles", ""], ["Wright", "Matthew A.", ""], ["McAllister", "Rowan", ""], ["Gonzalez", "Joseph E.", ""], ["Levine", "Sergey", ""]]}, {"id": "2104.10561", "submitter": "Gabriele Costa", "authors": "Gabriele Costa, Fabio Pinelli, Simone Soderi, Gabriele Tolomei", "title": "Covert Channel Attack to Federated Learning Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Federated learning (FL) goes beyond traditional, centralized machine learning\nby distributing model training among a large collection of edge clients. These\nclients cooperatively train a global, e.g., cloud-hosted, model without\ndisclosing their local, private training data. The global model is then shared\namong all the participants which use it for local predictions. In this paper,\nwe put forward a novel attacker model aiming at turning FL systems into covert\nchannels to implement a stealth communication infrastructure. The main\nintuition is that, during federated training, a malicious sender can poison the\nglobal model by submitting purposely crafted examples. Although the effect of\nthe model poisoning is negligible to other participants, and does not alter the\noverall model performance, it can be observed by a malicious receiver and used\nto transmit a single bit.\n", "versions": [{"version": "v1", "created": "Wed, 21 Apr 2021 14:32:03 GMT"}], "update_date": "2021-04-22", "authors_parsed": [["Costa", "Gabriele", ""], ["Pinelli", "Fabio", ""], ["Soderi", "Simone", ""], ["Tolomei", "Gabriele", ""]]}, {"id": "2104.10569", "submitter": "Houyi Li", "authors": "Houyi Li, Yongchao Liu, Yongyong Li, Bin Huang, Peng Zhang, Guowei\n  Zhang, Xintan Zeng, Kefeng Deng, Wenguang Chen, and Changhua He", "title": "GraphTheta: A Distributed Graph Neural Network Learning System With\n  Flexible Training Strategy", "comments": "15 pages, 9 figures, submitted to VLDB 2022", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph neural networks (GNNs) have been demonstrated as a powerful tool for\nanalysing non-Euclidean graph data. However, the lack of efficient distributed\ngraph learning systems severely hinders applications of GNNs, especially when\ngraphs are big, of high density or with highly skewed node degree\ndistributions. In this paper, we present a new distributed graph learning\nsystem GraphTheta, which supports multiple training strategies and enables\nefficient and scalable learning on big graphs. GraphTheta implements both\nlocalized and globalized graph convolutions on graphs, where a new graph\nlearning abstraction NN-TGAR is designed to bridge the gap between graph\nprocessing and graph learning frameworks. A distributed graph engine is\nproposed to conduct the stochastic gradient descent optimization with\nhybrid-parallel execution. Moreover, we add support for a new cluster-batched\ntraining strategy in addition to the conventional global-batched and\nmini-batched ones. We evaluate GraphTheta using a number of network data with\nnetwork size ranging from small-, modest- to large-scale. Experimental results\nshow that GraphTheta scales almost linearly to 1,024 workers and trains an\nin-house developed GNN model within 26 hours on Alipay dataset of 1.4 billion\nnodes and 4.1 billion attributed edges. Moreover, GraphTheta also obtains\nbetter prediction results than the state-of-the-art GNN methods. To the best of\nour knowledge, this work represents the largest edge-attributed GNN learning\ntask conducted on a billion-scale network in the literature.\n", "versions": [{"version": "v1", "created": "Wed, 21 Apr 2021 14:51:33 GMT"}], "update_date": "2021-04-22", "authors_parsed": [["Li", "Houyi", ""], ["Liu", "Yongchao", ""], ["Li", "Yongyong", ""], ["Huang", "Bin", ""], ["Zhang", "Peng", ""], ["Zhang", "Guowei", ""], ["Zeng", "Xintan", ""], ["Deng", "Kefeng", ""], ["Chen", "Wenguang", ""], ["He", "Changhua", ""]]}, {"id": "2104.10584", "submitter": "Weinan Zhang", "authors": "Weinan Zhang, Jiarui Qin, Wei Guo, Ruiming Tang, Xiuqiang He", "title": "Deep Learning for Click-Through Rate Estimation", "comments": "Paper accepted at IJCAI 2021 (Survey Track)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Click-through rate (CTR) estimation plays as a core function module in\nvarious personalized online services, including online advertising, recommender\nsystems, and web search etc. From 2015, the success of deep learning started to\nbenefit CTR estimation performance and now deep CTR models have been widely\napplied in many industrial platforms. In this survey, we provide a\ncomprehensive review of deep learning models for CTR estimation tasks. First,\nwe take a review of the transfer from shallow to deep CTR models and explain\nwhy going deep is a necessary trend of development. Second, we concentrate on\nexplicit feature interaction learning modules of deep CTR models. Then, as an\nimportant perspective on large platforms with abundant user histories, deep\nbehavior models are discussed. Moreover, the recently emerged automated methods\nfor deep CTR architecture design are presented. Finally, we summarize the\nsurvey and discuss the future prospects of this field.\n", "versions": [{"version": "v1", "created": "Wed, 21 Apr 2021 15:25:45 GMT"}], "update_date": "2021-04-22", "authors_parsed": [["Zhang", "Weinan", ""], ["Qin", "Jiarui", ""], ["Guo", "Wei", ""], ["Tang", "Ruiming", ""], ["He", "Xiuqiang", ""]]}, {"id": "2104.10586", "submitter": "Hao Cheng", "authors": "Kaidi Xu, Chenan Wang, Hao Cheng, Bhavya Kailkhura, Xue Lin, Ryan\n  Goldhahn", "title": "Mixture of Robust Experts (MoRE):A Robust Denoising Method towards\n  multiple perturbations", "comments": "This paper is a seminar and dicussing paper, which will not be\n  published and printed anywhere. And it will be keep updating", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To tackle the susceptibility of deep neural networks to examples, the\nadversarial training has been proposed which provides a notion of robust\nthrough an inner maximization problem presenting the first-order embedded\nwithin the outer minimization of the training loss. To generalize the\nadversarial robustness over different perturbation types, the adversarial\ntraining method has been augmented with the improved inner maximization\npresenting a union of multiple perturbations e.g., various $\\ell_p$\nnorm-bounded perturbations.\n", "versions": [{"version": "v1", "created": "Wed, 21 Apr 2021 15:27:07 GMT"}, {"version": "v2", "created": "Tue, 8 Jun 2021 15:05:42 GMT"}, {"version": "v3", "created": "Mon, 21 Jun 2021 15:57:13 GMT"}, {"version": "v4", "created": "Tue, 20 Jul 2021 06:25:54 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Xu", "Kaidi", ""], ["Wang", "Chenan", ""], ["Cheng", "Hao", ""], ["Kailkhura", "Bhavya", ""], ["Lin", "Xue", ""], ["Goldhahn", "Ryan", ""]]}, {"id": "2104.10596", "submitter": "Lennart Johnsson", "authors": "Nazanin Beheshti, Lennart Johnsson", "title": "Using CNNs for AD classification based on spatial correlation of BOLD\n  signals during the observation", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Resting state functional magnetic resonance images (fMRI) are commonly used\nfor classification of patients as having Alzheimer's disease (AD), mild\ncognitive impairment (MCI), or being cognitive normal (CN). Most methods use\ntime-series correlation of voxels signals during the observation period as a\nbasis for the classification. In this paper we show that Convolutional Neural\nNetwork (CNN) classification based on spatial correlation of time-averaged\nsignals yield a classification accuracy of up to 82% (sensitivity 86%,\nspecificity 80%)for a data set with 429 subjects (246 cognitive normal and 183\nAlzheimer patients). For the spatial correlation of time-averaged signal values\nwe use voxel subdomains around center points of the 90 regions AAL atlas. We\nform the subdomains as sets of voxels along a Hilbert curve of a bounding box\nin which the brain is embedded with the AAL regions center points serving as\nsubdomain seeds. The matrix resulting from the spatial correlation of the 90\narrays formed by the subdomain segments of the Hilbert curve yields a symmetric\n90x90 matrix that is used for the classification based on two different CNN\nnetworks, a 4-layer CNN network with 3x3 filters and with 4, 8, 16, and 32\noutput channels respectively, and a 2-layer CNN network with 3x3 filters and\nwith 4 and 8 output channels respectively. The results of the two networks are\nreported and compared.\n", "versions": [{"version": "v1", "created": "Wed, 21 Apr 2021 15:48:18 GMT"}], "update_date": "2021-04-22", "authors_parsed": [["Beheshti", "Nazanin", ""], ["Johnsson", "Lennart", ""]]}, {"id": "2104.10610", "submitter": "Alessandro Sestini", "authors": "Alessandro Sestini, Alexander Kuhnle, Andrew D. Bagdanov", "title": "Policy Fusion for Adaptive and Customizable Reinforcement Learning\n  Agents", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article we study the problem of training intelligent agents using\nReinforcement Learning for the purpose of game development. Unlike systems\nbuilt to replace human players and to achieve super-human performance, our\nagents aim to produce meaningful interactions with the player, and at the same\ntime demonstrate behavioral traits as desired by game designers. We show how to\ncombine distinct behavioral policies to obtain a meaningful \"fusion\" policy\nwhich comprises all these behaviors. To this end, we propose four different\npolicy fusion methods for combining pre-trained policies. We further\ndemonstrate how these methods can be used in combination with Inverse\nReinforcement Learning in order to create intelligent agents with specific\nbehavioral styles as chosen by game designers, without having to define many\nand possibly poorly-designed reward functions. Experiments on two different\nenvironments indicate that entropy-weighted policy fusion significantly\noutperforms all others. We provide several practical examples and use-cases for\nhow these methods are indeed useful for video game production and designers.\n", "versions": [{"version": "v1", "created": "Wed, 21 Apr 2021 16:08:44 GMT"}], "update_date": "2021-04-22", "authors_parsed": [["Sestini", "Alessandro", ""], ["Kuhnle", "Alexander", ""], ["Bagdanov", "Andrew D.", ""]]}, {"id": "2104.10611", "submitter": "Diptodip Deb", "authors": "Diptodip Deb, Zhenfei Jiao, Alex B. Chen, Misha B. Ahrens, Kaspar\n  Podgorski, Srinivas C. Turaga", "title": "Programmable 3D snapshot microscopy with Fourier convolutional networks", "comments": "Make zebrafish Types A,B,C,D more clear", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  3D snapshot microscopy enables fast volumetric imaging by capturing a 3D\nvolume in a single 2D camera image, and has found a variety of biological\napplications such as whole brain imaging of fast neural activity in larval\nzebrafish. The optimal microscope design for this optical 3D-to-2D encoding is\nboth sample- and task-dependent, with no general solution known. Highly\nprogrammable optical elements create new possibilities for sample-specific\ncomputational optimization of microscope parameters, e.g. tuning the collection\nof light for a given sample structure. We perform such optimization with deep\nlearning, using a differentiable wave-optics simulation of light propagation\nthrough a programmable microscope and a neural network to reconstruct volumes\nfrom the microscope image. We introduce a class of global kernel Fourier\nconvolutional neural networks which can efficiently decode information from\nmultiple depths in the volume, globally encoded across a 3D snapshot image. We\nshow that our proposed networks succeed in large field of view volume\nreconstruction and microscope parameter optimization where traditional networks\nfail. We also show that our networks outperform the state-of-the-art learned\nreconstruction algorithms for lensless computational photography.\n", "versions": [{"version": "v1", "created": "Wed, 21 Apr 2021 16:09:56 GMT"}, {"version": "v2", "created": "Wed, 9 Jun 2021 00:15:00 GMT"}, {"version": "v3", "created": "Tue, 15 Jun 2021 05:07:16 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Deb", "Diptodip", ""], ["Jiao", "Zhenfei", ""], ["Chen", "Alex B.", ""], ["Ahrens", "Misha B.", ""], ["Podgorski", "Kaspar", ""], ["Turaga", "Srinivas C.", ""]]}, {"id": "2104.10615", "submitter": "Markus Roland Ernst", "authors": "Markus Roland Ernst, Jochen Triesch, Thomas Burwick", "title": "Recurrent Feedback Improves Recognition of Partially Occluded Objects", "comments": "6 pages, 2 figures, 28th European Symposium on Artificial Neural\n  Networks, Computational Intelligence and Machine Learning (ESANN 2020). arXiv\n  admin note: substantial text overlap with arXiv:1909.06175", "journal-ref": "Proceedings of the 28th European Symposium on Artificial Neural\n  Networks, Computational Intelligence and Machine Learning (2020) 327-332", "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Recurrent connectivity in the visual cortex is believed to aid object\nrecognition for challenging conditions such as occlusion. Here we investigate\nif and how artificial neural networks also benefit from recurrence. We compare\narchitectures composed of bottom-up, lateral and top-down connections and\nevaluate their performance using two novel stereoscopic occluded object\ndatasets. We find that classification accuracy is significantly higher for\nrecurrent models when compared to feedforward models of matched parametric\ncomplexity. Additionally we show that for challenging stimuli, the recurrent\nfeedback is able to correctly revise the initial feedforward guess.\n", "versions": [{"version": "v1", "created": "Wed, 21 Apr 2021 16:18:34 GMT"}], "update_date": "2021-04-22", "authors_parsed": [["Ernst", "Markus Roland", ""], ["Triesch", "Jochen", ""], ["Burwick", "Thomas", ""]]}, {"id": "2104.10625", "submitter": "Quanming Yao", "authors": "Shimin Di, Quanming Yao, Lei Chen", "title": "Searching to Sparsify Tensor Decomposition for N-ary Relational Data", "comments": "WebConf 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Tensor, an extension of the vector and matrix to the multi-dimensional case,\nis a natural way to describe the N-ary relational data. Recently, tensor\ndecomposition methods have been introduced into N-ary relational data and\nbecome state-of-the-art on embedding learning. However, the performance of\nexisting tensor decomposition methods is not as good as desired. First, they\nsuffer from the data-sparsity issue since they can only learn from the N-ary\nrelational data with a specific arity, i.e., parts of common N-ary relational\ndata. Besides, they are neither effective nor efficient enough to be trained\ndue to the over-parameterization problem. In this paper, we propose a novel\nmethod, i.e., S2S, for effectively and efficiently learning from the N-ary\nrelational data. Specifically, we propose a new tensor decomposition framework,\nwhich allows embedding sharing to learn from facts with mixed arity. Since the\ncore tensors may still suffer from the over-parameterization, we propose to\nreduce parameters by sparsifying the core tensors while retaining their\nexpressive power using neural architecture search (NAS) techniques, which can\nsearch for data-dependent architectures. As a result, the proposed S2S not only\nguarantees to be expressive but also efficiently learns from mixed arity.\nFinally, empirical results have demonstrated that S2S is efficient to train and\nachieves state-of-the-art performance.\n", "versions": [{"version": "v1", "created": "Wed, 21 Apr 2021 16:37:04 GMT"}], "update_date": "2021-04-22", "authors_parsed": [["Di", "Shimin", ""], ["Yao", "Quanming", ""], ["Chen", "Lei", ""]]}, {"id": "2104.10631", "submitter": "Chen Huang", "authors": "Chen Huang, Shuangfei Zhai, Pengsheng Guo and Josh Susskind", "title": "MetricOpt: Learning to Optimize Black-Box Evaluation Metrics", "comments": "CVPR 2021 (Oral), Supplementary Materials added", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of directly optimizing arbitrary non-differentiable task\nevaluation metrics such as misclassification rate and recall. Our method, named\nMetricOpt, operates in a black-box setting where the computational details of\nthe target metric are unknown. We achieve this by learning a differentiable\nvalue function, which maps compact task-specific model parameters to metric\nobservations. The learned value function is easily pluggable into existing\noptimizers like SGD and Adam, and is effective for rapidly finetuning a\npre-trained model. This leads to consistent improvements since the value\nfunction provides effective metric supervision during finetuning, and helps to\ncorrect the potential bias of loss-only supervision. MetricOpt achieves\nstate-of-the-art performance on a variety of metrics for (image)\nclassification, image retrieval and object detection. Solid benefits are found\nover competing methods, which often involve complex loss design or adaptation.\nMetricOpt also generalizes well to new tasks and model architectures.\n", "versions": [{"version": "v1", "created": "Wed, 21 Apr 2021 16:50:01 GMT"}], "update_date": "2021-04-22", "authors_parsed": [["Huang", "Chen", ""], ["Zhai", "Shuangfei", ""], ["Guo", "Pengsheng", ""], ["Susskind", "Josh", ""]]}, {"id": "2104.10637", "submitter": "Zhan Yu", "authors": "Zhan Yu, Daniel W. C. Ho, Ding-Xuan Zhou", "title": "Robust Kernel-based Distribution Regression", "comments": "29 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.FA stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Regularization schemes for regression have been widely studied in learning\ntheory and inverse problems. In this paper, we study distribution regression\n(DR) which involves two stages of sampling, and aims at regressing from\nprobability measures to real-valued responses over a reproducing kernel Hilbert\nspace (RKHS). Recently, theoretical analysis on DR has been carried out via\nkernel ridge regression and several learning behaviors have been observed.\nHowever, the topic has not been explored and understood beyond the least square\nbased DR. By introducing a robust loss function $l_{\\sigma}$ for two-stage\nsampling problems, we present a novel robust distribution regression (RDR)\nscheme. With a windowing function $V$ and a scaling parameter $\\sigma$ which\ncan be appropriately chosen, $l_{\\sigma}$ can include a wide range of popular\nused loss functions that enrich the theme of DR. Moreover, the loss\n$l_{\\sigma}$ is not necessarily convex, hence largely improving the former\nregression class (least square) in the literature of DR. The learning rates\nunder different regularity ranges of the regression function $f_{\\rho}$ are\ncomprehensively studied and derived via integral operator techniques. The\nscaling parameter $\\sigma$ is shown to be crucial in providing robustness and\nsatisfactory learning rates of RDR.\n", "versions": [{"version": "v1", "created": "Wed, 21 Apr 2021 17:03:46 GMT"}], "update_date": "2021-04-22", "authors_parsed": [["Yu", "Zhan", ""], ["Ho", "Daniel W. C.", ""], ["Zhou", "Ding-Xuan", ""]]}, {"id": "2104.10638", "submitter": "Daniel Heestermans Svendsen", "authors": "Daniel Heestermans Svendsen, Pablo Morales-Alvarez, Ana Belen Ruescas,\n  Rafael Molina, Gustau Camps-Valls", "title": "Deep Gaussian Processes for Biogeophysical Parameter Retrieval and Model\n  Inversion", "comments": null, "journal-ref": "ISPRS Journal of Photogrammetry and Remote Sensing 166 (2020):\n  68-81", "doi": "10.1016/j.isprsjprs.2020.04.014", "report-no": null, "categories": "eess.SP cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Parameter retrieval and model inversion are key problems in remote sensing\nand Earth observation. Currently, different approximations exist: a direct, yet\ncostly, inversion of radiative transfer models (RTMs); the statistical\ninversion with in situ data that often results in problems with extrapolation\noutside the study area; and the most widely adopted hybrid modeling by which\nstatistical models, mostly nonlinear and non-parametric machine learning\nalgorithms, are applied to invert RTM simulations. We will focus on the latter.\nAmong the different existing algorithms, in the last decade kernel based\nmethods, and Gaussian Processes (GPs) in particular, have provided useful and\ninformative solutions to such RTM inversion problems. This is in large part due\nto the confidence intervals they provide, and their predictive accuracy.\nHowever, RTMs are very complex, highly nonlinear, and typically hierarchical\nmodels, so that often a shallow GP model cannot capture complex feature\nrelations for inversion. This motivates the use of deeper hierarchical\narchitectures, while still preserving the desirable properties of GPs. This\npaper introduces the use of deep Gaussian Processes (DGPs) for bio-geo-physical\nmodel inversion. Unlike shallow GP models, DGPs account for complicated\n(modular, hierarchical) processes, provide an efficient solution that scales\nwell to big datasets, and improve prediction accuracy over their single layer\ncounterpart. In the experimental section, we provide empirical evidence of\nperformance for the estimation of surface temperature and dew point temperature\nfrom infrared sounding data, as well as for the prediction of chlorophyll\ncontent, inorganic suspended matter, and coloured dissolved matter from\nmultispectral data acquired by the Sentinel-3 OLCI sensor. The presented\nmethodology allows for more expressive forms of GPs in remote sensing model\ninversion problems.\n", "versions": [{"version": "v1", "created": "Fri, 16 Apr 2021 10:42:01 GMT"}], "update_date": "2021-04-22", "authors_parsed": [["Svendsen", "Daniel Heestermans", ""], ["Morales-Alvarez", "Pablo", ""], ["Ruescas", "Ana Belen", ""], ["Molina", "Rafael", ""], ["Camps-Valls", "Gustau", ""]]}, {"id": "2104.10640", "submitter": "Sushant Singh", "authors": "Sushant Singh and Ausif Mahmood", "title": "The NLP Cookbook: Modern Recipes for Transformer based Deep Learning\n  Architectures", "comments": "27 pages and 29 figures", "journal-ref": "IEEE Access (Volume: 9), 2021", "doi": "10.1109/ACCESS.2021.3077350", "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  In recent years, Natural Language Processing (NLP) models have achieved\nphenomenal success in linguistic and semantic tasks like text classification,\nmachine translation, cognitive dialogue systems, information retrieval via\nNatural Language Understanding (NLU), and Natural Language Generation (NLG).\nThis feat is primarily attributed due to the seminal Transformer architecture,\nleading to designs such as BERT, GPT (I, II, III), etc. Although these\nlarge-size models have achieved unprecedented performances, they come at high\ncomputational costs. Consequently, some of the recent NLP architectures have\nutilized concepts of transfer learning, pruning, quantization, and knowledge\ndistillation to achieve moderate model sizes while keeping nearly similar\nperformances as achieved by their predecessors. Additionally, to mitigate the\ndata size challenge raised by language models from a knowledge extraction\nperspective, Knowledge Retrievers have been built to extricate explicit data\ndocuments from a large corpus of databases with greater efficiency and\naccuracy. Recent research has also focused on superior inference by providing\nefficient attention to longer input sequences. In this paper, we summarize and\nexamine the current state-of-the-art (SOTA) NLP models that have been employed\nfor numerous NLP tasks for optimal performance and efficiency. We provide a\ndetailed understanding and functioning of the different architectures, a\ntaxonomy of NLP designs, comparative evaluations, and future directions in NLP.\n", "versions": [{"version": "v1", "created": "Tue, 23 Mar 2021 22:38:20 GMT"}, {"version": "v2", "created": "Thu, 22 Apr 2021 05:38:37 GMT"}, {"version": "v3", "created": "Sat, 24 Apr 2021 17:31:46 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Singh", "Sushant", ""], ["Mahmood", "Ausif", ""]]}, {"id": "2104.10644", "submitter": "Mingming Liu", "authors": "Zhengyong Chen, Hongde Wu, Noel E. O'Connor, Mingming Liu", "title": "A Comparative Study of Using Spatial-Temporal Graph Convolutional\n  Networks for Predicting Availability in Bike Sharing Schemes", "comments": "This manuscript has been accepted at the IEEE ITSC 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurately forecasting transportation demand is crucial for efficient urban\ntraffic guidance, control and management. One solution to enhance the level of\nprediction accuracy is to leverage graph convolutional networks (GCN), a neural\nnetwork based modelling approach with the ability to process data contained in\ngraph based structures. As a powerful extension of GCN, a spatial-temporal\ngraph convolutional network (ST-GCN) aims to capture the relationship of data\ncontained in the graphical nodes across both spatial and temporal dimensions,\nwhich presents a novel deep learning paradigm for the analysis of complex\ntime-series data that also involves spatial information as present in\ntransportation use cases. In this paper, we present an Attention-based ST-GCN\n(AST-GCN) for predicting the number of available bikes in bike-sharing systems\nin cities, where the attention-based mechanism is introduced to further improve\nthe performance of an ST-GCN. Furthermore, we also discuss the impacts of\ndifferent modelling methods of adjacency matrices on the proposed architecture.\nOur experimental results are presented using two real-world datasets,\nDublinbikes and NYC-Citi Bike, to illustrate the efficacy of our proposed model\nwhich outperforms the majority of existing approaches.\n", "versions": [{"version": "v1", "created": "Wed, 21 Apr 2021 17:13:29 GMT"}, {"version": "v2", "created": "Wed, 7 Jul 2021 02:26:44 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Chen", "Zhengyong", ""], ["Wu", "Hongde", ""], ["O'Connor", "Noel E.", ""], ["Liu", "Mingming", ""]]}, {"id": "2104.10645", "submitter": "Lennart Heim", "authors": "Lennart Heim, Andreas Biri, Zhongnan Qu, Lothar Thiele", "title": "Measuring what Really Matters: Optimizing Neural Networks for TinyML", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the surge of inexpensive computational and memory resources, neural\nnetworks (NNs) have experienced an unprecedented growth in architectural and\ncomputational complexity. Introducing NNs to resource-constrained devices\nenables cost-efficient deployments, widespread availability, and the\npreservation of sensitive data. This work addresses the challenges of bringing\nMachine Learning to MCUs, where we focus on the ubiquitous ARM Cortex-M\narchitecture. The detailed effects and trade-offs that optimization methods,\nsoftware frameworks, and MCU hardware architecture have on key performance\nmetrics such as inference latency and energy consumption have not been\npreviously studied in depth for state-of-the-art frameworks such as TensorFlow\nLite Micro. We find that empirical investigations which measure the perceptible\nmetrics - performance as experienced by the user - are indispensable, as the\nimpact of specialized instructions and layer types can be subtle. To this end,\nwe propose an implementation-aware design as a cost-effective method for\nverification and benchmarking. Employing our developed toolchain, we\ndemonstrate how existing NN deployments on resource-constrained devices can be\nimproved by systematically optimizing NNs to their targeted application\nscenario.\n", "versions": [{"version": "v1", "created": "Wed, 21 Apr 2021 17:14:06 GMT"}], "update_date": "2021-04-22", "authors_parsed": [["Heim", "Lennart", ""], ["Biri", "Andreas", ""], ["Qu", "Zhongnan", ""], ["Thiele", "Lothar", ""]]}, {"id": "2104.10652", "submitter": "Biplob Biswas", "authors": "Biplob Biswas, Thai-Hoang Pham, Ping Zhang", "title": "TransICD: Transformer Based Code-wise Attention Model for Explainable\n  ICD Coding", "comments": "10 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  International Classification of Disease (ICD) coding procedure which refers\nto tagging medical notes with diagnosis codes has been shown to be effective\nand crucial to the billing system in medical sector. Currently, ICD codes are\nassigned to a clinical note manually which is likely to cause many errors.\nMoreover, training skilled coders also requires time and human resources.\nTherefore, automating the ICD code determination process is an important task.\nWith the advancement of artificial intelligence theory and computational\nhardware, machine learning approach has emerged as a suitable solution to\nautomate this process. In this project, we apply a transformer-based\narchitecture to capture the interdependence among the tokens of a document and\nthen use a code-wise attention mechanism to learn code-specific representations\nof the entire document. Finally, they are fed to separate dense layers for\ncorresponding code prediction. Furthermore, to handle the imbalance in the code\nfrequency of clinical datasets, we employ a label distribution aware margin\n(LDAM) loss function. The experimental results on the MIMIC-III dataset show\nthat our proposed model outperforms other baselines by a significant margin. In\nparticular, our best setting achieves a micro-AUC score of 0.923 compared to\n0.868 of bidirectional recurrent neural networks. We also show that by using\nthe code-wise attention mechanism, the model can provide more insights about\nits prediction, and thus it can support clinicians to make reliable decisions.\nOur code is available online (https://github.com/biplob1ly/TransICD)\n", "versions": [{"version": "v1", "created": "Sun, 28 Mar 2021 05:34:32 GMT"}], "update_date": "2021-04-22", "authors_parsed": [["Biswas", "Biplob", ""], ["Pham", "Thai-Hoang", ""], ["Zhang", "Ping", ""]]}, {"id": "2104.10658", "submitter": "Dewayne Whitfield", "authors": "Dewayne Whitfield", "title": "Using GPT-2 to Create Synthetic Data to Improve the Prediction\n  Performance of NLP Machine Learning Classification Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Classification Models use input data to predict the likelihood that the\nsubsequent input data will fall into predetermined categories. To perform\neffective classifications, these models require large datasets for training. It\nis becoming common practice to utilize synthetic data to boost the performance\nof Machine Learning Models. It is reported that Shell is using synthetic data\nto build models to detect problems that rarely occur; for example Shell created\nsynthetic data to help models to identify deteriorating oil lines. It is common\npractice for Machine Learning Practitioners to generate synthetic data by\nrotating, flipping, and cropping images to increase the volume of image data to\ntrain Convolutional Neural Networks. The purpose of this paper is to explore\ncreating and utilizing synthetic NLP data to improve the performance of Natural\nLanguage Processing Machine Learning Classification Models. In this paper I\nused a Yelp pizza restaurant reviews dataset and transfer learning to fine-tune\na pre-trained GPT-2 Transformer Model to generate synthetic pizza reviews data.\nI then combined this synthetic data with the original genuine data to create a\nnew joint dataset. The new combined model significantly outperformed the\noriginal model in accuracy and precision.\n", "versions": [{"version": "v1", "created": "Fri, 2 Apr 2021 20:20:42 GMT"}], "update_date": "2021-04-22", "authors_parsed": [["Whitfield", "Dewayne", ""]]}, {"id": "2104.10667", "submitter": "Hassan Habibi Gharakheili", "authors": "Iresha Pasquel Mohottige and Hassan Habibi Gharakheili and Vijay\n  Sivaraman and Tim Moors", "title": "Modeling Classroom Occupancy using Data of WiFi Infrastructure in a\n  University Campus", "comments": "23 pages, 20 figures, 8 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Universities worldwide are experiencing a surge in enrollments, therefore\ncampus estate managers are seeking continuous data on attendance patterns to\noptimize the usage of classroom space. As a result, there is an increasing\ntrend to measure classrooms attendance by employing various sensing\ntechnologies, among which pervasive WiFi infrastructure is seen as a low cost\nmethod. In a dense campus environment, the number of connected WiFi users does\nnot well estimate room occupancy since connection counts are polluted by\nadjoining rooms, outdoor walkways, and network load balancing.\n  In this paper, we develop machine learning based models to infer classroom\noccupancy from WiFi sensing infrastructure. Our contributions are three-fold:\n(1) We analyze metadata from a dense and dynamic wireless network comprising of\nthousands of access points (APs) to draw insights into coverage of APs,\nbehavior of WiFi connected users, and challenges of estimating room occupancy;\n(2) We propose a method to automatically map APs to classrooms using\nunsupervised clustering algorithms; and (3) We model classroom occupancy using\na combination of classification and regression methods of varying algorithms.\nWe achieve 84.6% accuracy in mapping APs to classrooms while the accuracy of\nour estimation for room occupancy is comparable to beam counter sensors with a\nsymmetric Mean Absolute Percentage Error (sMAPE) of 13.10%.\n", "versions": [{"version": "v1", "created": "Mon, 19 Apr 2021 06:15:45 GMT"}], "update_date": "2021-04-22", "authors_parsed": [["Mohottige", "Iresha Pasquel", ""], ["Gharakheili", "Hassan Habibi", ""], ["Sivaraman", "Vijay", ""], ["Moors", "Tim", ""]]}, {"id": "2104.10671", "submitter": "Yongfeng Zhang", "authors": "Yunqi Li, Hanxiong Chen, Zuohui Fu, Yingqiang Ge, Yongfeng Zhang", "title": "User-oriented Fairness in Recommendation", "comments": "Accepted to the 30th Web Conference (WWW 2021)", "journal-ref": null, "doi": "10.1145/3442381.3449866", "report-no": null, "categories": "cs.IR cs.AI cs.HC cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As a highly data-driven application, recommender systems could be affected by\ndata bias, resulting in unfair results for different data groups, which could\nbe a reason that affects the system performance. Therefore, it is important to\nidentify and solve the unfairness issues in recommendation scenarios. In this\npaper, we address the unfairness problem in recommender systems from the user\nperspective. We group users into advantaged and disadvantaged groups according\nto their level of activity, and conduct experiments to show that current\nrecommender systems will behave unfairly between two groups of users.\nSpecifically, the advantaged users (active) who only account for a small\nproportion in data enjoy much higher recommendation quality than those\ndisadvantaged users (inactive). Such bias can also affect the overall\nperformance since the disadvantaged users are the majority. To solve this\nproblem, we provide a re-ranking approach to mitigate this unfairness problem\nby adding constraints over evaluation metrics. The experiments we conducted on\nseveral real-world datasets with various recommendation algorithms show that\nour approach can not only improve group fairness of users in recommender\nsystems, but also achieve better overall recommendation performance.\n", "versions": [{"version": "v1", "created": "Wed, 21 Apr 2021 17:50:31 GMT"}], "update_date": "2021-04-22", "authors_parsed": [["Li", "Yunqi", ""], ["Chen", "Hanxiong", ""], ["Fu", "Zuohui", ""], ["Ge", "Yingqiang", ""], ["Zhang", "Yongfeng", ""]]}, {"id": "2104.10680", "submitter": "Bingyang Wen", "authors": "Bingyang Wen, Luis Oliveros Colon, K.P. Subbalakshmi and R.\n  Chandramouli", "title": "Causal-TGAN: Generating Tabular Data Using Causal Generative Adversarial\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Synthetic data generation becomes prevalent as a solution to privacy leakage\nand data shortage. Generative models are designed to generate a realistic\nsynthetic dataset, which can precisely express the data distribution for the\nreal dataset. The generative adversarial networks (GAN), which gain great\nsuccess in the computer vision fields, are doubtlessly used for synthetic data\ngeneration. Though there are prior works that have demonstrated great progress,\nmost of them learn the correlations in the data distributions rather than the\ntrue processes in which the datasets are naturally generated. Correlation is\nnot reliable for it is a statistical technique that only tells linear\ndependencies and is easily affected by the dataset's bias. Causality, which\nencodes all underlying factors of how the real data be naturally generated, is\nmore reliable than correlation. In this work, we propose a causal model named\nCausal Tabular Generative Neural Network (Causal-TGAN) to generate synthetic\ntabular data using the tabular data's causal information. Extensive experiments\non both simulated datasets and real datasets demonstrate the better performance\nof our method when given the true causal graph and a comparable performance\nwhen using the estimated causal graph.\n", "versions": [{"version": "v1", "created": "Wed, 21 Apr 2021 17:59:41 GMT"}], "update_date": "2021-04-22", "authors_parsed": [["Wen", "Bingyang", ""], ["Colon", "Luis Oliveros", ""], ["Subbalakshmi", "K. P.", ""], ["Chandramouli", "R.", ""]]}, {"id": "2104.10683", "submitter": "Arnd Koeppe", "authors": "Arnd Koeppe and Franz Bamer and Michael Selzer and Britta Nestler and\n  Bernd Markert", "title": "Explainable artificial intelligence for mechanics: physics-informing\n  neural networks for constitutive models", "comments": "Preprint - Rev-2 (minor grammatical changes; prevent Google from\n  archiving)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  (Artificial) neural networks have become increasingly popular in mechanics to\naccelerate computations with model order reduction techniques and as universal\nmodels for a wide variety of materials. However, the major disadvantage of\nneural networks remains: their numerous parameters are challenging to interpret\nand explain. Thus, neural networks are often labeled as black boxes, and their\nresults often elude human interpretation. In mechanics, the new and active\nfield of physics-informed neural networks attempts to mitigate this\ndisadvantage by designing deep neural networks on the basis of mechanical\nknowledge. By using this a priori knowledge, deeper and more complex neural\nnetworks became feasible, since the mechanical assumptions could be explained.\nHowever, the internal reasoning and explanation of neural network parameters\nremain mysterious.\n  Complementary to the physics-informed approach, we propose a first step\ntowards a physics-informing approach, which explains neural networks trained on\nmechanical data a posteriori. This novel explainable artificial intelligence\napproach aims at elucidating the black box of neural networks and their\nhigh-dimensional representations. Therein, the principal component analysis\ndecorrelates the distributed representations in cell states of RNNs and allows\nthe comparison to known and fundamental functions. The novel approach is\nsupported by a systematic hyperparameter search strategy that identifies the\nbest neural network architectures and training parameters. The findings of\nthree case studies on fundamental constitutive models (hyperelasticity,\nelastoplasticity, and viscoelasticity) imply that the proposed strategy can\nhelp identify numerical and analytical closed-form solutions to characterize\nnew materials.\n", "versions": [{"version": "v1", "created": "Tue, 20 Apr 2021 18:38:52 GMT"}, {"version": "v2", "created": "Thu, 20 May 2021 10:27:59 GMT"}, {"version": "v3", "created": "Mon, 14 Jun 2021 08:01:35 GMT"}, {"version": "v4", "created": "Mon, 12 Jul 2021 15:36:21 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Koeppe", "Arnd", ""], ["Bamer", "Franz", ""], ["Selzer", "Michael", ""], ["Nestler", "Britta", ""], ["Markert", "Bernd", ""]]}, {"id": "2104.10684", "submitter": "Sara Zahedian", "authors": "Sara Zahedian, Amir Nohekhan, Kaveh Farokhi Sadabadi", "title": "Dynamic Toll Prediction Using Historical Data on Toll Roads: Case Study\n  of the I-66 Inner Beltway", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Providing the users of a dynamic tolling system with predictions of tolling\nprices and the travel time difference between the toll road and the alternative\nroutes enables them to make their travel decisions before starting their trip.\nThis study aims to provide accurate predictions of tolling price through\ntraining and testing random forest, multilayer perceptron, and long short-term\nmemory models and compare them with the current situation that the best\nprediction is extending the current toll to the next timesteps. The prediction\ntime horizon includes five 6-minute time intervals ahead of the present time.\nThe prediction performance of models over the testing set reveals that while\nall the models were significantly better than the base model, the random forest\noutperforms all models. For instance, while in the trained models, the mean\nabsolute error range is from $1.5 to $2.5 for the next six minutes to the next\n30 minutes, respectively, the same measure in the base model is in the range of\n$2.5 to $6. The prediction of travel time difference along the toll road and\nits alternative route with the shortest travel time revealed that the\nmultilayer perceptron performs marginally better than the base model. However,\ndue to a relatively stable travel time difference, the current travel time\ndifference is an acceptable prediction for the next 30 minutes prediction\nhorizon.\n", "versions": [{"version": "v1", "created": "Tue, 20 Apr 2021 19:13:10 GMT"}], "update_date": "2021-04-23", "authors_parsed": [["Zahedian", "Sara", ""], ["Nohekhan", "Amir", ""], ["Sadabadi", "Kaveh Farokhi", ""]]}, {"id": "2104.10696", "submitter": "Sheng-Hsuan Lin", "authors": "Sheng-Hsuan Lin, Frank Pollmann", "title": "Scaling of neural-network quantum states for time evolution", "comments": "8 pages, 6 figures (+appendix: 4 pages, 3 figures)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cond-mat.dis-nn cond-mat.str-el cs.LG quant-ph", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Simulating quantum many-body dynamics on classical computers is a challenging\nproblem due to the exponential growth of the Hilbert space. Artificial neural\nnetworks have recently been introduced as a new tool to approximate\nquantum-many body states. We benchmark the variational power of different\nshallow and deep neural autoregressive quantum states to simulate global quench\ndynamics of a non-integrable quantum Ising chain. We find that the number of\nparameters required to represent the quantum state at a given accuracy\nincreases exponentially in time. The growth rate is only slightly affected by\nthe network architecture over a wide range of different design choices: shallow\nand deep networks, small and large filter sizes, dilated and normal\nconvolutions, with and without shortcut connections.\n", "versions": [{"version": "v1", "created": "Wed, 21 Apr 2021 18:00:07 GMT"}], "update_date": "2021-04-23", "authors_parsed": [["Lin", "Sheng-Hsuan", ""], ["Pollmann", "Frank", ""]]}, {"id": "2104.10706", "submitter": "Pratyush Maini", "authors": "Pratyush Maini and Mohammad Yaghini and Nicolas Papernot", "title": "Dataset Inference: Ownership Resolution in Machine Learning", "comments": "Published as a conference paper at ICLR 2021 (Spotlight Presentation)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With increasingly more data and computation involved in their training,\nmachine learning models constitute valuable intellectual property. This has\nspurred interest in model stealing, which is made more practical by advances in\nlearning with partial, little, or no supervision. Existing defenses focus on\ninserting unique watermarks in a model's decision surface, but this is\ninsufficient: the watermarks are not sampled from the training distribution and\nthus are not always preserved during model stealing. In this paper, we make the\nkey observation that knowledge contained in the stolen model's training set is\nwhat is common to all stolen copies. The adversary's goal, irrespective of the\nattack employed, is always to extract this knowledge or its by-products. This\ngives the original model's owner a strong advantage over the adversary: model\nowners have access to the original training data. We thus introduce $dataset$\n$inference$, the process of identifying whether a suspected model copy has\nprivate knowledge from the original model's dataset, as a defense against model\nstealing. We develop an approach for dataset inference that combines\nstatistical testing with the ability to estimate the distance of multiple data\npoints to the decision boundary. Our experiments on CIFAR10, SVHN, CIFAR100 and\nImageNet show that model owners can claim with confidence greater than 99% that\ntheir model (or dataset as a matter of fact) was stolen, despite only exposing\n50 of the stolen model's training points. Dataset inference defends against\nstate-of-the-art attacks even when the adversary is adaptive. Unlike prior\nwork, it does not require retraining or overfitting the defended model.\n", "versions": [{"version": "v1", "created": "Wed, 21 Apr 2021 18:12:18 GMT"}], "update_date": "2021-04-23", "authors_parsed": [["Maini", "Pratyush", ""], ["Yaghini", "Mohammad", ""], ["Papernot", "Nicolas", ""]]}, {"id": "2104.10715", "submitter": "Rishab Khincha", "authors": "Utkarsh Sarawgi, Rishab Khincha, Wazeer Zulfikar, Satrajit Ghosh,\n  Pattie Maes", "title": "Uncertainty-Aware Boosted Ensembling in Multi-Modal Settings", "comments": "Accepted at IJCNN 2021, to appear in IEEE proceedings. Equal\n  contributions from US, RK and WZ", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Reliability of machine learning (ML) systems is crucial in safety-critical\napplications such as healthcare, and uncertainty estimation is a widely\nresearched method to highlight the confidence of ML systems in deployment.\nSequential and parallel ensemble techniques have shown improved performance of\nML systems in multi-modal settings by leveraging the feature sets together. We\npropose an uncertainty-aware boosting technique for multi-modal ensembling in\norder to focus on the data points with higher associated uncertainty estimates,\nrather than the ones with higher loss values. We evaluate this method on\nhealthcare tasks related to Dementia and Parkinson's disease which involve\nreal-world multi-modal speech and text data, wherein our method shows an\nimproved performance. Additional analysis suggests that introducing\nuncertainty-awareness into the boosted ensembles decreases the overall entropy\nof the system, making it more robust to heteroscedasticity in the data, as well\nas better calibrating each of the modalities along with high quality prediction\nintervals. We open-source our entire codebase at\nhttps://github.com/usarawgi911/Uncertainty-aware-boosting\n", "versions": [{"version": "v1", "created": "Wed, 21 Apr 2021 18:28:13 GMT"}], "update_date": "2021-04-23", "authors_parsed": [["Sarawgi", "Utkarsh", ""], ["Khincha", "Rishab", ""], ["Zulfikar", "Wazeer", ""], ["Ghosh", "Satrajit", ""], ["Maes", "Pattie", ""]]}, {"id": "2104.10716", "submitter": "Chien-Yu Lin", "authors": "Chien-Yu Lin, Liang Luo, Luis Ceze", "title": "Accelerating SpMM Kernel with Cache-First Edge Sampling for Graph Neural\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph neural networks (GNNs), an emerging deep learning model class, can\nextract meaningful representations from highly expressive graph-structured data\nand are therefore gaining popularity for wider ranges of applications. However,\ncurrent GNNs suffer from the poor performance of their sparse-dense matrix\nmultiplication (SpMM) operator, even when using powerful GPUs. Our analysis\nshows that 95% of the inference time could be spent on SpMM when running\npopular GNN models on NVIDIA's advanced V100 GPU. Such SpMM performance\nbottleneck hinders GNNs' applicability to large-scale problems or the\ndevelopment of more sophisticated GNN models. To address this inference time\nbottleneck, we introduce ES-SpMM, a cache-first edge sampling mechanism and\ncodesigned SpMM kernel. ES-SpMM uses edge sampling to downsize the graph to fit\ninto GPU's shared memory. It thus reduces the computation cost and improves\nSpMM's cache locality. To evaluate ES-SpMM's performance, we integrated it with\na popular GNN framework, DGL, and tested it using representative GNN models and\ndatasets. Our results show that ES-SpMM outperforms the highly optimized\ncuSPARSE SpMM kernel by up to 4.35x with no accuracy loss and by 45.3x with\nless than a 1% accuracy loss.\n", "versions": [{"version": "v1", "created": "Wed, 21 Apr 2021 18:33:30 GMT"}, {"version": "v2", "created": "Fri, 23 Apr 2021 20:50:10 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Lin", "Chien-Yu", ""], ["Luo", "Liang", ""], ["Ceze", "Luis", ""]]}, {"id": "2104.10727", "submitter": "Benny Avelin", "authors": "Benny Avelin and Anders Karlsson", "title": "Deep limits and cut-off phenomena for neural networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.DS stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We consider dynamical and geometrical aspects of deep learning. For many\nstandard choices of layer maps we display semi-invariant metrics which quantify\ndifferences between data or decision functions. This allows us, when\nconsidering random layer maps and using non-commutative ergodic theorems, to\ndeduce that certain limits exist when letting the number of layers tend to\ninfinity. We also examine the random initialization of standard networks where\nwe observe a surprising cut-off phenomenon in terms of the number of layers,\nthe depth of the network. This could be a relevant parameter when choosing an\nappropriate number of layers for a given learning task, or for selecting a good\ninitialization procedure. More generally, we hope that the notions and results\nin this paper can provide a framework, in particular a geometric one, for a\npart of the theoretical understanding of deep neural networks.\n", "versions": [{"version": "v1", "created": "Wed, 21 Apr 2021 19:07:43 GMT"}], "update_date": "2021-04-23", "authors_parsed": [["Avelin", "Benny", ""], ["Karlsson", "Anders", ""]]}, {"id": "2104.10731", "submitter": "Sylvain Calinon Dr", "authors": "Sylvain Calinon", "title": "Mixture Models for the Analysis, Edition, and Synthesis of Continuous\n  Time Series", "comments": "20 pages, 7 figures", "journal-ref": "Bouguila, N. and Fan, W. (eds). Mixture Models and Applications,\n  pp. 39-57. Springer, 2019", "doi": "10.1007/978-3-030-23876-6_3", "report-no": null, "categories": "cs.RO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This chapter presents an overview of techniques used for the analysis,\nedition, and synthesis of time series, with a particular emphasis on motion\ndata. The use of mixture models allows the decomposition of time signals as a\nsuperposition of basis functions. It provides a compact representation that\naims at keeping the essential characteristics of the signals. Various types of\nbasis functions have been proposed, with developments originating from\ndifferent fields of research, including computer graphics, human motion\nscience, robotics, control, and neuroscience. Examples of applications with\nradial, Bernstein and Fourier basis functions will be presented, with\nassociated source codes to get familiar with these techniques.\n", "versions": [{"version": "v1", "created": "Wed, 21 Apr 2021 19:20:59 GMT"}], "update_date": "2021-04-23", "authors_parsed": [["Calinon", "Sylvain", ""]]}, {"id": "2104.10740", "submitter": "Ziteng Sun", "authors": "Jayadev Acharya, Ziteng Sun, Huanyu Zhang", "title": "Robust Testing and Estimation under Manipulation Attacks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.DM cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study robust testing and estimation of discrete distributions in the\nstrong contamination model. We consider both the \"centralized setting\" and the\n\"distributed setting with information constraints\" including communication and\nlocal privacy (LDP) constraints. Our technique relates the strength of\nmanipulation attacks to the earth-mover distance using Hamming distance as the\nmetric between messages(samples) from the users. In the centralized setting, we\nprovide optimal error bounds for both learning and testing. Our lower bounds\nunder local information constraints build on the recent lower bound methods in\ndistributed inference. In the communication constrained setting, we develop\nnovel algorithms based on random hashing and an $\\ell_1/\\ell_1$ isometry.\n", "versions": [{"version": "v1", "created": "Wed, 21 Apr 2021 19:49:49 GMT"}], "update_date": "2021-04-23", "authors_parsed": [["Acharya", "Jayadev", ""], ["Sun", "Ziteng", ""], ["Zhang", "Huanyu", ""]]}, {"id": "2104.10741", "submitter": "Florian Kadner", "authors": "Florian Kadner, Yannik Keller and Constantin A. Rothkopf", "title": "AdaptiFont: Increasing Individuals' Reading Speed with a Generative Font\n  Model and Bayesian Optimization", "comments": "18 pages, 11 figures", "journal-ref": "In Proceedings of the 2021 CHI Conference on Human Factors in\n  Computing Systems (CHI '21). Association for Computing Machinery, New York,\n  NY, USA, Article 585, 1-11", "doi": "10.1145/3411764.3445140", "report-no": null, "categories": "cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Digital text has become one of the primary ways of exchanging knowledge, but\ntext needs to be rendered to a screen to be read. We present AdaptiFont, a\nhuman-in-the-loop system that is aimed at interactively increasing readability\nof text displayed on a monitor. To this end, we first learn a generative font\nspace with non-negative matrix factorization from a set of classic fonts. In\nthis space we generate new true-type-fonts through active learning, render\ntexts with the new font, and measure individual users' reading speed. Bayesian\noptimization sequentially generates new fonts on the fly to progressively\nincrease individuals' reading speed. The results of a user study show that this\nadaptive font generation system finds regions in the font space corresponding\nto high reading speeds, that these fonts significantly increase participants'\nreading speed, and that the found fonts are significantly different across\nindividual readers.\n", "versions": [{"version": "v1", "created": "Wed, 21 Apr 2021 19:56:28 GMT"}], "update_date": "2021-05-13", "authors_parsed": [["Kadner", "Florian", ""], ["Keller", "Yannik", ""], ["Rothkopf", "Constantin A.", ""]]}, {"id": "2104.10745", "submitter": "Adrian Celaya", "authors": "Adrian Celaya, Jonas A. Actor, Rajarajeswari Muthusivarajan, Evan\n  Gates, Caroline Chung, Dawid Schellingerhout, Beatrice Riviere, David Fuentes", "title": "PocketNet: A Smaller Neural Network for Medical Image Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Medical imaging deep learning models are often large and complex, requiring\nspecialized hardware to train and evaluate these models. To address such\nissues, we propose the PocketNet paradigm to reduce the size of deep learning\nmodels by throttling the growth of the number of channels in convolutional\nneural networks. We demonstrate that, for a range of segmentation and\nclassification tasks, PocketNet architectures produce results comparable to\nthat of conventional neural networks while reducing the number of parameters by\nmultiple orders of magnitude, using up to 90% less GPU memory, and speeding up\ntraining times by up to 40%, thereby allowing such models to be trained and\ndeployed in resource-constrained settings.\n", "versions": [{"version": "v1", "created": "Wed, 21 Apr 2021 20:10:30 GMT"}, {"version": "v2", "created": "Thu, 24 Jun 2021 03:29:46 GMT"}], "update_date": "2021-06-25", "authors_parsed": [["Celaya", "Adrian", ""], ["Actor", "Jonas A.", ""], ["Muthusivarajan", "Rajarajeswari", ""], ["Gates", "Evan", ""], ["Chung", "Caroline", ""], ["Schellingerhout", "Dawid", ""], ["Riviere", "Beatrice", ""], ["Fuentes", "David", ""]]}, {"id": "2104.10746", "submitter": "Jan Palczewski", "authors": "Lukas Cironis, Jan Palczewski, Georgios Aivaliotis", "title": "Automatic model training under restrictive time constraints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a hyperparameter optimisation algorithm, Automated Budget\nConstrained Training (AutoBCT), which balances the quality of a model with the\ncomputational cost required to tune it. The relationship between\nhyperparameters, model quality and computational cost must be learnt and this\nlearning is incorporated directly into the optimisation problem. At each\ntraining epoch, the algorithm decides whether to terminate or continue\ntraining, and, in the latter case, what values of hyperparameters to use. This\ndecision weighs optimally potential improvements in the quality with the\nadditional training time and the uncertainty about the learnt quantities. The\nperformance of our algorithm is verified on a number of machine learning\nproblems encompassing random forests and neural networks. Our approach is\nrooted in the theory of Markov decision processes with partial information and\nwe develop a numerical method to compute the value function and an optimal\nstrategy.\n", "versions": [{"version": "v1", "created": "Wed, 21 Apr 2021 20:20:36 GMT"}], "update_date": "2021-04-23", "authors_parsed": [["Cironis", "Lukas", ""], ["Palczewski", "Jan", ""], ["Aivaliotis", "Georgios", ""]]}, {"id": "2104.10748", "submitter": "Laura O. Moraes", "authors": "Laura O. Moraes, Carlos Eduardo Pedreira", "title": "Clustering Introductory Computer Science Exercises Using Topic Modeling\n  Methods", "comments": "13 pages, 11 figures, published in IEEE Transactions on Learning\n  Technologies", "journal-ref": "IEEE Transactions on Learning Technologies, vol. 14, no. 1, pp.\n  42-54, Feb. 2021", "doi": "10.1109/TLT.2021.3056907", "report-no": null, "categories": "cs.LG cs.CL cs.IR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Manually determining concepts present in a group of questions is a\nchallenging and time-consuming process. However, the process is an essential\nstep while modeling a virtual learning environment since a mapping between\nconcepts and questions using mastery level assessment and recommendation\nengines are required. We investigated unsupervised semantic models (known as\ntopic modeling techniques) to assist computer science teachers in this task and\npropose a method to transform Computer Science 1 teacher-provided code\nsolutions into representative text documents, including the code structure\ninformation. By applying non-negative matrix factorization and latent Dirichlet\nallocation techniques, we extract the underlying relationship between questions\nand validate the results using an external dataset. We consider the\ninterpretability of the learned concepts using 14 university professors' data,\nand the results confirm six semantically coherent clusters using the current\ndataset. Moreover, the six topics comprise the main concepts present in the\ntest dataset, achieving 0.75 in the normalized pointwise mutual information\nmetric. The metric correlates with human ratings, making the proposed method\nuseful and providing semantics for large amounts of unannotated code.\n", "versions": [{"version": "v1", "created": "Wed, 21 Apr 2021 20:23:53 GMT"}], "update_date": "2021-04-23", "authors_parsed": [["Moraes", "Laura O.", ""], ["Pedreira", "Carlos Eduardo", ""]]}, {"id": "2104.10751", "submitter": "Hakan Akyuz", "authors": "M. Hakan Aky\\\"uz, \\c{S}. \\.Ilker Birbil", "title": "Discovering Classification Rules for Interpretable Learning with Linear\n  Programming", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Rules embody a set of if-then statements which include one or more conditions\nto classify a subset of samples in a dataset. In various applications such\nclassification rules are considered to be interpretable by the decision makers.\nWe introduce two new algorithms for interpretability and learning. Both\nalgorithms take advantage of linear programming, and hence, they are scalable\nto large data sets. The first algorithm extracts rules for interpretation of\ntrained models that are based on tree/rule ensembles. The second algorithm\ngenerates a set of classification rules through a column generation approach.\nThe proposed algorithms return a set of rules along with their optimal weights\nindicating the importance of each rule for classification. Moreover, our\nalgorithms allow assigning cost coefficients, which could relate to different\nattributes of the rules, such as; rule lengths, estimator weights, number of\nfalse negatives, and so on. Thus, the decision makers can adjust these\ncoefficients to divert the training process and obtain a set of rules that are\nmore appealing for their needs. We have tested the performances of both\nalgorithms on a collection of datasets and presented a case study to elaborate\non optimal rule weights. Our results show that a good compromise between\ninterpretability and accuracy can be obtained by the proposed algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 21 Apr 2021 20:31:28 GMT"}], "update_date": "2021-04-23", "authors_parsed": [["Aky\u00fcz", "M. Hakan", ""], ["Birbil", "\u015e. \u0130lker", ""]]}, {"id": "2104.10761", "submitter": "Youri Raaijmakers", "authors": "Youri Raaijmakers and Silvio Mandelli and Mark Doll", "title": "Reinforcement learning for Admission Control in 5G Wireless Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG eess.SP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The key challenge in admission control in wireless networks is to strike an\noptimal trade-off between the blocking probability for new requests while\nminimizing the dropping probability of ongoing requests. We consider two\napproaches for solving the admission control problem: i) the typically adopted\nthreshold policy and ii) our proposed policy relying on reinforcement learning\nwith neural networks. Extensive simulation experiments are conducted to analyze\nthe performance of both policies. The results show that the reinforcement\nlearning policy outperforms the threshold-based policies in the scenario with\nheterogeneous time-varying arrival rates and multiple user equipment types,\nproving its applicability in realistic wireless network scenarios.\n", "versions": [{"version": "v1", "created": "Tue, 13 Apr 2021 06:37:18 GMT"}], "update_date": "2021-04-23", "authors_parsed": [["Raaijmakers", "Youri", ""], ["Mandelli", "Silvio", ""], ["Doll", "Mark", ""]]}, {"id": "2104.10770", "submitter": "Zeyu Wei", "authors": "Zeyu Wei and Yen-Chi Chen", "title": "Skeleton Clustering: Dimension-Free Density-based Clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a density-based clustering method called skeleton clustering\nthat can detect clusters in multivariate and even high-dimensional data with\nirregular shapes. To bypass the curse of dimensionality, we propose surrogate\ndensity measures that are less dependent on the dimension but have intuitive\ngeometric interpretations. The clustering framework constructs a concise\nrepresentation of the given data as an intermediate step and can be thought of\nas a combination of prototype methods, density-based clustering, and\nhierarchical clustering. We show by theoretical analysis and empirical studies\nthat the skeleton clustering leads to reliable clusters in multivariate and\nhigh-dimensional scenarios.\n", "versions": [{"version": "v1", "created": "Wed, 21 Apr 2021 21:25:02 GMT"}], "update_date": "2021-04-23", "authors_parsed": [["Wei", "Zeyu", ""], ["Chen", "Yen-Chi", ""]]}, {"id": "2104.10771", "submitter": "Joceline Lega", "authors": "Adrienne C. Kinney, Sean Current, Joceline Lega", "title": "Aedes-AI: Neural Network Models of Mosquito Abundance", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.PE cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  We present artificial neural networks as a feasible replacement for a\nmechanistic model of mosquito abundance. We develop a feed-forward neural\nnetwork, a long short-term memory recurrent neural network, and a gated\nrecurrent unit network. We evaluate the networks in their ability to replicate\nthe spatiotemporal features of mosquito populations predicted by the\nmechanistic model, and discuss how augmenting the training data with both\nactual and artificially created time series affects model performance. We\nconclude with an outlook on how such equation-free models may facilitate vector\ncontrol or the estimation of disease risk at arbitrary spatial scales.\n", "versions": [{"version": "v1", "created": "Wed, 21 Apr 2021 21:28:03 GMT"}], "update_date": "2021-04-23", "authors_parsed": [["Kinney", "Adrienne C.", ""], ["Current", "Sean", ""], ["Lega", "Joceline", ""]]}, {"id": "2104.10777", "submitter": "Joseph de Vilmarest", "authors": "Joseph de Vilmarest (LPSM), Olivier Wintenberger (LPSM)", "title": "Recursive Estimation of State-Space Noise Covariance Matrix by\n  Approximate Variational Bayes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This working paper considers state-space models where the variance of the\nobservation is known but the covariance matrix of the state process is unknown\nand potentially time-varying. We propose an adaptive algorithm to estimate\njointly the state and the covariance matrix of the state process, relying on\nVariational Bayes and second-order Taylor approximations.\n", "versions": [{"version": "v1", "created": "Fri, 16 Apr 2021 07:41:42 GMT"}], "update_date": "2021-04-23", "authors_parsed": [["de Vilmarest", "Joseph", "", "LPSM"], ["Wintenberger", "Olivier", "", "LPSM"]]}, {"id": "2104.10785", "submitter": "Reza Godaz", "authors": "Reza Godaz, Reza Monsefi, Faezeh Toutounian, Reshad Hosseini", "title": "Accurate and fast matrix factorization for low-rank learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we tackle two important challenges related to the accurate\npartial singular value decomposition (SVD) and numerical rank estimation of a\nhuge matrix to use in low-rank learning problems in a fast way. We use the\nconcepts of Krylov subspaces such as the Golub-Kahan bidiagonalization process\nas well as Ritz vectors to achieve these goals. Our experiments identify\nvarious advantages of the proposed methods compared to traditional and\nrandomized SVD (R-SVD) methods with respect to the accuracy of the singular\nvalues and corresponding singular vectors computed in a similar execution time.\nThe proposed methods are appropriate for applications involving huge matrices\nwhere accuracy in all spectrum of the desired singular values, and also all of\ncorresponding singular vectors is essential. We evaluate our method in the real\napplication of Riemannian similarity learning (RSL) between two various image\ndatasets of MNIST and USPS.\n", "versions": [{"version": "v1", "created": "Wed, 21 Apr 2021 22:35:02 GMT"}, {"version": "v2", "created": "Mon, 3 May 2021 18:27:31 GMT"}, {"version": "v3", "created": "Thu, 15 Jul 2021 18:01:59 GMT"}], "update_date": "2021-07-19", "authors_parsed": [["Godaz", "Reza", ""], ["Monsefi", "Reza", ""], ["Toutounian", "Faezeh", ""], ["Hosseini", "Reshad", ""]]}, {"id": "2104.10790", "submitter": "Richard Zhang", "authors": "Richard Y. Zhang", "title": "Sharp Global Guarantees for Nonconvex Low-Rank Matrix Recovery in the\n  Overparameterized Regime", "comments": "v2 corrects minor typos", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove that it is possible for nonconvex low-rank matrix recovery to\ncontain no spurious local minima when the rank of the unknown ground truth\n$r^{\\star}<r$ is strictly less than the search rank $r$, and yet for the claim\nto be false when $r^{\\star}=r$. Under the restricted isometry property (RIP),\nwe prove, for the general overparameterized regime with $r^{\\star}\\le r$, that\nan RIP constant of $\\delta<1/(1+\\sqrt{r^{\\star}/r})$ is sufficient for the\ninexistence of spurious local minima, and that\n$\\delta<1/(1+1/\\sqrt{r-r^{\\star}+1})$ is necessary due to existence of\ncounterexamples. Without an explicit control over $r^{\\star}\\le r$, an RIP\nconstant of $\\delta<1/2$ is both necessary and sufficient for the exact\nrecovery of a rank-$r$ ground truth. But if the ground truth is known a priori\nto have $r^{\\star}=1$, then the sharp RIP threshold for exact recovery is\nimproved to $\\delta<1/(1+1/\\sqrt{r})$.\n", "versions": [{"version": "v1", "created": "Wed, 21 Apr 2021 23:07:18 GMT"}, {"version": "v2", "created": "Mon, 26 Apr 2021 23:47:45 GMT"}], "update_date": "2021-04-28", "authors_parsed": [["Zhang", "Richard Y.", ""]]}, {"id": "2104.10818", "submitter": "Aaron M. Roth", "authors": "Aaron M. Roth, Jing Liang, and Dinesh Manocha", "title": "XAI-N: Sensor-based Robot Navigation using Expert Policies and Decision\n  Trees", "comments": null, "journal-ref": "2021 IEEE/RSJ International Conference on Intelligent Robots and\n  Systems (IROS)", "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  We present a novel sensor-based learning navigation algorithm to compute a\ncollision-free trajectory for a robot in dense and dynamic environments with\nmoving obstacles or targets. Our approach uses deep reinforcement\nlearning-based expert policy that is trained using a sim2real paradigm. In\norder to increase the reliability and handle the failure cases of the expert\npolicy, we combine with a policy extraction technique to transform the\nresulting policy into a decision tree format. The resulting decision tree has\nproperties which we use to analyze and modify the policy and improve\nperformance on navigation metrics including smoothness, frequency of\noscillation, frequency of immobilization, and obstruction of target. We are\nable to modify the policy to address these imperfections without retraining,\ncombining the learning power of deep learning with the control of\ndomain-specific algorithms. We highlight the benefits of our algorithm in\nsimulated environments and navigating a Clearpath Jackal robot among moving\npedestrians. (Videos at this url:\nhttps://gamma.umd.edu/researchdirections/xrl/navviper)\n", "versions": [{"version": "v1", "created": "Thu, 22 Apr 2021 01:33:10 GMT"}, {"version": "v2", "created": "Mon, 19 Jul 2021 03:57:42 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Roth", "Aaron M.", ""], ["Liang", "Jing", ""], ["Manocha", "Dinesh", ""]]}, {"id": "2104.10819", "submitter": "Kun Li", "authors": "Kun Li, Liang Yuan, Yunquan Zhang, Gongwei Chen", "title": "An Accurate and Efficient Large-scale Regression Method through Best\n  Friend Clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  As the data size in Machine Learning fields grows exponentially, it is\ninevitable to accelerate the computation by utilizing the ever-growing large\nnumber of available cores provided by high-performance computing hardware.\nHowever, existing parallel methods for clustering or regression often suffer\nfrom problems of low accuracy, slow convergence, and complex\nhyperparameter-tuning. Furthermore, the parallel efficiency is usually\ndifficult to improve while striking a balance between preserving model\nproperties and partitioning computing workloads on distributed systems. In this\npaper, we propose a novel and simple data structure capturing the most\nimportant information among data samples. It has several advantageous\nproperties supporting a hierarchical clustering strategy that is irrelevant to\nthe hardware parallelism, well-defined metrics for determining optimal\nclustering, balanced partition for maintaining the compactness property, and\nefficient parallelization for accelerating computation phases. Then we combine\nthe clustering with regression techniques as a parallel library and utilize a\nhybrid structure of data and model parallelism to make predictions. Experiments\nillustrate that our library obtains remarkable performance on convergence,\naccuracy, and scalability.\n", "versions": [{"version": "v1", "created": "Thu, 22 Apr 2021 01:34:29 GMT"}], "update_date": "2021-04-23", "authors_parsed": [["Li", "Kun", ""], ["Yuan", "Liang", ""], ["Zhang", "Yunquan", ""], ["Chen", "Gongwei", ""]]}, {"id": "2104.10837", "submitter": "Bao Wang", "authors": "Matthew Thorpe and Bao Wang", "title": "Robust Certification for Laplace Learning on Geometric Graphs", "comments": "26 pages, 10 figures, Accepted for publication at Mathematical and\n  Scientific Machine Learning (MSML) 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA math.NA", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Graph Laplacian (GL)-based semi-supervised learning is one of the most used\napproaches for classifying nodes in a graph. Understanding and certifying the\nadversarial robustness of machine learning (ML) algorithms has attracted large\namounts of attention from different research communities due to its crucial\nimportance in many security-critical applied domains. There is great interest\nin the theoretical certification of adversarial robustness for popular ML\nalgorithms. In this paper, we provide the first adversarial robust\ncertification for the GL classifier. More precisely we quantitatively bound the\ndifference in the classification accuracy of the GL classifier before and after\nan adversarial attack. Numerically, we validate our theoretical certification\nresults and show that leveraging existing adversarial defenses for the\n$k$-nearest neighbor classifier can remarkably improve the robustness of the GL\nclassifier.\n", "versions": [{"version": "v1", "created": "Thu, 22 Apr 2021 02:52:21 GMT"}], "update_date": "2021-04-23", "authors_parsed": [["Thorpe", "Matthew", ""], ["Wang", "Bao", ""]]}, {"id": "2104.10840", "submitter": "Ichiro Takeuchi Prof.", "authors": "Toshiaki Tsukurimichi, Yu Inatsu, Vo Nguyen Le Duy, Ichiro Takeuchi", "title": "Conditional Selective Inference for Robust Regression and Outlier\n  Detection using Piecewise-Linear Homotopy Continuation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In practical data analysis under noisy environment, it is common to first use\nrobust methods to identify outliers, and then to conduct further analysis after\nremoving the outliers. In this paper, we consider statistical inference of the\nmodel estimated after outliers are removed, which can be interpreted as a\nselective inference (SI) problem. To use conditional SI framework, it is\nnecessary to characterize the events of how the robust method identifies\noutliers. Unfortunately, the existing methods cannot be directly used here\nbecause they are applicable to the case where the selection events can be\nrepresented by linear/quadratic constraints. In this paper, we propose a\nconditional SI method for popular robust regressions by using homotopy method.\nWe show that the proposed conditional SI method is applicable to a wide class\nof robust regression and outlier detection methods and has good empirical\nperformance on both synthetic data and real data experiments.\n", "versions": [{"version": "v1", "created": "Thu, 22 Apr 2021 03:01:18 GMT"}], "update_date": "2021-04-23", "authors_parsed": [["Tsukurimichi", "Toshiaki", ""], ["Inatsu", "Yu", ""], ["Duy", "Vo Nguyen Le", ""], ["Takeuchi", "Ichiro", ""]]}, {"id": "2104.10853", "submitter": "Yonggan Fu", "authors": "Yonggan Fu, Zhongzhi Yu, Yongan Zhang, Yifan Jiang, Chaojian Li,\n  Yongyuan Liang, Mingchao Jiang, Zhangyang Wang, Yingyan Lin", "title": "InstantNet: Automated Generation and Deployment of Instantaneously\n  Switchable-Precision Networks", "comments": "Accepted at DAC 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The promise of Deep Neural Network (DNN) powered Internet of Thing (IoT)\ndevices has motivated a tremendous demand for automated solutions to enable\nfast development and deployment of efficient (1) DNNs equipped with\ninstantaneous accuracy-efficiency trade-off capability to accommodate the\ntime-varying resources at IoT devices and (2) dataflows to optimize DNNs'\nexecution efficiency on different devices. Therefore, we propose InstantNet to\nautomatically generate and deploy instantaneously switchable-precision networks\nwhich operate at variable bit-widths. Extensive experiments show that the\nproposed InstantNet consistently outperforms state-of-the-art designs.\n", "versions": [{"version": "v1", "created": "Thu, 22 Apr 2021 04:07:43 GMT"}], "update_date": "2021-04-23", "authors_parsed": [["Fu", "Yonggan", ""], ["Yu", "Zhongzhi", ""], ["Zhang", "Yongan", ""], ["Jiang", "Yifan", ""], ["Li", "Chaojian", ""], ["Liang", "Yongyuan", ""], ["Jiang", "Mingchao", ""], ["Wang", "Zhangyang", ""], ["Lin", "Yingyan", ""]]}, {"id": "2104.10873", "submitter": "Hengjie Wang", "authors": "Hengjie Wang, Robert Planas, Aparna Chandramowlishwaran, Ramin\n  Bostanabad", "title": "Train Once and Use Forever: Solving Boundary Value Problems in Unseen\n  Domains with Pre-trained Deep Learning Models", "comments": "12 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.PF physics.comp-ph", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Physics-informed neural networks (PINNs) are increasingly employed to\nreplace/augment traditional numerical methods in solving partial differential\nequations (PDEs). While having many attractive features, state-of-the-art PINNs\nsurrogate a specific realization of a PDE system and hence are\nproblem-specific. That is, each time the boundary conditions and domain shape\nchange, the model needs to be re-trained. This limitation prohibits the\napplication of PINNs in realistic or large-scale engineering problems\nespecially since the costs and efforts associated with their training are\nconsiderable.\n  This paper introduces a transferable framework for solving boundary value\nproblems (BVPs) via deep neural networks which can be trained once and used\nforever for various domains of unseen sizes, shapes, and boundary conditions.\nFirst, we introduce \\emph{genomic flow network} (GFNet), a neural network that\ncan infer the solution of a BVP across arbitrary boundary conditions on a small\nsquare domain called \\emph{genome}. Then, we propose \\emph{mosaic flow} (MF)\npredictor, a novel iterative algorithm that assembles or stitches the GFNet's\ninferences to obtain the solution of BVPs on unseen, large domains while\npreserving the spatial regularity of the solution. We demonstrate that our\nframework can estimate the solution of Laplace and Navier-Stokes equations in\ndomains of unseen shapes and boundary conditions that are, respectively, $1200$\nand $12$ times larger than the domains where training is performed. Since our\nframework eliminates the need to re-train, it demonstrates up to 3 orders of\nmagnitude speedups compared to the state-of-the-art.\n", "versions": [{"version": "v1", "created": "Thu, 22 Apr 2021 05:20:27 GMT"}], "update_date": "2021-04-23", "authors_parsed": [["Wang", "Hengjie", ""], ["Planas", "Robert", ""], ["Chandramowlishwaran", "Aparna", ""], ["Bostanabad", "Ramin", ""]]}, {"id": "2104.10874", "submitter": "Savvas Karatsiolis", "authors": "Savvas Karatsiolis and Andreas Kamilaris", "title": "Focusing on Shadows for Predicting Heightmaps from Single Remotely\n  Sensed RGB Images with Deep Learning", "comments": "30 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Estimating the heightmaps of buildings and vegetation in single remotely\nsensed images is a challenging problem. Effective solutions to this problem can\ncomprise the stepping stone for solving complex and demanding problems that\nrequire 3D information of aerial imagery in the remote sensing discipline,\nwhich might be expensive or not feasible to require. We propose a task-focused\nDeep Learning (DL) model that takes advantage of the shadow map of a remotely\nsensed image to calculate its heightmap. The shadow is computed efficiently and\ndoes not add significant computation complexity. The model is trained with\naerial images and their Lidar measurements, achieving superior performance on\nthe task. We validate the model with a dataset covering a large area of\nManchester, UK, as well as the 2018 IEEE GRSS Data Fusion Contest Lidar\ndataset. Our work suggests that the proposed DL architecture and the technique\nof injecting shadows information into the model are valuable for improving the\nheightmap estimation task for single remotely sensed imagery.\n", "versions": [{"version": "v1", "created": "Thu, 22 Apr 2021 05:31:13 GMT"}], "update_date": "2021-04-23", "authors_parsed": [["Karatsiolis", "Savvas", ""], ["Kamilaris", "Andreas", ""]]}, {"id": "2104.10880", "submitter": "Shimin Di", "authors": "Shimin Di, Quanming Yao, Yongqi Zhang, Lei Chen", "title": "Efficient Relation-aware Scoring Function Search for Knowledge Graph\n  Embedding", "comments": "ICDE 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The scoring function, which measures the plausibility of triplets in\nknowledge graphs (KGs), is the key to ensure the excellent performance of KG\nembedding, and its design is also an important problem in the literature.\nAutomated machine learning (AutoML) techniques have recently been introduced\ninto KG to design task-aware scoring functions, which achieve state-of-the-art\nperformance in KG embedding. However, the effectiveness of searched scoring\nfunctions is still not as good as desired. In this paper, observing that\nexisting scoring functions can exhibit distinct performance on different\nsemantic patterns, we are motivated to explore such semantics by searching\nrelation-aware scoring functions. But the relation-aware search requires a much\nlarger search space than the previous one. Hence, we propose to encode the\nspace as a supernet and propose an efficient alternative minimization algorithm\nto search through the supernet in a one-shot manner. Finally, experimental\nresults on benchmark datasets demonstrate that the proposed method can\nefficiently search relation-aware scoring functions, and achieve better\nembedding performance than state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Thu, 22 Apr 2021 06:05:13 GMT"}], "update_date": "2021-04-23", "authors_parsed": [["Di", "Shimin", ""], ["Yao", "Quanming", ""], ["Zhang", "Yongqi", ""], ["Chen", "Lei", ""]]}, {"id": "2104.10903", "submitter": "Jay Kumar", "authors": "Rajesh Kumar, WenYong Wang, Cheng Yuan, Jay Kumar, Zakria, He Qing,\n  Ting Yang, Abdullah Aman Khan", "title": "Blockchain based Privacy-Preserved Federated Learning for Medical\n  Images: A Case Study of COVID-19 CT Scans", "comments": "15 Pages, 5 Tables, 11 Figures, Journal Paper, Elsevier format", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Medical health care centers are envisioned as a promising paradigm to handle\nthe massive volume of data of COVID-19 patients using artificial intelligence\n(AI). Traditionally, AI techniques often require centralized data collection\nand training the model in a single organization, which is most common weakness\ndue to the privacy and security of raw data communication. To solve this\nchallenging task, we propose a blockchain-based federated learning framework\nthat provides collaborative data training solutions by coordinating multiple\nhospitals to train and share encrypted federated models without leakage of data\nprivacy. The blockchain ledger technology provides the decentralization of\nfederated learning model without any central server. The proposed homomorphic\nencryption scheme encrypts and decrypts the gradients of model to preserve the\nprivacy. More precisely, the proposed framework: i) train the local model by a\nnovel capsule network to segmentation and classify COVID-19 images, ii) then\nuse the homomorphic encryption scheme to secure the local model that encrypts\nand decrypts the gradients, and finally the model is shared over a\ndecentralized platform through proposed blockchain-based federated learning\nalgorithm. The integration of blockchain and federated learning leads to a new\nparadigm for medical image data sharing in the decentralized network. The\nconducted experimental resultsdemonstrate the performance of the proposed\nscheme.\n", "versions": [{"version": "v1", "created": "Thu, 22 Apr 2021 07:32:04 GMT"}, {"version": "v2", "created": "Mon, 31 May 2021 06:04:39 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Kumar", "Rajesh", ""], ["Wang", "WenYong", ""], ["Yuan", "Cheng", ""], ["Kumar", "Jay", ""], ["Zakria", "", ""], ["Qing", "He", ""], ["Yang", "Ting", ""], ["Khan", "Abdullah Aman", ""]]}, {"id": "2104.10917", "submitter": "Chengwei Zhang", "authors": "Chengwei Zhang and Shan Jin and Wanli Xue and Xiaofei Xie and\n  Shengyong Chen and Rong Chen", "title": "Independent Reinforcement Learning for Weakly Cooperative Multiagent\n  Traffic Control Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The adaptive traffic signal control (ATSC) problem can be modeled as a\nmultiagent cooperative game among urban intersections, where intersections\ncooperate to optimize their common goal. Recently, reinforcement learning (RL)\nhas achieved marked successes in managing sequential decision making problems,\nwhich motivates us to apply RL in the ASTC problem. Here we use independent\nreinforcement learning (IRL) to solve a complex traffic cooperative control\nproblem in this study. One of the largest challenges of this problem is that\nthe observation information of intersection is typically partially observable,\nwhich limits the learning performance of IRL algorithms. To this, we model the\ntraffic control problem as a partially observable weak cooperative traffic\nmodel (PO-WCTM) to optimize the overall traffic situation of a group of\nintersections. Different from a traditional IRL task that averages the returns\nof all agents in fully cooperative games, the learning goal of each\nintersection in PO-WCTM is to reduce the cooperative difficulty of learning,\nwhich is also consistent with the traffic environment hypothesis. We also\npropose an IRL algorithm called Cooperative Important Lenient Double DQN\n(CIL-DDQN), which extends Double DQN (DDQN) algorithm using two mechanisms: the\nforgetful experience mechanism and the lenient weight training mechanism. The\nformer mechanism decreases the importance of experiences stored in the\nexperience reply buffer, which deals with the problem of experience failure\ncaused by the strategy change of other agents. The latter mechanism increases\nthe weight experiences with high estimation and `leniently' trains the DDQN\nneural network, which improves the probability of the selection of cooperative\njoint strategies. Experimental results show that CIL-DDQN outperforms other\nmethods in almost all performance indicators of the traffic control problem.\n", "versions": [{"version": "v1", "created": "Thu, 22 Apr 2021 07:55:46 GMT"}], "update_date": "2021-04-23", "authors_parsed": [["Zhang", "Chengwei", ""], ["Jin", "Shan", ""], ["Xue", "Wanli", ""], ["Xie", "Xiaofei", ""], ["Chen", "Shengyong", ""], ["Chen", "Rong", ""]]}, {"id": "2104.10922", "submitter": "Zander Venter", "authors": "Zander S. Venter, Markus A.K. Sydenham", "title": "Continental-scale land cover mapping at 10 m resolution over Europe\n  (ELC10)", "comments": null, "journal-ref": "Remote Sens. 2021, 13, 2301", "doi": "10.3390/rs13122301", "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Widely used European land cover maps such as CORINE are produced at medium\nspatial resolutions (100 m) and rely on diverse data with complex workflows\nrequiring significant institutional capacity. We present a high resolution (10\nm) land cover map (ELC10) of Europe based on a satellite-driven machine\nlearning workflow that is annually updatable. A Random Forest classification\nmodel was trained on 70K ground-truth points from the LUCAS (Land Use/Cover\nArea frame Survey) dataset. Within the Google Earth Engine cloud computing\nenvironment, the ELC10 map can be generated from approx. 700 TB of Sentinel\nimagery within approx. 4 days from a single research user account. The map\nachieved an overall accuracy of 90% across 8 land cover classes and could\naccount for statistical unit land cover proportions within 3.9% (R2 = 0.83) of\nthe actual value. These accuracies are higher than that of CORINE (100 m) and\nother 10-m land cover maps including S2GLC and FROM-GLC10. We found that\natmospheric correction of Sentinel-2 and speckle filtering of Sentinel-1\nimagery had minimal effect on enhancing classification accuracy (< 1%).\nHowever, combining optical and radar imagery increased accuracy by 3% compared\nto Sentinel-2 alone and by 10% compared to Sentinel-1 alone. The conversion of\nLUCAS points into homogenous polygons under the Copernicus module increased\naccuracy by <1%, revealing that Random Forests are robust against contaminated\ntraining data. Furthermore, the model requires very little training data to\nachieve moderate accuracies - the difference between 5K and 50K LUCAS points is\nonly 3% (86 vs 89%). At 10-m resolution, the ELC10 map can distinguish detailed\nlandscape features like hedgerows and gardens, and therefore holds potential\nfor aerial statistics at the city borough level and monitoring property-level\nenvironmental interventions (e.g. tree planting).\n", "versions": [{"version": "v1", "created": "Thu, 22 Apr 2021 08:24:15 GMT"}], "update_date": "2021-06-14", "authors_parsed": [["Venter", "Zander S.", ""], ["Sydenham", "Markus A. K.", ""]]}, {"id": "2104.10931", "submitter": "Bogdan Musat PhD candidate", "authors": "Bogdan Musat, Razvan Andonie", "title": "Semiotic Aggregation in Deep Learning", "comments": null, "journal-ref": "Entropy 2020, 22(12), 1365", "doi": "10.3390/e22121365", "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Convolutional neural networks utilize a hierarchy of neural network layers.\nThe statistical aspects of information concentration in successive layers can\nbring an insight into the feature abstraction process. We analyze the saliency\nmaps of these layers from the perspective of semiotics, also known as the study\nof signs and sign-using behavior. In computational semiotics, this aggregation\noperation (known as superization) is accompanied by a decrease of spatial\nentropy: signs are aggregated into supersign. Using spatial entropy, we compute\nthe information content of the saliency maps and study the superization\nprocesses which take place between successive layers of the network. In our\nexperiments, we visualize the superization process and show how the obtained\nknowledge can be used to explain the neural decision model. In addition, we\nattempt to optimize the architecture of the neural model employing a semiotic\ngreedy technique. To the extent of our knowledge, this is the first application\nof computational semiotics in the analysis and interpretation of deep neural\nnetworks.\n", "versions": [{"version": "v1", "created": "Thu, 22 Apr 2021 08:55:54 GMT"}], "update_date": "2021-04-23", "authors_parsed": [["Musat", "Bogdan", ""], ["Andonie", "Razvan", ""]]}, {"id": "2104.10935", "submitter": "Peihua Li", "authors": "Jiangtao Xie, Ruiren Zeng, Qilong Wang, Ziqi Zhou, Peihua Li", "title": "So-ViT: Mind Visual Tokens for Vision Transformer", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Recently the vision transformer (ViT) architecture, where the backbone purely\nconsists of self-attention mechanism, has achieved very promising performance\nin visual classification. However, the high performance of the original ViT\nheavily depends on pretraining using ultra large-scale datasets, and it\nsignificantly underperforms on ImageNet-1K if trained from scratch. This paper\nmakes the efforts toward addressing this problem, by carefully considering the\nrole of visual tokens. First, for classification head, existing ViT only\nexploits class token while entirely neglecting rich semantic information\ninherent in high-level visual tokens. Therefore, we propose a new\nclassification paradigm, where the second-order, cross-covariance pooling of\nvisual tokens is combined with class token for final classification. Meanwhile,\na fast singular value power normalization is proposed for improving the\nsecond-order pooling. Second, the original ViT employs the naive embedding of\nfixed-size image patches, lacking the ability to model translation equivariance\nand locality. To alleviate this problem, we develop a light-weight,\nhierarchical module based on off-the-shelf convolutions for visual token\nembedding. The proposed architecture, which we call So-ViT, is thoroughly\nevaluated on ImageNet-1K. The results show our models, when trained from\nscratch, outperform the competing ViT variants, while being on par with or\nbetter than state-of-the-art CNN models. Code is available at\nhttps://github.com/jiangtaoxie/So-ViT\n", "versions": [{"version": "v1", "created": "Thu, 22 Apr 2021 09:05:09 GMT"}], "update_date": "2021-04-23", "authors_parsed": [["Xie", "Jiangtao", ""], ["Zeng", "Ruiren", ""], ["Wang", "Qilong", ""], ["Zhou", "Ziqi", ""], ["Li", "Peihua", ""]]}, {"id": "2104.10941", "submitter": "Aneesh Balakrishnan", "authors": "Dan Alexandrescu, Aneesh Balakrishnan, Thomas Lange and Maximilien\n  Glorieux", "title": "Enabling Cross-Layer Reliability and Functional Safety Assessment\n  Through ML-Based Compact Models", "comments": "7 pages (paper) + 1 page copyright statement, Number of figures: 3,\n  Conference: 2020 IEEE 26th International Symposium on On-Line Testing and\n  Robust System Design (IOLTS)", "journal-ref": null, "doi": "10.1109/IOLTS50870.2020.9159750", "report-no": null, "categories": "cs.AR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Typical design flows are hierarchical and rely on assembling many individual\ntechnology elements from standard cells to complete boards. Providers use\ncompact models to provide simplified views of their products to their users.\nDesigners group simpler elements in more complex structures and have to manage\nthe corresponding propagation of reliability and functional safety information\nthrough the hierarchy of the system, accompanied by the obvious problems of IP\nconfidentiality, possibility of reverse engineering and so on. This paper\nproposes a machine-learning-based approach to integrate the many individual\nmodels of a subsystem's elements in a single compact model that can be re-used\nand assembled further up in the hierarchy. The compact models provide\nconsistency, accuracy and confidentiality, allowing technology, IP, component,\nsub-system or system providers to accompany their offering with high-quality\nreliability and functional safety compact models that can be safely and\naccurately consumed by their users.\n", "versions": [{"version": "v1", "created": "Thu, 22 Apr 2021 09:13:57 GMT"}], "update_date": "2021-04-23", "authors_parsed": [["Alexandrescu", "Dan", ""], ["Balakrishnan", "Aneesh", ""], ["Lange", "Thomas", ""], ["Glorieux", "Maximilien", ""]]}, {"id": "2104.10949", "submitter": "Sijun Tan", "authors": "Sijun Tan, Brian Knott, Yuan Tian, and David J. Wu", "title": "CryptGPU: Fast Privacy-Preserving Machine Learning on the GPU", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce CryptGPU, a system for privacy-preserving machine learning that\nimplements all operations on the GPU (graphics processing unit). Just as GPUs\nplayed a pivotal role in the success of modern deep learning, they are also\nessential for realizing scalable privacy-preserving deep learning. In this\nwork, we start by introducing a new interface to losslessly embed cryptographic\noperations over secret-shared values (in a discrete domain) into floating-point\noperations that can be processed by highly-optimized CUDA kernels for linear\nalgebra. We then identify a sequence of \"GPU-friendly\" cryptographic protocols\nto enable privacy-preserving evaluation of both linear and non-linear\noperations on the GPU. Our microbenchmarks indicate that our private GPU-based\nconvolution protocol is over 150x faster than the analogous CPU-based protocol;\nfor non-linear operations like the ReLU activation function, our GPU-based\nprotocol is around 10x faster than its CPU analog.\n  With CryptGPU, we support private inference and private training on\nconvolutional neural networks with over 60 million parameters as well as handle\nlarge datasets like ImageNet. Compared to the previous state-of-the-art, when\nconsidering large models and datasets, our protocols achieve a 2x to 8x\nimprovement in private inference and a 6x to 36x improvement for private\ntraining. Our work not only showcases the viability of performing secure\nmultiparty computation (MPC) entirely on the GPU to enable fast\nprivacy-preserving machine learning, but also highlights the importance of\ndesigning new MPC primitives that can take full advantage of the GPU's\ncomputing capabilities.\n", "versions": [{"version": "v1", "created": "Thu, 22 Apr 2021 09:21:40 GMT"}], "update_date": "2021-04-23", "authors_parsed": [["Tan", "Sijun", ""], ["Knott", "Brian", ""], ["Tian", "Yuan", ""], ["Wu", "David J.", ""]]}, {"id": "2104.10955", "submitter": "Yanbei Chen", "authors": "Yanbei Chen, Yongqin Xian, A. Sophia Koepke, Ying Shan, Zeynep Akata", "title": "Distilling Audio-Visual Knowledge by Compositional Contrastive Learning", "comments": "Accepted to CVPR2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Having access to multi-modal cues (e.g. vision and audio) empowers some\ncognitive tasks to be done faster compared to learning from a single modality.\nIn this work, we propose to transfer knowledge across heterogeneous modalities,\neven though these data modalities may not be semantically correlated. Rather\nthan directly aligning the representations of different modalities, we compose\naudio, image, and video representations across modalities to uncover richer\nmulti-modal knowledge. Our main idea is to learn a compositional embedding that\ncloses the cross-modal semantic gap and captures the task-relevant semantics,\nwhich facilitates pulling together representations across modalities by\ncompositional contrastive learning. We establish a new, comprehensive\nmulti-modal distillation benchmark on three video datasets: UCF101,\nActivityNet, and VGGSound. Moreover, we demonstrate that our model\nsignificantly outperforms a variety of existing knowledge distillation methods\nin transferring audio-visual knowledge to improve video representation\nlearning. Code is released here: https://github.com/yanbeic/CCL.\n", "versions": [{"version": "v1", "created": "Thu, 22 Apr 2021 09:31:20 GMT"}], "update_date": "2021-04-23", "authors_parsed": [["Chen", "Yanbei", ""], ["Xian", "Yongqin", ""], ["Koepke", "A. Sophia", ""], ["Shan", "Ying", ""], ["Akata", "Zeynep", ""]]}, {"id": "2104.10970", "submitter": "Antal Jakovac", "authors": "A. Jakovac", "title": "Time series analysis with dynamic law exploration", "comments": "17 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  In this paper we examine, how the dynamic laws governing the time evolution\nof a time series can be identified. We give a finite difference equation as\nwell as a differential equation representation for that. We also study, how the\nrequired symmetries, like time reversal can be imposed on the laws. We study\nthe compression performance of linear laws on sound data.\n", "versions": [{"version": "v1", "created": "Thu, 22 Apr 2021 10:08:02 GMT"}], "update_date": "2021-04-23", "authors_parsed": [["Jakovac", "A.", ""]]}, {"id": "2104.10972", "submitter": "Tal Ridnik", "authors": "Tal Ridnik, Emanuel Ben-Baruch, Asaf Noy, Lihi Zelnik-Manor", "title": "ImageNet-21K Pretraining for the Masses", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  ImageNet-1K serves as the primary dataset for pretraining deep learning\nmodels for computer vision tasks. ImageNet-21K dataset, which is bigger and\nmore diverse, is used less frequently for pretraining, mainly due to its\ncomplexity, low accessibility, and underestimation of its added value. This\npaper aims to close this gap, and make high-quality efficient pretraining on\nImageNet-21K available for everyone. Via a dedicated preprocessing stage,\nutilization of WordNet hierarchical structure, and a novel training scheme\ncalled semantic softmax, we show that various models significantly benefit from\nImageNet-21K pretraining on numerous datasets and tasks, including small\nmobile-oriented models. We also show that we outperform previous ImageNet-21K\npretraining schemes for prominent new models like ViT and Mixer. Our proposed\npretraining pipeline is efficient, accessible, and leads to SoTA reproducible\nresults, from a publicly available dataset. The training code and pretrained\nmodels are available at: https://github.com/Alibaba-MIIL/ImageNet21K\n", "versions": [{"version": "v1", "created": "Thu, 22 Apr 2021 10:10:14 GMT"}, {"version": "v2", "created": "Tue, 4 May 2021 16:13:28 GMT"}, {"version": "v3", "created": "Sun, 6 Jun 2021 08:29:51 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Ridnik", "Tal", ""], ["Ben-Baruch", "Emanuel", ""], ["Noy", "Asaf", ""], ["Zelnik-Manor", "Lihi", ""]]}, {"id": "2104.10984", "submitter": "C\\'edric Marco-Detchart", "authors": "Cedric Marco-Detchart, Giancarlo Lucca, Carlos Lopez-Molina, Laura De\n  Miguel, Gra\\c{c}aliz Pereira Dimuro, Humberto Bustince", "title": "Neuro-inspired edge feature fusion using Choquet integrals", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is known that the human visual system performs a hierarchical information\nprocess in which early vision cues (or primitives) are fused in the visual\ncortex to compose complex shapes and descriptors. While different aspects of\nthe process have been extensively studied, as the lens adaptation or the\nfeature detection, some other,as the feature fusion, have been mostly left\naside. In this work we elaborate on the fusion of early vision primitives using\ngeneralizations of the Choquet integral, and novel aggregation operators that\nhave been extensively studied in recent years. We propose to use\ngeneralizations of the Choquet integral to sensibly fuse elementary edge cues,\nin an attempt to model the behaviour of neurons in the early visual cortex. Our\nproposal leads to a full-framed edge detection algorithm, whose performance is\nput to the test in state-of-the-art boundary detection datasets.\n", "versions": [{"version": "v1", "created": "Thu, 22 Apr 2021 10:45:52 GMT"}], "update_date": "2021-04-23", "authors_parsed": [["Marco-Detchart", "Cedric", ""], ["Lucca", "Giancarlo", ""], ["Lopez-Molina", "Carlos", ""], ["De Miguel", "Laura", ""], ["Dimuro", "Gra\u00e7aliz Pereira", ""], ["Bustince", "Humberto", ""]]}, {"id": "2104.10986", "submitter": "Pascal Klink", "authors": "Stephan Weigand, Pascal Klink, Jan Peters, Joni Pajarinen", "title": "Reinforcement Learning using Guided Observability", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to recent breakthroughs, reinforcement learning (RL) has demonstrated\nimpressive performance in challenging sequential decision-making problems.\nHowever, an open question is how to make RL cope with partial observability\nwhich is prevalent in many real-world problems. Contrary to contemporary RL\napproaches, which focus mostly on improved memory representations or strong\nassumptions about the type of partial observability, we propose a simple but\nefficient approach that can be applied together with a wide variety of RL\nmethods. Our main insight is that smoothly transitioning from full\nobservability to partial observability during the training process yields a\nhigh performance policy. The approach, called partially observable guided\nreinforcement learning (PO-GRL), allows to utilize full state information\nduring policy optimization without compromising the optimality of the final\npolicy. A comprehensive evaluation in discrete partially observableMarkov\ndecision process (POMDP) benchmark problems and continuous partially observable\nMuJoCo and OpenAI gym tasks shows that PO-GRL improves performance. Finally, we\ndemonstrate PO-GRL in the ball-in-the-cup task on a real Barrett WAM robot\nunder partial observability.\n", "versions": [{"version": "v1", "created": "Thu, 22 Apr 2021 10:47:35 GMT"}], "update_date": "2021-04-23", "authors_parsed": [["Weigand", "Stephan", ""], ["Klink", "Pascal", ""], ["Peters", "Jan", ""], ["Pajarinen", "Joni", ""]]}, {"id": "2104.10995", "submitter": "Samuel T. Wauthier", "authors": "Samuel T. Wauthier, Pietro Mazzaglia, Ozan \\c{C}atal, Cedric De Boom,\n  Tim Verbelen, Bart Dhoedt", "title": "A learning gap between neuroscience and reinforcement learning", "comments": "Accepted as a workshop paper at BRAIN2AI @ ICLR2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Historically, artificial intelligence has drawn much inspiration from\nneuroscience to fuel advances in the field. However, current progress in\nreinforcement learning is largely focused on benchmark problems that fail to\ncapture many of the aspects that are of interest in neuroscience today. We\nillustrate this point by extending a T-maze task from neuroscience for use with\nreinforcement learning algorithms, and show that state-of-the-art algorithms\nare not capable of solving this problem. Finally, we point out where insights\nfrom neuroscience could help explain some of the issues encountered.\n", "versions": [{"version": "v1", "created": "Thu, 22 Apr 2021 11:25:21 GMT"}, {"version": "v2", "created": "Thu, 29 Apr 2021 08:38:39 GMT"}, {"version": "v3", "created": "Tue, 4 May 2021 13:01:13 GMT"}], "update_date": "2021-05-05", "authors_parsed": [["Wauthier", "Samuel T.", ""], ["Mazzaglia", "Pietro", ""], ["\u00c7atal", "Ozan", ""], ["De Boom", "Cedric", ""], ["Verbelen", "Tim", ""], ["Dhoedt", "Bart", ""]]}, {"id": "2104.11009", "submitter": "Udit Bhatia", "authors": "Pravin Bhasme, Jenil Vagadiya, Udit Bhatia", "title": "Enhancing predictive skills in physically-consistent way: Physics\n  Informed Machine Learning for Hydrological Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Current modeling approaches for hydrological modeling often rely on either\nphysics-based or data-science methods, including Machine Learning (ML)\nalgorithms. While physics-based models tend to rigid structure resulting in\nunrealistic parameter values in certain instances, ML algorithms establish the\ninput-output relationship while ignoring the constraints imposed by well-known\nphysical processes. While there is a notion that the physics model enables\nbetter process understanding and ML algorithms exhibit better predictive\nskills, scientific knowledge that does not add to predictive ability may be\ndeceptive. Hence, there is a need for a hybrid modeling approach to couple ML\nalgorithms and physics-based models in a synergistic manner. Here we develop a\nPhysics Informed Machine Learning (PIML) model that combines the process\nunderstanding of conceptual hydrological model with predictive abilities of\nstate-of-the-art ML models. We apply the proposed model to predict the monthly\ntime series of the target (streamflow) and intermediate variables (actual\nevapotranspiration) in the Narmada river basin in India. Our results show the\ncapability of the PIML model to outperform a purely conceptual model ($abcd$\nmodel) and ML algorithms while ensuring the physical consistency in outputs\nvalidated through water balance analysis. The systematic approach for combining\nconceptual model structure with ML algorithms could be used to improve the\npredictive accuracy of crucial hydrological processes important for flood risk\nassessment.\n", "versions": [{"version": "v1", "created": "Thu, 22 Apr 2021 12:13:42 GMT"}], "update_date": "2021-04-23", "authors_parsed": [["Bhasme", "Pravin", ""], ["Vagadiya", "Jenil", ""], ["Bhatia", "Udit", ""]]}, {"id": "2104.11014", "submitter": "Min-Hung Chen", "authors": "Min-Fong Hong, Hao-Yun Chen, Min-Hung Chen, Yu-Syuan Xu, Hsien-Kai\n  Kuo, Yi-Min Tsai, Hung-Jen Chen, Kevin Jou", "title": "Network Space Search for Pareto-Efficient Spaces", "comments": "CVPRW2021 [Oral] (Efficient Deep Learning for Computer Vision\n  Workshop). Website: https://minhungchen.netlify.app/publication/nss", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Network spaces have been known as a critical factor in both handcrafted\nnetwork designs or defining search spaces for Neural Architecture Search (NAS).\nHowever, an effective space involves tremendous prior knowledge and/or manual\neffort, and additional constraints are required to discover efficiency-aware\narchitectures. In this paper, we define a new problem, Network Space Search\n(NSS), as searching for favorable network spaces instead of a single\narchitecture. We propose an NSS method to directly search for efficient-aware\nnetwork spaces automatically, reducing the manual effort and immense cost in\ndiscovering satisfactory ones. The resultant network spaces, named Elite\nSpaces, are discovered from Expanded Search Space with minimal human expertise\nimposed. The Pareto-efficient Elite Spaces are aligned with the Pareto front\nunder various complexity constraints and can be further served as NAS search\nspaces, benefiting differentiable NAS approaches (e.g. In CIFAR-100, an\naveragely 2.3% lower error rate and 3.7% closer to target constraint than the\nbaseline with around 90% fewer samples required to find satisfactory networks).\nMoreover, our NSS approach is capable of searching for superior spaces in\nfuture unexplored spaces, revealing great potential in searching for network\nspaces automatically. Website: https://minhungchen.netlify.app/publication/nss.\n", "versions": [{"version": "v1", "created": "Thu, 22 Apr 2021 12:23:53 GMT"}, {"version": "v2", "created": "Thu, 10 Jun 2021 03:31:32 GMT"}, {"version": "v3", "created": "Sat, 12 Jun 2021 03:39:42 GMT"}, {"version": "v4", "created": "Tue, 15 Jun 2021 07:36:27 GMT"}, {"version": "v5", "created": "Wed, 16 Jun 2021 00:22:11 GMT"}, {"version": "v6", "created": "Sun, 20 Jun 2021 01:51:58 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Hong", "Min-Fong", ""], ["Chen", "Hao-Yun", ""], ["Chen", "Min-Hung", ""], ["Xu", "Yu-Syuan", ""], ["Kuo", "Hsien-Kai", ""], ["Tsai", "Yi-Min", ""], ["Chen", "Hung-Jen", ""], ["Jou", "Kevin", ""]]}, {"id": "2104.11017", "submitter": "Jingnan Jia", "authors": "Jingnan Jia, Zhiwei Zhai, M. Els Bakker, I. Hernandez Giron, Marius\n  Staring, Berend C. Stoel", "title": "Multi-task Semi-supervised Learning for Pulmonary Lobe Segmentation", "comments": "4 pages, to be published in ISBI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Pulmonary lobe segmentation is an important preprocessing task for the\nanalysis of lung diseases. Traditional methods relying on fissure detection or\nother anatomical features, such as the distribution of pulmonary vessels and\nairways, could provide reasonably accurate lobe segmentations. Deep learning\nbased methods can outperform these traditional approaches, but require large\ndatasets. Deep multi-task learning is expected to utilize labels of multiple\ndifferent structures. However, commonly such labels are distributed over\nmultiple datasets. In this paper, we proposed a multi-task semi-supervised\nmodel that can leverage information of multiple structures from unannotated\ndatasets and datasets annotated with different structures. A focused\nalternating training strategy is presented to balance the different tasks. We\nevaluated the trained model on an external independent CT dataset. The results\nshow that our model significantly outperforms single-task alternatives,\nimproving the mean surface distance from 7.174 mm to 4.196 mm. We also\ndemonstrated that our approach is successful for different network\narchitectures as backbones.\n", "versions": [{"version": "v1", "created": "Thu, 22 Apr 2021 12:33:30 GMT"}], "update_date": "2021-04-23", "authors_parsed": [["Jia", "Jingnan", ""], ["Zhai", "Zhiwei", ""], ["Bakker", "M. Els", ""], ["Giron", "I. Hernandez", ""], ["Staring", "Marius", ""], ["Stoel", "Berend C.", ""]]}, {"id": "2104.11026", "submitter": "Yang An", "authors": "Yang An and Liang Zhang and Mao You and Xueqing Tian and Bo Jin and\n  Xiaopeng Wei", "title": "MeSIN: Multilevel Selective and Interactive Network for Medication\n  Recommendation", "comments": "15 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recommending medications for patients using electronic health records (EHRs)\nis a crucial data mining task for an intelligent healthcare system. It can\nassist doctors in making clinical decisions more efficiently. However, the\ninherent complexity of the EHR data renders it as a challenging task: (1)\nMultilevel structures: the EHR data typically contains multilevel structures\nwhich are closely related with the decision-making pathways, e.g., laboratory\nresults lead to disease diagnoses, and then contribute to the prescribed\nmedications; (2) Multiple sequences interactions: multiple sequences in EHR\ndata are usually closely correlated with each other; (3) Abundant noise: lots\nof task-unrelated features or noise information within EHR data generally\nresult in suboptimal performance. To tackle the above challenges, we propose a\nmultilevel selective and interactive network (MeSIN) for medication\nrecommendation. Specifically, MeSIN is designed with three components. First,\nan attentional selective module (ASM) is applied to assign flexible attention\nscores to different medical codes embeddings by their relevance to the\nrecommended medications in every admission. Second, we incorporate a novel\ninteractive long-short term memory network (InLSTM) to reinforce the\ninteractions of multilevel medical sequences in EHR data with the help of the\ncalibrated memory-augmented cell and an enhanced input gate. Finally, we employ\na global selective fusion module (GSFM) to infuse the multi-sourced information\nembeddings into final patient representations for medications recommendation.\nTo validate our method, extensive experiments have been conducted on a\nreal-world clinical dataset. The results demonstrate a consistent superiority\nof our framework over several baselines and testify the effectiveness of our\nproposed approach.\n", "versions": [{"version": "v1", "created": "Thu, 22 Apr 2021 12:59:50 GMT"}], "update_date": "2021-04-23", "authors_parsed": [["An", "Yang", ""], ["Zhang", "Liang", ""], ["You", "Mao", ""], ["Tian", "Xueqing", ""], ["Jin", "Bo", ""], ["Wei", "Xiaopeng", ""]]}, {"id": "2104.11044", "submitter": "James Lucas", "authors": "James Lucas, Juhan Bae, Michael R. Zhang, Stanislav Fort, Richard\n  Zemel, Roger Grosse", "title": "Analyzing Monotonic Linear Interpolation in Neural Network Loss\n  Landscapes", "comments": "15 pages in main paper, 4 pages of references, 24 pages in appendix.\n  29 figures in total", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Linear interpolation between initial neural network parameters and converged\nparameters after training with stochastic gradient descent (SGD) typically\nleads to a monotonic decrease in the training objective. This Monotonic Linear\nInterpolation (MLI) property, first observed by Goodfellow et al. (2014)\npersists in spite of the non-convex objectives and highly non-linear training\ndynamics of neural networks. Extending this work, we evaluate several\nhypotheses for this property that, to our knowledge, have not yet been\nexplored. Using tools from differential geometry, we draw connections between\nthe interpolated paths in function space and the monotonicity of the network -\nproviding sufficient conditions for the MLI property under mean squared error.\nWhile the MLI property holds under various settings (e.g. network architectures\nand learning problems), we show in practice that networks violating the MLI\nproperty can be produced systematically, by encouraging the weights to move far\nfrom initialization. The MLI property raises important questions about the loss\nlandscape geometry of neural networks and highlights the need to further study\ntheir global properties.\n", "versions": [{"version": "v1", "created": "Thu, 22 Apr 2021 13:22:12 GMT"}, {"version": "v2", "created": "Fri, 23 Apr 2021 17:24:48 GMT"}], "update_date": "2021-04-26", "authors_parsed": [["Lucas", "James", ""], ["Bae", "Juhan", ""], ["Zhang", "Michael R.", ""], ["Fort", "Stanislav", ""], ["Zemel", "Richard", ""], ["Grosse", "Roger", ""]]}, {"id": "2104.11051", "submitter": "Dimitrios Stoidis", "authors": "Dimitrios Stoidis and Andrea Cavallaro", "title": "Protecting gender and identity with disentangled speech representations", "comments": "5 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Besides its linguistic content, our speech is rich in biometric information\nthat can be inferred by classifiers. Learning privacy-preserving\nrepresentations for speech signals enables downstream tasks without sharing\nunnecessary, private information about an individual. In this paper, we show\nthat protecting gender information in speech is more effective than modelling\nspeaker-identity information only when generating a non-sensitive\nrepresentation of speech. Our method relies on reconstructing speech by\ndecoding linguistic content along with gender information using a variational\nautoencoder. Specifically, we exploit disentangled representation learning to\nencode information about different attributes into separate subspaces that can\nbe factorised independently. We present a novel way to encode gender\ninformation and disentangle two sensitive biometric identifiers, namely gender\nand identity, in a privacy-protecting setting. Experiments on the LibriSpeech\ndataset show that gender recognition and speaker verification can be reduced to\na random guess, protecting against classification-based attacks.\n", "versions": [{"version": "v1", "created": "Thu, 22 Apr 2021 13:31:41 GMT"}, {"version": "v2", "created": "Wed, 16 Jun 2021 19:11:01 GMT"}], "update_date": "2021-06-18", "authors_parsed": [["Stoidis", "Dimitrios", ""], ["Cavallaro", "Andrea", ""]]}, {"id": "2104.11052", "submitter": "Zhen Gao", "authors": "Xisuo Ma, Zhen Gao, Feifei Gao, Marco Di Renzo", "title": "Model-Driven Deep Learning Based Channel Estimation and Feedback for\n  Millimeter-Wave Massive Hybrid MIMO Systems", "comments": "18 pages, 18 figures, 2 tables. Accepted in IEEE JSAC. The codes may\n  be available at https://gaozhen16.github.io", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG eess.SP math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a model-driven deep learning (MDDL)-based channel\nestimation and feedback scheme for wideband millimeter-wave (mmWave) massive\nhybrid multiple-input multiple-output (MIMO) systems, where the angle-delay\ndomain channels' sparsity is exploited for reducing the overhead. Firstly, we\nconsider the uplink channel estimation for time-division duplexing systems. To\nreduce the uplink pilot overhead for estimating the high-dimensional channels\nfrom a limited number of radio frequency (RF) chains at the base station (BS),\nwe propose to jointly train the phase shift network and the channel estimator\nas an auto-encoder. Particularly, by exploiting the channels' structured\nsparsity from an a priori model and learning the integrated trainable\nparameters from the data samples, the proposed multiple-measurement-vectors\nlearned approximate message passing (MMV-LAMP) network with the devised\nredundant dictionary can jointly recover multiple subcarriers' channels with\nsignificantly enhanced performance. Moreover, we consider the downlink channel\nestimation and feedback for frequency-division duplexing systems. Similarly,\nthe pilots at the BS and channel estimator at the users can be jointly trained\nas an encoder and a decoder, respectively. Besides, to further reduce the\nchannel feedback overhead, only the received pilots on part of the subcarriers\nare fed back to the BS, which can exploit the MMV-LAMP network to reconstruct\nthe spatial-frequency channel matrix. Numerical results show that the proposed\nMDDL-based channel estimation and feedback scheme outperforms the\nstate-of-the-art approaches.\n", "versions": [{"version": "v1", "created": "Thu, 22 Apr 2021 13:34:53 GMT"}, {"version": "v2", "created": "Wed, 28 Apr 2021 11:27:40 GMT"}, {"version": "v3", "created": "Thu, 6 May 2021 09:37:22 GMT"}], "update_date": "2021-05-07", "authors_parsed": [["Ma", "Xisuo", ""], ["Gao", "Zhen", ""], ["Gao", "Feifei", ""], ["Di Renzo", "Marco", ""]]}, {"id": "2104.11061", "submitter": "Zineb Belkacemi", "authors": "Zineb Belkacemi, Paraskevi Gkeka, Tony Leli\\`evre and Gabriel Stoltz", "title": "Chasing Collective Variables using Autoencoders and biased trajectories", "comments": "49 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.bio-ph cs.LG physics.comp-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the last decades, free energy biasing methods have proven to be powerful\ntools to accelerate the simulation of important conformational changes of\nmolecules by modifying the sampling measure. However, most of these methods\nrely on the prior knowledge of low-dimensional slow degrees of freedom, i.e.\nCollective Variables (CV). Alternatively, such CVs can be identified using\nmachine learning (ML) and dimensionality reduction algorithms. In this context,\napproaches where the CVs are learned in an iterative way using adaptive biasing\nhave been proposed: at each iteration, the learned CV is used to perform free\nenergy adaptive biasing to generate new data and learn a new CV. This implies\nthat at each iteration, a different measure is sampled, thus the new training\ndata is distributed according to a different distribution. Given that a machine\nlearning model is always dependent on the considered distribution, iterative\nmethods are not guaranteed to converge to a certain CV. This can be remedied by\na reweighting procedure to always fall back to learning with respect to the\nsame unbiased Boltzmann-Gibbs measure, regardless of the biased measure used in\nthe adaptive sampling. In this paper, we introduce a new iterative method\ninvolving CV learning with autoencoders: Free Energy Biasing and Iterative\nLearning with AutoEncoders (FEBILAE). Our method includes the reweighting\nscheme to ensure that the learning model optimizes the same loss, and achieves\nCV convergence. Using a small 2-dimensional toy system and the alanine\ndipeptide system as examples, we present results of our algorithm using the\nextended adaptive biasing force as the free energy adaptive biasing method.\n", "versions": [{"version": "v1", "created": "Thu, 22 Apr 2021 13:44:21 GMT"}], "update_date": "2021-04-23", "authors_parsed": [["Belkacemi", "Zineb", ""], ["Gkeka", "Paraskevi", ""], ["Leli\u00e8vre", "Tony", ""], ["Stoltz", "Gabriel", ""]]}, {"id": "2104.11069", "submitter": "S\\'ebastien Lafond", "authors": "Ivan Porres and Hergys Rexha and S\\'ebastien Lafond", "title": "Online GANs for Automatic Performance Testing", "comments": "5th International Workshop on Testing Extra-Functional Properties and\n  Quality Characteristics of Software Systems -\n  https://icst2021.icmc.usp.br/details/iteqs-2021-papers/4/Online-GANs-for-Automatic-Performance-Testing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.LG cs.PF", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper we present a novel algorithm for automatic performance testing\nthat uses an online variant of the Generative Adversarial Network (GAN) to\noptimize the test generation process. The objective of the proposed approach is\nto generate, for a given test budget, a test suite containing a high number of\ntests revealing performance defects. This is achieved using a GAN to generate\nthe tests and predict their outcome. This GAN is trained online while\ngenerating and executing the tests. The proposed approach does not require a\nprior training set or model of the system under test. We provide an initial\nevaluation the algorithm using an example test system, and compare the obtained\nresults with other possible approaches.\n  We consider that the presented algorithm serves as a proof of concept and we\nhope that it can spark a research discussion on the application of GANs to test\ngeneration.\n", "versions": [{"version": "v1", "created": "Wed, 21 Apr 2021 06:03:27 GMT"}], "update_date": "2021-04-23", "authors_parsed": [["Porres", "Ivan", ""], ["Rexha", "Hergys", ""], ["Lafond", "S\u00e9bastien", ""]]}, {"id": "2104.11070", "submitter": "Ashish Shenoy", "authors": "Ashish Shenoy, Sravan Bodapati, Monica Sunkara, Srikanth Ronanki,\n  Katrin Kirchhoff", "title": "Adapting Long Context NLM for ASR Rescoring in Conversational Agents", "comments": "Accepted to Interspeech 2021. arXiv admin note: text overlap with\n  arXiv:2103.10325", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SD", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Neural Language Models (NLM), when trained and evaluated with context\nspanning multiple utterances, have been shown to consistently outperform both\nconventional n-gram language models and NLMs that use limited context. In this\npaper, we investigate various techniques to incorporate turn based context\nhistory into both recurrent (LSTM) and Transformer-XL based NLMs. For recurrent\nbased NLMs, we explore context carry over mechanism and feature based\naugmentation, where we incorporate other forms of contextual information such\nas bot response and system dialogue acts as classified by a Natural Language\nUnderstanding (NLU) model. To mitigate the sharp nearby, fuzzy far away problem\nwith contextual NLM, we propose the use of attention layer over lexical\nmetadata to improve feature based augmentation. Additionally, we adapt our\ncontextual NLM towards user provided on-the-fly speech patterns by leveraging\nencodings from a large pre-trained masked language model and performing fusion\nwith a Transformer-XL based NLM. We test our proposed models using N-best\nrescoring of ASR hypotheses of task-oriented dialogues and also evaluate on\ndownstream NLU tasks such as intent classification and slot labeling. The best\nperforming model shows a relative WER between 1.6% and 9.1% and a slot labeling\nF1 score improvement of 4% over non-contextual baselines.\n", "versions": [{"version": "v1", "created": "Wed, 21 Apr 2021 00:15:21 GMT"}, {"version": "v2", "created": "Fri, 4 Jun 2021 22:22:53 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Shenoy", "Ashish", ""], ["Bodapati", "Sravan", ""], ["Sunkara", "Monica", ""], ["Ronanki", "Srikanth", ""], ["Kirchhoff", "Katrin", ""]]}, {"id": "2104.11092", "submitter": "Jayesh Malaviya", "authors": "Jayesh Malaviya", "title": "Survey on Modeling Intensity Function of Hawkes Process Using Neural\n  Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  The event sequence of many diverse systems is represented as a sequence of\ndiscrete events in a continuous space. Examples of such an event sequence are\nearthquake aftershock events, financial transactions, e-commerce transactions,\nsocial network activity of a user, and the user's web search pattern. Finding\nsuch an intricate pattern helps discover which event will occur in the future\nand when it will occur. A Hawkes process is a mathematical tool used for\nmodeling such time series discrete events. Traditionally, the Hawkes process\nuses a critical component for modeling data as an intensity function with a\nparameterized kernel function. The Hawkes process's intensity function involves\ntwo components: the background intensity and the effect of events' history.\nHowever, such parameterized assumption can not capture future event\ncharacteristics using past events data precisely due to bias in modeling kernel\nfunction. This paper explores the recent advancement using novel deep\nlearning-based methods to model kernel function to remove such parametrized\nkernel function. In the end, we will give potential future research directions\nto improve modeling using the Hawkes process.\n", "versions": [{"version": "v1", "created": "Thu, 22 Apr 2021 14:23:38 GMT"}], "update_date": "2021-04-23", "authors_parsed": [["Malaviya", "Jayesh", ""]]}, {"id": "2104.11103", "submitter": "Jing Wu", "authors": "Jing Wu, Mingyi Zhou, Ce Zhu, Yipeng Liu, Mehrtash Harandi, Li Li", "title": "Performance Evaluation of Adversarial Attacks: Discrepancies and\n  Solutions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, adversarial attack methods have been developed to challenge the\nrobustness of machine learning models. However, mainstream evaluation criteria\nexperience limitations, even yielding discrepancies among results under\ndifferent settings. By examining various attack algorithms, including\ngradient-based and query-based attacks, we notice the lack of a consensus on a\nuniform standard for unbiased performance evaluation. Accordingly, we propose a\nPiece-wise Sampling Curving (PSC) toolkit to effectively address the\naforementioned discrepancy, by generating a comprehensive comparison among\nadversaries in a given range. In addition, the PSC toolkit offers options for\nbalancing the computational cost and evaluation effectiveness. Experimental\nresults demonstrate our PSC toolkit presents comprehensive comparisons of\nattack algorithms, significantly reducing discrepancies in practice.\n", "versions": [{"version": "v1", "created": "Thu, 22 Apr 2021 14:36:51 GMT"}], "update_date": "2021-04-23", "authors_parsed": [["Wu", "Jing", ""], ["Zhou", "Mingyi", ""], ["Zhu", "Ce", ""], ["Liu", "Yipeng", ""], ["Harandi", "Mehrtash", ""], ["Li", "Li", ""]]}, {"id": "2104.11105", "submitter": "Mi{\\l}osz Stypi\\'nski", "authors": "Mi{\\l}osz Stypi\\'nski, Marcin Niemiec", "title": "Synchronization of Tree Parity Machines using non-binary input vectors", "comments": "This work has been submitted to the IEEE for possible publication.\n  Copyright may be transferred without notice, after which this version may no\n  longer be accessible", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Neural cryptography is the application of artificial neural networks in the\nsubject of cryptography. The functionality of this solution is based on a tree\nparity machine. It uses artificial neural networks to perform secure key\nexchange between network entities. This article proposes improvements to the\nsynchronization of two tree parity machines. The improvement is based on\nlearning artificial neural network using input vectors which have a wider range\nof values than binary ones. As a result, the duration of the synchronization\nprocess is reduced. Therefore, tree parity machines achieve common weights in a\nshorter time due to the reduction of necessary bit exchanges. This approach\nimproves the security of neural cryptography\n", "versions": [{"version": "v1", "created": "Thu, 22 Apr 2021 14:38:55 GMT"}], "update_date": "2021-04-23", "authors_parsed": [["Stypi\u0144ski", "Mi\u0142osz", ""], ["Niemiec", "Marcin", ""]]}, {"id": "2104.11110", "submitter": "Padraig Cunningham", "authors": "Bahavathy Kathirgamanathan and Padraig Cunningham", "title": "A Feature Selection Method for Multi-Dimension Time-Series Data", "comments": "12 pages, 3 figures", "journal-ref": "In: Advanced Analytics and Learning on Temporal Data. AALTD 2020.\n  LNCS, vol 12588. Springer, Cham (2020)", "doi": "10.1007/978-3-030-65742-0_15", "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Time-series data in application areas such as motion capture and activity\nrecognition is often multi-dimension. In these application areas data typically\ncomes from wearable sensors or is extracted from video. There is a lot of\nredundancy in these data streams and good classification accuracy will often be\nachievable with a small number of features (dimensions). In this paper we\npresent a method for feature subset selection on multidimensional time-series\ndata based on mutual information. This method calculates a merit score (MSTS)\nbased on correlation patterns of the outputs of classifiers trained on single\nfeatures and the `best' subset is selected accordingly. MSTS was found to be\nsignificantly more efficient in terms of computational cost while also managing\nto maintain a good overall accuracy when compared to Wrapper-based feature\nselection, a feature selection strategy that is popular elsewhere in Machine\nLearning. We describe the motivations behind this feature selection strategy\nand evaluate its effectiveness on six time series datasets.\n", "versions": [{"version": "v1", "created": "Thu, 22 Apr 2021 14:49:00 GMT"}], "update_date": "2021-04-23", "authors_parsed": [["Kathirgamanathan", "Bahavathy", ""], ["Cunningham", "Padraig", ""]]}, {"id": "2104.11116", "submitter": "Hang Zhou", "authors": "Hang Zhou, Yasheng Sun, Wayne Wu, Chen Change Loy, Xiaogang Wang,\n  Ziwei Liu", "title": "Pose-Controllable Talking Face Generation by Implicitly Modularized\n  Audio-Visual Representation", "comments": "Accepted to IEEE/CVF Conference on Computer Vision and Pattern\n  Recognition (CVPR), 2021. Code and models are available at\n  https://github.com/Hangz-nju-cuhk/Talking-Face_PC-AVS", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.MM cs.SD eess.AS eess.IV", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  While accurate lip synchronization has been achieved for arbitrary-subject\naudio-driven talking face generation, the problem of how to efficiently drive\nthe head pose remains. Previous methods rely on pre-estimated structural\ninformation such as landmarks and 3D parameters, aiming to generate\npersonalized rhythmic movements. However, the inaccuracy of such estimated\ninformation under extreme conditions would lead to degradation problems. In\nthis paper, we propose a clean yet effective framework to generate\npose-controllable talking faces. We operate on raw face images, using only a\nsingle photo as an identity reference. The key is to modularize audio-visual\nrepresentations by devising an implicit low-dimension pose code. Substantially,\nboth speech content and head pose information lie in a joint non-identity\nembedding space. While speech content information can be defined by learning\nthe intrinsic synchronization between audio-visual modalities, we identify that\na pose code will be complementarily learned in a modulated convolution-based\nreconstruction framework.\n  Extensive experiments show that our method generates accurately lip-synced\ntalking faces whose poses are controllable by other videos. Moreover, our model\nhas multiple advanced capabilities including extreme view robustness and\ntalking face frontalization. Code, models, and demo videos are available at\nhttps://hangz-nju-cuhk.github.io/projects/PC-AVS.\n", "versions": [{"version": "v1", "created": "Thu, 22 Apr 2021 15:10:26 GMT"}], "update_date": "2021-04-23", "authors_parsed": [["Zhou", "Hang", ""], ["Sun", "Yasheng", ""], ["Wu", "Wayne", ""], ["Loy", "Chen Change", ""], ["Wang", "Xiaogang", ""], ["Liu", "Ziwei", ""]]}, {"id": "2104.11125", "submitter": "Chia-Yu Chen", "authors": "Chia-Yu Chen, Jiamin Ni, Songtao Lu, Xiaodong Cui, Pin-Yu Chen, Xiao\n  Sun, Naigang Wang, Swagath Venkataramani, Vijayalakshmi Srinivasan, Wei\n  Zhang, Kailash Gopalakrishnan", "title": "ScaleCom: Scalable Sparsified Gradient Compression for\n  Communication-Efficient Distributed Training", "comments": "NeurIPS2020 accepted\n  https://proceedings.neurips.cc/paper/2020/hash/9d58963592071dbf38a0fa114269959c-Abstract.html", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Large-scale distributed training of Deep Neural Networks (DNNs) on\nstate-of-the-art platforms is expected to be severely communication\nconstrained. To overcome this limitation, numerous gradient compression\ntechniques have been proposed and have demonstrated high compression ratios.\nHowever, most existing methods do not scale well to large scale distributed\nsystems (due to gradient build-up) and/or fail to evaluate model fidelity (test\naccuracy) on large datasets. To mitigate these issues, we propose a new\ncompression technique, Scalable Sparsified Gradient Compression (ScaleCom),\nthat leverages similarity in the gradient distribution amongst learners to\nprovide significantly improved scalability. Using theoretical analysis, we show\nthat ScaleCom provides favorable convergence guarantees and is compatible with\ngradient all-reduce techniques. Furthermore, we experimentally demonstrate that\nScaleCom has small overheads, directly reduces gradient traffic and provides\nhigh compression rates (65-400X) and excellent scalability (up to 64 learners\nand 8-12X larger batch sizes over standard training) across a wide range of\napplications (image, language, and speech) without significant accuracy loss.\n", "versions": [{"version": "v1", "created": "Wed, 21 Apr 2021 02:22:10 GMT"}], "update_date": "2021-04-23", "authors_parsed": [["Chen", "Chia-Yu", ""], ["Ni", "Jiamin", ""], ["Lu", "Songtao", ""], ["Cui", "Xiaodong", ""], ["Chen", "Pin-Yu", ""], ["Sun", "Xiao", ""], ["Wang", "Naigang", ""], ["Venkataramani", "Swagath", ""], ["Srinivasan", "Vijayalakshmi", ""], ["Zhang", "Wei", ""], ["Gopalakrishnan", "Kailash", ""]]}, {"id": "2104.11142", "submitter": "Martin Huber", "authors": "Martin Huber, David Imhof", "title": "Deep learning for detecting bid rigging: Flagging cartel participants\n  based on convolutional neural networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Adding to the literature on the data-driven detection of bid-rigging cartels,\nwe propose a novel approach based on deep learning (a subfield of artificial\nintelligence) that flags cartel participants based on their pairwise bidding\ninteractions with other firms. More concisely, we combine a so-called\nconvolutional neural network for image recognition with graphs that in a\npairwise manner plot the normalized bid values of some reference firm against\nthe normalized bids of any other firms participating in the same tenders as the\nreference firm. Based on Japanese and Swiss procurement data, we construct such\ngraphs for both collusive and competitive episodes (i.e when a bid-rigging\ncartel is or is not active) and use a subset of graphs to train the neural\nnetwork such that it learns distinguishing collusive from competitive bidding\npatterns. We use the remaining graphs to test the neural network's\nout-of-sample performance in correctly classifying collusive and competitive\nbidding interactions. We obtain a very decent average accuracy of around 90% or\nslightly higher when either applying the method within Japanese, Swiss, or\nmixed data (in which Swiss and Japanese graphs are pooled). When using data\nfrom one country for training to test the trained model's performance in the\nother country (i.e. transnationally), predictive performance decreases (likely\ndue to institutional differences in procurement procedures across countries),\nbut often remains satisfactorily high. All in all, the generally quite high\naccuracy of the convolutional neural network despite being trained in a rather\nsmall sample of a few 100 graphs points to a large potential of deep learning\napproaches for flagging and fighting bid-rigging cartels.\n", "versions": [{"version": "v1", "created": "Thu, 22 Apr 2021 15:48:12 GMT"}], "update_date": "2021-04-23", "authors_parsed": [["Huber", "Martin", ""], ["Imhof", "David", ""]]}, {"id": "2104.11146", "submitter": "Kun Yang", "authors": "Kun Yang, Samory Kpotufe, Nick Feamster", "title": "An Efficient One-Class SVM for Anomaly Detection in the Internet of\n  Things", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Insecure Internet of things (IoT) devices pose significant threats to\ncritical infrastructure and the Internet at large; detecting anomalous behavior\nfrom these devices remains of critical importance, but fast, efficient,\naccurate anomaly detection (also called \"novelty detection\") for these classes\nof devices remains elusive. One-Class Support Vector Machines (OCSVM) are one\nof the state-of-the-art approaches for novelty detection (or anomaly detection)\nin machine learning, due to their flexibility in fitting complex nonlinear\nboundaries between {normal} and {novel} data. IoT devices in smart homes and\ncities and connected building infrastructure present a compelling use case for\nnovelty detection with OCSVM due to the variety of devices, traffic patterns,\nand types of anomalies that can manifest in such environments. Much previous\nresearch has thus applied OCSVM to novelty detection for IoT. Unfortunately,\nconventional OCSVMs introduce significant memory requirements and are\ncomputationally expensive at prediction time as the size of the train set\ngrows, requiring space and time that scales with the number of training points.\nThese memory and computational constraints can be prohibitive in practical,\nreal-world deployments, where large training sets are typically needed to\ndevelop accurate models when fitting complex decision boundaries. In this work,\nwe extend so-called Nystr\\\"om and (Gaussian) Sketching approaches to OCSVM, by\ncombining these methods with clustering and Gaussian mixture models to achieve\nsignificant speedups in prediction time and space in various IoT settings,\nwithout sacrificing detection accuracy.\n", "versions": [{"version": "v1", "created": "Thu, 22 Apr 2021 15:59:56 GMT"}], "update_date": "2021-04-23", "authors_parsed": [["Yang", "Kun", ""], ["Kpotufe", "Samory", ""], ["Feamster", "Nick", ""]]}, {"id": "2104.11159", "submitter": "Matan Rusanovsky", "authors": "Matan Rusanovsky, Ofer Beeri, Sigalit Ifergane and Gal Oren", "title": "An End-to-End Computer Vision Methodology for Quantitative Metallography", "comments": "arXiv admin note: substantial text overlap with arXiv:2003.04226", "journal-ref": null, "doi": null, "report-no": null, "categories": "cond-mat.mtrl-sci cs.CV cs.LG physics.data-an", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Metallography is crucial for a proper assessment of material's properties. It\ninvolves mainly the investigation of spatial distribution of grains and the\noccurrence and characteristics of inclusions or precipitates. This work\npresents an holistic artificial intelligence model for Anomaly Detection that\nautomatically quantifies the degree of anomaly of impurities in alloys. We\nsuggest the following examination process: (1) Deep semantic segmentation is\nperformed on the inclusions (based on a suitable metallographic database of\nalloys and corresponding tags of inclusions), producing inclusions masks that\nare saved into a separated database. (2) Deep image inpainting is performed to\nfill the removed inclusions parts, resulting in 'clean' metallographic images,\nwhich contain the background of grains. (3) Grains' boundaries are marked using\ndeep semantic segmentation (based on another metallographic database of\nalloys), producing boundaries that are ready for further inspection on the\ndistribution of grains' size. (4) Deep anomaly detection and pattern\nrecognition is performed on the inclusions masks to determine spatial, shape\nand area anomaly detection of the inclusions. Finally, the system recommends to\nan expert on areas of interests for further examination. The performance of the\nmodel is presented and analyzed based on few representative cases. Although the\nmodels presented here were developed for metallography analysis, most of them\ncan be generalized to a wider set of problems in which anomaly detection of\ngeometrical objects is desired. All models as well as the data-sets that were\ncreated for this work, are publicly available at\nhttps://github.com/Scientific-Computing-Lab-NRCN/MLography.\n", "versions": [{"version": "v1", "created": "Thu, 22 Apr 2021 16:29:44 GMT"}], "update_date": "2021-04-23", "authors_parsed": [["Rusanovsky", "Matan", ""], ["Beeri", "Ofer", ""], ["Ifergane", "Sigalit", ""], ["Oren", "Gal", ""]]}, {"id": "2104.11165", "submitter": "Zahra Gharaee", "authors": "Zahra Gharaee", "title": "Hierarchical growing grid networks for skeleton based action recognition", "comments": null, "journal-ref": "Cognitive Systems Research, vol.63, pp.11-29 (2020)", "doi": "10.1016/j.cogsys.2020.05.002", "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.RO", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In this paper, a novel cognitive architecture for action recognition is\ndeveloped by applying layers of growing grid neural networks.Using these layers\nmakes the system capable of automatically arranging its representational\nstructure. In addition to the expansion of the neural map during the growth\nphase, the system is provided with a prior knowledge of the input space, which\nincreases the processing speed of the learning phase. Apart from two layers of\ngrowing grid networks the architecture is composed of a preprocessing layer, an\nordered vector representation layer and a one-layer supervised neural network.\nThese layers are designed to solve the action recognition problem. The\nfirst-layer growing grid receives the input data of human actions and the\nneural map generates an action pattern vector representing each action sequence\nby connecting the elicited activation of the trained map. The pattern vectors\nare then sent to the ordered vector representation layer to build the\ntime-invariant input vectors of key activations for the second-layer growing\ngrid. The second-layer growing grid categorizes the input vectors to the\ncorresponding action clusters/sub-clusters and finally the one-layer supervised\nneural network labels the shaped clusters with action labels. Three experiments\nusing different datasets of actions show that the system is capable of learning\nto categorize the actions quickly and efficiently. The performance of the\ngrowing grid architecture is com-pared with the results from a system based on\nSelf-Organizing Maps, showing that the growing grid architecture performs\nsignificantly superior on the action recognition tasks.\n", "versions": [{"version": "v1", "created": "Thu, 22 Apr 2021 16:35:32 GMT"}], "update_date": "2021-04-23", "authors_parsed": [["Gharaee", "Zahra", ""]]}, {"id": "2104.11169", "submitter": "Seongsik Park", "authors": "Seongsik Park, Dongjin Lee, Sungroh Yoon", "title": "Noise-Robust Deep Spiking Neural Networks with Temporal Information", "comments": "Accepted to DAC 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Spiking neural networks (SNNs) have emerged as energy-efficient neural\nnetworks with temporal information. SNNs have shown a superior efficiency on\nneuromorphic devices, but the devices are susceptible to noise, which hinders\nthem from being applied in real-world applications. Several studies have\nincreased noise robustness, but most of them considered neither deep SNNs nor\ntemporal information. In this paper, we investigate the effect of noise on deep\nSNNs with various neural coding methods and present a noise-robust deep SNN\nwith temporal information. With the proposed methods, we have achieved a deep\nSNN that is efficient and robust to spike deletion and jitter.\n", "versions": [{"version": "v1", "created": "Thu, 22 Apr 2021 16:40:33 GMT"}], "update_date": "2021-04-23", "authors_parsed": [["Park", "Seongsik", ""], ["Lee", "Dongjin", ""], ["Yoon", "Sungroh", ""]]}, {"id": "2104.11178", "submitter": "Hassan Akbari", "authors": "Hassan Akbari, Linagzhe Yuan, Rui Qian, Wei-Hong Chuang, Shih-Fu\n  Chang, Yin Cui, Boqing Gong", "title": "VATT: Transformers for Multimodal Self-Supervised Learning from Raw\n  Video, Audio and Text", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.MM eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a framework for learning multimodal representations from unlabeled\ndata using convolution-free Transformer architectures. Specifically, our\nVideo-Audio-Text Transformer (VATT) takes raw signals as inputs and extracts\nmultimodal representations that are rich enough to benefit a variety of\ndownstream tasks. We train VATT end-to-end from scratch using multimodal\ncontrastive losses and evaluate its performance by the downstream tasks of\nvideo action recognition, audio event classification, image classification, and\ntext-to-video retrieval. Furthermore, we study a modality-agnostic\nsingle-backbone Transformer by sharing weights among the three modalities. We\nshow that the convolution-free VATT outperforms state-of-the-art ConvNet-based\narchitectures in the downstream tasks. Especially, VATT's vision Transformer\nachieves the top-1 accuracy of 82.1% on Kinetics-400, 83.6% on Kinetics-600,and\n41.1% on Moments in Time, new records while avoiding supervised pre-training.\nTransferring to image classification leads to 78.7% top-1 accuracy on ImageNet\ncompared to 64.7% by training the same Transformer from scratch, showing the\ngeneralizability of our model despite the domain gap between videos and images.\nVATT's audio Transformer also sets a new record on waveform-based audio event\nrecognition by achieving the mAP of 39.4% on AudioSet without any supervised\npre-training.\n", "versions": [{"version": "v1", "created": "Thu, 22 Apr 2021 17:07:41 GMT"}], "update_date": "2021-04-23", "authors_parsed": [["Akbari", "Hassan", ""], ["Yuan", "Linagzhe", ""], ["Qian", "Rui", ""], ["Chuang", "Wei-Hong", ""], ["Chang", "Shih-Fu", ""], ["Cui", "Yin", ""], ["Gong", "Boqing", ""]]}, {"id": "2104.11186", "submitter": "Jean Tarbouriech", "authors": "Jean Tarbouriech, Runlong Zhou, Simon S. Du, Matteo Pirotta, Michal\n  Valko, Alessandro Lazaric", "title": "Stochastic Shortest Path: Minimax, Parameter-Free and Towards\n  Horizon-Free Regret", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of learning in the stochastic shortest path (SSP)\nsetting, where an agent seeks to minimize the expected cost accumulated before\nreaching a goal state. We design a novel model-based algorithm EB-SSP that\ncarefully skews the empirical transitions and perturbs the empirical costs with\nan exploration bonus to guarantee both optimism and convergence of the\nassociated value iteration scheme. We prove that EB-SSP achieves the minimax\nregret rate $\\widetilde{O}(B_{\\star} \\sqrt{S A K})$, where $K$ is the number of\nepisodes, $S$ is the number of states, $A$ is the number of actions and\n$B_{\\star}$ bounds the expected cumulative cost of the optimal policy from any\nstate, thus closing the gap with the lower bound. Interestingly, EB-SSP obtains\nthis result while being parameter-free, i.e., it does not require any prior\nknowledge of $B_{\\star}$, nor of $T_{\\star}$ which bounds the expected\ntime-to-goal of the optimal policy from any state. Furthermore, we illustrate\nvarious cases (e.g., positive costs, or general costs when an order-accurate\nestimate of $T_{\\star}$ is available) where the regret only contains a\nlogarithmic dependence on $T_{\\star}$, thus yielding the first horizon-free\nregret bound beyond the finite-horizon MDP setting.\n", "versions": [{"version": "v1", "created": "Thu, 22 Apr 2021 17:20:48 GMT"}], "update_date": "2021-04-23", "authors_parsed": [["Tarbouriech", "Jean", ""], ["Zhou", "Runlong", ""], ["Du", "Simon S.", ""], ["Pirotta", "Matteo", ""], ["Valko", "Michal", ""], ["Lazaric", "Alessandro", ""]]}, {"id": "2104.11203", "submitter": "Abhishek Gupta", "authors": "Abhishek Gupta, Justin Yu, Tony Z. Zhao, Vikash Kumar, Aaron Rovinsky,\n  Kelvin Xu, Thomas Devlin, Sergey Levine", "title": "Reset-Free Reinforcement Learning via Multi-Task Learning: Learning\n  Dexterous Manipulation Behaviors without Human Intervention", "comments": "Published at ICRA 2021. First four authors contributed equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement Learning (RL) algorithms can in principle acquire complex\nrobotic skills by learning from large amounts of data in the real world,\ncollected via trial and error. However, most RL algorithms use a carefully\nengineered setup in order to collect data, requiring human supervision and\nintervention to provide episodic resets. This is particularly evident in\nchallenging robotics problems, such as dexterous manipulation. To make data\ncollection scalable, such applications require reset-free algorithms that are\nable to learn autonomously, without explicit instrumentation or human\nintervention. Most prior work in this area handles single-task learning.\nHowever, we might also want robots that can perform large repertoires of\nskills. At first, this would appear to only make the problem harder. However,\nthe key observation we make in this work is that an appropriately chosen\nmulti-task RL setting actually alleviates the reset-free learning challenge,\nwith minimal additional machinery required. In effect, solving a multi-task\nproblem can directly solve the reset-free problem since different combinations\nof tasks can serve to perform resets for other tasks. By learning multiple\ntasks together and appropriately sequencing them, we can effectively learn all\nof the tasks together reset-free. This type of multi-task learning can\neffectively scale reset-free learning schemes to much more complex problems, as\nwe demonstrate in our experiments. We propose a simple scheme for multi-task\nlearning that tackles the reset-free learning problem, and show its\neffectiveness at learning to solve complex dexterous manipulation tasks in both\nhardware and simulation without any explicit resets. This work shows the\nability to learn dexterous manipulation behaviors in the real world with RL\nwithout any human intervention.\n", "versions": [{"version": "v1", "created": "Thu, 22 Apr 2021 17:38:27 GMT"}], "update_date": "2021-04-23", "authors_parsed": [["Gupta", "Abhishek", ""], ["Yu", "Justin", ""], ["Zhao", "Tony Z.", ""], ["Kumar", "Vikash", ""], ["Rovinsky", "Aaron", ""], ["Xu", "Kelvin", ""], ["Devlin", "Thomas", ""], ["Levine", "Sergey", ""]]}, {"id": "2104.11212", "submitter": "Adam \\'Scibior", "authors": "Adam Scibior, Vasileios Lioutas, Daniele Reda, Peyman Bateni, Frank\n  Wood", "title": "Imagining The Road Ahead: Multi-Agent Trajectory Prediction via\n  Differentiable Simulation", "comments": "10 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  We develop a deep generative model built on a fully differentiable simulator\nfor multi-agent trajectory prediction. Agents are modeled with conditional\nrecurrent variational neural networks (CVRNNs), which take as input an\nego-centric birdview image representing the current state of the world and\noutput an action, consisting of steering and acceleration, which is used to\nderive the subsequent agent state using a kinematic bicycle model. The full\nsimulation state is then differentiably rendered for each agent, initiating the\nnext time step. We achieve state-of-the-art results on the INTERACTION dataset,\nusing standard neural architectures and a standard variational training\nobjective, producing realistic multi-modal predictions without any ad-hoc\ndiversity-inducing losses. We conduct ablation studies to examine individual\ncomponents of the simulator, finding that both the kinematic bicycle model and\nthe continuous feedback from the birdview image are crucial for achieving this\nlevel of performance. We name our model ITRA, for \"Imagining the Road Ahead\".\n", "versions": [{"version": "v1", "created": "Thu, 22 Apr 2021 17:48:08 GMT"}], "update_date": "2021-04-23", "authors_parsed": [["Scibior", "Adam", ""], ["Lioutas", "Vasileios", ""], ["Reda", "Daniele", ""], ["Bateni", "Peyman", ""], ["Wood", "Frank", ""]]}, {"id": "2104.11213", "submitter": "Kiana Ehsani", "authors": "Kiana Ehsani, Winson Han, Alvaro Herrasti, Eli VanderBilt, Luca Weihs,\n  Eric Kolve, Aniruddha Kembhavi, Roozbeh Mottaghi", "title": "ManipulaTHOR: A Framework for Visual Object Manipulation", "comments": "CVPR 2021 -- (Oral presentation)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The domain of Embodied AI has recently witnessed substantial progress,\nparticularly in navigating agents within their environments. These early\nsuccesses have laid the building blocks for the community to tackle tasks that\nrequire agents to actively interact with objects in their environment. Object\nmanipulation is an established research domain within the robotics community\nand poses several challenges including manipulator motion, grasping and\nlong-horizon planning, particularly when dealing with oft-overlooked practical\nsetups involving visually rich and complex scenes, manipulation using mobile\nagents (as opposed to tabletop manipulation), and generalization to unseen\nenvironments and objects. We propose a framework for object manipulation built\nupon the physics-enabled, visually rich AI2-THOR framework and present a new\nchallenge to the Embodied AI community known as ArmPointNav. This task extends\nthe popular point navigation task to object manipulation and offers new\nchallenges including 3D obstacle avoidance, manipulating objects in the\npresence of occlusion, and multi-object manipulation that necessitates long\nterm planning. Popular learning paradigms that are successful on PointNav\nchallenges show promise, but leave a large room for improvement.\n", "versions": [{"version": "v1", "created": "Thu, 22 Apr 2021 17:49:04 GMT"}], "update_date": "2021-04-23", "authors_parsed": [["Ehsani", "Kiana", ""], ["Han", "Winson", ""], ["Herrasti", "Alvaro", ""], ["VanderBilt", "Eli", ""], ["Weihs", "Luca", ""], ["Kolve", "Eric", ""], ["Kembhavi", "Aniruddha", ""], ["Mottaghi", "Roozbeh", ""]]}, {"id": "2104.11216", "submitter": "Sumith Kulal", "authors": "Sumith Kulal, Jiayuan Mao, Alex Aiken, Jiajun Wu", "title": "Hierarchical Motion Understanding via Motion Programs", "comments": "CVPR 2021. First two authors contributed equally. Project page:\n  https://sumith1896.github.io/motion2prog/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current approaches to video analysis of human motion focus on raw pixels or\nkeypoints as the basic units of reasoning. We posit that adding higher-level\nmotion primitives, which can capture natural coarser units of motion such as\nbackswing or follow-through, can be used to improve downstream analysis tasks.\nThis higher level of abstraction can also capture key features, such as loops\nof repeated primitives, that are currently inaccessible at lower levels of\nrepresentation. We therefore introduce Motion Programs, a neuro-symbolic,\nprogram-like representation that expresses motions as a composition of\nhigh-level primitives. We also present a system for automatically inducing\nmotion programs from videos of human motion and for leveraging motion programs\nin video synthesis. Experiments show that motion programs can accurately\ndescribe a diverse set of human motions and the inferred programs contain\nsemantically meaningful motion primitives, such as arm swings and jumping\njacks. Our representation also benefits downstream tasks such as video\ninterpolation and video prediction and outperforms off-the-shelf models. We\nfurther demonstrate how these programs can detect diverse kinds of repetitive\nmotion and facilitate interactive video editing.\n", "versions": [{"version": "v1", "created": "Thu, 22 Apr 2021 17:49:59 GMT"}], "update_date": "2021-04-23", "authors_parsed": [["Kulal", "Sumith", ""], ["Mao", "Jiayuan", ""], ["Aiken", "Alex", ""], ["Wu", "Jiajun", ""]]}, {"id": "2104.11222", "submitter": "Gaurav Parmar", "authors": "Gaurav Parmar, Richard Zhang, Jun-Yan Zhu", "title": "On Buggy Resizing Libraries and Surprising Subtleties in FID Calculation", "comments": "GitHub: https://www.github.com/GaParmar/clean-fid Website:\n  https://www.cs.cmu.edu/~clean-fid/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.GR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the sensitivity of the Fr\\'echet Inception Distance (FID)\nscore to inconsistent and often incorrect implementations across different\nimage processing libraries. FID score is widely used to evaluate generative\nmodels, but each FID implementation uses a different low-level image processing\nprocess. Image resizing functions in commonly-used deep learning libraries\noften introduce aliasing artifacts. We observe that numerous subtle choices\nneed to be made for FID calculation and a lack of consistencies in these\nchoices can lead to vastly different FID scores. In particular, we show that\nthe following choices are significant: (1) selecting what image resizing\nlibrary to use, (2) choosing what interpolation kernel to use, (3) what\nencoding to use when representing images. We additionally outline numerous\ncommon pitfalls that should be avoided and provide recommendations for\ncomputing the FID score accurately. We provide an easy-to-use optimized\nimplementation of our proposed recommendations in the accompanying code.\n", "versions": [{"version": "v1", "created": "Thu, 22 Apr 2021 17:58:38 GMT"}], "update_date": "2021-04-23", "authors_parsed": [["Parmar", "Gaurav", ""], ["Zhang", "Richard", ""], ["Zhu", "Jun-Yan", ""]]}, {"id": "2104.11227", "submitter": "Christoph Feichtenhofer", "authors": "Haoqi Fan, Bo Xiong, Karttikeya Mangalam, Yanghao Li, Zhicheng Yan,\n  Jitendra Malik, Christoph Feichtenhofer", "title": "Multiscale Vision Transformers", "comments": "Technical report", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present Multiscale Vision Transformers (MViT) for video and image\nrecognition, by connecting the seminal idea of multiscale feature hierarchies\nwith transformer models. Multiscale Transformers have several\nchannel-resolution scale stages. Starting from the input resolution and a small\nchannel dimension, the stages hierarchically expand the channel capacity while\nreducing the spatial resolution. This creates a multiscale pyramid of features\nwith early layers operating at high spatial resolution to model simple\nlow-level visual information, and deeper layers at spatially coarse, but\ncomplex, high-dimensional features. We evaluate this fundamental architectural\nprior for modeling the dense nature of visual signals for a variety of video\nrecognition tasks where it outperforms concurrent vision transformers that rely\non large scale external pre-training and are 5-10x more costly in computation\nand parameters. We further remove the temporal dimension and apply our model\nfor image classification where it outperforms prior work on vision\ntransformers. Code is available at:\nhttps://github.com/facebookresearch/SlowFast\n", "versions": [{"version": "v1", "created": "Thu, 22 Apr 2021 17:59:45 GMT"}], "update_date": "2021-04-23", "authors_parsed": [["Fan", "Haoqi", ""], ["Xiong", "Bo", ""], ["Mangalam", "Karttikeya", ""], ["Li", "Yanghao", ""], ["Yan", "Zhicheng", ""], ["Malik", "Jitendra", ""], ["Feichtenhofer", "Christoph", ""]]}, {"id": "2104.11231", "submitter": "Tekin Evrim Ozmermer", "authors": "Tekin Evrim Ozmermer, Viktors Roze, Stanislavs Hilcuks, Alina\n  Nescerecka", "title": "VeriMedi: Pill Identification using Proxy-based Deep Metric Learning and\n  Exact Solution", "comments": "31 pages, 21 figures, 10 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.IT cs.LG math.IT", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  We present the system that we have developed for the identification and\nverification of pills using images that are taken by the VeriMedi device. The\nVeriMedi device is an Internet of Things device that takes pictures of a filled\npill vial from the bottom of the vial and uses the solution that is presented\nin this research to identify the pills in the vials. The solution has two\nserially connected deep learning solutions which do segmentation and\nidentification. The segmentation solution creates the masks for each pill in\nthe vial image by using the Mask R-CNN model, then segments and crops the pills\nand blurs the background. After that, the segmented pill images are sent to the\nidentification solution where a Deep Metric Learning model that is trained with\nProxy Anchor Loss (PAL) function generates embedding vectors for each pill\nimage. The generated embedding vectors are fed into a one-layer fully connected\nnetwork that is trained with the exact solution to predict each single pill\nimage. Then, the aggregation/verification function aggregates the multiple\npredictions coming from multiple single pill images and verifies the\ncorrectness of the final prediction with respect to predefined rules. Besides,\nwe enhanced the PAL with a better proxy initialization that increased the\nperformance of the models and let the model learn the new classes of images\ncontinually without retraining the model with the whole dataset. When the model\nthat is trained with initial classes is retrained only with new classes, the\naccuracy of the model increases for both old and new classes. The\nidentification solution that we have presented in this research can also be\nreused for other problem domains which require continual learning and/or\nFine-Grained Visual Categorization.\n", "versions": [{"version": "v1", "created": "Thu, 22 Apr 2021 06:52:30 GMT"}], "update_date": "2021-04-26", "authors_parsed": [["Ozmermer", "Tekin Evrim", ""], ["Roze", "Viktors", ""], ["Hilcuks", "Stanislavs", ""], ["Nescerecka", "Alina", ""]]}, {"id": "2104.11274", "submitter": "Tapan Gandhi Prof", "authors": "Rohan Wadhawan and Tapan K. Gandhi", "title": "Landmark-Aware and Part-based Ensemble Transfer Learning Network for\n  Facial Expression Recognition from Static images", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Facial Expression Recognition from static images is a challenging problem in\ncomputer vision applications. Convolutional Neural Network (CNN), the\nstate-of-the-art method for various computer vision tasks, has had limited\nsuccess in predicting expressions from faces having extreme poses,\nillumination, and occlusion conditions. To mitigate this issue, CNNs are often\naccompanied by techniques like transfer, multi-task, or ensemble learning that\noften provide high accuracy at the cost of high computational complexity. In\nthis work, we propose a Part-based Ensemble Transfer Learning network, which\nmodels how humans recognize facial expressions by correlating the spatial\norientation pattern of the facial features with a specific expression. It\nconsists of 5 sub-networks, in which each sub-network performs transfer\nlearning from one of the five subsets of facial landmarks: eyebrows, eyes,\nnose, mouth, or jaw to expression classification. We test the proposed network\non the CK+, JAFFE, and SFEW datasets, and it outperforms the benchmark for CK+\nand JAFFE datasets by 0.51\\% and 5.34\\%, respectively. Additionally, it\nconsists of a total of 1.65M model parameters and requires only 3.28 $\\times$\n$10^{6}$ FLOPS, which ensures computational efficiency for real-time\ndeployment. Grad-CAM visualizations of our proposed ensemble highlight the\ncomplementary nature of its sub-networks, a key design parameter of an\neffective ensemble network. Lastly, cross-dataset evaluation results reveal\nthat our proposed ensemble has a high generalization capacity. Our model\ntrained on the SFEW Train dataset achieves an accuracy of 47.53\\% on the CK+\ndataset, which is higher than what it achieves on the SFEW Valid dataset.\n", "versions": [{"version": "v1", "created": "Thu, 22 Apr 2021 18:38:33 GMT"}], "update_date": "2021-04-26", "authors_parsed": [["Wadhawan", "Rohan", ""], ["Gandhi", "Tapan K.", ""]]}, {"id": "2104.11295", "submitter": "Rishi Jha", "authors": "Rishi Jha and Kai Mihata", "title": "On Geodesic Distances and Contextual Embedding Compression for Text\n  Classification", "comments": "6 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In some memory-constrained settings like IoT devices and over-the-network\ndata pipelines, it can be advantageous to have smaller contextual embeddings.\nWe investigate the efficacy of projecting contextual embedding data (BERT) onto\na manifold, and using nonlinear dimensionality reduction techniques to compress\nthese embeddings. In particular, we propose a novel post-processing approach,\napplying a combination of Isomap and PCA. We find that the geodesic distance\nestimations, estimates of the shortest path on a Riemannian manifold, from\nIsomap's k-Nearest Neighbors graph bolstered the performance of the compressed\nembeddings to be comparable to the original BERT embeddings. On one dataset, we\nfind that despite a 12-fold dimensionality reduction, the compressed embeddings\nperformed within 0.1% of the original BERT embeddings on a downstream\nclassification task. In addition, we find that this approach works particularly\nwell on tasks reliant on syntactic data, when compared with linear\ndimensionality reduction. These results show promise for a novel geometric\napproach to achieve lower dimensional text embeddings from existing\ntransformers and pave the way for data-specific and application-specific\nembedding compressions.\n", "versions": [{"version": "v1", "created": "Thu, 22 Apr 2021 19:30:06 GMT"}], "update_date": "2021-04-26", "authors_parsed": [["Jha", "Rishi", ""], ["Mihata", "Kai", ""]]}, {"id": "2104.11315", "submitter": "Sewoong Oh", "authors": "Jonathan Hayase, Weihao Kong, Raghav Somani, Sewoong Oh", "title": "SPECTRE: Defending Against Backdoor Attacks Using Robust Statistics", "comments": "29 pages 19 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Modern machine learning increasingly requires training on a large collection\nof data from multiple sources, not all of which can be trusted. A particularly\nconcerning scenario is when a small fraction of poisoned data changes the\nbehavior of the trained model when triggered by an attacker-specified\nwatermark. Such a compromised model will be deployed unnoticed as the model is\naccurate otherwise. There have been promising attempts to use the intermediate\nrepresentations of such a model to separate corrupted examples from clean ones.\nHowever, these defenses work only when a certain spectral signature of the\npoisoned examples is large enough for detection. There is a wide range of\nattacks that cannot be protected against by the existing defenses. We propose a\nnovel defense algorithm using robust covariance estimation to amplify the\nspectral signature of corrupted data. This defense provides a clean model,\ncompletely removing the backdoor, even in regimes where previous methods have\nno hope of detecting the poisoned examples. Code and pre-trained models are\navailable at https://github.com/SewoongLab/spectre-defense .\n", "versions": [{"version": "v1", "created": "Thu, 22 Apr 2021 20:49:40 GMT"}], "update_date": "2021-04-26", "authors_parsed": [["Hayase", "Jonathan", ""], ["Kong", "Weihao", ""], ["Somani", "Raghav", ""], ["Oh", "Sewoong", ""]]}, {"id": "2104.11320", "submitter": "Hina Tabassum Prof.", "authors": "Sheyda Zarandi and Hina Tabassum", "title": "Federated Double Deep Q-learning for Joint Delay and Energy Minimization\n  in IoT networks", "comments": "Accepted, in IEEE International Conference on Communications (ICC)\n  Workshops, 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we propose a federated deep reinforcement learning framework\nto solve a multi-objective optimization problem, where we consider minimizing\nthe expected long-term task completion delay and energy consumption of IoT\ndevices. This is done by optimizing offloading decisions, computation resource\nallocation, and transmit power allocation. Since the formulated problem is a\nmixed-integer non-linear programming (MINLP), we first cast our problem as a\nmulti-agent distributed deep reinforcement learning (DRL) problem and address\nit using double deep Q-network (DDQN), where the actions are offloading\ndecisions. The immediate cost of each agent is calculated through solving\neither the transmit power optimization or local computation resource\noptimization, based on the selected offloading decisions (actions). Then, to\nenhance the learning speed of IoT devices (agents), we incorporate federated\nlearning (FDL) at the end of each episode. FDL enhances the scalability of the\nproposed DRL framework, creates a context for cooperation between agents, and\nminimizes their privacy concerns. Our numerical results demonstrate the\nefficacy of our proposed federated DDQN framework in terms of learning speed\ncompared to federated deep Q network (DQN) and non-federated DDQN algorithms.\nIn addition, we investigate the impact of batch size, network layers, DDQN\ntarget network update frequency on the learning speed of the FDL.\n", "versions": [{"version": "v1", "created": "Fri, 2 Apr 2021 18:41:59 GMT"}], "update_date": "2021-04-26", "authors_parsed": [["Zarandi", "Sheyda", ""], ["Tabassum", "Hina", ""]]}, {"id": "2104.11342", "submitter": "Navid Zobeiry", "authors": "Keith D. Humfeld, Dawei Gu, Geoffrey A. Butler, Karl Nelson, Navid\n  Zobeiry", "title": "A Machine Learning Framework for Real-time Inverse Modeling and\n  Multi-objective Process Optimization of Composites for Active Manufacturing\n  Control", "comments": null, "journal-ref": null, "doi": "10.1016/j.compositesb.2021.109150", "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For manufacturing of aerospace composites, several parts may be processed\nsimultaneously using convective heating in an autoclave. Due to uncertainties\nincluding tool placement, convective Boundary Conditions (BCs) vary in each\nrun. As a result, temperature histories in some of the parts may not conform to\nprocess specifications due to under-curing or over-heating. Thermochemical\nanalysis using Finite Element (FE) simulations are typically conducted prior to\nfabrication based on assumed range of BCs. This, however, introduces\nunnecessary constraints on the design. To monitor the process, thermocouples\n(TCs) are placed under tools near critical locations. The TC data may be used\nto back-calculate BCs using trial-and-error FE analysis. However, since the\ninverse heat transfer problem is ill-posed, many solutions are obtained for\ngiven TC data. In this study, a novel machine learning (ML) framework is\npresented capable of optimizing air temperature cycle in real-time based on TC\ndata from multiple parts, for active control of manufacturing. The framework\nconsists of two recurrent Neural Networks (NN) for inverse modeling of the\nill-posed curing problem at the speed of 300 simulations/second, and a\nclassification NN for multi-objective optimization of the air temperature at\nthe speed of 35,000 simulations/second. A virtual demonstration of the\nframework for process optimization of three composite parts with data from\nthree TCs is presented.\n", "versions": [{"version": "v1", "created": "Thu, 22 Apr 2021 22:54:36 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Humfeld", "Keith D.", ""], ["Gu", "Dawei", ""], ["Butler", "Geoffrey A.", ""], ["Nelson", "Karl", ""], ["Zobeiry", "Navid", ""]]}, {"id": "2104.11347", "submitter": "Jianwei Zhang", "authors": "Jianwei Zhang, Suren Jayasuriya, Visar Berisha", "title": "Restoring degraded speech via a modified diffusion model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There are many deterministic mathematical operations (e.g. compression,\nclipping, downsampling) that degrade speech quality considerably. In this paper\nwe introduce a neural network architecture, based on a modification of the\nDiffWave model, that aims to restore the original speech signal. DiffWave, a\nrecently published diffusion-based vocoder, has shown state-of-the-art\nsynthesized speech quality and relatively shorter waveform generation times,\nwith only a small set of parameters. We replace the mel-spectrum upsampler in\nDiffWave with a deep CNN upsampler, which is trained to alter the degraded\nspeech mel-spectrum to match that of the original speech. The model is trained\nusing the original speech waveform, but conditioned on the degraded speech\nmel-spectrum. Post-training, only the degraded mel-spectrum is used as input\nand the model generates an estimate of the original speech. Our model results\nin improved speech quality (original DiffWave model as baseline) on several\ndifferent experiments. These include improving the quality of speech degraded\nby LPC-10 compression, AMR-NB compression, and signal clipping. Compared to the\noriginal DiffWave architecture, our scheme achieves better performance on\nseveral objective perceptual metrics and in subjective comparisons.\nImprovements over baseline are further amplified in a out-of-corpus evaluation\nsetting.\n", "versions": [{"version": "v1", "created": "Thu, 22 Apr 2021 23:03:23 GMT"}], "update_date": "2021-04-26", "authors_parsed": [["Zhang", "Jianwei", ""], ["Jayasuriya", "Suren", ""], ["Berisha", "Visar", ""]]}, {"id": "2104.11349", "submitter": "Jongwook Woo", "authors": "Shradha Shinde, Jay Joshi, Sowmya Mareedu, Yeon Pyo Kim, Jongwook Woo", "title": "Scalable Predictive Time-Series Analysis of COVID-19: Cases and\n  Fatalities", "comments": "8 pages, 7 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  COVID 19 is an acute disease that started spreading throughout the world,\nbeginning in December 2019. It has spread worldwide and has affected more than\n7 million people, and 200 thousand people have died due to this infection as of\nOct 2020. In this paper, we have forecasted the number of deaths and the\nconfirmed cases in Los Angeles and New York of the United States using the\ntraditional and Big Data platforms based on the Times Series: ARIMA and ETS. We\nalso implemented a more sophisticated time-series forecast model using Facebook\nProphet API. Furthermore, we developed the classification models: Logistic\nRegression and Random Forest regression to show that the Weather does not\naffect the number of the confirmed cases. The models are built and run in\nlegacy systems (Azure ML Studio) and Big Data systems (Oracle Cloud and\nDatabricks). Besides, we present the accuracy of the models.\n", "versions": [{"version": "v1", "created": "Thu, 22 Apr 2021 23:08:13 GMT"}], "update_date": "2021-04-26", "authors_parsed": [["Shinde", "Shradha", ""], ["Joshi", "Jay", ""], ["Mareedu", "Sowmya", ""], ["Kim", "Yeon Pyo", ""], ["Woo", "Jongwook", ""]]}, {"id": "2104.11353", "submitter": "Daniel Brown", "authors": "Avik Jain, Lawrence Chan, Daniel S. Brown, and Anca D. Dragan", "title": "Optimal Cost Design for Model Predictive Control", "comments": "In proceedings of 3rd Annual Learning for Dynamics & Control\n  Conference (L4DC) 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many robotics domains use some form of nonconvex model predictive control\n(MPC) for planning, which sets a reduced time horizon, performs trajectory\noptimization, and replans at every step. The actual task typically requires a\nmuch longer horizon than is computationally tractable, and is specified via a\ncost function that cumulates over that full horizon. For instance, an\nautonomous car may have a cost function that makes a desired trade-off between\nefficiency, safety, and obeying traffic laws. In this work, we challenge the\ncommon assumption that the cost we optimize using MPC should be the same as the\nground truth cost for the task (plus a terminal cost). MPC solvers can suffer\nfrom short planning horizons, local optima, incorrect dynamics models, and,\nimportantly, fail to account for future replanning ability. Thus, we propose\nthat in many tasks it could be beneficial to purposefully choose a different\ncost function for MPC to optimize: one that results in the MPC rollout having\nlow ground truth cost, rather than the MPC planned trajectory. We formalize\nthis as an optimal cost design problem, and propose a zeroth-order\noptimization-based approach that enables us to design optimal costs for an MPC\nplanning robot in continuous MDPs. We test our approach in an autonomous\ndriving domain where we find costs different from the ground truth that\nimplicitly compensate for replanning, short horizon, incorrect dynamics models,\nand local minima issues. As an example, the learned cost incentivizes MPC to\ndelay its decision until later, implicitly accounting for the fact that it will\nget more information in the future and be able to make a better decision. Code\nand videos available at https://sites.google.com/berkeley.edu/ocd-mpc/.\n", "versions": [{"version": "v1", "created": "Fri, 23 Apr 2021 00:00:58 GMT"}, {"version": "v2", "created": "Wed, 9 Jun 2021 23:54:22 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["Jain", "Avik", ""], ["Chan", "Lawrence", ""], ["Brown", "Daniel S.", ""], ["Dragan", "Anca D.", ""]]}, {"id": "2104.11384", "submitter": "Ali Ahmadvand", "authors": "Ali Ahmadvand, Sayyed M. Zahiri, Simon Hughes, Khalifa Al Jadda, Surya\n  Kallumadi, and Eugene Agichtein", "title": "APRF-Net: Attentive Pseudo-Relevance Feedback Network for Query\n  Categorization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Query categorization is an essential part of query intent understanding in\ne-commerce search. A common query categorization task is to select the relevant\nfine-grained product categories in a product taxonomy. For frequent queries,\nrich customer behavior (e.g., click-through data) can be used to infer the\nrelevant product categories. However, for more rare queries, which cover a\nlarge volume of search traffic, relying solely on customer behavior may not\nsuffice due to the lack of this signal. To improve categorization of rare\nqueries, we adapt the Pseudo-Relevance Feedback (PRF) approach to utilize the\nlatent knowledge embedded in semantically or lexically similar product\ndocuments to enrich the representation of the more rare queries. To this end,\nwe propose a novel deep neural model named Attentive Pseudo Relevance Feedback\nNetwork (APRF-Net) to enhance the representation of rare queries for query\ncategorization. To demonstrate the effectiveness of our approach, we collect\nsearch queries from a large commercial search engine, and compare APRF-Net to\nstate-of-the-art deep learning models for text classification. Our results show\nthat the APRF-Net significantly improves query categorization by 5.9% on F1@1\nscore over the baselines, which increases to 8.2% improvement for the rare\n(tail) queries. The findings of this paper can be leveraged for further\nimprovements in search query representation and understanding.\n", "versions": [{"version": "v1", "created": "Fri, 23 Apr 2021 02:34:08 GMT"}, {"version": "v2", "created": "Mon, 10 May 2021 18:47:46 GMT"}], "update_date": "2021-05-12", "authors_parsed": [["Ahmadvand", "Ali", ""], ["Zahiri", "Sayyed M.", ""], ["Hughes", "Simon", ""], ["Jadda", "Khalifa Al", ""], ["Kallumadi", "Surya", ""], ["Agichtein", "Eugene", ""]]}, {"id": "2104.11395", "submitter": "Chunyan Ji", "authors": "Chunyan Ji and Yi Pan", "title": "Infant Vocal Tract Development Analysis and Diagnosis by Cry Signals\n  with CNN Age Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  From crying to babbling and then to speech, infant's vocal tract goes through\nanatomic restructuring. In this paper, we propose a non-invasive fast method of\nusing infant cry signals with convolutional neural network (CNN) based age\nclassification to diagnose the abnormality of the vocal tract development as\nearly as 4-month age. We study F0, F1, F2, and spectrograms and relate them to\nthe postnatal development of infant vocalization. A novel CNN based age\nclassification is performed with binary age pairs to discover the pattern and\ntendency of the vocal tract changes. The effectiveness of this approach is\nevaluated on Baby2020 with healthy infant cries and Baby Chillanto database\nwith pathological infant cries. The results show that our approach yields\n79.20% accuracy for healthy cries, 84.80% for asphyxiated cries, and 91.20% for\ndeaf cries. Our method first reveals that infants' vocal tract develops to a\ncertain level at 4-month age and infants can start controlling the vocal folds\nto produce discontinuous cry sounds leading to babbling. Early diagnosis of\ngrowth abnormality of the vocal tract can help parents keep vigilant and adopt\nmedical treatment or training therapy for their infants as early as possible.\n", "versions": [{"version": "v1", "created": "Fri, 23 Apr 2021 03:09:16 GMT"}], "update_date": "2021-04-26", "authors_parsed": [["Ji", "Chunyan", ""], ["Pan", "Yi", ""]]}, {"id": "2104.11401", "submitter": "Jaehee Chun", "authors": "Jaehee Chun (3), Justin C. Park (1), Sven Olberg (1 and 2), You Zhang\n  (1), Dan Nguyen (1), Jing Wang (1), Jin Sung Kim (3), Steve Jiang (1) ((1)\n  Medical Artificial Intelligence and Automation (MAIA) Laboratory, Department\n  of Radiation Oncology, University of Texas Southwestern Medical Center,\n  Dallas, USA, (2) Department of Biomedical Engineering, Washington University\n  in St. Louis, St. Louis, USA, (3) Department of Radiation Oncology, Yonsei\n  Cancer Center, Yonsei University College of Medicine, Seoul, South Korea)", "title": "Intentional Deep Overfit Learning (IDOL): A Novel Deep Learning Strategy\n  for Adaptive Radiation Therapy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this study, we propose a tailored DL framework for patient-specific\nperformance that leverages the behavior of a model intentionally overfitted to\na patient-specific training dataset augmented from the prior information\navailable in an ART workflow - an approach we term Intentional Deep Overfit\nLearning (IDOL). Implementing the IDOL framework in any task in radiotherapy\nconsists of two training stages: 1) training a generalized model with a diverse\ntraining dataset of N patients, just as in the conventional DL approach, and 2)\nintentionally overfitting this general model to a small training\ndataset-specific the patient of interest (N+1) generated through perturbations\nand augmentations of the available task- and patient-specific prior information\nto establish a personalized IDOL model. The IDOL framework itself is\ntask-agnostic and is thus widely applicable to many components of the ART\nworkflow, three of which we use as a proof of concept here: the auto-contouring\ntask on re-planning CTs for traditional ART, the MRI super-resolution (SR) task\nfor MRI-guided ART, and the synthetic CT (sCT) reconstruction task for MRI-only\nART. In the re-planning CT auto-contouring task, the accuracy measured by the\nDice similarity coefficient improves from 0.847 with the general model to 0.935\nby adopting the IDOL model. In the case of MRI SR, the mean absolute error\n(MAE) is improved by 40% using the IDOL framework over the conventional model.\nFinally, in the sCT reconstruction task, the MAE is reduced from 68 to 22 HU by\nutilizing the IDOL framework.\n", "versions": [{"version": "v1", "created": "Fri, 23 Apr 2021 03:41:49 GMT"}], "update_date": "2021-04-26", "authors_parsed": [["Chun", "Jaehee", "", "1 and 2"], ["Park", "Justin C.", "", "1 and 2"], ["Olberg", "Sven", "", "1 and 2"], ["Zhang", "You", ""], ["Nguyen", "Dan", ""], ["Wang", "Jing", ""], ["Kim", "Jin Sung", ""], ["Jiang", "Steve", ""]]}, {"id": "2104.11408", "submitter": "Xin Dong", "authors": "Xin Dong, Junfeng Guo, Wei-Te Ting, H.T. Kung", "title": "Lightweight Detection of Out-of-Distribution and Adversarial Samples via\n  Channel Mean Discrepancy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Detecting out-of-distribution (OOD) and adversarial samples is essential when\ndeploying classification models in real-world applications. We introduce\nChannel Mean Discrepancy (CMD), a model-agnostic distance metric for evaluating\nthe statistics of features extracted by classification models, inspired by\nintegral probability metrics. CMD compares the feature statistics of incoming\nsamples against feature statistics estimated from previously seen training\nsamples with minimal overhead. We experimentally demonstrate that CMD magnitude\nis significantly smaller for legitimate samples than for OOD and adversarial\nsamples. We propose a simple method to reliably differentiate between\nlegitimate samples from OOD and adversarial samples using CMD, requiring only a\nsingle forward pass on a pre-trained classification model per sample. We\nfurther demonstrate how to achieve single image detection by using a\nlightweight model for channel sensitivity tuning, an improvement on other\nstatistical detection methods. Preliminary results show that our simple yet\neffective method outperforms several state-of-the-art approaches to detecting\nOOD and adversarial samples across various datasets and attack methods with\nhigh efficiency and generalizability.\n", "versions": [{"version": "v1", "created": "Fri, 23 Apr 2021 04:15:53 GMT"}], "update_date": "2021-04-26", "authors_parsed": [["Dong", "Xin", ""], ["Guo", "Junfeng", ""], ["Ting", "Wei-Te", ""], ["Kung", "H. T.", ""]]}, {"id": "2104.11410", "submitter": "Tom Portegys PhD", "authors": "Thomas E. Portegys", "title": "A modularity comparison of Long Short-Term Memory and Morphognosis\n  neural networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This study compares the modularity performance of two artificial neural\nnetwork architectures: a Long Short-Term Memory (LSTM) recurrent network, and\nMorphognosis, a neural network based on a hierarchy of spatial and temporal\ncontexts. Mazes are used to measure performance, defined as the ability to\nutilize independently learned mazes to solve mazes composed of them. A maze is\na sequence of rooms connected by doors. The modular task is implemented as\nfollows: at the beginning of the maze, an initial door choice forms a context\nthat must be retained until the end of an intervening maze, where the same door\nmust be chosen again to reach the goal. For testing, the door-association mazes\nand separately trained intervening mazes are presented together for the first\ntime. While both neural networks perform well during training, the testing\nperformance of Morphognosis is significantly better than LSTM on this modular\ntask.\n", "versions": [{"version": "v1", "created": "Fri, 23 Apr 2021 04:22:26 GMT"}], "update_date": "2021-04-26", "authors_parsed": [["Portegys", "Thomas E.", ""]]}, {"id": "2104.11413", "submitter": "Mohammad Samragh", "authors": "Mohammad Samragh, Hossein Hosseini, Aleksei Triastcyn, Kambiz Azarian,\n  Joseph Soriaga, Farinaz Koushanfar", "title": "Unsupervised Information Obfuscation for Split Inference of Neural\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Splitting network computations between the edge device and a server enables\nlow edge-compute inference of neural networks but might expose sensitive\ninformation about the test query to the server. To address this problem,\nexisting techniques train the model to minimize information leakage for a given\nset of sensitive attributes. In practice, however, the test queries might\ncontain attributes that are not foreseen during training. We propose instead an\nunsupervised obfuscation method to discard the information irrelevant to the\nmain task. We formulate the problem via an information theoretical framework\nand derive an analytical solution for a given distortion to the model output.\nIn our method, the edge device runs the model up to a split layer determined\nbased on its computational capacity. It then obfuscates the obtained feature\nvector based on the first layer of the server model by removing the components\nin the null space as well as the low-energy components of the remaining signal.\nOur experimental results show that our method outperforms existing techniques\nin removing the information of the irrelevant attributes and maintaining the\naccuracy on the target label. We also show that our method reduces the\ncommunication cost and incurs only a small computational overhead.\n", "versions": [{"version": "v1", "created": "Fri, 23 Apr 2021 05:02:07 GMT"}, {"version": "v2", "created": "Wed, 23 Jun 2021 03:03:12 GMT"}], "update_date": "2021-06-24", "authors_parsed": [["Samragh", "Mohammad", ""], ["Hosseini", "Hossein", ""], ["Triastcyn", "Aleksei", ""], ["Azarian", "Kambiz", ""], ["Soriaga", "Joseph", ""], ["Koushanfar", "Farinaz", ""]]}, {"id": "2104.11416", "submitter": "Yige Peng", "authors": "Yige Peng, Lei Bi, Ashnil Kumar, Michael Fulham, Dagan Feng, Jinman\n  Kim", "title": "Predicting Distant Metastases in Soft-Tissue Sarcomas from PET-CT scans\n  using Constrained Hierarchical Multi-Modality Feature Learning", "comments": "Under Review", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Distant metastases (DM) refer to the dissemination of tumors, usually, beyond\nthe organ where the tumor originated. They are the leading cause of death in\npatients with soft-tissue sarcomas (STSs). Positron emission\ntomography-computed tomography (PET-CT) is regarded as the imaging modality of\nchoice for the management of STSs. It is difficult to determine from imaging\nstudies which STS patients will develop metastases. 'Radiomics' refers to the\nextraction and analysis of quantitative features from medical images and it has\nbeen employed to help identify such tumors. The state-of-the-art in radiomics\nis based on convolutional neural networks (CNNs). Most CNNs are designed for\nsingle-modality imaging data (CT or PET alone) and do not exploit the\ninformation embedded in PET-CT where there is a combination of an anatomical\nand functional imaging modality. Furthermore, most radiomic methods rely on\nmanual input from imaging specialists for tumor delineation, definition and\nselection of radiomic features. This approach, however, may not be scalable to\ntumors with complex boundaries and where there are multiple other sites of\ndisease. We outline a new 3D CNN to help predict DM in STS patients from PET-CT\ndata. The 3D CNN uses a constrained feature learning module and a hierarchical\nmulti-modality feature learning module that leverages the complementary\ninformation from the modalities to focus on semantically important regions. Our\nresults on a public PET-CT dataset of STS patients show that multi-modal\ninformation improves the ability to identify those patients who develop DM.\nFurther our method outperformed all other related state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Fri, 23 Apr 2021 05:12:02 GMT"}], "update_date": "2021-04-26", "authors_parsed": [["Peng", "Yige", ""], ["Bi", "Lei", ""], ["Kumar", "Ashnil", ""], ["Fulham", "Michael", ""], ["Feng", "Dagan", ""], ["Kim", "Jinman", ""]]}, {"id": "2104.11421", "submitter": "Woodo Lee", "authors": "Woodo Lee, Jakyung Koo, Nokyung Park, Pilgu Kang, Jeakwon Shim", "title": "A Framework for Recognizing and Estimating Human Concentration Levels", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.IV eess.SP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  One of the major tasks in online education is to estimate the concentration\nlevels of each student. Previous studies have a limitation of classifying the\nlevels using discrete states only. The purpose of this paper is to estimate the\nsubtle levels as specified states by using the minimum amount of body movement\ndata. This is done by a framework composed of a Deep Neural Network and Kalman\nFilter. Using this framework, we successfully extracted the concentration\nlevels, which can be used to aid lecturers and expand to other areas.\n", "versions": [{"version": "v1", "created": "Fri, 23 Apr 2021 05:37:48 GMT"}], "update_date": "2021-04-26", "authors_parsed": [["Lee", "Woodo", ""], ["Koo", "Jakyung", ""], ["Park", "Nokyung", ""], ["Kang", "Pilgu", ""], ["Shim", "Jeakwon", ""]]}, {"id": "2104.11426", "submitter": "Kyubaek Yoon", "authors": "Kyubaek Yoon, Hojun You, Wei-Ying Wu, Chae Young Lim, Jongeun Choi,\n  Connor Boss, Ahmed Ramadan, John M. Popovich Jr., Jacek Cholewicki, N. Peter\n  Reeves, Clark J. Radcliffe", "title": "Regularized Nonlinear Regression for Simultaneously Selecting and\n  Estimating Key Model Parameters", "comments": "13 pages, 4 figures, 2 Tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In system identification, estimating parameters of a model using limited\nobservations results in poor identifiability. To cope with this issue, we\npropose a new method to simultaneously select and estimate sensitive parameters\nas key model parameters and fix the remaining parameters to a set of typical\nvalues. Our method is formulated as a nonlinear least squares estimator with\nL1-regularization on the deviation of parameters from a set of typical values.\nFirst, we provide consistency and oracle properties of the proposed estimator\nas a theoretical foundation. Second, we provide a novel approach based on\nLevenberg-Marquardt optimization to numerically find the solution to the\nformulated problem. Third, to show the effectiveness, we present an application\nidentifying a biomechanical parametric model of a head position tracking task\nfor 10 human subjects from limited data. In a simulation study, the variances\nof estimated parameters are decreased by 96.1% as compared to that of the\nestimated parameters without L1-regularization. In an experimental study, our\nmethod improves the model interpretation by reducing the number of parameters\nto be estimated while maintaining variance accounted for (VAF) at above 82.5%.\nMoreover, the variances of estimated parameters are reduced by 71.1% as\ncompared to that of the estimated parameters without L1-regularization. Our\nmethod is 54 times faster than the standard simplex-based optimization to solve\nthe regularized nonlinear regression.\n", "versions": [{"version": "v1", "created": "Fri, 23 Apr 2021 06:17:57 GMT"}], "update_date": "2021-04-26", "authors_parsed": [["Yoon", "Kyubaek", ""], ["You", "Hojun", ""], ["Wu", "Wei-Ying", ""], ["Lim", "Chae Young", ""], ["Choi", "Jongeun", ""], ["Boss", "Connor", ""], ["Ramadan", "Ahmed", ""], ["Popovich", "John M.", "Jr."], ["Cholewicki", "Jacek", ""], ["Reeves", "N. Peter", ""], ["Radcliffe", "Clark J.", ""]]}, {"id": "2104.11430", "submitter": "Benjamin Wilson", "authors": "Benjamin Wilson", "title": "Learning phylogenetic trees as hyperbolic point configurations", "comments": "17 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel method for the inference of phylogenetic trees that\nutilises point configurations on hyperbolic space as its optimisation\nlandscape. Each taxon corresponds to a point of the point configuration, while\nthe evolutionary distance between taxa is represented by the geodesic distance\nbetween their corresponding points. The point configuration is iteratively\nmodified to increase an objective function that additively combines pairwise\nlog-likelihood terms. After convergence, the final tree is derived from the\ninter-point distances using a standard distance-based method. The objective\nfunction, which is shown to mimic the log-likelihood on tree space, is a\ndifferentiable function on a Riemannian manifold. Thus gradient-based\noptimisation techniques can be applied, avoiding the need for combinatorial\nrearrangements of tree topology.\n", "versions": [{"version": "v1", "created": "Fri, 23 Apr 2021 06:32:58 GMT"}, {"version": "v2", "created": "Fri, 4 Jun 2021 06:23:01 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["Wilson", "Benjamin", ""]]}, {"id": "2104.11434", "submitter": "Kaidi Yang", "authors": "Daniele Gammelli, Kaidi Yang, James Harrison, Filipe Rodrigues,\n  Francisco C. Pereira, Marco Pavone", "title": "Graph Neural Network Reinforcement Learning for Autonomous\n  Mobility-on-Demand Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.LG cs.RO cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autonomous mobility-on-demand (AMoD) systems represent a rapidly developing\nmode of transportation wherein travel requests are dynamically handled by a\ncoordinated fleet of robotic, self-driving vehicles. Given a graph\nrepresentation of the transportation network - one where, for example, nodes\nrepresent areas of the city, and edges the connectivity between them - we argue\nthat the AMoD control problem is naturally cast as a node-wise decision-making\nproblem. In this paper, we propose a deep reinforcement learning framework to\ncontrol the rebalancing of AMoD systems through graph neural networks.\nCrucially, we demonstrate that graph neural networks enable reinforcement\nlearning agents to recover behavior policies that are significantly more\ntransferable, generalizable, and scalable than policies learned through other\napproaches. Empirically, we show how the learned policies exhibit promising\nzero-shot transfer capabilities when faced with critical portability tasks such\nas inter-city generalization, service area expansion, and adaptation to\npotentially complex urban topologies.\n", "versions": [{"version": "v1", "created": "Fri, 23 Apr 2021 06:42:38 GMT"}], "update_date": "2021-04-26", "authors_parsed": [["Gammelli", "Daniele", ""], ["Yang", "Kaidi", ""], ["Harrison", "James", ""], ["Rodrigues", "Filipe", ""], ["Pereira", "Francisco C.", ""], ["Pavone", "Marco", ""]]}, {"id": "2104.11455", "submitter": "Tonghan Wang", "authors": "Heng Dong, Tonghan Wang, Jiayuan Liu, Chi Han, Chongjie Zhang", "title": "Birds of a Feather Flock Together: A Close Look at Cooperation Emergence\n  via Multi-Agent RL", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How cooperation emerges is a long-standing and interdisciplinary problem.\nGame-theoretical studies on social dilemmas reveal that altruistic incentives\nare critical to the emergence of cooperation but their analyses are limited to\nstateless games. For more realistic scenarios, multi-agent reinforcement\nlearning has been used to study sequential social dilemmas (SSDs). Recent works\nshow that learning to incentivize other agents can promote cooperation in SSDs.\nHowever, we find that, with these incentivizing mechanisms, the team\ncooperation level does not converge and regularly oscillates between\ncooperation and defection during learning. We show that a second-order social\ndilemma resulting from the incentive mechanisms is the main reason for such\nfragile cooperation. We formally analyze the dynamics of second-order social\ndilemmas and find that a typical tendency of humans, called homophily, provides\na promising solution. We propose a novel learning framework to encourage\nhomophilic incentives and show that it achieves stable cooperation in both SSDs\nof public goods and tragedy of the commons.\n", "versions": [{"version": "v1", "created": "Fri, 23 Apr 2021 08:00:45 GMT"}, {"version": "v2", "created": "Sat, 5 Jun 2021 12:44:20 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Dong", "Heng", ""], ["Wang", "Tonghan", ""], ["Liu", "Jiayuan", ""], ["Han", "Chi", ""], ["Zhang", "Chongjie", ""]]}, {"id": "2104.11467", "submitter": "Robin Karlsson", "authors": "Robin Karlsson, David Robert Wong, Kazunari Kawabata, Simon Thompson,\n  Naoki Sakai", "title": "Probabilistic Rainfall Estimation from Automotive Lidar", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.CV cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robust sensing and perception in adverse weather conditions remains one of\nthe biggest challenges for realizing reliable autonomous vehicle mobility\nservices. Prior work has established that rainfall rate is a useful measure for\nadversity of atmospheric weather conditions. This work presents a probabilistic\nhierarchical Bayesian model that infers rainfall rate from automotive lidar\npoint cloud sequences with high accuracy and reliability. The model is a\nhierarchical mixture of expert model, or a probabilistic decision tree, with\ngating and expert nodes consisting of variational logistic and linear\nregression models. Experimental data used to train and evaluate the model is\ncollected in a large-scale rainfall experiment facility from both stationary\nand moving vehicle platforms. The results show prediction accuracy comparable\nto the measurement resolution of a disdrometer, and the soundness and\nusefulness of the uncertainty estimation. The model achieves RMSE 2.42 mm/h\nafter filtering out uncertain predictions. The error is comparable to the mean\nrainfall rate change of 3.5 mm/h between measurements. Model parameter studies\nshow how predictive performance changes with tree depth, sampling duration, and\ncrop box dimension. A second experiment demonstrate the predictability of\nhigher rainfall above 300 mm/h using a different lidar sensor, demonstrating\nsensor independence.\n", "versions": [{"version": "v1", "created": "Fri, 23 Apr 2021 08:35:54 GMT"}], "update_date": "2021-04-26", "authors_parsed": [["Karlsson", "Robin", ""], ["Wong", "David Robert", ""], ["Kawabata", "Kazunari", ""], ["Thompson", "Simon", ""], ["Sakai", "Naoki", ""]]}, {"id": "2104.11470", "submitter": "Zeyu Qin", "authors": "Zeyu Qin, Yanbo Fan, Hongyuan Zha, Baoyuan Wu", "title": "Theoretical Study of Random Noise Defense against Query-Based Black-Box\n  Attacks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The query-based black-box attacks, which don't require any knowledge about\nthe attacked models and datasets, have raised serious threats to machine\nlearning models in many real applications. In this work, we study a simple but\npromising defense technique, dubbed Random Noise Defense (RND) against\nquery-based black-box attacks, which adds proper Gaussian noise to each query.\nIt is lightweight and can be directly combined with any off-the-shelf models\nand other defense strategies. However, the theoretical guarantee of random\nnoise defense is missing, and the actual effectiveness of this defense is not\nyet fully understood. In this work, we present solid theoretical analyses to\ndemonstrate that the defense effect of RND against the query-based black-box\nattack and the corresponding adaptive attack heavily depends on the magnitude\nratio between the random noise added by the defender (i.e., RND) and the random\nnoise added by the attacker for gradient estimation. Extensive experiments on\nCIFAR-10 and ImageNet verify our theoretical studies. Based on RND, we also\npropose a stronger defense method that combines RND with Gaussian augmentation\ntraining (RND-GT) and achieves better defense performance.\n", "versions": [{"version": "v1", "created": "Fri, 23 Apr 2021 08:39:41 GMT"}], "update_date": "2021-04-26", "authors_parsed": [["Qin", "Zeyu", ""], ["Fan", "Yanbo", ""], ["Zha", "Hongyuan", ""], ["Wu", "Baoyuan", ""]]}, {"id": "2104.11475", "submitter": "Julia Gastinger", "authors": "Julia Gastinger, S\\'ebastien Nicolas, Du\\v{s}ica Stepi\\'c, Mischa\n  Schmidt, Anett Sch\\\"ulke", "title": "A study on Ensemble Learning for Time Series Forecasting and the need\n  for Meta-Learning", "comments": "Accepted at IJCNN 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The contribution of this work is twofold: (1) We introduce a collection of\nensemble methods for time series forecasting to combine predictions from base\nmodels. We demonstrate insights on the power of ensemble learning for\nforecasting, showing experiment results on about 16000 openly available\ndatasets, from M4, M5, M3 competitions, as well as FRED (Federal Reserve\nEconomic Data) datasets. Whereas experiments show that ensembles provide a\nbenefit on forecasting results, there is no clear winning ensemble strategy\n(plus hyperparameter configuration). Thus, in addition, (2), we propose a\nmeta-learning step to choose, for each dataset, the most appropriate ensemble\nmethod and their hyperparameter configuration to run based on dataset\nmeta-features.\n", "versions": [{"version": "v1", "created": "Fri, 23 Apr 2021 08:44:51 GMT"}], "update_date": "2021-04-26", "authors_parsed": [["Gastinger", "Julia", ""], ["Nicolas", "S\u00e9bastien", ""], ["Stepi\u0107", "Du\u0161ica", ""], ["Schmidt", "Mischa", ""], ["Sch\u00fclke", "Anett", ""]]}, {"id": "2104.11478", "submitter": "Cristian Vicas", "authors": "Cristian Vicas", "title": "Inductive biases and Self Supervised Learning in modelling a physical\n  heating system", "comments": "For the code and a small data sample see:\n  https://github.com/cristi-zz/auto_iccp2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Model Predictive Controllers (MPC) require a good model for the controlled\nprocess. In this paper I infer inductive biases about a physical system. I use\nthese biases to derive a new neural network architecture that can model this\nreal system that has noise and inertia. The main inductive biases exploited\nhere are: the delayed impact of some inputs on the system and the separability\nbetween the temporal component and how the inputs interact to produce the\noutput of a system. The inputs are independently delayed using shifted\nconvolutional kernels. Feature interactions are modelled using a fully\nconnected network that does not have access to temporal information. The\navailable data and the problem setup allow the usage of Self Supervised\nLearning in order to train the models. The baseline architecture is an\nAttention based Reccurent network adapted to work with MPC like inputs. The\nproposed networks are faster, better at exploiting larger data volumes and are\nalmost as good as baseline networks in terms of prediction performance. The\nproposed architecture family called Delay can be used in a real scenario to\ncontrol systems with delayed responses with respect to its controls or inputs.\nAblation studies show that the presence of delay kernels are vital to obtain\nany learning in proposed architecture. Code and some experimental data are\navailable online.\n", "versions": [{"version": "v1", "created": "Fri, 23 Apr 2021 08:50:41 GMT"}], "update_date": "2021-04-26", "authors_parsed": [["Vicas", "Cristian", ""]]}, {"id": "2104.11487", "submitter": "Davide Abati", "authors": "Amirhossein Habibian, Davide Abati, Taco S. Cohen, Babak Ehteshami\n  Bejnordi", "title": "Skip-Convolutions for Efficient Video Processing", "comments": "CVPR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose Skip-Convolutions to leverage the large amount of redundancies in\nvideo streams and save computations. Each video is represented as a series of\nchanges across frames and network activations, denoted as residuals. We\nreformulate standard convolution to be efficiently computed on residual frames:\neach layer is coupled with a binary gate deciding whether a residual is\nimportant to the model prediction,~\\eg foreground regions, or it can be safely\nskipped, e.g. background regions. These gates can either be implemented as an\nefficient network trained jointly with convolution kernels, or can simply skip\nthe residuals based on their magnitude. Gating functions can also incorporate\nblock-wise sparsity structures, as required for efficient implementation on\nhardware platforms. By replacing all convolutions with Skip-Convolutions in two\nstate-of-the-art architectures, namely EfficientDet and HRNet, we reduce their\ncomputational cost consistently by a factor of 3~4x for two different tasks,\nwithout any accuracy drop. Extensive comparisons with existing model\ncompression, as well as image and video efficiency methods demonstrate that\nSkip-Convolutions set a new state-of-the-art by effectively exploiting the\ntemporal redundancies in videos.\n", "versions": [{"version": "v1", "created": "Fri, 23 Apr 2021 09:10:39 GMT"}], "update_date": "2021-04-26", "authors_parsed": [["Habibian", "Amirhossein", ""], ["Abati", "Davide", ""], ["Cohen", "Taco S.", ""], ["Bejnordi", "Babak Ehteshami", ""]]}, {"id": "2104.11507", "submitter": "Xuequan Lu", "authors": "Sheldon Fung, Xuequan Lu, Chao Zhang, Chang-Tsun Li", "title": "DeepfakeUCL: Deepfake Detection via Unsupervised Contrastive Learning", "comments": "accepted to IJCNN2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Face deepfake detection has seen impressive results recently. Nearly all\nexisting deep learning techniques for face deepfake detection are fully\nsupervised and require labels during training. In this paper, we design a novel\ndeepfake detection method via unsupervised contrastive learning. We first\ngenerate two different transformed versions of an image and feed them into two\nsequential sub-networks, i.e., an encoder and a projection head. The\nunsupervised training is achieved by maximizing the correspondence degree of\nthe outputs of the projection head. To evaluate the detection performance of\nour unsupervised method, we further use the unsupervised features to train an\nefficient linear classification network. Extensive experiments show that our\nunsupervised learning method enables comparable detection performance to\nstate-of-the-art supervised techniques, in both the intra- and inter-dataset\nsettings. We also conduct ablation studies for our method.\n", "versions": [{"version": "v1", "created": "Fri, 23 Apr 2021 09:48:10 GMT"}], "update_date": "2021-04-26", "authors_parsed": [["Fung", "Sheldon", ""], ["Lu", "Xuequan", ""], ["Zhang", "Chao", ""], ["Li", "Chang-Tsun", ""]]}, {"id": "2104.11510", "submitter": "Guangcan Liu", "authors": "Guangcan Liu", "title": "Time Series Forecasting via Learning Convolutionally Low-Rank Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently,~\\citet{liu:arxiv:2019} studied the rather challenging problem of\ntime series forecasting from the perspective of compressed sensing. They\nproposed a no-learning method, named Convolution Nuclear Norm Minimization\n(CNNM), and proved that CNNM can exactly recover the future part of a series\nfrom its observed part, provided that the series is convolutionally low-rank.\nWhile impressive, the convolutional low-rankness condition may not be satisfied\nwhenever the series is far from being seasonal, and is in fact brittle to the\npresence of trends and dynamics. This paper tries to approach the issues by\nintegrating a learnable, orthonormal transformation into CNNM, with the purpose\nfor converting the series of involute structures into regular signals of\nconvolutionally low-rank. We prove that the resulted model, termed\nLearning-Based CNNM (LbCNNM), strictly succeeds in identifying the future part\nof a series, as long as the transform of the series is convolutionally\nlow-rank. To learn proper transformations that may meet the required success\nconditions, we devise an interpretable method based on Principal Component\nPurist (PCP). Equipped with this learning method and some elaborate data\nargumentation skills, LbCNNM not only can handle well the major components of\ntime series (including trends, seasonality and dynamics), but also can make use\nof the forecasts provided by some other forecasting methods; this means LbCNNM\ncan be used as a general tool for model combination. Extensive experiments on\n100,452 real-world time series from TSDL and M4 demonstrate the superior\nperformance of LbCNNM.\n", "versions": [{"version": "v1", "created": "Fri, 23 Apr 2021 09:53:28 GMT"}], "update_date": "2021-04-26", "authors_parsed": [["Liu", "Guangcan", ""]]}, {"id": "2104.11522", "submitter": "Kevin Alexander Laube", "authors": "Kevin Alexander Laube, Andreas Zell", "title": "Inter-choice dependent super-network weights", "comments": "7 pages, 5 figures, 2 tables, further figures and tables in the\n  appendix, code provided", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The automatic design of architectures for neural networks, Neural\nArchitecture Search, has gained a lot of attention over the recent years, as\nthe thereby created networks repeatedly broke state-of-the-art results for\nseveral disciplines. The network search spaces are often finite and designed by\nhand, in a way that a fixed and small number of decisions constitute a specific\narchitecture. Given these circumstances, inter-choice dependencies are likely\nto exist and affect the network search, but are unaccounted for in the popular\none-shot methods. We extend the Single-Path One-Shot search-networks with\nadditional weights that depend on combinations of choices and analyze their\neffect. Experiments in NAS-Bench 201 and SubImageNet based search spaces show\nan improved super-network performance in only-convolutions settings and that\nthe overhead is nearly negligible for sequential network designs.\n", "versions": [{"version": "v1", "created": "Fri, 23 Apr 2021 10:16:24 GMT"}], "update_date": "2021-04-26", "authors_parsed": [["Laube", "Kevin Alexander", ""], ["Zell", "Andreas", ""]]}, {"id": "2104.11530", "submitter": "Junaid Ahmed Ghauri", "authors": "Junaid Ahmed Ghauri, Sherzod Hakimov, Ralph Ewerth", "title": "Supervised Video Summarization via Multiple Feature Sets with Parallel\n  Attention", "comments": "Accepted in IEEE International Conference on Multimedia and Expo\n  (ICME) 2021 (They have copyright to publish camera ready version of this\n  work)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.IR cs.LG cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The assignment of importance scores to particular frames or (short) segments\nin a video is crucial for summarization, but also a difficult task. Previous\nwork utilizes only one source of visual features. In this paper, we suggest a\nnovel model architecture that combines three feature sets for visual content\nand motion to predict importance scores. The proposed architecture utilizes an\nattention mechanism before fusing motion features and features representing the\n(static) visual content, i.e., derived from an image classification model.\nComprehensive experimental evaluations are reported for two well-known\ndatasets, SumMe and TVSum. In this context, we identify methodological issues\non how previous work used these benchmark datasets, and present a fair\nevaluation scheme with appropriate data splits that can be used in future work.\nWhen using static and motion features with parallel attention mechanism, we\nimprove state-of-the-art results for SumMe, while being on par with the state\nof the art for the other dataset.\n", "versions": [{"version": "v1", "created": "Fri, 23 Apr 2021 10:46:35 GMT"}, {"version": "v2", "created": "Thu, 13 May 2021 16:07:41 GMT"}], "update_date": "2021-05-14", "authors_parsed": [["Ghauri", "Junaid Ahmed", ""], ["Hakimov", "Sherzod", ""], ["Ewerth", "Ralph", ""]]}, {"id": "2104.11557", "submitter": "Anastasiia Sedova", "authors": "Anastasiia Sedova, Andreas Stephan, Marina Speranskaya, Benjamin Roth", "title": "Knodle: Modular Weakly Supervised Learning with PyTorch", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Strategies for improving the training and prediction quality of weakly\nsupervised machine learning models vary in how much they are tailored to a\nspecific task or integrated with a specific model architecture. In this work,\nwe introduce Knodle, a software framework that treats weak data annotations,\ndeep learning models, and methods for improving weakly supervised training as\nseparate, modular components. This modularization gives the training process\naccess to fine-grained information such as data set characteristics, matches of\nheuristic rules, or elements of the deep learning model ultimately used for\nprediction. Hence, our framework can encompass a wide range of training methods\nfor improving weak supervision, ranging from methods that only look at\ncorrelations of rules and output classes (independently of the machine learning\nmodel trained with the resulting labels), to those that harness the interplay\nof neural networks and weakly labeled data. We illustrate the benchmarking\npotential of the framework with a performance comparison of several reference\nimplementations on a selection of datasets that are already available in\nKnodle.\n  The framework is published as an open-source Python package knodle and\navailable at https://github.com/knodle/knodle.\n", "versions": [{"version": "v1", "created": "Fri, 23 Apr 2021 12:33:25 GMT"}, {"version": "v2", "created": "Mon, 10 May 2021 21:06:30 GMT"}, {"version": "v3", "created": "Sun, 4 Jul 2021 13:31:33 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Sedova", "Anastasiia", ""], ["Stephan", "Andreas", ""], ["Speranskaya", "Marina", ""], ["Roth", "Benjamin", ""]]}, {"id": "2104.11568", "submitter": "Lorin Sweeney", "authors": "Lorin Sweeney, Graham Healy, Alan F. Smeaton", "title": "The Influence of Audio on Video Memorability with an Audio Gestalt\n  Regulated Video Memorability System", "comments": "6 pages, 3 figures, 4 tables, paper accepted in CBMI 2021 for\n  publication and oral presentation", "journal-ref": null, "doi": "10.1109/CBMI50038.2021.9461903", "report-no": null, "categories": "cs.MM cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Memories are the tethering threads that tie us to the world, and memorability\nis the measure of their tensile strength. The threads of memory are spun from\nfibres of many modalities, obscuring the contribution of a single fibre to a\nthread's overall tensile strength. Unfurling these fibres is the key to\nunderstanding the nature of their interaction, and how we can ultimately create\nmore meaningful media content. In this paper, we examine the influence of audio\non video recognition memorability, finding evidence to suggest that it can\nfacilitate overall video recognition memorability rich in high-level (gestalt)\naudio features. We introduce a novel multimodal deep learning-based late-fusion\nsystem that uses audio gestalt to estimate the influence of a given video's\naudio on its overall short-term recognition memorability, and selectively\nleverages audio features to make a prediction accordingly. We benchmark our\naudio gestalt based system on the Memento10k short-term video memorability\ndataset, achieving top-2 state-of-the-art results.\n", "versions": [{"version": "v1", "created": "Fri, 23 Apr 2021 12:53:33 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Sweeney", "Lorin", ""], ["Healy", "Graham", ""], ["Smeaton", "Alan F.", ""]]}, {"id": "2104.11574", "submitter": "Maged Abdalla Helmy Abdou", "authors": "Maged Helmy, Anastasiya Dykyy, Tuyen Trung Truong, Paulo Ferreira,\n  Eric Jul", "title": "CapillaryNet: An Automated System to Analyze Microcirculation Videos\n  from Handheld Vital Microscopy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Capillaries are the smallest vessels in the body responsible for the delivery\nof oxygen and nutrients to the surrounding cells. Various diseases have been\nshown to alter the density of nutritive capillaries and the flow velocity of\nerythrocytes. In previous studies, capillary density and flow velocity have\nbeen assessed manually by trained specialists. Manual analysis of a 20-second\nlong microvascular video takes on average 20 minutes and requires extensive\ntraining. Several studies have reported that manual analysis hinders the\napplication of microvascular microscopy in a clinical setting. In this paper,\nwe present a fully automated system, called CapillaryNet, that can automate\nmicrovascular microscopy analysis so it can be used as a clinical application.\nMoreover, CapillaryNet measures several microvascular parameters that\nresearchers were previously unable to quantify, i.e. capillary hematocrit and\nintra-capillary flow velocity heterogeneity.\n", "versions": [{"version": "v1", "created": "Fri, 23 Apr 2021 13:14:47 GMT"}, {"version": "v2", "created": "Fri, 21 May 2021 15:08:25 GMT"}], "update_date": "2021-05-24", "authors_parsed": [["Helmy", "Maged", ""], ["Dykyy", "Anastasiya", ""], ["Truong", "Tuyen Trung", ""], ["Ferreira", "Paulo", ""], ["Jul", "Eric", ""]]}, {"id": "2104.11578", "submitter": "Aaron Buhendwa", "authors": "Aaron B. Buhendwa, Deniz A. Bezgin, Nikolaus Adams", "title": "Consistent and symmetry preserving data-driven interface reconstruction\n  for the level-set method", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.flu-dyn cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Recently, machine learning has been used to substitute parts of conventional\ncomputational fluid dynamics, e.g. the cell-face reconstruction in\nfinite-volume solvers or the curvature computation in the Volume-of-Fluid (VOF)\nmethod. The latter showed improvements in terms of accuracy for coarsely\nresolved interfaces, however at the expense of convergence and symmetry. In\nthis work, a combined approach is proposed, adressing the aforementioned\nshortcomings. We focus on interface reconstruction (IR) in the level-set\nmethod, i.e. the computation of the volume fraction and apertures. The combined\nmodel consists of a classification neural network, that chooses between the\nconventional (linear) IR and the neural network IR depending on the local\ninterface resolution. The proposed approach improves accuracy for coarsely\nresolved interfaces and recovers the conventional IR for high resolutions,\nyielding first order overall convergence. Symmetry is preserved by mirroring\nand rotating the input level-set grid and subsequently averaging the\npredictions. The combined model is implemented into a CFD solver and\ndemonstrated for two-phase flows. Furthermore, we provide details of floating\npoint symmetric implementation and computational efficiency.\n", "versions": [{"version": "v1", "created": "Fri, 23 Apr 2021 13:21:10 GMT"}], "update_date": "2021-04-26", "authors_parsed": [["Buhendwa", "Aaron B.", ""], ["Bezgin", "Deniz A.", ""], ["Adams", "Nikolaus", ""]]}, {"id": "2104.11589", "submitter": "Sang Hun Lee", "authors": "Sangrok Lee, Taekang Woo, Sang Hun Lee", "title": "SBNet: Segmentation-based Network for Natural Language-based Vehicle\n  Search", "comments": "7 pages, 4 figures, CVPR Workshop Paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Natural language-based vehicle retrieval is a task to find a target vehicle\nwithin a given image based on a natural language description as a query. This\ntechnology can be applied to various areas including police searching for a\nsuspect vehicle. However, it is challenging due to the ambiguity of language\ndescriptions and the difficulty of processing multi-modal data. To tackle this\nproblem, we propose a deep neural network called SBNet that performs natural\nlanguage-based segmentation for vehicle retrieval. We also propose two\ntask-specific modules to improve performance: a substitution module that helps\nfeatures from different domains to be embedded in the same space and a future\nprediction module that learns temporal information. SBnet has been trained\nusing the CityFlow-NL dataset that contains 2,498 tracks of vehicles with three\nunique natural language descriptions each and tested 530 unique vehicle tracks\nand their corresponding query sets. SBNet achieved a significant improvement\nover the baseline in the natural language-based vehicle tracking track in the\nAI City Challenge 2021.\n", "versions": [{"version": "v1", "created": "Thu, 22 Apr 2021 08:06:17 GMT"}], "update_date": "2021-04-26", "authors_parsed": [["Lee", "Sangrok", ""], ["Woo", "Taekang", ""], ["Lee", "Sang Hun", ""]]}, {"id": "2104.11593", "submitter": "Hariharan Manikandan", "authors": "Anshul Tanwar, Hariharan Manikandan, Krishna Sundaresan, Prasanna\n  Ganesan, Sathish Kumar Chandrasekaran, Sriram Ravi", "title": "Assessing Validity of Static Analysis Warnings using Ensemble Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Static Analysis (SA) tools are used to identify potential weaknesses in code\nand fix them in advance, while the code is being developed. In legacy codebases\nwith high complexity, these rules-based static analysis tools generally report\na lot of false warnings along with the actual ones. Though the SA tools uncover\nmany hidden bugs, they are lost in the volume of fake warnings reported. The\ndevelopers expend large hours of time and effort in identifying the true\nwarnings. Other than impacting the developer productivity, true bugs are also\nmissed out due to this challenge. To address this problem, we propose a Machine\nLearning (ML)-based learning process that uses source codes, historic commit\ndata, and classifier-ensembles to prioritize the True warnings from the given\nlist of warnings. This tool is integrated into the development workflow to\nfilter out the false warnings and prioritize actual bugs. We evaluated our\napproach on the networking C codes, from a large data pool of static analysis\nwarnings reported by the tools. Time-to-time these warnings are addressed by\nthe developers, labelling them as authentic bugs or fake alerts. The ML model\nis trained with full supervision over the code features. Our results confirm\nthat applying deep learning over the traditional static analysis reports is an\nassuring approach for drastically reducing the false positive rates.\n", "versions": [{"version": "v1", "created": "Wed, 21 Apr 2021 19:39:20 GMT"}], "update_date": "2021-04-26", "authors_parsed": [["Tanwar", "Anshul", ""], ["Manikandan", "Hariharan", ""], ["Sundaresan", "Krishna", ""], ["Ganesan", "Prasanna", ""], ["Chandrasekaran", "Sathish Kumar", ""], ["Ravi", "Sriram", ""]]}, {"id": "2104.11610", "submitter": "Alan Blair", "authors": "Xuefeng Li and Alan Blair", "title": "Eccentric Regularization: Minimizing Hyperspherical Energy without\n  explicit projection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Several regularization methods have recently been introduced which force the\nlatent activations of an autoencoder or deep neural network to conform to\neither a Gaussian or hyperspherical distribution, or to minimize the implicit\nrank of the distribution in latent space. In the present work, we introduce a\nnovel regularizing loss function which simulates a pairwise repulsive force\nbetween items and an attractive force of each item toward the origin. We show\nthat minimizing this loss function in isolation achieves a hyperspherical\ndistribution. Moreover, when used as a regularizing term, the scaling factor\ncan be adjusted to allow greater flexibility and tolerance of eccentricity,\nthus allowing the latent variables to be stratified according to their relative\nimportance, while still promoting diversity. We apply this method of Eccentric\nRegularization to an autoencoder, and demonstrate its effectiveness in image\ngeneration, representation learning and downstream classification tasks.\n", "versions": [{"version": "v1", "created": "Fri, 23 Apr 2021 13:55:17 GMT"}], "update_date": "2021-04-26", "authors_parsed": [["Li", "Xuefeng", ""], ["Blair", "Alan", ""]]}, {"id": "2104.11619", "submitter": "Jose Luis Gomez", "authors": "Jose L. G\\'omez, Gabriel Villalonga, Antonio M. L\\'opez", "title": "Co-training for Deep Object Detection: Comparing Single-modal and\n  Multi-modal Approaches", "comments": null, "journal-ref": "special issue of Sensors (ISSN 1424-8220) \"Feature Papers in\n  Physical Sensors Section 2020\"", "doi": "10.3390/s21093185", "report-no": "sensors-1185064", "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Top-performing computer vision models are powered by convolutional neural\nnetworks (CNNs). Training an accurate CNN highly depends on both the raw sensor\ndata and their associated ground truth (GT). Collecting such GT is usually done\nthrough human labeling, which is time-consuming and does not scale as we wish.\nThis data labeling bottleneck may be intensified due to domain shifts among\nimage sensors, which could force per-sensor data labeling. In this paper, we\nfocus on the use of co-training, a semi-supervised learning (SSL) method, for\nobtaining self-labeled object bounding boxes (BBs), i.e., the GT to train deep\nobject detectors. In particular, we assess the goodness of multi-modal\nco-training by relying on two different views of an image, namely, appearance\n(RGB) and estimated depth (D). Moreover, we compare appearance-based\nsingle-modal co-training with multi-modal. Our results suggest that in a\nstandard SSL setting (no domain shift, a few human-labeled data) and under\nvirtual-to-real domain shift (many virtual-world labeled data, no human-labeled\ndata) multi-modal co-training outperforms single-modal. In the latter case, by\nperforming GAN-based domain translation both co-training modalities are on\npair; at least, when using an off-the-shelf depth estimation model not\nspecifically trained on the translated images.\n", "versions": [{"version": "v1", "created": "Fri, 23 Apr 2021 14:13:59 GMT"}], "update_date": "2021-05-05", "authors_parsed": [["G\u00f3mez", "Jose L.", ""], ["Villalonga", "Gabriel", ""], ["L\u00f3pez", "Antonio M.", ""]]}, {"id": "2104.11620", "submitter": "Nibaran Das", "authors": "Bodhisatwa Mandal, Swarnendu Ghosh, Teresa Gon\\c{c}alves, Paulo\n  Quaresma, Mita Nasipuri, Nibaran Das", "title": "GuideBP: Guiding Backpropagation Through Weaker Pathways of Parallel\n  Logits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional neural networks often generate multiple logits and use simple\ntechniques like addition or averaging for loss computation. But this allows\ngradients to be distributed equally among all paths. The proposed approach\nguides the gradients of backpropagation along weakest concept representations.\nA weakness scores defines the class specific performance of individual pathways\nwhich is then used to create a logit that would guide gradients along the\nweakest pathways. The proposed approach has been shown to perform better than\ntraditional column merging techniques and can be used in several application\nscenarios. Not only can the proposed model be used as an efficient technique\nfor training multiple instances of a model parallely, but also CNNs with\nmultiple output branches have been shown to perform better with the proposed\nupgrade. Various experiments establish the flexibility of the learning\ntechnique which is simple yet effective in various multi-objective scenarios\nboth empirically and statistically.\n", "versions": [{"version": "v1", "created": "Fri, 23 Apr 2021 14:14:00 GMT"}], "update_date": "2021-04-26", "authors_parsed": [["Mandal", "Bodhisatwa", ""], ["Ghosh", "Swarnendu", ""], ["Gon\u00e7alves", "Teresa", ""], ["Quaresma", "Paulo", ""], ["Nasipuri", "Mita", ""], ["Das", "Nibaran", ""]]}, {"id": "2104.11629", "submitter": "Shahin Amiriparian", "authors": "Shahin Amiriparian (1), Tobias H\\\"ubner (1), Maurice Gerczuk (1),\n  Sandra Ottl (1), Bj\\\"orn W. Schuller (1,2) ((1) EIHW -- Chair of Embedded\n  Intelligence for Health Care and Wellbeing, University of Augsburg, Germany,\n  (2) GLAM -- Group on Language, Audio, and Music, Imperial College London, UK)", "title": "DeepSpectrumLite: A Power-Efficient Transfer Learning Framework for\n  Embedded Speech and Audio Processing from Decentralised Data", "comments": "5 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Deep neural speech and audio processing systems have a large number of\ntrainable parameters, a relatively complex architecture, and require a vast\namount of training data and computational power. These constraints make it more\nchallenging to integrate such systems into embedded devices and utilise them\nfor real-time, real-world applications. We tackle these limitations by\nintroducing DeepSpectrumLite, an open-source, lightweight transfer learning\nframework for on-device speech and audio recognition using pre-trained image\nconvolutional neural networks (CNNs). The framework creates and augments\nMel-spectrogram plots on-the-fly from raw audio signals which are then used to\nfinetune specific pre-trained CNNs for the target classification task.\nSubsequently, the whole pipeline can be run in real-time with a mean inference\nlag of 242.0 ms when a DenseNet121 model is used on a consumer-grade Motorola\nmoto e7 plus smartphone. DeepSpectrumLite operates decentralised, eliminating\nthe need for data upload for further processing. By obtaining state-of-the-art\nresults on a set of paralinguistics tasks, we demonstrate the suitability of\nthe proposed transfer learning approach for embedded audio signal processing,\neven when data is scarce. We provide an extensive command-line interface for\nusers and developers which is comprehensively documented and publicly available\nat https://github.com/DeepSpectrum/DeepSpectrumLite.\n", "versions": [{"version": "v1", "created": "Fri, 23 Apr 2021 14:32:33 GMT"}], "update_date": "2021-04-26", "authors_parsed": [["Amiriparian", "Shahin", ""], ["H\u00fcbner", "Tobias", ""], ["Gerczuk", "Maurice", ""], ["Ottl", "Sandra", ""], ["Schuller", "Bj\u00f6rn W.", ""]]}, {"id": "2104.11637", "submitter": "Zahra Gharaee", "authors": "Zahra Gharaee", "title": "Online recognition of unsegmented actions with hierarchical SOM\n  architecture", "comments": null, "journal-ref": "Cogn Process 22, 77-91 (2021)", "doi": "10.1007/s10339-020-00986-4", "report-no": null, "categories": "cs.CV cs.AI cs.HC cs.LG cs.RO", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Automatic recognition of an online series of unsegmented actions requires a\nmethod for segmentation that determines when an action starts and when it ends.\nIn this paper, a novel approach for recognizing unsegmented actions in online\ntest experiments is proposed. The method uses self-organizing neural networks\nto build a three-layer cognitive architecture. The unique features of an action\nsequence are represented as a series of elicited key activations by the\nfirst-layer self-organizing map. An average length of a key activation vector\nis calculated for all action sequences in a training set and adjusted in\nlearning trials to generate input patterns to the second-layer self-organizing\nmap. The pattern vectors are clustered in the second layer, and the clusters\nare then labeled by an action identity in the third layer neural network. The\nexperiment results show that although the performance drops slightly in online\nexperiments compared to the offline tests, the ability of the proposed\narchitecture to deal with the unsegmented action sequences as well as the\nonline performance makes the system more plausible and practical in real-case\nscenarios.\n", "versions": [{"version": "v1", "created": "Fri, 23 Apr 2021 14:41:46 GMT"}], "update_date": "2021-04-26", "authors_parsed": [["Gharaee", "Zahra", ""]]}, {"id": "2104.11642", "submitter": "Deniz  Kavi", "authors": "Deniz Kavi", "title": "Turkish Text Classification: From Lexicon Analysis to Bidirectional\n  Transformer", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Text classification has seen an increased use in both academic and industry\nsettings. Though rule based methods have been fairly successful, supervised\nmachine learning has been shown to be most successful for most languages, where\nmost research was done on English. In this article, the success of lexicon\nanalysis, support vector machines, and extreme gradient boosting for the task\nof text classification and sentiment analysis are evaluated in Turkish and a\npretrained transformer based classifier is proposed, outperforming previous\nmethods for Turkish text classification. In the context of text classification,\nall machine learning models proposed in the article are domain-independent and\ndo not require any task-specific modifications.\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2020 13:30:44 GMT"}], "update_date": "2021-04-26", "authors_parsed": [["Kavi", "Deniz", ""]]}, {"id": "2104.11645", "submitter": "Di Wu", "authors": "Di Wu, Xiaofeng Xie, Xiang Ni, Bin Fu, Hanhui Deng, Haibo Zeng, and\n  Zhijin Qin", "title": "Software-Defined Edge Computing: A New Architecture Paradigm to Support\n  IoT Data Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The rapid deployment of Internet of Things (IoT) applications leads to\nmassive data that need to be processed. These IoT applications have specific\ncommunication requirements on latency and bandwidth, and present new features\non their generated data such as time-dependency. Therefore, it is desirable to\nreshape the current IoT architectures by exploring their inherent nature of\ncommunication and computing to support smart IoT data process and analysis. We\nintroduce in this paper features of IoT data, trends of IoT network\narchitectures, some problems in IoT data analysis, and their solutions.\nSpecifically, we view that software-defined edge computing is a promising\narchitecture to support the unique needs of IoT data analysis. We further\npresent an experiment on data anomaly detection in this architecture, and the\ncomparison between two architectures for ECG diagnosis. Results show that our\nmethod is effective and feasible.\n", "versions": [{"version": "v1", "created": "Thu, 22 Apr 2021 11:19:20 GMT"}, {"version": "v2", "created": "Mon, 26 Apr 2021 02:39:57 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Wu", "Di", ""], ["Xie", "Xiaofeng", ""], ["Ni", "Xiang", ""], ["Fu", "Bin", ""], ["Deng", "Hanhui", ""], ["Zeng", "Haibo", ""], ["Qin", "Zhijin", ""]]}, {"id": "2104.11667", "submitter": "Samuel Kim", "authors": "Samuel Kim, Peter Y. Lu, Charlotte Loh, Jamie Smith, Jasper Snoek,\n  Marin Solja\\v{c}i\\'c", "title": "Scalable and Flexible Deep Bayesian Optimization with Auxiliary\n  Information for Scientific Problems", "comments": "18 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG physics.app-ph physics.chem-ph physics.optics", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Bayesian optimization (BO) is a popular paradigm for global optimization of\nexpensive black-box functions, but there are many domains where the function is\nnot completely black-box. The data may have some known structure, e.g.\nsymmetries, and the data generation process can yield useful intermediate or\nauxiliary information in addition to the value of the optimization objective.\nHowever, surrogate models traditionally employed in BO, such as Gaussian\nProcesses (GPs), scale poorly with dataset size and struggle to incorporate\nknown structure or auxiliary information. Instead, we propose performing BO on\ncomplex, structured problems by using Bayesian Neural Networks (BNNs), a class\nof scalable surrogate models that have the representation power and flexibility\nto handle structured data and exploit auxiliary information. We demonstrate BO\non a number of realistic problems in physics and chemistry, including topology\noptimization of photonic crystal materials using convolutional neural networks,\nand chemical property optimization of molecules using graph neural networks. On\nthese complex tasks, we show that BNNs often outperform GPs as surrogate models\nfor BO in terms of both sampling efficiency and computational cost.\n", "versions": [{"version": "v1", "created": "Fri, 23 Apr 2021 15:46:37 GMT"}], "update_date": "2021-04-28", "authors_parsed": [["Kim", "Samuel", ""], ["Lu", "Peter Y.", ""], ["Loh", "Charlotte", ""], ["Smith", "Jamie", ""], ["Snoek", "Jasper", ""], ["Solja\u010di\u0107", "Marin", ""]]}, {"id": "2104.11673", "submitter": "Gabriel Mittag", "authors": "Gabriel Mittag, Sebastian M\\\"oller", "title": "Deep Learning Based Assessment of Synthetic Speech Naturalness", "comments": "Late upload, presented at Interspeech 2020", "journal-ref": null, "doi": "10.21437/Interspeech.2020-2382", "report-no": null, "categories": "cs.SD cs.AI cs.CL cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a new objective prediction model for synthetic\nspeech naturalness. It can be used to evaluate Text-To-Speech or Voice\nConversion systems and works language independently. The model is trained\nend-to-end and based on a CNN-LSTM network that previously showed to give good\nresults for speech quality estimation. We trained and tested the model on 16\ndifferent datasets, such as from the Blizzard Challenge and the Voice\nConversion Challenge. Further, we show that the reliability of deep\nlearning-based naturalness prediction can be improved by transfer learning from\nspeech quality prediction models that are trained on objective POLQA scores.\nThe proposed model is made publicly available and can, for example, be used to\nevaluate different TTS system configurations.\n", "versions": [{"version": "v1", "created": "Fri, 23 Apr 2021 16:05:20 GMT"}], "update_date": "2021-04-26", "authors_parsed": [["Mittag", "Gabriel", ""], ["M\u00f6ller", "Sebastian", ""]]}, {"id": "2104.11674", "submitter": "Tianyue Cheng", "authors": "Tianyue Cheng, Tianchi Fan, Landi Wang", "title": "Genetic Constrained Graph Variational Autoencoder for COVID-19 Drug\n  Discovery", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-bio.QM", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  In the past several months, COVID-19 has spread over the globe and caused\nsevere damage to the people and the society. In the context of this severe\nsituation, an effective drug discovery method to generate potential drugs is\nextremely meaningful. In this paper, we provide a methodology of discovering\npotential drugs for the treatment of Severe Acute Respiratory Syndrome\nCorona-Virus 2 (commonly known as SARS-CoV-2). We proposed a new model called\nGenetic Constrained Graph Variational Autoencoder (GCGVAE) to solve this\nproblem. We trained our model based on the data of various viruses' protein\nstructure, including that of the SARS, HIV, Hep3, and MERS, and used it to\ngenerate possible drugs for SARS-CoV-2. Several optimization algorithms,\nincluding valency masking and genetic algorithm, are deployed to fine tune our\nmodel. According to the simulation, our generated molecules have great\neffectiveness in inhibiting SARS-CoV-2. We quantitatively calculated the scores\nof our generated molecules and compared it with the scores of existing drugs,\nand the result shows our generated molecules scores much better than those\nexisting drugs. Moreover, our model can be also applied to generate effective\ndrugs for treating other viruses given their protein structure, which could be\nused to generate drugs for future viruses.\n", "versions": [{"version": "v1", "created": "Fri, 23 Apr 2021 16:10:15 GMT"}], "update_date": "2021-04-26", "authors_parsed": [["Cheng", "Tianyue", ""], ["Fan", "Tianchi", ""], ["Wang", "Landi", ""]]}, {"id": "2104.11677", "submitter": "Arsalan Tahir", "authors": "Arsalan Tahir, Muhammad Adil and Arslan Ali", "title": "Rapid Detection of Aircrafts in Satellite Imagery based on Deep Neural\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Object detection is one of the fundamental objectives in Applied Computer\nVision. In some of the applications, object detection becomes very challenging\nsuch as in the case of satellite image processing. Satellite image processing\nhas remained the focus of researchers in domains of Precision Agriculture,\nClimate Change, Disaster Management, etc. Therefore, object detection in\nsatellite imagery is one of the most researched problems in this domain. This\npaper focuses on aircraft detection. in satellite imagery using deep learning\ntechniques. In this paper, we used YOLO deep learning framework for aircraft\ndetection. This method uses satellite images collected by different sources as\nlearning for the model to perform detection. Object detection in satellite\nimages is mostly complex because objects have many variations, types, poses,\nsizes, complex and dense background. YOLO has some limitations for small size\nobjects (less than$\\sim$32 pixels per object), therefore we upsample the\nprediction grid to reduce the coarseness of the model and to accurately detect\nthe densely clustered objects. The improved model shows good accuracy and\nperformance on different unknown images having small, rotating, and dense\nobjects to meet the requirements in real-time.\n", "versions": [{"version": "v1", "created": "Wed, 21 Apr 2021 18:13:16 GMT"}], "update_date": "2021-04-26", "authors_parsed": [["Tahir", "Arsalan", ""], ["Adil", "Muhammad", ""], ["Ali", "Arslan", ""]]}, {"id": "2104.11688", "submitter": "Quay Au", "authors": "Quay Au, Julia Herbinger, Clemens Stachl, Bernd Bischl, Giuseppe\n  Casalicchio", "title": "Grouped Feature Importance and Combined Features Effect Plot", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Interpretable machine learning has become a very active area of research due\nto the rising popularity of machine learning algorithms and their inherently\nchallenging interpretability. Most work in this area has been focused on the\ninterpretation of single features in a model. However, for researchers and\npractitioners, it is often equally important to quantify the importance or\nvisualize the effect of feature groups. To address this research gap, we\nprovide a comprehensive overview of how existing model-agnostic techniques can\nbe defined for feature groups to assess the grouped feature importance,\nfocusing on permutation-based, refitting, and Shapley-based methods. We also\nintroduce an importance-based sequential procedure that identifies a stable and\nwell-performing combination of features in the grouped feature space.\nFurthermore, we introduce the combined features effect plot, which is a\ntechnique to visualize the effect of a group of features based on a sparse,\ninterpretable linear combination of features. We used simulation studies and a\nreal data example from computational psychology to analyze, compare, and\ndiscuss these methods.\n", "versions": [{"version": "v1", "created": "Fri, 23 Apr 2021 16:27:38 GMT"}], "update_date": "2021-04-26", "authors_parsed": [["Au", "Quay", ""], ["Herbinger", "Julia", ""], ["Stachl", "Clemens", ""], ["Bischl", "Bernd", ""], ["Casalicchio", "Giuseppe", ""]]}, {"id": "2104.11691", "submitter": "Julia Rosenzweig", "authors": "Julia Rosenzweig, Joachim Sicking, Sebastian Houben, Michael Mock,\n  Maram Akila", "title": "Patch Shortcuts: Interpretable Proxy Models Efficiently Find Black-Box\n  Vulnerabilities", "comments": "Under IEEE Copyright; accepted at the SAIAD (Safe Artificial\n  Intelligence for Automated Driving) Workshop at CVPR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An important pillar for safe machine learning (ML) is the systematic\nmitigation of weaknesses in neural networks to afford their deployment in\ncritical applications. An ubiquitous class of safety risks are learned\nshortcuts, i.e. spurious correlations a network exploits for its decisions that\nhave no semantic connection to the actual task. Networks relying on such\nshortcuts bear the risk of not generalizing well to unseen inputs.\nExplainability methods help to uncover such network vulnerabilities. However,\nmany of these techniques are not directly applicable if access to the network\nis constrained, in so-called black-box setups. These setups are prevalent when\nusing third-party ML components. To address this constraint, we present an\napproach to detect learned shortcuts using an interpretable-by-design network\nas a proxy to the black-box model of interest. Leveraging the proxy's\nguarantees on introspection we automatically extract candidates for learned\nshortcuts. Their transferability to the black box is validated in a systematic\nfashion. Concretely, as proxy model we choose a BagNet, which bases its\ndecisions purely on local image patches. We demonstrate on the autonomous\ndriving dataset A2D2 that extracted patch shortcuts significantly influence the\nblack box model. By efficiently identifying such patch-based vulnerabilities,\nwe contribute to safer ML models.\n", "versions": [{"version": "v1", "created": "Thu, 22 Apr 2021 05:44:40 GMT"}], "update_date": "2021-04-26", "authors_parsed": [["Rosenzweig", "Julia", ""], ["Sicking", "Joachim", ""], ["Houben", "Sebastian", ""], ["Mock", "Michael", ""], ["Akila", "Maram", ""]]}, {"id": "2104.11695", "submitter": "Kenneth Alperin", "authors": "Kenneth Alperin, Emily Joback, Leslie Shing, Gabe Elkin", "title": "A Framework for Unsupervised Classificiation and Data Mining of Tweets\n  about Cyber Vulnerabilities", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many cyber network defense tools rely on the National Vulnerability Database\n(NVD) to provide timely information on known vulnerabilities that exist within\nsystems on a given network. However, recent studies have indicated that the NVD\nis not always up to date, with known vulnerabilities being discussed publicly\non social media platforms, like Twitter and Reddit, months before they are\npublished to the NVD. To that end, we present a framework for unsupervised\nclassification to filter tweets for relevance to cyber security. We consider\nand evaluate two unsupervised machine learning techniques for inclusion in our\nframework, and show that zero-shot classification using a Bidirectional and\nAuto-Regressive Transformers (BART) model outperforms the other technique with\n83.52% accuracy and a F1 score of 83.88, allowing for accurate filtering of\ntweets without human intervention or labelled data for training. Additionally,\nwe discuss different insights that can be derived from these cyber-relevant\ntweets, such as trending topics of tweets and the counts of Twitter mentions\nfor Common Vulnerabilities and Exposures (CVEs), that can be used in an alert\nor report to augment current NVD-based risk assessment tools.\n", "versions": [{"version": "v1", "created": "Fri, 23 Apr 2021 16:33:38 GMT"}], "update_date": "2021-04-26", "authors_parsed": [["Alperin", "Kenneth", ""], ["Joback", "Emily", ""], ["Shing", "Leslie", ""], ["Elkin", "Gabe", ""]]}, {"id": "2104.11700", "submitter": "Saeedeh Parsaeefard", "authors": "Saeedeh Parsaeefard, Sayed Ehsan Etesami and Alberto Leon Garcia", "title": "Robust Federated Learning by Mixture of Experts", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC cs.NE cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present a novel weighted average model based on the mixture of experts\n(MoE) concept to provide robustness in Federated learning (FL) against the\npoisoned/corrupted/outdated local models. These threats along with the non-IID\nnature of data sets can considerably diminish the accuracy of the FL model. Our\nproposed MoE-FL setup relies on the trust between users and the server where\nthe users share a portion of their public data sets with the server. The server\napplies a robust aggregation method by solving the optimization problem or the\nSoftmax method to highlight the outlier cases and to reduce their adverse\neffect on the FL process. Our experiments illustrate that MoE-FL outperforms\nthe performance of the traditional aggregation approach for high rate of\npoisoned data from attackers.\n", "versions": [{"version": "v1", "created": "Fri, 23 Apr 2021 16:41:04 GMT"}], "update_date": "2021-04-26", "authors_parsed": [["Parsaeefard", "Saeedeh", ""], ["Etesami", "Sayed Ehsan", ""], ["Garcia", "Alberto Leon", ""]]}, {"id": "2104.11706", "submitter": "Max Mowbray Mr", "authors": "Max Mowbray, Panagiotis Petsagkourakis, Ehecatl Antonio del R\\'io\n  Chanona, Robin Smith, Dongda Zhang", "title": "Safe Chance Constrained Reinforcement Learning for Batch Process Control", "comments": "35 pages, 4 algorithms, 3 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Reinforcement Learning (RL) controllers have generated excitement within the\ncontrol community. The primary advantage of RL controllers relative to existing\nmethods is their ability to optimize uncertain systems independently of\nexplicit assumption of process uncertainty. Recent focus on engineering\napplications has been directed towards the development of safe RL controllers.\nPrevious works have proposed approaches to account for constraint satisfaction\nthrough constraint tightening from the domain of stochastic model predictive\ncontrol. Here, we extend these approaches to account for plant-model mismatch.\nSpecifically, we propose a data-driven approach that utilizes Gaussian\nprocesses for the offline simulation model and use the associated posterior\nuncertainty prediction to account for joint chance constraints and plant-model\nmismatch. The method is benchmarked against nonlinear model predictive control\nvia case studies. The results demonstrate the ability of the methodology to\naccount for process uncertainty, enabling satisfaction of joint chance\nconstraints even in the presence of plant-model mismatch.\n", "versions": [{"version": "v1", "created": "Fri, 23 Apr 2021 16:48:46 GMT"}], "update_date": "2021-04-26", "authors_parsed": [["Mowbray", "Max", ""], ["Petsagkourakis", "Panagiotis", ""], ["Chanona", "Ehecatl Antonio del R\u00edo", ""], ["Smith", "Robin", ""], ["Zhang", "Dongda", ""]]}, {"id": "2104.11707", "submitter": "Soroush Nasiriany", "authors": "Soroush Nasiriany, Vitchyr H. Pong, Ashvin Nair, Alexander Khazatsky,\n  Glen Berseth, Sergey Levine", "title": "DisCo RL: Distribution-Conditioned Reinforcement Learning for\n  General-Purpose Policies", "comments": "ICRA 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Can we use reinforcement learning to learn general-purpose policies that can\nperform a wide range of different tasks, resulting in flexible and reusable\nskills? Contextual policies provide this capability in principle, but the\nrepresentation of the context determines the degree of generalization and\nexpressivity. Categorical contexts preclude generalization to entirely new\ntasks. Goal-conditioned policies may enable some generalization, but cannot\ncapture all tasks that might be desired. In this paper, we propose goal\ndistributions as a general and broadly applicable task representation suitable\nfor contextual policies. Goal distributions are general in the sense that they\ncan represent any state-based reward function when equipped with an appropriate\ndistribution class, while the particular choice of distribution class allows us\nto trade off expressivity and learnability. We develop an off-policy algorithm\ncalled distribution-conditioned reinforcement learning (DisCo RL) to\nefficiently learn these policies. We evaluate DisCo RL on a variety of robot\nmanipulation tasks and find that it significantly outperforms prior methods on\ntasks that require generalization to new goal distributions.\n", "versions": [{"version": "v1", "created": "Fri, 23 Apr 2021 16:51:58 GMT"}], "update_date": "2021-04-26", "authors_parsed": [["Nasiriany", "Soroush", ""], ["Pong", "Vitchyr H.", ""], ["Nair", "Ashvin", ""], ["Khazatsky", "Alexander", ""], ["Berseth", "Glen", ""], ["Levine", "Sergey", ""]]}, {"id": "2104.11734", "submitter": "Jacob Zavatone-Veth", "authors": "Jacob A. Zavatone-Veth and Cengiz Pehlevan", "title": "Exact priors of finite neural networks", "comments": "12+11 pages, 4 figures; v2: references and figures added", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cond-mat.dis-nn stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Bayesian neural networks are theoretically well-understood only in the\ninfinite-width limit, where Gaussian priors over network weights yield Gaussian\npriors over network outputs. Recent work has suggested that finite Bayesian\nnetworks may outperform their infinite counterparts, but their non-Gaussian\noutput priors have been characterized only though perturbative approaches.\nHere, we derive exact solutions for the output priors for individual input\nexamples of a class of finite fully-connected feedforward Bayesian neural\nnetworks. For deep linear networks, the prior has a simple expression in terms\nof the Meijer $G$-function. The prior of a finite ReLU network is a mixture of\nthe priors of linear networks of smaller widths, corresponding to different\nnumbers of active units in each layer. Our results unify previous descriptions\nof finite network priors in terms of their tail decay and large-width behavior.\n", "versions": [{"version": "v1", "created": "Fri, 23 Apr 2021 17:31:42 GMT"}, {"version": "v2", "created": "Tue, 18 May 2021 17:42:44 GMT"}], "update_date": "2021-05-19", "authors_parsed": [["Zavatone-Veth", "Jacob A.", ""], ["Pehlevan", "Cengiz", ""]]}, {"id": "2104.11758", "submitter": "Rapha\\\"el Berthon", "authors": "Rapha\\\"el Berthon, Adrien Boiret, Guillermo A. Perez,\n  Jean-Fran\\c{c}ois Raskin", "title": "Active Learning of Sequential Transducers with Side Information about\n  the Domain", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Active learning is a setting in which a student queries a teacher, through\nmembership and equivalence queries, in order to learn a language. Performance\non these algorithms is often measured in the number of queries required to\nlearn a target, with an emphasis on costly equivalence queries. In graybox\nlearning, the learning process is accelerated by foreknowledge of some\ninformation on the target. Here, we consider graybox active learning of\nsubsequential string transducers, where a regular overapproximation of the\ndomain is known by the student. We show that there exists an algorithm using\nstring equation solvers that uses this knowledge to learn subsequential string\ntransducers with a better guarantee on the required number of equivalence\nqueries than classical active learning.\n", "versions": [{"version": "v1", "created": "Fri, 23 Apr 2021 18:01:10 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Berthon", "Rapha\u00ebl", ""], ["Boiret", "Adrien", ""], ["Perez", "Guillermo A.", ""], ["Raskin", "Jean-Fran\u00e7ois", ""]]}, {"id": "2104.11760", "submitter": "Ali Ahmadvand", "authors": "Ali Ahmadvand, Surya Kallumadi, Faizan Javed, and Eugene Agichtein", "title": "DeepCAT: Deep Category Representation for Query Understanding in\n  E-commerce Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mapping a search query to a set of relevant categories in the product\ntaxonomy is a significant challenge in e-commerce search for two reasons: 1)\nTraining data exhibits severe class imbalance problem due to biased click\nbehavior, and 2) queries with little customer feedback (e.g., tail queries) are\nnot well-represented in the training set, and cause difficulties for query\nunderstanding. To address these problems, we propose a deep learning model,\nDeepCAT, which learns joint word-category representations to enhance the query\nunderstanding process. We believe learning category interactions helps to\nimprove the performance of category mapping on minority classes, tail and torso\nqueries. DeepCAT contains a novel word-category representation model that\ntrains the category representations based on word-category co-occurrences in\nthe training set. The category representation is then leveraged to introduce a\nnew loss function to estimate the category-category co-occurrences for refining\njoint word-category embeddings. To demonstrate our model's effectiveness on\nminority categories and tail queries, we conduct two sets of experiments. The\nresults show that DeepCAT reaches a 10% improvement on minority classes and a\n7.1% improvement on tail queries over a state-of-the-art label embedding model.\nOur findings suggest a promising direction for improving e-commerce search by\nsemantic modeling of taxonomy hierarchies.\n", "versions": [{"version": "v1", "created": "Fri, 23 Apr 2021 18:04:44 GMT"}, {"version": "v2", "created": "Mon, 10 May 2021 06:12:02 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Ahmadvand", "Ali", ""], ["Kallumadi", "Surya", ""], ["Javed", "Faizan", ""], ["Agichtein", "Eugene", ""]]}, {"id": "2104.11776", "submitter": "Pablo Martinez-Gonzalez", "authors": "Pablo Martinez-Gonzalez, Sergiu Oprea, John Alejandro Castro-Vargas,\n  Alberto Garcia-Garcia, Sergio Orts-Escolano, Jose Garcia-Rodriguez and Markus\n  Vincze", "title": "UnrealROX+: An Improved Tool for Acquiring Synthetic Data from Virtual\n  3D Environments", "comments": "Accepted at International Joint Conference on Neural Networks (IJCNN)\n  2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.GR cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Synthetic data generation has become essential in last years for feeding\ndata-driven algorithms, which surpassed traditional techniques performance in\nalmost every computer vision problem. Gathering and labelling the amount of\ndata needed for these data-hungry models in the real world may become\nunfeasible and error-prone, while synthetic data give us the possibility of\ngenerating huge amounts of data with pixel-perfect annotations. However, most\nsynthetic datasets lack from enough realism in their rendered images. In that\ncontext UnrealROX generation tool was presented in 2019, allowing to generate\nhighly realistic data, at high resolutions and framerates, with an efficient\npipeline based on Unreal Engine, a cutting-edge videogame engine. UnrealROX\nenabled robotic vision researchers to generate realistic and visually plausible\ndata with full ground truth for a wide variety of problems such as class and\ninstance semantic segmentation, object detection, depth estimation, visual\ngrasping, and navigation. Nevertheless, its workflow was very tied to generate\nimage sequences from a robotic on-board camera, making hard to generate data\nfor other purposes. In this work, we present UnrealROX+, an improved version of\nUnrealROX where its decoupled and easy-to-use data acquisition system allows to\nquickly design and generate data in a much more flexible and customizable way.\nMoreover, it is packaged as an Unreal plug-in, which makes it more comfortable\nto use with already existing Unreal projects, and it also includes new features\nsuch as generating albedo or a Python API for interacting with the virtual\nenvironment from Deep Learning frameworks.\n", "versions": [{"version": "v1", "created": "Fri, 23 Apr 2021 18:45:42 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Martinez-Gonzalez", "Pablo", ""], ["Oprea", "Sergiu", ""], ["Castro-Vargas", "John Alejandro", ""], ["Garcia-Garcia", "Alberto", ""], ["Orts-Escolano", "Sergio", ""], ["Garcia-Rodriguez", "Jose", ""], ["Vincze", "Markus", ""]]}, {"id": "2104.11797", "submitter": "Gabriel Eilertsen", "authors": "Gabriel Eilertsen, Apostolia Tsirikoglou, Claes Lundstr\\\"om, Jonas\n  Unger", "title": "Ensembles of GANs for synthetic training data generation", "comments": "ICLR 2021 workshop on Synthetic Data Generation: Quality, Privacy,\n  Bias", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Insufficient training data is a major bottleneck for most deep learning\npractices, not least in medical imaging where data is difficult to collect and\npublicly available datasets are scarce due to ethics and privacy. This work\ninvestigates the use of synthetic images, created by generative adversarial\nnetworks (GANs), as the only source of training data. We demonstrate that for\nthis application, it is of great importance to make use of multiple GANs to\nimprove the diversity of the generated data, i.e. to sufficiently cover the\ndata distribution. While a single GAN can generate seemingly diverse image\ncontent, training on this data in most cases lead to severe over-fitting. We\ntest the impact of ensembled GANs on synthetic 2D data as well as common image\ndatasets (SVHN and CIFAR-10), and using both DCGANs and progressively growing\nGANs. As a specific use case, we focus on synthesizing digital pathology\npatches to provide anonymized training data.\n", "versions": [{"version": "v1", "created": "Fri, 23 Apr 2021 19:38:48 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Eilertsen", "Gabriel", ""], ["Tsirikoglou", "Apostolia", ""], ["Lundstr\u00f6m", "Claes", ""], ["Unger", "Jonas", ""]]}, {"id": "2104.11798", "submitter": "Th\\'eophile Champion", "authors": "Th\\'eophile Champion, Marek Grze\\'s, Howard Bowman", "title": "Realising Active Inference in Variational Message Passing: the\n  Outcome-blind Certainty Seeker", "comments": "60 pages, 19 figures, final version accepted for publication in\n  Neural Computation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Active inference is a state-of-the-art framework in neuroscience that offers\na unified theory of brain function. It is also proposed as a framework for\nplanning in AI. Unfortunately, the complex mathematics required to create new\nmodels -- can impede application of active inference in neuroscience and AI\nresearch. This paper addresses this problem by providing a complete\nmathematical treatment of the active inference framework -- in discrete time\nand state spaces -- and the derivation of the update equations for any new\nmodel. We leverage the theoretical connection between active inference and\nvariational message passing as describe by John Winn and Christopher M. Bishop\nin 2005. Since, variational message passing is a well-defined methodology for\nderiving Bayesian belief update equations, this paper opens the door to\nadvanced generative models for active inference. We show that using a fully\nfactorized variational distribution simplifies the expected free energy -- that\nfurnishes priors over policies -- so that agents seek unambiguous states.\nFinally, we consider future extensions that support deep tree searches for\nsequential policy optimisation -- based upon structure learning and belief\npropagation.\n", "versions": [{"version": "v1", "created": "Fri, 23 Apr 2021 19:40:55 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Champion", "Th\u00e9ophile", ""], ["Grze\u015b", "Marek", ""], ["Bowman", "Howard", ""]]}, {"id": "2104.11805", "submitter": "Gunduz Vehbi Demirci", "authors": "Gunduz Vehbi Demirci, Hakan Ferhatosmanoglu", "title": "Partitioning sparse deep neural networks for scalable training and\n  inference", "comments": "Gunduz Vehbi Demirci and Hakan Ferhatosmanoglu. 2021. Partitioning\n  Sparse Deep Neural Networks for Scalable Training and Inference. In 2021\n  International Conference on Supercomputing (ICS '21), June 14-17, 2021,\n  Virtual Event, USA. ACM, New York, NY, USA, 12 pages", "journal-ref": null, "doi": "10.1145/3447818.3460372", "report-no": null, "categories": "cs.LG cs.AI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The state-of-the-art deep neural networks (DNNs) have significant\ncomputational and data management requirements. The size of both training data\nand models continue to increase. Sparsification and pruning methods are shown\nto be effective in removing a large fraction of connections in DNNs. The\nresulting sparse networks present unique challenges to further improve the\ncomputational efficiency of training and inference in deep learning. Both the\nfeedforward (inference) and backpropagation steps in stochastic gradient\ndescent (SGD) algorithm for training sparse DNNs involve consecutive sparse\nmatrix-vector multiplications (SpMVs). We first introduce a distributed-memory\nparallel SpMV-based solution for the SGD algorithm to improve its scalability.\nThe parallelization approach is based on row-wise partitioning of weight\nmatrices that represent neuron connections between consecutive layers. We then\npropose a novel hypergraph model for partitioning weight matrices to reduce the\ntotal communication volume and ensure computational load-balance among\nprocessors. Experiments performed on sparse DNNs demonstrate that the proposed\nsolution is highly efficient and scalable. By utilizing the proposed matrix\npartitioning scheme, the performance of our solution is further improved\nsignificantly.\n", "versions": [{"version": "v1", "created": "Fri, 23 Apr 2021 20:05:52 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Demirci", "Gunduz Vehbi", ""], ["Ferhatosmanoglu", "Hakan", ""]]}, {"id": "2104.11824", "submitter": "Dheeraj Baby", "authors": "Dheeraj Baby and Yu-Xiang Wang", "title": "Optimal Dynamic Regret in Exp-Concave Online Learning", "comments": "Added a post processing step to Lemma 5; Added Remark 6", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We consider the problem of the Zinkevich (2003)-style dynamic regret\nminimization in online learning with exp-concave losses. We show that whenever\nimproper learning is allowed, a Strongly Adaptive online learner achieves the\ndynamic regret of $\\tilde O^*(n^{1/3}C_n^{2/3} \\vee 1)$ where $C_n$ is the\ntotal variation (a.k.a. path length) of the an arbitrary sequence of\ncomparators that may not be known to the learner ahead of time. Achieving this\nrate was highly nontrivial even for squared losses in 1D where the best known\nupper bound was $O(\\sqrt{nC_n} \\vee \\log n)$ (Yuan and Lamperski, 2019). Our\nnew proof techniques make elegant use of the intricate structures of the primal\nand dual variables imposed by the KKT conditions and could be of independent\ninterest. Finally, we apply our results to the classical statistical problem of\nlocally adaptive non-parametric regression (Mammen, 1991; Donoho and Johnstone,\n1998) and obtain a stronger and more flexible algorithm that do not require any\nstatistical assumptions or any hyperparameter tuning.\n", "versions": [{"version": "v1", "created": "Fri, 23 Apr 2021 21:36:51 GMT"}, {"version": "v2", "created": "Sat, 3 Jul 2021 04:53:58 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Baby", "Dheeraj", ""], ["Wang", "Yu-Xiang", ""]]}, {"id": "2104.11832", "submitter": "Zhe Gan", "authors": "Zhe Gan, Yen-Chun Chen, Linjie Li, Tianlong Chen, Yu Cheng, Shuohang\n  Wang, Jingjing Liu", "title": "Playing Lottery Tickets with Vision and Language", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Large-scale transformer-based pre-training has recently revolutionized\nvision-and-language (V+L) research. Models such as LXMERT, ViLBERT and UNITER\nhave significantly lifted the state of the art over a wide range of V+L tasks.\nHowever, the large number of parameters in such models hinders their\napplication in practice. In parallel, work on the lottery ticket hypothesis has\nshown that deep neural networks contain small matching subnetworks that can\nachieve on par or even better performance than the dense networks when trained\nin isolation. In this work, we perform the first empirical study to assess\nwhether such trainable subnetworks also exist in pre-trained V+L models. We use\nUNITER, one of the best-performing V+L models, as the testbed, and consolidate\n7 representative V+L tasks for experiments, including visual question\nanswering, visual commonsense reasoning, visual entailment, referring\nexpression comprehension, image-text retrieval, GQA, and NLVR$^2$. Through\ncomprehensive analysis, we summarize our main findings as follows. ($i$) It is\ndifficult to find subnetworks (i.e., the tickets) that strictly match the\nperformance of the full UNITER model. However, it is encouraging to confirm\nthat we can find \"relaxed\" winning tickets at 50%-70% sparsity that maintain\n99% of the full accuracy. ($ii$) Subnetworks found by task-specific pruning\ntransfer reasonably well to the other tasks, while those found on the\npre-training tasks at 60%/70% sparsity transfer universally, matching 98%/96%\nof the full accuracy on average over all the tasks. ($iii$) Adversarial\ntraining can be further used to enhance the performance of the found lottery\ntickets.\n", "versions": [{"version": "v1", "created": "Fri, 23 Apr 2021 22:24:33 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Gan", "Zhe", ""], ["Chen", "Yen-Chun", ""], ["Li", "Linjie", ""], ["Chen", "Tianlong", ""], ["Cheng", "Yu", ""], ["Wang", "Shuohang", ""], ["Liu", "Jingjing", ""]]}, {"id": "2104.11833", "submitter": "Eric Bax", "authors": "Eric Bax", "title": "Selecting a number of voters for a voting ensemble", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  For a voting ensemble that selects an odd-sized subset of the ensemble\nclassifiers at random for each example, applies them to the example, and\nreturns the majority vote, we show that any number of voters may minimize the\nerror rate over an out-of-sample distribution. The optimal number of voters\ndepends on the out-of-sample distribution of the number of classifiers in\nerror. To select a number of voters to use, estimating that distribution then\ninferring error rates for numbers of voters gives lower-variance estimates than\ndirectly estimating those error rates.\n", "versions": [{"version": "v1", "created": "Fri, 23 Apr 2021 22:37:02 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Bax", "Eric", ""]]}, {"id": "2104.11834", "submitter": "Hannes Eriksson", "authors": "Hannes Eriksson, Christos Dimitrakakis, Lars Carlsson", "title": "High-dimensional near-optimal experiment design for drug discovery via\n  Bayesian sparse sampling", "comments": "14 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-bio.QM stat.ML", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  We study the problem of performing automated experiment design for drug\nscreening through Bayesian inference and optimisation. In particular, we\ncompare and contrast the behaviour of linear-Gaussian models and Gaussian\nprocesses, when used in conjunction with upper confidence bound algorithms,\nThompson sampling, or bounded horizon tree search. We show that non-myopic\nsophisticated exploration techniques using sparse tree search have a distinct\nadvantage over methods such as Thompson sampling or upper confidence bounds in\nthis setting. We demonstrate the significant superiority of the approach over\nexisting and synthetic datasets of drug toxicity.\n", "versions": [{"version": "v1", "created": "Fri, 23 Apr 2021 22:43:16 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Eriksson", "Hannes", ""], ["Dimitrakakis", "Christos", ""], ["Carlsson", "Lars", ""]]}, {"id": "2104.11843", "submitter": "Tianhao Wang", "authors": "Tianhao Wang, Si Chen, Ruoxi Jia", "title": "One-Round Active Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Active learning has been a main solution for reducing data labeling costs.\nHowever, existing active learning strategies assume that a data owner can\ninteract with annotators in an online, timely manner, which is usually\nimpractical. Even with such interactive annotators, for existing active\nlearning strategies to be effective, they often require many rounds of\ninteractions between the data owner and annotators, which is often\ntime-consuming. In this work, we initiate the study of one-round active\nlearning, which aims to select a subset of unlabeled data points that achieve\nthe highest utility after being labeled with only the information from\ninitially labeled data points. We propose DULO, a general framework for\none-round active learning based on the notion of data utility functions, which\nmap a set of data points to some performance measure of the model trained on\nthe set. We formulate the one-round active learning problem as data utility\nfunction maximization. We further propose strategies to make the estimation and\noptimization of data utility functions scalable to large models and large\nunlabeled data sets. Our results demonstrate that while existing active\nlearning approaches could succeed with multiple rounds, DULO consistently\nperforms better in the one-round setting.\n", "versions": [{"version": "v1", "created": "Fri, 23 Apr 2021 23:59:50 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Wang", "Tianhao", ""], ["Chen", "Si", ""], ["Jia", "Ruoxi", ""]]}, {"id": "2104.11846", "submitter": "Osman Boyaci", "authors": "Osman Boyaci, Mohammad Rasoul Narimani, Katherine Davis, Muhammad\n  Ismail, Thomas J Overbye, and Erchin Serpedin", "title": "Joint Detection and Localization of Stealth False Data Injection Attacks\n  in Smart Grids using Graph Neural Networks", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  False data injection attacks (FDIA) are becoming an active avenue of research\nas such attacks are more frequently encountered in power systems. Contrary to\nthe detection of these attacks, less attention has been paid to identifying the\nattacked units of the grid. To this end, this work jointly studies detecting\nand localizing the stealth FDIA in modern power grids. Exploiting the inherent\ngraph topology of power systems as well as the spatial correlations of smart\nmeters' data, this paper proposes an approach based on the graph neural network\n(GNN) to identify the presence and location of the FDIA. The proposed approach\nleverages the auto-regressive moving average (ARMA) type graph convolutional\nfilters which offer better noise robustness and frequency response flexibility\ncompared to the polynomial type graph convolutional filters such as Chebyshev.\nTo the best of our knowledge, this is the first work based on GNN that\nautomatically detects and localizes FDIA in power systems. Extensive\nsimulations and visualizations show that the proposed approach outperforms the\navailable methods in both detection and localization FDIA for different IEEE\ntest systems. Thus, the targeted areas in power grids can be identified and\npreventive actions can be taken before the attack impacts the grid.\n", "versions": [{"version": "v1", "created": "Sat, 24 Apr 2021 00:33:45 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Boyaci", "Osman", ""], ["Narimani", "Mohammad Rasoul", ""], ["Davis", "Katherine", ""], ["Ismail", "Muhammad", ""], ["Overbye", "Thomas J", ""], ["Serpedin", "Erchin", ""]]}, {"id": "2104.11849", "submitter": "Stone Yun", "authors": "Stone Yun and Alexander Wong", "title": "Do All MobileNets Quantize Poorly? Gaining Insights into the Effect of\n  Quantization on Depthwise Separable Convolutional Networks Through the Eyes\n  of Multi-scale Distributional Dynamics", "comments": "Accepted for publication in Mobile AI (MAI) Workshop 2021 at CVPR", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  As the \"Mobile AI\" revolution continues to grow, so does the need to\nunderstand the behaviour of edge-deployed deep neural networks. In particular,\nMobileNets are the go-to family of deep convolutional neural networks (CNN) for\nmobile. However, they often have significant accuracy degradation under\npost-training quantization. While studies have introduced quantization-aware\ntraining and other methods to tackle this challenge, there is limited\nunderstanding into why MobileNets (and potentially depthwise-separable CNNs\n(DWSCNN) in general) quantize so poorly compared to other CNN architectures.\nMotivated to gain deeper insights into this phenomenon, we take a different\nstrategy and study the multi-scale distributional dynamics of MobileNet-V1, a\nset of smaller DWSCNNs, and regular CNNs. Specifically, we investigate the\nimpact of quantization on the weight and activation distributional dynamics as\ninformation propagates from layer to layer, as well as overall changes in\ndistributional dynamics at the network level. This fine-grained analysis\nrevealed significant dynamic range fluctuations and a \"distributional mismatch\"\nbetween channelwise and layerwise distributions in DWSCNNs that lead to\nincreasing quantized degradation and distributional shift during information\npropagation. Furthermore, analysis of the activation quantization errors show\nthat there is greater quantization error accumulation in DWSCNN compared to\nregular CNNs. The hope is that such insights can lead to innovative strategies\nfor reducing such distributional dynamics changes and improve post-training\nquantization for mobile.\n", "versions": [{"version": "v1", "created": "Sat, 24 Apr 2021 01:28:29 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Yun", "Stone", ""], ["Wong", "Alexander", ""]]}, {"id": "2104.11861", "submitter": "Lukasz Korycki", "authors": "{\\L}ukasz Korycki, Bartosz Krawczyk", "title": "Class-Incremental Experience Replay for Continual Learning under Concept\n  Drift", "comments": "IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\n  Workshops, 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern machine learning systems need to be able to cope with constantly\narriving and changing data. Two main areas of research dealing with such\nscenarios are continual learning and data stream mining. Continual learning\nfocuses on accumulating knowledge and avoiding forgetting, assuming information\nonce learned should be stored. Data stream mining focuses on adaptation to\nconcept drift and discarding outdated information, assuming that only the most\nrecent data is relevant. While these two areas are mainly being developed in\nseparation, they offer complementary views on the problem of learning from\ndynamic data. There is a need for unifying them, by offering architectures\ncapable of both learning and storing new information, as well as revisiting and\nadapting to changes in previously seen concepts. We propose a novel continual\nlearning approach that can handle both tasks. Our experience replay method is\nfueled by a centroid-driven memory storing diverse instances of incrementally\narriving classes. This is enhanced with a reactive subspace buffer that tracks\nconcept drift occurrences in previously seen classes and adapts clusters\naccordingly. The proposed architecture is thus capable of both remembering\nvalid and forgetting outdated information, offering a holistic framework for\ncontinual learning under concept drift.\n", "versions": [{"version": "v1", "created": "Sat, 24 Apr 2021 02:36:38 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Korycki", "\u0141ukasz", ""], ["Krawczyk", "Bartosz", ""]]}, {"id": "2104.11867", "submitter": "Peng Xie", "authors": "Peng Xie, Wenyuan Tao, Jie Li, Wentao Huang, Siming Chen", "title": "Exploring Multi-dimensional Data via Subset Embedding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-dimensional data exploration is a classic research topic in\nvisualization. Most existing approaches are designed for identifying record\npatterns in dimensional space or subspace. In this paper, we propose a visual\nanalytics approach to exploring subset patterns. The core of the approach is a\nsubset embedding network (SEN) that represents a group of subsets as\nuniformly-formatted embeddings. We implement the SEN as multiple subnets with\nseparate loss functions. The design enables to handle arbitrary subsets and\ncapture the similarity of subsets on single features, thus achieving accurate\npattern exploration, which in most cases is searching for subsets having\nsimilar values on few features. Moreover, each subnet is a fully-connected\nneural network with one hidden layer. The simple structure brings high training\nefficiency. We integrate the SEN into a visualization system that achieves a\n3-step workflow. Specifically, analysts (1) partition the given dataset into\nsubsets, (2) select portions in a projected latent space created using the SEN,\nand (3) determine the existence of patterns within selected subsets. Generally,\nthe system combines visualizations, interactions, automatic methods, and\nquantitative measures to balance the exploration flexibility and operation\nefficiency, and improve the interpretability and faithfulness of the identified\npatterns. Case studies and quantitative experiments on multiple open datasets\ndemonstrate the general applicability and effectiveness of our approach.\n", "versions": [{"version": "v1", "created": "Sat, 24 Apr 2021 03:08:08 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Xie", "Peng", ""], ["Tao", "Wenyuan", ""], ["Li", "Jie", ""], ["Huang", "Wentao", ""], ["Chen", "Siming", ""]]}, {"id": "2104.11892", "submitter": "Mohammad Samar Ansari", "authors": "Syed Sahil Abbas Zaidi, Mohammad Samar Ansari, Asra Aslam, Nadia\n  Kanwal, Mamoona Asghar, and Brian Lee", "title": "A Survey of Modern Deep Learning based Object Detection Models", "comments": "Preprint submitted to IET Computer Vision", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Object Detection is the task of classification and localization of objects in\nan image or video. It has gained prominence in recent years due to its\nwidespread applications. This article surveys recent developments in deep\nlearning based object detectors. Concise overview of benchmark datasets and\nevaluation metrics used in detection is also provided along with some of the\nprominent backbone architectures used in recognition tasks. It also covers\ncontemporary lightweight classification models used on edge devices. Lastly, we\ncompare the performances of these architectures on multiple metrics.\n", "versions": [{"version": "v1", "created": "Sat, 24 Apr 2021 06:33:54 GMT"}, {"version": "v2", "created": "Wed, 12 May 2021 16:45:20 GMT"}], "update_date": "2021-05-13", "authors_parsed": [["Zaidi", "Syed Sahil Abbas", ""], ["Ansari", "Mohammad Samar", ""], ["Aslam", "Asra", ""], ["Kanwal", "Nadia", ""], ["Asghar", "Mamoona", ""], ["Lee", "Brian", ""]]}, {"id": "2104.11893", "submitter": "Jingwei Guo", "authors": "Jingwei Guo, Kaizhu Huang, Xinping Yi, Rui Zhang", "title": "LGD-GCN: Local and Global Disentangled Graph Convolutional Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Disentangled Graph Convolutional Network (DisenGCN) is an encouraging\nframework to disentangle the latent factors arising in a real-world graph.\nHowever, it relies on disentangling information heavily from a local range\n(i.e., a node and its 1-hop neighbors), while the local information in many\ncases can be uneven and incomplete, hindering the interpretabiliy power and\nmodel performance of DisenGCN. In this paper, we introduce a novel Local and\nGlobal Disentangled Graph Convolutional Network (LGD-GCN) to capture both local\nand global information for graph disentanglement. LGD-GCN performs a\nstatistical mixture modeling to derive a factor-aware latent continuous space,\nand then constructs different structures w.r.t. different factors from the\nrevealed space. In this way, the global factor-specific information can be\nefficiently and selectively encoded via a message passing along these built\nstructures, strengthening the intra-factor consistency. We also propose a novel\ndiversity promoting regularizer employed with the latent space modeling, to\nencourage inter-factor diversity. Evaluations of the proposed LGD-GCN on the\nsynthetic and real-world datasets show a better interpretability and improved\nperformance in node classification over the existing competitive models.\n", "versions": [{"version": "v1", "created": "Sat, 24 Apr 2021 06:40:35 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Guo", "Jingwei", ""], ["Huang", "Kaizhu", ""], ["Yi", "Xinping", ""], ["Zhang", "Rui", ""]]}, {"id": "2104.11895", "submitter": "Shiyu Liang", "authors": "Shiyu Liang, Ruoyu Sun and R. Srikant", "title": "Achieving Small Test Error in Mildly Overparameterized Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recent theoretical works on over-parameterized neural nets have focused on\ntwo aspects: optimization and generalization. Many existing works that study\noptimization and generalization together are based on neural tangent kernel and\nrequire a very large width. In this work, we are interested in the following\nquestion: for a binary classification problem with two-layer mildly\nover-parameterized ReLU network, can we find a point with small test error in\npolynomial time? We first show that the landscape of loss functions with\nexplicit regularization has the following property: all local minima and\ncertain other points which are only stationary in certain directions achieve\nsmall test error. We then prove that for convolutional neural nets, there is an\nalgorithm which finds one of these points in polynomial time (in the input\ndimension and the number of data points). In addition, we prove that for a\nfully connected neural net, with an additional assumption on the data\ndistribution, there is a polynomial time algorithm.\n", "versions": [{"version": "v1", "created": "Sat, 24 Apr 2021 06:47:20 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Liang", "Shiyu", ""], ["Sun", "Ruoyu", ""], ["Srikant", "R.", ""]]}, {"id": "2104.11902", "submitter": "Jivat Neet Kaur", "authors": "Jivat Neet Kaur, Yiding Jiang, Paul Pu Liang", "title": "Ask & Explore: Grounded Question Answering for Curiosity-Driven\n  Exploration", "comments": "Accepted at ICLR 2021 Workshop on Embodied Multimodal Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In many real-world scenarios where extrinsic rewards to the agent are\nextremely sparse, curiosity has emerged as a useful concept providing intrinsic\nrewards that enable the agent to explore its environment and acquire\ninformation to achieve its goals. Despite their strong performance on many\nsparse-reward tasks, existing curiosity approaches rely on an overly holistic\nview of state transitions, and do not allow for a structured understanding of\nspecific aspects of the environment. In this paper, we formulate curiosity\nbased on grounded question answering by encouraging the agent to ask questions\nabout the environment and be curious when the answers to these questions\nchange. We show that natural language questions encourage the agent to uncover\nspecific knowledge about their environment such as the physical properties of\nobjects as well as their spatial relationships with other objects, which serve\nas valuable curiosity rewards to solve sparse-reward tasks more efficiently.\n", "versions": [{"version": "v1", "created": "Sat, 24 Apr 2021 07:56:31 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Kaur", "Jivat Neet", ""], ["Jiang", "Yiding", ""], ["Liang", "Paul Pu", ""]]}, {"id": "2104.11914", "submitter": "Natalia D\\'iaz-Rodr\\'iguez PhD", "authors": "Natalia D\\'iaz-Rodr\\'iguez, Alberto Lamas, Jules Sanchez, Gianni\n  Franchi, Ivan Donadello, Siham Tabik, David Filliat, Policarpo Cruz, Rosana\n  Montes, Francisco Herrera", "title": "EXplainable Neural-Symbolic Learning (X-NeSyL) methodology to fuse deep\n  learning representations with expert knowledge graphs: the MonuMAI cultural\n  heritage use case", "comments": "Under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.SC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The latest Deep Learning (DL) models for detection and classification have\nachieved an unprecedented performance over classical machine learning\nalgorithms. However, DL models are black-box methods hard to debug, interpret,\nand certify. DL alone cannot provide explanations that can be validated by a\nnon technical audience. In contrast, symbolic AI systems that convert concepts\ninto rules or symbols -- such as knowledge graphs -- are easier to explain.\nHowever, they present lower generalisation and scaling capabilities. A very\nimportant challenge is to fuse DL representations with expert knowledge. One\nway to address this challenge, as well as the performance-explainability\ntrade-off is by leveraging the best of both streams without obviating domain\nexpert knowledge. We tackle such problem by considering the symbolic knowledge\nis expressed in form of a domain expert knowledge graph. We present the\neXplainable Neural-symbolic learning (X-NeSyL) methodology, designed to learn\nboth symbolic and deep representations, together with an explainability metric\nto assess the level of alignment of machine and human expert explanations. The\nultimate objective is to fuse DL representations with expert domain knowledge\nduring the learning process to serve as a sound basis for explainability.\nX-NeSyL methodology involves the concrete use of two notions of explanation at\ninference and training time respectively: 1) EXPLANet: Expert-aligned\neXplainable Part-based cLAssifier NETwork Architecture, a compositional CNN\nthat makes use of symbolic representations, and 2) SHAP-Backprop, an\nexplainable AI-informed training procedure that guides the DL process to align\nwith such symbolic representations in form of knowledge graphs. We showcase\nX-NeSyL methodology using MonuMAI dataset for monument facade image\nclassification, and demonstrate that our approach improves explainability and\nperformance.\n", "versions": [{"version": "v1", "created": "Sat, 24 Apr 2021 09:06:08 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["D\u00edaz-Rodr\u00edguez", "Natalia", ""], ["Lamas", "Alberto", ""], ["Sanchez", "Jules", ""], ["Franchi", "Gianni", ""], ["Donadello", "Ivan", ""], ["Tabik", "Siham", ""], ["Filliat", "David", ""], ["Cruz", "Policarpo", ""], ["Montes", "Rosana", ""], ["Herrera", "Francisco", ""]]}, {"id": "2104.11918", "submitter": "Helge Spieker", "authors": "Helge Spieker", "title": "Constraint-Guided Reinforcement Learning: Augmenting the\n  Agent-Environment-Interaction", "comments": "IJCNN 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Reinforcement Learning (RL) agents have great successes in solving tasks with\nlarge observation and action spaces from limited feedback. Still, training the\nagents is data-intensive and there are no guarantees that the learned behavior\nis safe and does not violate rules of the environment, which has limitations\nfor the practical deployment in real-world scenarios. This paper discusses the\nengineering of reliable agents via the integration of deep RL with\nconstraint-based augmentation models to guide the RL agent towards safe\nbehavior. Within the constraints set, the RL agent is free to adapt and\nexplore, such that its effectiveness to solve the given problem is not\nhindered. However, once the RL agent leaves the space defined by the\nconstraints, the outside models can provide guidance to still work reliably. We\ndiscuss integration points for constraint guidance within the RL process and\nperform experiments on two case studies: a strictly constrained card game and a\ngrid world environment with additional combinatorial subgoals. Our results show\nthat constraint-guidance does both provide reliability improvements and safer\nbehavior, as well as accelerated training.\n", "versions": [{"version": "v1", "created": "Sat, 24 Apr 2021 10:04:14 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Spieker", "Helge", ""]]}, {"id": "2104.11946", "submitter": "Micha{\\l} Stypu{\\l}kowski", "authors": "Jan Chorowski, Grzegorz Ciesielski, Jaros{\\l}aw Dzikowski, Adrian\n  {\\L}a\\'ncucki, Ricard Marxer, Mateusz Opala, Piotr Pusz, Pawe{\\l}\n  Rychlikowski, Micha{\\l} Stypu{\\l}kowski", "title": "Aligned Contrastive Predictive Coding", "comments": "Published in Interspeech 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the possibility of forcing a self-supervised model trained\nusing a contrastive predictive loss to extract slowly varying latent\nrepresentations. Rather than producing individual predictions for each of the\nfuture representations, the model emits a sequence of predictions shorter than\nthat of the upcoming representations to which they will be aligned. In this\nway, the prediction network solves a simpler task of predicting the next\nsymbols, but not their exact timing, while the encoding network is trained to\nproduce piece-wise constant latent codes. We evaluate the model on a speech\ncoding task and demonstrate that the proposed Aligned Contrastive Predictive\nCoding (ACPC) leads to higher linear phone prediction accuracy and lower ABX\nerror rates, while being slightly faster to train due to the reduced number of\nprediction heads.\n", "versions": [{"version": "v1", "created": "Sat, 24 Apr 2021 13:07:22 GMT"}, {"version": "v2", "created": "Thu, 29 Apr 2021 14:15:08 GMT"}, {"version": "v3", "created": "Tue, 22 Jun 2021 08:22:00 GMT"}], "update_date": "2021-06-23", "authors_parsed": [["Chorowski", "Jan", ""], ["Ciesielski", "Grzegorz", ""], ["Dzikowski", "Jaros\u0142aw", ""], ["\u0141a\u0144cucki", "Adrian", ""], ["Marxer", "Ricard", ""], ["Opala", "Mateusz", ""], ["Pusz", "Piotr", ""], ["Rychlikowski", "Pawe\u0142", ""], ["Stypu\u0142kowski", "Micha\u0142", ""]]}, {"id": "2104.11949", "submitter": "Navid Ghassemi", "authors": "Navid Ghassemi, Afshin Shoeibi, Marjane Khodatars, Jonathan Heras,\n  Alireza Rahimi, Assef Zare, Ram Bilas Pachori, J. Manuel Gorriz", "title": "Automatic Diagnosis of COVID-19 from CT Images using CycleGAN and\n  Transfer Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  The outbreak of the corona virus disease (COVID-19) has changed the lives of\nmost people on Earth. Given the high prevalence of this disease, its correct\ndiagnosis in order to quarantine patients is of the utmost importance in steps\nof fighting this pandemic. Among the various modalities used for diagnosis,\nmedical imaging, especially computed tomography (CT) imaging, has been the\nfocus of many previous studies due to its accuracy and availability. In\naddition, automation of diagnostic methods can be of great help to physicians.\nIn this paper, a method based on pre-trained deep neural networks is presented,\nwhich, by taking advantage of a cyclic generative adversarial net (CycleGAN)\nmodel for data augmentation, has reached state-of-the-art performance for the\ntask at hand, i.e., 99.60% accuracy. Also, in order to evaluate the method, a\ndataset containing 3163 images from 189 patients has been collected and labeled\nby physicians. Unlike prior datasets, normal data have been collected from\npeople suspected of having COVID-19 disease and not from data from other\ndiseases, and this database is made available publicly.\n", "versions": [{"version": "v1", "created": "Sat, 24 Apr 2021 13:12:20 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Ghassemi", "Navid", ""], ["Shoeibi", "Afshin", ""], ["Khodatars", "Marjane", ""], ["Heras", "Jonathan", ""], ["Rahimi", "Alireza", ""], ["Zare", "Assef", ""], ["Pachori", "Ram Bilas", ""], ["Gorriz", "J. Manuel", ""]]}, {"id": "2104.11952", "submitter": "Zhi Chen", "authors": "Zhi Chen, Jiang Duan, Li Kang and Guoping Qiu", "title": "Supervised Anomaly Detection via Conditional Generative Adversarial\n  Network and Ensemble Active Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Anomaly detection has wide applications in machine intelligence but is still\na difficult unsolved problem. Major challenges include the rarity of labeled\nanomalies and it is a class highly imbalanced problem. Traditional unsupervised\nanomaly detectors are suboptimal while supervised models can easily make biased\npredictions towards normal data. In this paper, we present a new supervised\nanomaly detector through introducing the novel Ensemble Active Learning\nGenerative Adversarial Network (EAL-GAN). EAL-GAN is a conditional GAN having a\nunique one generator vs. multiple discriminators architecture where anomaly\ndetection is implemented by an auxiliary classifier of the discriminator. In\naddition to using the conditional GAN to generate class balanced supplementary\ntraining data, an innovative ensemble learning loss function ensuring each\ndiscriminator makes up for the deficiencies of the others is designed to\novercome the class imbalanced problem, and an active learning algorithm is\nintroduced to significantly reduce the cost of labeling real-world data. We\npresent extensive experimental results to demonstrate that the new anomaly\ndetector consistently outperforms a variety of SOTA methods by significant\nmargins. The codes are available on Github.\n", "versions": [{"version": "v1", "created": "Sat, 24 Apr 2021 13:47:50 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Chen", "Zhi", ""], ["Duan", "Jiang", ""], ["Kang", "Li", ""], ["Qiu", "Guoping", ""]]}, {"id": "2104.11970", "submitter": "Hassan Alsawadi", "authors": "Hassan Alsawadi and Muhammad Bilal", "title": "Measuring Novelty in Autonomous Vehicles Motion Using Local Outlier\n  Factor Algorithm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Under unexpected conditions or scenarios, autonomous vehicles (AV) are more\nlikely to follow abnormal unplanned actions, due to the limited set of rules or\namount of experience they possess at that time. Enabling AV to measure the\ndegree at which their movements are novel in real-time may help to decrease any\npossible negative consequences. We propose a method based on the Local Outlier\nFactor (LOF) algorithm to quantify this novelty measure. We extracted features\nfrom the inertial measurement unit (IMU) sensor's readings, which captures the\nvehicle's motion. We followed a novelty detection approach in which the model\nis fitted only using the normal data. Using datasets obtained from real-world\nvehicle missions, we demonstrate that the suggested metric can quantify to some\nextent the degree of novelty. Finally, a performance evaluation of the model\nconfirms that our novelty metric can be practical.\n", "versions": [{"version": "v1", "created": "Sat, 24 Apr 2021 15:19:35 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Alsawadi", "Hassan", ""], ["Bilal", "Muhammad", ""]]}, {"id": "2104.11977", "submitter": "Salvatore Ivan Trapasso", "authors": "Fabio Nicola and S. Ivan Trapasso", "title": "On the stability of deep convolutional neural networks under irregular\n  or random deformations", "comments": "36 pages, 6 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.FA cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of robustness under location deformations for deep convolutional\nneural networks (DCNNs) is of great theoretical and practical interest. This\nissue has been studied in pioneering works, especially for scattering-type\narchitectures, for deformation vector fields $\\tau(x)$ with some regularity -\nat least $C^1$. Here we address this issue for any field $\\tau\\in\nL^\\infty(\\mathbb{R}^d;\\mathbb{R}^d)$, without any additional regularity\nassumption, hence including the case of wild irregular deformations such as a\nnoise on the pixel location of an image. We prove that for signals in\nmultiresolution approximation spaces $U_s$ at scale $s$, whenever the network\nis Lipschitz continuous (regardless of its architecture), stability in $L^2$\nholds in the regime $\\|\\tau\\|_{L^\\infty}/s\\ll 1$, essentially as a consequence\nof the uncertainty principle. When $\\|\\tau\\|_{L^\\infty}/s\\gg 1$ instability can\noccur even for well-structured DCNNs such as the wavelet scattering networks,\nand we provide a sharp upper bound for the asymptotic growth rate. The\nstability results are then extended to signals in the Besov space\n$B^{d/2}_{2,1}$ tailored to the given multiresolution approximation. We also\nconsider the case of more general time-frequency deformations. Finally, we\nprovide stochastic versions of the aforementioned results, namely we study the\nissue of stability in mean when $\\tau(x)$ is modeled as a random field (not\nbounded, in general) with with identically distributed variables $|\\tau(x)|$,\n$x\\in\\mathbb{R}^d$.\n", "versions": [{"version": "v1", "created": "Sat, 24 Apr 2021 16:16:30 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Nicola", "Fabio", ""], ["Trapasso", "S. Ivan", ""]]}, {"id": "2104.11980", "submitter": "Michael Alcorn", "authors": "Michael A. Alcorn, Anh Nguyen", "title": "baller2vec++: A Look-Ahead Multi-Entity Transformer For Modeling\n  Coordinated Agents", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many multi-agent spatiotemporal systems, the agents are under the\ninfluence of shared, unobserved variables (e.g., the play a team is executing\nin a game of basketball). As a result, the trajectories of the agents are often\nstatistically dependent at any given time step; however, almost universally,\nmulti-agent models implicitly assume the agents' trajectories are statistically\nindependent at each time step. In this paper, we introduce baller2vec++, a\nmulti-entity Transformer that can effectively model coordinated agents.\nSpecifically, baller2vec++ applies a specially designed self-attention mask to\na mixture of location and \"look-ahead\" trajectory sequences to learn the\ndistributions of statistically dependent agent trajectories. We show that,\nunlike baller2vec (baller2vec++'s predecessor), baller2vec++ can learn to\nemulate the behavior of perfectly coordinated agents in a simulated toy\ndataset. Additionally, when modeling the trajectories of professional\nbasketball players, baller2vec++ outperforms baller2vec by a wide margin.\n", "versions": [{"version": "v1", "created": "Sat, 24 Apr 2021 16:20:47 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Alcorn", "Michael A.", ""], ["Nguyen", "Anh", ""]]}, {"id": "2104.11981", "submitter": "Kun Yuan", "authors": "Kun Yuan, Yiming Chen, Xinmeng Huang, Yingya Zhang, Pan Pan, Yinghui\n  Xu, Wotao Yin", "title": "DecentLaM: Decentralized Momentum SGD for Large-batch Deep Training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The scale of deep learning nowadays calls for efficient distributed training\nalgorithms. Decentralized momentum SGD (DmSGD), in which each node averages\nonly with its neighbors, is more communication efficient than vanilla Parallel\nmomentum SGD that incurs global average across all computing nodes. On the\nother hand, the large-batch training has been demonstrated critical to achieve\nruntime speedup. This motivates us to investigate how DmSGD performs in the\nlarge-batch scenario.\n  In this work, we find the momentum term can amplify the inconsistency bias in\nDmSGD. Such bias becomes more evident as batch-size grows large and hence\nresults in severe performance degradation. We next propose DecentLaM, a novel\ndecentralized large-batch momentum SGD to remove the momentum-incurred bias.\nThe convergence rate for both non-convex and strongly-convex scenarios is\nestablished. Our theoretical results justify the superiority of DecentLaM to\nDmSGD especially in the large-batch scenario. Experimental results on a variety\nof computer vision tasks and models demonstrate that DecentLaM promises both\nefficient and high-quality training.\n", "versions": [{"version": "v1", "created": "Sat, 24 Apr 2021 16:21:01 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Yuan", "Kun", ""], ["Chen", "Yiming", ""], ["Huang", "Xinmeng", ""], ["Zhang", "Yingya", ""], ["Pan", "Pan", ""], ["Xu", "Yinghui", ""], ["Yin", "Wotao", ""]]}, {"id": "2104.11984", "submitter": "Ilaria Manco", "authors": "Ilaria Manco, Emmanouil Benetos, Elio Quinton, Gyorgy Fazekas", "title": "MusCaps: Generating Captions for Music Audio", "comments": "Accepted to IJCNN 2021 for the Special Session on Representation\n  Learning for Audio, Speech, and Music Processing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.CL cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Content-based music information retrieval has seen rapid progress with the\nadoption of deep learning. Current approaches to high-level music description\ntypically make use of classification models, such as in auto-tagging or genre\nand mood classification. In this work, we propose to address music description\nvia audio captioning, defined as the task of generating a natural language\ndescription of music audio content in a human-like manner. To this end, we\npresent the first music audio captioning model, MusCaps, consisting of an\nencoder-decoder with temporal attention. Our method combines convolutional and\nrecurrent neural network architectures to jointly process audio-text inputs\nthrough a multimodal encoder and leverages pre-training on audio data to obtain\nrepresentations that effectively capture and summarise musical features in the\ninput. Evaluation of the generated captions through automatic metrics shows\nthat our method outperforms a baseline designed for non-music audio captioning.\nThrough an ablation study, we unveil that this performance boost can be mainly\nattributed to pre-training of the audio encoder, while other design choices -\nmodality fusion, decoding strategy and the use of attention - contribute only\nmarginally. Our model represents a shift away from classification-based music\ndescription and combines tasks requiring both auditory and linguistic\nunderstanding to bridge the semantic gap in music information retrieval.\n", "versions": [{"version": "v1", "created": "Sat, 24 Apr 2021 16:34:47 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Manco", "Ilaria", ""], ["Benetos", "Emmanouil", ""], ["Quinton", "Elio", ""], ["Fazekas", "Gyorgy", ""]]}, {"id": "2104.12000", "submitter": "Hadi Jahanshahi", "authors": "Hadi Jahanshahi, Aysun Bozanta, Mucahit Cevik, Eray Mert Kavuk,\n  Ay\\c{s}e Tosun, Sibel B. Sonuc, Bilgin Kosucu, Ay\\c{s}e Ba\\c{s}ar", "title": "A Deep Reinforcement Learning Approach for the Meal Delivery Problem", "comments": "Keywords: meal delivery, courier assignment, reinforcement learning,\n  DQN, DDQN", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a meal delivery service fulfilling dynamic customer requests\ngiven a set of couriers over the course of a day. A courier's duty is to\npick-up an order from a restaurant and deliver it to a customer. We model this\nservice as a Markov decision process and use deep reinforcement learning as the\nsolution approach. We experiment with the resulting policies on synthetic and\nreal-world datasets and compare those with the baseline policies. We also\nexamine the courier utilization for different numbers of couriers. In our\nanalysis, we specifically focus on the impact of the limited available\nresources in the meal delivery problem. Furthermore, we investigate the effect\nof intelligent order rejection and re-positioning of the couriers. Our\nnumerical experiments show that, by incorporating the geographical locations of\nthe restaurants, customers, and the depot, our model significantly improves the\noverall service quality as characterized by the expected total reward and the\ndelivery times. Our results present valuable insights on both the courier\nassignment process and the optimal number of couriers for different order\nfrequencies on a given day. The proposed model also shows a robust performance\nunder a variety of scenarios for real-world implementation.\n", "versions": [{"version": "v1", "created": "Sat, 24 Apr 2021 19:01:59 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Jahanshahi", "Hadi", ""], ["Bozanta", "Aysun", ""], ["Cevik", "Mucahit", ""], ["Kavuk", "Eray Mert", ""], ["Tosun", "Ay\u015fe", ""], ["Sonuc", "Sibel B.", ""], ["Kosucu", "Bilgin", ""], ["Ba\u015far", "Ay\u015fe", ""]]}, {"id": "2104.12001", "submitter": "Hadi Jahanshahi", "authors": "Hadi Jahanshahi, Mucahit Cevik, Ay\\c{s}e Ba\\c{s}ar", "title": "Predicting the Number of Reported Bugs in a Software Repository", "comments": null, "journal-ref": "Canadian AI 2020: Advances in Artificial Intelligence pp 309-320", "doi": "10.1007/978-3-030-47358-7_31", "report-no": null, "categories": "cs.SE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The bug growth pattern prediction is a complicated, unrelieved task, which\nneeds considerable attention. Advance knowledge of the likely number of bugs\ndiscovered in the software system helps software developers in designating\nsufficient resources at a convenient time. The developers may also use such\ninformation to take necessary actions to increase the quality of the system and\nin turn customer satisfaction. In this study, we examine eight different time\nseries forecasting models, including Long Short Term Memory Neural Networks\n(LSTM), auto-regressive integrated moving average (ARIMA), and Random Forest\nRegressor. Further, we assess the impact of exogenous variables such as\nsoftware release dates by incorporating those into the prediction models. We\nanalyze the quality of long-term prediction for each model based on different\nperformance metrics. The assessment is conducted on Mozilla, which is a large\nopen-source software application. The dataset is originally mined from Bugzilla\nand contains the number of bugs for the project between Jan 2010 and Dec 2019.\nOur numerical analysis provides insights on evaluating the trends in a bug\nrepository. We observe that LSTM is effective when considering long-run\npredictions whereas Random Forest Regressor enriched by exogenous variables\nperforms better for predicting the number of bugs in the short term.\n", "versions": [{"version": "v1", "created": "Sat, 24 Apr 2021 19:06:35 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Jahanshahi", "Hadi", ""], ["Cevik", "Mucahit", ""], ["Ba\u015far", "Ay\u015fe", ""]]}, {"id": "2104.12021", "submitter": "Debaditya Chakraborty", "authors": "Debaditya Chakraborty, Cristina Ivan, Paola Amero, Maliha Khan,\n  Cristian Rodriguez-Aguayo, Hakan Ba\\c{s}a\\u{g}ao\\u{g}lu, and Gabriel\n  Lopez-Berestein", "title": "Explainable Artificial Intelligence Reveals Novel Insight into Tumor\n  Microenvironment Conditions Linked with Better Prognosis in Patients with\n  Breast Cancer", "comments": "14 pages, 5 figures, preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.GN cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We investigated the data-driven relationship between features in the tumor\nmicroenvironment (TME) and the overall and 5-year survival in triple-negative\nbreast cancer (TNBC) and non-TNBC (NTNBC) patients by using Explainable\nArtificial Intelligence (XAI) models. We used clinical information from\npatients with invasive breast carcinoma from The Cancer Genome Atlas and from\ntwo studies from the cbioPortal, the PanCanAtlas project and the GDAC Firehose\nstudy. In this study, we used a normalized RNA sequencing data-driven cohort\nfrom 1,015 breast cancer patients, alive or deceased, from the UCSC Xena data\nset and performed integrated deconvolution with the EPIC method to estimate the\npercentage of seven different immune and stromal cells from RNA sequencing\ndata. Novel insights derived from our XAI model showed that CD4+ T cells and B\ncells are more critical than other TME features for enhanced prognosis for both\nTNBC and NTNBC patients. Our XAI model revealed the critical inflection points\n(i.e., threshold fractions) of CD4+ T cells and B cells above or below which\n5-year survival rates improve. Subsequently, we ascertained the conditional\nprobabilities of $\\geq$ 5-year survival in both TNBC and NTNBC patients under\nspecific conditions inferred from the inflection points. In particular, the XAI\nmodels revealed that a B-cell fraction exceeding 0.018 in the TME could ensure\n100% 5-year survival for NTNBC patients. The findings from this research could\nlead to more accurate clinical predictions and enhanced immunotherapies and to\nthe design of innovative strategies to reprogram the TME of breast cancer\npatients.\n", "versions": [{"version": "v1", "created": "Sat, 24 Apr 2021 20:50:41 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Chakraborty", "Debaditya", ""], ["Ivan", "Cristina", ""], ["Amero", "Paola", ""], ["Khan", "Maliha", ""], ["Rodriguez-Aguayo", "Cristian", ""], ["Ba\u015fa\u011fao\u011flu", "Hakan", ""], ["Lopez-Berestein", "Gabriel", ""]]}, {"id": "2104.12031", "submitter": "Yuetian Luo", "authors": "Yuetian Luo, Anru R. Zhang", "title": "Low-rank Tensor Estimation via Riemannian Gauss-Newton: Statistical\n  Optimality and Second-Order Convergence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.NA math.NA math.OC stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider the estimation of a low Tucker rank tensor from a\nnumber of noisy linear measurements. The general problem covers many specific\nexamples arising from applications, including tensor regression, tensor\ncompletion, and tensor PCA/SVD. We propose a Riemannian Gauss-Newton (RGN)\nmethod with fast implementations for low Tucker rank tensor estimation.\nDifferent from the generic (super)linear convergence guarantee of RGN in the\nliterature, we prove the first quadratic convergence guarantee of RGN for\nlow-rank tensor estimation under some mild conditions. A deterministic\nestimation error lower bound, which matches the upper bound, is provided that\ndemonstrates the statistical optimality of RGN. The merit of RGN is illustrated\nthrough two machine learning applications: tensor regression and tensor SVD.\nFinally, we provide the simulation results to corroborate our theoretical\nfindings.\n", "versions": [{"version": "v1", "created": "Sat, 24 Apr 2021 22:24:14 GMT"}, {"version": "v2", "created": "Tue, 27 Apr 2021 04:01:36 GMT"}], "update_date": "2021-04-28", "authors_parsed": [["Luo", "Yuetian", ""], ["Zhang", "Anru R.", ""]]}, {"id": "2104.12036", "submitter": "Ruimeng Hu", "authors": "Jiequn Han, Ruimeng Hu, Jihao Long", "title": "A Class of Dimensionality-free Metrics for the Convergence of Empirical\n  Measures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper concerns the convergence of empirical measures in high dimensions.\nWe propose a new class of metrics and show that under such metrics, the\nconvergence is free of the curse of dimensionality (CoD). Such a feature is\ncritical for high-dimensional analysis and stands in contrast to classical\nmetrics ({\\it e.g.}, the Wasserstein distance). The proposed metrics originate\nfrom the maximum mean discrepancy, which we generalize by proposing specific\ncriteria for selecting test function spaces to guarantee the property of being\nfree of CoD. Therefore, we call this class of metrics the generalized maximum\nmean discrepancy (GMMD). Examples of the selected test function spaces include\nthe reproducing kernel Hilbert space, Barron space, and flow-induced function\nspaces. Three applications of the proposed metrics are presented: 1. The\nconvergence of empirical measure in the case of random variables; 2. The\nconvergence of $n$-particle system to the solution to McKean-Vlasov stochastic\ndifferential equation; 3. The construction of an $\\varepsilon$-Nash equilibrium\nfor a homogeneous $n$-player game by its mean-field limit. As a byproduct, we\nprove that, given a distribution close to the target distribution measured by\nGMMD and a certain representation of the target distribution, we can generate a\ndistribution close to the target one in terms of the Wasserstein distance and\nrelative entropy. Overall, we show that the proposed class of metrics is a\npowerful tool to analyze the convergence of empirical measures in high\ndimensions without CoD.\n", "versions": [{"version": "v1", "created": "Sat, 24 Apr 2021 23:27:40 GMT"}, {"version": "v2", "created": "Tue, 27 Apr 2021 16:42:46 GMT"}], "update_date": "2021-04-28", "authors_parsed": [["Han", "Jiequn", ""], ["Hu", "Ruimeng", ""], ["Long", "Jihao", ""]]}, {"id": "2104.12040", "submitter": "Mohammed Amer", "authors": "Mohammed Amer, Tom\\'as Maul, Iman Yi Liao", "title": "Balancing Accuracy and Latency in Multipath Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The growing capacity of neural networks has strongly contributed to their\nsuccess at complex machine learning tasks and the computational demand of such\nlarge models has, in turn, stimulated a significant improvement in the hardware\nnecessary to accelerate their computations. However, models with high latency\naren't suitable for limited-resource environments such as hand-held and IoT\ndevices. Hence, many deep learning techniques aim to address this problem by\ndeveloping models with reasonable accuracy without violating the\nlimited-resource constraint. In this work, we use a one-shot neural\narchitecture search model to implicitly evaluate the performance of an\nintractable number of multipath neural networks. Combining this architecture\nsearch with a pruning technique and architecture sample evaluation, we can\nmodel the relation between the accuracy and the latency of a spectrum of models\nwith graded complexity. We show that our method can accurately model the\nrelative performance between models with different latencies and predict the\nperformance of unseen models with good precision across different datasets.\n", "versions": [{"version": "v1", "created": "Sun, 25 Apr 2021 00:05:48 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Amer", "Mohammed", ""], ["Maul", "Tom\u00e1s", ""], ["Liao", "Iman Yi", ""]]}, {"id": "2104.12044", "submitter": "Xiaowei Xu", "authors": "Xiaowe Xu, Jiawei Zhang, Jinglan Liu, Yukun Ding, Tianchen Wang,\n  Hailong Qiu, Haiyun Yuan, Jian Zhuang, and Wen Xie, Yuhao Dong, Qianjun Jia,\n  Meiping Huang, Yiyu Shi", "title": "Multi-Cycle-Consistent Adversarial Networks for Edge Denoising of\n  Computed Tomography Images", "comments": "16 pages, 7 figures, 4 tables, accepted by the ACM Journal on\n  Emerging Technologies in Computing Systems (JETC). arXiv admin note:\n  substantial text overlap with arXiv:2002.12130", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As one of the most commonly ordered imaging tests, computed tomography (CT)\nscan comes with inevitable radiation exposure that increases the cancer risk to\npatients. However, CT image quality is directly related to radiation dose, thus\nit is desirable to obtain high-quality CT images with as little dose as\npossible. CT image denoising tries to obtain high dose like high-quality CT\nimages (domain X) from low dose low-quality CTimages (domain Y), which can be\ntreated as an image-to-image translation task where the goal is to learn the\ntransform between a source domain X (noisy images) and a target domain Y (clean\nimages). In this paper, we propose a multi-cycle-consistent adversarial network\n(MCCAN) that builds intermediate domains and enforces both local and global\ncycle-consistency for edge denoising of CT images. The global cycle-consistency\ncouples all generators together to model the whole denoising process, while the\nlocal cycle-consistency imposes effective supervision on the process between\nadjacent domains. Experiments show that both local and global cycle-consistency\nare important for the success of MCCAN, which outperformsCCADN in terms of\ndenoising quality with slightly less computation resource consumption.\n", "versions": [{"version": "v1", "created": "Sun, 25 Apr 2021 01:53:46 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Xu", "Xiaowe", ""], ["Zhang", "Jiawei", ""], ["Liu", "Jinglan", ""], ["Ding", "Yukun", ""], ["Wang", "Tianchen", ""], ["Qiu", "Hailong", ""], ["Yuan", "Haiyun", ""], ["Zhuang", "Jian", ""], ["Xie", "Wen", ""], ["Dong", "Yuhao", ""], ["Jia", "Qianjun", ""], ["Huang", "Meiping", ""], ["Shi", "Yiyu", ""]]}, {"id": "2104.12047", "submitter": "Mengxue Zhang", "authors": "Mengxue Zhang, Zichao Wang, Richard Baraniuk, Andrew Lan", "title": "Math Operation Embeddings for Open-ended Solution Analysis and Feedback", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Feedback on student answers and even during intermediate steps in their\nsolutions to open-ended questions is an important element in math education.\nSuch feedback can help students correct their errors and ultimately lead to\nimproved learning outcomes. Most existing approaches for automated student\nsolution analysis and feedback require manually constructing cognitive models\nand anticipating student errors for each question. This process requires\nsignificant human effort and does not scale to most questions used in homework\nand practices that do not come with this information. In this paper, we analyze\nstudents' step-by-step solution processes to equation solving questions in an\nattempt to scale up error diagnostics and feedback mechanisms developed for a\nsmall number of questions to a much larger number of questions. Leveraging a\nrecent math expression encoding method, we represent each math operation\napplied in solution steps as a transition in the math embedding vector space.\nWe use a dataset that contains student solution steps in the Cognitive Tutor\nsystem to learn implicit and explicit representations of math operations. We\nexplore whether these representations can i) identify math operations a student\nintends to perform in each solution step, regardless of whether they did it\ncorrectly or not, and ii) select the appropriate feedback type for incorrect\nsteps. Experimental results show that our learned math operation\nrepresentations generalize well across different data distributions.\n", "versions": [{"version": "v1", "created": "Sun, 25 Apr 2021 02:09:17 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Zhang", "Mengxue", ""], ["Wang", "Zichao", ""], ["Baraniuk", "Richard", ""], ["Lan", "Andrew", ""]]}, {"id": "2104.12053", "submitter": "Adji Bousso Dieng", "authors": "Adji B. Dieng", "title": "Deep Probabilistic Graphical Modeling", "comments": "This thesis was defended in April 2020 and accepted without revision.\n  The author received her PhD in Statistics from Columbia University on May 20,\n  2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Probabilistic graphical modeling (PGM) provides a framework for formulating\nan interpretable generative process of data and expressing uncertainty about\nunknowns, but it lacks flexibility. Deep learning (DL) is an alternative\nframework for learning from data that has achieved great empirical success in\nrecent years. DL offers great flexibility, but it lacks the interpretability\nand calibration of PGM. This thesis develops deep probabilistic graphical\nmodeling (DPGM.) DPGM consists in leveraging DL to make PGM more flexible. DPGM\nbrings about new methods for learning from data that exhibit the advantages of\nboth PGM and DL.\n  We use DL within PGM to build flexible models endowed with an interpretable\nlatent structure. One model class we develop extends exponential family PCA\nusing neural networks to improve predictive performance while enforcing the\ninterpretability of the latent factors. Another model class we introduce\nenables accounting for long-term dependencies when modeling sequential data,\nwhich is a challenge when using purely DL or PGM approaches. Finally, DPGM\nsuccessfully solves several outstanding problems of probabilistic topic models,\na widely used family of models in PGM.\n  DPGM also brings about new algorithms for learning with complex data. We\ndevelop reweighted expectation maximization, an algorithm that unifies several\nexisting maximum likelihood-based algorithms for learning models parameterized\nby neural networks. This unifying view is made possible using expectation\nmaximization, a canonical inference algorithm in PGM. We also develop\nentropy-regularized adversarial learning, a learning paradigm that deviates\nfrom the traditional maximum likelihood approach used in PGM. From the DL\nperspective, entropy-regularized adversarial learning provides a solution to\nthe long-standing mode collapse problem of generative adversarial networks, a\nwidely used DL approach.\n", "versions": [{"version": "v1", "created": "Sun, 25 Apr 2021 03:48:02 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Dieng", "Adji B.", ""]]}, {"id": "2104.12055", "submitter": "Md Easin Hasan", "authors": "Fahad B. Mostafa and Md Easin Hasan", "title": "Machine Learning Approaches for Binary Classification to Discover Liver\n  Diseases using Clinical Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  For a medical diagnosis, health professionals use different kinds of\npathological ways to make a decision for medical reports in terms of patients\nmedical condition. In the modern era, because of the advantage of computers and\ntechnologies, one can collect data and visualize many hidden outcomes from\nthem. Statistical machine learning algorithms based on specific problems can\nassist one to make decisions. Machine learning data driven algorithms can be\nused to validate existing methods and help researchers to suggest potential new\ndecisions. In this paper, multiple imputation by chained equations was applied\nto deal with missing data, and Principal Component Analysis to reduce the\ndimensionality. To reveal significant findings, data visualizations were\nimplemented. We presented and compared many binary classifier machine learning\nalgorithms (Artificial Neural Network, Random Forest, Support Vector Machine)\nwhich were used to classify blood donors and non-blood donors with hepatitis,\nfibrosis and cirrhosis diseases. From the data published in UCI-MLR [1], all\nmentioned techniques were applied to find one better method to classify blood\ndonors and non-blood donors (hepatitis, fibrosis, and cirrhosis) that can help\nhealth professionals in a laboratory to make better decisions. Our proposed\nML-method showed better accuracy score (e.g. 98.23% for SVM). Thus, it improved\nthe quality of classification.\n", "versions": [{"version": "v1", "created": "Sun, 25 Apr 2021 04:10:19 GMT"}, {"version": "v2", "created": "Sat, 5 Jun 2021 19:34:28 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Mostafa", "Fahad B.", ""], ["Hasan", "Md Easin", ""]]}, {"id": "2104.12081", "submitter": "Dapeng Hu", "authors": "Dapeng Hu, Qizhengqiu Lu, Lanqing Hong, Hailin Hu, Yifan Zhang,\n  Zhenguo Li, Alfred Shen, Jiashi Feng", "title": "How Well Self-Supervised Pre-Training Performs with Streaming Data?", "comments": "16 pages; 16figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The common self-supervised pre-training practice requires collecting massive\nunlabeled data together and then trains a representation model, dubbed\n\\textbf{joint training}. However, in real-world scenarios where data are\ncollected in a streaming fashion, the joint training scheme is usually\nstorage-heavy and time-consuming. A more efficient alternative is to train a\nmodel continually with streaming data, dubbed \\textbf{sequential training}.\nNevertheless, it is unclear how well sequential self-supervised pre-training\nperforms with streaming data. In this paper, we conduct thorough experiments to\ninvestigate self-supervised pre-training with streaming data. Specifically, we\nevaluate the transfer performance of sequential self-supervised pre-training\nwith four different data sequences on three different downstream tasks and make\ncomparisons with joint self-supervised pre-training. Surprisingly, we find\nsequential self-supervised learning exhibits almost the same performance as the\njoint training when the distribution shifts within streaming data are mild.\nEven for data sequences with large distribution shifts, sequential\nself-supervised training with simple techniques, e.g., parameter regularization\nor data replay, still performs comparably to joint training. Based on our\nfindings, we recommend using sequential self-supervised training as a\n\\textbf{more efficient yet performance-competitive} representation learning\npractice for real-world applications.\n", "versions": [{"version": "v1", "created": "Sun, 25 Apr 2021 06:56:48 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Hu", "Dapeng", ""], ["Lu", "Qizhengqiu", ""], ["Hong", "Lanqing", ""], ["Hu", "Hailin", ""], ["Zhang", "Yifan", ""], ["Li", "Zhenguo", ""], ["Shen", "Alfred", ""], ["Feng", "Jiashi", ""]]}, {"id": "2104.12086", "submitter": "Chen Zhao", "authors": "Chen Zhao, Zhipeng Gao, Qian Wang, Kaile Xiao, Zijia Mo, M. Jamal Deen", "title": "FedSup: A Communication-Efficient Federated Learning Fatigue Driving\n  Behaviors Supervision Framework", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the proliferation of edge smart devices and the Internet of Vehicles\n(IoV) technologies, intelligent fatigue detection has become one of the\nmost-used methods in our daily driving. To improve the performance of the\ndetection model, a series of techniques have been developed. However, existing\nwork still leaves much to be desired, such as privacy disclosure and\ncommunication cost. To address these issues, we propose FedSup, a\nclient-edge-cloud framework for privacy and efficient fatigue detection.\nInspired by the federated learning technique, FedSup intelligently utilizes the\ncollaboration between client, edge, and cloud server to realizing dynamic model\noptimization while protecting edge data privacy. Moreover, to reduce the\nunnecessary system communication overhead, we further propose a Bayesian\nconvolutional neural network (BCNN) approximation strategy on the clients and\nan uncertainty weighted aggregation algorithm on the cloud to enhance the\ncentral model training efficiency. Extensive experiments demonstrate that the\nFedSup framework is suitable for IoV scenarios and outperforms other mainstream\nmethods.\n", "versions": [{"version": "v1", "created": "Sun, 25 Apr 2021 07:16:49 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Zhao", "Chen", ""], ["Gao", "Zhipeng", ""], ["Wang", "Qian", ""], ["Xiao", "Kaile", ""], ["Mo", "Zijia", ""], ["Deen", "M. Jamal", ""]]}, {"id": "2104.12103", "submitter": "Louis-Serge Bouchard", "authors": "Khalid Youssef, Greg Schuette, Yubin Cai, Daisong Zhang, Yikun Huang,\n  Yahya Rahmat-Samii, Louis-S. Bouchard", "title": "Scalable End-to-End RF Classification: A Case Study on Undersized\n  Dataset Regularization by Convolutional-MST", "comments": "12 pages, 14 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Unlike areas such as computer vision and speech recognition where\nconvolutional and recurrent neural networks-based approaches have proven\neffective to the nature of the respective areas of application, deep learning\n(DL) still lacks a general approach suitable for the unique nature and\nchallenges of RF systems such as radar, signals intelligence, electronic\nwarfare, and communications. Existing approaches face problems in robustness,\nconsistency, efficiency, repeatability and scalability. One of the main\nchallenges in RF sensing such as radar target identification is the difficulty\nand cost of obtaining data. Hundreds to thousands of samples per class are\ntypically used when training for classifying signals into 2 to 12 classes with\nreported accuracy ranging from 87% to 99%, where accuracy generally decreases\nwith more classes added. In this paper, we present a new DL approach based on\nmultistage training and demonstrate it on RF sensing signal classification. We\nconsistently achieve over 99% accuracy for up to 17 diverse classes using only\n11 samples per class for training, yielding up to 35% improvement in accuracy\nover standard DL approaches.\n", "versions": [{"version": "v1", "created": "Sun, 25 Apr 2021 08:41:52 GMT"}, {"version": "v2", "created": "Thu, 13 May 2021 08:44:15 GMT"}], "update_date": "2021-05-14", "authors_parsed": [["Youssef", "Khalid", ""], ["Schuette", "Greg", ""], ["Cai", "Yubin", ""], ["Zhang", "Daisong", ""], ["Huang", "Yikun", ""], ["Rahmat-Samii", "Yahya", ""], ["Bouchard", "Louis-S.", ""]]}, {"id": "2104.12112", "submitter": "Xinmeng Huang", "authors": "Xinmeng Huang, Kun Yuan, Xianghui Mao, Wotao Yin", "title": "On the Comparison between Cyclic Sampling and Random Reshuffling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When applying a stochastic/incremental algorithm, one must choose the order\nto draw samples. Among the most popular approaches are cyclic sampling and\nrandom reshuffling, which are empirically faster and more cache-friendly than\nuniform-iid-sampling. Cyclic sampling draws the samples in a fixed, cyclic\norder, which is less robust than reshuffling the samples periodically. Indeed,\nexisting works have established worst case convergence rates for cyclic\nsampling, which are generally worse than that of random reshuffling. In this\npaper, however, we found a certain cyclic order can be much faster than\nreshuffling and one can discover it at a low cost!\n  Studying and comparing different sampling orders typically require new\nanalytic techniques. In this paper, we introduce a norm, which is defined based\non the sampling order, to measure the distance to solution. Applying this\ntechnique on proximal Finito/MISO algorithm allows us to identify the optimal\nfixed ordering, which can beat random reshuffling by a factor up to log(n)/n in\nterms of the best-known upper bounds. We also propose a strategy to discover\nthe optimal fixed ordering numerically. The established rates are\nstate-of-the-art compared to previous works.\n", "versions": [{"version": "v1", "created": "Sun, 25 Apr 2021 09:29:43 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Huang", "Xinmeng", ""], ["Yuan", "Kun", ""], ["Mao", "Xianghui", ""], ["Yin", "Wotao", ""]]}, {"id": "2104.12116", "submitter": "Tai Le Quy", "authors": "Tai Le Quy, Arjun Roy, Gunnar Friege and Eirini Ntoutsi", "title": "Fair-Capacitated Clustering", "comments": "10 pages, 5 figures, 14th International Conference on Educational\n  Data Mining - EDM 2021 (short paper)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Traditionally, clustering algorithms focus on partitioning the data into\ngroups of similar instances. The similarity objective, however, is not\nsufficient in applications where a fair-representation of the groups in terms\nof protected attributes like gender or race, is required for each cluster.\nMoreover, in many applications, to make the clusters useful for the end-user, a\nbalanced cardinality among the clusters is required. Our motivation comes from\nthe education domain where studies indicate that students might learn better in\ndiverse student groups and of course groups of similar cardinality are more\npractical e.g., for group assignments. To this end, we introduce the\nfair-capacitated clustering problem that partitions the data into clusters of\nsimilar instances while ensuring cluster fairness and balancing cluster\ncardinalities. We propose a two-step solution to the problem: i) we rely on\nfairlets to generate minimal sets that satisfy the fair constraint and ii) we\npropose two approaches, namely hierarchical clustering and partitioning-based\nclustering, to obtain the fair-capacitated clustering. The hierarchical\napproach embeds the additional cardinality requirements during the merging step\nwhile the partitioning-based one alters the assignment step using a knapsack\nproblem formulation to satisfy the additional requirements. Our experiments on\nfour educational datasets show that our approaches deliver well-balanced\nclusters in terms of both fairness and cardinality while maintaining a good\nclustering quality.\n", "versions": [{"version": "v1", "created": "Sun, 25 Apr 2021 09:39:39 GMT"}, {"version": "v2", "created": "Wed, 28 Apr 2021 07:24:28 GMT"}], "update_date": "2021-04-29", "authors_parsed": [["Quy", "Tai Le", ""], ["Roy", "Arjun", ""], ["Friege", "Gunnar", ""], ["Ntoutsi", "Eirini", ""]]}, {"id": "2104.12125", "submitter": "Anjukan Kathirgamanathan", "authors": "Anjukan Kathirgamanathan, Eleni Mangina, Donal P. Finn", "title": "Development of a Soft Actor Critic Deep Reinforcement Learning Approach\n  for Harnessing Energy Flexibility in a Large Office Building", "comments": "submitted to Energy and AI", "journal-ref": null, "doi": "10.1016/j.egyai.2021.100101", "report-no": null, "categories": "cs.LG cs.SY eess.SY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This research is concerned with the novel application and investigation of\n`Soft Actor Critic' (SAC) based Deep Reinforcement Learning (DRL) to control\nthe cooling setpoint (and hence cooling loads) of a large commercial building\nto harness energy flexibility. The research is motivated by the challenge\nassociated with the development and application of conventional model-based\ncontrol approaches at scale to the wider building stock. SAC is a model-free\nDRL technique that is able to handle continuous action spaces and which has\nseen limited application to real-life or high-fidelity simulation\nimplementations in the context of automated and intelligent control of building\nenergy systems. Such control techniques are seen as one possible solution to\nsupporting the operation of a smart, sustainable and future electrical grid.\nThis research tests the suitability of the SAC DRL technique through training\nand deployment of the agent on an EnergyPlus based environment of the office\nbuilding. The SAC DRL was found to learn an optimal control policy that was\nable to minimise energy costs by 9.7% compared to the default rule-based\ncontrol (RBC) scheme and was able to improve or maintain thermal comfort limits\nover a test period of one week. The algorithm was shown to be robust to the\ndifferent hyperparameters and this optimal control policy was learnt through\nthe use of a minimal state space consisting of readily available variables. The\nrobustness of the algorithm was tested through investigation of the speed of\nlearning and ability to deploy to different seasons and climates. It was found\nthat the SAC DRL requires minimal training sample points and outperforms the\nRBC after three months of operation and also without disruption to thermal\ncomfort during this period. The agent is transferable to other climates and\nseasons although further retraining or hyperparameter tuning is recommended.\n", "versions": [{"version": "v1", "created": "Sun, 25 Apr 2021 10:33:35 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Kathirgamanathan", "Anjukan", ""], ["Mangina", "Eleni", ""], ["Finn", "Donal P.", ""]]}, {"id": "2104.12138", "submitter": "Yukun Zhou", "authors": "Yukun Zhou, Moucheng Xu, Yipeng Hu, Hongxiang Lin, Joseph Jacob,\n  Pearse Keane, Daniel Alexander", "title": "Learning to Address Intra-segment Misclassification in Retinal Imaging", "comments": "10 pages, 5 figures, and 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurate multi-class segmentation is a long-standing challenge in medical\nimaging, especially in scenarios where classes share strong similarity.\nSegmenting retinal blood vessels in retinal photographs is one such scenario,\nin which arteries and veins need to be identified and differentiated from each\nother and from the background. Intra-segment misclassification, i.e. veins\nclassified as arteries or vice versa, frequently occurs when arteries and veins\nintersect, whereas in binary retinal vessel segmentation, error rates are much\nlower. We thus propose a new approach that decomposes multi-class segmentation\ninto multiple binary, followed by a binary-to-multi-class fusion network. The\nnetwork merges representations of artery, vein, and multi-class feature maps,\neach of which are supervised by expert vessel annotation in adversarial\ntraining. A skip-connection based merging process explicitly maintains\nclass-specific gradients to avoid gradient vanishing in deep layers, to favor\nthe discriminative features. The results show that, our model respectively\nimproves F1-score by 4.4\\%, 5.1\\%, and 4.2\\% compared with three\nstate-of-the-art deep learning based methods on DRIVE-AV, LES-AV, and HRF-AV\ndata sets.\n", "versions": [{"version": "v1", "created": "Sun, 25 Apr 2021 11:57:26 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Zhou", "Yukun", ""], ["Xu", "Moucheng", ""], ["Hu", "Yipeng", ""], ["Lin", "Hongxiang", ""], ["Jacob", "Joseph", ""], ["Keane", "Pearse", ""], ["Alexander", "Daniel", ""]]}, {"id": "2104.12149", "submitter": "Xiao Ma", "authors": "Xiao Ma, David Hsu, Wee Sun Lee", "title": "Learning Latent Graph Dynamics for Deformable Object Manipulation", "comments": "14 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Manipulating deformable objects, such as cloth and ropes, is a long-standing\nchallenge in robotics: their large number of degrees of freedom (DoFs) and\ncomplex non-linear dynamics make motion planning extremely difficult. This work\naims to learn latent Graph dynamics for DefOrmable Object Manipulation\n(G-DOOM). To tackle the challenge of many DoFs and complex dynamics, G-DOOM\napproximates a deformable object as a sparse set of interacting keypoints and\nlearns a graph neural network that captures abstractly the geometry and\ninteraction dynamics of the keypoints. Further, to tackle the perceptual\nchallenge, specifically, object self-occlusion, G-DOOM adds a recurrent neural\nnetwork to track the keypoints over time and condition their interactions on\nthe history. We then train the resulting recurrent graph dynamics model through\ncontrastive learning in a high-fidelity simulator. For manipulation planning,\nG-DOOM explicitly reasons about the learned dynamics model through\nmodel-predictive control applied at each of the keypoints. We evaluate G-DOOM\non a set of challenging cloth and rope manipulation tasks and show that G-DOOM\noutperforms a state-of-the-art method. Further, although trained entirely on\nsimulation data, G-DOOM transfers directly to a real robot for both cloth and\nrope manipulation in our experiments.\n", "versions": [{"version": "v1", "created": "Sun, 25 Apr 2021 13:06:02 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Ma", "Xiao", ""], ["Hsu", "David", ""], ["Lee", "Wee Sun", ""]]}, {"id": "2104.12159", "submitter": "Swagatam Das", "authors": "Sandipan Dhar, Nanda Dulal Jana, Swagatam Das", "title": "An Adaptive Learning based Generative Adversarial Network for One-To-One\n  Voice Conversion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Voice Conversion (VC) emerged as a significant domain of research in the\nfield of speech synthesis in recent years due to its emerging application in\nvoice-assisting technology, automated movie dubbing, and speech-to-singing\nconversion to name a few. VC basically deals with the conversion of vocal style\nof one speaker to another speaker while keeping the linguistic contents\nunchanged. VC task is performed through a three-stage pipeline consisting of\nspeech analysis, speech feature mapping, and speech reconstruction. Nowadays\nthe Generative Adversarial Network (GAN) models are widely in use for speech\nfeature mapping from source to target speaker. In this paper, we propose an\nadaptive learning-based GAN model called ALGAN-VC for an efficient one-to-one\nVC of speakers. Our ALGAN-VC framework consists of some approaches to improve\nthe speech quality and voice similarity between source and target speakers. The\nmodel incorporates a Dense Residual Network (DRN) like architecture to the\ngenerator network for efficient speech feature learning, for source to target\nspeech feature conversion. We also integrate an adaptive learning mechanism to\ncompute the loss function for the proposed model. Moreover, we use a boosted\nlearning rate approach to enhance the learning capability of the proposed\nmodel. The model is trained by using both forward and inverse mapping\nsimultaneously for a one-to-one VC. The proposed model is tested on Voice\nConversion Challenge (VCC) 2016, 2018, and 2020 datasets as well as on our\nself-prepared speech dataset, which has been recorded in Indian regional\nlanguages and in English. A subjective and objective evaluation of the\ngenerated speech samples indicated that the proposed model elegantly performed\nthe voice conversion task by achieving high speaker similarity and adequate\nspeech quality.\n", "versions": [{"version": "v1", "created": "Sun, 25 Apr 2021 13:44:32 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Dhar", "Sandipan", ""], ["Jana", "Nanda Dulal", ""], ["Das", "Swagatam", ""]]}, {"id": "2104.12174", "submitter": "Ivan Y. Tyukin", "authors": "Ivan Y. Tyukin, Alexander N. Gorban, Muhammad H. Alkhudaydi, Qinghua\n  Zhou", "title": "Demystification of Few-shot and One-shot Learning", "comments": "IEEE International Joint Conference on Neural Networks, IJCNN 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.ST stat.TH", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Few-shot and one-shot learning have been the subject of active and intensive\nresearch in recent years, with mounting evidence pointing to successful\nimplementation and exploitation of few-shot learning algorithms in practice.\nClassical statistical learning theories do not fully explain why few- or\none-shot learning is at all possible since traditional generalisation bounds\nnormally require large training and testing samples to be meaningful. This\nsharply contrasts with numerous examples of successful one- and few-shot\nlearning systems and applications.\n  In this work we present mathematical foundations for a theory of one-shot and\nfew-shot learning and reveal conditions specifying when such learning schemes\nare likely to succeed. Our theory is based on intrinsic properties of\nhigh-dimensional spaces. We show that if the ambient or latent decision space\nof a learning machine is sufficiently high-dimensional than a large class of\nobjects in this space can indeed be easily learned from few examples provided\nthat certain data non-concentration conditions are met.\n", "versions": [{"version": "v1", "created": "Sun, 25 Apr 2021 14:47:05 GMT"}, {"version": "v2", "created": "Sat, 29 May 2021 12:25:59 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Tyukin", "Ivan Y.", ""], ["Gorban", "Alexander N.", ""], ["Alkhudaydi", "Muhammad H.", ""], ["Zhou", "Qinghua", ""]]}, {"id": "2104.12199", "submitter": "Joshua N. Cooper", "authors": "Rory Mitchell, Joshua Cooper, Eibe Frank, Geoffrey Holmes", "title": "Sampling Permutations for Shapley Value Estimation", "comments": "33 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.CO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Game-theoretic attribution techniques based on Shapley values are used\nextensively to interpret black-box machine learning models, but their exact\ncalculation is generally NP-hard, requiring approximation methods for\nnon-trivial models. As the computation of Shapley values can be expressed as a\nsummation over a set of permutations, a common approach is to sample a subset\nof these permutations for approximation. Unfortunately, standard Monte Carlo\nsampling methods can exhibit slow convergence, and more sophisticated quasi\nMonte Carlo methods are not well defined on the space of permutations. To\naddress this, we investigate new approaches based on two classes of\napproximation methods and compare them empirically. First, we demonstrate\nquadrature techniques in a RKHS containing functions of permutations, using the\nMallows kernel to obtain explicit convergence rates of $O(1/n)$, improving on\n$O(1/\\sqrt{n})$ for plain Monte Carlo. The RKHS perspective also leads to quasi\nMonte Carlo type error bounds, with a tractable discrepancy measure defined on\npermutations. Second, we exploit connections between the hypersphere\n$\\mathbb{S}^{d-2}$ and permutations to create practical algorithms for\ngenerating permutation samples with good properties. Experiments show the above\ntechniques provide significant improvements for Shapley value estimates over\nexisting methods, converging to a smaller RMSE in the same number of model\nevaluations.\n", "versions": [{"version": "v1", "created": "Sun, 25 Apr 2021 16:44:18 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Mitchell", "Rory", ""], ["Cooper", "Joshua", ""], ["Frank", "Eibe", ""], ["Holmes", "Geoffrey", ""]]}, {"id": "2104.12201", "submitter": "Tharindu Ranasinghe Mr", "authors": "Lasitha Uyangodage, Tharindu Ranasinghe, Hansi Hettiarachchi", "title": "Transformers to Fight the COVID-19 Infodemic", "comments": "Accepted to Workshop on NLP for Internet Freedom (NLP4IF) at NAACL\n  2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The massive spread of false information on social media has become a global\nrisk especially in a global pandemic situation like COVID-19. False information\ndetection has thus become a surging research topic in recent months.\nNLP4IF-2021 shared task on fighting the COVID-19 infodemic has been organised\nto strengthen the research in false information detection where the\nparticipants are asked to predict seven different binary labels regarding false\ninformation in a tweet. The shared task has been organised in three languages;\nArabic, Bulgarian and English. In this paper, we present our approach to tackle\nthe task objective using transformers. Overall, our approach achieves a 0.707\nmean F1 score in Arabic, 0.578 mean F1 score in Bulgarian and 0.864 mean F1\nscore in English ranking 4th place in all the languages.\n", "versions": [{"version": "v1", "created": "Sun, 25 Apr 2021 16:49:23 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Uyangodage", "Lasitha", ""], ["Ranasinghe", "Tharindu", ""], ["Hettiarachchi", "Hansi", ""]]}, {"id": "2104.12210", "submitter": "Haoyang Cao", "authors": "Haoyang Cao and Xin Guo", "title": "Generative Adversarial Network: Some Analytical Perspectives", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.MF cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ever since its debut, generative adversarial networks (GANs) have attracted\ntremendous amount of attention. Over the past years, different variations of\nGANs models have been developed and tailored to different applications in\npractice. Meanwhile, some issues regarding the performance and training of GANs\nhave been noticed and investigated from various theoretical perspectives. This\nsubchapter will start from an introduction of GANs from an analytical\nperspective, then move on the training of GANs via SDE approximations and\nfinally discuss some applications of GANs in computing high dimensional MFGs as\nwell as tackling mathematical finance problems.\n", "versions": [{"version": "v1", "created": "Sun, 25 Apr 2021 17:12:32 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Cao", "Haoyang", ""], ["Guo", "Xin", ""]]}, {"id": "2104.12219", "submitter": "Andrew Miller", "authors": "Andrew C. Miller, Nicholas J. Foti, Emily B. Fox", "title": "Breiman's two cultures: You don't have to choose sides", "comments": "Commentary to appear in a special issue of Observational Studies,\n  discussing Leo Breiman's paper \"Statistical Modeling: The Two Cultures\"\n  (https://doi.org/10.1214/ss/1009213726)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Breiman's classic paper casts data analysis as a choice between two cultures:\ndata modelers and algorithmic modelers. Stated broadly, data modelers use\nsimple, interpretable models with well-understood theoretical properties to\nanalyze data. Algorithmic modelers prioritize predictive accuracy and use more\nflexible function approximations to analyze data. This dichotomy overlooks a\nthird set of models $-$ mechanistic models derived from scientific theories\n(e.g., ODE/SDE simulators). Mechanistic models encode application-specific\nscientific knowledge about the data. And while these categories represent\nextreme points in model space, modern computational and algorithmic tools\nenable us to interpolate between these points, producing flexible,\ninterpretable, and scientifically-informed hybrids that can enjoy accurate and\nrobust predictions, and resolve issues with data analysis that Breiman\ndescribes, such as the Rashomon effect and Occam's dilemma. Challenges still\nremain in finding an appropriate point in model space, with many choices on how\nto compose model components and the degree to which each component informs\ninferences.\n", "versions": [{"version": "v1", "created": "Sun, 25 Apr 2021 17:58:46 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Miller", "Andrew C.", ""], ["Foti", "Nicholas J.", ""], ["Fox", "Emily B.", ""]]}, {"id": "2104.12225", "submitter": "Priya Donti", "authors": "Priya L. Donti, David Rolnick, J. Zico Kolter", "title": "DC3: A learning method for optimization with hard constraints", "comments": "In ICLR 2021. Code available at https://github.com/locuslab/DC3", "journal-ref": "International Conference on Learning Representations 2021", "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Large optimization problems with hard constraints arise in many settings, yet\nclassical solvers are often prohibitively slow, motivating the use of deep\nnetworks as cheap \"approximate solvers.\" Unfortunately, naive deep learning\napproaches typically cannot enforce the hard constraints of such problems,\nleading to infeasible solutions. In this work, we present Deep Constraint\nCompletion and Correction (DC3), an algorithm to address this challenge.\nSpecifically, this method enforces feasibility via a differentiable procedure,\nwhich implicitly completes partial solutions to satisfy equality constraints\nand unrolls gradient-based corrections to satisfy inequality constraints. We\ndemonstrate the effectiveness of DC3 in both synthetic optimization tasks and\nthe real-world setting of AC optimal power flow, where hard constraints encode\nthe physics of the electrical grid. In both cases, DC3 achieves near-optimal\nobjective values while preserving feasibility.\n", "versions": [{"version": "v1", "created": "Sun, 25 Apr 2021 18:21:59 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Donti", "Priya L.", ""], ["Rolnick", "David", ""], ["Kolter", "J. Zico", ""]]}, {"id": "2104.12226", "submitter": "Tim Dernedde", "authors": "Ahmad Bdeir, Simon Boeder, Tim Dernedde, Kirill Tkachuk, Jonas K.\n  Falkner, Lars Schmidt-Thieme", "title": "RP-DQN: An application of Q-Learning to Vehicle Routing Problems", "comments": "14 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  In this paper we present a new approach to tackle complex routing problems\nwith an improved state representation that utilizes the model complexity better\nthan previous methods. We enable this by training from temporal differences.\nSpecifically Q-Learning is employed. We show that our approach achieves\nstate-of-the-art performance for autoregressive policies that sequentially\ninsert nodes to construct solutions on the CVRP. Additionally, we are the first\nto tackle the MDVRP with machine learning methods and demonstrate that this\nproblem type greatly benefits from our approach over other ML methods.\n", "versions": [{"version": "v1", "created": "Sun, 25 Apr 2021 18:28:35 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Bdeir", "Ahmad", ""], ["Boeder", "Simon", ""], ["Dernedde", "Tim", ""], ["Tkachuk", "Kirill", ""], ["Falkner", "Jonas K.", ""], ["Schmidt-Thieme", "Lars", ""]]}, {"id": "2104.12231", "submitter": "Andrew Miller", "authors": "Andrew C. Miller, Leon A. Gatys, Joseph Futoma, Emily B. Fox", "title": "Model-based metrics: Sample-efficient estimates of predictive model\n  subpopulation performance", "comments": "27 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning models $-$ now commonly developed to screen, diagnose, or\npredict health conditions $-$ are evaluated with a variety of performance\nmetrics. An important first step in assessing the practical utility of a model\nis to evaluate its average performance over an entire population of interest.\nIn many settings, it is also critical that the model makes good predictions\nwithin predefined subpopulations. For instance, showing that a model is fair or\nequitable requires evaluating the model's performance in different demographic\nsubgroups. However, subpopulation performance metrics are typically computed\nusing only data from that subgroup, resulting in higher variance estimates for\nsmaller groups. We devise a procedure to measure subpopulation performance that\ncan be more sample-efficient than the typical subsample estimates. We propose\nusing an evaluation model $-$ a model that describes the conditional\ndistribution of the predictive model score $-$ to form model-based metric (MBM)\nestimates. Our procedure incorporates model checking and validation, and we\npropose a computationally efficient approximation of the traditional\nnonparametric bootstrap to form confidence intervals. We evaluate MBMs on two\nmain tasks: a semi-synthetic setting where ground truth metrics are available\nand a real-world hospital readmission prediction task. We find that MBMs\nconsistently produce more accurate and lower variance estimates of model\nperformance for small subpopulations.\n", "versions": [{"version": "v1", "created": "Sun, 25 Apr 2021 19:06:34 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Miller", "Andrew C.", ""], ["Gatys", "Leon A.", ""], ["Futoma", "Joseph", ""], ["Fox", "Emily B.", ""]]}, {"id": "2104.12276", "submitter": "Yuming Du", "authors": "Yuming Du, Yang Xiao, Vincent Lepetit", "title": "Learning to Better Segment Objects from Unseen Classes with Unlabeled\n  Videos", "comments": "18 pages, 14 figures. See project page\n  https://dulucas.github.io/Homepage/gbopt/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The ability to localize and segment objects from unseen classes would open\nthe door to new applications, such as autonomous object learning in active\nvision. Nonetheless, improving the performance on unseen classes requires\nadditional training data, while manually annotating the objects of the unseen\nclasses can be labor-extensive and expensive. In this paper, we explore the use\nof unlabeled video sequences to automatically generate training data for\nobjects of unseen classes. It is in principle possible to apply existing video\nsegmentation methods to unlabeled videos and automatically obtain object masks,\nwhich can then be used as a training set even for classes with no manual labels\navailable. However, our experiments show that these methods do not perform well\nenough for this purpose. We therefore introduce a Bayesian method that is\nspecifically designed to automatically create such a training set: Our method\nstarts from a set of object proposals and relies on (non-realistic)\nanalysis-by-synthesis to select the correct ones by performing an efficient\noptimization over all the frames simultaneously. Through extensive experiments,\nwe show that our method can generate a high-quality training set which\nsignificantly boosts the performance of segmenting objects of unseen classes.\nWe thus believe that our method could open the door for open-world instance\nsegmentation using abundant Internet videos.\n", "versions": [{"version": "v1", "created": "Sun, 25 Apr 2021 22:05:44 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Du", "Yuming", ""], ["Xiao", "Yang", ""], ["Lepetit", "Vincent", ""]]}, {"id": "2104.12284", "submitter": "Lucas Jacaruso", "authors": "Lucas Cassiel Jacaruso", "title": "Accuracy Improvement for Fully Convolutional Networks via Selective\n  Augmentation with Applications to Electrocardiogram Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deep learning methods have shown suitability for time series classification\nin the health and medical domain, with promising results for electrocardiogram\ndata classification. Successful identification of myocardial infarction holds\nlife saving potential and any meaningful improvement upon deep learning models\nin this area is of great interest. Conventionally, data augmentation methods\nare applied universally to the training set when data are limited in order to\nameliorate data resolution or sample size. In the method proposed in this\nstudy, data augmentation was not applied in the context of data scarcity.\nInstead, samples that yield low confidence predictions were selectively\naugmented in order to bolster the model's sensitivity to features or patterns\nless strongly associated with a given class. This approach was tested for\nimproving the performance of a Fully Convolutional Network. The proposed\napproach achieved 90 percent accuracy for classifying myocardial infarction as\nopposed to 82 percent accuracy for the baseline, a marked improvement. Further,\nthe accuracy of the proposed approach was optimal near a defined upper\nthreshold for qualifying low confidence samples and decreased as this threshold\nwas raised to include higher confidence samples. This suggests exclusively\nselecting lower confidence samples for data augmentation comes with distinct\nbenefits for electrocardiogram data classification with Fully Convolutional\nNetworks.\n", "versions": [{"version": "v1", "created": "Sun, 25 Apr 2021 23:01:27 GMT"}, {"version": "v2", "created": "Sat, 10 Jul 2021 18:26:35 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Jacaruso", "Lucas Cassiel", ""]]}, {"id": "2104.12289", "submitter": "Pascal Fernsel", "authors": "Pascal Fernsel", "title": "Spatially Coherent Clustering Based on Orthogonal Nonnegative Matrix\n  Factorization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.LG cs.NA math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classical approaches in cluster analysis are typically based on a feature\nspace analysis. However, many applications lead to datasets with additional\nspatial information and a ground truth with spatially coherent classes, which\nwill not necessarily be reconstructed well by standard clustering methods.\nMotivated by applications in hyperspectral imaging, we introduce in this work\nclustering models based on orthogonal nonnegative matrix factorization, which\ninclude an additional total variation (TV) regularization procedure on the\ncluster membership matrix to enforce the needed spatial coherence in the\nclusters. We propose several approaches with different optimization techniques,\nwhere the TV regularization is either performed as a subsequent postprocessing\nstep or included into the clustering algorithm. Finally, we provide a numerical\nevaluation of all proposed methods on a hyperspectral dataset obtained from a\nmatrix-assisted laser desorption/ionisation imaging measurement, which leads to\nsignificantly better clustering results compared to classical clustering\nmodels.\n", "versions": [{"version": "v1", "created": "Sun, 25 Apr 2021 23:40:41 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Fernsel", "Pascal", ""]]}, {"id": "2104.12290", "submitter": "Gokhan Egri", "authors": "Gokhan Egri, Todd Zickler", "title": "StegaPos: Preventing Crops and Splices with Imperceptible Positional\n  Encodings", "comments": "For NeurIPS 2021 submission, 8 pages (main), 18 pages (total)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a model for differentiating between images that are authentic\ncopies of ones published by photographers, and images that have been\nmanipulated by cropping, splicing or downsampling after publication. The model\ncomprises an encoder that resides with the photographer and a matching decoder\nthat is available to observers. The encoder learns to embed imperceptible\npositional signatures into image values prior to publication. The decoder\nlearns to use these steganographic positional (\"stegapos\") signatures to\ndetermine, for each small image patch, the 2D positional coordinates that were\nheld by the patch in its originally-published image. Crop, splice and\ndownsample edits become detectable by the inconsistencies they cause in the\nhidden positional signatures. We find that training the encoder and decoder\ntogether produces a model that imperceptibly encodes position, and that enables\nsuperior performance on established benchmarks for splice detection and high\naccuracy on a new benchmark for crop detection.\n", "versions": [{"version": "v1", "created": "Sun, 25 Apr 2021 23:42:29 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Egri", "Gokhan", ""], ["Zickler", "Todd", ""]]}, {"id": "2104.12300", "submitter": "Ricky Ma", "authors": "Ricky Ma (The University of British Columbia)", "title": "ODDObjects: A Framework for Multiclass Unsupervised Anomaly Detection on\n  Masked Objects", "comments": "11 pages, 15 Postscript figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This paper presents a novel framework for unsupervised anomaly detection on\nmasked objects called ODDObjects, which stands for Out-of-Distribution\nDetection on Objects. ODDObjects is designed to detect anomalies of various\ncategories using unsupervised autoencoders trained on COCO-style datasets. The\nmethod utilizes autoencoder-based image reconstruction, where high\nreconstruction error indicates the possibility of an anomaly. The framework\nextends previous work on anomaly detection with autoencoders, comparing\nstate-of-the-art models trained on object recognition datasets. Various model\narchitectures were compared, and experimental results show that\nmemory-augmented deep convolutional autoencoders perform the best at detecting\nout-of-distribution objects.\n", "versions": [{"version": "v1", "created": "Mon, 26 Apr 2021 01:13:28 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Ma", "Ricky", "", "The University of British Columbia"]]}, {"id": "2104.12308", "submitter": "Zhiqiang Fu", "authors": "Zhiqiang Fu, Yao Zhao, Dongxia Chang, Xingxing Zhang, Yiming Wang", "title": "Auto-weighted low-rank representation for clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, a novel unsupervised low-rank representation model, i.e.,\nAuto-weighted Low-Rank Representation (ALRR), is proposed to construct a more\nfavorable similarity graph (SG) for clustering. In particular, ALRR enhances\nthe discriminability of SG by capturing the multi-subspace structure and\nextracting the salient features simultaneously. Specifically, an auto-weighted\npenalty is introduced to learn a similarity graph by highlighting the effective\nfeatures, and meanwhile, overshadowing the disturbed features. Consequently,\nALRR obtains a similarity graph that can preserve the intrinsic geometrical\nstructures within the data by enforcing a smaller similarity on two dissimilar\nsamples. Moreover, we employ a block-diagonal regularizer to guarantee the\nlearned graph contains $k$ diagonal blocks. This can facilitate a more\ndiscriminative representation learning for clustering tasks. Extensive\nexperimental results on synthetic and real databases demonstrate the\nsuperiority of ALRR over other state-of-the-art methods with a margin of\n1.8\\%$\\sim$10.8\\%.\n", "versions": [{"version": "v1", "created": "Mon, 26 Apr 2021 01:37:26 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Fu", "Zhiqiang", ""], ["Zhao", "Yao", ""], ["Chang", "Dongxia", ""], ["Zhang", "Xingxing", ""], ["Wang", "Yiming", ""]]}, {"id": "2104.12311", "submitter": "Zexuan Yin", "authors": "Zexuan Yin, Paolo Barucca", "title": "Stochastic Recurrent Neural Network for Multistep Time Series\n  Forecasting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Time series forecasting based on deep architectures has been gaining\npopularity in recent years due to their ability to model complex non-linear\ntemporal dynamics. The recurrent neural network is one such model capable of\nhandling variable-length input and output. In this paper, we leverage recent\nadvances in deep generative models and the concept of state space models to\npropose a stochastic adaptation of the recurrent neural network for\nmultistep-ahead time series forecasting, which is trained with stochastic\ngradient variational Bayes. In our model design, the transition function of the\nrecurrent neural network, which determines the evolution of the hidden states,\nis stochastic rather than deterministic as in a regular recurrent neural\nnetwork; this is achieved by incorporating a latent random variable into the\ntransition process which captures the stochasticity of the temporal dynamics.\nOur model preserves the architectural workings of a recurrent neural network\nfor which all relevant information is encapsulated in its hidden states, and\nthis flexibility allows our model to be easily integrated into any deep\narchitecture for sequential modelling. We test our model on a wide range of\ndatasets from finance to healthcare; results show that the stochastic recurrent\nneural network consistently outperforms its deterministic counterpart.\n", "versions": [{"version": "v1", "created": "Mon, 26 Apr 2021 01:43:43 GMT"}, {"version": "v2", "created": "Sun, 2 May 2021 00:59:40 GMT"}, {"version": "v3", "created": "Fri, 25 Jun 2021 03:00:47 GMT"}], "update_date": "2021-06-28", "authors_parsed": [["Yin", "Zexuan", ""], ["Barucca", "Paolo", ""]]}, {"id": "2104.12314", "submitter": "Wanli Qiao", "authors": "Wanli Qiao and Wolfgang Polonik", "title": "Algorithms for ridge estimation with convergence guarantees", "comments": "41 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The extraction of filamentary structure from a point cloud is discussed. The\nfilaments are modeled as ridge lines or higher dimensional ridges of an\nunderlying density. We propose two novel algorithms, and provide theoretical\nguarantees for their convergences. We consider the new algorithms as\nalternatives to the Subspace Constraint Mean Shift (SCMS) algorithm that do not\nsuffer from a shortcoming of the SCMS that is also revealed in this paper.\n", "versions": [{"version": "v1", "created": "Mon, 26 Apr 2021 01:57:04 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Qiao", "Wanli", ""], ["Polonik", "Wolfgang", ""]]}, {"id": "2104.12325", "submitter": "Mohammad Amin Nabian", "authors": "Mohammad Amin Nabian, Rini Jasmine Gladstone, Hadi Meidani", "title": "Efficient training of physics-informed neural networks via importance\n  sampling", "comments": "Computer-Aided Civil and Infrastructure Engineering (2021)", "journal-ref": null, "doi": "10.1111/mice.12685", "report-no": null, "categories": "cs.LG cs.NA math.AP math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Physics-Informed Neural Networks (PINNs) are a class of deep neural networks\nthat are trained, using automatic differentiation, to compute the response of\nsystems governed by partial differential equations (PDEs). The training of\nPINNs is simulation-free, and does not require any training dataset to be\nobtained from numerical PDE solvers. Instead, it only requires the physical\nproblem description, including the governing laws of physics, domain geometry,\ninitial/boundary conditions, and the material properties. This training usually\ninvolves solving a non-convex optimization problem using variants of the\nstochastic gradient descent method, with the gradient of the loss function\napproximated on a batch of collocation points, selected randomly in each\niteration according to a uniform distribution. Despite the success of PINNs in\naccurately solving a wide variety of PDEs, the method still requires\nimprovements in terms of computational efficiency. To this end, in this paper,\nwe study the performance of an importance sampling approach for efficient\ntraining of PINNs. Using numerical examples together with theoretical\nevidences, we show that in each training iteration, sampling the collocation\npoints according to a distribution proportional to the loss function will\nimprove the convergence behavior of the PINNs training. Additionally, we show\nthat providing a piecewise constant approximation to the loss function for\nfaster importance sampling can further improve the training efficiency. This\nimportance sampling approach is straightforward and easy to implement in the\nexisting PINN codes, and also does not introduce any new hyperparameter to\ncalibrate. The numerical examples include elasticity, diffusion and plane\nstress problems, through which we numerically verify the accuracy and\nefficiency of the importance sampling approach compared to the predominant\nuniform sampling approach.\n", "versions": [{"version": "v1", "created": "Mon, 26 Apr 2021 02:45:10 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Nabian", "Mohammad Amin", ""], ["Gladstone", "Rini Jasmine", ""], ["Meidani", "Hadi", ""]]}, {"id": "2104.12333", "submitter": "Tao Ni", "authors": "Tao Ni, Qing Wang, Gabriela Ferraro", "title": "Explore BiLSTM-CRF-Based Models for Open Relation Extraction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Extracting multiple relations from text sentences is still a challenge for\ncurrent Open Relation Extraction (Open RE) tasks. In this paper, we develop\nseveral Open RE models based on the bidirectional LSTM-CRF (BiLSTM-CRF) neural\nnetwork and different contextualized word embedding methods. We also propose a\nnew tagging scheme to solve overlapping problems and enhance models'\nperformance. From the evaluation results and comparisons between models, we\nselect the best combination of tagging scheme, word embedder, and BiLSTM-CRF\nnetwork to achieve an Open RE model with a remarkable extracting ability on\nmultiple-relation sentences.\n", "versions": [{"version": "v1", "created": "Mon, 26 Apr 2021 03:37:22 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Ni", "Tao", ""], ["Wang", "Qing", ""], ["Ferraro", "Gabriela", ""]]}, {"id": "2104.12363", "submitter": "Takuya Kanazawa", "authors": "Takuya Kanazawa", "title": "One-parameter family of acquisition functions for efficient global\n  optimization", "comments": "13 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian optimization (BO) with Gaussian processes is a powerful methodology\nto optimize an expensive black-box function with as few function evaluations as\npossible. The expected improvement (EI) and probability of improvement (PI) are\namong the most widely used schemes for BO. There is a plethora of other schemes\nthat outperform EI and PI, but most of them are numerically far more expensive\nthan EI and PI. In this work, we propose a new one-parameter family of\nacquisition functions for BO that unifies EI and PI. The proposed method is\nnumerically inexpensive, is easy to implement, can be easily parallelized, and\non benchmark tasks shows a performance superior to EI and GP-UCB. Its\ngeneralization to BO with Student-t processes is also presented.\n", "versions": [{"version": "v1", "created": "Mon, 26 Apr 2021 06:41:30 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Kanazawa", "Takuya", ""]]}, {"id": "2104.12365", "submitter": "Zeshi Yang", "authors": "Zeshi Yang and Zhiqi Yin", "title": "Efficient Hyperparameter Optimization for Physics-based Character\n  Animation", "comments": "published in ACM SIGGRAPH Symposium on Interactive 3D Graphics and\n  Games 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GR cs.AI cs.LG cs.RO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Physics-based character animation has seen significant advances in recent\nyears with the adoption of Deep Reinforcement Learning (DRL). However,\nDRL-based learning methods are usually computationally expensive and their\nperformance crucially depends on the choice of hyperparameters. Tuning\nhyperparameters for these methods often requires repetitive training of control\npolicies, which is even more computationally prohibitive. In this work, we\npropose a novel Curriculum-based Multi-Fidelity Bayesian Optimization framework\n(CMFBO) for efficient hyperparameter optimization of DRL-based character\ncontrol systems. Using curriculum-based task difficulty as fidelity criterion,\nour method improves searching efficiency by gradually pruning search space\nthrough evaluation on easier motor skill tasks. We evaluate our method on two\nphysics-based character control tasks: character morphology optimization and\nhyperparameter tuning of DeepMimic. Our algorithm significantly outperforms\nstate-of-the-art hyperparameter optimization methods applicable for\nphysics-based character animation. In particular, we show that hyperparameters\noptimized through our algorithm result in at least 5x efficiency gain comparing\nto author-released settings in DeepMimic.\n", "versions": [{"version": "v1", "created": "Mon, 26 Apr 2021 06:46:36 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Yang", "Zeshi", ""], ["Yin", "Zhiqi", ""]]}, {"id": "2104.12368", "submitter": "Minh Ha Quang", "authors": "Minh Ha Quang", "title": "Finite sample approximations of exact and entropic Wasserstein distances\n  between covariance operators and Gaussian processes", "comments": "30 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work studies finite sample approximations of the exact and entropic\nregularized Wasserstein distances between centered Gaussian processes and, more\ngenerally, covariance operators of functional random processes. We first show\nthat these distances/divergences are fully represented by reproducing kernel\nHilbert space (RKHS) covariance and cross-covariance operators associated with\nthe corresponding covariance functions. Using this representation, we show that\nthe Sinkhorn divergence between two centered Gaussian processes can be\nconsistently and efficiently estimated from the divergence between their\ncorresponding normalized finite-dimensional covariance matrices, or\nalternatively, their sample covariance operators. Consequently, this leads to a\nconsistent and efficient algorithm for estimating the Sinkhorn divergence from\nfinite samples generated by the two processes. For a fixed regularization\nparameter, the convergence rates are {\\it dimension-independent} and of the\nsame order as those for the Hilbert-Schmidt distance. If at least one of the\nRKHS is finite-dimensional, we obtain a {\\it dimension-dependent} sample\ncomplexity for the exact Wasserstein distance between the Gaussian processes.\n", "versions": [{"version": "v1", "created": "Mon, 26 Apr 2021 06:57:14 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Quang", "Minh Ha", ""]]}, {"id": "2104.12384", "submitter": "Konstantinos Zygalakis", "authors": "J.M. Sanz-Serna, Konstantinos C. Zygalakis", "title": "Wasserstein distance estimates for the distributions of numerical\n  approximations to ergodic stochastic differential equations", "comments": "29 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.NA math.NA math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a framework that allows for the non-asymptotic study of the\n$2$-Wasserstein distance between the invariant distribution of an ergodic\nstochastic differential equation and the distribution of its numerical\napproximation in the strongly log-concave case. This allows us to study in a\nunified way a number of different integrators proposed in the literature for\nthe overdamped and underdamped Langevin dynamics. In addition, we analyse a\nnovel splitting method for the underdamped Langevin dynamics which only\nrequires one gradient evaluation per time step. Under an additional smoothness\nassumption on a $d$--dimensional strongly log-concave distribution with\ncondition number $\\kappa$, the algorithm is shown to produce with an\n$\\mathcal{O}\\big(\\kappa^{5/4} d^{1/4}\\epsilon^{-1/2} \\big)$ complexity samples\nfrom a distribution that, in Wasserstein distance, is at most $\\epsilon>0$ away\nfrom the target distribution.\n", "versions": [{"version": "v1", "created": "Mon, 26 Apr 2021 07:50:04 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Sanz-Serna", "J. M.", ""], ["Zygalakis", "Konstantinos C.", ""]]}, {"id": "2104.12385", "submitter": "Tudor Cebere BSc", "authors": "Adam James Hall, Madhava Jay, Tudor Cebere, Bogdan Cebere, Koen\n  Lennart van der Veen, George Muraru, Tongye Xu, Patrick Cason, William\n  Abramson, Ayoub Benaissa, Chinmay Shah, Alan Aboudib, Th\\'eo Ryffel, Kritika\n  Prakash, Tom Titcombe, Varun Kumar Khare, Maddie Shang, Ionesio Junior,\n  Animesh Gupta, Jason Paumier, Nahua Kang, Vova Manannikov, Andrew Trask", "title": "Syft 0.5: A Platform for Universally Deployable Structured Transparency", "comments": "ICLR 2021 Workshop on Distributed and Private Machine Learning (DPML\n  2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present Syft 0.5, a general-purpose framework that combines a core group\nof privacy-enhancing technologies that facilitate a universal set of structured\ntransparency systems. This framework is demonstrated through the design and\nimplementation of a novel privacy-preserving inference information flow where\nwe pass homomorphically encrypted activation signals through a split neural\nnetwork for inference. We show that splitting the model further up the\ncomputation chain significantly reduces the computation time of inference and\nthe payload size of activation signals at the cost of model secrecy. We\nevaluate our proposed flow with respect to its provision of the core structural\ntransparency principles.\n", "versions": [{"version": "v1", "created": "Mon, 26 Apr 2021 07:54:16 GMT"}, {"version": "v2", "created": "Tue, 27 Apr 2021 17:02:42 GMT"}], "update_date": "2021-04-28", "authors_parsed": [["Hall", "Adam James", ""], ["Jay", "Madhava", ""], ["Cebere", "Tudor", ""], ["Cebere", "Bogdan", ""], ["van der Veen", "Koen Lennart", ""], ["Muraru", "George", ""], ["Xu", "Tongye", ""], ["Cason", "Patrick", ""], ["Abramson", "William", ""], ["Benaissa", "Ayoub", ""], ["Shah", "Chinmay", ""], ["Aboudib", "Alan", ""], ["Ryffel", "Th\u00e9o", ""], ["Prakash", "Kritika", ""], ["Titcombe", "Tom", ""], ["Khare", "Varun Kumar", ""], ["Shang", "Maddie", ""], ["Junior", "Ionesio", ""], ["Gupta", "Animesh", ""], ["Paumier", "Jason", ""], ["Kang", "Nahua", ""], ["Manannikov", "Vova", ""], ["Trask", "Andrew", ""]]}, {"id": "2104.12389", "submitter": "Huanyu He", "authors": "Yuang Zhang, Huanyu He, Jianguo Li, Yuxi Li, John See, Weiyao Lin", "title": "Variational Pedestrian Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Pedestrian detection in a crowd is a challenging task due to a high number of\nmutually-occluding human instances, which brings ambiguity and optimization\ndifficulties to the current IoU-based ground truth assignment procedure in\nclassical object detection methods. In this paper, we develop a unique\nperspective of pedestrian detection as a variational inference problem. We\nformulate a novel and efficient algorithm for pedestrian detection by modeling\nthe dense proposals as a latent variable while proposing a customized Auto\nEncoding Variational Bayes (AEVB) algorithm. Through the optimization of our\nproposed algorithm, a classical detector can be fashioned into a variational\npedestrian detector. Experiments conducted on CrowdHuman and CityPersons\ndatasets show that the proposed algorithm serves as an efficient solution to\nhandle the dense pedestrian detection problem for the case of single-stage\ndetectors. Our method can also be flexibly applied to two-stage detectors,\nachieving notable performance enhancement.\n", "versions": [{"version": "v1", "created": "Mon, 26 Apr 2021 08:06:41 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Zhang", "Yuang", ""], ["He", "Huanyu", ""], ["Li", "Jianguo", ""], ["Li", "Yuxi", ""], ["See", "John", ""], ["Lin", "Weiyao", ""]]}, {"id": "2104.12395", "submitter": "Ryuichi Yamamoto", "authors": "Kosuke Futamata, Byeongseon Park, Ryuichi Yamamoto, Kentaro Tachibana", "title": "Phrase break prediction with bidirectional encoder representations in\n  Japanese text-to-speech synthesis", "comments": "Submitted to INTERSPEECH 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel phrase break prediction method that combines implicit\nfeatures extracted from a pre-trained large language model, a.k.a BERT, and\nexplicit features extracted from BiLSTM with linguistic features. In\nconventional BiLSTM based methods, word representations and/or sentence\nrepresentations are used as independent components. The proposed method takes\naccount of both representations to extract the latent semantics, which cannot\nbe captured by previous methods. The objective evaluation results show that the\nproposed method obtains an absolute improvement of 3.2 points for the F1 score\ncompared with BiLSTM-based conventional methods using linguistic features.\nMoreover, the perceptual listening test results verify that a TTS system that\napplied our proposed method achieved a mean opinion score of 4.39 in prosody\nnaturalness, which is highly competitive with the score of 4.37 for synthesized\nspeech with ground-truth phrase breaks.\n", "versions": [{"version": "v1", "created": "Mon, 26 Apr 2021 08:29:29 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Futamata", "Kosuke", ""], ["Park", "Byeongseon", ""], ["Yamamoto", "Ryuichi", ""], ["Tachibana", "Kentaro", ""]]}, {"id": "2104.12407", "submitter": "Yuezhou Zhang", "authors": "Yuezhou Zhang, Amos A Folarin, Shaoxiong Sun, Nicholas Cummins,\n  Yatharth Ranjan, Zulqarnain Rashid, Pauline Conde, Callum Stewart, Petroula\n  Laiou, Faith Matcham, Carolin Oetzmann, Femke Lamers, Sara Siddi, Sara\n  Simblett, Aki Rintala, David C Mohr, Inez Myin-Germeys, Til Wykes, Josep\n  Maria Haro, Brenda WJH Pennix, Vaibhav A Narayan, Peter Annas, Matthew\n  Hotopf, Richard JB Dobson", "title": "Predicting Depressive Symptom Severity through Individuals' Nearby\n  Bluetooth Devices Count Data Collected by Mobile Phones: A Preliminary\n  Longitudinal Study", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Bluetooth sensor embedded in mobile phones provides an unobtrusive,\ncontinuous, and cost-efficient means to capture individuals' proximity\ninformation, such as the nearby Bluetooth devices count (NBDC). The continuous\nNBDC data can partially reflect individuals' behaviors and status, such as\nsocial connections and interactions, working status, mobility, and social\nisolation and loneliness, which were found to be significantly associated with\ndepression by previous survey-based studies. This paper aims to explore the\nNBDC data's value in predicting depressive symptom severity as measured via the\n8-item Patient Health Questionnaire (PHQ-8). The data used in this paper\nincluded 2,886 bi-weekly PHQ-8 records collected from 316 participants\nrecruited from three study sites in the Netherlands, Spain, and the UK as part\nof the EU RADAR-CNS study. From the NBDC data two weeks prior to each PHQ-8\nscore, we extracted 49 Bluetooth features, including statistical features and\nnonlinear features for measuring periodicity and regularity of individuals'\nlife rhythms. Linear mixed-effect models were used to explore associations\nbetween Bluetooth features and the PHQ-8 score. We then applied hierarchical\nBayesian linear regression models to predict the PHQ-8 score from the extracted\nBluetooth features. A number of significant associations were found between\nBluetooth features and depressive symptom severity. Compared with commonly used\nmachine learning models, the proposed hierarchical Bayesian linear regression\nmodel achieved the best prediction metrics, R2= 0.526, and root mean squared\nerror (RMSE) of 3.891. Bluetooth features can explain an extra 18.8% of the\nvariance in the PHQ-8 score relative to the baseline model without Bluetooth\nfeatures (R2=0.338, RMSE = 4.547).\n", "versions": [{"version": "v1", "created": "Mon, 26 Apr 2021 09:06:02 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Zhang", "Yuezhou", ""], ["Folarin", "Amos A", ""], ["Sun", "Shaoxiong", ""], ["Cummins", "Nicholas", ""], ["Ranjan", "Yatharth", ""], ["Rashid", "Zulqarnain", ""], ["Conde", "Pauline", ""], ["Stewart", "Callum", ""], ["Laiou", "Petroula", ""], ["Matcham", "Faith", ""], ["Oetzmann", "Carolin", ""], ["Lamers", "Femke", ""], ["Siddi", "Sara", ""], ["Simblett", "Sara", ""], ["Rintala", "Aki", ""], ["Mohr", "David C", ""], ["Myin-Germeys", "Inez", ""], ["Wykes", "Til", ""], ["Haro", "Josep Maria", ""], ["Pennix", "Brenda WJH", ""], ["Narayan", "Vaibhav A", ""], ["Annas", "Peter", ""], ["Hotopf", "Matthew", ""], ["Dobson", "Richard JB", ""]]}, {"id": "2104.12416", "submitter": "Zhefeng Qiao", "authors": "Zhefeng Qiao, Xianghao Yu, Jun Zhang, Khaled B. Letaief", "title": "Communication-Efficient Federated Learning with Dual-Side Low-Rank\n  Compression", "comments": "6 pages, 5 figures, submitted for potential publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning (FL) is a promising and powerful approach for training\ndeep learning models without sharing the raw data of clients. During the\ntraining process of FL, the central server and distributed clients need to\nexchange a vast amount of model information periodically. To address the\nchallenge of communication-intensive training, we propose a new training\nmethod, referred to as federated learning with dual-side low-rank compression\n(FedDLR), where the deep learning model is compressed via low-rank\napproximations at both the server and client sides. The proposed FedDLR not\nonly reduces the communication overhead during the training stage but also\ndirectly generates a compact model to speed up the inference process. We shall\nprovide convergence analysis, investigate the influence of the key parameters,\nand empirically show that FedDLR outperforms the state-of-the-art solutions in\nterms of both the communication and computation efficiency.\n", "versions": [{"version": "v1", "created": "Mon, 26 Apr 2021 09:13:31 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Qiao", "Zhefeng", ""], ["Yu", "Xianghao", ""], ["Zhang", "Jun", ""], ["Letaief", "Khaled B.", ""]]}, {"id": "2104.12418", "submitter": "Swarup Mohalik", "authors": "Moumita Das, Rajarshi Ray, Swarup Kumar Mohalik, Ansuman Banerjee", "title": "Fast Falsification of Neural Networks using Property Directed Testing", "comments": "10 pages, 3 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks are now extensively used in perception, prediction and\ncontrol of autonomous systems. Their deployment in safety-critical systems\nbrings forth the need for verification techniques for such networks. As an\nalternative to exhaustive and costly verification algorithms, lightweight\nfalsification algorithms have been heavily used to search for an input to the\nsystem that produces an unsafe output, i.e., a counterexample to the safety of\nthe system. In this work, we propose a falsification algorithm for neural\nnetworks that directs the search for a counterexample, guided by a safety\nproperty specification. Our algorithm uses a derivative-free sampling-based\noptimization method. We evaluate our algorithm on 45 trained neural network\nbenchmarks of the ACAS Xu system against 10 safety properties. We show that our\nfalsification procedure detects all the unsafe instances that other\nverification tools also report as unsafe. Moreover, in terms of performance,\nour falsification procedure identifies most of the unsafe instances faster, in\ncomparison to the state-of-the-art verification tools for feed-forward neural\nnetworks such as NNENUM and Neurify and in many instances, by orders of\nmagnitude.\n", "versions": [{"version": "v1", "created": "Mon, 26 Apr 2021 09:16:27 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Das", "Moumita", ""], ["Ray", "Rajarshi", ""], ["Mohalik", "Swarup Kumar", ""], ["Banerjee", "Ansuman", ""]]}, {"id": "2104.12419", "submitter": "Quentin Paletta", "authors": "Quentin Paletta, Anthony Hu, Guillaume Arbod, Joan Lasenby", "title": "ECLIPSE : Envisioning Cloud Induced Perturbations in Solar Energy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Efficient integration of solar energy into the electricity mix depends on a\nreliable anticipation of its intermittency. A promising approach to forecast\nthe temporal variability of solar irradiance resulting from the cloud cover\ndynamics, is based on the analysis of sequences of ground-taken sky images.\nDespite encouraging results, a recurrent limitation of current Deep Learning\napproaches lies in the ubiquitous tendency of reacting to past observations\nrather than actively anticipating future events. This leads to a systematic\ntemporal lag and little ability to predict sudden events. To address this\nchallenge, we introduce ECLIPSE, a spatio-temporal neural network architecture\nthat models cloud motion from sky images to predict both future segmented\nimages and corresponding irradiance levels. We show that ECLIPSE anticipates\ncritical events and considerably reduces temporal delay while generating\nvisually realistic futures.\n", "versions": [{"version": "v1", "created": "Mon, 26 Apr 2021 09:19:43 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Paletta", "Quentin", ""], ["Hu", "Anthony", ""], ["Arbod", "Guillaume", ""], ["Lasenby", "Joan", ""]]}, {"id": "2104.12426", "submitter": "Pavlos Papadopoulos", "authors": "Pavlos Papadopoulos, Oliver Thornewill von Essen, Nikolaos Pitropakis,\n  Christos Chrysoulas, Alexios Mylonas, William J. Buchanan", "title": "Launching Adversarial Attacks against Network Intrusion Detection\n  Systems for IoT", "comments": "MDPI Mach. Learn. Knowl. Extr. 2021, 3(2), 333-356;\n  https://www.mdpi.com/2624-800X/1/2/14", "journal-ref": "J. Cybersecur. Priv. 2021, 1(2), 252-273", "doi": "10.3390/jcp1020014", "report-no": null, "categories": "cs.LG cs.CR cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  As the internet continues to be populated with new devices and emerging\ntechnologies, the attack surface grows exponentially. Technology is shifting\ntowards a profit-driven Internet of Things market where security is an\nafterthought. Traditional defending approaches are no longer sufficient to\ndetect both known and unknown attacks to high accuracy. Machine learning\nintrusion detection systems have proven their success in identifying unknown\nattacks with high precision. Nevertheless, machine learning models are also\nvulnerable to attacks. Adversarial examples can be used to evaluate the\nrobustness of a designed model before it is deployed. Further, using\nadversarial examples is critical to creating a robust model designed for an\nadversarial environment. Our work evaluates both traditional machine learning\nand deep learning models' robustness using the Bot-IoT dataset. Our methodology\nincluded two main approaches. First, label poisoning, used to cause incorrect\nclassification by the model. Second, the fast gradient sign method, used to\nevade detection measures. The experiments demonstrated that an attacker could\nmanipulate or circumvent detection with significant probability.\n", "versions": [{"version": "v1", "created": "Mon, 26 Apr 2021 09:36:29 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Papadopoulos", "Pavlos", ""], ["von Essen", "Oliver Thornewill", ""], ["Pitropakis", "Nikolaos", ""], ["Chrysoulas", "Christos", ""], ["Mylonas", "Alexios", ""], ["Buchanan", "William J.", ""]]}, {"id": "2104.12437", "submitter": "Darius Afchar", "authors": "Darius Afchar, Romain Hennequin and Vincent Guigue", "title": "Towards Rigorous Interpretations: a Formalisation of Feature Attribution", "comments": "38th International Conference on Machine Learning (ICML 2021)", "journal-ref": "PMLR 139:76-86, 2021", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Feature attribution is often loosely presented as the process of selecting a\nsubset of relevant features as a rationale of a prediction. Task-dependent by\nnature, precise definitions of \"relevance\" encountered in the literature are\nhowever not always consistent. This lack of clarity stems from the fact that we\nusually do not have access to any notion of ground-truth attribution and from a\nmore general debate on what good interpretations are. In this paper we propose\nto formalise feature selection/attribution based on the concept of relaxed\nfunctional dependence. In particular, we extend our notions to the\ninstance-wise setting and derive necessary properties for candidate selection\nsolutions, while leaving room for task-dependence. By computing ground-truth\nattributions on synthetic datasets, we evaluate many state-of-the-art\nattribution methods and show that, even when optimised, some fail to verify the\nproposed properties and provide wrong solutions.\n", "versions": [{"version": "v1", "created": "Mon, 26 Apr 2021 10:04:44 GMT"}, {"version": "v2", "created": "Mon, 5 Jul 2021 14:27:00 GMT"}], "update_date": "2021-07-12", "authors_parsed": [["Afchar", "Darius", ""], ["Hennequin", "Romain", ""], ["Guigue", "Vincent", ""]]}, {"id": "2104.12446", "submitter": "Boris Ivanovic", "authors": "Boris Ivanovic, Kuan-Hui Lee, Pavel Tokmakov, Blake Wulfe, Rowan\n  McAllister, Adrien Gaidon, Marco Pavone", "title": "Heterogeneous-Agent Trajectory Forecasting Incorporating Class\n  Uncertainty", "comments": "17 pages, 12 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reasoning about the future behavior of other agents is critical to safe robot\nnavigation. The multiplicity of plausible futures is further amplified by the\nuncertainty inherent to agent state estimation from data, including positions,\nvelocities, and semantic class. Forecasting methods, however, typically neglect\nclass uncertainty, conditioning instead only on the agent's most likely class,\neven though perception models often return full class distributions. To exploit\nthis information, we present HAICU, a method for heterogeneous-agent trajectory\nforecasting that explicitly incorporates agents' class probabilities. We\nadditionally present PUP, a new challenging real-world autonomous driving\ndataset, to investigate the impact of Perceptual Uncertainty in Prediction. It\ncontains challenging crowded scenes with unfiltered agent class probabilities\nthat reflect the long-tail of current state-of-the-art perception systems. We\ndemonstrate that incorporating class probabilities in trajectory forecasting\nsignificantly improves performance in the face of uncertainty, and enables new\nforecasting capabilities such as counterfactual predictions.\n", "versions": [{"version": "v1", "created": "Mon, 26 Apr 2021 10:28:34 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Ivanovic", "Boris", ""], ["Lee", "Kuan-Hui", ""], ["Tokmakov", "Pavel", ""], ["Wulfe", "Blake", ""], ["McAllister", "Rowan", ""], ["Gaidon", "Adrien", ""], ["Pavone", "Marco", ""]]}, {"id": "2104.12459", "submitter": "Pedro Saleiro", "authors": "Catarina Bel\\'em, Vladimir Balayan, Pedro Saleiro, Pedro Bizarro", "title": "Weakly Supervised Multi-task Learning for Concept-based Explainability", "comments": "Accepted at ICLR 2021 Workshop on Weakly Supervised Learning (WeaSuL)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In ML-aided decision-making tasks, such as fraud detection or medical\ndiagnosis, the human-in-the-loop, usually a domain-expert without technical ML\nknowledge, prefers high-level concept-based explanations instead of low-level\nexplanations based on model features. To obtain faithful concept-based\nexplanations, we leverage multi-task learning to train a neural network that\njointly learns to predict a decision task based on the predictions of a\nprecedent explainability task (i.e., multi-label concepts). There are two main\nchallenges to overcome: concept label scarcity and the joint learning. To\naddress both, we propose to: i) use expert rules to generate a large dataset of\nnoisy concept labels, and ii) apply two distinct multi-task learning strategies\ncombining noisy and golden labels. We compare these strategies with a fully\nsupervised approach in a real-world fraud detection application with few golden\nlabels available for the explainability task. With improvements of 9.26% and of\n417.8% at the explainability and decision tasks, respectively, our results show\nit is possible to improve performance at both tasks by combining labels of\nheterogeneous quality.\n", "versions": [{"version": "v1", "created": "Mon, 26 Apr 2021 10:42:19 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Bel\u00e9m", "Catarina", ""], ["Balayan", "Vladimir", ""], ["Saleiro", "Pedro", ""], ["Bizarro", "Pedro", ""]]}, {"id": "2104.12469", "submitter": "Konstantin Klemmer", "authors": "Konstantin Klemmer, Sudipan Saha, Matthias Kahl, Tianlin Xu, Xiao\n  Xiang Zhu", "title": "Generative modeling of spatio-temporal weather patterns with extreme\n  event conditioning", "comments": "ICLR'21 Workshop AI: Modeling Oceans and Climate Change (AIMOCC)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG physics.ao-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep generative models are increasingly used to gain insights in the\ngeospatial data domain, e.g., for climate data. However, most existing\napproaches work with temporal snapshots or assume 1D time-series; few are able\nto capture spatio-temporal processes simultaneously. Beyond this, Earth-systems\ndata often exhibit highly irregular and complex patterns, for example caused by\nextreme weather events. Because of climate change, these phenomena are only\nincreasing in frequency. Here, we proposed a novel GAN-based approach for\ngenerating spatio-temporal weather patterns conditioned on detected extreme\nevents. Our approach augments GAN generator and discriminator with an encoded\nextreme weather event segmentation mask. These segmentation masks can be\ncreated from raw input using existing event detection frameworks. As such, our\napproach is highly modular and can be combined with custom GAN architectures.\nWe highlight the applicability of our proposed approach in experiments with\nreal-world surface radiation and zonal wind data.\n", "versions": [{"version": "v1", "created": "Mon, 26 Apr 2021 10:58:44 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Klemmer", "Konstantin", ""], ["Saha", "Sudipan", ""], ["Kahl", "Matthias", ""], ["Xu", "Tianlin", ""], ["Zhu", "Xiao Xiang", ""]]}, {"id": "2104.12477", "submitter": "Neta Shoham", "authors": "Neta Shoham, Tomer Avidor, Nadav Israel", "title": "An Exploration into why Output Regularization Mitigates Label Noise", "comments": "This paper will appear at CVPR 2021 workshop on learning from limited\n  and imperfect data (L2ID)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Label noise presents a real challenge for supervised learning algorithms.\nConsequently, mitigating label noise has attracted immense research in recent\nyears. Noise robust losses is one of the more promising approaches for dealing\nwith label noise, as these methods only require changing the loss function and\ndo not require changing the design of the classifier itself, which can be\nexpensive in terms of development time. In this work we focus on losses that\nuse output regularization (such as label smoothing and entropy). Although these\nlosses perform well in practice, their ability to mitigate label noise lack\nmathematical rigor. In this work we aim at closing this gap by showing that\nlosses, which incorporate an output regularization term, become symmetric as\nthe regularization coefficient goes to infinity. We argue that the\nregularization coefficient can be seen as a hyper-parameter controlling the\nsymmetricity, and thus, the noise robustness of the loss function.\n", "versions": [{"version": "v1", "created": "Mon, 26 Apr 2021 11:16:30 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Shoham", "Neta", ""], ["Avidor", "Tomer", ""], ["Israel", "Nadav", ""]]}, {"id": "2104.12485", "submitter": "Ga\\\"el Poux-M\\'edard", "authors": "Ga\\\"el Poux-M\\'edard and Julien Velcin and Sabine Loudcher", "title": "Powered Dirichlet Process for Controlling the Importance of\n  \"Rich-Get-Richer\" Prior Assumptions in Bayesian Clustering", "comments": "17 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DM", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  One of the most used priors in Bayesian clustering is the Dirichlet prior. It\ncan be expressed as a Chinese Restaurant Process. This process allows\nnonparametric estimation of the number of clusters when partitioning datasets.\nIts key feature is the \"rich-get-richer\" property, which assumes a cluster has\nan a priori probability to get chosen linearly dependent on population. In this\npaper, we show that such prior is not always the best choice to model data. We\nderive the Powered Chinese Restaurant process from a modified version of the\nDirichlet-Multinomial distribution to answer this problem. We then develop some\nof its fundamental properties (expected number of clusters, convergence).\nUnlike state-of-the-art efforts in this direction, this new formulation allows\nfor direct control of the importance of the \"rich-get-richer\" prior.\n", "versions": [{"version": "v1", "created": "Mon, 26 Apr 2021 11:36:23 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Poux-M\u00e9dard", "Ga\u00ebl", ""], ["Velcin", "Julien", ""], ["Loudcher", "Sabine", ""]]}, {"id": "2104.12493", "submitter": "Marcin Michalak", "authors": "Marcin Michalak, Jes\\'us S. Aguilar-Ruiz", "title": "Boolean Reasoning-Based Biclustering for Shifting Pattern Extraction", "comments": "29 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Biclustering is a powerful approach to search for patterns in data, as it can\nbe driven by a function that measures the quality of diverse types of patterns\nof interest. However, due to its computational complexity, the exploration of\nthe search space is usually guided by an algorithmic strategy, sometimes\nintroducing random factors that simplify the computational cost (e.g. greedy\nsearch or evolutionary computation).\n  Shifting patterns are specially interesting as they account constant\nfluctuations in data, i.e. they capture situations in which all the values in\nthe pattern move up or down for one dimension maintaining the range amplitude\nfor all the dimensions. This behaviour is very common in nature, e.g. in the\nanalysis of gene expression data, where a subset of genes might go up or down\nfor a subset of patients or experimental conditions, identifying functionally\ncoherent categories.\n  Boolean reasoning was recently revealed as an appropriate methodology to\naddress the search for constant biclusters. In this work, this direction is\nextended to search for more general biclusters that include shifting patterns.\nThe mathematical foundations are described in order to associate Boolean\nconcepts with shifting patterns, and the methodology is presented to show that\nthe induction of shifting patterns by means of Boolean reasoning is due to the\nability of finding all inclusion--maximal {\\delta}-shifting patterns.\n  Experiments with a real dataset show the potential of our approach at finding\nbiclusters with {\\delta}-shifting patterns, which have been evaluated with the\nmean squared residue (MSR), providing an excellent performance at finding\nresults very close to zero.\n", "versions": [{"version": "v1", "created": "Mon, 26 Apr 2021 11:40:17 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Michalak", "Marcin", ""], ["Aguilar-Ruiz", "Jes\u00fas S.", ""]]}, {"id": "2104.12501", "submitter": "Sejin Seo", "authors": "Sejin Seo, Seung-Woo Ko, Jihong Park, Seong-Lyun Kim, and Mehdi Bennis", "title": "Communication-Efficient and Personalized Federated Lottery Ticket\n  Learning", "comments": "5 pages, 2 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT cs.NI math.IT", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  The lottery ticket hypothesis (LTH) claims that a deep neural network (i.e.,\nground network) contains a number of subnetworks (i.e., winning tickets), each\nof which exhibiting identically accurate inference capability as that of the\nground network. Federated learning (FL) has recently been applied in LotteryFL\nto discover such winning tickets in a distributed way, showing higher accuracy\nmulti-task learning than Vanilla FL. Nonetheless, LotteryFL relies on unicast\ntransmission on the downlink, and ignores mitigating stragglers, questioning\nscalability. Motivated by this, in this article we propose a personalized and\ncommunication-efficient federated lottery ticket learning algorithm, coined\nCELL, which exploits downlink broadcast for communication efficiency.\nFurthermore, it utilizes a novel user grouping method, thereby alternating\nbetween FL and lottery learning to mitigate stragglers. Numerical simulations\nvalidate that CELL achieves up to 3.6% higher personalized task classification\naccuracy with 4.3x smaller total communication cost until convergence under the\nCIFAR-10 dataset.\n", "versions": [{"version": "v1", "created": "Mon, 26 Apr 2021 12:01:41 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Seo", "Sejin", ""], ["Ko", "Seung-Woo", ""], ["Park", "Jihong", ""], ["Kim", "Seong-Lyun", ""], ["Bennis", "Mehdi", ""]]}, {"id": "2104.12503", "submitter": "Francesca Soldan", "authors": "Francesca Soldan, Enea Bionda, Giuseppe Mauri, Silvia Celaschi", "title": "Short-term forecast of EV charging stations occupancy probability using\n  big data streaming analysis", "comments": "7 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The widespread diffusion of electric mobility requires a contextual expansion\nof the charging infrastructure. An extended collection and processing of\ninformation regarding charging of electric vehicles may turn each electric\nvehicle charging station into a valuable source of streaming data. Charging\npoint operators may profit from all these data for optimizing their operation\nand planning activities. In such a scenario, big data and machine learning\ntechniques would allow valorizing real-time data coming from electric vehicle\ncharging stations. This paper presents an architecture able to deal with data\nstreams from a charging infrastructure, with the final aim to forecast electric\ncharging station availability after a set amount of minutes from present time.\nBoth batch data regarding past charges and real-time data streams are used to\ntrain a streaming logistic regression model, to take into account recurrent\npast situations and unexpected actual events. The streaming model performs\nbetter than a model trained only using historical data. The results highlight\nthe importance of constantly updating the predictive model parameters in order\nto adapt to changing conditions and always provide accurate forecasts.\n", "versions": [{"version": "v1", "created": "Mon, 26 Apr 2021 12:03:02 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Soldan", "Francesca", ""], ["Bionda", "Enea", ""], ["Mauri", "Giuseppe", ""], ["Celaschi", "Silvia", ""]]}, {"id": "2104.12516", "submitter": "Mark Green", "authors": "Mark Green", "title": "Evaluating the performance of personal, social, health-related,\n  biomarker and genetic data for predicting an individuals future health using\n  machine learning: A longitudinal analysis", "comments": "19 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  As we gain access to a greater depth and range of health-related information\nabout individuals, three questions arise: (1) Can we build better models to\npredict individual-level risk of ill health? (2) How much data do we need to\neffectively predict ill health? (3) Are new methods required to process the\nadded complexity that new forms of data bring? The aim of the study is to apply\na machine learning approach to identify the relative contribution of personal,\nsocial, health-related, biomarker and genetic data as predictors of future\nhealth in individuals. Using longitudinal data from 6830 individuals in the UK\nfrom Understanding Society (2010-12 to 2015-17), the study compares the\npredictive performance of five types of measures: personal (e.g. age, sex),\nsocial (e.g. occupation, education), health-related (e.g. body weight, grip\nstrength), biomarker (e.g. cholesterol, hormones) and genetic single nucleotide\npolymorphisms (SNPs). The predicted outcome variable was limiting long-term\nillness one and five years from baseline. Two machine learning approaches were\nused to build predictive models: deep learning via neural networks and XGBoost\n(gradient boosting decision trees). Model fit was compared to traditional\nlogistic regression models. Results found that health-related measures had the\nstrongest prediction of future health status, with genetic data performing\npoorly. Machine learning models only offered marginal improvements in model\naccuracy when compared to logistic regression models, but also performed well\non other metrics e.g. neural networks were best on AUC and XGBoost on\nprecision. The study suggests that increasing complexity of data and methods\ndoes not necessarily translate to improved understanding of the determinants of\nhealth or performance of predictive models of ill health.\n", "versions": [{"version": "v1", "created": "Mon, 26 Apr 2021 12:31:40 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Green", "Mark", ""]]}, {"id": "2104.12518", "submitter": "Amit Roy", "authors": "Amit Roy, Kashob Kumar Roy, Amin Ahsan Ali, M Ashraful Amin and A K M\n  Mahbubur Rahman", "title": "Unified Spatio-Temporal Modeling for Traffic Forecasting using Graph\n  Neural Network", "comments": "Accepted for publication in International Joint Conference on Neural\n  Networks (IJCNN-2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Research in deep learning models to forecast traffic intensities has gained\ngreat attention in recent years due to their capability to capture the complex\nspatio-temporal relationships within the traffic data. However, most\nstate-of-the-art approaches have designed spatial-only (e.g. Graph Neural\nNetworks) and temporal-only (e.g. Recurrent Neural Networks) modules to\nseparately extract spatial and temporal features. However, we argue that it is\nless effective to extract the complex spatio-temporal relationship with such\nfactorized modules. Besides, most existing works predict the traffic intensity\nof a particular time interval only based on the traffic data of the previous\none hour of that day. And thereby ignores the repetitive daily/weekly pattern\nthat may exist in the last hour of data. Therefore, we propose a Unified\nSpatio-Temporal Graph Convolution Network (USTGCN) for traffic forecasting that\nperforms both spatial and temporal aggregation through direct information\npropagation across different timestamp nodes with the help of spectral graph\nconvolution on a spatio-temporal graph. Furthermore, it captures historical\ndaily patterns in previous days and current-day patterns in current-day traffic\ndata. Finally, we validate our work's effectiveness through experimental\nanalysis, which shows that our model USTGCN can outperform state-of-the-art\nperformances in three popular benchmark datasets from the Performance\nMeasurement System (PeMS). Moreover, the training time is reduced significantly\nwith our proposed USTGCN model.\n", "versions": [{"version": "v1", "created": "Mon, 26 Apr 2021 12:33:17 GMT"}, {"version": "v2", "created": "Wed, 28 Apr 2021 07:44:19 GMT"}], "update_date": "2021-04-29", "authors_parsed": [["Roy", "Amit", ""], ["Roy", "Kashob Kumar", ""], ["Ali", "Amin Ahsan", ""], ["Amin", "M Ashraful", ""], ["Rahman", "A K M Mahbubur", ""]]}, {"id": "2104.12528", "submitter": "Sayeed Shafayet Chowdhury", "authors": "Sayeed Shafayet Chowdhury, Isha Garg and Kaushik Roy", "title": "Spatio-Temporal Pruning and Quantization for Low-latency Spiking Neural\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.IV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Spiking Neural Networks (SNNs) are a promising alternative to traditional\ndeep learning methods since they perform event-driven information processing.\nHowever, a major drawback of SNNs is high inference latency. The efficiency of\nSNNs could be enhanced using compression methods such as pruning and\nquantization. Notably, SNNs, unlike their non-spiking counterparts, consist of\na temporal dimension, the compression of which can lead to latency reduction.\nIn this paper, we propose spatial and temporal pruning of SNNs. First,\nstructured spatial pruning is performed by determining the layer-wise\nsignificant dimensions using principal component analysis of the average\naccumulated membrane potential of the neurons. This step leads to 10-14X model\ncompression. Additionally, it enables inference with lower latency and\ndecreases the spike count per inference. To further reduce latency, temporal\npruning is performed by gradually reducing the timesteps while training. The\nnetworks are trained using surrogate gradient descent based backpropagation and\nwe validate the results on CIFAR10 and CIFAR100, using VGG architectures. The\nspatiotemporally pruned SNNs achieve 89.04% and 66.4% accuracy on CIFAR10 and\nCIFAR100, respectively, while performing inference with 3-30X reduced latency\ncompared to state-of-the-art SNNs. Moreover, they require 8-14X lesser compute\nenergy compared to their unpruned standard deep learning counterparts. The\nenergy numbers are obtained by multiplying the number of operations with energy\nper operation. These SNNs also provide 1-4% higher robustness against Gaussian\nnoise corrupted inputs. Furthermore, we perform weight quantization and find\nthat performance remains reasonably stable up to 5-bit quantization.\n", "versions": [{"version": "v1", "created": "Mon, 26 Apr 2021 12:50:58 GMT"}, {"version": "v2", "created": "Thu, 29 Apr 2021 00:15:55 GMT"}], "update_date": "2021-04-30", "authors_parsed": [["Chowdhury", "Sayeed Shafayet", ""], ["Garg", "Isha", ""], ["Roy", "Kaushik", ""]]}, {"id": "2104.12546", "submitter": "Andrea Loreggia", "authors": "Andrea Loreggia, Anna Passarelli", "title": "The Effects of Air Quality on the Spread of the COVID-19. An Artificial\n  Intelligence Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The COVID-19 pandemic considerably affects public health systems around the\nworld. The lack of knowledge about the virus, the extension of this phenomenon,\nand the speed of the evolution of the infection are all factors that highlight\nthe necessity of employing new approaches to study these events. Artificial\nintelligence techniques may be useful in analyzing data related to areas\naffected by the virus. The aim of this work is to investigate any possible\nrelationships between air quality and confirmed cases of COVID-19 in Italian\ndistricts. Specifically, we report an analysis of the correlation between daily\nCOVID-19 cases and environmental factors, such as temperature, relative\nhumidity, and atmospheric pollutants. Our analysis confirms a significant\nassociation of some environmental parameters with the spread of the virus. This\nsuggests that machine learning models trained on the environmental parameters\nto predict the number of future infected cases may be accurate. Predictive\nmodels may be useful for helping institutions in making decisions for\nprotecting the population and contrasting the pandemic.\n", "versions": [{"version": "v1", "created": "Fri, 9 Apr 2021 19:08:59 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Loreggia", "Andrea", ""], ["Passarelli", "Anna", ""]]}, {"id": "2104.12556", "submitter": "Longbing Cao", "authors": "Longbing Cao and Qing Liu", "title": "COVID-19 Modeling: A Review", "comments": "67 pages, 3 figures, 9 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The SARS-CoV-2 virus and COVID-19 disease have posed unprecedented and\noverwhelming challenges and opportunities to data and domain-driven modeling.\nThis paper makes a comprehensive review of the challenges, tasks, methods, gaps\nand opportunities on modeling COVID-19 problems and data. It constructs a\nresearch landscape of COVID-19 modeling, and further categorizes, compares and\ndiscusses the related work on modeling COVID-19 epidemic transmission processes\nand dynamics, case identification and tracing, infection diagnosis and trends,\nmedical treatments, non-pharmaceutical intervention effect, drug and vaccine\ndevelopment, psychological, economic and social impact, and misinformation,\netc. The modeling methods involve mathematical and statistical models,\ndomain-driven modeling by epidemiological compartmental models, medical and\nbiomedical analysis, data-driven learning by shallow and deep machine learning,\nsimulation systems, social science methods, and hybrid methods.\n", "versions": [{"version": "v1", "created": "Fri, 16 Apr 2021 12:41:15 GMT"}, {"version": "v2", "created": "Mon, 12 Jul 2021 23:46:57 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Cao", "Longbing", ""], ["Liu", "Qing", ""]]}, {"id": "2104.12561", "submitter": "Kashif Ahmad", "authors": "Yasir Saleem Afridi, Kashif Ahmad, Laiq Hassan", "title": "Artificial Intelligence Based Prognostic Maintenance of Renewable Energy\n  Systems: A Review of Techniques, Challenges, and Future Research Directions", "comments": "20 pages, 4 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Since the depletion of fossil fuels, the world has started to rely heavily on\nrenewable sources of energy. With every passing year, our dependency on the\nrenewable sources of energy is increasing exponentially. As a result, complex\nand hybrid generation systems are being designed and developed to meet the\nenergy demands and ensure energy security in a country. The continual\nimprovement in the technology and an effort towards the provision of\nuninterrupted power to the end-users is strongly dependent on an effective and\nfault resilient Operation and Maintenance (O&M) system. Ingenious algorithms\nand techniques are hence been introduced aiming to minimize equipment and plant\ndowntime. Efforts are being made to develop robust Prognostic Maintenance\nsystems that can identify the faults before they occur. To this aim, complex\nData Analytics and Machine Learning (ML) techniques are being used to increase\nthe overall efficiency of these prognostic maintenance systems.\n  This paper provides an overview of the predictive/prognostic maintenance\nframeworks reported in the literature. We pay a particular focus to the\napproaches, challenges including data-related issues, such as the availability\nand quality of the data and data auditing, feature engineering,\ninterpretability, and security issues. Being a key aspect of ML-based\nsolutions, we also discuss some of the commonly used publicly available\ndatasets in the domain. The paper also identifies key future research\ndirections. We believe such detailed analysis will provide a baseline for\nfuture research in the domain.\n", "versions": [{"version": "v1", "created": "Tue, 20 Apr 2021 11:41:00 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Afridi", "Yasir Saleem", ""], ["Ahmad", "Kashif", ""], ["Hassan", "Laiq", ""]]}, {"id": "2104.12570", "submitter": "Nikolaos Bakas", "authors": "Nikolaos P. Bakas", "title": "Algorithmic Solution for Non-Square, Dense Systems of Linear Equations,\n  with applications in Feature Selection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present a novel algorithm attaining excessively fast, the sought solution\nof linear systems of equations. The algorithm is short in its basic formulation\nand by definition vectorised, while the memory allocation demands trivial,\nbecause for each iteration only one dimension of the given input matrix\n$\\mathbf x$ is utilized. The execution time is very short compared with\nstate-of-the-art methods, exhibiting up to $\\mathcal{O}(10^3)$ speed-up and low\nmemory allocation demands, especially for non-square Systems of Linear\nEquations, with ratio of equations versus features high (tall systems), or low\n(wide systems) accordingly. The accuracy is high and straightforwardly\ncontrolled, and the numerical results highlight the efficiency of the proposed\nalgorithm, in terms of computation time, solution accuracy and memory\nallocations demands. The parallelisation of the algorithm is also presented in\nmulti-threaded and GPU accelerators' setting. The paper also comprises a\ntheoretical proof for the algorithmic convergence. Finally, we extend the\nimplementation of the proposed algorithmic rationale to feature selection\ntasks.\n", "versions": [{"version": "v1", "created": "Mon, 26 Apr 2021 13:40:31 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Bakas", "Nikolaos P.", ""]]}, {"id": "2104.12576", "submitter": "Yanhang Zhang", "authors": "Yanhang Zhang, Junxian Zhu, Jin Zhu, Xueqin Wang", "title": "Certifiably Polynomial Algorithm for Best Group Subset Selection", "comments": "45 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Best group subset selection aims to choose a small part of non-overlapping\ngroups to achieve the best interpretability on the response variable. It is\npractically attractive for group variable selection; however, due to the\ncomputational intractability in high dimensionality setting, it doesn't catch\nenough attention. To fill the blank of efficient algorithms for best group\nsubset selection, in this paper, we propose a group-splicing algorithm that\niteratively detects effective groups and excludes the helpless ones. Moreover,\ncoupled with a novel Bayesian group information criterion, an adaptive\nalgorithm is developed to determine the true group subset size. It is\ncertifiable that our algorithms enable identifying the optimal group subset in\npolynomial time under mild conditions. We demonstrate the efficiency and\naccuracy of our proposal by comparing state-of-the-art algorithms on both\nsynthetic and real-world datasets.\n", "versions": [{"version": "v1", "created": "Fri, 23 Apr 2021 03:05:11 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Zhang", "Yanhang", ""], ["Zhu", "Junxian", ""], ["Zhu", "Jin", ""], ["Wang", "Xueqin", ""]]}, {"id": "2104.12581", "submitter": "Bochen Shen", "authors": "Longling Zhang, Bochen Shen, Ahmed Barnawi, Shan Xi, Neeraj Kumar, Yi\n  Wu", "title": "FedDPGAN: Federated Differentially Private Generative Adversarial\n  Networks Framework for the Detection of COVID-19 Pneumonia", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Existing deep learning technologies generally learn the features of chest\nX-ray data generated by Generative Adversarial Networks (GAN) to diagnose\nCOVID-19 pneumonia. However, the above methods have a critical challenge: data\nprivacy. GAN will leak the semantic information of the training data which can\nbe used to reconstruct the training samples by attackers, thereby this method\nwill leak the privacy of the patient. Furthermore, for this reason that is the\nlimitation of the training data sample, different hospitals jointly train the\nmodel through data sharing, which will also cause the privacy leakage. To solve\nthis problem, we adopt the Federated Learning (FL) frame-work which is a new\ntechnique being used to protect the data privacy. Under the FL framework and\nDifferentially Private thinking, we propose a FederatedDifferentially Private\nGenerative Adversarial Network (FedDPGAN) to detectCOVID-19 pneumonia for\nsustainable smart cities. Specifically, we use DP-GAN to privately generate\ndiverse patient data in which differential privacy technology is introduced to\nmake sure the privacy protection of the semantic information of training\ndataset. Furthermore, we leverage FL to allow hospitals to collaboratively\ntrain COVID-19 models without sharing the original data. Under Independent and\nIdentically Distributed (IID) and non-IID settings, The evaluation of the\nproposed model is on three types of chest X-ray (CXR) images dataset (COVID-19,\nnormal, and normal pneumonia). A large number of the truthful reports make the\nverification of our model can effectively diagnose COVID-19 without\ncompromising privacy.\n", "versions": [{"version": "v1", "created": "Mon, 26 Apr 2021 13:52:12 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Zhang", "Longling", ""], ["Shen", "Bochen", ""], ["Barnawi", "Ahmed", ""], ["Xi", "Shan", ""], ["Kumar", "Neeraj", ""], ["Wu", "Yi", ""]]}, {"id": "2104.12586", "submitter": "Alessandro D'Ortenzio", "authors": "A. D'Ortenzio and C. Manes", "title": "Consistency issues in Gaussian Mixture Models reduction algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IT cs.LG math.IT math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many contexts Gaussian Mixtures (GM) are used to approximate probability\ndistributions, possibly time-varying. In some applications the number of GM\ncomponents exponentially increases over time, and reduction procedures are\nrequired to keep them reasonably limited. The GM reduction (GMR) problem can be\nformulated by choosing different measures of the dissimilarity of GMs before\nand after reduction, like the Kullback-Leibler Divergence (KLD) and the\nIntegral Squared Error (ISE). Since in no case the solution is obtained in\nclosed form, many approximate GMR algorithms have been proposed in the past\nthree decades, although none of them provides optimality guarantees. In this\nwork we discuss the importance of the choice of the dissimilarity measure and\nthe issue of consistency of all steps of a reduction algorithm with the chosen\nmeasure. Indeed, most of the existing GMR algorithms are composed by several\nsteps which are not consistent with a unique measure, and for this reason may\nproduce reduced GMs far from optimality. In particular, the use of the KLD, of\nthe ISE and normalized ISE is discussed and compared in this perspective.\n", "versions": [{"version": "v1", "created": "Mon, 26 Apr 2021 13:53:46 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["D'Ortenzio", "A.", ""], ["Manes", "C.", ""]]}, {"id": "2104.12592", "submitter": "Chenguang Lu", "authors": "Chenguang Lu", "title": "Understanding and Accelerating EM Algorithm's Convergence by Fair\n  Competition Principle and Rate-Verisimilitude Function", "comments": "31 pages,12 figures. arXiv admin note: text overlap with\n  arXiv:2007.12845", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Why can the Expectation-Maximization (EM) algorithm for mixture models\nconverge? Why can different initial parameters cause various convergence\ndifficulties? The Q-L synchronization theory explains that the observed data\nlog-likelihood L and the complete data log-likelihood Q are positively\ncorrelated; we can achieve maximum L by maximizing Q. According to this theory,\nthe Deterministic Annealing EM (DAEM) algorithm's authors make great efforts to\neliminate locally maximal Q for avoiding L's local convergence. However, this\npaper proves that in some cases, Q may and should decrease for L to increase;\nslow or local convergence exists only because of small samples and unfair\ncompetition. This paper uses marriage competition to explain different\nconvergence difficulties and proposes the Fair Competition Principle (FCP) with\nan initialization map for improving initializations. It uses the\nrate-verisimilitude function, extended from the rate-distortion function, to\nexplain the convergence of the EM and improved EM algorithms. This convergence\nproof adopts variational and iterative methods that Shannon et al. used for\nanalyzing rate-distortion functions. The initialization map can vastly save\nboth algorithms' running times for binary Gaussian mixtures. The FCP and the\ninitialization map are useful for complicated mixtures but not sufficient; we\nneed further studies for specific methods.\n", "versions": [{"version": "v1", "created": "Wed, 21 Apr 2021 20:27:25 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Lu", "Chenguang", ""]]}, {"id": "2104.12594", "submitter": "Syed Muhammad Yousaf Hashmy", "authors": "Yousuf Hashmy, ZillUllah Khan, Rehan Hafiz, Usman Younis, and Tausif\n  Tauqeer", "title": "MAQ-CaF: A Modular Air Quality Calibration and Forecasting method for\n  cross-sensitive pollutants", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The climatic challenges are rising across the globe in general and in worst\nhit under-developed countries in particular. The need for accurate measurements\nand forecasting of pollutants with low-cost deployment is more pertinent today\nthan ever before. Low-cost air quality monitoring sensors are prone to\nerroneous measurements, frequent downtimes, and uncertain operational\nconditions. Such a situation demands a prudent approach to ensure an effective\nand flexible calibration scheme. We propose MAQ-CaF, a modular air quality\ncalibration, and forecasting methodology, that side-steps the challenges of\nunreliability through its modular machine learning-based design which leverages\nthe potential of IoT framework. It stores the calibrated data both locally and\nremotely with an added feature of future predictions. Our specially designed\nvalidation process helps to establish the proposed solution's applicability and\nflexibility without compromising accuracy. CO, SO2, NO2, O3, PM1.0, PM2.5 and\nPM10 were calibrated and monitored with reasonable accuracy. Such an attempt is\na step toward addressing climate change's global challenge through appropriate\nmonitoring and air quality tracking across a wider geographical region via\naffordable monitoring.\n", "versions": [{"version": "v1", "created": "Thu, 22 Apr 2021 13:34:06 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Hashmy", "Yousuf", ""], ["Khan", "ZillUllah", ""], ["Hafiz", "Rehan", ""], ["Younis", "Usman", ""], ["Tauqeer", "Tausif", ""]]}, {"id": "2104.12602", "submitter": "Alex Sim", "authors": "Jeeyung Kim, Alex Sim, Jinoh Kim, Kesheng Wu, Jaegyoon Hahm", "title": "Improving Botnet Detection with Recurrent Neural Network and Transfer\n  Learning", "comments": "arXiv admin note: text overlap with arXiv:2004.00234", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.NI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Botnet detection is a critical step in stopping the spread of botnets and\npreventing malicious activities. However, reliable detection is still a\nchallenging task, due to a wide variety of botnets involving ever-increasing\ntypes of devices and attack vectors. Recent approaches employing machine\nlearning (ML) showed improved performance than earlier ones, but these ML-\nbased approaches still have significant limitations. For example, most ML\napproaches can not incorporate sequential pattern analysis techniques key to\ndetect some classes of botnets. Another common shortcoming of ML-based\napproaches is the need to retrain neural networks in order to detect the\nevolving botnets; however, the training process is time-consuming and requires\nsignificant efforts to label the training data. For fast-evolving botnets, it\nmight take too long to create sufficient training samples before the botnets\nhave changed again. To address these challenges, we propose a novel botnet\ndetection method, built upon Recurrent Variational Autoencoder (RVAE) that\neffectively captures sequential characteristics of botnet activities. In the\nexperiment, this semi-supervised learning method achieves better detection\naccuracy than similar learning methods, especially on hard to detect classes.\nAdditionally, we devise a transfer learning framework to learn from a\nwell-curated source data set and transfer the knowledge to a target problem\ndomain not seen before. Tests show that the true-positive rate (TPR) with\ntransfer learning is higher than the RVAE semi-supervised learning method\ntrained using the target data set (91.8% vs. 68.3%).\n", "versions": [{"version": "v1", "created": "Mon, 26 Apr 2021 14:05:01 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Kim", "Jeeyung", ""], ["Sim", "Alex", ""], ["Kim", "Jinoh", ""], ["Wu", "Kesheng", ""], ["Hahm", "Jaegyoon", ""]]}, {"id": "2104.12608", "submitter": "Saeedeh Parsaeefard", "authors": "Saeedeh Parsaeefard and Alberto Leon Garcia", "title": "Generalized ADMM in Distributed Learning via Variational Inequality", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.DC cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Due to the explosion in size and complexity of modern data sets and privacy\nconcerns of data holders, it is increasingly important to be able to solve\nmachine learning problems in distributed manners. The Alternating Direction\nMethod of Multipliers (ADMM) through the concept of consensus variables is a\npractical algorithm in this context where its diverse variations and its\nperformance have been studied in different application areas. In this paper, we\nstudy the effect of the local data sets of users in the distributed learning of\nADMM. Our aim is to deploy variational inequality (VI) to attain an unified\nview of ADMM variations. Through the simulation results, we demonstrate how\nmore general definitions of consensus parameters and introducing the uncertain\nparameters in distribute approach can help to get the better results in\nlearning processes.\n", "versions": [{"version": "v1", "created": "Mon, 26 Apr 2021 14:16:14 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Parsaeefard", "Saeedeh", ""], ["Garcia", "Alberto Leon", ""]]}, {"id": "2104.12623", "submitter": "Sebastian Szyller", "authors": "Sebastian Szyller, Vasisht Duddu, Tommi Gr\\\"ondahl, N. Asokan", "title": "Good Artists Copy, Great Artists Steal: Model Extraction Attacks Against\n  Image Translation Generative Adversarial Networks", "comments": "9 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning models are typically made available to potential client\nusers via inference APIs. Model extraction attacks occur when a malicious\nclient uses information gleaned from queries to the inference API of a victim\nmodel $F_V$ to build a surrogate model $F_A$ that has comparable functionality.\nRecent research has shown successful model extraction attacks against image\nclassification, and NLP models. In this paper, we show the first model\nextraction attack against real-world generative adversarial network (GAN) image\ntranslation models. We present a framework for conducting model extraction\nattacks against image translation models, and show that the adversary can\nsuccessfully extract functional surrogate models. The adversary is not required\nto know $F_V$'s architecture or any other information about it beyond its\nintended image translation task, and queries $F_V$'s inference interface using\ndata drawn from the same domain as the training data for $F_V$. We evaluate the\neffectiveness of our attacks using three different instances of two popular\ncategories of image translation: (1) Selfie-to-Anime and (2) Monet-to-Photo\n(image style transfer), and (3) Super-Resolution (super resolution). Using\nstandard performance metrics for GANs, we show that our attacks are effective\nin each of the three cases -- the differences between $F_V$ and $F_A$, compared\nto the target are in the following ranges: Selfie-to-Anime: FID $13.36-68.66$,\nMonet-to-Photo: FID $3.57-4.40$, and Super-Resolution: SSIM: $0.06-0.08$ and\nPSNR: $1.43-4.46$. Furthermore, we conducted a large scale (125 participants)\nuser study on Selfie-to-Anime and Monet-to-Photo to show that human perception\nof the images produced by the victim and surrogate models can be considered\nequivalent, within an equivalence bound of Cohen's $d=0.3$.\n", "versions": [{"version": "v1", "created": "Mon, 26 Apr 2021 14:50:59 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Szyller", "Sebastian", ""], ["Duddu", "Vasisht", ""], ["Gr\u00f6ndahl", "Tommi", ""], ["Asokan", "N.", ""]]}, {"id": "2104.12642", "submitter": "Manas Sahni", "authors": "Manas Sahni, Shreya Varshini, Alind Khare, Alexey Tumanov", "title": "CompOFA: Compound Once-For-All Networks for Faster Multi-Platform\n  Deployment", "comments": "Published as a conference paper at ICLR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The emergence of CNNs in mainstream deployment has necessitated methods to\ndesign and train efficient architectures tailored to maximize the accuracy\nunder diverse hardware & latency constraints. To scale these resource-intensive\ntasks with an increasing number of deployment targets, Once-For-All (OFA)\nproposed an approach to jointly train several models at once with a constant\ntraining cost. However, this cost remains as high as 40-50 GPU days and also\nsuffers from a combinatorial explosion of sub-optimal model configurations. We\nseek to reduce this search space -- and hence the training budget -- by\nconstraining search to models close to the accuracy-latency Pareto frontier. We\nincorporate insights of compound relationships between model dimensions to\nbuild CompOFA, a design space smaller by several orders of magnitude. Through\nexperiments on ImageNet, we demonstrate that even with simple heuristics we can\nachieve a 2x reduction in training time and 216x speedup in model\nsearch/extraction time compared to the state of the art, without loss of Pareto\noptimality! We also show that this smaller design space is dense enough to\nsupport equally accurate models for a similar diversity of hardware and latency\ntargets, while also reducing the complexity of the training and subsequent\nextraction algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 26 Apr 2021 15:10:48 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Sahni", "Manas", ""], ["Varshini", "Shreya", ""], ["Khare", "Alind", ""], ["Tumanov", "Alexey", ""]]}, {"id": "2104.12647", "submitter": "Yunpeng Tai", "authors": "Yunpeng Tai", "title": "A Survey Of Regression Algorithms And Connections With Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Regression has attracted immense interest lately due to its effectiveness in\ntasks like predicting values. And Regression is of widespread use in multiple\nfields such as Economics, Finance, Business, Biology and so on. While\nconsiderable studies have proposed some impressive models, few of them have\nprovided a whole picture regarding how and to what extent Regression has\ndeveloped. With the aim of aiding beginners in understanding the relationships\namong different Regression algorithms, this paper characterizes a broad and\nthoughtful selection of recent regression algorithms, providing an organized\nand comprehensive overview of existing work and models utilized frequently. In\nthis paper, the relationship between Regression and Deep Learning is also\ndiscussed and a conclusion can be drawn that Deep Learning can be more powerful\nas an combination with Regression models in the future.\n", "versions": [{"version": "v1", "created": "Mon, 26 Apr 2021 15:18:00 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Tai", "Yunpeng", ""]]}, {"id": "2104.12657", "submitter": "Micha{\\l} Narajewski", "authors": "Micha{\\l} Narajewski, Jens Kley-Holsteg, Florian Ziel", "title": "tsrobprep -- an R package for robust preprocessing of time series data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.MS stat.CO", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Data cleaning is a crucial part of every data analysis exercise. Yet, the\ncurrently available R packages do not provide fast and robust methods for\ncleaning and preparation of time series data. The open source package tsrobprep\nintroduces efficient methods for handling missing values and outliers using\nmodel based approaches. For data imputation a probabilistic replacement model\nis proposed, which may consist of autoregressive components and external\ninputs. For outlier detection a clustering algorithm based on finite mixture\nmodelling is introduced, which considers typical time series related properties\nas features. By assigning to each observation a probability of being an\noutlying data point, the degree of outlyingness can be determined. The methods\nwork robust and are fully tunable. Moreover, by providing the\nauto_data_cleaning function the data preprocessing can be carried out in one\ncast, without manual tuning and providing suitable results. The primary\nmotivation of the package is the preprocessing of energy system data, however,\nthe package is also suited for other moderate and large sized time series data\nset. We present application for electricity load, wind and solar power data.\n", "versions": [{"version": "v1", "created": "Mon, 26 Apr 2021 15:35:11 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Narajewski", "Micha\u0142", ""], ["Kley-Holsteg", "Jens", ""], ["Ziel", "Florian", ""]]}, {"id": "2104.12667", "submitter": "Benedikt Fesl", "authors": "B. Fesl, N. Turan, M. Koller, and W. Utschick", "title": "A Low-Complexity MIMO Channel Estimator with Implicit Structure of a\n  Convolutional Neural Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG math.IT", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A low-complexity convolutional neural network estimator which learns the\nminimum mean squared error channel estimator for single-antenna users was\nrecently proposed. We generalize the architecture to the estimation of MIMO\nchannels with multiple-antenna users and incorporate complexity-reducing\nassumptions based on the channel model. Learning is used in this context to\ncombat the mismatch between the assumptions and real scenarios where the\nassumptions may not hold. We derive a high-level description of the estimator\nfor arbitrary choices of the pilot sequence. It turns out that the proposed\nestimator has the implicit structure of a two-layered convolutional neural\nnetwork, where the derived quantities can be relaxed to learnable parameters.\nWe show that by using discrete Fourier transform based pilots the number of\nlearnable network parameters decreases significantly and the online run time of\nthe estimator is reduced considerably, where we can achieve linearithmic order\nof complexity in the number of antennas. Numerical results demonstrate\nperformance gains compared to state-of-the-art algorithms from the field of\ncompressive sensing or covariance estimation of the same or even higher\ncomputational complexity. The simulation code is available online.\n", "versions": [{"version": "v1", "created": "Mon, 26 Apr 2021 15:52:29 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Fesl", "B.", ""], ["Turan", "N.", ""], ["Koller", "M.", ""], ["Utschick", "W.", ""]]}, {"id": "2104.12669", "submitter": "Brian Lim", "authors": "Xuejun Zhao, Wencan Zhang, Xiaokui Xiao, Brian Y. Lim", "title": "Exploiting Explanations for Model Inversion Attacks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The successful deployment of artificial intelligence (AI) in many domains\nfrom healthcare to hiring requires their responsible use, particularly in model\nexplanations and privacy. Explainable artificial intelligence (XAI) provides\nmore information to help users to understand model decisions, yet this\nadditional knowledge exposes additional risks for privacy attacks. Hence,\nproviding explanation harms privacy. We study this risk for image-based model\ninversion attacks and identified several attack architectures with increasing\nperformance to reconstruct private image data from model explanations. We have\ndeveloped several multi-modal transposed CNN architectures that achieve\nsignificantly higher inversion performance than using the target model\nprediction only. These XAI-aware inversion models were designed to exploit the\nspatial knowledge in image explanations. To understand which explanations have\nhigher privacy risk, we analyzed how various explanation types and factors\ninfluence inversion performance. In spite of some models not providing\nexplanations, we further demonstrate increased inversion performance even for\nnon-explainable target models by exploiting explanations of surrogate models\nthrough attention transfer. This method first inverts an explanation from the\ntarget prediction, then reconstructs the target image. These threats highlight\nthe urgent and significant privacy risks of explanations and calls attention\nfor new privacy preservation techniques that balance the dual-requirement for\nAI explainability and privacy.\n", "versions": [{"version": "v1", "created": "Mon, 26 Apr 2021 15:53:57 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Zhao", "Xuejun", ""], ["Zhang", "Wencan", ""], ["Xiao", "Xiaokui", ""], ["Lim", "Brian Y.", ""]]}, {"id": "2104.12672", "submitter": "Yiqiao Yin", "authors": "Shaw-Hwa Lo, Yiqiao Yin", "title": "A Novel Interaction-based Methodology Towards Explainable AI with Better\n  Understanding of Pneumonia Chest X-ray Images", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.AP", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  In the field of eXplainable AI (XAI), robust \"blackbox\" algorithms such as\nConvolutional Neural Networks (CNNs) are known for making high prediction\nperformance. However, the ability to explain and interpret these algorithms\nstill require innovation in the understanding of influential and, more\nimportantly, explainable features that directly or indirectly impact the\nperformance of predictivity. A number of methods existing in literature focus\non visualization techniques but the concepts of explainability and\ninterpretability still require rigorous definition. In view of the above needs,\nthis paper proposes an interaction-based methodology -- Influence Score\n(I-score) -- to screen out the noisy and non-informative variables in the\nimages hence it nourishes an environment with explainable and interpretable\nfeatures that are directly associated to feature predictivity. We apply the\nproposed method on a real world application in Pneumonia Chest X-ray Image data\nset and produced state-of-the-art results. We demonstrate how to apply the\nproposed approach for more general big data problems by improving the\nexplainability and interpretability without sacrificing the prediction\nperformance. The contribution of this paper opens a novel angle that moves the\ncommunity closer to the future pipelines of XAI problems.\n", "versions": [{"version": "v1", "created": "Mon, 19 Apr 2021 23:02:43 GMT"}, {"version": "v2", "created": "Sun, 13 Jun 2021 03:57:08 GMT"}, {"version": "v3", "created": "Tue, 15 Jun 2021 05:29:26 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Lo", "Shaw-Hwa", ""], ["Yin", "Yiqiao", ""]]}, {"id": "2104.12676", "submitter": "Babak Barazandeh", "authors": "Babak Barazandeh, Davoud Ataee Tarzanagh, George Michailidis", "title": "Solving a class of non-convex min-max games using adaptive momentum\n  methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adaptive momentum methods have recently attracted a lot of attention for\ntraining of deep neural networks. They use an exponential moving average of\npast gradients of the objective function to update both search directions and\nlearning rates. However, these methods are not suited for solving min-max\noptimization problems that arise in training generative adversarial networks.\nIn this paper, we propose an adaptive momentum min-max algorithm that\ngeneralizes adaptive momentum methods to the non-convex min-max regime.\nFurther, we establish non-asymptotic rates of convergence for the proposed\nalgorithm when used in a reasonably broad class of non-convex min-max\noptimization problems. Experimental results illustrate its superior performance\nvis-a-vis benchmark methods for solving such problems.\n", "versions": [{"version": "v1", "created": "Mon, 26 Apr 2021 16:06:39 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Barazandeh", "Babak", ""], ["Tarzanagh", "Davoud Ataee", ""], ["Michailidis", "George", ""]]}, {"id": "2104.12678", "submitter": "Yuchang Sun", "authors": "Yuchang Sun and Jiawei Shao and Yuyi Mao and Jun Zhang", "title": "Semi-Decentralized Federated Edge Learning for Fast Convergence on\n  Non-IID Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated edge learning (FEEL) has emerged as an effective alternative to\nreduce the large communication latency in Cloud-based machine learning\nsolutions, while preserving data privacy. Unfortunately, the learning\nperformance of FEEL may be compromised due to limited training data in a single\nedge cluster. In this paper, we investigate a novel framework of FEEL, namely\nsemi-decentralized federated edge learning (SD-FEEL). By allowing model\naggregation between different edge clusters, SD-FEEL enjoys the benefit of FEEL\nin reducing training latency and improves the learning performance by accessing\nricher training data from multiple edge clusters. A training algorithm for\nSD-FEEL with three main procedures in each round is presented, including local\nmodel updates, intra-cluster and inter-cluster model aggregations, and it is\nproved to converge on non-independent and identically distributed (non-IID)\ndata. We also characterize the interplay between the network topology of the\nedge servers and the communication overhead of inter-cluster model aggregation\non training performance. Experiment results corroborate our analysis and\ndemonstrate the effectiveness of SD-FFEL in achieving fast convergence.\nBesides, guidelines on choosing critical hyper-parameters of the training\nalgorithm are also provided.\n", "versions": [{"version": "v1", "created": "Mon, 26 Apr 2021 16:11:47 GMT"}, {"version": "v2", "created": "Tue, 27 Apr 2021 04:27:54 GMT"}, {"version": "v3", "created": "Tue, 18 May 2021 06:38:39 GMT"}], "update_date": "2021-05-19", "authors_parsed": [["Sun", "Yuchang", ""], ["Shao", "Jiawei", ""], ["Mao", "Yuyi", ""], ["Zhang", "Jun", ""]]}, {"id": "2104.12679", "submitter": "R\\'emi Bernhard", "authors": "R\\'emi Bernhard, Pierre-Alain Moellic, Martial Mermillod, Yannick\n  Bourrier, Romain Cohendet, Miguel Solinas, Marina Reyboz", "title": "Impact of Spatial Frequency Based Constraints on Adversarial Robustness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial examples mainly exploit changes to input pixels to which humans\nare not sensitive to, and arise from the fact that models make decisions based\non uninterpretable features. Interestingly, cognitive science reports that the\nprocess of interpretability for human classification decision relies\npredominantly on low spatial frequency components. In this paper, we\ninvestigate the robustness to adversarial perturbations of models enforced\nduring training to leverage information corresponding to different spatial\nfrequency ranges. We show that it is tightly linked to the spatial frequency\ncharacteristics of the data at stake. Indeed, depending on the data set, the\nsame constraint may results in very different level of robustness (up to 0.41\nadversarial accuracy difference). To explain this phenomenon, we conduct\nseveral experiments to enlighten influential factors such as the level of\nsensitivity to high frequencies, and the transferability of adversarial\nperturbations between original and low-pass filtered inputs.\n", "versions": [{"version": "v1", "created": "Mon, 26 Apr 2021 16:12:04 GMT"}, {"version": "v2", "created": "Wed, 5 May 2021 07:30:28 GMT"}], "update_date": "2021-05-06", "authors_parsed": [["Bernhard", "R\u00e9mi", ""], ["Moellic", "Pierre-Alain", ""], ["Mermillod", "Martial", ""], ["Bourrier", "Yannick", ""], ["Cohendet", "Romain", ""], ["Solinas", "Miguel", ""], ["Reyboz", "Marina", ""]]}, {"id": "2104.12686", "submitter": "Benedikt Pf\\\"ulb", "authors": "Alexander Gepperth, Benedikt Pf\\\"ulb", "title": "Image Modeling with Deep Convolutional Gaussian Mixture Models", "comments": "accepted at IJCNN2021, 9 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this conceptual work, we present Deep Convolutional Gaussian Mixture\nModels (DCGMMs): a new formulation of deep hierarchical Gaussian Mixture Models\n(GMMs) that is particularly suitable for describing and generating images.\nVanilla (i.e., flat) GMMs require a very large number of components to describe\nimages well, leading to long training times and memory issues. DCGMMs avoid\nthis by a stacked architecture of multiple GMM layers, linked by convolution\nand pooling operations. This allows to exploit the compositionality of images\nin a similar way as deep CNNs do. DCGMMs can be trained end-to-end by\nStochastic Gradient Descent. This sets them apart from vanilla GMMs which are\ntrained by Expectation-Maximization, requiring a prior k-means initialization\nwhich is infeasible in a layered structure. For generating sharp images with\nDCGMMs, we introduce a new gradient-based technique for sampling through\nnon-invertible operations like convolution and pooling. Based on the MNIST and\nFashionMNIST datasets, we validate the DCGMMs model by demonstrating its\nsuperiority over flat GMMs for clustering, sampling and outlier detection.\n", "versions": [{"version": "v1", "created": "Mon, 19 Apr 2021 12:08:53 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Gepperth", "Alexander", ""], ["Pf\u00fclb", "Benedikt", ""]]}, {"id": "2104.12696", "submitter": "Isaac Neal", "authors": "Isaac Neal, Sohan Seth, Gary Watmough, Mamadou Saliou Diallo", "title": "Towards Sustainable Census Independent Population Estimation in\n  Mozambique", "comments": "5 pages, 2 figures, published in the AI for Public Health Workshop,\n  ICLR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Reliable and frequent population estimation is key for making policies around\nvaccination and planning infrastructure delivery. Since censuses lack the\nspatio-temporal resolution required for these tasks, census-independent\napproaches, using remote sensing and microcensus data, have become popular. We\nestimate intercensal population count in two pilot districts in Mozambique. To\nencourage sustainability, we assess the feasibility of using publicly available\ndatasets to estimate population. We also explore transfer learning with\nexisting annotated datasets for predicting building footprints, and training\nwith additional `dot' annotations from regions of interest to enhance these\nestimations. We observe that population predictions improve when using\nfootprint area estimated with this approach versus only publicly available\nfeatures.\n", "versions": [{"version": "v1", "created": "Mon, 26 Apr 2021 16:37:41 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Neal", "Isaac", ""], ["Seth", "Sohan", ""], ["Watmough", "Gary", ""], ["Diallo", "Mamadou Saliou", ""]]}, {"id": "2104.12717", "submitter": "Tommaso Teofili", "authors": "Rob Geada, Tommaso Teofili, Rui Vieira, Rebecca Whitworth, Daniele\n  Zonca", "title": "TrustyAI Explainability Toolkit", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial intelligence (AI) is becoming increasingly more popular and can be\nfound in workplaces and homes around the world. However, how do we ensure trust\nin these systems? Regulation changes such as the GDPR mean that users have a\nright to understand how their data has been processed as well as saved.\nTherefore if, for example, you are denied a loan you have the right to ask why.\nThis can be hard if the method for working this out uses \"black box\" machine\nlearning techniques such as neural networks. TrustyAI is a new initiative which\nlooks into explainable artificial intelligence (XAI) solutions to address\ntrustworthiness in ML as well as decision services landscapes.\n  In this paper we will look at how TrustyAI can support trust in decision\nservices and predictive models. We investigate techniques such as LIME, SHAP\nand counterfactuals, benchmarking both LIME and counterfactual techniques\nagainst existing implementations. We also look into an extended version of\nSHAP, which supports background data selection to be evaluated based on\nquantitative data and allows for error bounds.\n", "versions": [{"version": "v1", "created": "Mon, 26 Apr 2021 17:00:32 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Geada", "Rob", ""], ["Teofili", "Tommaso", ""], ["Vieira", "Rui", ""], ["Whitworth", "Rebecca", ""], ["Zonca", "Daniele", ""]]}, {"id": "2104.12722", "submitter": "Yayati Jadhav", "authors": "Yayati Jadhav, Amir Barati Farimani", "title": "Dominant motion identification of multi-particle system using deep\n  learning from video", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Identifying underlying governing equations and physical relevant information\nfrom high-dimensional observable data has always been a challenge in physical\nsciences. With the recent advances in sensing technology and available\ndatasets, various machine learning techniques have made it possible to distill\nunderlying mathematical models from sufficiently clean and usable datasets.\nHowever, most of these techniques rely on prior knowledge of the system and\nnoise-free data obtained by simulation of physical system or by direct\nmeasurements of the signals. Hence, the inference obtained by using these\ntechniques is often unreliable to be used in the real world where observed data\nis noisy and requires feature engineering to extract relevant features. In this\nwork, we provide a deep-learning framework that extracts relevant information\nfrom real-world videos of highly stochastic systems, with no prior knowledge\nand distills the underlying governing equation representing the system. We\ndemonstrate this approach on videos of confined multi-agent/particle systems of\nants, termites, fishes as well as a simulated confined multi-particle system\nwith elastic collision interactions. Furthermore, we explore how these\nseemingly diverse systems have predictable underlying behavior. In this study,\nwe have used computer vision and motion tracking to extract spatial\ntrajectories of individual agents/particles in a system, and by using LSTM VAE\nwe projected these features on a low-dimensional latent space from which the\nunderlying differential equation representing the data was extracted using\nSINDy framework.\n", "versions": [{"version": "v1", "created": "Mon, 26 Apr 2021 17:10:56 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Jadhav", "Yayati", ""], ["Farimani", "Amir Barati", ""]]}, {"id": "2104.12733", "submitter": "Ward Haddadin", "authors": "Ward Haddadin", "title": "Invariant polynomials and machine learning", "comments": "27 pages, 5 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "hep-ph cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present an application of invariant polynomials in machine learning. Using\nthe methods developed in previous work, we obtain two types of generators of\nthe Lorentz- and permutation-invariant polynomials in particle momenta; minimal\nalgebra generators and Hironaka decompositions. We discuss and prove some\napproximation theorems to make use of these invariant generators in machine\nlearning algorithms in general and in neural networks specifically. By\nimplementing these generators in neural networks applied to regression tasks,\nwe test the improvements in performance under a wide range of hyperparameter\nchoices and find a reduction of the loss on training data and a significant\nreduction of the loss on validation data. For a different approach on\nquantifying the performance of these neural networks, we treat the problem from\na Bayesian inference perspective and employ nested sampling techniques to\nperform model comparison. Beyond a certain network size, we find that networks\nutilising Hironaka decompositions perform the best.\n", "versions": [{"version": "v1", "created": "Mon, 26 Apr 2021 17:24:29 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Haddadin", "Ward", ""]]}, {"id": "2104.12741", "submitter": "Julian Risch", "authors": "Timo M\\\"oller and Julian Risch and Malte Pietsch", "title": "GermanQuAD and GermanDPR: Improving Non-English Question Answering and\n  Passage Retrieval", "comments": "See https://deepset.ai/germanquad for downloading the datasets and\n  models", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A major challenge of research on non-English machine reading for question\nanswering (QA) is the lack of annotated datasets. In this paper, we present\nGermanQuAD, a dataset of 13,722 extractive question/answer pairs. To improve\nthe reproducibility of the dataset creation approach and foster QA research on\nother languages, we summarize lessons learned and evaluate reformulation of\nquestion/answer pairs as a way to speed up the annotation process. An\nextractive QA model trained on GermanQuAD significantly outperforms\nmultilingual models and also shows that machine-translated training data cannot\nfully substitute hand-annotated training data in the target language. Finally,\nwe demonstrate the wide range of applications of GermanQuAD by adapting it to\nGermanDPR, a training dataset for dense passage retrieval (DPR), and train and\nevaluate the first non-English DPR model.\n", "versions": [{"version": "v1", "created": "Mon, 26 Apr 2021 17:34:31 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["M\u00f6ller", "Timo", ""], ["Risch", "Julian", ""], ["Pietsch", "Malte", ""]]}, {"id": "2104.12744", "submitter": "Hadi Jahanshahi", "authors": "Hadi Jahanshahi, Kritika Chhabra, Mucahit Cevik, Ay\\c{s}e Ba\\c{s}ar", "title": "DABT: A Dependency-aware Bug Triaging Method", "comments": "This paper is accepted at EASE'21: The International Conference on\n  Evaluation and Assessment in Software Engineering; June 21--23, 2021", "journal-ref": null, "doi": "10.1145/3463274.3463342.", "report-no": null, "categories": "cs.SE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In software engineering practice, fixing a bug promptly reduces the\nassociated costs. On the other hand, the manual bug fixing process can be\ntime-consuming, cumbersome, and error-prone. In this work, we introduce a bug\ntriaging method, called Dependency-aware Bug Triaging (DABT), which leverages\nnatural language processing and integer programming to assign bugs to\nappropriate developers. Unlike previous works that mainly focus on one aspect\nof the bug reports, DABT considers the textual information, cost associated\nwith each bug, and dependency among them. Therefore, this comprehensive\nformulation covers the most important aspect of the previous works while\nconsidering the blocking effect of the bugs. We report the performance of the\nalgorithm on three open-source software systems, i.e., EclipseJDT, LibreOffice,\nand Mozilla. Our result shows that DABT is able to reduce the number of overdue\nbugs up to 12\\%. It also decreases the average fixing time of the bugs by half.\nMoreover, it reduces the complexity of the bug dependency graph by prioritizing\nblocking bugs.\n", "versions": [{"version": "v1", "created": "Mon, 26 Apr 2021 17:35:42 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Jahanshahi", "Hadi", ""], ["Chhabra", "Kritika", ""], ["Cevik", "Mucahit", ""], ["Ba\u015far", "Ay\u015fe", ""]]}, {"id": "2104.12748", "submitter": "Abhinav Tamaskar", "authors": "Abhinav Tamaskar, Bud Mishra", "title": "Efficient Evolutionary Models with Digraphons", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present two main contributions which help us in leveraging the theory of\ngraphons for modeling evolutionary processes. We show a generative model for\ndigraphons using a finite basis of subgraphs, which is representative of\nbiological networks with evolution by duplication. We show a simple MAP\nestimate on the Bayesian non parametric model using the Dirichlet Chinese\nrestaurant process representation, with the help of a Gibbs sampling algorithm\nto infer the prior. Next we show an efficient implementation to do simulations\non finite basis segmentations of digraphons. This implementation is used for\ndeveloping fast evolutionary simulations with the help of an efficient 2-D\nrepresentation of the digraphon using dynamic segment-trees with the\nsquare-root decomposition representation. We further show how this\nrepresentation is flexible enough to handle changing graph nodes and can be\nused to also model dynamic digraphons with the help of an amortized update\nrepresentation to achieve an efficient time complexity of the update at\n$O(\\sqrt{|V|}\\log{|V|})$.\n", "versions": [{"version": "v1", "created": "Mon, 26 Apr 2021 17:40:13 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Tamaskar", "Abhinav", ""], ["Mishra", "Bud", ""]]}, {"id": "2104.12753", "submitter": "Chengyue Gong", "authors": "Chengyue Gong, Dilin Wang, Meng Li, Vikas Chandra, Qiang Liu", "title": "Vision Transformers with Patch Diversification", "comments": "preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Vision transformer has demonstrated promising performance on challenging\ncomputer vision tasks. However, directly training the vision transformers may\nyield unstable and sub-optimal results. Recent works propose to improve the\nperformance of the vision transformers by modifying the transformer structures,\ne.g., incorporating convolution layers. In contrast, we investigate an\northogonal approach to stabilize the vision transformer training without\nmodifying the networks. We observe the instability of the training can be\nattributed to the significant similarity across the extracted patch\nrepresentations. More specifically, for deep vision transformers, the\nself-attention blocks tend to map different patches into similar latent\nrepresentations, yielding information loss and performance degradation. To\nalleviate this problem, in this work, we introduce novel loss functions in\nvision transformer training to explicitly encourage diversity across patch\nrepresentations for more discriminative feature extraction. We empirically show\nthat our proposed techniques stabilize the training and allow us to train wider\nand deeper vision transformers. We further show the diversified features\nsignificantly benefit the downstream tasks in transfer learning. For semantic\nsegmentation, we enhance the state-of-the-art (SOTA) results on Cityscapes and\nADE20k. Our code is available at\nhttps://github.com/ChengyueGongR/PatchVisionTransformer.\n", "versions": [{"version": "v1", "created": "Mon, 26 Apr 2021 17:43:04 GMT"}, {"version": "v2", "created": "Thu, 10 Jun 2021 05:55:42 GMT"}, {"version": "v3", "created": "Fri, 11 Jun 2021 01:35:08 GMT"}], "update_date": "2021-06-14", "authors_parsed": [["Gong", "Chengyue", ""], ["Wang", "Dilin", ""], ["Li", "Meng", ""], ["Chandra", "Vikas", ""], ["Liu", "Qiang", ""]]}, {"id": "2104.12755", "submitter": "Hadi Jahanshahi", "authors": "Hadi Jahanshahi, Syed Kazmi, Mucahit Cevik", "title": "Auto Response Generation in Online Medical Chat Services", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Telehealth helps to facilitate access to medical professionals by enabling\nremote medical services for the patients. These services have become gradually\npopular over the years with the advent of necessary technological\ninfrastructure. The benefits of telehealth have been even more apparent since\nthe beginning of the COVID-19 crisis, as people have become less inclined to\nvisit doctors in person during the pandemic. In this paper, we focus on\nfacilitating the chat sessions between a doctor and a patient. We note that the\nquality and efficiency of the chat experience can be critical as the demand for\ntelehealth services increases. Accordingly, we develop a smart auto-response\ngeneration mechanism for medical conversations that helps doctors respond to\nconsultation requests efficiently, particularly during busy sessions. We\nexplore over 900,000 anonymous, historical online messages between doctors and\npatients collected over nine months. We implement clustering algorithms to\nidentify the most frequent responses by doctors and manually label the data\naccordingly. We then train machine learning algorithms using this preprocessed\ndata to generate the responses. The considered algorithm has two steps: a\nfiltering (i.e., triggering) model to filter out infeasible patient messages\nand a response generator to suggest the top-3 doctor responses for the ones\nthat successfully pass the triggering phase. The method provides an accuracy of\n83.28\\% for precision@3 and shows robustness to its parameters.\n", "versions": [{"version": "v1", "created": "Mon, 26 Apr 2021 17:45:10 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Jahanshahi", "Hadi", ""], ["Kazmi", "Syed", ""], ["Cevik", "Mucahit", ""]]}, {"id": "2104.12759", "submitter": "Pranoy Panda", "authors": "Pranoy Panda, Sai Srinivas Kancheti, Vineeth N Balasubramanian", "title": "Instance-wise Causal Feature Selection for Model Interpretation", "comments": "6 pages, 5 figures. Accepted at the Causality in Vision workshop,\n  CVPR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We formulate a causal extension to the recently introduced paradigm of\ninstance-wise feature selection to explain black-box visual classifiers. Our\nmethod selects a subset of input features that has the greatest causal effect\non the models output. We quantify the causal influence of a subset of features\nby the Relative Entropy Distance measure. Under certain assumptions this is\nequivalent to the conditional mutual information between the selected subset\nand the output variable. The resulting causal selections are sparser and cover\nsalient objects in the scene. We show the efficacy of our approach on multiple\nvision datasets by measuring the post-hoc accuracy and Average Causal Effect of\nselected features on the models output.\n", "versions": [{"version": "v1", "created": "Mon, 26 Apr 2021 17:51:42 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Panda", "Pranoy", ""], ["Kancheti", "Sai Srinivas", ""], ["Balasubramanian", "Vineeth N", ""]]}, {"id": "2104.12761", "submitter": "Yu-Guan Hsieh", "authors": "Yu-Guan Hsieh, Kimon Antonakopoulos, Panayotis Mertikopoulos", "title": "Adaptive Learning in Continuous Games: Optimal Regret Bounds and\n  Convergence to Nash Equilibrium", "comments": "34 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In game-theoretic learning, several agents are simultaneously following their\nindividual interests, so the environment is non-stationary from each player's\nperspective. In this context, the performance of a learning algorithm is often\nmeasured by its regret. However, no-regret algorithms are not created equal in\nterms of game-theoretic guarantees: depending on how they are tuned, some of\nthem may drive the system to an equilibrium, while others could produce cyclic,\nchaotic, or otherwise divergent trajectories. To account for this, we propose a\nrange of no-regret policies based on optimistic mirror descent, with the\nfollowing desirable properties: i) they do not require any prior tuning or\nknowledge of the game; ii) they all achieve O(\\sqrt{T}) regret against\narbitrary, adversarial opponents; and iii) they converge to the best response\nagainst convergent opponents. Also, if employed by all players, then iv) they\nguarantee O(1) social regret; while v) the induced sequence of play converges\nto Nash equilibrium with O(1) individual regret in all variationally stable\ngames (a class of games that includes all monotone and convex-concave zero-sum\ngames).\n", "versions": [{"version": "v1", "created": "Mon, 26 Apr 2021 17:52:29 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Hsieh", "Yu-Guan", ""], ["Antonakopoulos", "Kimon", ""], ["Mertikopoulos", "Panayotis", ""]]}, {"id": "2104.12763", "submitter": "Aishwarya Kamath", "authors": "Aishwarya Kamath, Mannat Singh, Yann LeCun, Ishan Misra, Gabriel\n  Synnaeve, Nicolas Carion", "title": "MDETR -- Modulated Detection for End-to-End Multi-Modal Understanding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Multi-modal reasoning systems rely on a pre-trained object detector to\nextract regions of interest from the image. However, this crucial module is\ntypically used as a black box, trained independently of the downstream task and\non a fixed vocabulary of objects and attributes. This makes it challenging for\nsuch systems to capture the long tail of visual concepts expressed in free form\ntext. In this paper we propose MDETR, an end-to-end modulated detector that\ndetects objects in an image conditioned on a raw text query, like a caption or\na question. We use a transformer-based architecture to reason jointly over text\nand image by fusing the two modalities at an early stage of the model. We\npre-train the network on 1.3M text-image pairs, mined from pre-existing\nmulti-modal datasets having explicit alignment between phrases in text and\nobjects in the image. We then fine-tune on several downstream tasks such as\nphrase grounding, referring expression comprehension and segmentation,\nachieving state-of-the-art results on popular benchmarks. We also investigate\nthe utility of our model as an object detector on a given label set when\nfine-tuned in a few-shot setting. We show that our pre-training approach\nprovides a way to handle the long tail of object categories which have very few\nlabelled instances. Our approach can be easily extended for visual question\nanswering, achieving competitive performance on GQA and CLEVR. The code and\nmodels are available at https://github.com/ashkamath/mdetr.\n", "versions": [{"version": "v1", "created": "Mon, 26 Apr 2021 17:55:33 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Kamath", "Aishwarya", ""], ["Singh", "Mannat", ""], ["LeCun", "Yann", ""], ["Misra", "Ishan", ""], ["Synnaeve", "Gabriel", ""], ["Carion", "Nicolas", ""]]}, {"id": "2104.12820", "submitter": "Yash Chandak", "authors": "Yash Chandak, Scott Niekum, Bruno Castro da Silva, Erik\n  Learned-Miller, Emma Brunskill, Philip S. Thomas", "title": "Universal Off-Policy Evaluation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When faced with sequential decision-making problems, it is often useful to be\nable to predict what would happen if decisions were made using a new policy.\nThose predictions must often be based on data collected under some previously\nused decision-making rule. Many previous methods enable such off-policy (or\ncounterfactual) estimation of the expected value of a performance measure\ncalled the return. In this paper, we take the first steps towards a universal\noff-policy estimator (UnO) -- one that provides off-policy estimates and\nhigh-confidence bounds for any parameter of the return distribution. We use UnO\nfor estimating and simultaneously bounding the mean, variance,\nquantiles/median, inter-quantile range, CVaR, and the entire cumulative\ndistribution of returns. Finally, we also discuss Uno's applicability in\nvarious settings, including fully observable, partially observable (i.e., with\nunobserved confounders), Markovian, non-Markovian, stationary, smoothly\nnon-stationary, and discrete distribution shifts.\n", "versions": [{"version": "v1", "created": "Mon, 26 Apr 2021 18:54:31 GMT"}], "update_date": "2021-04-28", "authors_parsed": [["Chandak", "Yash", ""], ["Niekum", "Scott", ""], ["da Silva", "Bruno Castro", ""], ["Learned-Miller", "Erik", ""], ["Brunskill", "Emma", ""], ["Thomas", "Philip S.", ""]]}, {"id": "2104.12822", "submitter": "Diego Antognini", "authors": "Martin Milenkoski, Diego Antognini, Claudiu Musat", "title": "Recommending Burgers based on Pizza Preferences: Addressing Data\n  Sparsity with a Product of Experts", "comments": "Under review. 16 pages, 5 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we describe a method to tackle data sparsity and create\nrecommendations in domains with limited knowledge about the user preferences.\nWe expand the variational autoencoder collaborative filtering from a\nsingle-domain to a multi domain setting. The intuition is that user-item\ninteractions in a source domain can augment the recommendation quality in a\ntarget domain. The intuition can be taken to its extreme, where, in a\ncross-domain setup, the user history in a source domain is enough to generate\nhigh quality recommendations in a target one. We thus create a\nProduct-of-Experts (POE) architecture for recommendations that jointly models\nuser-item interactions across multiple domains. The method is resilient to\nmissing data for one or more of the domains, which is a situation often found\nin real life. We present results on two widely-used datasets - Amazon and Yelp,\nwhich support the claim that holistic user preference knowledge leads to better\nrecommendations. Surprisingly, we find that in select cases, a POE recommender\nthat does not access the target domain user representation can surpass a strong\nVAE recommender baseline trained on the target domain. We complete the analysis\nwith a study of the reasons behind this outperformance and an in-depth look at\nthe resulting embedding spaces.\n", "versions": [{"version": "v1", "created": "Mon, 26 Apr 2021 18:56:04 GMT"}], "update_date": "2021-04-28", "authors_parsed": [["Milenkoski", "Martin", ""], ["Antognini", "Diego", ""], ["Musat", "Claudiu", ""]]}, {"id": "2104.12827", "submitter": "Byungjin Cho", "authors": "Byungjin Cho and Yu Xiao", "title": "Learning-based decentralized offloading decision making in an\n  adversarial environment", "comments": "This work has been submitted to the IEEE for possible publication.\n  Copyright may be transferred without notice, after which this version may no\n  longer be accessible", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Vehicular fog computing (VFC) pushes the cloud computing capability to the\ndistributed fog nodes at the edge of the Internet, enabling compute-intensive\nand latency-sensitive computing services for vehicles through task offloading.\nHowever, a heterogeneous mobility environment introduces uncertainties in terms\nof resource supply and demand, which are inevitable bottlenecks for the optimal\noffloading decision. Also, these uncertainties bring extra challenges to task\noffloading under the oblivious adversary attack and data privacy risks. In this\narticle, we develop a new adversarial online learning algorithm with bandit\nfeedback based on the adversarial multi-armed bandit theory, to enable scalable\nand low-complexity offloading decision making. Specifically, we focus on\noptimizing fog node selection with the aim of minimizing the offloading service\ncosts in terms of delay and energy. The key is to implicitly tune the\nexploration bonus in the selection process and the assessment rules of the\ndesigned algorithm, taking into account volatile resource supply and demand. We\ntheoretically prove that the input-size dependent selection rule allows to\nchoose a suitable fog node without exploring the sub-optimal actions, and also\nan appropriate score patching rule allows to quickly adapt to evolving\ncircumstances, which reduce variance and bias simultaneously, thereby achieving\na better exploitation-exploration balance. Simulation results verify the\neffectiveness and robustness of the proposed algorithm.\n", "versions": [{"version": "v1", "created": "Mon, 26 Apr 2021 19:04:55 GMT"}, {"version": "v2", "created": "Mon, 26 Jul 2021 18:56:29 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Cho", "Byungjin", ""], ["Xiao", "Yu", ""]]}, {"id": "2104.12835", "submitter": "Daniel Glasner", "authors": "Srikumar Ramalingam, Daniel Glasner, Kaushal Patel, Raviteja\n  Vemulapalli, Sadeep Jayasumana, Sanjiv Kumar", "title": "Balancing Constraints and Submodularity in Data Subset Selection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deep learning has yielded extraordinary results in vision and natural\nlanguage processing, but this achievement comes at a cost. Most deep learning\nmodels require enormous resources during training, both in terms of computation\nand in human labeling effort. In this paper, we show that one can achieve\nsimilar accuracy to traditional deep-learning models, while using less training\ndata. Much of the previous work in this area relies on using uncertainty or\nsome form of diversity to select subsets of a larger training set.\nSubmodularity, a discrete analogue of convexity, has been exploited to model\ndiversity in various settings including data subset selection. In contrast to\nprior methods, we propose a novel diversity driven objective function, and\nbalancing constraints on class labels and decision boundaries using matroids.\nThis allows us to use efficient greedy algorithms with approximation guarantees\nfor subset selection. We outperform baselines on standard image classification\ndatasets such as CIFAR-10, CIFAR-100, and ImageNet. In addition, we also show\nthat the proposed balancing constraints can play a key role in boosting the\nperformance in long-tailed datasets such as CIFAR-100-LT.\n", "versions": [{"version": "v1", "created": "Mon, 26 Apr 2021 19:22:27 GMT"}], "update_date": "2021-04-28", "authors_parsed": [["Ramalingam", "Srikumar", ""], ["Glasner", "Daniel", ""], ["Patel", "Kaushal", ""], ["Vemulapalli", "Raviteja", ""], ["Jayasumana", "Sadeep", ""], ["Kumar", "Sanjiv", ""]]}, {"id": "2104.12837", "submitter": "Joel G\\'ongora", "authors": "Trent J. Bradberry, Christopher H. Hase, LeAnna Kent, Joel A.\n  G\\'ongora", "title": "Unsupervised Instance Selection with Low-Label, Supervised Learning for\n  Outlier Detection", "comments": "16 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The laborious process of labeling data often bottlenecks projects that aim to\nleverage the power of supervised machine learning. Active Learning (AL) has\nbeen established as a technique to ameliorate this condition through an\niterative framework that queries a human annotator for labels of instances with\nthe most uncertain class assignment. Via this mechanism, AL produces a binary\nclassifier trained on less labeled data but with little, if any, loss in\npredictive performance. Despite its advantages, AL can have difficulty with\nclass-imbalanced datasets and results in an inefficient labeling process. To\naddress these drawbacks, we investigate our unsupervised instance selection\n(UNISEL) technique followed by a Random Forest (RF) classifier on 10 outlier\ndetection datasets under low-label conditions. These results are compared to AL\nperformed on the same datasets. Further, we investigate the combination of\nUNISEL and AL. Results indicate that UNISEL followed by an RF performs\ncomparably to AL with an RF and that the combination of UNISEL and AL\ndemonstrates superior performance. The practical implications of these findings\nin terms of time savings and generalizability afforded by UNISEL are discussed.\n", "versions": [{"version": "v1", "created": "Mon, 26 Apr 2021 19:23:58 GMT"}], "update_date": "2021-04-28", "authors_parsed": [["Bradberry", "Trent J.", ""], ["Hase", "Christopher H.", ""], ["Kent", "LeAnna", ""], ["G\u00f3ngora", "Joel A.", ""]]}, {"id": "2104.12839", "submitter": "M. Hamed Mozaffari", "authors": "M. Hamed Mozaffari and Li-Lin Tay", "title": "One-dimensional Active Contour Models for Raman Spectrum Baseline\n  Correction", "comments": "4 figures, and 9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.CV cs.LG cs.NE eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Raman spectroscopy is a powerful and non-invasive method for analysis of\nchemicals and detection of unknown substances. However, Raman signal is so weak\nthat background noise can distort the actual Raman signal. These baseline\nshifts that exist in the Raman spectrum might deteriorate analytical results.\nIn this paper, a modified version of active contour models in one-dimensional\nspace has been proposed for the baseline correction of Raman spectra. Our\ntechnique, inspired by principles of physics and heuristic optimization\nmethods, iteratively deforms an initialized curve toward the desired baseline.\nThe performance of the proposed algorithm was evaluated and compared with\nsimilar techniques using simulated Raman spectra. The results showed that the\n1D active contour model outperforms many iterative baseline correction methods.\nThe proposed algorithm was successfully applied to experimental Raman spectral\ndata, and the results indicate that the baseline of Raman spectra can be\nautomatically subtracted.\n", "versions": [{"version": "v1", "created": "Mon, 26 Apr 2021 19:30:34 GMT"}], "update_date": "2021-04-28", "authors_parsed": [["Mozaffari", "M. Hamed", ""], ["Tay", "Li-Lin", ""]]}, {"id": "2104.12840", "submitter": "Yushun Dong", "authors": "Yushun Dong, Kaize Ding, Brian Jalaian, Shuiwang Ji, Jundong Li", "title": "Graph Neural Networks with Adaptive Frequency Response Filter", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph Neural Networks have recently become a prevailing paradigm for various\nhigh-impact graph learning tasks. Existing efforts can be mainly categorized as\nspectral-based and spatial-based methods. The major challenge for the former is\nto find an appropriate graph filter to distill discriminative information from\ninput signals for learning. Recently, attempts such as Graph Convolutional\nNetwork (GCN) leverage Chebyshev polynomial truncation to seek an approximation\nof graph filters and bridge these two families of methods. It has been shown in\nrecent studies that GCN and its variants are essentially employing fixed\nlow-pass filters to perform information denoising. Thus their learning\ncapability is rather limited and may over-smooth node representations at deeper\nlayers. To tackle these problems, we develop a novel graph neural network\nframework AdaGNN with a well-designed adaptive frequency response filter. At\nits core, AdaGNN leverages a simple but elegant trainable filter that spans\nacross multiple layers to capture the varying importance of different frequency\ncomponents for node representation learning. The inherent differences among\ndifferent feature channels are also well captured by the filter. As such, it\nempowers AdaGNN with stronger expressiveness and naturally alleviates the\nover-smoothing problem. We empirically validate the effectiveness of the\nproposed framework on various benchmark datasets. Theoretical analysis is also\nprovided to show the superiority of the proposed AdaGNN. The implementation of\nAdaGNN is available at \\url{https://github.com/yushundong/AdaGNN}.\n", "versions": [{"version": "v1", "created": "Mon, 26 Apr 2021 19:31:21 GMT"}], "update_date": "2021-04-28", "authors_parsed": [["Dong", "Yushun", ""], ["Ding", "Kaize", ""], ["Jalaian", "Brian", ""], ["Ji", "Shuiwang", ""], ["Li", "Jundong", ""]]}, {"id": "2104.12844", "submitter": "Ryan Urbanowicz", "authors": "Robert Zhang, Rachael Stolzenberg-Solomon, Shannon M. Lynch, Ryan J.\n  Urbanowicz", "title": "LCS-DIVE: An Automated Rule-based Machine Learning Visualization\n  Pipeline for Characterizing Complex Associations in Classification", "comments": "21 pages, 11 figures, submitted for review on 4/26/21", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Machine learning (ML) research has yielded powerful tools for training\naccurate prediction models despite complex multivariate associations (e.g.\ninteractions and heterogeneity). In fields such as medicine, improved\ninterpretability of ML modeling is required for knowledge discovery,\naccountability, and fairness. Rule-based ML approaches such as Learning\nClassifier Systems (LCSs) strike a balance between predictive performance and\ninterpretability in complex, noisy domains. This work introduces the LCS\nDiscovery and Visualization Environment (LCS-DIVE), an automated LCS model\ninterpretation pipeline for complex biomedical classification. LCS-DIVE\nconducts modeling using a new scikit-learn implementation of ExSTraCS, an LCS\ndesigned to overcome noise and scalability in biomedical data mining yielding\nhuman readable IF:THEN rules as well as feature-tracking scores for each\ntraining sample. LCS-DIVE leverages feature-tracking scores and/or rules to\nautomatically guide characterization of (1) feature importance (2) underlying\nadditive, epistatic, and/or heterogeneous patterns of association, and (3)\nmodel-driven heterogeneous instance subgroups via clustering, visualization\ngeneration, and cluster interrogation. LCS-DIVE was evaluated over a diverse\nset of simulated genetic and benchmark datasets encoding a variety of complex\nmultivariate associations, demonstrating its ability to differentiate between\nthem and then applied to characterize associations within a real-world study of\npancreatic cancer.\n", "versions": [{"version": "v1", "created": "Mon, 26 Apr 2021 19:47:03 GMT"}], "update_date": "2021-04-28", "authors_parsed": [["Zhang", "Robert", ""], ["Stolzenberg-Solomon", "Rachael", ""], ["Lynch", "Shannon M.", ""], ["Urbanowicz", "Ryan J.", ""]]}, {"id": "2104.12845", "submitter": "Andr\\'e Zazzera", "authors": "Kevin Hoffman, Jae Yoon Sung, Andr\\'e Zazzera", "title": "Multi-Output Random Forest Regression to Emulate the Earliest Stages of\n  Planet Formation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "astro-ph.EP astro-ph.IM cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  In the current paradigm of planet formation research, it is believed that the\nfirst step to forming massive bodies (such as asteroids and planets) requires\nthat small interstellar dust grains floating through space collide with each\nother and grow to larger sizes. The initial formation of these pebbles is\ngoverned by an integro-differential equation known as the Smoluchowski\ncoagulation equation, to which analytical solutions are intractable for all but\nthe simplest possible scenarios. While brute-force methods of approximation\nhave been developed, they are computationally costly, currently making it\ninfeasible to simulate this process including other physical processes relevant\nto planet formation, and across the very large range of scales on which it\noccurs. In this paper, we take a machine learning approach to designing a\nsystem for a much faster approximation. We develop a multi-output random forest\nregression model trained on brute-force simulation data to approximate\ndistributions of dust particle sizes in protoplanetary disks at different\npoints in time. The performance of our random forest model is measured against\nthe existing brute-force models, which are the standard for realistic\nsimulations. Results indicate that the random forest model can generate highly\naccurate predictions relative to the brute-force simulation results, with an\n$R^{2}$ of 0.97, and do so significantly faster than brute-force methods.\n", "versions": [{"version": "v1", "created": "Mon, 26 Apr 2021 19:51:40 GMT"}], "update_date": "2021-04-28", "authors_parsed": [["Hoffman", "Kevin", ""], ["Sung", "Jae Yoon", ""], ["Zazzera", "Andr\u00e9", ""]]}, {"id": "2104.12862", "submitter": "Muhammad Shaban", "authors": "Muhammad Shaban, Shan E Ahmed Raza, Mariam Hassan, Arif Jamshed, Sajid\n  Mushtaq, Asif Loya, Nikolaos Batis, Jill Brooks, Paul Nankivell, Neil Sharma,\n  Max Robinson, Hisham Mehanna, Syed Ali Khurram, Nasir Rajpoot", "title": "A digital score of tumour-associated stroma infiltrating lymphocytes\n  predicts survival in head and neck squamous cell carcinoma", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The infiltration of T-lymphocytes in the stroma and tumour is an indication\nof an effective immune response against the tumour, resulting in better\nsurvival. In this study, our aim is to explore the prognostic significance of\ntumour-associated stroma infiltrating lymphocytes (TASILs) in head and neck\nsquamous cell carcinoma (HNSCC) through an AI based automated method. A deep\nlearning based automated method was employed to segment tumour, stroma and\nlymphocytes in digitally scanned whole slide images of HNSCC tissue slides. The\nspatial patterns of lymphocytes and tumour-associated stroma were digitally\nquantified to compute the TASIL-score. Finally, prognostic significance of the\nTASIL-score for disease-specific and disease-free survival was investigated\nwith the Cox proportional hazard analysis. Three different cohorts of\nHaematoxylin & Eosin (H&E) stained tissue slides of HNSCC cases (n=537 in\ntotal) were studied, including publicly available TCGA head and neck cancer\ncases. The TASIL-score carries prognostic significance (p=0.002) for\ndisease-specific survival of HNSCC patients. The TASIL-score also shows a\nbetter separation between low- and high-risk patients as compared to the manual\nTIL scoring by pathologists for both disease-specific and disease-free\nsurvival. A positive correlation of TASIL-score with molecular estimates of\nCD8+ T cells was also found, which is in line with existing findings. To the\nbest of our knowledge, this is the first study to automate the quantification\nof TASIL from routine H&E slides of head and neck cancer. Our TASIL-score based\nfindings are aligned with the clinical knowledge with the added advantages of\nobjectivity, reproducibility and strong prognostic value. A comprehensive\nevaluation on large multicentric cohorts is required before the proposed\ndigital score can be adopted in clinical practice.\n", "versions": [{"version": "v1", "created": "Fri, 16 Apr 2021 19:45:00 GMT"}], "update_date": "2021-04-28", "authors_parsed": [["Shaban", "Muhammad", ""], ["Raza", "Shan E Ahmed", ""], ["Hassan", "Mariam", ""], ["Jamshed", "Arif", ""], ["Mushtaq", "Sajid", ""], ["Loya", "Asif", ""], ["Batis", "Nikolaos", ""], ["Brooks", "Jill", ""], ["Nankivell", "Paul", ""], ["Sharma", "Neil", ""], ["Robinson", "Max", ""], ["Mehanna", "Hisham", ""], ["Khurram", "Syed Ali", ""], ["Rajpoot", "Nasir", ""]]}, {"id": "2104.12868", "submitter": "Ali Akbar Sadat Asl", "authors": "Ali Akbar Sadat Asl, Mohammad Mahdi Ershadi, Shahabeddin Sotudian", "title": "Fuzzy Expert Systems for Prediction of ICU Admission in Patients with\n  COVID-19", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  The pandemic COVID-19 disease has had a dramatic impact on almost all\ncountries around the world so that many hospitals have been overwhelmed with\nCovid-19 cases. As medical resources are limited, deciding on the proper\nallocation of these resources is a very crucial issue. Besides, uncertainty is\na major factor that can affect decisions, especially in medical fields. To cope\nwith this issue, we use fuzzy logic (FL) as one of the most suitable methods in\nmodeling systems with high uncertainty and complexity. We intend to make use of\nthe advantages of FL in decisions on cases that need to treat in ICU. In this\nstudy, an interval type-2 fuzzy expert system is proposed for prediction of ICU\nadmission in COVID-19 patients. For this prediction task, we also developed an\nadaptive neuro-fuzzy inference system (ANFIS). Finally, the results of these\nfuzzy systems are compared to some well-known classification methods such as\nNaive Bayes (NB), Case-Based Reasoning (CBR), Decision Tree (DT), and K Nearest\nNeighbor (KNN). The results show that the type-2 fuzzy expert system and ANFIS\nmodels perform competitively in terms of accuracy and F-measure compared to the\nother system modeling techniques.\n", "versions": [{"version": "v1", "created": "Thu, 22 Apr 2021 05:12:49 GMT"}], "update_date": "2021-04-28", "authors_parsed": [["Asl", "Ali Akbar Sadat", ""], ["Ershadi", "Mohammad Mahdi", ""], ["Sotudian", "Shahabeddin", ""]]}, {"id": "2104.12869", "submitter": "Neslihan Suzen", "authors": "Neslihan Suzen, Alexander Gorban, Jeremy Levesley and Evgeny Mirkes", "title": "Semantic Analysis for Automated Evaluation of the Potential Impact of\n  Research Articles", "comments": "36 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IT cs.LG math.IT", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Can the analysis of the semantics of words used in the text of a scientific\npaper predict its future impact measured by citations? This study details\nexamples of automated text classification that achieved 80% success rate in\ndistinguishing between highly-cited and little-cited articles. Automated\nintelligent systems allow the identification of promising works that could\nbecome influential in the scientific community.\n  The problems of quantifying the meaning of texts and representation of human\nlanguage have been clear since the inception of Natural Language Processing.\nThis paper presents a novel method for vector representation of text meaning\nbased on information theory and show how this informational semantics is used\nfor text classification on the basis of the Leicester Scientific Corpus.\n  We describe the experimental framework used to evaluate the impact of\nscientific articles through their informational semantics. Our interest is in\ncitation classification to discover how important semantics of texts are in\npredicting the citation count. We propose the semantics of texts as an\nimportant factor for citation prediction.\n  For each article, our system extracts the abstract of paper, represents the\nwords of the abstract as vectors in Meaning Space, automatically analyses the\ndistribution of scientific categories (Web of Science categories) within the\ntext of abstract, and then classifies papers according to citation counts\n(highly-cited, little-cited).\n  We show that an informational approach to representing the meaning of a text\nhas offered a way to effectively predict the scientific impact of research\npapers.\n", "versions": [{"version": "v1", "created": "Mon, 26 Apr 2021 20:37:13 GMT"}], "update_date": "2021-04-28", "authors_parsed": [["Suzen", "Neslihan", ""], ["Gorban", "Alexander", ""], ["Levesley", "Jeremy", ""], ["Mirkes", "Evgeny", ""]]}, {"id": "2104.12870", "submitter": "David Qiu", "authors": "David Qiu, Yanzhang He, Qiujia Li, Yu Zhang, Liangliang Cao, Ian\n  McGraw", "title": "Multi-Task Learning for End-to-End ASR Word and Utterance Confidence\n  with Deletion Prediction", "comments": "Submitted to Interspeech 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Confidence scores are very useful for downstream applications of automatic\nspeech recognition (ASR) systems. Recent works have proposed using neural\nnetworks to learn word or utterance confidence scores for end-to-end ASR. In\nthose studies, word confidence by itself does not model deletions, and\nutterance confidence does not take advantage of word-level training signals.\nThis paper proposes to jointly learn word confidence, word deletion, and\nutterance confidence. Empirical results show that multi-task learning with all\nthree objectives improves confidence metrics (NCE, AUC, RMSE) without the need\nfor increasing the model size of the confidence estimation module. Using the\nutterance-level confidence for rescoring also decreases the word error rates on\nGoogle's Voice Search and Long-tail Maps datasets by 3-5% relative, without\nneeding a dedicated neural rescorer.\n", "versions": [{"version": "v1", "created": "Mon, 26 Apr 2021 20:38:42 GMT"}], "update_date": "2021-04-28", "authors_parsed": [["Qiu", "David", ""], ["He", "Yanzhang", ""], ["Li", "Qiujia", ""], ["Zhang", "Yu", ""], ["Cao", "Liangliang", ""], ["McGraw", "Ian", ""]]}, {"id": "2104.12876", "submitter": "Aman Priyanshu", "authors": "Aman Priyanshu and Mudit Sinha and Shreyans Mehta", "title": "Continual Distributed Learning for Crisis Management", "comments": "6 pages, 3 figures, Accepted at 3rd Workshop on Continual and\n  Multimodal Learning for Internet of Things and Presented at IEEESBM Manipal\n  Paper Presentation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Social media platforms such as Twitter, Facebook etc can be utilised as an\nimportant source of information during disaster events. This information can be\nused for disaster response and crisis management if processed accurately and\nquickly. However, the data present in such situations is ever-changing, and\nusing considerable resources during such a crisis is not feasible. Therefore,\nwe have to develop a low resource and continually learning system that\nincorporates text classification models which are robust against noisy and\nunordered data. We utilised Distributed learning which enabled us to learn on\nresource-constrained devices, then to alleviate catastrophic forgetting in our\ntarget neural networks we utilized regularization. We then applied federated\naveraging for distributed learning and to aggregate the central model for\ncontinual learning.\n", "versions": [{"version": "v1", "created": "Mon, 26 Apr 2021 21:01:29 GMT"}, {"version": "v2", "created": "Thu, 1 Jul 2021 05:19:29 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Priyanshu", "Aman", ""], ["Sinha", "Mudit", ""], ["Mehta", "Shreyans", ""]]}, {"id": "2104.12895", "submitter": "Claude Kl\\\"ockl", "authors": "Christoph Graf, Viktor Zobernig, Johannes Schmidt, Claude Kl\\\"ockl", "title": "Computational Performance of Deep Reinforcement Learning to find Nash\n  Equilibria", "comments": "48 pages + 9 figures, comments welcome!", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI cs.LG cs.MA econ.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We test the performance of deep deterministic policy gradient (DDPG), a deep\nreinforcement learning algorithm, able to handle continuous state and action\nspaces, to learn Nash equilibria in a setting where firms compete in prices.\nThese algorithms are typically considered model-free because they do not\nrequire transition probability functions (as in e.g., Markov games) or\npredefined functional forms. Despite being model-free, a large set of\nparameters are utilized in various steps of the algorithm. These are e.g.,\nlearning rates, memory buffers, state-space dimensioning, normalizations, or\nnoise decay rates and the purpose of this work is to systematically test the\neffect of these parameter configurations on convergence to the analytically\nderived Bertrand equilibrium. We find parameter choices that can reach\nconvergence rates of up to 99%. The reliable convergence may make the method a\nuseful tool to study strategic behavior of firms even in more complex settings.\nKeywords: Bertrand Equilibrium, Competition in Uniform Price Auctions, Deep\nDeterministic Policy Gradient Algorithm, Parameter Sensitivity Analysis\n", "versions": [{"version": "v1", "created": "Mon, 26 Apr 2021 22:14:17 GMT"}], "update_date": "2021-04-28", "authors_parsed": [["Graf", "Christoph", ""], ["Zobernig", "Viktor", ""], ["Schmidt", "Johannes", ""], ["Kl\u00f6ckl", "Claude", ""]]}, {"id": "2104.12909", "submitter": "Yusuke Narita", "authors": "Yusuke Narita and Kohei Yata", "title": "Algorithm is Experiment: Machine Learning, Market Design, and Policy\n  Eligibility Rules", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.EM cs.LG stat.ME stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Algorithms produce a growing portion of decisions and recommendations both in\npolicy and business. Such algorithmic decisions are natural experiments\n(conditionally quasi-randomly assigned instruments) since the algorithms make\ndecisions based only on observable input variables. We use this observation to\ndevelop a treatment-effect estimator for a class of stochastic and\ndeterministic decision-making algorithms. Our estimator is shown to be\nconsistent and asymptotically normal for well-defined causal effects. A key\nspecial case of our estimator is a multidimensional regression discontinuity\ndesign. We apply our estimator to evaluate the effect of the Coronavirus Aid,\nRelief, and Economic Security (CARES) Act, where more than \\$175 billion worth\nof relief funding is allocated to hospitals via an algorithmic rule. Our\nestimates suggest that the relief funding has little effect on COVID-19-related\nhospital activity levels. Naive OLS and IV estimates exhibit substantial\nselection bias.\n", "versions": [{"version": "v1", "created": "Mon, 26 Apr 2021 23:18:34 GMT"}, {"version": "v2", "created": "Mon, 28 Jun 2021 12:37:09 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Narita", "Yusuke", ""], ["Yata", "Kohei", ""]]}, {"id": "2104.12922", "submitter": "Joseph Turian", "authors": "Joseph Turian and Jordie Shier and George Tzanetakis and Kirk McNally\n  and Max Henry", "title": "One Billion Audio Sounds from GPU-enabled Modular Synthesis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.AI cs.LG eess.AS eess.SP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We release synth1B1, a multi-modal audio corpus consisting of 1 billion\n4-second synthesized sounds, paired with the synthesis parameters used to\ngenerate them. The dataset is 100x larger than any audio dataset in the\nliterature. We also introduce torchsynth, an open source modular synthesizer\nthat generates the synth1B1 samples on-the-fly at 16200x faster than real-time\n(714MHz) on a single GPU. Finally, we release two new audio datasets: FM synth\ntimbre and subtractive synth pitch. Using these datasets, we demonstrate new\nrank-based evaluation criteria for existing audio representations. Finally, we\npropose a novel approach to synthesizer hyperparameter optimization.\n", "versions": [{"version": "v1", "created": "Tue, 27 Apr 2021 00:38:52 GMT"}, {"version": "v2", "created": "Tue, 20 Jul 2021 17:46:41 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Turian", "Joseph", ""], ["Shier", "Jordie", ""], ["Tzanetakis", "George", ""], ["McNally", "Kirk", ""], ["Henry", "Max", ""]]}, {"id": "2104.12928", "submitter": "Steffen Schneider", "authors": "Evgenia Rusak, Steffen Schneider, Peter Gehler, Oliver Bringmann,\n  Wieland Brendel and Matthias Bethge", "title": "Adapting ImageNet-scale models to complex distribution shifts with\n  self-learning", "comments": "Web: https://domainadaptation.org/selflearning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While self-learning methods are an important component in many recent domain\nadaptation techniques, they are not yet comprehensively evaluated on\nImageNet-scale datasets common in robustness research. In extensive experiments\non ResNet and EfficientNet models, we find that three components are crucial\nfor increasing performance with self-learning: (i) using short update times\nbetween the teacher and the student network, (ii) fine-tuning only few affine\nparameters distributed across the network, and (iii) leveraging methods from\nrobust classification to counteract the effect of label noise. We use these\ninsights to obtain drastically improved state-of-the-art results on ImageNet-C\n(22.0% mCE), ImageNet-R (17.4% error) and ImageNet-A (14.8% error). Our\ntechniques yield further improvements in combination with previously proposed\nrobustification methods. Self-learning is able to reduce the top-1 error to a\npoint where no substantial further progress can be expected. We therefore\nre-purpose the dataset from the Visual Domain Adaptation Challenge 2019 and use\na subset of it as a new robustness benchmark (ImageNet-D) which proves to be a\nmore challenging dataset for all current state-of-the-art models (58.2% error)\nto guide future research efforts at the intersection of robustness and domain\nadaptation on ImageNet scale.\n", "versions": [{"version": "v1", "created": "Tue, 27 Apr 2021 01:02:15 GMT"}, {"version": "v2", "created": "Wed, 28 Apr 2021 01:12:40 GMT"}], "update_date": "2021-04-29", "authors_parsed": [["Rusak", "Evgenia", ""], ["Schneider", "Steffen", ""], ["Gehler", "Peter", ""], ["Bringmann", "Oliver", ""], ["Brendel", "Wieland", ""], ["Bethge", "Matthias", ""]]}, {"id": "2104.12949", "submitter": "Michael Burkhart", "authors": "Michael C. Burkhart", "title": "Discriminative Bayesian Filtering Lends Momentum to the Stochastic\n  Newton Method for Minimizing Log-Convex Functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To minimize the average of a set of log-convex functions, the stochastic\nNewton method iteratively updates its estimate using subsampled versions of the\nfull objective's gradient and Hessian. We contextualize this optimization\nproblem as sequential Bayesian inference on a latent state-space model with a\ndiscriminatively-specified observation process. Applying Bayesian filtering\nthen yields a novel optimization algorithm that considers the entire history of\ngradients and Hessians when forming an update. We establish matrix-based\nconditions under which the effect of older observations diminishes over time,\nin a manner analogous to Polyak's heavy ball momentum. We illustrate various\naspects of our approach with an example and review other relevant innovations\nfor the stochastic Newton method.\n", "versions": [{"version": "v1", "created": "Tue, 27 Apr 2021 02:39:21 GMT"}], "update_date": "2021-04-28", "authors_parsed": [["Burkhart", "Michael C.", ""]]}, {"id": "2104.12953", "submitter": "Yuandu Lai", "authors": "Yuandu Lai, Yucheng Shi, Yahong Han, Yunfeng Shao, Meiyu Qi, Bingshuai\n  Li", "title": "Exploring Uncertainty in Deep Learning for Construction of Prediction\n  Intervals", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning has achieved impressive performance on many tasks in recent\nyears. However, it has been found that it is still not enough for deep neural\nnetworks to provide only point estimates. For high-risk tasks, we need to\nassess the reliability of the model predictions. This requires us to quantify\nthe uncertainty of model prediction and construct prediction intervals. In this\npaper, We explore the uncertainty in deep learning to construct the prediction\nintervals. In general, We comprehensively consider two categories of\nuncertainties: aleatory uncertainty and epistemic uncertainty. We design a\nspecial loss function, which enables us to learn uncertainty without\nuncertainty label. We only need to supervise the learning of regression task.\nWe learn the aleatory uncertainty implicitly from the loss function. And that\nepistemic uncertainty is accounted for in ensembled form. Our method correlates\nthe construction of prediction intervals with the uncertainty estimation.\nImpressive results on some publicly available datasets show that the\nperformance of our method is competitive with other state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Tue, 27 Apr 2021 02:58:20 GMT"}], "update_date": "2021-04-28", "authors_parsed": [["Lai", "Yuandu", ""], ["Shi", "Yucheng", ""], ["Han", "Yahong", ""], ["Shao", "Yunfeng", ""], ["Qi", "Meiyu", ""], ["Li", "Bingshuai", ""]]}, {"id": "2104.12964", "submitter": "Zawar Hussain Mr", "authors": "Zawar Hussain, Quan Z. Sheng, Wei Emma Zhang, Jorge Ortiz, Seyedamin\n  Pouriyeh", "title": "A Review of the Non-Invasive Techniques for Monitoring Different Aspects\n  of Sleep", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Quality sleep is very important for a healthy life. Nowadays, many people\naround the world are not getting enough sleep which is having negative impacts\non their lifestyles. Studies are being conducted for sleep monitoring and have\nnow become an important tool for understanding sleep behavior. The gold\nstandard method for sleep analysis is polysomnography (PSG) conducted in a\nclinical environment but this method is both expensive and complex for\nlong-term use. With the advancements in the field of sensors and the\nintroduction of off-the-shelf technologies, unobtrusive solutions are becoming\ncommon as alternatives for in-home sleep monitoring. Various solutions have\nbeen proposed using both wearable and non-wearable methods which are cheap and\neasy to use for in-home sleep monitoring. In this paper, we present a\ncomprehensive survey of the latest research works (2015 and after) conducted in\nvarious categories of sleep monitoring including sleep stage classification,\nsleep posture recognition, sleep disorders detection, and vital signs\nmonitoring. We review the latest works done using the non-invasive approach and\ncover both wearable and non-wearable methods. We discuss the design approaches\nand key attributes of the work presented and provide an extensive analysis\nbased on 10 key factors, to give a comprehensive overview of the recent\ndevelopments and trends in all four categories of sleep monitoring. We also\npresent some publicly available datasets for different categories of sleep\nmonitoring. In the end, we discuss several open issues and provide future\nresearch directions in the area of sleep monitoring.\n", "versions": [{"version": "v1", "created": "Tue, 27 Apr 2021 04:12:43 GMT"}], "update_date": "2021-04-28", "authors_parsed": [["Hussain", "Zawar", ""], ["Sheng", "Quan Z.", ""], ["Zhang", "Wei Emma", ""], ["Ortiz", "Jorge", ""], ["Pouriyeh", "Seyedamin", ""]]}, {"id": "2104.13000", "submitter": "Jiyuan Liu", "authors": "Siqi Wang, Jiyuan Liu, Guang Yu, Xinwang Liu, Sihang Zhou, En Zhu,\n  Yuexiang Yang, Jianping Yin", "title": "Multi-view Deep One-class Classification: A Systematic Exploration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One-class classification (OCC), which models one single positive class and\ndistinguishes it from the negative class, has been a long-standing topic with\npivotal application to realms like anomaly detection. As modern society often\ndeals with massive high-dimensional complex data spawned by multiple sources,\nit is natural to consider OCC from the perspective of multi-view deep learning.\nHowever, it has not been discussed by the literature and remains an unexplored\ntopic. Motivated by this blank, this paper makes four-fold contributions:\nFirst, to our best knowledge, this is the first work that formally identifies\nand formulates the multi-view deep OCC problem. Second, we take recent advances\nin relevant areas into account and systematically devise eleven different\nbaseline solutions for multi-view deep OCC, which lays the foundation for\nresearch on multi-view deep OCC. Third, to remedy the problem that limited\nbenchmark datasets are available for multi-view deep OCC, we extensively\ncollect existing public data and process them into more than 30 new multi-view\nbenchmark datasets via multiple means, so as to provide a publicly available\nevaluation platform for multi-view deep OCC. Finally, by comprehensively\nevaluating the devised solutions on benchmark datasets, we conduct a thorough\nanalysis on the effectiveness of the designed baselines, and hopefully provide\nother researchers with beneficial guidance and insight to multi-view deep OCC.\nOur data and codes are opened at https://github.com/liujiyuan13/MvDOCC-datasets\nand https://github.com/liujiyuan13/MvDOCC-code respectively to facilitate\nfuture research.\n", "versions": [{"version": "v1", "created": "Tue, 27 Apr 2021 06:44:07 GMT"}], "update_date": "2021-04-28", "authors_parsed": [["Wang", "Siqi", ""], ["Liu", "Jiyuan", ""], ["Yu", "Guang", ""], ["Liu", "Xinwang", ""], ["Zhou", "Sihang", ""], ["Zhu", "En", ""], ["Yang", "Yuexiang", ""], ["Yin", "Jianping", ""]]}, {"id": "2104.13012", "submitter": "Kashob Kumar Roy", "authors": "Kashob Kumar Roy, Amit Roy, A K M Mahbubur Rahman, M Ashraful Amin and\n  Amin Ahsan Ali", "title": "Structure-Aware Hierarchical Graph Pooling using Information Bottleneck", "comments": "Accepted at IJCNN 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Graph pooling is an essential ingredient of Graph Neural Networks (GNNs) in\ngraph classification and regression tasks. For these tasks, different pooling\nstrategies have been proposed to generate a graph-level representation by\ndownsampling and summarizing nodes' features in a graph. However, most existing\npooling methods are unable to capture distinguishable structural information\neffectively. Besides, they are prone to adversarial attacks. In this work, we\npropose a novel pooling method named as {HIBPool} where we leverage the\nInformation Bottleneck (IB) principle that optimally balances the\nexpressiveness and robustness of a model to learn representations of input\ndata. Furthermore, we introduce a novel structure-aware Discriminative Pooling\nReadout ({DiP-Readout}) function to capture the informative local subgraph\nstructures in the graph. Finally, our experimental results show that our model\nsignificantly outperforms other state-of-art methods on several graph\nclassification benchmarks and more resilient to feature-perturbation attack\nthan existing pooling methods.\n", "versions": [{"version": "v1", "created": "Tue, 27 Apr 2021 07:27:43 GMT"}], "update_date": "2021-04-28", "authors_parsed": [["Roy", "Kashob Kumar", ""], ["Roy", "Amit", ""], ["Rahman", "A K M Mahbubur", ""], ["Amin", "M Ashraful", ""], ["Ali", "Amin Ahsan", ""]]}, {"id": "2104.13014", "submitter": "Kashob Kumar Roy", "authors": "Kashob Kumar Roy, Amit Roy, A K M Mahbubur Rahman, M Ashraful Amin and\n  Amin Ahsan Ali", "title": "Node Embedding using Mutual Information and Self-Supervision based\n  Bi-level Aggregation", "comments": "Accepted at IJCNN 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Graph Neural Networks (GNNs) learn low dimensional representations of nodes\nby aggregating information from their neighborhood in graphs. However,\ntraditional GNNs suffer from two fundamental shortcomings due to their local\n($l$-hop neighborhood) aggregation scheme. First, not all nodes in the\nneighborhood carry relevant information for the target node. Since GNNs do not\nexclude noisy nodes in their neighborhood, irrelevant information gets\naggregated, which reduces the quality of the representation. Second,\ntraditional GNNs also fail to capture long-range non-local dependencies between\nnodes. To address these limitations, we exploit mutual information (MI) to\ndefine two types of neighborhood, 1) \\textit{Local Neighborhood} where nodes\nare densely connected within a community and each node would share higher MI\nwith its neighbors, and 2) \\textit{Non-Local Neighborhood} where MI-based node\nclustering is introduced to assemble informative but graphically distant nodes\nin the same cluster. To generate node presentations, we combine the embeddings\ngenerated by bi-level aggregation - local aggregation to aggregate features\nfrom local neighborhoods to avoid noisy information and non-local aggregation\nto aggregate features from non-local neighborhoods. Furthermore, we leverage\nself-supervision learning to estimate MI with few labeled data. Finally, we\nshow that our model significantly outperforms the state-of-the-art methods in a\nwide range of assortative and disassortative graphs.\n", "versions": [{"version": "v1", "created": "Tue, 27 Apr 2021 07:32:57 GMT"}], "update_date": "2021-04-28", "authors_parsed": [["Roy", "Kashob Kumar", ""], ["Roy", "Amit", ""], ["Rahman", "A K M Mahbubur", ""], ["Amin", "M Ashraful", ""], ["Ali", "Amin Ahsan", ""]]}, {"id": "2104.13020", "submitter": "Jose M. Pe\\~na", "authors": "Jose M. Pe\\~na", "title": "Simple yet Sharp Sensitivity Analysis for Unmeasured Confounding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a method for assessing the sensitivity of the true causal effect\nto unmeasured confounding. The method requires the analyst to specify two\nintuitive parameters. Otherwise, the method is assumption-free. The method\nreturns an interval that contains the true causal effect. Moreover, the bounds\nof the interval are sharp, i.e. attainable. We show experimentally that our\nbounds can be sharper than those obtained by the method of Ding and VanderWeele\n(2016). Finally, we extend our method to bound the natural direct and indirect\neffects when there are measured mediators and unmeasured exposure-outcome\nconfounding.\n", "versions": [{"version": "v1", "created": "Tue, 27 Apr 2021 07:43:52 GMT"}, {"version": "v2", "created": "Fri, 2 Jul 2021 11:44:25 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Pe\u00f1a", "Jose M.", ""]]}, {"id": "2104.13026", "submitter": "Johan Larsson", "authors": "Johan Larsson, Jonas Wallin", "title": "The Hessian Screening Rule", "comments": "17 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predictor screening rules, which discard predictors from the design matrix\nbefore fitting a model, have had sizable impacts on the speed with which\n$\\ell_1$-regularized regression problems, such as the lasso, can be solved.\nCurrent state-of-the-art screening rules, however, have difficulties in dealing\nwith highly-correlated predictors, often becoming too conservative. In this\npaper, we present a new screening rule to deal with this issue: the Hessian\nScreening Rule. The rule uses second-order information from the model in order\nto provide more accurate screening as well as higher-quality warm starts. In\nour experiments on $\\ell_1$-regularized least-squares (the lasso) and logistic\nregression, we show that the rule outperforms all other alternatives in\nsimulated experiments with high correlation, as well as in the majority of real\ndatasets that we study.\n", "versions": [{"version": "v1", "created": "Tue, 27 Apr 2021 07:55:29 GMT"}], "update_date": "2021-04-28", "authors_parsed": [["Larsson", "Johan", ""], ["Wallin", "Jonas", ""]]}, {"id": "2104.13030", "submitter": "Kun Zhang", "authors": "Le Wu, Xiangnan He, Xiang Wang, Kun Zhang, Meng Wang", "title": "A Survey on Neural Recommendation: From Collaborative Filtering to\n  Content and Context Enriched Recommendation", "comments": "In submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Influenced by the stunning success of deep learning in computer vision and\nlanguage understanding, research in recommendation has shifted to inventing new\nrecommender models based on neural networks. In recent years, we have witnessed\nsignificant progress in developing neural recommender models, which generalize\nand surpass traditional recommender models owing to the strong representation\npower of neural networks. In this survey paper, we conduct a systematic review\non neural recommender models, aiming to summarize the field to facilitate\nfuture progress. Distinct from existing surveys that categorize existing\nmethods based on the taxonomy of deep learning techniques, we instead summarize\nthe field from the perspective of recommendation modeling, which could be more\ninstructive to researchers and practitioners working on recommender systems.\nSpecifically, we divide the work into three types based on the data they used\nfor recommendation modeling: 1) collaborative filtering models, which leverage\nthe key source of user-item interaction data; 2) content enriched models, which\nadditionally utilize the side information associated with users and items, like\nuser profile and item knowledge graph; and 3) context enriched models, which\naccount for the contextual information associated with an interaction, such as\ntime, location, and the past interactions. After reviewing representative works\nfor each type, we finally discuss some promising directions in this field,\nincluding benchmarking recommender systems, graph reasoning based\nrecommendation models, and explainable and fair recommendations for social\ngood.\n", "versions": [{"version": "v1", "created": "Tue, 27 Apr 2021 08:03:52 GMT"}], "update_date": "2021-04-28", "authors_parsed": [["Wu", "Le", ""], ["He", "Xiangnan", ""], ["Wang", "Xiang", ""], ["Zhang", "Kun", ""], ["Wang", "Meng", ""]]}, {"id": "2104.13039", "submitter": "Akira Harada", "authors": "Akira Harada, Shota Nishikawa, and Shoichi Yamada", "title": "Deep Learning of the Eddington Tensor in the Core-collapse Supernova\n  Simulation", "comments": "12 pages, 11 figures, submitted to ApJ", "journal-ref": null, "doi": null, "report-no": "RIKEN-iTHEMS-Report-21", "categories": "astro-ph.HE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We trained deep neural networks (DNNs) as a function of the neutrino energy\ndensity, flux, and the fluid velocity to reproduce the Eddington tensor for\nneutrinos obtained in our first-principles core-collapse supernova (CCSN)\nsimulations. Although the moment method, which is one of the most popular\napproximations for neutrino transport, requires a closure relation, none of the\nanalytical closure relations commonly employed in the literature captures all\naspects of the neutrino angular distribution in momentum space. In this paper,\nwe developed a closure relation by using the DNN that takes the neutrino energy\ndensity, flux, and the fluid velocity as the input and the Eddington tensor as\nthe output. We consider two kinds of DNNs: a conventional DNN named a\ncomponent-wise neural network (CWNN) and a tensor-basis neural network (TBNN).\nWe found that the diagonal component of the Eddington tensor is reproduced\nbetter by the DNNs than the M1-closure relation especially for low to\nintermediate energies. For the off-diagonal component, the DNNs agree better\nwith the Boltzmann solver than the M1 closure at large radii. In the comparison\nbetween the two DNNs, the TBNN has slightly better performance than the CWNN.\nWith the new closure relations at hand based on the DNNs that well reproduce\nthe Eddington tensor with much smaller costs, we opened up a new possibility\nfor the moment method.\n", "versions": [{"version": "v1", "created": "Tue, 27 Apr 2021 08:26:52 GMT"}], "update_date": "2021-04-28", "authors_parsed": [["Harada", "Akira", ""], ["Nishikawa", "Shota", ""], ["Yamada", "Shoichi", ""]]}, {"id": "2104.13048", "submitter": "Zelin Zang", "authors": "Zelin Zang, Siyuan Li, Di Wu, Jianzhu Guo, Yongjie Xu, Stan Z. Li", "title": "Unsupervised Deep Manifold Attributed Graph Embedding", "comments": "arXiv admin note: text overlap with arXiv:2007.01594 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Unsupervised attributed graph representation learning is challenging since\nboth structural and feature information are required to be represented in the\nlatent space. Existing methods concentrate on learning latent representation\nvia reconstruction tasks, but cannot directly optimize representation and are\nprone to oversmoothing, thus limiting the applications on downstream tasks. To\nalleviate these issues, we propose a novel graph embedding framework named Deep\nManifold Attributed Graph Embedding (DMAGE). A node-to-node geodesic similarity\nis proposed to compute the inter-node similarity between the data space and the\nlatent space and then use Bergman divergence as loss function to minimize the\ndifference between them. We then design a new network structure with fewer\naggregation to alleviate the oversmoothing problem and incorporate graph\nstructure augmentation to improve the representation's stability. Our proposed\nDMAGE surpasses state-of-the-art methods by a significant margin on three\ndownstream tasks: unsupervised visualization, node clustering, and link\nprediction across four popular datasets.\n", "versions": [{"version": "v1", "created": "Tue, 27 Apr 2021 08:47:39 GMT"}], "update_date": "2021-04-28", "authors_parsed": [["Zang", "Zelin", ""], ["Li", "Siyuan", ""], ["Wu", "Di", ""], ["Guo", "Jianzhu", ""], ["Xu", "Yongjie", ""], ["Li", "Stan Z.", ""]]}, {"id": "2104.13050", "submitter": "Yanjun Zhang", "authors": "Yanjun Zhang, Guangdong Bai, Xue Li, Surya Nepal, Ryan K L Ko", "title": "Confined Gradient Descent: Privacy-preserving Optimization for Federated\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Federated learning enables multiple participants to collaboratively train a\nmodel without aggregating the training data. Although the training data are\nkept within each participant and the local gradients can be securely\nsynthesized, recent studies have shown that such privacy protection is\ninsufficient. The global model parameters that have to be shared for\noptimization are susceptible to leak information about training data. In this\nwork, we propose Confined Gradient Descent (CGD) that enhances privacy of\nfederated learning by eliminating the sharing of global model parameters. CGD\nexploits the fact that a gradient descent optimization can start with a set of\ndiscrete points and converges to another set at the neighborhood of the global\nminimum of the objective function. It lets the participants independently train\non their local data, and securely share the sum of local gradients to benefit\neach other. We formally demonstrate CGD's privacy enhancement over traditional\nFL. We prove that less information is exposed in CGD compared to that of\ntraditional FL. CGD also guarantees desired model accuracy. We theoretically\nestablish a convergence rate for CGD. We prove that the loss of the proprietary\nmodels learned for each participant against a model learned by aggregated\ntraining data is bounded. Extensive experimental results on two real-world\ndatasets demonstrate the performance of CGD is comparable with the centralized\nlearning, with marginal differences on validation loss (mostly within 0.05) and\naccuracy (mostly within 1%).\n", "versions": [{"version": "v1", "created": "Tue, 27 Apr 2021 08:49:42 GMT"}], "update_date": "2021-04-28", "authors_parsed": [["Zhang", "Yanjun", ""], ["Bai", "Guangdong", ""], ["Li", "Xue", ""], ["Nepal", "Surya", ""], ["Ko", "Ryan K L", ""]]}, {"id": "2104.13056", "submitter": "Dimos Makris", "authors": "Dimos Makris, Kat R. Agres, Dorien Herremans", "title": "Generating Lead Sheets with Affect: A Novel Conditional seq2seq\n  Framework", "comments": "Accepted for the International Joint Conference on Neural Networks\n  (IJCNN), Shenzhen, China, 18-22 July 2021 (virtual)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The field of automatic music composition has seen great progress in the last\nfew years, much of which can be attributed to advances in deep neural networks.\nThere are numerous studies that present different strategies for generating\nsheet music from scratch. The inclusion of high-level musical characteristics\n(e.g., perceived emotional qualities), however, as conditions for controlling\nthe generation output remains a challenge. In this paper, we present a novel\napproach for calculating the valence (the positivity or negativity of the\nperceived emotion) of a chord progression within a lead sheet, using\npre-defined mood tags proposed by music experts. Based on this approach, we\npropose a novel strategy for conditional lead sheet generation that allows us\nto steer the music generation in terms of valence, phrasing, and time\nsignature. Our approach is similar to a Neural Machine Translation (NMT)\nproblem, as we include high-level conditions in the encoder part of the\nsequence-to-sequence architectures used (i.e., long-short term memory networks,\nand a Transformer network). We conducted experiments to thoroughly analyze\nthese two architectures. The results show that the proposed strategy is able to\ngenerate lead sheets in a controllable manner, resulting in distributions of\nmusical attributes similar to those of the training dataset. We also verified\nthrough a subjective listening test that our approach is effective in\ncontrolling the valence of a generated chord progression.\n", "versions": [{"version": "v1", "created": "Tue, 27 Apr 2021 09:04:21 GMT"}], "update_date": "2021-04-28", "authors_parsed": [["Makris", "Dimos", ""], ["Agres", "Kat R.", ""], ["Herremans", "Dorien", ""]]}, {"id": "2104.13061", "submitter": "Bal\\'azs Pej\\'o", "authors": "Mathias P. M. Parisot, Balazs Pejo and Dayana Spagnuelo", "title": "Property Inference Attacks on Convolutional Neural Networks: Influence\n  and Implications of Target Model's Complexity", "comments": "The long version of the paper \"Property Inference Attacks,\n  Convolutional Neural Networks, Model Complexity\" from SECRYPT'21", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Machine learning models' goal is to make correct predictions for specific\ntasks by learning important properties and patterns from data. By doing so,\nthere is a chance that the model learns properties that are unrelated to its\nprimary task. Property Inference Attacks exploit this and aim to infer from a\ngiven model (\\ie the target model) properties about the training dataset\nseemingly unrelated to the model's primary goal. If the training data is\nsensitive, such an attack could lead to privacy leakage. This paper\ninvestigates the influence of the target model's complexity on the accuracy of\nthis type of attack, focusing on convolutional neural network classifiers. We\nperform attacks on models that are trained on facial images to predict whether\nsomeone's mouth is open. Our attacks' goal is to infer whether the training\ndataset is balanced gender-wise. Our findings reveal that the risk of a privacy\nbreach is present independently of the target model's complexity: for all\nstudied architectures, the attack's accuracy is clearly over the baseline. We\ndiscuss the implication of the property inference on personal data in the light\nof Data Protection Regulations and Guidelines.\n", "versions": [{"version": "v1", "created": "Tue, 27 Apr 2021 09:19:36 GMT"}], "update_date": "2021-04-28", "authors_parsed": [["Parisot", "Mathias P. M.", ""], ["Pejo", "Balazs", ""], ["Spagnuelo", "Dayana", ""]]}, {"id": "2104.13083", "submitter": "Moussa Doumbouya", "authors": "Moussa Doumbouya, Lisa Einstein, Chris Piech", "title": "Using Radio Archives for Low-Resource Speech Recognition: Towards an\n  Intelligent Virtual Assistant for Illiterate Users", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  For many of the 700 million illiterate people around the world, speech\nrecognition technology could provide a bridge to valuable information and\nservices. Yet, those most in need of this technology are often the most\nunderserved by it. In many countries, illiterate people tend to speak only\nlow-resource languages, for which the datasets necessary for speech technology\ndevelopment are scarce. In this paper, we investigate the effectiveness of\nunsupervised speech representation learning on noisy radio broadcasting\narchives, which are abundant even in low-resource languages. We make three core\ncontributions. First, we release two datasets to the research community. The\nfirst, West African Radio Corpus, contains 142 hours of audio in more than 10\nlanguages with a labeled validation subset. The second, West African Virtual\nAssistant Speech Recognition Corpus, consists of 10K labeled audio clips in\nfour languages. Next, we share West African wav2vec, a speech encoder trained\non the noisy radio corpus, and compare it with the baseline Facebook speech\nencoder trained on six times more data of higher quality. We show that West\nAfrican wav2vec performs similarly to the baseline on a multilingual speech\nrecognition task, and significantly outperforms the baseline on a West African\nlanguage identification task. Finally, we share the first-ever speech\nrecognition models for Maninka, Pular and Susu, languages spoken by a combined\n10 million people in over seven countries, including six where the majority of\nthe adult population is illiterate. Our contributions offer a path forward for\nethical AI research to serve the needs of those most disadvantaged by the\ndigital divide.\n", "versions": [{"version": "v1", "created": "Tue, 27 Apr 2021 10:09:34 GMT"}], "update_date": "2021-04-28", "authors_parsed": [["Doumbouya", "Moussa", ""], ["Einstein", "Lisa", ""], ["Piech", "Chris", ""]]}, {"id": "2104.13094", "submitter": "Manojit Chakraborty", "authors": "Manojit Chakraborty, Shubham Das, Radhika Mamidi", "title": "Detection of Fake Users in SMPs Using NLP and Graph Embeddings", "comments": "5 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Social Media Platforms (SMPs) like Facebook, Twitter, Instagram etc. have\nlarge user base all around the world that generates huge amount of data every\nsecond. This includes a lot of posts by fake and spam users, typically used by\nmany organisations around the globe to have competitive edge over others. In\nthis work, we aim at detecting such user accounts in Twitter using a novel\napproach. We show how to distinguish between Genuine and Spam accounts in\nTwitter using a combination of Graph Representation Learning and Natural\nLanguage Processing techniques.\n", "versions": [{"version": "v1", "created": "Tue, 27 Apr 2021 10:30:23 GMT"}], "update_date": "2021-04-28", "authors_parsed": [["Chakraborty", "Manojit", ""], ["Das", "Shubham", ""], ["Mamidi", "Radhika", ""]]}, {"id": "2104.13096", "submitter": "Jo\\~ao Rico", "authors": "Jo\\~ao Rico, Jos\\'e Barateiro, Arlindo Oliveira", "title": "Graph Neural Networks for Traffic Forecasting", "comments": null, "journal-ref": "OMAINTEC 2019", "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The significant increase in world population and urbanisation has brought\nseveral important challenges, in particular regarding the sustainability,\nmaintenance and planning of urban mobility. At the same time, the exponential\nincrease of computing capability and of available sensor and location data have\noffered the potential for innovative solutions to these challenges. In this\nwork, we focus on the challenge of traffic forecasting and review the recent\ndevelopment and application of graph neural networks (GNN) to this problem.\nGNNs are a class of deep learning methods that directly process the input as\ngraph data. This leverages more directly the spatial dependencies of traffic\ndata and makes use of the advantages of deep learning producing\nstate-of-the-art results. We introduce and review the emerging topic of GNNs,\nincluding their most common variants, with a focus on its application to\ntraffic forecasting. We address the different ways of modelling traffic\nforecasting as a (temporal) graph, the different approaches developed so far to\ncombine the graph and temporal learning components, as well as current\nlimitations and research opportunities.\n", "versions": [{"version": "v1", "created": "Tue, 27 Apr 2021 10:39:00 GMT"}], "update_date": "2021-04-28", "authors_parsed": [["Rico", "Jo\u00e3o", ""], ["Barateiro", "Jos\u00e9", ""], ["Oliveira", "Arlindo", ""]]}, {"id": "2104.13101", "submitter": "Felix P. Kemeth", "authors": "Felix P. Kemeth, Tom Bertalan, Nikolaos Evangelou, Tianqi Cui, Saurabh\n  Malani, Ioannis G. Kevrekidis", "title": "Initializing LSTM internal states via manifold learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG nlin.PS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present an approach, based on learning an intrinsic data manifold, for the\ninitialization of the internal state values of LSTM recurrent neural networks,\nensuring consistency with the initial observed input data. Exploiting the\ngeneralized synchronization concept, we argue that the converged, \"mature\"\ninternal states constitute a function on this learned manifold. The dimension\nof this manifold then dictates the length of observed input time series data\nrequired for consistent initialization. We illustrate our approach through a\npartially observed chemical model system, where initializing the internal LSTM\nstates in this fashion yields visibly improved performance. Finally, we show\nthat learning this data manifold enables the transformation of partially\nobserved dynamics into fully observed ones, facilitating alternative\nidentification paths for nonlinear dynamical systems.\n", "versions": [{"version": "v1", "created": "Tue, 27 Apr 2021 10:54:53 GMT"}, {"version": "v2", "created": "Wed, 12 May 2021 06:59:24 GMT"}], "update_date": "2021-05-13", "authors_parsed": [["Kemeth", "Felix P.", ""], ["Bertalan", "Tom", ""], ["Evangelou", "Nikolaos", ""], ["Cui", "Tianqi", ""], ["Malani", "Saurabh", ""], ["Kevrekidis", "Ioannis G.", ""]]}, {"id": "2104.13114", "submitter": "Chaosheng Dong", "authors": "Chaosheng Dong, Xiaojie Jin, Weihao Gao, Yijia Wang, Hongyi Zhang,\n  Xiang Wu, Jianchao Yang, Xiaobing Liu", "title": "One Backward from Ten Forward, Subsampling for Large-Scale Deep Learning", "comments": "13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning models in large-scale machine learning systems are often\ncontinuously trained with enormous data from production environments. The sheer\nvolume of streaming training data poses a significant challenge to real-time\ntraining subsystems and ad-hoc sampling is the standard practice. Our key\ninsight is that these deployed ML systems continuously perform forward passes\non data instances during inference, but ad-hoc sampling does not take advantage\nof this substantial computational effort. Therefore, we propose to record a\nconstant amount of information per instance from these forward passes. The\nextra information measurably improves the selection of which data instances\nshould participate in forward and backward passes. A novel optimization\nframework is proposed to analyze this problem and we provide an efficient\napproximation algorithm under the framework of Mini-batch gradient descent as a\npractical solution. We also demonstrate the effectiveness of our framework and\nalgorithm on several large-scale classification and regression tasks, when\ncompared with competitive baselines widely used in industry.\n", "versions": [{"version": "v1", "created": "Tue, 27 Apr 2021 11:29:02 GMT"}], "update_date": "2021-04-28", "authors_parsed": [["Dong", "Chaosheng", ""], ["Jin", "Xiaojie", ""], ["Gao", "Weihao", ""], ["Wang", "Yijia", ""], ["Zhang", "Hongyi", ""], ["Wu", "Xiang", ""], ["Yang", "Jianchao", ""], ["Liu", "Xiaobing", ""]]}, {"id": "2104.13166", "submitter": "Clara Luc\\'ia Galimberti", "authors": "Clara L. Galimberti, Liang Xu, Giancarlo Ferrari Trecate", "title": "A unified framework for Hamiltonian deep neural networks", "comments": "11 pages, 4 figures, accepted for L4DC 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training deep neural networks (DNNs) can be difficult due to the occurrence\nof vanishing/exploding gradients during weight optimization. To avoid this\nproblem, we propose a class of DNNs stemming from the time discretization of\nHamiltonian systems. The time-invariant version of the corresponding\nHamiltonian models enjoys marginal stability, a property that, as shown in\nprevious works and for specific DNNs architectures, can mitigate convergence to\nzero or divergence of gradients. In the present paper, we formally study this\nfeature by deriving and analysing the backward gradient dynamics in continuous\ntime. The proposed Hamiltonian framework, besides encompassing existing\nnetworks inspired by marginally stable ODEs, allows one to derive new and more\nexpressive architectures. The good performance of the novel DNNs is\ndemonstrated on benchmark classification problems, including digit recognition\nusing the MNIST dataset.\n", "versions": [{"version": "v1", "created": "Tue, 27 Apr 2021 13:20:24 GMT"}], "update_date": "2021-04-28", "authors_parsed": [["Galimberti", "Clara L.", ""], ["Xu", "Liang", ""], ["Trecate", "Giancarlo Ferrari", ""]]}, {"id": "2104.13171", "submitter": "Wenwen Min", "authors": "Wenwen Min, Taosheng Xu, Xiang Wan and Tsung-Hui Chang", "title": "Structured Sparse Non-negative Matrix Factorization with L20-Norm for\n  scRNA-seq Data Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Non-negative matrix factorization (NMF) is a powerful tool for dimensionality\nreduction and clustering. Unfortunately, the interpretation of the clustering\nresults from NMF is difficult, especially for the high-dimensional biological\ndata without effective feature selection. In this paper, we first introduce a\nrow-sparse NMF with $\\ell_{2,0}$-norm constraint (NMF_$\\ell_{20}$), where the\nbasis matrix $W$ is constrained by the $\\ell_{2,0}$-norm, such that $W$ has a\nrow-sparsity pattern with feature selection. It is a challenge to solve the\nmodel, because the $\\ell_{2,0}$-norm is non-convex and non-smooth. Fortunately,\nwe prove that the $\\ell_{2,0}$-norm satisfies the Kurdyka-\\L{ojasiewicz}\nproperty. Based on the finding, we present a proximal alternating linearized\nminimization algorithm and its monotone accelerated version to solve the\nNMF_$\\ell_{20}$ model. In addition, we also present a orthogonal NMF with\n$\\ell_{2,0}$-norm constraint (ONMF_$\\ell_{20}$) to enhance the clustering\nperformance by using a non-negative orthogonal constraint. We propose an\nefficient algorithm to solve ONMF_$\\ell_{20}$ by transforming it into a series\nof constrained and penalized matrix factorization problems. The results on\nnumerical and scRNA-seq datasets demonstrate the efficiency of our methods in\ncomparison with existing methods.\n", "versions": [{"version": "v1", "created": "Tue, 27 Apr 2021 13:31:41 GMT"}], "update_date": "2021-04-28", "authors_parsed": [["Min", "Wenwen", ""], ["Xu", "Taosheng", ""], ["Wan", "Xiang", ""], ["Chang", "Tsung-Hui", ""]]}, {"id": "2104.13184", "submitter": "Luc Le Magoarou", "authors": "Luc Le Magoarou (IRT b-com, Hypermedia)", "title": "Efficient channel charting via phase-insensitive distance computation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Channel charting is an unsupervised learning task whose objective is to\nencode channels so that the obtained representation reflects the relative\nspatial locations of the corresponding users. It has many potential\napplications, ranging from user scheduling to proactive handover. In this\npaper, a channel charting method is proposed, based on a distance measure\nspecifically designed to reduce the effect of small scale fading, which is an\nirrelevant phenomenon with respect to the channel charting task. A nonlinear\ndimensionality reduction technique aimed at preserving local distances (Isomap)\nis then applied to actually get the channel representation. The approach is\nempirically validated on realistic synthetic MIMO channels, achieving better\nresults than previously proposed approaches, at a lower cost.\n", "versions": [{"version": "v1", "created": "Tue, 27 Apr 2021 13:42:18 GMT"}], "update_date": "2021-04-28", "authors_parsed": [["Magoarou", "Luc Le", "", "IRT b-com, Hypermedia"]]}, {"id": "2104.13187", "submitter": "Tegg Sung", "authors": "Tegg Taekyong Sung, Bo Ryu", "title": "A Scalable and Reproducible System-on-Chip Simulation for Reinforcement\n  Learning", "comments": "6 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Reinforcement Learning (DRL) underlies in a simulated environment and\noptimizes objective goals. By extending the conventional interaction scheme,\nthis paper proffers gym-ds3, a scalable and reproducible open environment\ntailored for a high-fidelity Domain-Specific System-on-Chip (DSSoC)\napplication. The simulation corroborates to schedule hierarchical jobs onto\nheterogeneous System-on-Chip (SoC) processors and bridges the system to\nreinforcement learning research. We systematically analyze the representative\nSoC simulator and discuss the primary challenging aspects that the system (1)\ncontinuously generates indefinite jobs at a rapid injection rate, (2) optimizes\ncomplex objectives, and (3) operates in steady-state scheduling. We provide\nexemplary snippets and experimentally demonstrate the run-time performances on\ndifferent schedulers that successfully mimic results achieved from the standard\nDS3 framework and real-world embedded systems.\n", "versions": [{"version": "v1", "created": "Tue, 27 Apr 2021 13:46:57 GMT"}], "update_date": "2021-04-28", "authors_parsed": [["Sung", "Tegg Taekyong", ""], ["Ryu", "Bo", ""]]}, {"id": "2104.13189", "submitter": "Marko Rajkovi\\'c", "authors": "Juliane Braunsmann, Marko Rajkovi\\'c, Martin Rumpf, Benedikt Wirth", "title": "Learning low bending and low distortion manifold embeddings", "comments": "16 pages, 6 figures, accepted for DiffCVML2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Autoencoders are a widespread tool in machine learning to transform\nhigh-dimensional data into a lowerdimensional representation which still\nexhibits the essential characteristics of the input. The encoder provides an\nembedding from the input data manifold into a latent space which may then be\nused for further processing. For instance, learning interpolation on the\nmanifold may be simplified via the new manifold representation in latent space.\nThe efficiency of such further processing heavily depends on the regularity and\nstructure of the embedding. In this article, the embedding into latent space is\nregularized via a loss function that promotes an as isometric and as flat\nembedding as possible. The required training data comprises pairs of nearby\npoints on the input manifold together with their local distance and their local\nFrechet average. This regularity loss functional even allows to train the\nencoder on its own. The loss functional is computed via a Monte Carlo\nintegration which is shown to be consistent with a geometric loss functional\ndefined directly on the embedding map. Numerical tests are performed using\nimage data that encodes different data manifolds. The results show that smooth\nmanifold embeddings in latent space are obtained. These embeddings are regular\nenough such that interpolation between not too distant points on the manifold\nis well approximated by linear interpolation in latent space.\n", "versions": [{"version": "v1", "created": "Tue, 27 Apr 2021 13:51:12 GMT"}], "update_date": "2021-04-28", "authors_parsed": [["Braunsmann", "Juliane", ""], ["Rajkovi\u0107", "Marko", ""], ["Rumpf", "Martin", ""], ["Wirth", "Benedikt", ""]]}, {"id": "2104.13190", "submitter": "Md Tahmid Rahman Laskar", "authors": "Md Tahmid Rahman Laskar, Jimmy Huang, Vladan Smetana, Chris Stewart,\n  Kees Pouw, Aijun An, Stephen Chan, Lei Liu", "title": "Extending Isolation Forest for Anomaly Detection in Big Data via K-Means", "comments": "The final version will be published at ACM Transactions on\n  Cyber-Physical Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Industrial Information Technology (IT) infrastructures are often vulnerable\nto cyberattacks. To ensure security to the computer systems in an industrial\nenvironment, it is required to build effective intrusion detection systems to\nmonitor the cyber-physical systems (e.g., computer networks) in the industry\nfor malicious activities. This paper aims to build such intrusion detection\nsystems to protect the computer networks from cyberattacks. More specifically,\nwe propose a novel unsupervised machine learning approach that combines the\nK-Means algorithm with the Isolation Forest for anomaly detection in industrial\nbig data scenarios. Since our objective is to build the intrusion detection\nsystem for the big data scenario in the industrial domain, we utilize the\nApache Spark framework to implement our proposed model which was trained in\nlarge network traffic data (about 123 million instances of network traffic)\nstored in Elasticsearch. Moreover, we evaluate our proposed model on the live\nstreaming data and find that our proposed system can be used for real-time\nanomaly detection in the industrial setup. In addition, we address different\nchallenges that we face while training our model on large datasets and\nexplicitly describe how these issues were resolved. Based on our empirical\nevaluation in different use-cases for anomaly detection in real-world network\ntraffic data, we observe that our proposed system is effective to detect\nanomalies in big data scenarios. Finally, we evaluate our proposed model on\nseveral academic datasets to compare with other models and find that it\nprovides comparable performance with other state-of-the-art approaches.\n", "versions": [{"version": "v1", "created": "Tue, 27 Apr 2021 16:21:48 GMT"}], "update_date": "2021-04-28", "authors_parsed": [["Laskar", "Md Tahmid Rahman", ""], ["Huang", "Jimmy", ""], ["Smetana", "Vladan", ""], ["Stewart", "Chris", ""], ["Pouw", "Kees", ""], ["An", "Aijun", ""], ["Chan", "Stephen", ""], ["Liu", "Lei", ""]]}, {"id": "2104.13193", "submitter": "Prakhar Sharma", "authors": "Prakhar Sharma, Phillip Porras, Steven Cheung, James Carpenter, Vinod\n  Yegneswaran", "title": "Scalable Microservice Forensics and Stability Assessment Using\n  Variational Autoencoders", "comments": "4 pages, appendix, references", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present a deep learning based approach to containerized application\nruntime stability analysis, and an intelligent publishing algorithm that can\ndynamically adjust the depth of process-level forensics published to a backend\nincident analysis repository. The approach applies variational autoencoders\n(VAEs) to learn the stable runtime patterns of container images, and then\ninstantiates these container-specific VAEs to implement stability detection and\nadaptive forensics publishing. In performance comparisons using a 50-instance\ncontainer workload, a VAE-optimized service versus a conventional eBPF-based\nforensic publisher demonstrates 2 orders of magnitude (OM) CPU performance\nimprovement, a 3 OM reduction in network transport volume, and a 4 OM reduction\nin Elasticsearch storage costs. We evaluate the VAE-based stability detection\ntechnique against two attacks, CPUMiner and HTTP-flood attack, finding that it\nis effective in isolating both anomalies. We believe this technique provides a\nnovel approach to integrating fine-grained process monitoring and\ndigital-forensic services into large container ecosystems that today simply\ncannot be monitored by conventional techniques\n", "versions": [{"version": "v1", "created": "Fri, 23 Apr 2021 18:51:41 GMT"}], "update_date": "2021-04-28", "authors_parsed": [["Sharma", "Prakhar", ""], ["Porras", "Phillip", ""], ["Cheung", "Steven", ""], ["Carpenter", "James", ""], ["Yegneswaran", "Vinod", ""]]}, {"id": "2104.13195", "submitter": "Nathan Danneman", "authors": "Nathan Danneman, James Hyde", "title": "Predicting Adversary Lateral Movement Patterns with Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper develops a predictive model for which host, in an enterprise\nnetwork, an adversary is likely to compromise next in the course of a campaign.\nSuch a model might support dynamic monitoring or defenses. We generate data for\nthis model using simulated networks, with hosts, users, and adversaries as\nfirst-class entities. We demonstrate the predictive accuracy of the model on\nout-of-sample simulated data, and validate the findings against data captured\nfrom a Red Team event on a live enterprise network\n", "versions": [{"version": "v1", "created": "Fri, 23 Apr 2021 16:44:31 GMT"}], "update_date": "2021-04-28", "authors_parsed": [["Danneman", "Nathan", ""], ["Hyde", "James", ""]]}, {"id": "2104.13201", "submitter": "Maximilian Croci", "authors": "Maximilian L. Croci, Ushnish Sengupta, Matthew P. Juniper", "title": "Online parameter inference for the simulation of a Bunsen flame using\n  heteroscedastic Bayesian neural network ensembles", "comments": "6 pages, 3 figures", "journal-ref": "ICLR 2021 Deep Learning for Simulation Workshop", "doi": null, "report-no": null, "categories": "cs.LG stat.AP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper proposes a Bayesian data-driven machine learning method for the\nonline inference of the parameters of a G-equation model of a ducted, premixed\nflame. Heteroscedastic Bayesian neural network ensembles are trained on a\nlibrary of 1.7 million flame fronts simulated in LSGEN2D, a G-equation solver,\nto learn the Bayesian posterior distribution of the model parameters given\nobservations. The ensembles are then used to infer the parameters of Bunsen\nflame experiments so that the dynamics of these can be simulated in LSGEN2D.\nThis allows the surface area variation of the flame edge, a proxy for the heat\nrelease rate, to be calculated. The proposed method provides cheap and online\nparameter and uncertainty estimates matching results obtained with the ensemble\nKalman filter, at less computational cost. This enables fast and reliable\nsimulation of the combustion process.\n", "versions": [{"version": "v1", "created": "Mon, 26 Apr 2021 16:47:43 GMT"}], "update_date": "2021-04-28", "authors_parsed": [["Croci", "Maximilian L.", ""], ["Sengupta", "Ushnish", ""], ["Juniper", "Matthew P.", ""]]}, {"id": "2104.13207", "submitter": "R\\'emy Portelas", "authors": "Grgur Kova\\v{c}, R\\'emy Portelas, Katja Hofmann, Pierre-Yves Oudeyer", "title": "SocialAI 0.1: Towards a Benchmark to Stimulate Research on\n  Socio-Cognitive Abilities in Deep Reinforcement Learning Agents", "comments": "Accepted at NAACL ViGIL Workshop 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Building embodied autonomous agents capable of participating in social\ninteractions with humans is one of the main challenges in AI. This problem\nmotivated many research directions on embodied language use. Current approaches\nfocus on language as a communication tool in very simplified and non diverse\nsocial situations: the \"naturalness\" of language is reduced to the concept of\nhigh vocabulary size and variability. In this paper, we argue that aiming\ntowards human-level AI requires a broader set of key social skills: 1) language\nuse in complex and variable social contexts; 2) beyond language, complex\nembodied communication in multimodal settings within constantly evolving social\nworlds. In this work we explain how concepts from cognitive sciences could help\nAI to draw a roadmap towards human-like intelligence, with a focus on its\nsocial dimensions. We then study the limits of a recent SOTA Deep RL approach\nwhen tested on a first grid-world environment from the upcoming SocialAI, a\nbenchmark to assess the social skills of Deep RL agents. Videos and code are\navailable at https://sites.google.com/view/socialai01 .\n", "versions": [{"version": "v1", "created": "Tue, 27 Apr 2021 14:16:29 GMT"}], "update_date": "2021-04-28", "authors_parsed": [["Kova\u010d", "Grgur", ""], ["Portelas", "R\u00e9my", ""], ["Hofmann", "Katja", ""], ["Oudeyer", "Pierre-Yves", ""]]}, {"id": "2104.13208", "submitter": "Jean-Jil Duchamps", "authors": "Cl\\'ement Dombry and Jean-Jil Duchamps", "title": "Infinitesimal gradient boosting", "comments": "44 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.PR math.ST stat.TH", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We define infinitesimal gradient boosting as a limit of the popular\ntree-based gradient boosting algorithm from machine learning. The limit is\nconsidered in the vanishing-learning-rate asymptotic, that is when the learning\nrate tends to zero and the number of gradient trees is rescaled accordingly.\nFor this purpose, we introduce a new class of randomized regression trees\nbridging totally randomized trees and Extra Trees and using a softmax\ndistribution for binary splitting. Our main result is the convergence of the\nassociated stochastic algorithm and the characterization of the limiting\nprocedure as the unique solution of a nonlinear ordinary differential equation\nin a infinite dimensional function space. Infinitesimal gradient boosting\ndefines a smooth path in the space of continuous functions along which the\ntraining error decreases, the residuals remain centered and the total variation\nis well controlled.\n", "versions": [{"version": "v1", "created": "Mon, 26 Apr 2021 15:09:05 GMT"}], "update_date": "2021-04-28", "authors_parsed": [["Dombry", "Cl\u00e9ment", ""], ["Duchamps", "Jean-Jil", ""]]}, {"id": "2104.13215", "submitter": "Elsa Rizk", "authors": "Elsa Rizk and Ali H. Sayed", "title": "A Graph Federated Architecture with Privacy Preserving Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning involves a central processor that works with multiple\nagents to find a global model. The process consists of repeatedly exchanging\nestimates, which results in the diffusion of information pertaining to the\nlocal private data. Such a scheme can be inconvenient when dealing with\nsensitive data, and therefore, there is a need for the privatization of the\nalgorithms. Furthermore, the current architecture of a server connected to\nmultiple clients is highly sensitive to communication failures and\ncomputational overloads at the server. Thus in this work, we develop a private\nmulti-server federated learning scheme, which we call graph federated learning.\nWe use cryptographic and differential privacy concepts to privatize the\nfederated learning algorithm that we extend to the graph structure. We study\nthe effect of privatization on the performance of the learning algorithm for\ngeneral private schemes that can be modeled as additive noise. We show under\nconvexity and Lipschitz conditions, that the privatized process matches the\nperformance of the non-private algorithm, even when we increase the noise\nvariance.\n", "versions": [{"version": "v1", "created": "Mon, 26 Apr 2021 09:51:24 GMT"}], "update_date": "2021-04-28", "authors_parsed": [["Rizk", "Elsa", ""], ["Sayed", "Ali H.", ""]]}, {"id": "2104.13216", "submitter": "Cheng Wang", "authors": "Cheng Wang, Sun Kim, Taiwoo Park, Sajal Choudhary, Sunghyun Park,\n  Young-Bum Kim, Ruhi Sarikaya, Sungjin Lee", "title": "Handling Long-Tail Queries with Slice-Aware Conversational Systems", "comments": "Published at ICLR 2021 Workshop on Weakly Supervised Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We have been witnessing the usefulness of conversational AI systems such as\nSiri and Alexa, directly impacting our daily lives. These systems normally rely\non machine learning models evolving over time to provide quality user\nexperience. However, the development and improvement of the models are\nchallenging because they need to support both high (head) and low (tail) usage\nscenarios, requiring fine-grained modeling strategies for specific data subsets\nor slices. In this paper, we explore the recent concept of slice-based learning\n(SBL) (Chen et al., 2019) to improve our baseline conversational skill routing\nsystem on the tail yet critical query traffic. We first define a set of\nlabeling functions to generate weak supervision data for the tail intents. We\nthen extend the baseline model towards a slice-aware architecture, which\nmonitors and improves the model performance on the selected tail intents.\nApplied to de-identified live traffic from a commercial conversational AI\nsystem, our experiments show that the slice-aware model is beneficial in\nimproving model performance for the tail intents while maintaining the overall\nperformance.\n", "versions": [{"version": "v1", "created": "Mon, 26 Apr 2021 10:23:28 GMT"}], "update_date": "2021-04-28", "authors_parsed": [["Wang", "Cheng", ""], ["Kim", "Sun", ""], ["Park", "Taiwoo", ""], ["Choudhary", "Sajal", ""], ["Park", "Sunghyun", ""], ["Kim", "Young-Bum", ""], ["Sarikaya", "Ruhi", ""], ["Lee", "Sungjin", ""]]}, {"id": "2104.13225", "submitter": "Grzegorz Chrupa{\\l}a", "authors": "Grzegorz Chrupa{\\l}a", "title": "Visually grounded models of spoken language: A survey of datasets,\n  architectures and evaluation techniques", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG cs.SD eess.AS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This survey provides an overview of the evolution of visually grounded models\nof spoken language over the last 20 years. Such models are inspired by the\nobservation that when children pick up a language, they rely on a wide range of\nindirect and noisy clues, crucially including signals from the visual modality\nco-occurring with spoken utterances. Several fields have made important\ncontributions to this approach to modeling or mimicking the process of learning\nlanguage: Machine Learning, Natural Language and Speech Processing, Computer\nVision and Cognitive Science. The current paper brings together these\ncontributions in order to provide a useful introduction and overview for\npractitioners in all these areas. We discuss the central research questions\naddressed, the timeline of developments, and the datasets which enabled much of\nthis work. We then summarize the main modeling architectures and offer an\nexhaustive overview of the evaluation metrics and analysis techniques.\n", "versions": [{"version": "v1", "created": "Tue, 27 Apr 2021 14:32:22 GMT"}, {"version": "v2", "created": "Sat, 1 May 2021 14:59:07 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Chrupa\u0142a", "Grzegorz", ""]]}, {"id": "2104.13227", "submitter": "Mohammad-Ali Javidian", "authors": "Mohammad Ali Javidian, Vaneet Aggarwal, Zubin Jacob", "title": "Quantum Causal Inference in the Presence of Hidden Common Causes: an\n  Entropic Approach", "comments": "arXiv admin note: text overlap with arXiv:2102.11764", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.AI cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantum causality is an emerging field of study which has the potential to\ngreatly advance our understanding of quantum systems. One of the most important\nproblems in quantum causality is linked to this prominent aphorism that states\ncorrelation does not mean causation. A direct generalization of the existing\ncausal inference techniques to the quantum domain is not possible due to\nsuperposition and entanglement. We put forth a new theoretical framework for\nmerging quantum information science and causal inference by exploiting entropic\nprinciples. For this purpose, we leverage the concept of conditional density\nmatrices to develop a scalable algorithmic approach for inferring causality in\nthe presence of latent confounders (common causes) in quantum systems. We apply\nour proposed framework to an experimentally relevant scenario of identifying\nmessage senders on quantum noisy links, where it is validated that the input\nbefore noise as a latent confounder is the cause of the noisy outputs. We also\ndemonstrate that the proposed approach outperforms the results of classical\ncausal inference even when the variables are classical by exploiting quantum\ndependence between variables through density matrices rather than joint\nprobability distributions. Thus, the proposed approach unifies classical and\nquantum causal inference in a principled way. This successful inference on a\nsynthetic quantum dataset can lay the foundations of identifying originators of\nmalicious activity on future multi-node quantum networks.\n", "versions": [{"version": "v1", "created": "Sat, 24 Apr 2021 22:45:50 GMT"}], "update_date": "2021-06-12", "authors_parsed": [["Javidian", "Mohammad Ali", ""], ["Aggarwal", "Vaneet", ""], ["Jacob", "Zubin", ""]]}, {"id": "2104.13228", "submitter": "Inavamsi Enaganti", "authors": "Inavamsi Enaganti and Bud Mishra", "title": "To mock a Mocking bird : Studies in Biomimicry", "comments": "15 pages, 14 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.PE cs.GT cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This paper dwells on certain novel game-theoretic investigations in\nbio-mimicry, discussed from the perspectives of information asymmetry,\nindividual utility and its optimization via strategic interactions involving\nco-evolving preys (e.g., insects) and predators (e.g., reptiles) who learn.\nFormally, we consider a panmictic ecosystem, occupied by species of prey with\nrelatively short lifespan, which evolve mimicry signals over generations as\nthey interact with predators with relatively longer lifespans, thus endowing\npredators with the ability to learn prey signals. Every prey sends a signal and\nprovides utility to the predator. The prey can be either nutritious or toxic to\nthe predator, but the prey may signal (possibly) deceptively without revealing\nits true \"type.\" The model is used to study the situation where multi-armed\nbandit predators with zero prior information are introduced into the ecosystem.\nAs a result of exploration and exploitation the predators naturally select the\nprey that result in the evolution of those signals. This co-evolution of\nstrategies produces a variety of interesting phenomena which are subjects of\nthis paper.\n", "versions": [{"version": "v1", "created": "Mon, 26 Apr 2021 09:55:40 GMT"}], "update_date": "2021-04-28", "authors_parsed": [["Enaganti", "Inavamsi", ""], ["Mishra", "Bud", ""]]}, {"id": "2104.13230", "submitter": "Manish Shukla", "authors": "Sanjay Seetharaman, Shubham Malaviya, Rosni KV, Manish Shukla, Sachin\n  Lodha", "title": "Influence Based Defense Against Data Poisoning Attacks in Online\n  Learning", "comments": "18 pages, 3 Figures, 2 Tables, Adversarial Machine Learning, Data\n  Poisoning, Online Learning, Defense, Influence Function", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Data poisoning is a type of adversarial attack on training data where an\nattacker manipulates a fraction of data to degrade the performance of machine\nlearning model. Therefore, applications that rely on external data-sources for\ntraining data are at a significantly higher risk. There are several known\ndefensive mechanisms that can help in mitigating the threat from such attacks.\nFor example, data sanitization is a popular defensive mechanism wherein the\nlearner rejects those data points that are sufficiently far from the set of\ntraining instances. Prior work on data poisoning defense primarily focused on\noffline setting, wherein all the data is assumed to be available for analysis.\nDefensive measures for online learning, where data points arrive sequentially,\nhave not garnered similar interest.\n  In this work, we propose a defense mechanism to minimize the degradation\ncaused by the poisoned training data on a learner's model in an online setup.\nOur proposed method utilizes an influence function which is a classic technique\nin robust statistics. Further, we supplement it with the existing data\nsanitization methods for filtering out some of the poisoned data points. We\nstudy the effectiveness of our defense mechanism on multiple datasets and\nacross multiple attack strategies against an online learner.\n", "versions": [{"version": "v1", "created": "Sat, 24 Apr 2021 08:39:13 GMT"}], "update_date": "2021-04-28", "authors_parsed": [["Seetharaman", "Sanjay", ""], ["Malaviya", "Shubham", ""], ["KV", "Rosni", ""], ["Shukla", "Manish", ""], ["Lodha", "Sachin", ""]]}, {"id": "2104.13242", "submitter": "Xingfu Wu", "authors": "Xingfu Wu, Michael Kruse, Prasanna Balaprakash, Hal Finkel, Paul\n  Hovland, Valerie Taylor, and Mary Hall", "title": "Autotuning PolyBench Benchmarks with LLVM Clang/Polly Loop Optimization\n  Pragmas Using Bayesian Optimization (extended version)", "comments": "Submitted to CCPE journal. arXiv admin note: substantial text overlap\n  with arXiv:2010.08040", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.PF", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we develop a ytopt autotuning framework that leverages\nBayesian optimization to explore the parameter space search and compare four\ndifferent supervised learning methods within Bayesian optimization and evaluate\ntheir effectiveness. We select six of the most complex PolyBench benchmarks and\napply the newly developed LLVM Clang/Polly loop optimization pragmas to the\nbenchmarks to optimize them. We then use the autotuning framework to optimize\nthe pragma parameters to improve their performance. The experimental results\nshow that our autotuning approach outperforms the other compiling methods to\nprovide the smallest execution time for the benchmarks syr2k, 3mm, heat-3d, lu,\nand covariance with two large datasets in 200 code evaluations for effectively\nsearching the parameter spaces with up to 170,368 different configurations. We\nfind that the Floyd-Warshall benchmark did not benefit from autotuning because\nPolly uses heuristics to optimize the benchmark to make it run much slower. To\ncope with this issue, we provide some compiler option solutions to improve the\nperformance. Then we present loop autotuning without a user's knowledge using a\nsimple mctree autotuning framework to further improve the performance of the\nFloyd-Warshall benchmark. We also extend the ytopt autotuning framework to tune\na deep learning application.\n", "versions": [{"version": "v1", "created": "Tue, 27 Apr 2021 14:46:57 GMT"}], "update_date": "2021-04-28", "authors_parsed": [["Wu", "Xingfu", ""], ["Kruse", "Michael", ""], ["Balaprakash", "Prasanna", ""], ["Finkel", "Hal", ""], ["Hovland", "Paul", ""], ["Taylor", "Valerie", ""], ["Hall", "Mary", ""]]}, {"id": "2104.13255", "submitter": "Ting-Wu Chin", "authors": "Ting-Wu Chin, Diana Marculescu, Ari S. Morcos", "title": "Width Transfer: On the (In)variance of Width Optimization", "comments": "Full paper accepted at CVPR Workshops 2021; a 4-page abridged version\n  is accepted at ICLR 2021 NAS Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Optimizing the channel counts for different layers of a CNN has shown great\npromise in improving the efficiency of CNNs at test-time. However, these\nmethods often introduce large computational overhead (e.g., an additional 2x\nFLOPs of standard training). Minimizing this overhead could therefore\nsignificantly speed up training. In this work, we propose width transfer, a\ntechnique that harnesses the assumptions that the optimized widths (or channel\ncounts) are regular across sizes and depths. We show that width transfer works\nwell across various width optimization algorithms and networks. Specifically,\nwe can achieve up to 320x reduction in width optimization overhead without\ncompromising the top-1 accuracy on ImageNet, making the additional cost of\nwidth optimization negligible relative to initial training. Our findings not\nonly suggest an efficient way to conduct width optimization but also highlight\nthat the widths that lead to better accuracy are invariant to various aspects\nof network architectures and training data.\n", "versions": [{"version": "v1", "created": "Sat, 24 Apr 2021 19:51:53 GMT"}], "update_date": "2021-04-28", "authors_parsed": [["Chin", "Ting-Wu", ""], ["Marculescu", "Diana", ""], ["Morcos", "Ari S.", ""]]}, {"id": "2104.13257", "submitter": "Youssef Achenchabe", "authors": "Youssef Achenchabe, Alexis Bondu, Antoine Cornu\\'ejols, Vincent\n  Lemaire", "title": "Early Classification of Time Series is Meaningful", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Many approaches have been proposed for early classification of time series in\nlight of its significance in a wide range of applications including healthcare,\ntransportation and finance. However, recently a preprint saved on Arxiv claim\nthat all research done for almost 20 years now on the Early Classification of\nTime Series is useless, or, at the very least, ill-oriented because severely\nlacking a strong ground. In this paper, we answer in detail the main issues and\nmisunderstandings raised by the authors of the preprint, and propose directions\nto further expand the fields of application of early classification of time\nseries.\n", "versions": [{"version": "v1", "created": "Tue, 27 Apr 2021 15:16:21 GMT"}, {"version": "v2", "created": "Fri, 30 Apr 2021 09:36:38 GMT"}], "update_date": "2021-05-03", "authors_parsed": [["Achenchabe", "Youssef", ""], ["Bondu", "Alexis", ""], ["Cornu\u00e9jols", "Antoine", ""], ["Lemaire", "Vincent", ""]]}, {"id": "2104.13268", "submitter": "Madeleine Kotzagiannidis", "authors": "Madeleine Kotzagiannidis, Carola-Bibiane Sch\\\"onlieb", "title": "Semi-supervised Superpixel-based Multi-Feature Graph Learning for\n  Hyperspectral Image Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graphs naturally lend themselves to model the complexities of Hyperspectral\nImage (HSI) data as well as to serve as semi-supervised classifiers by\npropagating given labels among nearest neighbours. In this work, we present a\nnovel framework for the classification of HSI data in light of a very limited\namount of labelled data, inspired by multi-view graph learning and graph signal\nprocessing. Given an a priori superpixel-segmented hyperspectral image, we seek\na robust and efficient graph construction and label propagation method to\nconduct semi-supervised learning (SSL). Since the graph is paramount to the\nsuccess of the subsequent classification task, particularly in light of the\nintrinsic complexity of HSI data, we consider the problem of finding the\noptimal graph to model such data. Our contribution is two-fold: firstly, we\npropose a multi-stage edge-efficient semi-supervised graph learning framework\nfor HSI data which exploits given label information through pseudo-label\nfeatures embedded in the graph construction. Secondly, we examine and enhance\nthe contribution of multiple superpixel features embedded in the graph on the\nbasis of pseudo-labels in an extension of the previous framework, which is less\nreliant on excessive parameter tuning. Ultimately, we demonstrate the\nsuperiority of our approaches in comparison with state-of-the-art methods\nthrough extensive numerical experiments.\n", "versions": [{"version": "v1", "created": "Tue, 27 Apr 2021 15:36:26 GMT"}], "update_date": "2021-04-28", "authors_parsed": [["Kotzagiannidis", "Madeleine", ""], ["Sch\u00f6nlieb", "Carola-Bibiane", ""]]}, {"id": "2104.13276", "submitter": "Gabriel Meseguer-Brocal", "authors": "Gabriel Meseguer-Brocal", "title": "MULTIMODAL ANALYSIS: Informed content estimation and audio source\n  separation", "comments": "Ph.D. dissertation. Thesis supervisor: Geoffroy Peeters. Jury:Laurent\n  Girin, Ga\\\"el Richard, Rachel Bittner, Elena Cabrio, Bruno Gas, Perfecto\n  Herrera Boyer, Antoine Liutkus", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.DB cs.IR cs.LG eess.AS", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This dissertation proposes the study of multimodal learning in the context of\nmusical signals. Throughout, we focus on the interaction between audio signals\nand text information. Among the many text sources related to music that can be\nused (e.g. reviews, metadata, or social network feedback), we concentrate on\nlyrics. The singing voice directly connects the audio signal and the text\ninformation in a unique way, combining melody and lyrics where a linguistic\ndimension complements the abstraction of musical instruments. Our study focuses\non the audio and lyrics interaction for targeting source separation and\ninformed content estimation.\n", "versions": [{"version": "v1", "created": "Tue, 27 Apr 2021 15:45:21 GMT"}, {"version": "v2", "created": "Mon, 3 May 2021 14:50:58 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Meseguer-Brocal", "Gabriel", ""]]}, {"id": "2104.13277", "submitter": "Stefan Jaeger", "authors": "Stefan Jaeger", "title": "A Dual Process Model for Optimizing Cross Entropy in Neural Networks", "comments": "8 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Minimizing cross-entropy is a widely used method for training artificial\nneural networks. Many training procedures based on backpropagation use\ncross-entropy directly as their loss function. Instead, this theoretical essay\ninvestigates a dual process model with two processes, in which one process\nminimizes the Kullback-Leibler divergence while its dual counterpart minimizes\nthe Shannon entropy. Postulating that learning consists of two dual processes\ncomplementing each other, the model defines an equilibrium state for both\nprocesses in which the loss function assumes its minimum. An advantage of the\nproposed model is that it allows deriving the optimal learning rate and\nmomentum weight to update network weights for backpropagation. Furthermore, the\nmodel introduces the golden ratio and complex numbers as important new concepts\nin machine learning.\n", "versions": [{"version": "v1", "created": "Tue, 27 Apr 2021 15:45:43 GMT"}], "update_date": "2021-04-28", "authors_parsed": [["Jaeger", "Stefan", ""]]}, {"id": "2104.13289", "submitter": "Rita Fioresi", "authors": "Luca Grementieri, Rita Fioresi", "title": "Model-centric Data Manifold: the Data Through the Eyes of the Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We discover that deep ReLU neural network classifiers can see a\nlow-dimensional Riemannian manifold structure on data. Such structure comes via\nthe local data matrix, a variation of the Fisher information matrix, where the\nrole of the model parameters is taken by the data variables. We obtain a\nfoliation of the data domain and we show that the dataset on which the model is\ntrained lies on a leaf, the data leaf, whose dimension is bounded by the number\nof classification labels. We validate our results with some experiments with\nthe MNIST dataset: paths on the data leaf connect valid images, while other\nleaves cover noisy images.\n", "versions": [{"version": "v1", "created": "Mon, 26 Apr 2021 16:03:09 GMT"}], "update_date": "2021-04-28", "authors_parsed": [["Grementieri", "Luca", ""], ["Fioresi", "Rita", ""]]}, {"id": "2104.13297", "submitter": "Otto Menegasso Pires", "authors": "O. M. Pires, E. I. Duzzioni, J. Marchi, R. Santiago", "title": "Quantum circuit synthesis of Bell and GHZ states using projective\n  simulation in the NISQ era", "comments": null, "journal-ref": "Inteligencia Artificial, 24(67) (2021), 90-101", "doi": "10.4114/intartif.vol24iss67pp90-101", "report-no": null, "categories": "quant-ph cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Quantum Computing has been evolving in the last years. Although nowadays\nquantum algorithms performance has shown superior to their classical\ncounterparts, quantum decoherence and additional auxiliary qubits needed for\nerror tolerance routines have been huge barriers for quantum algorithms\nefficient use. These restrictions lead us to search for ways to minimize\nalgorithms costs, i.e the number of quantum logical gates and the depth of the\ncircuit. For this, quantum circuit synthesis and quantum circuit optimization\ntechniques are explored. We studied the viability of using Projective\nSimulation, a reinforcement learning technique, to tackle the problem of\nquantum circuit synthesis for noise quantum computers with limited number of\nqubits. The agent had the task of creating quantum circuits up to 5 qubits to\ngenerate GHZ states in the IBM Tenerife (IBM QX4) quantum processor. Our\nsimulations demonstrated that the agent had a good performance but its capacity\nfor learning new circuits decreased as the number of qubits increased.\n", "versions": [{"version": "v1", "created": "Tue, 27 Apr 2021 16:11:27 GMT"}], "update_date": "2021-05-06", "authors_parsed": [["Pires", "O. M.", ""], ["Duzzioni", "E. I.", ""], ["Marchi", "J.", ""], ["Santiago", "R.", ""]]}, {"id": "2104.13299", "submitter": "David Alvarez-Melis", "authors": "David Alvarez-Melis, Harmanpreet Kaur, Hal Daum\\'e III, Hanna Wallach,\n  Jennifer Wortman Vaughan", "title": "A Human-Centered Interpretability Framework Based on Weight of Evidence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we take a human-centered approach to interpretable machine\nlearning. First, drawing inspiration from the study of explanation in\nphilosophy, cognitive science, and the social sciences, we propose a list of\ndesign principles for machine-generated explanations that are meaningful to\nhumans. Using the concept of weight of evidence from information theory, we\ndevelop a method for producing explanations that adhere to these principles. We\nshow that this method can be adapted to handle high-dimensional, multi-class\nsettings, yielding a flexible meta-algorithm for generating explanations. We\ndemonstrate that these explanations can be estimated accurately from finite\nsamples and are robust to small perturbations of the inputs. We also evaluate\nour method through a qualitative user study with machine learning\npractitioners, where we observe that the resulting explanations are usable\ndespite some participants struggling with background concepts like prior class\nprobabilities. Finally, we conclude by surfacing design implications for\ninterpretability tools\n", "versions": [{"version": "v1", "created": "Tue, 27 Apr 2021 16:13:35 GMT"}], "update_date": "2021-04-28", "authors_parsed": [["Alvarez-Melis", "David", ""], ["Kaur", "Harmanpreet", ""], ["Daum\u00e9", "Hal", "III"], ["Wallach", "Hanna", ""], ["Vaughan", "Jennifer Wortman", ""]]}, {"id": "2104.13302", "submitter": "Shiqi Chen", "authors": "Shiqi Chen, Zhengyu Chen, Donglin Wang", "title": "Adaptive Adversarial Training for Meta Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Meta Reinforcement Learning (MRL) enables an agent to learn from a limited\nnumber of past trajectories and extrapolate to a new task. In this paper, we\nattempt to improve the robustness of MRL. We build upon model-agnostic\nmeta-learning (MAML) and propose a novel method to generate adversarial samples\nfor MRL by using Generative Adversarial Network (GAN). That allows us to\nenhance the robustness of MRL to adversal attacks by leveraging these attacks\nduring meta training process.\n", "versions": [{"version": "v1", "created": "Tue, 27 Apr 2021 16:23:34 GMT"}], "update_date": "2021-04-28", "authors_parsed": [["Chen", "Shiqi", ""], ["Chen", "Zhengyu", ""], ["Wang", "Donglin", ""]]}, {"id": "2104.13312", "submitter": "Arjun Roy", "authors": "Arjun Roy, Vasileios Iosifidis, Eirini Ntoutsi", "title": "Multi-Fair Pareto Boosting", "comments": "16 Pages main paper, 6 pages supplementary, submitted in ECML-PKDD\n  2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fairness-aware machine learning for multiple protected at-tributes (referred\nto as multi-fairness hereafter) is receiving increasing attention as\ntraditional single-protected attribute approaches cannot en-sure fairness\nw.r.t. other protected attributes. Existing methods, how-ever, still ignore the\nfact that datasets in this domain are often imbalanced, leading to unfair\ndecisions towards the minority class. Thus, solutions are needed that achieve\nmulti-fairness,accurate predictive performance in overall, and balanced\nperformance across the different classes.To this end, we introduce a new\nfairness notion,Multi-Max Mistreatment(MMM), which measures unfairness while\nconsidering both (multi-attribute) protected group and class membership of\ninstances. To learn an MMM-fair classifier, we propose a multi-objective\nproblem formulation. We solve the problem using a boosting approach that\nin-training,incorporates multi-fairness treatment in the distribution update\nand post-training, finds multiple Pareto-optimal solutions; then uses\npseudo-weight based decision making to select optimal solution(s) among\naccurate, balanced, and multi-attribute fair solutions\n", "versions": [{"version": "v1", "created": "Tue, 27 Apr 2021 16:37:35 GMT"}, {"version": "v2", "created": "Tue, 4 May 2021 08:57:50 GMT"}], "update_date": "2021-05-05", "authors_parsed": [["Roy", "Arjun", ""], ["Iosifidis", "Vasileios", ""], ["Ntoutsi", "Eirini", ""]]}, {"id": "2104.13315", "submitter": "Shivam Handa", "authors": "Shivam Handa and Martin Rinard", "title": "Inductive Program Synthesis over Noisy Datasets using Abstraction\n  Refinement Based Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.FL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new synthesis algorithm to solve program synthesis over noisy\ndatasets, i.e., data that may contain incorrect/corrupted input-output\nexamples. Our algorithm uses an abstraction refinement based optimization\nprocess to synthesize programs which optimize the tradeoff between the loss\nover the noisy dataset and the complexity of the synthesized program. The\nalgorithm uses abstractions to divide the search space of programs into\nsubspaces by computing an abstract value that represents outputs for all\nprograms in a subspace. The abstract value allows our algorithm to compute, for\neach subspace, a sound approximate lower bound of the loss over all programs in\nthe subspace. It iteratively refines these abstractions to further subdivide\nthe space into smaller subspaces, prune subspaces that do not contain an\noptimal program, and eventually synthesize an optimal program.\n  We implemented this algorithm in a tool called Rose. We compare Rose to a\ncurrent state-of-the-art noisy program synthesis system using the SyGuS 2018\nbenchmark suite. Our evaluation demonstrates that Rose significantly\noutperforms this previous system: on two noisy benchmark program synthesis\nproblems sets drawn from the SyGus 2018 benchmark suite, Rose delivers speedups\nof up to 1587 and 81.7, with median speedups of 20.5 and 81.7. Rose also\nterminates on 20 (out of 54) and 4 (out of 11) more benchmark problems than the\nprevious system. Both Rose and the previous system synthesize programs that are\noptimal over the provided noisy data sets. For the majority of the problems in\nthe benchmark sets ($272$ out of $286$), the synthesized programs also produce\ncorrect outputs for all inputs in the original (unseen) noise-free data set.\nThese results highlight the benefits that Rose can deliver for effective noisy\nprogram synthesis.\n", "versions": [{"version": "v1", "created": "Tue, 27 Apr 2021 16:45:11 GMT"}], "update_date": "2021-04-28", "authors_parsed": [["Handa", "Shivam", ""], ["Rinard", "Martin", ""]]}, {"id": "2104.13316", "submitter": "Kai-Hung Chang", "authors": "Kai-Hung Chang, Chin-Yi Cheng, Jieliang Luo, Shingo Murata, Mehdi\n  Nourbakhsh, Yoshito Tsuji", "title": "Building-GAN: Graph-Conditioned Architectural Volumetric Design\n  Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Volumetric design is the first and critical step for professional building\ndesign, where architects not only depict the rough 3D geometry of the building\nbut also specify the programs to form a 2D layout on each floor. Though 2D\nlayout generation for a single story has been widely studied, there is no\ndeveloped method for multi-story buildings. This paper focuses on volumetric\ndesign generation conditioned on an input program graph. Instead of outputting\ndense 3D voxels, we propose a new 3D representation named voxel graph that is\nboth compact and expressive for building geometries. Our generator is a\ncross-modal graph neural network that uses a pointer mechanism to connect the\ninput program graph and the output voxel graph, and the whole pipeline is\ntrained using the adversarial framework. The generated designs are evaluated\nqualitatively by a user study and quantitatively using three metrics: quality,\ndiversity, and connectivity accuracy. We show that our model generates\nrealistic 3D volumetric designs and outperforms previous methods and baselines.\n", "versions": [{"version": "v1", "created": "Tue, 27 Apr 2021 16:49:34 GMT"}], "update_date": "2021-04-28", "authors_parsed": [["Chang", "Kai-Hung", ""], ["Cheng", "Chin-Yi", ""], ["Luo", "Jieliang", ""], ["Murata", "Shingo", ""], ["Nourbakhsh", "Mehdi", ""], ["Tsuji", "Yoshito", ""]]}, {"id": "2104.13321", "submitter": "Tobias Skovgaard Jepsen", "authors": "Tobias Skovgaard Jepsen and Christian S. Jensen and Thomas Dyhre\n  Nielsen", "title": "UniTE -- The Best of Both Worlds: Unifying Function-Fitting and\n  Aggregation-Based Approaches to Travel Time and Travel Speed Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Travel time or speed estimation are part of many intelligent transportation\napplications. Existing estimation approaches rely on either function fitting or\naggregation and represent different trade-offs between generalizability and\naccuracy. Function-fitting approaches learn functions that map feature vectors\nof, e.g., routes, to travel time or speed estimates, which enables\ngeneralization to unseen routes. However, mapping functions are imperfect and\noffer poor accuracy in practice. Aggregation-based approaches instead form\nestimates by aggregating historical data, e.g., traversal data for routes. This\nenables very high accuracy given sufficient data. However, they rely on\nsimplistic heuristics when insufficient data is available, yielding poor\ngeneralizability. We present a Unifying approach to Travel time and speed\nEstimation (UniTE) that combines function-fitting and aggregation-based\napproaches into a unified framework that aims to achieve the generalizability\nof function-fitting approaches and the accuracy of aggregation-based\napproaches. An empirical study finds that an instance of UniTE can improve the\naccuracies of travel speed distribution and travel time estimation by $40-64\\%$\nand $3-23\\%$, respectively, compared to using function fitting or aggregation\nalone\n", "versions": [{"version": "v1", "created": "Tue, 27 Apr 2021 16:55:24 GMT"}], "update_date": "2021-04-28", "authors_parsed": [["Jepsen", "Tobias Skovgaard", ""], ["Jensen", "Christian S.", ""], ["Nielsen", "Thomas Dyhre", ""]]}, {"id": "2104.13323", "submitter": "Xin Sun", "authors": "Xin Sun, Zenghui Song, Yongbo Yu, Junyu Dong, Claudia Plant, and\n  Christian Boehm", "title": "Network Embedding via Deep Prediction Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network-structured data becomes ubiquitous in daily life and is growing at a\nrapid pace. It presents great challenges to feature engineering due to the high\nnon-linearity and sparsity of the data. The local and global structure of the\nreal-world networks can be reflected by dynamical transfer behaviors among\nnodes. This paper proposes a network embedding framework to capture the\ntransfer behaviors on structured networks via deep prediction models. We first\ndesign a degree-weight biased random walk model to capture the transfer\nbehaviors on the network. Then a deep network embedding method is introduced to\npreserve the transfer possibilities among the nodes. A network structure\nembedding layer is added into conventional deep prediction models, including\nLong Short-Term Memory Network and Recurrent Neural Network, to utilize the\nsequence prediction ability. To keep the local network neighborhood, we further\nperform a Laplacian supervised space optimization on the embedding feature\nrepresentations. Experimental studies are conducted on various datasets\nincluding social networks, citation networks, biomedical network, collaboration\nnetwork and language network. The results show that the learned representations\ncan be effectively used as features in a variety of tasks, such as clustering,\nvisualization, classification, reconstruction and link prediction, and achieve\npromising performance compared with state-of-the-arts.\n", "versions": [{"version": "v1", "created": "Tue, 27 Apr 2021 16:56:00 GMT"}], "update_date": "2021-04-28", "authors_parsed": [["Sun", "Xin", ""], ["Song", "Zenghui", ""], ["Yu", "Yongbo", ""], ["Dong", "Junyu", ""], ["Plant", "Claudia", ""], ["Boehm", "Christian", ""]]}, {"id": "2104.13326", "submitter": "Yaodong Yu", "authors": "Yaodong Yu, Tianyi Lin, Eric Mazumdar, Michael I. Jordan", "title": "Fast Distributionally Robust Learning with Variance Reduced Min-Max\n  Optimization", "comments": "The first three authors contributed equally to this work; 37 pages,\n  20 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributionally robust supervised learning (DRSL) is emerging as a key\nparadigm for building reliable machine learning systems for real-world\napplications -- reflecting the need for classifiers and predictive models that\nare robust to the distribution shifts that arise from phenomena such as\nselection bias or nonstationarity. Existing algorithms for solving Wasserstein\nDRSL -- one of the most popular DRSL frameworks based around robustness to\nperturbations in the Wasserstein distance -- involve solving complex\nsubproblems or fail to make use of stochastic gradients, limiting their use in\nlarge-scale machine learning problems. We revisit Wasserstein DRSL through the\nlens of min-max optimization and derive scalable and efficiently implementable\nstochastic extra-gradient algorithms which provably achieve faster convergence\nrates than existing approaches. We demonstrate their effectiveness on synthetic\nand real data when compared to existing DRSL approaches. Key to our results is\nthe use of variance reduction and random reshuffling to accelerate stochastic\nmin-max optimization, the analysis of which may be of independent interest.\n", "versions": [{"version": "v1", "created": "Tue, 27 Apr 2021 16:56:09 GMT"}], "update_date": "2021-04-28", "authors_parsed": [["Yu", "Yaodong", ""], ["Lin", "Tianyi", ""], ["Mazumdar", "Eric", ""], ["Jordan", "Michael I.", ""]]}, {"id": "2104.13332", "submitter": "Rodrigo Mira", "authors": "Rodrigo Mira, Konstantinos Vougioukas, Pingchuan Ma, Stavros Petridis,\n  Bj\\\"orn W. Schuller, Maja Pantic", "title": "End-to-End Video-To-Speech Synthesis using Generative Adversarial\n  Networks", "comments": "This work has been submitted to the IEEE for possible publication.\n  Copyright may be transferred without notice, after which this version may no\n  longer be accessible", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Video-to-speech is the process of reconstructing the audio speech from a\nvideo of a spoken utterance. Previous approaches to this task have relied on a\ntwo-step process where an intermediate representation is inferred from the\nvideo, and is then decoded into waveform audio using a vocoder or a waveform\nreconstruction algorithm. In this work, we propose a new end-to-end\nvideo-to-speech model based on Generative Adversarial Networks (GANs) which\ntranslates spoken video to waveform end-to-end without using any intermediate\nrepresentation or separate waveform synthesis algorithm. Our model consists of\nan encoder-decoder architecture that receives raw video as input and generates\nspeech, which is then fed to a waveform critic and a power critic. The use of\nan adversarial loss based on these two critics enables the direct synthesis of\nraw audio waveform and ensures its realism. In addition, the use of our three\ncomparative losses helps establish direct correspondence between the generated\naudio and the input video. We show that this model is able to reconstruct\nspeech with remarkable realism for constrained datasets such as GRID, and that\nit is the first end-to-end model to produce intelligible speech for LRW (Lip\nReading in the Wild), featuring hundreds of speakers recorded entirely `in the\nwild'. We evaluate the generated samples in two different scenarios -- seen and\nunseen speakers -- using four objective metrics which measure the quality and\nintelligibility of artificial speech. We demonstrate that the proposed approach\noutperforms all previous works in most metrics on GRID and LRW.\n", "versions": [{"version": "v1", "created": "Tue, 27 Apr 2021 17:12:30 GMT"}, {"version": "v2", "created": "Fri, 30 Apr 2021 17:04:57 GMT"}], "update_date": "2021-05-03", "authors_parsed": [["Mira", "Rodrigo", ""], ["Vougioukas", "Konstantinos", ""], ["Ma", "Pingchuan", ""], ["Petridis", "Stavros", ""], ["Schuller", "Bj\u00f6rn W.", ""], ["Pantic", "Maja", ""]]}, {"id": "2104.13343", "submitter": "Franco Pellegrini", "authors": "Franco Pellegrini, Giulio Biroli", "title": "Sifting out the features by pruning: Are convolutional networks the\n  winning lottery ticket of fully connected ones?", "comments": "25 pages, 18 figures; typos corrected, references added", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Pruning methods can considerably reduce the size of artificial neural\nnetworks without harming their performance. In some cases, they can even\nuncover sub-networks that, when trained in isolation, match or surpass the test\naccuracy of their dense counterparts. Here we study the inductive bias that\npruning imprints in such \"winning lottery tickets\". Focusing on visual tasks,\nwe analyze the architecture resulting from iterative magnitude pruning of a\nsimple fully connected network (FCN). We show that the surviving node\nconnectivity is local in input space, and organized in patterns reminiscent of\nthe ones found in convolutional networks (CNN). We investigate the role played\nby data and tasks in shaping the architecture of pruned sub-networks. Our\nresults show that the winning lottery tickets of FCNs display the key features\nof CNNs. The ability of such automatic network-simplifying procedure to recover\nthe key features \"hand-crafted\" in the design of CNNs suggests interesting\napplications to other datasets and tasks, in order to discover new and\nefficient architectural inductive biases.\n", "versions": [{"version": "v1", "created": "Tue, 27 Apr 2021 17:25:54 GMT"}, {"version": "v2", "created": "Fri, 14 May 2021 10:52:49 GMT"}], "update_date": "2021-05-17", "authors_parsed": [["Pellegrini", "Franco", ""], ["Biroli", "Giulio", ""]]}, {"id": "2104.13352", "submitter": "Ajay Agarwal", "authors": "Ajay Agarwal, Basant Agarwal", "title": "Tracking Peaceful Tractors on Social Media -- XAI-enabled analysis of\n  Red Fort Riots 2021", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  On 26 January 2021, India witnessed a national embarrassment from the\ndemographic least expected from - farmers. People across the nation watched in\nhorror as a pseudo-patriotic mob of farmers stormed capital Delhi and\nvandalized the national pride- Red Fort. Investigations that followed the event\nrevealed the existence of a social media trail that led to the likes of such an\nevent. Consequently, it became essential and necessary to archive this trail\nfor social media analysis - not only to understand the bread-crumbs that are\ndispersed across the trail but also to visualize the role played by\nmisinformation and fake news in this event. In this paper, we propose the\ntractor2twitter dataset which contains around 0.05 million tweets that were\nposted before, during, and after this event. Also, we benchmark our dataset\nwith an Explainable AI ML model for classification of each tweet into either of\nthe three categories - disinformation, misinformation, and opinion.\n", "versions": [{"version": "v1", "created": "Sat, 24 Apr 2021 08:54:02 GMT"}, {"version": "v2", "created": "Sun, 13 Jun 2021 12:27:10 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Agarwal", "Ajay", ""], ["Agarwal", "Basant", ""]]}, {"id": "2104.13369", "submitter": "Michal Yarom", "authors": "Oran Lang, Yossi Gandelsman, Michal Yarom, Yoav Wald, Gal Elidan,\n  Avinatan Hassidim, William T. Freeman, Phillip Isola, Amir Globerson, Michal\n  Irani, Inbar Mosseri", "title": "Explaining in Style: Training a GAN to explain a classifier in\n  StyleSpace", "comments": "First four authors contributed equally. Project page:\n  https://explaining-in-style.github.io/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Image classification models can depend on multiple different semantic\nattributes of the image. An explanation of the decision of the classifier needs\nto both discover and visualize these properties. Here we present StylEx, a\nmethod for doing this, by training a generative model to specifically explain\nmultiple attributes that underlie classifier decisions. A natural source for\nsuch attributes is the StyleSpace of StyleGAN, which is known to generate\nsemantically meaningful dimensions in the image. However, because standard GAN\ntraining is not dependent on the classifier, it may not represent these\nattributes which are important for the classifier decision, and the dimensions\nof StyleSpace may represent irrelevant attributes. To overcome this, we propose\na training procedure for a StyleGAN, which incorporates the classifier model,\nin order to learn a classifier-specific StyleSpace. Explanatory attributes are\nthen selected from this space. These can be used to visualize the effect of\nchanging multiple attributes per image, thus providing image-specific\nexplanations. We apply StylEx to multiple domains, including animals, leaves,\nfaces and retinal images. For these, we show how an image can be modified in\ndifferent ways to change its classifier output. Our results show that the\nmethod finds attributes that align well with semantic ones, generate meaningful\nimage-specific explanations, and are human-interpretable as measured in\nuser-studies.\n", "versions": [{"version": "v1", "created": "Tue, 27 Apr 2021 17:57:19 GMT"}], "update_date": "2021-04-28", "authors_parsed": [["Lang", "Oran", ""], ["Gandelsman", "Yossi", ""], ["Yarom", "Michal", ""], ["Wald", "Yoav", ""], ["Elidan", "Gal", ""], ["Hassidim", "Avinatan", ""], ["Freeman", "William T.", ""], ["Isola", "Phillip", ""], ["Globerson", "Amir", ""], ["Irani", "Michal", ""], ["Mosseri", "Inbar", ""]]}, {"id": "2104.13386", "submitter": "Tatsuhiro Onodera Mr.", "authors": "Logan G. Wright, Tatsuhiro Onodera, Martin M. Stein, Tianyu Wang,\n  Darren T. Schachter, Zoey Hu, Peter L. McMahon", "title": "Deep physical neural networks enabled by a backpropagation algorithm for\n  arbitrary physical systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cond-mat.dis-nn cs.ET physics.optics", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deep neural networks have become a pervasive tool in science and engineering.\nHowever, modern deep neural networks' growing energy requirements now\nincreasingly limit their scaling and broader use. We propose a radical\nalternative for implementing deep neural network models: Physical Neural\nNetworks. We introduce a hybrid physical-digital algorithm called Physics-Aware\nTraining to efficiently train sequences of controllable physical systems to act\nas deep neural networks. This method automatically trains the functionality of\nany sequence of real physical systems, directly, using backpropagation, the\nsame technique used for modern deep neural networks. To illustrate their\ngenerality, we demonstrate physical neural networks with three diverse physical\nsystems-optical, mechanical, and electrical. Physical neural networks may\nfacilitate unconventional machine learning hardware that is orders of magnitude\nfaster and more energy efficient than conventional electronic processors.\n", "versions": [{"version": "v1", "created": "Tue, 27 Apr 2021 18:00:02 GMT"}], "update_date": "2021-04-29", "authors_parsed": [["Wright", "Logan G.", ""], ["Onodera", "Tatsuhiro", ""], ["Stein", "Martin M.", ""], ["Wang", "Tianyu", ""], ["Schachter", "Darren T.", ""], ["Hu", "Zoey", ""], ["McMahon", "Peter L.", ""]]}, {"id": "2104.13398", "submitter": "Dominik Dold", "authors": "Dominik Dold, Josep Soler Garrido", "title": "SpikE: spike-based embeddings for multi-relational graph data", "comments": "Accepted for publication at IJCNN 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG q-bio.NC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Despite the recent success of reconciling spike-based coding with the error\nbackpropagation algorithm, spiking neural networks are still mostly applied to\ntasks stemming from sensory processing, operating on traditional data\nstructures like visual or auditory data. A rich data representation that finds\nwide application in industry and research is the so-called knowledge graph - a\ngraph-based structure where entities are depicted as nodes and relations\nbetween them as edges. Complex systems like molecules, social networks and\nindustrial factory systems can be described using the common language of\nknowledge graphs, allowing the usage of graph embedding algorithms to make\ncontext-aware predictions in these information-packed environments. We propose\na spike-based algorithm where nodes in a graph are represented by single spike\ntimes of neuron populations and relations as spike time differences between\npopulations. Learning such spike-based embeddings only requires knowledge about\nspike times and spike time differences, compatible with recently proposed\nframeworks for training spiking neural networks. The presented model is easily\nmapped to current neuromorphic hardware systems and thereby moves inference on\nknowledge graphs into a domain where these architectures thrive, unlocking a\npromising industrial application area for this technology.\n", "versions": [{"version": "v1", "created": "Tue, 27 Apr 2021 18:00:12 GMT"}, {"version": "v2", "created": "Mon, 17 May 2021 09:14:28 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Dold", "Dominik", ""], ["Garrido", "Josep Soler", ""]]}, {"id": "2104.13400", "submitter": "Babak Ehteshami Bejnordi", "authors": "Amir Ghodrati, Babak Ehteshami Bejnordi, Amirhossein Habibian", "title": "FrameExit: Conditional Early Exiting for Efficient Video Recognition", "comments": "CVPR 2021 | Oral paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we propose a conditional early exiting framework for efficient\nvideo recognition. While existing works focus on selecting a subset of salient\nframes to reduce the computation costs, we propose to use a simple sampling\nstrategy combined with conditional early exiting to enable efficient\nrecognition. Our model automatically learns to process fewer frames for simpler\nvideos and more frames for complex ones. To achieve this, we employ a cascade\nof gating modules to automatically determine the earliest point in processing\nwhere an inference is sufficiently reliable. We generate on-the-fly supervision\nsignals to the gates to provide a dynamic trade-off between accuracy and\ncomputational cost. Our proposed model outperforms competing methods on three\nlarge-scale video benchmarks. In particular, on ActivityNet1.3 and\nmini-kinetics, we outperform the state-of-the-art efficient video recognition\nmethods with 1.3$\\times$ and 2.1$\\times$ less GFLOPs, respectively.\nAdditionally, our method sets a new state of the art for efficient video\nunderstanding on the HVU benchmark.\n", "versions": [{"version": "v1", "created": "Tue, 27 Apr 2021 18:01:05 GMT"}], "update_date": "2021-04-29", "authors_parsed": [["Ghodrati", "Amir", ""], ["Bejnordi", "Babak Ehteshami", ""], ["Habibian", "Amirhossein", ""]]}, {"id": "2104.13414", "submitter": "Semin Kwak", "authors": "Semin Kwak, Nikolas Geroliminis, Pascal Frossard", "title": "Predicting traffic signals on transportation networks using\n  spatio-temporal correlations on graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Forecasting multivariate time series is challenging as the variables are\nintertwined in time and space, like in the case of traffic signals. Defining\nsignals on graphs relaxes such complexities by representing the evolution of\nsignals over a space using relevant graph kernels such as the heat diffusion\nkernel. However, this kernel alone does not fully capture the actual dynamics\nof the data as it only relies on the graph structure. The gap can be filled by\ncombining the graph kernel representation with data-driven models that utilize\nhistorical data. This paper proposes a traffic propagation model that merges\nmultiple heat diffusion kernels into a data-driven prediction model to forecast\ntraffic signals. We optimize the model parameters using Bayesian inference to\nminimize the prediction errors and, consequently, determine the mixing ratio of\nthe two approaches. Such mixing ratio strongly depends on training data size\nand data anomalies, which typically correspond to the peak hours for traffic\ndata. The proposed model demonstrates prediction accuracy comparable to that of\nthe state-of-the-art deep neural networks with lower computational effort. It\nparticularly shows excellent performance for long-term prediction since it\ninherits the data-driven models' periodicity modeling.\n", "versions": [{"version": "v1", "created": "Tue, 27 Apr 2021 18:17:42 GMT"}], "update_date": "2021-04-29", "authors_parsed": [["Kwak", "Semin", ""], ["Geroliminis", "Nikolas", ""], ["Frossard", "Pascal", ""]]}, {"id": "2104.13417", "submitter": "Weituo Hao", "authors": "Weituo Hao, Mostafa El-Khamy, Jungwon Lee, Jianyi Zhang, Kevin J\n  Liang, Changyou Chen, Lawrence Carin", "title": "Towards Fair Federated Learning with Zero-Shot Data Augmentation", "comments": "Accepted by IEEE CVPR Workshop on Fair, Data Efficient And Trusted\n  Computer Vision", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning has emerged as an important distributed learning paradigm,\nwhere a server aggregates a global model from many client-trained models while\nhaving no access to the client data. Although it is recognized that statistical\nheterogeneity of the client local data yields slower global model convergence,\nit is less commonly recognized that it also yields a biased federated global\nmodel with a high variance of accuracy across clients. In this work, we aim to\nprovide federated learning schemes with improved fairness. To tackle this\nchallenge, we propose a novel federated learning system that employs zero-shot\ndata augmentation on under-represented data to mitigate statistical\nheterogeneity and encourage more uniform accuracy performance across clients in\nfederated networks. We study two variants of this scheme, Fed-ZDAC (federated\nlearning with zero-shot data augmentation at the clients) and Fed-ZDAS\n(federated learning with zero-shot data augmentation at the server). Empirical\nresults on a suite of datasets demonstrate the effectiveness of our methods on\nsimultaneously improving the test accuracy and fairness.\n", "versions": [{"version": "v1", "created": "Tue, 27 Apr 2021 18:23:54 GMT"}], "update_date": "2021-04-29", "authors_parsed": [["Hao", "Weituo", ""], ["El-Khamy", "Mostafa", ""], ["Lee", "Jungwon", ""], ["Zhang", "Jianyi", ""], ["Liang", "Kevin J", ""], ["Chen", "Changyou", ""], ["Carin", "Lawrence", ""]]}, {"id": "2104.13424", "submitter": "Nemanja Rakicevic", "authors": "Nemanja Rakicevic, Antoine Cully, Petar Kormushev", "title": "Policy Manifold Search: Exploring the Manifold Hypothesis for\n  Diversity-based Neuroevolution", "comments": "Accepted as a full paper at Genetic and Evolutionary Computation\n  Conference, GECCO 2021. arXiv admin note: substantial text overlap with\n  arXiv:2012.08676", "journal-ref": null, "doi": "10.1145/3449639.3459320", "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neuroevolution is an alternative to gradient-based optimisation that has the\npotential to avoid local minima and allows parallelisation. The main limiting\nfactor is that usually it does not scale well with parameter space\ndimensionality. Inspired by recent work examining neural network intrinsic\ndimension and loss landscapes, we hypothesise that there exists a\nlow-dimensional manifold, embedded in the policy network parameter space,\naround which a high-density of diverse and useful policies are located. This\npaper proposes a novel method for diversity-based policy search via\nNeuroevolution, that leverages learned representations of the policy network\nparameters, by performing policy search in this learned representation space.\nOur method relies on the Quality-Diversity (QD) framework which provides a\nprincipled approach to policy search, and maintains a collection of diverse\npolicies, used as a dataset for learning policy representations. Further, we\nuse the Jacobian of the inverse-mapping function to guide the search in the\nrepresentation space. This ensures that the generated samples remain in the\nhigh-density regions, after mapping back to the original space. Finally, we\nevaluate our contributions on four continuous-control tasks in simulated\nenvironments, and compare to diversity-based baselines.\n", "versions": [{"version": "v1", "created": "Tue, 27 Apr 2021 18:52:03 GMT"}], "update_date": "2021-04-29", "authors_parsed": [["Rakicevic", "Nemanja", ""], ["Cully", "Antoine", ""], ["Kormushev", "Petar", ""]]}, {"id": "2104.13433", "submitter": "Siyuan Xiang", "authors": "Siyuan Xiang, Anbang Yang, Yanfei Xue, Yaoqing Yang, Chen Feng", "title": "Contrastive Spatial Reasoning on Multi-View Line Drawings", "comments": "The first two authors contributed equally. Chen Feng is the\n  corresponding author", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spatial reasoning on multi-view line drawings by state-of-the-art supervised\ndeep networks is recently shown with puzzling low performances on the SPARE3D\ndataset. To study the reason behind the low performance and to further our\nunderstandings of these tasks, we design controlled experiments on both input\ndata and network designs. Guided by the hindsight from these experiment\nresults, we propose a simple contrastive learning approach along with other\nnetwork modifications to improve the baseline performance. Our approach uses a\nself-supervised binary classification network to compare the line drawing\ndifferences between various views of any two similar 3D objects. It enables\ndeep networks to effectively learn detail-sensitive yet view-invariant line\ndrawing representations of 3D objects. Experiments show that our method could\nsignificantly increase the baseline performance in SPARE3D, while some popular\nself-supervised learning methods cannot.\n", "versions": [{"version": "v1", "created": "Tue, 27 Apr 2021 19:05:27 GMT"}], "update_date": "2021-04-29", "authors_parsed": [["Xiang", "Siyuan", ""], ["Yang", "Anbang", ""], ["Xue", "Yanfei", ""], ["Yang", "Yaoqing", ""], ["Feng", "Chen", ""]]}, {"id": "2104.13437", "submitter": "Murat Tulga\\c{c}", "authors": "Murat Tulga\\c{c}, Enes Y\\\"unc\\\"u, Mohamad-Alhaddad and Ceylan\n  Yozgatl{\\i}gil", "title": "Incident Detection on Junctions Using Image Processing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  In traffic management, it is a very important issue to shorten the response\ntime by detecting the incidents (accident, vehicle breakdown, an object falling\non the road, etc.) and informing the corresponding personnel. In this study, an\nanomaly detection framework for road junctions is proposed. The final judgment\nis based on the trajectories followed by the vehicles. Trajectory information\nis provided by vehicle detection and tracking algorithms on visual data\nstreamed from a fisheye camera. Deep learning algorithms are used for vehicle\ndetection, and Kalman Filter is used for tracking. To observe the trajectories\nmore accurately, the detected vehicle coordinates are transferred to the bird's\neye view coordinates using the lens distortion model prediction algorithm. The\nsystem determines whether there is an abnormality in trajectories by comparing\nhistorical trajectory data and instantaneous incoming data. The proposed system\nhas achieved 84.6% success in vehicle detection and 96.8% success in\nabnormality detection on synthetic data. The system also works with a 97.3%\nsuccess rate in detecting abnormalities on real data.\n", "versions": [{"version": "v1", "created": "Tue, 27 Apr 2021 19:18:05 GMT"}], "update_date": "2021-04-29", "authors_parsed": [["Tulga\u00e7", "Murat", ""], ["Y\u00fcnc\u00fc", "Enes", ""], ["Mohamad-Alhaddad", "", ""], ["Yozgatl\u0131gil", "Ceylan", ""]]}, {"id": "2104.13446", "submitter": "Bozhidar Vasilev", "authors": "Bozhidar Vasilev, Tarun Gupta, Bei Peng, Shimon Whiteson", "title": "Semi-On-Policy Training for Sample Efficient Multi-Agent Policy\n  Gradients", "comments": "AAMAS Adaptive and Learning Agents Workshop. 20th International\n  Conference on Autonomous Agents and Multiagent Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.MA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Policy gradient methods are an attractive approach to multi-agent\nreinforcement learning problems due to their convergence properties and\nrobustness in partially observable scenarios. However, there is a significant\nperformance gap between state-of-the-art policy gradient and value-based\nmethods on the popular StarCraft Multi-Agent Challenge (SMAC) benchmark. In\nthis paper, we introduce semi-on-policy (SOP) training as an effective and\ncomputationally efficient way to address the sample inefficiency of on-policy\npolicy gradient methods. We enhance two state-of-the-art policy gradient\nalgorithms with SOP training, demonstrating significant performance\nimprovements. Furthermore, we show that our methods perform as well or better\nthan state-of-the-art value-based methods on a variety of SMAC tasks.\n", "versions": [{"version": "v1", "created": "Tue, 27 Apr 2021 19:37:01 GMT"}, {"version": "v2", "created": "Thu, 6 May 2021 15:25:59 GMT"}], "update_date": "2021-05-07", "authors_parsed": [["Vasilev", "Bozhidar", ""], ["Gupta", "Tarun", ""], ["Peng", "Bei", ""], ["Whiteson", "Shimon", ""]]}, {"id": "2104.13449", "submitter": "Elvis Nunez", "authors": "Elvis Nunez, Andrew Lizarraga, and Shantanu H. Joshi", "title": "SrvfNet: A Generative Network for Unsupervised Multiple Diffeomorphic\n  Shape Alignment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG math.DG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  We present SrvfNet, a generative deep learning framework for the joint\nmultiple alignment of large collections of functional data comprising\nsquare-root velocity functions (SRVF) to their templates. Our proposed\nframework is fully unsupervised and is capable of aligning to a predefined\ntemplate as well as jointly predicting an optimal template from data while\nsimultaneously achieving alignment. Our network is constructed as a generative\nencoder-decoder architecture comprising fully-connected layers capable of\nproducing a distribution space of the warping functions. We demonstrate the\nstrength of our framework by validating it on synthetic data as well as\ndiffusion profiles from magnetic resonance imaging (MRI) data.\n", "versions": [{"version": "v1", "created": "Tue, 27 Apr 2021 19:49:46 GMT"}], "update_date": "2021-04-29", "authors_parsed": [["Nunez", "Elvis", ""], ["Lizarraga", "Andrew", ""], ["Joshi", "Shantanu H.", ""]]}, {"id": "2104.13450", "submitter": "Innfarn Yoo", "authors": "Innfarn Yoo and Huiwen Chang and Xiyang Luo and Ondrej Stava and Ce\n  Liu and Peyman Milanfar and Feng Yang", "title": "Deep 3D-to-2D Watermarking: Embedding Messages in 3D Meshes and\n  Extracting Them from 2D Renderings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR cs.LG eess.IV", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Digital watermarking is widely used for copyright protection. Traditional 3D\nwatermarking approaches or commercial software are typically designed to embed\nmessages into 3D meshes, and later retrieve the messages directly from\ndistorted/undistorted watermarked 3D meshes. Retrieving messages from 2D\nrenderings of such meshes, however, is still challenging and underexplored. We\nintroduce a novel end-to-end learning framework to solve this problem through:\n1) an encoder to covertly embed messages in both mesh geometry and textures; 2)\na differentiable renderer to render watermarked 3D objects from different\ncamera angles and under varied lighting conditions; 3) a decoder to recover the\nmessages from 2D rendered images. From extensive experiments, we show that our\nmodels learn to embed information visually imperceptible to humans, and to\nreconstruct the embedded information from 2D renderings robust to 3D\ndistortions. In addition, we demonstrate that our method can be generalized to\nwork with different renderers, such as ray tracers and real-time renderers.\n", "versions": [{"version": "v1", "created": "Tue, 27 Apr 2021 19:51:39 GMT"}, {"version": "v2", "created": "Thu, 29 Apr 2021 05:37:55 GMT"}], "update_date": "2021-04-30", "authors_parsed": [["Yoo", "Innfarn", ""], ["Chang", "Huiwen", ""], ["Luo", "Xiyang", ""], ["Stava", "Ondrej", ""], ["Liu", "Ce", ""], ["Milanfar", "Peyman", ""], ["Yang", "Feng", ""]]}, {"id": "2104.13453", "submitter": "Zeyang Liu", "authors": "Zeyang Liu, Ke Zhou and Max L. Wilson", "title": "Meta-evaluation of Conversational Search Evaluation Metrics", "comments": "43 pages", "journal-ref": null, "doi": "10.1145/3445029", "report-no": null, "categories": "cs.IR cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conversational search systems, such as Google Assistant and Microsoft\nCortana, enable users to interact with search systems in multiple rounds\nthrough natural language dialogues. Evaluating such systems is very challenging\ngiven that any natural language responses could be generated, and users\ncommonly interact for multiple semantically coherent rounds to accomplish a\nsearch task. Although prior studies proposed many evaluation metrics, the\nextent of how those measures effectively capture user preference remains to be\ninvestigated. In this paper, we systematically meta-evaluate a variety of\nconversational search metrics. We specifically study three perspectives on\nthose metrics: (1) reliability: the ability to detect \"actual\" performance\ndifferences as opposed to those observed by chance; (2) fidelity: the ability\nto agree with ultimate user preference; and (3) intuitiveness: the ability to\ncapture any property deemed important: adequacy, informativeness, and fluency\nin the context of conversational search. By conducting experiments on two test\ncollections, we find that the performance of different metrics varies\nsignificantly across different scenarios whereas consistent with prior studies,\nexisting metrics only achieve a weak correlation with ultimate user preference\nand satisfaction. METEOR is, comparatively speaking, the best existing\nsingle-turn metric considering all three perspectives. We also demonstrate that\nadapted session-based evaluation metrics can be used to measure multi-turn\nconversational search, achieving moderate concordance with user satisfaction.\nTo our knowledge, our work establishes the most comprehensive meta-evaluation\nfor conversational search to date.\n", "versions": [{"version": "v1", "created": "Tue, 27 Apr 2021 20:01:03 GMT"}], "update_date": "2021-04-29", "authors_parsed": [["Liu", "Zeyang", ""], ["Zhou", "Ke", ""], ["Wilson", "Max L.", ""]]}, {"id": "2104.13458", "submitter": "Salvatore Scognamiglio Dr.", "authors": "Vali Asimit, Ioannis Kyriakou, Simone Santoni, Salvatore Scognamiglio\n  and Rui Zhu", "title": "Robust Classification via Support Vector Machines", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  The loss function choice for any Support Vector Machine classifier has raised\ngreat interest in the literature due to the lack of robustness of the Hinge\nloss, which is the standard loss choice. In this paper, we plan to robustify\nthe binary classifier by maintaining the overall advantages of the Hinge loss,\nrather than modifying this standard choice. We propose two robust classifiers\nunder data uncertainty. The first is called Single Perturbation SVM (SP-SVM)\nand provides a constructive method by allowing a controlled perturbation to one\nfeature of the data. The second method is called Extreme Empirical Loss SVM\n(EEL-SVM) and is based on a new empirical loss estimate, namely, the Extreme\nEmpirical Loss (EEL), that puts more emphasis on extreme violations of the\nclassification hyper-plane, rather than taking the usual sample average with\nequal importance for all hyper-plane violations. Extensive numerical\ninvestigation reveals the advantages of the two robust classifiers on simulated\ndata and well-known real datasets.\n", "versions": [{"version": "v1", "created": "Tue, 27 Apr 2021 20:20:12 GMT"}], "update_date": "2021-04-29", "authors_parsed": [["Asimit", "Vali", ""], ["Kyriakou", "Ioannis", ""], ["Santoni", "Simone", ""], ["Scognamiglio", "Salvatore", ""], ["Zhu", "Rui", ""]]}, {"id": "2104.13467", "submitter": "Tianyu Wang", "authors": "Tianyu Wang, Shi-Yuan Ma, Logan G. Wright, Tatsuhiro Onodera, Brian\n  Richard and Peter L. McMahon", "title": "An optical neural network using less than 1 photon per multiplication", "comments": "42 pages, 21 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.optics cs.ET cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning has rapidly become a widespread tool in both scientific and\ncommercial endeavors. Milestones of deep learning exceeding human performance\nhave been achieved for a growing number of tasks over the past several years,\nacross areas as diverse as game-playing, natural-language translation, and\nmedical-image analysis. However, continued progress is increasingly hampered by\nthe high energy costs associated with training and running deep neural networks\non electronic processors. Optical neural networks have attracted attention as\nan alternative physical platform for deep learning, as it has been\ntheoretically predicted that they can fundamentally achieve higher energy\nefficiency than neural networks deployed on conventional digital computers.\nHere, we experimentally demonstrate an optical neural network achieving 99%\naccuracy on handwritten-digit classification using ~3.2 detected photons per\nweight multiplication and ~90% accuracy using ~0.64 photons (~$2.4 \\times\n10^{-19}$ J of optical energy) per weight multiplication. This performance was\nachieved using a custom free-space optical processor that executes\nmatrix-vector multiplications in a massively parallel fashion, with up to ~0.5\nmillion scalar (weight) multiplications performed at the same time. Using\ncommercially available optical components and standard neural-network training\nmethods, we demonstrated that optical neural networks can operate near the\nstandard quantum limit with extremely low optical powers and still achieve high\naccuracy. Our results provide a proof-of-principle for low-optical-power\noperation, and with careful system design including the surrounding electronics\nused for data storage and control, open up a path to realizing optical\nprocessors that require only $10^{-16}$ J total energy per scalar\nmultiplication -- which is orders of magnitude more efficient than current\ndigital processors.\n", "versions": [{"version": "v1", "created": "Tue, 27 Apr 2021 20:43:23 GMT"}], "update_date": "2021-04-29", "authors_parsed": [["Wang", "Tianyu", ""], ["Ma", "Shi-Yuan", ""], ["Wright", "Logan G.", ""], ["Onodera", "Tatsuhiro", ""], ["Richard", "Brian", ""], ["McMahon", "Peter L.", ""]]}, {"id": "2104.13468", "submitter": "Aviv Keren", "authors": "Aviv Keren", "title": "The Role of General Intelligence in Mathematical Reasoning", "comments": null, "journal-ref": "1st Mathematical Reasoning in General Artificial Intelligence\n  Workshop, ICLR 2021", "doi": null, "report-no": null, "categories": "cs.AI cs.LG math.HO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Objects are a centerpiece of the mathematical realm and our interaction with\nand reasoning about it, just as they are of the physical one (if not more). And\nhumans' mathematical reasoning must ultimately be grounded in our general\nintelligence. Yet in contemporary cognitive science and A.I., the physical and\nmathematical domains are customarily explored separately, which allows for\nbaking in assumptions for what objects are for the system - and missing\npotential connections.\n  In this paper, I put the issue into its philosophical and cognitive context.\nI then describe an abstract theoretical framework for learning object\nrepresentations, that makes room for mathematical objects on par with\nnon-mathematical ones. Finally, I describe a case study that builds on that\nview to show how our general ability for integrating different aspects of\nobjects effects our conception of the natural numbers.\n", "versions": [{"version": "v1", "created": "Tue, 27 Apr 2021 20:43:25 GMT"}], "update_date": "2021-04-29", "authors_parsed": [["Keren", "Aviv", ""]]}, {"id": "2104.13471", "submitter": "Georgios D. Barmparis", "authors": "G. D. Barmparis and G. P. Tsironis", "title": "Discovering nonlinear resonances through physics-informed machine\n  learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.comp-ph cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For an ensemble of nonlinear systems that model, for instance, molecules or\nphotonic systems, we propose a method that finds efficiently the configuration\nthat has prescribed transfer properties. Specifically, we use physics-informed\nmachine-learning (PIML) techniques to find the parameters for the efficient\ntransfer of an electron (or photon) to a targeted state in a non-linear dimer.\nWe create a machine learning model containing two variables, $\\chi_D$, and\n$\\chi_A$, representing the non-linear terms in the donor and acceptor target\nsystem states. We then introduce a data-free physics-informed loss function as\n$1.0 - P_j$, where $P_j$ is the probability, the electron being in the targeted\nstate, $j$. By minimizing the loss function, we maximize the occupation\nprobability to the targeted state. The method recovers known results in the\nTargeted Energy Transfer (TET) model, and it is then applied to a more complex\nsystem with an additional intermediate state. In this trimer configuration, the\nPIML approach discovers desired resonant paths from the donor to acceptor\nunits. The proposed PIML method is general and may be used in the chemical\ndesign of molecular complexes or engineering design of quantum or photonic\nsystems.\n", "versions": [{"version": "v1", "created": "Tue, 27 Apr 2021 20:53:40 GMT"}, {"version": "v2", "created": "Mon, 26 Jul 2021 08:18:10 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Barmparis", "G. D.", ""], ["Tsironis", "G. P.", ""]]}, {"id": "2104.13478", "submitter": "Petar Veli\\v{c}kovi\\'c", "authors": "Michael M. Bronstein, Joan Bruna, Taco Cohen, Petar Veli\\v{c}kovi\\'c", "title": "Geometric Deep Learning: Grids, Groups, Graphs, Geodesics, and Gauges", "comments": "156 pages. Work in progress -- comments welcome!", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The last decade has witnessed an experimental revolution in data science and\nmachine learning, epitomised by deep learning methods. Indeed, many\nhigh-dimensional learning tasks previously thought to be beyond reach -- such\nas computer vision, playing Go, or protein folding -- are in fact feasible with\nappropriate computational scale. Remarkably, the essence of deep learning is\nbuilt from two simple algorithmic principles: first, the notion of\nrepresentation or feature learning, whereby adapted, often hierarchical,\nfeatures capture the appropriate notion of regularity for each task, and\nsecond, learning by local gradient-descent type methods, typically implemented\nas backpropagation.\n  While learning generic functions in high dimensions is a cursed estimation\nproblem, most tasks of interest are not generic, and come with essential\npre-defined regularities arising from the underlying low-dimensionality and\nstructure of the physical world. This text is concerned with exposing these\nregularities through unified geometric principles that can be applied\nthroughout a wide spectrum of applications.\n  Such a 'geometric unification' endeavour, in the spirit of Felix Klein's\nErlangen Program, serves a dual purpose: on one hand, it provides a common\nmathematical framework to study the most successful neural network\narchitectures, such as CNNs, RNNs, GNNs, and Transformers. On the other hand,\nit gives a constructive procedure to incorporate prior physical knowledge into\nneural architectures and provide principled way to build future architectures\nyet to be invented.\n", "versions": [{"version": "v1", "created": "Tue, 27 Apr 2021 21:09:51 GMT"}, {"version": "v2", "created": "Sun, 2 May 2021 16:16:03 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Bronstein", "Michael M.", ""], ["Bruna", "Joan", ""], ["Cohen", "Taco", ""], ["Veli\u010dkovi\u0107", "Petar", ""]]}, {"id": "2104.13479", "submitter": "Prachi Loliencar", "authors": "Prachi Loliencar and Giseon Heo", "title": "Phenotyping OSA: a time series analysis using fuzzy clustering and\n  persistent homology", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sleep apnea is a disorder that has serious consequences for the pediatric\npopulation. There has been recent concern that traditional diagnosis of the\ndisorder using the apnea-hypopnea index may be ineffective in capturing its\nmulti-faceted outcomes. In this work, we take a first step in addressing this\nissue by phenotyping patients using a clustering analysis of airflow time\nseries. This is approached in three ways: using feature-based fuzzy clustering\nin the time and frequency domains, and using persistent homology to study the\nsignal from a topological perspective. The fuzzy clusters are analyzed in a\nnovel manner using a Dirichlet regression analysis, while the topological\napproach leverages Takens embedding theorem to study the periodicity properties\nof the signals.\n", "versions": [{"version": "v1", "created": "Tue, 27 Apr 2021 21:12:30 GMT"}], "update_date": "2021-04-29", "authors_parsed": [["Loliencar", "Prachi", ""], ["Heo", "Giseon", ""]]}, {"id": "2104.13484", "submitter": "Mahmoud Hossam", "authors": "Mahmoud Hossam, Trung Le, He Zhao, Viet Huynh, Dinh Phung", "title": "Improved and Efficient Text Adversarial Attacks using Target Information", "comments": "Accepted in the International Conference on Learning Representations\n  (ICLR) workshop on Robust and Reliable Machine Learning in the Real World\n  (RobustML)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There has been recently a growing interest in studying adversarial examples\non natural language models in the black-box setting. These methods attack\nnatural language classifiers by perturbing certain important words until the\nclassifier label is changed. In order to find these important words, these\nmethods rank all words by importance by querying the target model word by word\nfor each input sentence, resulting in high query inefficiency. A new\ninteresting approach was introduced that addresses this problem through\ninterpretable learning to learn the word ranking instead of previous expensive\nsearch. The main advantage of using this approach is that it achieves\ncomparable attack rates to the state-of-the-art methods, yet faster and with\nfewer queries, where fewer queries are desirable to avoid suspicion towards the\nattacking agent. Nonetheless, this approach sacrificed the useful information\nthat could be leveraged from the target classifier for that sake of query\nefficiency. In this paper we study the effect of leveraging the target model\noutputs and data on both attack rates and average number of queries, and we\nshow that both can be improved, with a limited overhead of additional queries.\n", "versions": [{"version": "v1", "created": "Tue, 27 Apr 2021 21:25:55 GMT"}, {"version": "v2", "created": "Sun, 2 May 2021 08:49:09 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Hossam", "Mahmoud", ""], ["Le", "Trung", ""], ["Zhao", "He", ""], ["Huynh", "Viet", ""], ["Phung", "Dinh", ""]]}, {"id": "2104.13488", "submitter": "Mahmoud Hossam", "authors": "Mahmoud Hossam, Trung Le, Michael Papasimeon, Viet Huynh, Dinh Phung", "title": "Text Generation with Deep Variational GAN", "comments": "Accepted in the Third Workshop on Bayesian Deep Learning (NIPS /\n  NeurIPS 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generating realistic sequences is a central task in many machine learning\napplications. There has been considerable recent progress on building deep\ngenerative models for sequence generation tasks. However, the issue of\nmode-collapsing remains a main issue for the current models. In this paper we\npropose a GAN-based generic framework to address the problem of mode-collapse\nin a principled approach. We change the standard GAN objective to maximize a\nvariational lower-bound of the log-likelihood while minimizing the\nJensen-Shanon divergence between data and model distributions. We experiment\nour model with text generation task and show that it can generate realistic\ntext with high diversity.\n", "versions": [{"version": "v1", "created": "Tue, 27 Apr 2021 21:42:13 GMT"}], "update_date": "2021-04-29", "authors_parsed": [["Hossam", "Mahmoud", ""], ["Le", "Trung", ""], ["Papasimeon", "Michael", ""], ["Huynh", "Viet", ""], ["Phung", "Dinh", ""]]}, {"id": "2104.13492", "submitter": "John Shin", "authors": "John Y. Shin, Prathamesh Dharangutte", "title": "An Energy-Based View of Graph Neural Networks", "comments": "Accepted to the ICLR2021 EBM Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph neural networks are a popular variant of neural networks that work with\ngraph-structured data. In this work, we consider combining graph neural\nnetworks with the energy-based view of Grathwohl et al. (2019) with the aim of\nobtaining a more robust classifier. We successfully implement this framework by\nproposing a novel method to ensure generation over features as well as the\nadjacency matrix and evaluate our method against the standard graph\nconvolutional network (GCN) architecture (Kipf & Welling (2016)). Our approach\nobtains comparable discriminative performance while improving robustness,\nopening promising new directions for future research for energy-based graph\nneural networks.\n", "versions": [{"version": "v1", "created": "Tue, 27 Apr 2021 21:54:30 GMT"}], "update_date": "2021-04-29", "authors_parsed": [["Shin", "John Y.", ""], ["Dharangutte", "Prathamesh", ""]]}, {"id": "2104.13498", "submitter": "Han-Chin Shing", "authors": "Han-Chin Shing, Chaitanya Shivade, Nima Pourdamghani, Feng Nan, Philip\n  Resnik, Douglas Oard and Parminder Bhatia", "title": "Towards Clinical Encounter Summarization: Learning to Compose Discharge\n  Summaries from Prior Notes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The records of a clinical encounter can be extensive and complex, thus\nplacing a premium on tools that can extract and summarize relevant information.\nThis paper introduces the task of generating discharge summaries for a clinical\nencounter. Summaries in this setting need to be faithful, traceable, and scale\nto multiple long documents, motivating the use of extract-then-abstract\nsummarization cascades. We introduce two new measures, faithfulness and\nhallucination rate for evaluation in this task, which complement existing\nmeasures for fluency and informativeness. Results across seven medical sections\nand five models show that a summarization architecture that supports\ntraceability yields promising results, and that a sentence-rewriting approach\nperforms consistently on the measure used for faithfulness\n(faithfulness-adjusted $F_3$) over a diverse range of generated sections.\n", "versions": [{"version": "v1", "created": "Tue, 27 Apr 2021 22:45:54 GMT"}], "update_date": "2021-04-29", "authors_parsed": [["Shing", "Han-Chin", ""], ["Shivade", "Chaitanya", ""], ["Pourdamghani", "Nima", ""], ["Nan", "Feng", ""], ["Resnik", "Philip", ""], ["Oard", "Douglas", ""], ["Bhatia", "Parminder", ""]]}, {"id": "2104.13504", "submitter": "Kevin Kim", "authors": "Kevin Kim and Alex Gittens", "title": "Learning Fair Canonical Polyadical Decompositions using a Kernel\n  Independence Criterion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work proposes to learn fair low-rank tensor decompositions by\nregularizing the Canonical Polyadic Decomposition factorization with the kernel\nHilbert-Schmidt independence criterion (KHSIC). It is shown, theoretically and\nempirically, that a small KHSIC between a latent factor and the sensitive\nfeatures guarantees approximate statistical parity. The proposed algorithm\nsurpasses the state-of-the-art algorithm, FATR (Zhu et al., 2018), in\ncontrolling the trade-off between fairness and residual fit on synthetic and\nreal data sets.\n", "versions": [{"version": "v1", "created": "Tue, 27 Apr 2021 23:16:10 GMT"}], "update_date": "2021-04-29", "authors_parsed": [["Kim", "Kevin", ""], ["Gittens", "Alex", ""]]}, {"id": "2104.13517", "submitter": "Ji Oon Lee", "authors": "Ji Hyung Jung, Hye Won Chung, Ji Oon Lee", "title": "Detection of Signal in the Spiked Rectangular Models", "comments": "38 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG math.PR stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of detecting signals in the rank-one\nsignal-plus-noise data matrix models that generalize the spiked Wishart\nmatrices. We show that the principal component analysis can be improved by\npre-transforming the matrix entries if the noise is non-Gaussian. As an\nintermediate step, we prove a sharp phase transition of the largest eigenvalues\nof spiked rectangular matrices, which extends the Baik-Ben Arous-P\\'ech\\'e\n(BBP) transition. We also propose a hypothesis test to detect the presence of\nsignal with low computational complexity, based on the linear spectral\nstatistics, which minimizes the sum of the Type-I and Type-II errors when the\nnoise is Gaussian.\n", "versions": [{"version": "v1", "created": "Wed, 28 Apr 2021 01:15:45 GMT"}], "update_date": "2021-04-29", "authors_parsed": [["Jung", "Ji Hyung", ""], ["Chung", "Hye Won", ""], ["Lee", "Ji Oon", ""]]}, {"id": "2104.13553", "submitter": "Woosung Choi", "authors": "Woosung Choi, Minseok Kim, Marco A. Mart\\'inez Ram\\'irez, Jaehwa\n  Chung, Soonyoung Jung", "title": "AMSS-Net: Audio Manipulation on User-Specified Sources with Textual\n  Queries", "comments": "10 pages, 8 figures, 3 tables, under reviewing of ACMMM 21", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a neural network that performs audio transformations to\nuser-specified sources (e.g., vocals) of a given audio track according to a\ngiven description while preserving other sources not mentioned in the\ndescription. Audio Manipulation on a Specific Source (AMSS) is challenging\nbecause a sound object (i.e., a waveform sample or frequency bin) is\n`transparent'; it usually carries information from multiple sources, in\ncontrast to a pixel in an image. To address this challenging problem, we\npropose AMSS-Net, which extracts latent sources and selectively manipulates\nthem while preserving irrelevant sources. We also propose an evaluation\nbenchmark for several AMSS tasks, and we show that AMSS-Net outperforms\nbaselines on several AMSS tasks via objective metrics and empirical\nverification.\n", "versions": [{"version": "v1", "created": "Wed, 28 Apr 2021 03:27:01 GMT"}], "update_date": "2021-04-29", "authors_parsed": [["Choi", "Woosung", ""], ["Kim", "Minseok", ""], ["Ram\u00edrez", "Marco A. Mart\u00ednez", ""], ["Chung", "Jaehwa", ""], ["Jung", "Soonyoung", ""]]}, {"id": "2104.13557", "submitter": "Shiba Kuanar", "authors": "Shiba Kuanar, Vassilis Athitsos, Dwarikanath Mahapatra, Anand Rajan", "title": "Multi-scale Deep Learning Architecture for Nucleus Detection in Renal\n  Cell Carcinoma Microscopy Image", "comments": "This article has been removed by arXiv administrators because the\n  submitter did not have the authority to grant the license applied at the time\n  of submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clear cell renal cell carcinoma (ccRCC) is one of the most common forms of\nintratumoral heterogeneity in the study of renal cancer. ccRCC originates from\nthe epithelial lining of proximal convoluted renal tubules. These cells undergo\nabnormal mutations in the presence of Ki67 protein and create a lump-like\nstructure through cell proliferation. Manual counting of tumor cells in the\ntissue-affected sections is one of the strongest prognostic markers for renal\ncancer. However, this procedure is time-consuming and also prone to\nsubjectivity. These assessments are based on the physical cell appearance and\nsuffer wide intra-observer variations. Therefore, better cell nucleus detection\nand counting techniques can be an important biomarker for the assessment of\ntumor cell proliferation in routine pathological investigations. In this paper,\nwe introduce a deep learning-based detection model for cell classification on\nIHC stained histology images. These images are classified into binary classes\nto find the presence of Ki67 protein in cancer-affected nucleus regions. Our\nmodel maps the multi-scale pyramid features and saliency information from local\nbounded regions and predicts the bounding box coordinates through regression.\nOur method validates the impact of Ki67 expression across a cohort of four\nhundred histology images treated with localized ccRCC and compares our results\nwith the existing state-of-the-art nucleus detection methods. The precision and\nrecall scores of the proposed method are computed and compared on the clinical\ndata sets. The experimental results demonstrate that our model improves the F1\nscore up to 86.3% and an average area under the Precision-Recall curve as\n85.73%.\n", "versions": [{"version": "v1", "created": "Wed, 28 Apr 2021 03:36:02 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Kuanar", "Shiba", ""], ["Athitsos", "Vassilis", ""], ["Mahapatra", "Dwarikanath", ""], ["Rajan", "Anand", ""]]}, {"id": "2104.13561", "submitter": "Byung Cheol Song", "authors": "Seunghyun Lee, Byung Cheol Song", "title": "Interpretable Embedding Procedure Knowledge Transfer via Stacked\n  Principal Component Analysis and Graph Neural Network", "comments": "accepted at AAAI2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge distillation (KD) is one of the most useful techniques for\nlight-weight neural networks. Although neural networks have a clear purpose of\nembedding datasets into the low-dimensional space, the existing knowledge was\nquite far from this purpose and provided only limited information. We argue\nthat good knowledge should be able to interpret the embedding procedure. This\npaper proposes a method of generating interpretable embedding procedure (IEP)\nknowledge based on principal component analysis, and distilling it based on a\nmessage passing neural network. Experimental results show that the student\nnetwork trained by the proposed KD method improves 2.28% in the CIFAR100\ndataset, which is higher performance than the state-of-the-art (SOTA) method.\nWe also demonstrate that the embedding procedure knowledge is interpretable via\nvisualization of the proposed KD process. The implemented code is available at\nhttps://github.com/sseung0703/IEPKT.\n", "versions": [{"version": "v1", "created": "Wed, 28 Apr 2021 03:40:37 GMT"}], "update_date": "2021-04-29", "authors_parsed": [["Lee", "Seunghyun", ""], ["Song", "Byung Cheol", ""]]}, {"id": "2104.13581", "submitter": "Mohammad Mahfujur Rahman", "authors": "Mohammad Mahfujur Rahman, Clinton Fookes, Sridha Sridharan", "title": "Deep Domain Generalization with Feature-norm Network", "comments": "Submitted to Pattern Recognition", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  In this paper, we tackle the problem of training with multiple source domains\nwith the aim to generalize to new domains at test time without an adaptation\nstep. This is known as domain generalization (DG). Previous works on DG assume\nidentical categories or label space across the source domains. In the case of\ncategory shift among the source domains, previous methods on DG are vulnerable\nto negative transfer due to the large mismatch among label spaces, decreasing\nthe target classification accuracy. To tackle the aforementioned problem, we\nintroduce an end-to-end feature-norm network (FNN) which is robust to negative\ntransfer as it does not need to match the feature distribution among the source\ndomains. We also introduce a collaborative feature-norm network (CFNN) to\nfurther improve the generalization capability of FNN. The CFNN matches the\npredictions of the next most likely categories for each training sample which\nincreases each network's posterior entropy. We apply the proposed FNN and CFNN\nnetworks to the problem of DG for image classification tasks and demonstrate\nsignificant improvement over the state-of-the-art.\n", "versions": [{"version": "v1", "created": "Wed, 28 Apr 2021 06:13:47 GMT"}], "update_date": "2021-04-29", "authors_parsed": [["Rahman", "Mohammad Mahfujur", ""], ["Fookes", "Clinton", ""], ["Sridharan", "Sridha", ""]]}, {"id": "2104.13614", "submitter": "Changhong Zhong", "authors": "Zhuoyun Li, Changhong Zhong, Sijia Liu, Ruixuan Wang, and Wei-Shi\n  Zheng", "title": "Preserving Earlier Knowledge in Continual Learning with the Help of All\n  Previous Feature Extractors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Continual learning of new knowledge over time is one desirable capability for\nintelligent systems to recognize more and more classes of objects. Without or\nwith very limited amount of old data stored, an intelligent system often\ncatastrophically forgets previously learned old knowledge when learning new\nknowledge. Recently, various approaches have been proposed to alleviate the\ncatastrophic forgetting issue. However, old knowledge learned earlier is\ncommonly less preserved than that learned more recently. In order to reduce the\nforgetting of particularly earlier learned old knowledge and improve the\noverall continual learning performance, we propose a simple yet effective\nfusion mechanism by including all the previously learned feature extractors\ninto the intelligent model. In addition, a new feature extractor is included to\nthe model when learning a new set of classes each time, and a feature extractor\npruning is also applied to prevent the whole model size from growing rapidly.\nExperiments on multiple classification tasks show that the proposed approach\ncan effectively reduce the forgetting of old knowledge, achieving\nstate-of-the-art continual learning performance.\n", "versions": [{"version": "v1", "created": "Wed, 28 Apr 2021 07:49:24 GMT"}], "update_date": "2021-04-29", "authors_parsed": [["Li", "Zhuoyun", ""], ["Zhong", "Changhong", ""], ["Liu", "Sijia", ""], ["Wang", "Ruixuan", ""], ["Zheng", "Wei-Shi", ""]]}, {"id": "2104.13615", "submitter": "Minjin Choi", "authors": "Minjin Choi, Sunkyung Lee, Eunseong Choi, Heesoo Park, Junhyuk Lee,\n  Dongwon Lee, and Jongwuk Lee", "title": "MelBERT: Metaphor Detection via Contextualized Late Interaction using\n  Metaphorical Identification Theories", "comments": "In Proceedings of 2021 Annual Conference of the North American\n  Chapter of the Association for Computational Linguistics. 11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automated metaphor detection is a challenging task to identify metaphorical\nexpressions of words in a sentence. To tackle this problem, we adopt\npre-trained contextualized models, e.g., BERT and RoBERTa. To this end, we\npropose a novel metaphor detection model, namely metaphor-aware late\ninteraction over BERT (MelBERT). Our model not only leverages contextualized\nword representation but also benefits from linguistic metaphor identification\ntheories to distinguish between the contextual and literal meaning of words.\nOur empirical results demonstrate that MelBERT outperforms several strong\nbaselines on four benchmark datasets, i.e., VUA-18, VUA-20, MOH-X, and TroFi.\n", "versions": [{"version": "v1", "created": "Wed, 28 Apr 2021 07:52:01 GMT"}], "update_date": "2021-04-29", "authors_parsed": [["Choi", "Minjin", ""], ["Lee", "Sunkyung", ""], ["Choi", "Eunseong", ""], ["Park", "Heesoo", ""], ["Lee", "Junhyuk", ""], ["Lee", "Dongwon", ""], ["Lee", "Jongwuk", ""]]}, {"id": "2104.13617", "submitter": "Alessandro Paolo Capasso", "authors": "Alessandro Paolo Capasso, Paolo Maramotti, Anthony Dell'Eva, Alberto\n  Broggi", "title": "End-to-End Intersection Handling using Multi-Agent Deep Reinforcement\n  Learning", "comments": "IEEE Intelligent Vehicle 2021 (IV 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Navigating through intersections is one of the main challenging tasks for an\nautonomous vehicle. However, for the majority of intersections regulated by\ntraffic lights, the problem could be solved by a simple rule-based method in\nwhich the autonomous vehicle behavior is closely related to the traffic light\nstates. In this work, we focus on the implementation of a system able to\nnavigate through intersections where only traffic signs are provided. We\npropose a multi-agent system using a continuous, model-free Deep Reinforcement\nLearning algorithm used to train a neural network for predicting both the\nacceleration and the steering angle at each time step. We demonstrate that\nagents learn both the basic rules needed to handle intersections by\nunderstanding the priorities of other learners inside the environment, and to\ndrive safely along their paths. Moreover, a comparison between our system and a\nrule-based method proves that our model achieves better results especially with\ndense traffic conditions. Finally, we test our system on real world scenarios\nusing real recorded traffic data, proving that our module is able to generalize\nboth to unseen environments and to different traffic conditions.\n", "versions": [{"version": "v1", "created": "Wed, 28 Apr 2021 07:54:40 GMT"}, {"version": "v2", "created": "Sat, 1 May 2021 07:17:36 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Capasso", "Alessandro Paolo", ""], ["Maramotti", "Paolo", ""], ["Dell'Eva", "Anthony", ""], ["Broggi", "Alberto", ""]]}, {"id": "2104.13619", "submitter": "Gergely Hajgat\\'o", "authors": "Gergely Hajgat\\'o and B\\'alint Gyires-T\\'oth and Gy\\\"orgy Pa\\'al", "title": "Reconstructing nodal pressures in water distribution systems with graph\n  neural networks", "comments": "11 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowing the pressure at all times in each node of a water distribution system\n(WDS) facilitates safe and efficient operation. Yet, complete measurement data\ncannot be collected due to the limited number of instruments in a real-life\nWDS. The data-driven methodology of reconstructing all the nodal pressures by\nobserving only a limited number of nodes is presented in the paper. The\nreconstruction method is based on K-localized spectral graph filters, wherewith\ngraph convolution on water networks is possible. The effect of the number of\nlayers, layer depth and the degree of the Chebyshev-polynomial applied in the\nkernel is discussed taking into account the peculiarities of the application.\nIn addition, a weighting method is shown, wherewith information on friction\nloss can be embed into the spectral graph filters through the adjacency matrix.\nThe performance of the proposed model is presented on 3 WDSs at different\nnumber of nodes observed compared to the total number of nodes. The weighted\nconnections prove no benefit over the binary connections, but the proposed\nmodel reconstructs the nodal pressure with at most 5% relative error on average\nat an observation ratio of 5% at least. The results are achieved with shallow\ngraph neural networks by following the considerations discussed in the paper.\n", "versions": [{"version": "v1", "created": "Wed, 28 Apr 2021 07:56:55 GMT"}], "update_date": "2021-04-29", "authors_parsed": [["Hajgat\u00f3", "Gergely", ""], ["Gyires-T\u00f3th", "B\u00e1lint", ""], ["Pa\u00e1l", "Gy\u00f6rgy", ""]]}, {"id": "2104.13621", "submitter": "Antonio Ginart", "authors": "Antonio Ginart, Martin Zhang, James Zou", "title": "MLDemon: Deployment Monitoring for Machine Learning Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Post-deployment monitoring of the performance of ML systems is critical for\nensuring reliability, especially as new user inputs can differ from the\ntraining distribution. Here we propose a novel approach, MLDemon, for ML\nDEployment MONitoring. MLDemon integrates both unlabeled features and a small\namount of on-demand labeled examples over time to produce a real-time estimate\nof the ML model's current performance on a given data stream. Subject to budget\nconstraints, MLDemon decides when to acquire additional, potentially costly,\nsupervised labels to verify the model. On temporal datasets with diverse\ndistribution drifts and models, MLDemon substantially outperforms existing\nmonitoring approaches. Moreover, we provide theoretical analysis to show that\nMLDemon is minimax rate optimal up to logarithmic factors and is provably\nrobust against broad distribution drifts whereas prior approaches are not.\n", "versions": [{"version": "v1", "created": "Wed, 28 Apr 2021 07:59:10 GMT"}, {"version": "v2", "created": "Thu, 29 Apr 2021 06:31:52 GMT"}, {"version": "v3", "created": "Wed, 5 May 2021 18:06:53 GMT"}, {"version": "v4", "created": "Wed, 9 Jun 2021 23:04:50 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["Ginart", "Antonio", ""], ["Zhang", "Martin", ""], ["Zou", "James", ""]]}, {"id": "2104.13626", "submitter": "Paul Viallard", "authors": "Paul Viallard (LHC), Pascal Germain (ULaval), Amaury Habrard (LHC),\n  Emilie Morvant (LHC)", "title": "Self-Bounding Majority Vote Learning Algorithms by the Direct\n  Minimization of a Tight PAC-Bayesian C-Bound", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the PAC-Bayesian literature, the C-Bound refers to an insightful relation\nbetween the risk of a majority vote classifier (under the zero-one loss) and\nthe first two moments of its margin (i.e., the expected margin and the voters'\ndiversity). Until now, learning algorithms developed in this framework minimize\nthe empirical version of the C-Bound, instead of explicit PAC-Bayesian\ngeneralization bounds. In this paper, by directly optimizing PAC-Bayesian\nguarantees on the C-Bound, we derive self-bounding majority vote learning\nalgorithms. Moreover, our algorithms based on gradient descent are scalable and\nlead to accurate predictors paired with non-vacuous guarantees.\n", "versions": [{"version": "v1", "created": "Wed, 28 Apr 2021 08:23:18 GMT"}], "update_date": "2021-04-29", "authors_parsed": [["Viallard", "Paul", "", "LHC"], ["Germain", "Pascal", "", "ULaval"], ["Habrard", "Amaury", "", "LHC"], ["Morvant", "Emilie", "", "LHC"]]}, {"id": "2104.13628", "submitter": "Quanquan Gu", "authors": "Yuan Cao and Quanquan Gu and Mikhail Belkin", "title": "Risk Bounds for Over-parameterized Maximum Margin Classification on\n  Sub-Gaussian Mixtures", "comments": "35 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern machine learning systems such as deep neural networks are often highly\nover-parameterized so that they can fit the noisy training data exactly, yet\nthey can still achieve small test errors in practice. In this paper, we study\nthis \"benign overfitting\" (Bartlett et al. (2020)) phenomenon of the maximum\nmargin classifier for linear classification problems. Specifically, we consider\ndata generated from sub-Gaussian mixtures, and provide a tight risk bound for\nthe maximum margin linear classifier in the over-parameterized setting. Our\nresults precisely characterize the condition under which benign overfitting can\noccur in linear classification problems, and improve on previous work. They\nalso have direct implications for over-parameterized logistic regression.\n", "versions": [{"version": "v1", "created": "Wed, 28 Apr 2021 08:25:16 GMT"}], "update_date": "2021-04-29", "authors_parsed": [["Cao", "Yuan", ""], ["Gu", "Quanquan", ""], ["Belkin", "Mikhail", ""]]}, {"id": "2104.13629", "submitter": "Sohei Itahara", "authors": "Sohei Itahara, Takayuki Nishio, and Koji Yamamoto", "title": "Packet-Loss-Tolerant Split Inference for Delay-Sensitive Deep Learning\n  in Lossy Wireless Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The distributed inference framework is an emerging technology for real-time\napplications empowered by cutting-edge deep machine learning (ML) on\nresource-constrained Internet of things (IoT) devices. In distributed\ninference, computational tasks are offloaded from the IoT device to other\ndevices or the edge server via lossy IoT networks. However, narrow-band and\nlossy IoT networks cause non-negligible packet losses and retransmissions,\nresulting in non-negligible communication latency. This study solves the\nproblem of the incremental retransmission latency caused by packet loss in a\nlossy IoT network. We propose a split inference with no retransmissions (SI-NR)\nmethod that achieves high accuracy without any retransmissions, even when\npacket loss occurs. In SI-NR, the key idea is to train the ML model by\nemulating the packet loss by a dropout method, which randomly drops the output\nof hidden units in a DNN layer. This enables the SI-NR system to obtain\nrobustness against packet losses. Our ML experimental evaluation reveals that\nSI-NR obtains accurate predictions without packet retransmission at a packet\nloss rate of 60%.\n", "versions": [{"version": "v1", "created": "Wed, 28 Apr 2021 08:28:22 GMT"}], "update_date": "2021-04-29", "authors_parsed": [["Itahara", "Sohei", ""], ["Nishio", "Takayuki", ""], ["Yamamoto", "Koji", ""]]}, {"id": "2104.13638", "submitter": "Manu Joseph", "authors": "Manu Joseph", "title": "PyTorch Tabular: A Framework for Deep Learning with Tabular Data", "comments": "This work has been submitted to the IEEE for possible publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In spite of showing unreasonable effectiveness in modalities like Text and\nImage, Deep Learning has always lagged Gradient Boosting in tabular data - both\nin popularity and performance. But recently there have been newer models\ncreated specifically for tabular data, which is pushing the performance bar.\nBut popularity is still a challenge because there is no easy, ready-to-use\nlibrary like Sci-Kit Learn for deep learning. PyTorch Tabular is a new deep\nlearning library which makes working with Deep Learning and tabular data easy\nand fast. It is a library built on top of PyTorch and PyTorch Lightning and\nworks on pandas dataframes directly. Many SOTA models like NODE and TabNet are\nalready integrated and implemented in the library with a unified API. PyTorch\nTabular is designed to be easily extensible for researchers, simple for\npractitioners, and robust in industrial deployments.\n", "versions": [{"version": "v1", "created": "Wed, 28 Apr 2021 08:50:08 GMT"}], "update_date": "2021-04-29", "authors_parsed": [["Joseph", "Manu", ""]]}, {"id": "2104.13640", "submitter": "Navid Rekabsaz", "authors": "Navid Rekabsaz and Simone Kopeinik and Markus Schedl", "title": "Societal Biases in Retrieved Contents: Measurement Framework and\n  Adversarial Mitigation for BERT Rankers", "comments": "Accepted at SIGIR 2021", "journal-ref": null, "doi": "10.1145/3404835.3462949", "report-no": null, "categories": "cs.IR cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Societal biases resonate in the retrieved contents of information retrieval\n(IR) systems, resulting in reinforcing existing stereotypes. Approaching this\nissue requires established measures of fairness in respect to the\nrepresentation of various social groups in retrieval results, as well as\nmethods to mitigate such biases, particularly in the light of the advances in\ndeep ranking models. In this work, we first provide a novel framework to\nmeasure the fairness in the retrieved text contents of ranking models.\nIntroducing a ranker-agnostic measurement, the framework also enables the\ndisentanglement of the effect on fairness of collection from that of rankers.\nTo mitigate these biases, we propose AdvBert, a ranking model achieved by\nadapting adversarial bias mitigation for IR, which jointly learns to predict\nrelevance and remove protected attributes. We conduct experiments on two\npassage retrieval collections (MSMARCO Passage Re-ranking and TREC Deep\nLearning 2019 Passage Re-ranking), which we extend by fairness annotations of a\nselected subset of queries regarding gender attributes. Our results on the\nMSMARCO benchmark show that, (1) all ranking models are less fair in comparison\nwith ranker-agnostic baselines, and (2) the fairness of Bert rankers\nsignificantly improves when using the proposed AdvBert models. Lastly, we\ninvestigate the trade-off between fairness and utility, showing that we can\nmaintain the significant improvements in fairness without any significant loss\nin utility.\n", "versions": [{"version": "v1", "created": "Wed, 28 Apr 2021 08:53:54 GMT"}, {"version": "v2", "created": "Tue, 11 May 2021 07:02:56 GMT"}], "update_date": "2021-05-12", "authors_parsed": [["Rekabsaz", "Navid", ""], ["Kopeinik", "Simone", ""], ["Schedl", "Markus", ""]]}, {"id": "2104.13666", "submitter": "Abbas Cheddad", "authors": "Mengqiao Zhao, Andre G. Hochuli, Abbas Cheddad", "title": "End-to-End Approach for Recognition of Historical Digit Strings", "comments": "Cite as: Mengqiao Zhao, Andre G. Hochuli and Abbas Cheddad,\n  End-to-End Approach for Recognition of Historical Digit Strings, to appear in\n  the 16th International Conference on Document Analysis and Recognition (ICDAR\n  2021), LNCS, Springer, Lausanne, Switzerland", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The plethora of digitalised historical document datasets released in recent\nyears has rekindled interest in advancing the field of handwriting pattern\nrecognition. In the same vein, a recently published data set, known as ARDIS,\npresents handwritten digits manually cropped from 15.000 scanned documents of\nSwedish church books and exhibiting various handwriting styles. To this end, we\npropose an end-to-end segmentation-free deep learning approach to handle this\nchallenging ancient handwriting style of dates present in the ARDIS dataset\n(4-digits long strings). We show that with slight modifications in the VGG-16\ndeep model, the framework can achieve a recognition rate of 93.2%, resulting in\na feasible solution free of heuristic methods, segmentation, and fusion\nmethods. Moreover, the proposed approach outperforms the well-known CRNN method\n(a model widely applied in handwriting recognition tasks).\n", "versions": [{"version": "v1", "created": "Wed, 28 Apr 2021 09:39:29 GMT"}], "update_date": "2021-04-29", "authors_parsed": [["Zhao", "Mengqiao", ""], ["Hochuli", "Andre G.", ""], ["Cheddad", "Abbas", ""]]}, {"id": "2104.13669", "submitter": "Calypso Herrera", "authors": "Calypso Herrera, Florian Krach, Pierre Ruyssen, Josef Teichmann", "title": "Optimal Stopping via Randomized Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.NA math.NA math.PR q-fin.CP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper presents new machine learning approaches to approximate the\nsolution of optimal stopping problems. The key idea of these methods is to use\nneural networks, where the hidden layers are generated randomly and only the\nlast layer is trained, in order to approximate the continuation value. Our\napproaches are applicable for high dimensional problems where the existing\napproaches become increasingly impractical. In addition, since our approaches\ncan be optimized using a simple linear regression, they are very easy to\nimplement and theoretical guarantees can be provided. In Markovian examples our\nrandomized reinforcement learning approach and in non-Markovian examples our\nrandomized recurrent neural network approach outperform the state-of-the-art\nand other relevant machine learning approaches.\n", "versions": [{"version": "v1", "created": "Wed, 28 Apr 2021 09:47:21 GMT"}], "update_date": "2021-04-29", "authors_parsed": [["Herrera", "Calypso", ""], ["Krach", "Florian", ""], ["Ruyssen", "Pierre", ""], ["Teichmann", "Josef", ""]]}, {"id": "2104.13671", "submitter": "Pritam Majumder", "authors": "Pritam Majumder, Jiayi Huang, Sungkeun Kim, Abdullah Muzahid, Dylan\n  Siegers, Chia-Che Tsai, and Eun Jung Kim", "title": "Continual Learning Approach for Improving the Data and Computation\n  Mapping in Near-Memory Processing System", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR cs.LG cs.NI cs.OS", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  The resurgence of near-memory processing (NMP) with the advent of big data\nhas shifted the computation paradigm from processor-centric to memory-centric\ncomputing. To meet the bandwidth and capacity demands of memory-centric\ncomputing, 3D memory has been adopted to form a scalable memory-cube network.\nAlong with NMP and memory system development, the mapping for placing data and\nguiding computation in the memory-cube network has become crucial in driving\nthe performance improvement in NMP. However, it is very challenging to design a\nuniversal optimal mapping for all applications due to unique application\nbehavior and intractable decision space. In this paper, we propose an\nartificially intelligent memory mapping scheme, AIMM, that optimizes data\nplacement and resource utilization through page and computation remapping. Our\nproposed technique involves continuously evaluating and learning the impact of\nmapping decisions on system performance for any application. AIMM uses a neural\nnetwork to achieve a near-optimal mapping during execution, trained using a\nreinforcement learning algorithm that is known to be effective for exploring a\nvast design space. We also provide a detailed AIMM hardware design that can be\nadopted as a plugin module for various NMP systems. Our experimental evaluation\nshows that AIMM improves the baseline NMP performance in single and multiple\nprogram scenario by up to 70% and 50%, respectively.\n", "versions": [{"version": "v1", "created": "Wed, 28 Apr 2021 09:50:35 GMT"}], "update_date": "2021-04-29", "authors_parsed": [["Majumder", "Pritam", ""], ["Huang", "Jiayi", ""], ["Kim", "Sungkeun", ""], ["Muzahid", "Abdullah", ""], ["Siegers", "Dylan", ""], ["Tsai", "Chia-Che", ""], ["Kim", "Eun Jung", ""]]}, {"id": "2104.13695", "submitter": "Ga\\\"el Poux-M\\'edard", "authors": "Ga\\\"el Poux-M\\'edard and Julien Velcin and Sabine Loudcher", "title": "Information Interaction Profile of Choice Adoption", "comments": "18 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.HC cs.SI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Interactions between pieces of information (entities) play a substantial role\nin the way an individual acts on them: adoption of a product, the spread of\nnews, strategy choice, etc. However, the underlying interaction mechanisms are\noften unknown and have been little explored in the literature. We introduce an\nefficient method to infer both the entities interaction network and its\nevolution according to the temporal distance separating interacting entities;\ntogether, they form the interaction profile. The interaction profile allows\ncharacterizing the mechanisms of the interaction processes. We approach this\nproblem via a convex model based on recent advances in multi-kernel inference.\nWe consider an ordered sequence of exposures to entities (URL, ads, situations)\nand the actions the user exerts on them (share, click, decision). We study how\nusers exhibit different behaviors according to combinations of exposures they\nhave been exposed to. We show that the effect of a combination of exposures on\na user is more than the sum of each exposure's independent effect--there is an\ninteraction. We reduce this modeling to a non-parametric convex optimization\nproblem that can be solved in parallel. Our method recovers state-of-the-art\nresults on interaction processes on three real-world datasets and outperforms\nbaselines in the inference of the underlying data generation mechanisms.\nFinally, we show that interaction profiles can be visualized intuitively,\neasing the interpretation of the model.\n", "versions": [{"version": "v1", "created": "Wed, 28 Apr 2021 10:42:25 GMT"}], "update_date": "2021-04-29", "authors_parsed": [["Poux-M\u00e9dard", "Ga\u00ebl", ""], ["Velcin", "Julien", ""], ["Loudcher", "Sabine", ""]]}, {"id": "2104.13712", "submitter": "Yao-Hung Tsai", "authors": "Yao-Hung Hubert Tsai, Shaojie Bai, Louis-Philippe Morency, Ruslan\n  Salakhutdinov", "title": "A Note on Connecting Barlow Twins with Negative-Sample-Free Contrastive\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this report, we relate the algorithmic design of Barlow Twins' method to\nthe Hilbert-Schmidt Independence Criterion (HSIC), thus establishing it as a\ncontrastive learning approach that is free of negative samples. Through this\nperspective, we argue that Barlow Twins (and thus the class of\nnegative-sample-free contrastive learning methods) suggests a possibility to\nbridge the two major families of self-supervised learning philosophies:\nnon-contrastive and contrastive approaches. In particular, Barlow twins\nexemplified how we could combine the best practices of both worlds: avoiding\nthe need of large training batch size and negative sample pairing (like\nnon-contrastive methods) and avoiding symmetry-breaking network designs (like\ncontrastive methods).\n", "versions": [{"version": "v1", "created": "Wed, 28 Apr 2021 11:36:09 GMT"}], "update_date": "2021-04-29", "authors_parsed": [["Tsai", "Yao-Hung Hubert", ""], ["Bai", "Shaojie", ""], ["Morency", "Louis-Philippe", ""], ["Salakhutdinov", "Ruslan", ""]]}, {"id": "2104.13718", "submitter": "Jie Chen", "authors": "Jie Chen, Shouzhen Chen, Mingyuan Bai, Jian Pu, Junping Zhang, Junbin\n  Gao", "title": "Graph Decoupling Attention Markov Networks for Semi-supervised Graph\n  Node Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph neural networks (GNN) have been ubiquitous in graph learning tasks such\nas node classification. Most of GNN methods update the node embedding\niteratively by aggregating its neighbors' information. However, they often\nsuffer from negative disturbance, due to edges connecting nodes with different\nlabels. One approach to alleviate this negative disturbance is to use\nattention, but current attention always considers feature similarity and\nsuffers from the lack of supervision. In this paper, we consider the label\ndependency of graph nodes and propose a decoupling attention mechanism to learn\nboth hard and soft attention. The hard attention is learned on labels for a\nrefined graph structure with fewer inter-class edges. Its purpose is to reduce\nthe aggregation's negative disturbance. The soft attention is learned on\nfeatures maximizing the information gain by message passing over better graph\nstructures. Moreover, the learned attention guides the label propagation and\nthe feature propagation. Extensive experiments are performed on five well-known\nbenchmark graph datasets to verify the effectiveness of the proposed method.\n", "versions": [{"version": "v1", "created": "Wed, 28 Apr 2021 11:44:13 GMT"}], "update_date": "2021-04-29", "authors_parsed": [["Chen", "Jie", ""], ["Chen", "Shouzhen", ""], ["Bai", "Mingyuan", ""], ["Pu", "Jian", ""], ["Zhang", "Junping", ""], ["Gao", "Junbin", ""]]}, {"id": "2104.13725", "submitter": "Mohammad Mahfujur Rahman", "authors": "Mohammad Mahfujur Rahman, Clinton Fookes, Sridha Sridharan", "title": "Preserving Semantic Consistency in Unsupervised Domain Adaptation Using\n  Generative Adversarial Networks", "comments": "Submitted to Pattern Recognition Letters", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Unsupervised domain adaptation seeks to mitigate the distribution discrepancy\nbetween source and target domains, given labeled samples of the source domain\nand unlabeled samples of the target domain. Generative adversarial networks\n(GANs) have demonstrated significant improvement in domain adaptation by\nproducing images which are domain specific for training. However, most of the\nexisting GAN based techniques for unsupervised domain adaptation do not\nconsider semantic information during domain matching, hence these methods\ndegrade the performance when the source and target domain data are semantically\ndifferent. In this paper, we propose an end-to-end novel semantic consistent\ngenerative adversarial network (SCGAN). This network can achieve source to\ntarget domain matching by capturing semantic information at the feature level\nand producing images for unsupervised domain adaptation from both the source\nand the target domains. We demonstrate the robustness of our proposed method\nwhich exceeds the state-of-the-art performance in unsupervised domain\nadaptation settings by performing experiments on digit and object\nclassification tasks.\n", "versions": [{"version": "v1", "created": "Wed, 28 Apr 2021 12:23:30 GMT"}], "update_date": "2021-04-29", "authors_parsed": [["Rahman", "Mohammad Mahfujur", ""], ["Fookes", "Clinton", ""], ["Sridharan", "Sridha", ""]]}, {"id": "2104.13730", "submitter": "Scott Mueller", "authors": "Scott Mueller, Ang Li, Judea Pearl", "title": "Causes of Effects: Learning individual responses from population data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of individualization is recognized as crucial in almost every\nfield. Identifying causes of effects in specific events is likewise essential\nfor accurate decision making. However, such estimates invoke counterfactual\nrelationships, and are therefore indeterminable from population data. For\nexample, the probability of benefiting from a treatment concerns an individual\nhaving a favorable outcome if treated and an unfavorable outcome if untreated.\nExperiments conditioning on fine-grained features are fundamentally inadequate\nbecause we can't test both possibilities for an individual. Tian and Pearl\nprovided bounds on this and other probabilities of causation using a\ncombination of experimental and observational data. Even though those bounds\nwere proven tight, narrower bounds, sometimes significantly so, can be achieved\nwhen structural information is available in the form of a causal model. This\nhas the power to solve central problems, such as explainable AI, legal\nresponsibility, and personalized medicine, all of which demand counterfactual\nlogic. We analyze and expand on existing research by applying bounds to the\nprobability of necessity and sufficiency (PNS) along with graphical criteria\nand practical applications.\n", "versions": [{"version": "v1", "created": "Wed, 28 Apr 2021 12:38:11 GMT"}, {"version": "v2", "created": "Sun, 2 May 2021 06:48:55 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Mueller", "Scott", ""], ["Li", "Ang", ""], ["Pearl", "Judea", ""]]}, {"id": "2104.13732", "submitter": "Alexander Brauckmann", "authors": "Alexander Brauckmann, Andr\\'es Goens, Jeronimo Castrillon", "title": "A Reinforcement Learning Environment for Polyhedral Optimizations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC cs.DM cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The polyhedral model allows a structured way of defining semantics-preserving\ntransformations to improve the performance of a large class of loops. Finding\nprofitable points in this space is a hard problem which is usually approached\nby heuristics that generalize from domain-expert knowledge. Existing problem\nformulations in state-of-the-art heuristics depend on the shape of particular\nloops, making it hard to leverage generic and more powerful optimization\ntechniques from the machine learning domain. In this paper, we propose PolyGym,\na shape-agnostic formulation for the space of legal transformations in the\npolyhedral model as a Markov Decision Process (MDP). Instead of using\ntransformations, the formulation is based on an abstract space of possible\nschedules. In this formulation, states model partial schedules, which are\nconstructed by actions that are reusable across different loops. With a simple\nheuristic to traverse the space, we demonstrate that our formulation is\npowerful enough to match and outperform state-of-the-art heuristics. On the\nPolybench benchmark suite, we found transformations that led to a speedup of\n3.39x over LLVM O3, which is 1.83x better than the speedup achieved by ISL. Our\ngeneric MDP formulation enables using reinforcement learning to learn\noptimization policies over a wide range of loops. This also contributes to the\nemerging field of machine learning in compilers, as it exposes a novel problem\nformulation that can push the limits of existing methods.\n", "versions": [{"version": "v1", "created": "Wed, 28 Apr 2021 12:41:52 GMT"}, {"version": "v2", "created": "Thu, 29 Apr 2021 08:04:04 GMT"}], "update_date": "2021-04-30", "authors_parsed": [["Brauckmann", "Alexander", ""], ["Goens", "Andr\u00e9s", ""], ["Castrillon", "Jeronimo", ""]]}, {"id": "2104.13733", "submitter": "Chuan Guo", "authors": "Chuan Guo, Alexandre Sablayrolles, Herv\\'e J\\'egou, Douwe Kiela", "title": "Gradient-based Adversarial Attacks against Text Transformers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose the first general-purpose gradient-based attack against\ntransformer models. Instead of searching for a single adversarial example, we\nsearch for a distribution of adversarial examples parameterized by a\ncontinuous-valued matrix, hence enabling gradient-based optimization. We\nempirically demonstrate that our white-box attack attains state-of-the-art\nattack performance on a variety of natural language tasks. Furthermore, we show\nthat a powerful black-box transfer attack, enabled by sampling from the\nadversarial distribution, matches or exceeds existing methods, while only\nrequiring hard-label outputs.\n", "versions": [{"version": "v1", "created": "Thu, 15 Apr 2021 17:43:43 GMT"}], "update_date": "2021-04-29", "authors_parsed": [["Guo", "Chuan", ""], ["Sablayrolles", "Alexandre", ""], ["J\u00e9gou", "Herv\u00e9", ""], ["Kiela", "Douwe", ""]]}, {"id": "2104.13753", "submitter": "Alexander Dunlap", "authors": "Alexander Dunlap and Jean-Christophe Mourrat", "title": "Sum-of-norms clustering does not separate nearby balls", "comments": "26 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sum-of-norms clustering is a popular convexification of $K$-means clustering.\nWe show that, if the dataset is made of a large number of independent random\nvariables distributed according to the uniform measure on the union of two\ndisjoint balls of unit radius, and if the balls are sufficiently close to one\nanother, then sum-of-norms clustering will typically fail to recover the\ndecomposition of the dataset into two clusters. As the dimension tends to\ninfinity, this happens even when the distance between the centers of the two\nballs is taken to be as large as $2\\sqrt{2}$. In order to show this, we\nintroduce and analyze a continuous version of sum-of-norms clustering, where\nthe dataset is replaced by a general measure. In particular, we state and prove\na local-global characterization of the clustering that seems to be new even in\nthe case of discrete datapoints.\n", "versions": [{"version": "v1", "created": "Wed, 28 Apr 2021 13:35:17 GMT"}], "update_date": "2021-04-29", "authors_parsed": [["Dunlap", "Alexander", ""], ["Mourrat", "Jean-Christophe", ""]]}, {"id": "2104.13756", "submitter": "Sebastian Gabriel Popescu", "authors": "Sebastian G. Popescu, David J. Sharp, James H. Cole, Konstantinos\n  Kamnitsas, Ben Glocker", "title": "Distributional Gaussian Process Layers for Outlier Detection in Image\n  Segmentation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose a parameter efficient Bayesian layer for hierarchical\nconvolutional Gaussian Processes that incorporates Gaussian Processes operating\nin Wasserstein-2 space to reliably propagate uncertainty. This directly\nreplaces convolving Gaussian Processes with a distance-preserving affine\noperator on distributions. Our experiments on brain tissue-segmentation show\nthat the resulting architecture approaches the performance of well-established\ndeterministic segmentation algorithms (U-Net), which has never been achieved\nwith previous hierarchical Gaussian Processes. Moreover, by applying the same\nsegmentation model to out-of-distribution data (i.e., images with pathology\nsuch as brain tumors), we show that our uncertainty estimates result in\nout-of-distribution detection that outperforms the capabilities of previous\nBayesian networks and reconstruction-based approaches that learn normative\ndistributions.\n", "versions": [{"version": "v1", "created": "Wed, 28 Apr 2021 13:37:10 GMT"}], "update_date": "2021-04-29", "authors_parsed": [["Popescu", "Sebastian G.", ""], ["Sharp", "David J.", ""], ["Cole", "James H.", ""], ["Kamnitsas", "Konstantinos", ""], ["Glocker", "Ben", ""]]}, {"id": "2104.13772", "submitter": "Jincaho Zhou", "authors": "Qi Xuan, Jinchao Zhou, Kunfeng Qiu, Dongwei Xu, Shilian Zheng and\n  Xiaoniu Yang", "title": "CLPVG: Circular limited penetrable visibility graph as a new network\n  model for time series", "comments": "9 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Visibility Graph (VG) transforms time series into graphs, facilitating signal\nprocessing by advanced graph data mining algorithms. In this paper, based on\nthe classic Limited Penetrable Visibility Graph (LPVG) method, we propose a\nnovel nonlinear mapping method named Circular Limited Penetrable Visibility\nGraph (CLPVG). The testing on degree distribution and clustering coefficient on\nthe generated graphs of typical time series validates that our CLPVG is able to\neffectively capture the important features of time series and has better\nanti-noise ability than traditional LPVG. The experiments on real-world\ntime-series datasets of radio signal and electroencephalogram (EEG) also\nsuggest that the structural features provided by CLPVG, rather than LPVG, are\nmore useful for time-series classification, leading to higher accuracy. And\nthis classification performance can be further enhanced through structural\nfeature expansion by adopting Subgraph Networks (SGN). All of these results\nvalidate the effectiveness of our CLPVG model.\n", "versions": [{"version": "v1", "created": "Mon, 1 Mar 2021 03:13:58 GMT"}], "update_date": "2021-04-29", "authors_parsed": [["Xuan", "Qi", ""], ["Zhou", "Jinchao", ""], ["Qiu", "Kunfeng", ""], ["Xu", "Dongwei", ""], ["Zheng", "Shilian", ""], ["Yang", "Xiaoniu", ""]]}, {"id": "2104.13773", "submitter": "Amena Khatun", "authors": "Amena Khatun, Simon Denman, Sridha Sridharan, Clinton Fookes", "title": "Pose-driven Attention-guided Image Generation for Person\n  Re-Identification", "comments": "Submitted to Pattern Recognition", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Person re-identification (re-ID) concerns the matching of subject images\nacross different camera views in a multi camera surveillance system. One of the\nmajor challenges in person re-ID is pose variations across the camera network,\nwhich significantly affects the appearance of a person. Existing development\ndata lack adequate pose variations to carry out effective training of person\nre-ID systems. To solve this issue, in this paper we propose an end-to-end\npose-driven attention-guided generative adversarial network, to generate\nmultiple poses of a person. We propose to attentively learn and transfer the\nsubject pose through an attention mechanism. A semantic-consistency loss is\nproposed to preserve the semantic information of the person during pose\ntransfer. To ensure fine image details are realistic after pose translation, an\nappearance discriminator is used while a pose discriminator is used to ensure\nthe pose of the transferred images will exactly be the same as the target pose.\nWe show that by incorporating the proposed approach in a person\nre-identification framework, realistic pose transferred images and\nstate-of-the-art re-identification results can be achieved.\n", "versions": [{"version": "v1", "created": "Wed, 28 Apr 2021 14:02:24 GMT"}], "update_date": "2021-04-29", "authors_parsed": [["Khatun", "Amena", ""], ["Denman", "Simon", ""], ["Sridharan", "Sridha", ""], ["Fookes", "Clinton", ""]]}, {"id": "2104.13780", "submitter": "Amena Khatun", "authors": "Amena Khatun, Simon Denman, Sridha Sridharan, Clinton Fookes", "title": "Semantic Consistency and Identity Mapping Multi-Component Generative\n  Adversarial Network for Person Re-Identification", "comments": "Accepted in WACV 2020", "journal-ref": "WACV, 2020", "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  In a real world environment, person re-identification (Re-ID) is a\nchallenging task due to variations in lighting conditions, viewing angles, pose\nand occlusions. Despite recent performance gains, current person Re-ID\nalgorithms still suffer heavily when encountering these variations. To address\nthis problem, we propose a semantic consistency and identity mapping\nmulti-component generative adversarial network (SC-IMGAN) which provides style\nadaptation from one to many domains. To ensure that transformed images are as\nrealistic as possible, we propose novel identity mapping and semantic\nconsistency losses to maintain identity across the diverse domains. For the\nRe-ID task, we propose a joint verification-identification quartet network\nwhich is trained with generated and real images, followed by an effective\nquartet loss for verification. Our proposed method outperforms state-of-the-art\ntechniques on six challenging person Re-ID datasets: CUHK01, CUHK03, VIPeR,\nPRID2011, iLIDS and Market-1501.\n", "versions": [{"version": "v1", "created": "Wed, 28 Apr 2021 14:12:29 GMT"}], "update_date": "2021-04-29", "authors_parsed": [["Khatun", "Amena", ""], ["Denman", "Simon", ""], ["Sridharan", "Sridha", ""], ["Fookes", "Clinton", ""]]}, {"id": "2104.13786", "submitter": "Dejan Stepec", "authors": "Dejan Stepec and Danijel Skocaj", "title": "Unsupervised Detection of Cancerous Regions in Histology Imagery using\n  Image-to-Image Translation", "comments": "CVPR 2021 CVMI workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Detection of visual anomalies refers to the problem of finding patterns in\ndifferent imaging data that do not conform to the expected visual appearance\nand is a widely studied problem in different domains. Due to the nature of\nanomaly occurrences and underlying generating processes, it is hard to\ncharacterize them and obtain labeled data. Obtaining labeled data is especially\ndifficult in biomedical applications, where only trained domain experts can\nprovide labels, which often come in large diversity and complexity. Recently\npresented approaches for unsupervised detection of visual anomalies approaches\nomit the need for labeled data and demonstrate promising results in domains,\nwhere anomalous samples significantly deviate from the normal appearance.\nDespite promising results, the performance of such approaches still lags behind\nsupervised approaches and does not provide a one-fits-all solution. In this\nwork, we present an image-to-image translation-based framework that\nsignificantly surpasses the performance of existing unsupervised methods and\napproaches the performance of supervised methods in a challenging domain of\ncancerous region detection in histology imagery.\n", "versions": [{"version": "v1", "created": "Wed, 28 Apr 2021 14:19:00 GMT"}], "update_date": "2021-04-29", "authors_parsed": [["Stepec", "Dejan", ""], ["Skocaj", "Danijel", ""]]}, {"id": "2104.13790", "submitter": "Yangfan Zhou", "authors": "Yangfan Zhou, Kaizhu Huang, Cheng Cheng, Xuguang Wang, Amir Hussain,\n  and Xin Liu", "title": "FastAdaBelief: Improving Convergence Rate for Belief-based Adaptive\n  Optimizers by Exploiting Strong Convexity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  AdaBelief, one of the current best optimizers, demonstrates superior\ngeneralization ability compared to the popular Adam algorithm by viewing the\nexponential moving average of observed gradients. AdaBelief is theoretically\nappealing in that it has a data-dependent $O(\\sqrt{T})$ regret bound when\nobjective functions are convex, where $T$ is a time horizon. It remains however\nan open problem whether the convergence rate can be further improved without\nsacrificing its generalization ability. %on how to exploit strong convexity to\nfurther improve the convergence rate of AdaBelief. To this end, we make a first\nattempt in this work and design a novel optimization algorithm called\nFastAdaBelief that aims to exploit its strong convexity in order to achieve an\neven faster convergence rate. In particular, by adjusting the step size that\nbetter considers strong convexity and prevents fluctuation, our proposed\nFastAdaBelief demonstrates excellent generalization ability as well as superior\nconvergence. As an important theoretical contribution, we prove that\nFastAdaBelief attains a data-dependant $O(\\log T)$ regret bound, which is\nsubstantially lower than AdaBelief. On the empirical side, we validate our\ntheoretical analysis with extensive experiments in both scenarios of strong and\nnon-strong convexity on three popular baseline models. Experimental results are\nvery encouraging: FastAdaBelief converges the quickest in comparison to all\nmainstream algorithms while maintaining an excellent generalization ability, in\ncases of both strong or non-strong convexity. FastAdaBelief is thus posited as\na new benchmark model for the research community.\n", "versions": [{"version": "v1", "created": "Wed, 28 Apr 2021 14:23:37 GMT"}, {"version": "v2", "created": "Tue, 8 Jun 2021 01:59:50 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Zhou", "Yangfan", ""], ["Huang", "Kaizhu", ""], ["Cheng", "Cheng", ""], ["Wang", "Xuguang", ""], ["Hussain", "Amir", ""], ["Liu", "Xin", ""]]}, {"id": "2104.13794", "submitter": "Sourangshu Bhattacharya", "authors": "Soumi Das, Arshdeep Singh, Saptarshi Chatterjee, Suparna Bhattacharya,\n  Sourangshu Bhattacharya", "title": "Finding High-Value Training Data Subset through Differentiable Convex\n  Programming", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Finding valuable training data points for deep neural networks has been a\ncore research challenge with many applications. In recent years, various\ntechniques for calculating the \"value\" of individual training datapoints have\nbeen proposed for explaining trained models. However, the value of a training\ndatapoint also depends on other selected training datapoints - a notion that is\nnot explicitly captured by existing methods. In this paper, we study the\nproblem of selecting high-value subsets of training data. The key idea is to\ndesign a learnable framework for online subset selection, which can be learned\nusing mini-batches of training data, thus making our method scalable. This\nresults in a parameterized convex subset selection problem that is amenable to\na differentiable convex programming paradigm, thus allowing us to learn the\nparameters of the selection model in end-to-end training. Using this framework,\nwe design an online alternating minimization-based algorithm for jointly\nlearning the parameters of the selection model and ML model. Extensive\nevaluation on a synthetic dataset, and three standard datasets, show that our\nalgorithm finds consistently higher value subsets of training data, compared to\nthe recent state-of-the-art methods, sometimes ~20% higher value than existing\nmethods. The subsets are also useful in finding mislabelled training data. Our\nalgorithm takes running time comparable to the existing valuation functions.\n", "versions": [{"version": "v1", "created": "Wed, 28 Apr 2021 14:33:26 GMT"}], "update_date": "2021-04-29", "authors_parsed": [["Das", "Soumi", ""], ["Singh", "Arshdeep", ""], ["Chatterjee", "Saptarshi", ""], ["Bhattacharya", "Suparna", ""], ["Bhattacharya", "Sourangshu", ""]]}, {"id": "2104.13816", "submitter": "Andrea Wang", "authors": "Andrea W Wang (1), Jo-Yu Lan (2), Chihhao Yu (1), Ming-Hung Wang (2)\n  ((1) Information Operations Research Group (IORG) (2) Department of\n  Information Engineering and Computer Science, Feng Chia University)", "title": "The Evolution of Rumors on a Closed Platform during COVID-19", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CL cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we looked into a dataset of 114 thousands of suspicious messages\ncollected from the most popular closed messaging platform in Taiwan between\nJanuary and July, 2020. We proposed an hybrid algorithm that could efficiently\ncluster a large number of text messages according their topics and narratives.\nThat is, we obtained groups of messages that are within a limited content\nalterations within each other. By employing the algorithm to the dataset, we\nwere able to look at the content alterations and the temporal dynamics of each\nparticular rumor over time. With qualitative case studies of three COVID-19\nrelated rumors, we have found that key authoritative figures were often\nmisquoted in false information. It was an effective measure to increase the\npopularity of one false information. In addition, fact-check was not effective\nin stopping misinformation from getting attention. In fact, the popularity of\none false information was often more influenced by major societal events and\neffective content alterations.\n", "versions": [{"version": "v1", "created": "Wed, 28 Apr 2021 15:04:22 GMT"}], "update_date": "2021-04-29", "authors_parsed": [["Wang", "Andrea W", ""], ["Lan", "Jo-Yu", ""], ["Yu", "Chihhao", ""], ["Wang", "Ming-Hung", ""]]}, {"id": "2104.13818", "submitter": "Ali Ramezani-Kebrya", "authors": "Ali Ramezani-Kebrya, Fartash Faghri, Ilya Markov, Vitalii Aksenov, Dan\n  Alistarh, Daniel M. Roy", "title": "NUQSGD: Provably Communication-efficient Data-parallel SGD via\n  Nonuniform Quantization", "comments": "This entry is redundant and was created in error. See\n  arXiv:1908.06077 for the latest version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As the size and complexity of models and datasets grow, so does the need for\ncommunication-efficient variants of stochastic gradient descent that can be\ndeployed to perform parallel model training. One popular\ncommunication-compression method for data-parallel SGD is QSGD (Alistarh et\nal., 2017), which quantizes and encodes gradients to reduce communication\ncosts. The baseline variant of QSGD provides strong theoretical guarantees,\nhowever, for practical purposes, the authors proposed a heuristic variant which\nwe call QSGDinf, which demonstrated impressive empirical gains for distributed\ntraining of large neural networks. In this paper, we build on this work to\npropose a new gradient quantization scheme, and show that it has both stronger\ntheoretical guarantees than QSGD, and matches and exceeds the empirical\nperformance of the QSGDinf heuristic and of other compression methods.\n", "versions": [{"version": "v1", "created": "Wed, 28 Apr 2021 15:07:03 GMT"}, {"version": "v2", "created": "Sat, 1 May 2021 20:34:38 GMT"}], "update_date": "2021-05-05", "authors_parsed": [["Ramezani-Kebrya", "Ali", ""], ["Faghri", "Fartash", ""], ["Markov", "Ilya", ""], ["Aksenov", "Vitalii", ""], ["Alistarh", "Dan", ""], ["Roy", "Daniel M.", ""]]}, {"id": "2104.13826", "submitter": "David Dubois", "authors": "Philippe Raffy, Jean-Fran\\c{c}ois Pambrun, Ashish Kumar, David Dubois,\n  Jay Waldron Patti, Robyn Alexandra Cairns, Ryan Young", "title": "Deep Learning Body Region Classification of MRI and CT examinations", "comments": "21 pages, 2 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Standardized body region labelling of individual images provides data that\ncan improve human and computer use of medical images. A CNN-based classifier\nwas developed to identify body regions in CT and MRI. 17 CT (18 MRI) body\nregions covering the entire human body were defined for the classification\ntask. Three retrospective databases were built for the AI model training,\nvalidation, and testing, with a balanced distribution of studies per body\nregion. The test databases originated from a different healthcare network.\nAccuracy, recall and precision of the classifier was evaluated for patient age,\npatient gender, institution, scanner manufacturer, contrast, slice thickness,\nMRI sequence, and CT kernel. The data included a retrospective cohort of 2,934\nanonymized CT cases (training: 1,804 studies, validation: 602 studies, test:\n528 studies) and 3,185 anonymized MRI cases (training: 1,911 studies,\nvalidation: 636 studies, test: 638 studies). 27 institutions from primary care\nhospitals, community hospitals and imaging centers contributed to the test\ndatasets. The data included cases of all genders in equal proportions and\nsubjects aged from a few months old to +90 years old. An image-level prediction\naccuracy of 91.9% (90.2 - 92.1) for CT, and 94.2% (92.0 - 95.6) for MRI was\nachieved. The classification results were robust across all body regions and\nconfounding factors. Due to limited data, performance results for subjects\nunder 10 years-old could not be reliably evaluated. We show that deep learning\nmodels can classify CT and MRI images by body region including lower and upper\nextremities with high accuracy.\n", "versions": [{"version": "v1", "created": "Wed, 28 Apr 2021 15:20:21 GMT"}, {"version": "v2", "created": "Tue, 29 Jun 2021 15:17:03 GMT"}], "update_date": "2021-06-30", "authors_parsed": [["Raffy", "Philippe", ""], ["Pambrun", "Jean-Fran\u00e7ois", ""], ["Kumar", "Ashish", ""], ["Dubois", "David", ""], ["Patti", "Jay Waldron", ""], ["Cairns", "Robyn Alexandra", ""], ["Young", "Ryan", ""]]}, {"id": "2104.13840", "submitter": "Xiangxiang Chu", "authors": "Xiangxiang Chu and Zhi Tian and Yuqing Wang and Bo Zhang and Haibing\n  Ren and Xiaolin Wei and Huaxia Xia and Chunhua Shen", "title": "Twins: Revisiting the Design of Spatial Attention in Vision Transformers", "comments": "Two simple and effective designs of vision transformer, which is on\n  par with the Swin transformer", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Very recently, a variety of vision transformer architectures for dense\nprediction tasks have been proposed and they show that the design of spatial\nattention is critical to their success in these tasks. In this work, we revisit\nthe design of the spatial attention and demonstrate that a carefully-devised\nyet simple spatial attention mechanism performs favourably against the\nstate-of-the-art schemes. As a result, we propose two vision transformer\narchitectures, namely, Twins-PCPVT and Twins-SVT. Our proposed architectures\nare highly-efficient and easy to implement, only involving matrix\nmultiplications that are highly optimized in modern deep learning frameworks.\nMore importantly, the proposed architectures achieve excellent performance on a\nwide range of visual tasks including imagelevel classification as well as dense\ndetection and segmentation. The simplicity and strong performance suggest that\nour proposed architectures may serve as stronger backbones for many vision\ntasks. Our code will be released soon at\nhttps://github.com/Meituan-AutoML/Twins .\n", "versions": [{"version": "v1", "created": "Wed, 28 Apr 2021 15:42:31 GMT"}, {"version": "v2", "created": "Tue, 11 May 2021 15:41:36 GMT"}, {"version": "v3", "created": "Fri, 11 Jun 2021 11:54:21 GMT"}], "update_date": "2021-06-14", "authors_parsed": [["Chu", "Xiangxiang", ""], ["Tian", "Zhi", ""], ["Wang", "Yuqing", ""], ["Zhang", "Bo", ""], ["Ren", "Haibing", ""], ["Wei", "Xiaolin", ""], ["Xia", "Huaxia", ""], ["Shen", "Chunhua", ""]]}, {"id": "2104.13844", "submitter": "Andrew Patterson", "authors": "Andrew Patterson, Adam White, Sina Ghiassian, Martha White", "title": "A Generalized Projected Bellman Error for Off-policy Value Estimation in\n  Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many reinforcement learning algorithms rely on value estimation. However, the\nmost widely used algorithms -- namely temporal difference algorithms -- can\ndiverge under both off-policy sampling and nonlinear function approximation.\nMany algorithms have been developed for off-policy value estimation which are\nsound under linear function approximation, based on the linear mean-squared\nprojected Bellman error (PBE). Extending these methods to the non-linear case\nhas been largely unsuccessful. Recently, several methods have been introduced\nthat approximate a different objective, called the mean-squared Bellman error\n(BE), which naturally facilities nonlinear approximation. In this work, we\nbuild on these insights and introduce a new generalized PBE, that extends the\nlinear PBE to the nonlinear setting. We show how this generalized objective\nunifies previous work, including previous theory, and obtain new bounds for the\nvalue error of the solutions of the generalized objective. We derive an\neasy-to-use, but sound, algorithm to minimize the generalized objective which\nis more stable across runs, is less sensitive to hyperparameters, and performs\nfavorably across four control domains with neural network function\napproximation.\n", "versions": [{"version": "v1", "created": "Wed, 28 Apr 2021 15:50:34 GMT"}], "update_date": "2021-04-29", "authors_parsed": [["Patterson", "Andrew", ""], ["White", "Adam", ""], ["Ghiassian", "Sina", ""], ["White", "Martha", ""]]}, {"id": "2104.13853", "submitter": "Carl Andersson", "authors": "Carl R. Andersson, Niklas Wahlstr\\\"om, Thomas B. Sch\\\"on", "title": "Learning deep autoregressive models for hierarchical data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose a model for hierarchical structured data as an extension to the\nstochastic temporal convolutional network. The proposed model combines an\nautoregressive model with a hierarchical variational autoencoder and\ndownsampling to achieve superior computational complexity. We evaluate the\nproposed model on two different types of sequential data: speech and\nhandwritten text. The results are promising with the proposed model achieving\nstate-of-the-art performance.\n", "versions": [{"version": "v1", "created": "Wed, 28 Apr 2021 15:58:45 GMT"}, {"version": "v2", "created": "Thu, 6 May 2021 16:04:54 GMT"}, {"version": "v3", "created": "Thu, 1 Jul 2021 15:02:56 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Andersson", "Carl R.", ""], ["Wahlstr\u00f6m", "Niklas", ""], ["Sch\u00f6n", "Thomas B.", ""]]}, {"id": "2104.13868", "submitter": "Fengjun Yang", "authors": "Fengjun Yang and Nikolai Matni", "title": "Communication Topology Co-Design in Graph Recurrent Neural Network Based\n  Distributed Control", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.LG cs.SY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  When designing large-scale distributed controllers, the information-sharing\nconstraints between sub-controllers, as defined by a communication topology\ninterconnecting them, are as important as the controller itself. Controllers\nimplemented using dense topologies typically outperform those implemented using\nsparse topologies, but it is also desirable to minimize the cost of controller\ndeployment. Motivated by the above, we introduce a compact but expressive graph\nrecurrent neural network (GRNN) parameterization of distributed controllers\nthat is well suited for distributed controller and communication topology\nco-design. Our proposed parameterization enjoys a local and distributed\narchitecture, similar to previous Graph Neural Network (GNN)-based\nparameterizations, while further naturally allowing for joint optimization of\nthe distributed controller and communication topology needed to implement it.\nWe show that the distributed controller/communication topology co-design task\ncan be posed as an $\\ell_1$-regularized empirical risk minimization problem\nthat can be efficiently solved using stochastic gradient methods. We run\nextensive simulations to study the performance of GRNN-based distributed\ncontrollers and show that (a) they achieve performance comparable to GNN-based\ncontrollers while having fewer free parameters, and (b) our method allows for\nperformance/communication density tradeoff curves to be efficiently\napproximated.\n", "versions": [{"version": "v1", "created": "Wed, 28 Apr 2021 16:30:02 GMT"}], "update_date": "2021-04-29", "authors_parsed": [["Yang", "Fengjun", ""], ["Matni", "Nikolai", ""]]}, {"id": "2104.13877", "submitter": "Michael Zhang", "authors": "Michael R. Zhang, Tom Le Paine, Ofir Nachum, Cosmin Paduraru, George\n  Tucker, Ziyu Wang, Mohammad Norouzi", "title": "Autoregressive Dynamics Models for Offline Policy Evaluation and\n  Optimization", "comments": "ICLR 2021. 17 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Standard dynamics models for continuous control make use of feedforward\ncomputation to predict the conditional distribution of next state and reward\ngiven current state and action using a multivariate Gaussian with a diagonal\ncovariance structure. This modeling choice assumes that different dimensions of\nthe next state and reward are conditionally independent given the current state\nand action and may be driven by the fact that fully observable physics-based\nsimulation environments entail deterministic transition dynamics. In this\npaper, we challenge this conditional independence assumption and propose a\nfamily of expressive autoregressive dynamics models that generate different\ndimensions of the next state and reward sequentially conditioned on previous\ndimensions. We demonstrate that autoregressive dynamics models indeed\noutperform standard feedforward models in log-likelihood on heldout\ntransitions. Furthermore, we compare different model-based and model-free\noff-policy evaluation (OPE) methods on RL Unplugged, a suite of offline MuJoCo\ndatasets, and find that autoregressive dynamics models consistently outperform\nall baselines, achieving a new state-of-the-art. Finally, we show that\nautoregressive dynamics models are useful for offline policy optimization by\nserving as a way to enrich the replay buffer through data augmentation and\nimproving performance using model-based planning.\n", "versions": [{"version": "v1", "created": "Wed, 28 Apr 2021 16:48:44 GMT"}], "update_date": "2021-04-29", "authors_parsed": [["Zhang", "Michael R.", ""], ["Paine", "Tom Le", ""], ["Nachum", "Ofir", ""], ["Paduraru", "Cosmin", ""], ["Tucker", "George", ""], ["Wang", "Ziyu", ""], ["Norouzi", "Mohammad", ""]]}, {"id": "2104.13881", "submitter": "Jason Klusowski M", "authors": "Jason M. Klusowski", "title": "Universal Consistency of Decision Trees in High Dimensions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper shows that decision trees constructed with Classification and\nRegression Trees (CART) methodology are universally consistent in an additive\nmodel context, even when the number of predictor variables scales exponentially\nwith the sample size, under certain $1$-norm sparsity constraints. The\nconsistency is universal in the sense that there are no a priori assumptions on\nthe distribution of the predictor variables. Amazingly, this adaptivity to\n(approximate or exact) sparsity is achieved with a single tree, as opposed to\nwhat might be expected for an ensemble. Finally, we show that these qualitative\nproperties of individual trees are inherited by Breiman's random forests.\nAnother surprise is that consistency holds even when the \"mtry\" tuning\nparameter vanishes as a fraction of the number of predictor variables, thus\nspeeding up computation of the forest. A key step in the analysis is the\nestablishment of an oracle inequality, which precisely characterizes the\ngoodness-of-fit and complexity tradeoff for a misspecified model.\n", "versions": [{"version": "v1", "created": "Wed, 28 Apr 2021 16:59:03 GMT"}, {"version": "v2", "created": "Fri, 7 May 2021 16:04:44 GMT"}, {"version": "v3", "created": "Tue, 25 May 2021 14:32:02 GMT"}, {"version": "v4", "created": "Mon, 21 Jun 2021 01:31:29 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Klusowski", "Jason M.", ""]]}, {"id": "2104.13894", "submitter": "Abiy Tasissa", "authors": "Abiy Tasissa, Pranay Tankala and Demba Ba", "title": "Weighed $\\ell_1$ on the simplex: Compressive sensing meets locality", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.IT cs.LG math.IT math.OC", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Sparse manifold learning algorithms combine techniques in manifold learning\nand sparse optimization to learn features that could be utilized for downstream\ntasks. The standard setting of compressive sensing can not be immediately\napplied to this setup. Due to the intrinsic geometric structure of data,\ndictionary atoms might be redundant and do not satisfy the restricted isometry\nproperty or coherence condition. In addition, manifold learning emphasizes\nlearning local geometry which is not reflected in a standard $\\ell_1$\nminimization problem. We propose weighted $\\ell_0$ and weighted $\\ell_1$\nmetrics that encourage representation via neighborhood atoms suited for\ndictionary based manifold learning. Assuming that the data is generated from\nDelaunay triangulation, we show the equivalence of weighted $\\ell_1$ and\nweighted $\\ell_0$. We discuss an optimization program that learns the\ndictionaries and sparse coefficients and demonstrate the utility of our\nregularization on synthetic and real datasets.\n", "versions": [{"version": "v1", "created": "Wed, 28 Apr 2021 17:26:29 GMT"}], "update_date": "2021-04-29", "authors_parsed": [["Tasissa", "Abiy", ""], ["Tankala", "Pranay", ""], ["Ba", "Demba", ""]]}, {"id": "2104.13896", "submitter": "Mustapha Saidallah", "authors": "Mustapha Saidallah, Fatimazahra Taki, Abdelbaki El Belrhiti El Alaoui\n  and Abdeslam El Fergougui", "title": "Classification and comparison of license plates localization algorithms", "comments": "11 pages", "journal-ref": "April 2021, Volume 12", "doi": "10.5121/sipij.2021.12201", "report-no": "02", "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The Intelligent Transportation Systems (ITS) are the subject of a world\neconomic competition. They are the application of new information and\ncommunication technologies in the transport sector, to make the infrastructures\nmore efficient, more reliable and more ecological. License Plates Recognition\n(LPR) is the key module of these systems, in which the License Plate\nLocalization (LPL) is the most important stage, because it determines the speed\nand robustness of this module. Thus, during this step the algorithm must\nprocess the image and overcome several constraints as climatic and lighting\nconditions, sensors and angles variety, LPs no-standardization, and the real\ntime processing. This paper presents a classification and comparison of License\nPlates Localization (LPL) algorithms and describes the advantages,\ndisadvantages and improvements made by each of them\n", "versions": [{"version": "v1", "created": "Wed, 28 Apr 2021 17:26:52 GMT"}], "update_date": "2021-05-12", "authors_parsed": [["Saidallah", "Mustapha", ""], ["Taki", "Fatimazahra", ""], ["Alaoui", "Abdelbaki El Belrhiti El", ""], ["Fergougui", "Abdeslam El", ""]]}, {"id": "2104.13901", "submitter": "Alex Devonport", "authors": "Alex Devonport, Adnane Saoud, and Murat Arcak", "title": "Symbolic Abstractions From Data: A PAC Learning Approach", "comments": "8 pages, 2 figures. Submitted to IEEE CDC 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Symbolic control techniques aim to satisfy complex logic specifications. A\ncritical step in these techniques is the construction of a symbolic (discrete)\nabstraction, a finite-state system whose behaviour mimics that of a given\ncontinuous-state system. The methods used to compute symbolic abstractions,\nhowever, require knowledge of an accurate closed-form model. To generalize them\nto systems with unknown dynamics, we present a new data-driven approach that\ndoes not require closed-form dynamics, instead relying only the ability to\nevaluate successors of each state under given inputs. To provide guarantees for\nthe learned abstraction, we use the Probably Approximately Correct (PAC)\nstatistical framework. We first introduce a PAC-style behavioural relationship\nand an appropriate refinement procedure. We then show how the symbolic\nabstraction can be constructed to satisfy this new behavioural relationship.\nMoreover, we provide PAC bounds that dictate the number of data required to\nguarantee a prescribed level of accuracy and confidence. Finally, we present an\nillustrative example.\n", "versions": [{"version": "v1", "created": "Wed, 28 Apr 2021 17:34:28 GMT"}], "update_date": "2021-04-29", "authors_parsed": [["Devonport", "Alex", ""], ["Saoud", "Adnane", ""], ["Arcak", "Murat", ""]]}, {"id": "2104.13906", "submitter": "Brad Knox", "authors": "W. Bradley Knox, Alessandro Allievi, Holger Banzhaf, Felix Schmitt,\n  Peter Stone", "title": "Reward (Mis)design for Autonomous Driving", "comments": "13 pages (25 pages with appendix), 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers the problem of reward design for autonomous driving\n(AD), with insights that are also applicable to the design of cost functions\nand performance metrics more generally. Herein we develop 8 simple sanity\nchecks for identifying flaws in reward functions. The sanity checks are applied\nto reward functions from past work on reinforcement learning (RL) for\nautonomous driving, revealing near-universal flaws in reward design for AD that\nmight also exist pervasively across reward design for other tasks. Lastly, we\nexplore promising directions that may help future researchers design reward\nfunctions for AD.\n", "versions": [{"version": "v1", "created": "Wed, 28 Apr 2021 17:41:35 GMT"}], "update_date": "2021-04-29", "authors_parsed": [["Knox", "W. Bradley", ""], ["Allievi", "Alessandro", ""], ["Banzhaf", "Holger", ""], ["Schmitt", "Felix", ""], ["Stone", "Peter", ""]]}, {"id": "2104.13907", "submitter": "Trevor Ablett", "authors": "Trevor Ablett, Yifan Zhai, Jonathan Kelly", "title": "Seeing All the Angles: Learning Multiview Manipulation Policies for\n  Contact-Rich Tasks from Demonstrations", "comments": "To appear in the IEEE/RSJ International Conference on Intelligent\n  Robots and Systems (IROS 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learned visuomotor policies have shown considerable success as an alternative\nto traditional, hand-crafted frameworks for robotic manipulation. Surprisingly,\nan extension of these methods to the multiview domain is relatively unexplored.\nA successful multiview policy could be deployed on a mobile manipulation\nplatform, allowing the robot to complete a task regardless of its view of the\nscene. In this work, we demonstrate that a multiview policy can be found\nthrough imitation learning by collecting data from a variety of viewpoints. We\nillustrate the general applicability of the method by learning to complete\nseveral challenging multi-stage and contact-rich tasks, from numerous\nviewpoints, both in a simulated environment and on a real mobile manipulation\nplatform. Furthermore, we analyze our policies to determine the benefits of\nlearning from multiview data compared to learning with data collected from a\nfixed perspective. We show that learning from multiview data results in little,\nif any, penalty to performance for a fixed-view task compared to learning with\nan equivalent amount of fixed-view data. Finally, we examine the visual\nfeatures learned by the multiview and fixed-view policies. Our results indicate\nthat multiview policies implicitly learn to identify spatially correlated\nfeatures.\n", "versions": [{"version": "v1", "created": "Wed, 28 Apr 2021 17:43:29 GMT"}, {"version": "v2", "created": "Fri, 16 Jul 2021 14:45:13 GMT"}], "update_date": "2021-07-19", "authors_parsed": [["Ablett", "Trevor", ""], ["Zhai", "Yifan", ""], ["Kelly", "Jonathan", ""]]}, {"id": "2104.13911", "submitter": "Przemyslaw Zielinski", "authors": "Przemyslaw Zielinski and Jan S. Hesthaven", "title": "Discovery of slow variables in a class of multiscale stochastic systems\n  via neural networks", "comments": "26 pages, 15 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.DS cs.LG cs.NA math.NA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Finding a reduction of complex, high-dimensional dynamics to its essential,\nlow-dimensional \"heart\" remains a challenging yet necessary prerequisite for\ndesigning efficient numerical approaches. Machine learning methods have the\npotential to provide a general framework to automatically discover such\nrepresentations. In this paper, we consider multiscale stochastic systems with\nlocal slow-fast time scale separation and propose a new method to encode in an\nartificial neural network a map that extracts the slow representation from the\nsystem. The architecture of the network consists of an encoder-decoder pair\nthat we train in a supervised manner to learn the appropriate low-dimensional\nembedding in the bottleneck layer. We test the method on a number of examples\nthat illustrate the ability to discover a correct slow representation.\nMoreover, we provide an error measure to assess the quality of the embedding\nand demonstrate that pruning the network can pinpoint an essential coordinates\nof the system to build the slow representation.\n", "versions": [{"version": "v1", "created": "Wed, 28 Apr 2021 17:48:25 GMT"}, {"version": "v2", "created": "Thu, 6 May 2021 16:56:37 GMT"}], "update_date": "2021-05-07", "authors_parsed": [["Zielinski", "Przemyslaw", ""], ["Hesthaven", "Jan S.", ""]]}, {"id": "2104.13915", "submitter": "Krzysztof Maziarz", "authors": "Krzysztof Maziarz, Anna Krason, Zbigniew Wojna", "title": "Deep Learning for Rheumatoid Arthritis: Joint Detection and Damage\n  Scoring in X-rays", "comments": "Presented at the Workshop on AI for Public Health at ICLR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advancements in computer vision promise to automate medical image\nanalysis. Rheumatoid arthritis is an autoimmune disease that would profit from\ncomputer-based diagnosis, as there are no direct markers known, and doctors\nhave to rely on manual inspection of X-ray images. In this work, we present a\nmulti-task deep learning model that simultaneously learns to localize joints on\nX-ray images and diagnose two kinds of joint damage: narrowing and erosion.\nAdditionally, we propose a modification of label smoothing, which combines\nclassification and regression cues into a single loss and achieves 5% relative\nerror reduction compared to standard loss functions. Our final model obtained\n4th place in joint space narrowing and 5th place in joint erosion in the global\nRA2 DREAM challenge.\n", "versions": [{"version": "v1", "created": "Wed, 28 Apr 2021 17:53:19 GMT"}], "update_date": "2021-04-29", "authors_parsed": [["Maziarz", "Krzysztof", ""], ["Krason", "Anna", ""], ["Wojna", "Zbigniew", ""]]}, {"id": "2104.13921", "submitter": "Xiuye Gu", "authors": "Xiuye Gu, Tsung-Yi Lin, Weicheng Kuo, Yin Cui", "title": "Zero-Shot Detection via Vision and Language Knowledge Distillation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Zero-shot image classification has made promising progress by training the\naligned image and text encoders. The goal of this work is to advance zero-shot\nobject detection, which aims to detect novel objects without bounding box nor\nmask annotations. We propose ViLD, a training method via Vision and Language\nknowledge Distillation. We distill the knowledge from a pre-trained zero-shot\nimage classification model (e.g., CLIP) into a two-stage detector (e.g., Mask\nR-CNN). Our method aligns the region embeddings in the detector to the text and\nimage embeddings inferred by the pre-trained model. We use the text embeddings\nas the detection classifier, obtained by feeding category names into the\npre-trained text encoder. We then minimize the distance between the region\nembeddings and image embeddings, obtained by feeding region proposals into the\npre-trained image encoder. During inference, we include text embeddings of\nnovel categories into the detection classifier for zero-shot detection. We\nbenchmark the performance on LVIS dataset by holding out all rare categories as\nnovel categories. ViLD obtains 16.1 mask AP$_r$ with a Mask R-CNN (ResNet-50\nFPN) for zero-shot detection, outperforming the supervised counterpart by 3.8.\nThe model can directly transfer to other datasets, achieving 72.2 AP$_{50}$,\n36.6 AP and 11.8 AP on PASCAL VOC, COCO and Objects365, respectively.\n", "versions": [{"version": "v1", "created": "Wed, 28 Apr 2021 17:58:57 GMT"}], "update_date": "2021-04-29", "authors_parsed": [["Gu", "Xiuye", ""], ["Lin", "Tsung-Yi", ""], ["Kuo", "Weicheng", ""], ["Cui", "Yin", ""]]}, {"id": "2104.13936", "submitter": "Tianze Shi", "authors": "Tianze Shi, Adrian Benton, Igor Malioutov, Ozan \\.Irsoy", "title": "Diversity-Aware Batch Active Learning for Dependency Parsing", "comments": "NAACL 2021", "journal-ref": "In Proceedings of NAACL 2021", "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While the predictive performance of modern statistical dependency parsers\nrelies heavily on the availability of expensive expert-annotated treebank data,\nnot all annotations contribute equally to the training of the parsers. In this\npaper, we attempt to reduce the number of labeled examples needed to train a\nstrong dependency parser using batch active learning (AL). In particular, we\ninvestigate whether enforcing diversity in the sampled batches, using\ndeterminantal point processes (DPPs), can improve over their diversity-agnostic\ncounterparts. Simulation experiments on an English newswire corpus show that\nselecting diverse batches with DPPs is superior to strong selection strategies\nthat do not enforce batch diversity, especially during the initial stages of\nthe learning process. Additionally, our diversityaware strategy is robust under\na corpus duplication setting, where diversity-agnostic sampling strategies\nexhibit significant degradation.\n", "versions": [{"version": "v1", "created": "Wed, 28 Apr 2021 18:00:05 GMT"}], "update_date": "2021-04-30", "authors_parsed": [["Shi", "Tianze", ""], ["Benton", "Adrian", ""], ["Malioutov", "Igor", ""], ["\u0130rsoy", "Ozan", ""]]}, {"id": "2104.13950", "submitter": "Zafiirah Hosenie", "authors": "Zafiirah Hosenie, Steven Bloemen, Paul Groot, Robert Lyon, Bart\n  Scheers, Benjamin Stappers, Fiorenzo Stoppa, Paul Vreeswijk, Simon De Wet,\n  Marc Klein Wolt, Elmar K\\\"ording, Vanessa McBride, Rudolf Le Poole, Kerry\n  Paterson, Dani\\\"elle L. A. Pieterse and Patrick Woudt", "title": "MeerCRAB: MeerLICHT Classification of Real and Bogus Transients using\n  Deep Learning", "comments": "15 pages, 13 figures, Accepted for publication in Experimental\n  Astronomy and appeared in the 3rd Workshop on Machine Learning and the\n  Physical Sciences, NeurIPS 2020", "journal-ref": "Exp Astron (2021)", "doi": "10.1007/s10686-021-09757-1", "report-no": null, "categories": "astro-ph.IM astro-ph.GA cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Astronomers require efficient automated detection and classification\npipelines when conducting large-scale surveys of the (optical) sky for variable\nand transient sources. Such pipelines are fundamentally important, as they\npermit rapid follow-up and analysis of those detections most likely to be of\nscientific value. We therefore present a deep learning pipeline based on the\nconvolutional neural network architecture called $\\texttt{MeerCRAB}$. It is\ndesigned to filter out the so called 'bogus' detections from true astrophysical\nsources in the transient detection pipeline of the MeerLICHT telescope. Optical\ncandidates are described using a variety of 2D images and numerical features\nextracted from those images. The relationship between the input images and the\ntarget classes is unclear, since the ground truth is poorly defined and often\nthe subject of debate. This makes it difficult to determine which source of\ninformation should be used to train a classification algorithm. We therefore\nused two methods for labelling our data (i) thresholding and (ii) latent class\nmodel approaches. We deployed variants of $\\texttt{MeerCRAB}$ that employed\ndifferent network architectures trained using different combinations of input\nimages and training set choices, based on classification labels provided by\nvolunteers. The deepest network worked best with an accuracy of 99.5$\\%$ and\nMatthews correlation coefficient (MCC) value of 0.989. The best model was\nintegrated to the MeerLICHT transient vetting pipeline, enabling the accurate\nand efficient classification of detected transients that allows researchers to\nselect the most promising candidates for their research goals.\n", "versions": [{"version": "v1", "created": "Wed, 28 Apr 2021 18:12:51 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Hosenie", "Zafiirah", ""], ["Bloemen", "Steven", ""], ["Groot", "Paul", ""], ["Lyon", "Robert", ""], ["Scheers", "Bart", ""], ["Stappers", "Benjamin", ""], ["Stoppa", "Fiorenzo", ""], ["Vreeswijk", "Paul", ""], ["De Wet", "Simon", ""], ["Wolt", "Marc Klein", ""], ["K\u00f6rding", "Elmar", ""], ["McBride", "Vanessa", ""], ["Poole", "Rudolf Le", ""], ["Paterson", "Kerry", ""], ["Pieterse", "Dani\u00eblle L. A.", ""], ["Woudt", "Patrick", ""]]}, {"id": "2104.13958", "submitter": "Pradip Kumar Gautam", "authors": "Pradip Kumar Gautam and Deweshvar Singh", "title": "Defined the predictors of the lightning over India by using artificial\n  neural network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.ao-ph cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Lightning casualties cause tremendous loss to life and property. However,\nvery lately lightning has been considered as one of the major natural\ncalamities which is now studied or monitored with proper instrumentation. The\nlightning characteristics over India have been studying by using daily data low\nresolution time series and monthly data high resolution monthly climatology. We\nhave used ANN time series method (a neural network) to analyze the time series\nand defined which one will be the best predictor of lightning over India. The\ntime series of lightning is output(dependent) and input (independent) are\nk-index, AOD, Cape etc. The Gaussian process regression, support vector\nmachine, regression trees and linear regression defined the input variables.\nWhich show approximately linear relation.\n", "versions": [{"version": "v1", "created": "Wed, 28 Apr 2021 18:29:51 GMT"}], "update_date": "2021-04-30", "authors_parsed": [["Gautam", "Pradip Kumar", ""], ["Singh", "Deweshvar", ""]]}, {"id": "2104.13962", "submitter": "Sourav Dutta", "authors": "Sourav Dutta, Peter Rivera-Casillas, Matthew W. Farthing", "title": "Neural Ordinary Differential Equations for Data-Driven Reduced Order\n  Modeling of Environmental Hydrodynamics", "comments": "10 pages, 6 figures, To Appear in Proceedings of AAAI 2021 Spring\n  Symposium on Combining Artificial Intelligence and Machine Learning with\n  Physics Sciences, March 22-24, 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG physics.comp-ph", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Model reduction for fluid flow simulation continues to be of great interest\nacross a number of scientific and engineering fields. Here, we explore the use\nof Neural Ordinary Differential Equations, a recently introduced family of\ncontinuous-depth, differentiable networks (Chen et al 2018), as a way to\npropagate latent-space dynamics in reduced order models. We compare their\nbehavior with two classical non-intrusive methods based on proper orthogonal\ndecomposition and radial basis function interpolation as well as dynamic mode\ndecomposition. The test problems we consider include incompressible flow around\na cylinder as well as real-world applications of shallow water hydrodynamics in\nriverine and estuarine systems. Our findings indicate that Neural ODEs provide\nan elegant framework for stable and accurate evolution of latent-space dynamics\nwith a promising potential of extrapolatory predictions. However, in order to\nfacilitate their widespread adoption for large-scale systems, significant\neffort needs to be directed at accelerating their training times. This will\nenable a more comprehensive exploration of the hyperparameter space for\nbuilding generalizable Neural ODE approximations over a wide range of system\ndynamics.\n", "versions": [{"version": "v1", "created": "Thu, 22 Apr 2021 19:20:47 GMT"}], "update_date": "2021-04-30", "authors_parsed": [["Dutta", "Sourav", ""], ["Rivera-Casillas", "Peter", ""], ["Farthing", "Matthew W.", ""]]}, {"id": "2104.13963", "submitter": "Mahmoud Assran", "authors": "Mahmoud Assran, Mathilde Caron, Ishan Misra, Piotr Bojanowski, Armand\n  Joulin, Nicolas Ballas, Michael Rabbat", "title": "Semi-Supervised Learning of Visual Features by Non-Parametrically\n  Predicting View Assignments with Support Samples", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a novel method of learning by predicting view assignments\nwith support samples (PAWS). The method trains a model to minimize a\nconsistency loss, which ensures that different views of the same unlabeled\ninstance are assigned similar pseudo-labels. The pseudo-labels are generated\nnon-parametrically, by comparing the representations of the image views to\nthose of a set of randomly sampled labeled images. The distance between the\nview representations and labeled representations is used to provide a weighting\nover class labels, which we interpret as a soft pseudo-label. By\nnon-parametrically incorporating labeled samples in this way, PAWS extends the\ndistance-metric loss used in self-supervised methods such as BYOL and SwAV to\nthe semi-supervised setting. Despite the simplicity of the approach, PAWS\noutperforms other semi-supervised methods across architectures, setting a new\nstate-of-the-art for a ResNet-50 on ImageNet trained with either 10% or 1% of\nthe labels, reaching 75.5% and 66.5% top-1 respectively. PAWS requires 4x to\n12x less training than the previous best methods.\n", "versions": [{"version": "v1", "created": "Wed, 28 Apr 2021 18:44:07 GMT"}, {"version": "v2", "created": "Thu, 27 May 2021 03:02:09 GMT"}], "update_date": "2021-05-28", "authors_parsed": [["Assran", "Mahmoud", ""], ["Caron", "Mathilde", ""], ["Misra", "Ishan", ""], ["Bojanowski", "Piotr", ""], ["Joulin", "Armand", ""], ["Ballas", "Nicolas", ""], ["Rabbat", "Michael", ""]]}, {"id": "2104.13968", "submitter": "Gurpreet Singh", "authors": "Gurpreet Singh and Soumyajit Gupta", "title": "Tail-Net: Extracting Lowest Singular Triplets for Big Data Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  SVD serves as an exploratory tool in identifying the dominant features in the\nform of top rank-r singular factors corresponding to the largest singular\nvalues. For Big Data applications it is well known that Singular Value\nDecomposition (SVD) is restrictive due to main memory requirements. However, a\nnumber of applications such as community detection, clustering, or bottleneck\nidentification in large scale graph data-sets rely upon identifying the lowest\nsingular values and the singular corresponding vectors. For example, the lowest\nsingular values of a graph Laplacian reveal the number of isolated clusters\n(zero singular values) or bottlenecks (lowest non-zero singular values) for\nundirected, acyclic graphs. A naive approach here would be to perform a full\nSVD however, this quickly becomes infeasible for practical big data\napplications due to the enormous memory requirements. Furthermore, for such\napplications only a few lowest singular factors are desired making a full\ndecomposition computationally exorbitant. In this work, we trivially extend the\npreviously proposed Range-Net to \\textbf{Tail-Net} for a memory and compute\nefficient extraction of lowest singular factors of a given big dataset and a\nspecified rank-r. We present a number of numerical experiments on both\nsynthetic and practical data-sets for verification and bench-marking using\nconventional SVD as the baseline.\n", "versions": [{"version": "v1", "created": "Wed, 28 Apr 2021 19:17:34 GMT"}], "update_date": "2021-04-30", "authors_parsed": [["Singh", "Gurpreet", ""], ["Gupta", "Soumyajit", ""]]}, {"id": "2104.13969", "submitter": "Ryan Sander", "authors": "Jan Petrich, Ryan Sander, Eliza Bradley, Adam Dawood, Shawn Hough", "title": "On the Importance of 3D Surface Information for Remote Sensing\n  Classification Tasks", "comments": "Accepted to CODATA Data Science Journal", "journal-ref": null, "doi": "10.5334/dsj-2021-020", "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  There has been a surge in remote sensing machine learning applications that\noperate on data from active or passive sensors as well as multi-sensor\ncombinations (Ma et al. (2019)). Despite this surge, however, there has been\nrelatively little study on the comparative value of 3D surface information for\nmachine learning classification tasks. Adding 3D surface information to RGB\nimagery can provide crucial geometric information for semantic classes such as\nbuildings, and can thus improve out-of-sample predictive performance. In this\npaper, we examine in-sample and out-of-sample classification performance of\nFully Convolutional Neural Networks (FCNNs) and Support Vector Machines (SVMs)\ntrained with and without 3D normalized digital surface model (nDSM)\ninformation. We assess classification performance using multispectral imagery\nfrom the International Society for Photogrammetry and Remote Sensing (ISPRS) 2D\nSemantic Labeling contest and the United States Special Operations Command\n(USSOCOM) Urban 3D Challenge. We find that providing RGB classifiers with\nadditional 3D nDSM information results in little increase in in-sample\nclassification performance, suggesting that spectral information alone may be\nsufficient for the given classification tasks. However, we observe that\nproviding these RGB classifiers with additional nDSM information leads to\nsignificant gains in out-of-sample predictive performance. Specifically, we\nobserve an average improvement in out-of-sample all-class accuracy of 14.4% on\nthe ISPRS dataset and an average improvement in out-of-sample F1 score of 8.6%\non the USSOCOM dataset. In addition, the experiments establish that nDSM\ninformation is critical in machine learning and classification settings that\nface training sample scarcity.\n", "versions": [{"version": "v1", "created": "Mon, 26 Apr 2021 19:55:51 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Petrich", "Jan", ""], ["Sander", "Ryan", ""], ["Bradley", "Eliza", ""], ["Dawood", "Adam", ""], ["Hough", "Shawn", ""]]}, {"id": "2104.13970", "submitter": "Quan Wang", "authors": "Rajeev Rikhye, Quan Wang, Qiao Liang, Yanzhang He, Ding Zhao, Yiteng\n  (Arden) Huang, Arun Narayanan, Ian McGraw", "title": "Personalized Keyphrase Detection using Speaker and Environment\n  Information", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce a streaming keyphrase detection system that can\nbe easily customized to accurately detect any phrase composed of words from a\nlarge vocabulary. The system is implemented with an end-to-end trained\nautomatic speech recognition (ASR) model and a text-independent speaker\nverification model. To address the challenge of detecting these keyphrases\nunder various noisy conditions, a speaker separation model is added to the\nfeature frontend of the speaker verification model, and an adaptive noise\ncancellation (ANC) algorithm is included to exploit cross-microphone noise\ncoherence. Our experiments show that the text-independent speaker verification\nmodel largely reduces the false triggering rate of the keyphrase detection,\nwhile the speaker separation model and adaptive noise cancellation largely\nreduce false rejections.\n", "versions": [{"version": "v1", "created": "Wed, 28 Apr 2021 18:50:19 GMT"}, {"version": "v2", "created": "Tue, 15 Jun 2021 15:38:06 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Rikhye", "Rajeev", "", "Arden"], ["Wang", "Quan", "", "Arden"], ["Liang", "Qiao", "", "Arden"], ["He", "Yanzhang", "", "Arden"], ["Zhao", "Ding", "", "Arden"], ["Yiteng", "", "", "Arden"], ["Huang", "", ""], ["Narayanan", "Arun", ""], ["McGraw", "Ian", ""]]}, {"id": "2104.13971", "submitter": "Ryosuke Motegi", "authors": "Ryosuke Motegi and Yoichi Seki", "title": "SMLSOM: The shrinking maximum likelihood self-organizing map", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Determining the number of clusters in a dataset is a fundamental issue in\ndata clustering. Many methods have been proposed to solve the problem of\nselecting the number of clusters, considering it to be a problem with regard to\nmodel selection. This paper proposes a greedy algorithm that automatically\nselects a suitable number of clusters based on a probability distribution model\nframework. The algorithm includes two components. First, a generalization of\nKohonen's self-organizing map (SOM), which has nodes linked to a probability\ndistribution model, and which enables the algorithm to search for the winner\nbased on the likelihood of each node, is introduced. Second, the proposed\nmethod uses a graph structure and a neighbor defined by the length of the\nshortest path between nodes, in contrast to Kohonen's SOM in which the nodes\nare fixed in the Euclidean space. This implementation makes it possible to\nupdate its graph structure by cutting links to weakly connected nodes to avoid\nunnecessary node deletion. The weakness of a node connection is measured using\nthe Kullback--Leibler divergence and the redundancy of a node is measured by\nthe minimum description length (MDL). This updating step makes it easy to\ndetermine the suitable number of clusters. Compared with existing methods, our\nproposed method is computationally efficient and can accurately select the\nnumber of clusters and perform clustering.\n", "versions": [{"version": "v1", "created": "Wed, 28 Apr 2021 18:50:36 GMT"}], "update_date": "2021-04-30", "authors_parsed": [["Motegi", "Ryosuke", ""], ["Seki", "Yoichi", ""]]}, {"id": "2104.13981", "submitter": "Jordan Cambe PhD", "authors": "Jordan Cambe, Krittika D'Silva, Anastasios Noulas, Cecilia Mascolo,\n  Adam Waksman", "title": "Modelling Cooperation and Competition in Urban Retail Ecosystems with\n  Complex Network Metrics", "comments": "11 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.soc-ph cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding the impact that a new business has on the local market\necosystem is a challenging task as it is multifaceted in nature. Past work in\nthis space has examined the collaborative or competitive role of homogeneous\nvenue types (i.e. the impact of a new bookstore on existing bookstores).\nHowever, these prior works have been limited in their scope and explanatory\npower. To better measure retail performance in a modern city, a model should\nconsider a number of factors that interact synchronously. This paper is the\nfirst which considers the multifaceted types of interactions that occur in\nurban cities when examining the impact of new businesses. We first present a\nmodeling framework which examines the role of new businesses in their\nrespective local areas. Using a longitudinal dataset from location technology\nplatform Foursquare, we model new venue impact across 26 major cities\nworldwide. Representing cities as connected networks of venues, we quantify\ntheir structure and characterise their dynamics over time. We note a strong\ncommunity structure emerging in these retail networks, an observation that\nhighlights the interplay of cooperative and competitive forces that emerge in\nlocal ecosystems of retail establishments. We next devise a data-driven metric\nthat captures the first-order correlation on the impact of a new venue on\nretailers within its vicinity accounting for both homogeneous and heterogeneous\ninteractions between venue types. Lastly, we build a supervised machine\nlearning model to predict the impact of a given new venue on its local retail\necosystem. Our approach highlights the power of complex network measures in\nbuilding machine learning prediction models. These models have numerous\napplications within the retail sector and can support policymakers, business\nowners, and urban planners in the development of models to characterize and\npredict changes in urban settings.\n", "versions": [{"version": "v1", "created": "Wed, 28 Apr 2021 19:18:23 GMT"}], "update_date": "2021-04-30", "authors_parsed": [["Cambe", "Jordan", ""], ["D'Silva", "Krittika", ""], ["Noulas", "Anastasios", ""], ["Mascolo", "Cecilia", ""], ["Waksman", "Adam", ""]]}, {"id": "2104.14006", "submitter": "Christos Kyrkou", "authors": "Christos Kyrkou and Theocharis Theocharides", "title": "EmergencyNet: Efficient Aerial Image Classification for Drone-Based\n  Emergency Monitoring Using Atrous Convolutional Feature Fusion", "comments": "C.Kyrkou and T. Theocharides, \"EmergencyNet: Efficient Aerial Image\n  Classification for Drone-Based Emergency Monitoring Using Atrous\n  Convolutional Feature Fusion,\" in IEEE J Sel Top Appl Earth Obs Remote Sens.\n  (JSTARS), vol. 13, pp. 1687-1699, 2020. arXiv admin note: substantial text\n  overlap with arXiv:1906.08716", "journal-ref": "IEEE Journal of Selected Topics in Applied Earth Observations and\n  Remote Sensing ( Volume: 13), Page(s): 1687 - 1699, 2020", "doi": "10.1109/JSTARS.2020.2969809", "report-no": null, "categories": "cs.CV cs.LG cs.RO", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Deep learning-based algorithms can provide state-of-the-art accuracy for\nremote sensing technologies such as unmanned aerial vehicles (UAVs)/drones,\npotentially enhancing their remote sensing capabilities for many emergency\nresponse and disaster management applications. In particular, UAVs equipped\nwith camera sensors can operating in remote and difficult to access\ndisaster-stricken areas, analyze the image and alert in the presence of various\ncalamities such as collapsed buildings, flood, or fire in order to faster\nmitigate their effects on the environment and on human population. However, the\nintegration of deep learning introduces heavy computational requirements,\npreventing the deployment of such deep neural networks in many scenarios that\nimpose low-latency constraints on inference, in order to make mission-critical\ndecisions in real time. To this end, this article focuses on the efficient\naerial image classification from on-board a UAV for emergency\nresponse/monitoring applications. Specifically, a dedicated Aerial Image\nDatabase for Emergency Response applications is introduced and a comparative\nanalysis of existing approaches is performed. Through this analysis a\nlightweight convolutional neural network architecture is proposed, referred to\nas EmergencyNet, based on atrous convolutions to process multiresolution\nfeatures and capable of running efficiently on low-power embedded platforms\nachieving upto 20x higher performance compared to existing models with minimal\nmemory requirements with less than 1% accuracy drop compared to\nstate-of-the-art models.\n", "versions": [{"version": "v1", "created": "Wed, 28 Apr 2021 20:24:10 GMT"}], "update_date": "2021-04-30", "authors_parsed": [["Kyrkou", "Christos", ""], ["Theocharides", "Theocharis", ""]]}, {"id": "2104.14012", "submitter": "Leszek Szczecinski", "authors": "Leszek Szczecinski and Rapha\\\"elle Tihon", "title": "Simplified Kalman filter for online rating: one-fits-all approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this work, we deal with the problem of rating in sports, where the skills\nof the players/teams are inferred from the observed outcomes of the games. Our\nfocus is on the online rating algorithms which estimate the skills after each\nnew game by exploiting the probabilistic models of the relationship between the\nskills and the game outcome. We propose a Bayesian approach which may be seen\nas an approximate Kalman filter and which is generic in the sense that it can\nbe used with any skills-outcome model and can be applied in the individual --\nas well as in the group-sports. We show how the well-know algorithms (such as\nthe Elo, the Glicko, and the TrueSkill algorithms) may be seen as instances of\nthe one-fits-all approach we propose. In order to clarify the conditions under\nwhich the gains of the Bayesian approach over the simpler solutions can\nactually materialize, we critically compare the known and the new algorithms by\nmeans of numerical examples using the synthetic as well as the empirical data.\n", "versions": [{"version": "v1", "created": "Wed, 28 Apr 2021 20:44:10 GMT"}], "update_date": "2021-04-30", "authors_parsed": [["Szczecinski", "Leszek", ""], ["Tihon", "Rapha\u00eblle", ""]]}, {"id": "2104.14014", "submitter": "William Blanzeisky", "authors": "William Blanzeisky, P\\'adraig Cunningham", "title": "Algorithmic Factors Influencing Bias in Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  It is fair to say that many of the prominent examples of bias in Machine\nLearning (ML) arise from bias that is there in the training data. In fact, some\nwould argue that supervised ML algorithms cannot be biased, they reflect the\ndata on which they are trained. In this paper we demonstrate how ML algorithms\ncan misrepresent the training data through underestimation. We show how\nirreducible error, regularization and feature and class imbalance can\ncontribute to this underestimation. The paper concludes with a demonstration of\nhow the careful management of synthetic counterfactuals can ameliorate the\nimpact of this underestimation bias.\n", "versions": [{"version": "v1", "created": "Wed, 28 Apr 2021 20:45:41 GMT"}], "update_date": "2021-04-30", "authors_parsed": [["Blanzeisky", "William", ""], ["Cunningham", "P\u00e1draig", ""]]}, {"id": "2104.14028", "submitter": "Pengyu Li", "authors": "Ryan Budahazy, Lu Cheng, Yihuan Huang, Andrew Johnson, Pengyu Li,\n  Joshua Vendrow, Zhoutong Wu, Denali Molitor, Elizaveta Rebrova, Deanna\n  Needell", "title": "Analysis of Legal Documents via Non-negative Matrix Factorization\n  Methods", "comments": "16 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The California Innocence Project (CIP), a clinical law school program aiming\nto free wrongfully convicted prisoners, evaluates thousands of mails containing\nnew requests for assistance and corresponding case files. Processing and\ninterpreting this large amount of information presents a significant challenge\nfor CIP officials, which can be successfully aided by topic modeling\ntechniques.In this paper, we apply Non-negative Matrix Factorization (NMF)\nmethod and implement various offshoots of it to the important and previously\nunstudied data set compiled by CIP. We identify underlying topics of existing\ncase files and classify request files by crime type and case status (decision\ntype). The results uncover the semantic structure of current case files and can\nprovide CIP officials with a general understanding of newly received case files\nbefore further examinations. We also provide an exposition of popular variants\nof NMF with their experimental results and discuss the benefits and drawbacks\nof each variant through the real-world application.\n", "versions": [{"version": "v1", "created": "Wed, 28 Apr 2021 21:32:22 GMT"}], "update_date": "2021-04-30", "authors_parsed": [["Budahazy", "Ryan", ""], ["Cheng", "Lu", ""], ["Huang", "Yihuan", ""], ["Johnson", "Andrew", ""], ["Li", "Pengyu", ""], ["Vendrow", "Joshua", ""], ["Wu", "Zhoutong", ""], ["Molitor", "Denali", ""], ["Rebrova", "Elizaveta", ""], ["Needell", "Deanna", ""]]}, {"id": "2104.14029", "submitter": "Krishanu Sarker", "authors": "Krishanu Sarker, Sharbani Pandit, Anupam Sarker, Saeid Belkasim and\n  Shihao Ji", "title": "Reducing Risk and Uncertainty of Deep Neural Networks on Diagnosing\n  COVID-19 Infection", "comments": "AAAI, TAIH workshop, 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Effective and reliable screening of patients via Computer-Aided Diagnosis can\nplay a crucial part in the battle against COVID-19. Most of the existing works\nfocus on developing sophisticated methods yielding high detection performance,\nyet not addressing the issue of predictive uncertainty. In this work, we\nintroduce uncertainty estimation to detect confusing cases for expert referral\nto address the unreliability of state-of-the-art (SOTA) DNNs on COVID-19\ndetection. To the best of our knowledge, we are the first to address this issue\non the COVID-19 detection problem. In this work, we investigate a number of\nSOTA uncertainty estimation methods on publicly available COVID dataset and\npresent our experimental findings. In collaboration with medical professionals,\nwe further validate the results to ensure the viability of the best performing\nmethod in clinical practice.\n", "versions": [{"version": "v1", "created": "Wed, 28 Apr 2021 21:36:25 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Sarker", "Krishanu", ""], ["Pandit", "Sharbani", ""], ["Sarker", "Anupam", ""], ["Belkasim", "Saeid", ""], ["Ji", "Shihao", ""]]}, {"id": "2104.14033", "submitter": "Anirbit Mukherjee", "authors": "Anirbit Mukherjee", "title": "A Study of the Mathematics of Deep Learning", "comments": "(A) Our PAC-Bayes risk bounds on neural nets given in Section 6 here\n  does not yet occur in any other file on arXiv. (B) In our paper\n  arXiv:/2005.04211, there is a significantly improved version of Section 3.3\n  of this thesis", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.AP stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  \"Deep Learning\"/\"Deep Neural Nets\" is a technological marvel that is now\nincreasingly deployed at the cutting-edge of artificial intelligence tasks.\nThis dramatic success of deep learning in the last few years has been hinged on\nan enormous amount of heuristics and it has turned out to be a serious\nmathematical challenge to be able to rigorously explain them. In this thesis,\nsubmitted to the Department of Applied Mathematics and Statistics, Johns\nHopkins University we take several steps towards building strong theoretical\nfoundations for these new paradigms of deep-learning. In chapter 2 we show new\ncircuit complexity theorems for deep neural functions and prove classification\ntheorems about these function spaces which in turn lead to exact algorithms for\nempirical risk minimization for depth 2 ReLU nets. We also motivate a measure\nof complexity of neural functions to constructively establish the existence of\nhigh-complexity neural functions. In chapter 3 we give the first algorithm\nwhich can train a ReLU gate in the realizable setting in linear time in an\nalmost distribution free set up. In chapter 4 we give rigorous proofs towards\nexplaining the phenomenon of autoencoders being able to do sparse-coding. In\nchapter 5 we give the first-of-its-kind proofs of convergence for stochastic\nand deterministic versions of the widely used adaptive gradient deep-learning\nalgorithms, RMSProp and ADAM. This chapter also includes a detailed empirical\nstudy on autoencoders of the hyper-parameter values at which modern algorithms\nhave a significant advantage over classical acceleration based methods. In the\nlast chapter 6 we give new and improved PAC-Bayesian bounds for the risk of\nstochastic neural nets. This chapter also includes an experimental\ninvestigation revealing new geometric properties of the paths in weight space\nthat are traced out by the net during the training.\n", "versions": [{"version": "v1", "created": "Wed, 28 Apr 2021 22:05:54 GMT"}], "update_date": "2021-04-30", "authors_parsed": [["Mukherjee", "Anirbit", ""]]}, {"id": "2104.14034", "submitter": "Gabriel Barros", "authors": "Gabriel F. Barros, Mal\\'u Grave, Alex Viguerie, Alessandro Reali,\n  Alvaro L. G. A. Coutinho", "title": "Dynamic Mode Decomposition in Adaptive Mesh Refinement and Coarsening\n  Simulations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dynamic Mode Decomposition (DMD) is a powerful data-driven method used to\nextract spatio-temporal coherent structures that dictate a given dynamical\nsystem. The method consists of stacking collected temporal snapshots into a\nmatrix and mapping the nonlinear dynamics using a linear operator. The standard\nprocedure considers that snapshots possess the same dimensionality for all the\nobservable data. However, this often does not occur in numerical simulations\nwith adaptive mesh refinement/coarsening schemes (AMR/C). This paper proposes a\nstrategy to enable DMD to extract features from observations with different\nmesh topologies and dimensions, such as those found in AMR/C simulations. For\nthis purpose, the adaptive snapshots are projected onto the same reference\nfunction space, enabling the use of snapshot-based methods such as DMD. The\npresent strategy is applied to challenging AMR/C simulations: a continuous\ndiffusion-reaction epidemiological model for COVID-19, a density-driven gravity\ncurrent simulation, and a bubble rising problem. We also evaluate the DMD\nefficiency to reconstruct the dynamics and some relevant quantities of\ninterest. In particular, for the SEIRD model and the bubble rising problem, we\nevaluate DMD's ability to extrapolate in time (short-time future estimates).\n", "versions": [{"version": "v1", "created": "Wed, 28 Apr 2021 22:14:25 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Barros", "Gabriel F.", ""], ["Grave", "Mal\u00fa", ""], ["Viguerie", "Alex", ""], ["Reali", "Alessandro", ""], ["Coutinho", "Alvaro L. G. A.", ""]]}, {"id": "2104.14045", "submitter": "Denis Stanev", "authors": "Denis Stanev, Riccardo Riva, Michele Umassi", "title": "Deep Neural Network as an alternative to Boosted Decision Trees for PID", "comments": "9 pages, 6 figures. The code can be found at\n  https://github.com/Denis-Stanev/DNN-vs-BDT . The data file can be found here:\n  https://archive.ics.uci.edu/ml/datasets/MiniBooNE+particle+identification", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.data-an cs.LG physics.comp-ph", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper we recreate, and improve, the binary classification method for\nparticles proposed in Roe et al. (2005) paper \"Boosted decision trees as an\nalternative to artificial neural networks for particle identification\". Such\nparticles are tau neutrinos, which we will refer to as background, and\nelectronic neutrinos: the signal we are interested in. In the original paper\nthe preferred algorithm is a Boosted decision tree. This is due to its low\neffort tuning and good overall performance at the time. Our choice for\nimplementation is a deep neural network, faster and more promising in\nperformance. We will show how, using modern techniques, we are able to improve\non the original result, both in accuracy and in training time.\n", "versions": [{"version": "v1", "created": "Wed, 28 Apr 2021 23:32:42 GMT"}], "update_date": "2021-04-30", "authors_parsed": [["Stanev", "Denis", ""], ["Riva", "Riccardo", ""], ["Umassi", "Michele", ""]]}, {"id": "2104.14049", "submitter": "Alessandro Salatiello", "authors": "Alessandro Salatiello and Martin A. Giese", "title": "Continuous Decoding of Daily-Life Hand Movements from Forearm Muscle\n  Activity for Enhanced Myoelectric Control of Hand Prostheses", "comments": "Accepted for publication in the Proceedings of the 2021 IEEE\n  International Joint Conference on Neural Networks (IJCNN 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  State-of-the-art motorized hand prostheses are endowed with actuators able to\nprovide independent and proportional control of as many as six degrees of\nfreedom (DOFs). The control signals are derived from residual electromyographic\n(EMG) activity, recorded concurrently from relevant forearm muscles.\nNevertheless, the functional mapping between forearm EMG activity and hand\nkinematics is only known with limited accuracy. Therefore, no robust method\nexists for the reliable computation of control signals for the independent and\nproportional actuation of more than two DOFs. A common approach to deal with\nthis limitation is to pre-program the prostheses for the execution of a\nrestricted number of behaviors (e.g., pinching, grasping, and wrist rotation)\nthat are activated by the detection of specific EMG activation patterns.\nHowever, this approach severely limits the range of activities users can\nperform with the prostheses during their daily living. In this work, we\nintroduce a novel method, based on a long short-term memory (LSTM) network, to\ncontinuously map forearm EMG activity onto hand kinematics. Critically, unlike\nprevious work, which often focuses on simple and highly controlled motor tasks,\nwe tested our method on a dataset of activities of daily living (ADLs): the\nKIN-MUS UJI dataset. To the best of our knowledge, ours is the first reported\nwork on the prediction of hand kinematics that uses this challenging dataset.\nRemarkably, we show that our network is able to generalize to novel untrained\nADLs. Our results suggest that the presented method is suitable for the\ngeneration of control signals for the independent and proportional actuation of\nthe multiple DOFs of state-of-the-art hand prostheses.\n", "versions": [{"version": "v1", "created": "Thu, 29 Apr 2021 00:11:32 GMT"}], "update_date": "2021-04-30", "authors_parsed": [["Salatiello", "Alessandro", ""], ["Giese", "Martin A.", ""]]}, {"id": "2104.14060", "submitter": "Yunxiang Zhao", "authors": "Yunxiang Zhao and Jianzhong Qi and Qingwei Liu and Rui Zhang", "title": "WGCN: Graph Convolutional Networks with Weighted Structural Features", "comments": null, "journal-ref": null, "doi": "10.1145/3404835.3462834", "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph structural information such as topologies or connectivities provides\nvaluable guidance for graph convolutional networks (GCNs) to learn nodes'\nrepresentations. Existing GCN models that capture nodes' structural information\nweight in- and out-neighbors equally or differentiate in- and out-neighbors\nglobally without considering nodes' local topologies. We observe that in- and\nout-neighbors contribute differently for nodes with different local topologies.\nTo explore the directional structural information for different nodes, we\npropose a GCN model with weighted structural features, named WGCN. WGCN first\ncaptures nodes' structural fingerprints via a direction and degree aware Random\nWalk with Restart algorithm, where the walk is guided by both edge direction\nand nodes' in- and out-degrees. Then, the interactions between nodes'\nstructural fingerprints are used as the weighted node structural features. To\nfurther capture nodes' high-order dependencies and graph geometry, WGCN embeds\ngraphs into a latent space to obtain nodes' latent neighbors and geometrical\nrelationships. Based on nodes' geometrical relationships in the latent space,\nWGCN differentiates latent, in-, and out-neighbors with an attention-based\ngeometrical aggregation. Experiments on transductive node classification tasks\nshow that WGCN outperforms the baseline models consistently by up to 17.07% in\nterms of accuracy on five benchmark datasets.\n", "versions": [{"version": "v1", "created": "Thu, 29 Apr 2021 00:50:06 GMT"}, {"version": "v2", "created": "Mon, 31 May 2021 14:17:20 GMT"}, {"version": "v3", "created": "Wed, 21 Jul 2021 05:07:21 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Zhao", "Yunxiang", ""], ["Qi", "Jianzhong", ""], ["Liu", "Qingwei", ""], ["Zhang", "Rui", ""]]}, {"id": "2104.14072", "submitter": "Anthony Gruber", "authors": "Anthony Gruber, Max Gunzburger, Lili Ju, Yuankai Teng, Zhu Wang", "title": "Nonlinear Level Set Learning for Function Approximation on Sparse Data\n  with Applications to Parametric Differential Equations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A dimension reduction method based on the \"Nonlinear Level set Learning\"\n(NLL) approach is presented for the pointwise prediction of functions which\nhave been sparsely sampled. Leveraging geometric information provided by the\nImplicit Function Theorem, the proposed algorithm effectively reduces the input\ndimension to the theoretical lower bound with minor accuracy loss, providing a\none-dimensional representation of the function which can be used for regression\nand sensitivity analysis. Experiments and applications are presented which\ncompare this modified NLL with the original NLL and the Active Subspaces (AS)\nmethod. While accommodating sparse input data, the proposed algorithm is shown\nto train quickly and provide a much more accurate and informative reduction\nthan either AS or the original NLL on two example functions with\nhigh-dimensional domains, as well as two state-dependent quantities depending\non the solutions to parametric differential equations.\n", "versions": [{"version": "v1", "created": "Thu, 29 Apr 2021 01:54:05 GMT"}], "update_date": "2021-04-30", "authors_parsed": [["Gruber", "Anthony", ""], ["Gunzburger", "Max", ""], ["Ju", "Lili", ""], ["Teng", "Yuankai", ""], ["Wang", "Zhu", ""]]}, {"id": "2104.14074", "submitter": "Kelly Zhang", "authors": "Kelly W. Zhang, Lucas Janson, and Susan A. Murphy", "title": "Statistical Inference with M-Estimators on Adaptively Collected Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Bandit algorithms are increasingly used in real-world sequential\ndecision-making problems. Associated with this is an increased desire to be\nable to use the resulting datasets to answer scientific questions like: Did one\ntype of ad lead to more purchases? In which contexts is a mobile health\nintervention effective? However, classical statistical approaches fail to\nprovide valid confidence intervals when used with data collected with bandit\nalgorithms. Alternative methods have recently been developed for simple models\n(e.g., comparison of means). Yet there is a lack of general methods for\nconducting statistical inference using more complex models on data collected\nwith (contextual) bandit algorithms; for example, current methods cannot be\nused for valid inference on parameters in a logistic regression model for a\nbinary reward. In this work, we develop theory justifying the use of\nM-estimators -- which includes estimators based on empirical risk minimization\nas well as maximum likelihood -- on data collected with adaptive algorithms,\nincluding (contextual) bandit algorithms. Specifically, we show that\nM-estimators, modified with particular adaptive weights, can be used to\nconstruct asymptotically valid confidence regions for a variety of inferential\ntargets.\n", "versions": [{"version": "v1", "created": "Thu, 29 Apr 2021 01:56:44 GMT"}, {"version": "v2", "created": "Fri, 28 May 2021 20:11:42 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Zhang", "Kelly W.", ""], ["Janson", "Lucas", ""], ["Murphy", "Susan A.", ""]]}, {"id": "2104.14088", "submitter": "Zixian An", "authors": "Yunkai Wei, Zixian An, Supeng Leng and Kun Yang", "title": "Connecting AI Learning and Blockchain Mining in 6G Systems", "comments": "7 pages, 6 figures, submitted to IEEE Communications Magazine", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The sixth generation (6G) systems are generally recognized to be established\non ubiquitous Artificial Intelligence (AI) and distributed ledger such as\nblockchain. However, the AI training demands tremendous computing resource,\nwhich is limited in most 6G devices. Meanwhile, miners in Proof-of-Work (PoW)\nbased blockchains devote massive computing power to block mining, and are\nwidely criticized for the waste of computation. To address this dilemma, we\npropose an Evolved-Proof-of-Work (E-PoW) consensus that can integrate the\nmatrix computations, which are widely existed in AI training, into the process\nof brute-force searches in the block mining. Consequently, E-PoW can connect AI\nlearning and block mining via the multiply used common computing resource.\nExperimental results show that E-PoW can salvage by up to 80 percent computing\npower from pure block mining for parallel AI training in 6G systems.\n", "versions": [{"version": "v1", "created": "Thu, 29 Apr 2021 03:19:52 GMT"}], "update_date": "2021-04-30", "authors_parsed": [["Wei", "Yunkai", ""], ["An", "Zixian", ""], ["Leng", "Supeng", ""], ["Yang", "Kun", ""]]}, {"id": "2104.14090", "submitter": "Howard Heaton", "authors": "Howard Heaton, Samy Wu Fung, Aviv Gibali, Wotao Yin", "title": "Feasibility-based Fixed Point Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inverse problems consist of recovering a signal from a collection of noisy\nmeasurements. These problems can often be cast as feasibility problems;\nhowever, additional regularization is typically necessary to ensure accurate\nand stable recovery with respect to data perturbations. Hand-chosen analytic\nregularization can yield desirable theoretical guarantees, but such approaches\nhave limited effectiveness recovering signals due to their inability to\nleverage large amounts of available data. To this end, this work fuses\ndata-driven regularization and convex feasibility in a theoretically sound\nmanner. This is accomplished using feasibility-based fixed point networks\n(F-FPNs). Each F-FPN defines a collection of nonexpansive operators, each of\nwhich is the composition of a projection-based operator and a data-driven\nregularization operator. Fixed point iteration is used to compute fixed points\nof these operators, and weights of the operators are tuned so that the fixed\npoints closely represent available data. Numerical examples demonstrate\nperformance increases by F-FPNs when compared to standard TV-based recovery\nmethods for CT reconstruction and a comparable neural network based on\nalgorithm unrolling.\n", "versions": [{"version": "v1", "created": "Thu, 29 Apr 2021 03:24:36 GMT"}], "update_date": "2021-04-30", "authors_parsed": [["Heaton", "Howard", ""], ["Fung", "Samy Wu", ""], ["Gibali", "Aviv", ""], ["Yin", "Wotao", ""]]}, {"id": "2104.14095", "submitter": "Somak Aditya", "authors": "Vishesh Agarwal, Somak Aditya, Navin Goyal", "title": "Analyzing the Nuances of Transformers' Polynomial Simplification\n  Abilities", "comments": "16 pages, 18 Tables, Accepted ICLR 2021 MathAI Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Symbolic Mathematical tasks such as integration often require multiple\nwell-defined steps and understanding of sub-tasks to reach a solution. To\nunderstand Transformers' abilities in such tasks in a fine-grained manner, we\ndeviate from traditional end-to-end settings, and explore a step-wise\npolynomial simplification task. Polynomials can be written in a simple normal\nform as a sum of monomials which are ordered in a lexicographic order. For a\npolynomial which is not necessarily in this normal form, a sequence of\nsimplification steps is applied to reach the fully simplified (i.e., in the\nnormal form) polynomial. We propose a synthetic Polynomial dataset generation\nalgorithm that generates polynomials with unique proof steps. Through varying\ncoefficient configurations, input representation, proof granularity, and\nextensive hyper-parameter tuning, we observe that Transformers consistently\nstruggle with numeric multiplication. We explore two ways to mitigate this:\nCurriculum Learning and a Symbolic Calculator approach (where the numeric\noperations are offloaded to a calculator). Both approaches provide significant\ngains over the vanilla Transformers-based baseline.\n", "versions": [{"version": "v1", "created": "Thu, 29 Apr 2021 03:52:46 GMT"}], "update_date": "2021-04-30", "authors_parsed": [["Agarwal", "Vishesh", ""], ["Aditya", "Somak", ""], ["Goyal", "Navin", ""]]}, {"id": "2104.14101", "submitter": "Jonathan Lacotte", "authors": "Jonathan Lacotte and Mert Pilanci", "title": "Fast Convex Quadratic Optimization Solvers with Adaptive Sketching-based\n  Preconditioners", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider least-squares problems with quadratic regularization and propose\nnovel sketching-based iterative methods with an adaptive sketch size. The\nsketch size can be as small as the effective dimension of the data matrix to\nguarantee linear convergence. However, a major difficulty in choosing the\nsketch size in terms of the effective dimension lies in the fact that the\nlatter is usually unknown in practice. Current sketching-based solvers for\nregularized least-squares fall short on addressing this issue. Our main\ncontribution is to propose adaptive versions of standard sketching-based\niterative solvers, namely, the iterative Hessian sketch and the preconditioned\nconjugate gradient method, that do not require a priori estimation of the\neffective dimension. We propose an adaptive mechanism to control the sketch\nsize according to the progress made in each step of the iterative solver. If\nenough progress is not made, the sketch size increases to improve the\nconvergence rate. We prove that the adaptive sketch size scales at most in\nterms of the effective dimension, and that our adaptive methods are guaranteed\nto converge linearly. Consequently, our adaptive methods improve the\nstate-of-the-art complexity for solving dense, ill-conditioned least-squares\nproblems. Importantly, we illustrate numerically on several synthetic and real\ndatasets that our method is extremely efficient and is often significantly\nfaster than standard least-squares solvers such as a direct factorization based\nsolver, the conjugate gradient method and its preconditioned variants.\n", "versions": [{"version": "v1", "created": "Thu, 29 Apr 2021 04:36:41 GMT"}], "update_date": "2021-04-30", "authors_parsed": [["Lacotte", "Jonathan", ""], ["Pilanci", "Mert", ""]]}, {"id": "2104.14113", "submitter": "Manuel W\\\"uthrich", "authors": "Manuel W\\\"uthrich, Bernhard Sch\\\"olkopf, Andreas Krause", "title": "Regret Bounds for Gaussian-Process Optimization in Large Domains", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The goal of this paper is to characterize Gaussian-Process optimization in\nthe setting where the function domain is large relative to the number of\nadmissible function evaluations, i.e., where it is impossible to find the\nglobal optimum. We provide upper bounds on the suboptimality (Bayesian simple\nregret) of the solution found by optimization strategies that are closely\nrelated to the widely used expected improvement (EI) and upper confidence bound\n(UCB) algorithms. These regret bounds illuminate the relationship between the\nnumber of evaluations, the domain size (i.e. cardinality of finite domains /\nLipschitz constant of the covariance function in continuous domains), and the\noptimality of the retrieved function value. In particular, they show that even\nwhen the number of evaluations is far too small to find the global optimum, we\ncan find nontrivial function values (e.g. values that achieve a certain ratio\nwith the optimal value).\n", "versions": [{"version": "v1", "created": "Thu, 29 Apr 2021 05:19:03 GMT"}], "update_date": "2021-04-30", "authors_parsed": [["W\u00fcthrich", "Manuel", ""], ["Sch\u00f6lkopf", "Bernhard", ""], ["Krause", "Andreas", ""]]}, {"id": "2104.14116", "submitter": "Abbas Raza Ali", "authors": "Abbas Raza Ali and Marcin Budka", "title": "An Automated Approach for Timely Diagnosis and Prognosis of Coronavirus\n  Disease", "comments": "to be published in IJCNN 2021", "journal-ref": "International Joint Conference on Neural Networks (IJCNN), 2021", "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Since the outbreak of Coronavirus Disease 2019 (COVID-19), most of the\nimpacted patients have been diagnosed with high fever, dry cough, and soar\nthroat leading to severe pneumonia. Hence, to date, the diagnosis of COVID-19\nfrom lung imaging is proved to be a major evidence for early diagnosis of the\ndisease. Although nucleic acid detection using real-time reverse-transcriptase\npolymerase chain reaction (rRT-PCR) remains a gold standard for the detection\nof COVID-19, the proposed approach focuses on the automated diagnosis and\nprognosis of the disease from a non-contrast chest computed tomography (CT)scan\nfor timely diagnosis and triage of the patient. The prognosis covers the\nquantification and assessment of the disease to help hospitals with the\nmanagement and planning of crucial resources, such as medical staff,\nventilators and intensive care units (ICUs) capacity. The approach utilises\ndeep learning techniques for automated quantification of the severity of\nCOVID-19 disease via measuring the area of multiple rounded ground-glass\nopacities (GGO) and consolidations in the periphery (CP) of the lungs and\naccumulating them to form a severity score. The severity of the disease can be\ncorrelated with the medicines prescribed during the triage to assess the\neffectiveness of the treatment. The proposed approach shows promising results\nwhere the classification model achieved 93% accuracy on hold-out data.\n", "versions": [{"version": "v1", "created": "Thu, 29 Apr 2021 05:26:30 GMT"}], "update_date": "2021-04-30", "authors_parsed": [["Ali", "Abbas Raza", ""], ["Budka", "Marcin", ""]]}, {"id": "2104.14121", "submitter": "Xiang-Rong Sheng", "authors": "Siyu Gu, Xiang-Rong Sheng, Ying Fan, Guorui Zhou, Xiaoqiang Zhu", "title": "Real Negatives Matter: Continuous Training with Real Negatives for\n  Delayed Feedback Modeling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  One of the difficulties of conversion rate (CVR) prediction is that the\nconversions can delay and take place long after the clicks. The delayed\nfeedback poses a challenge: fresh data are beneficial to continuous training\nbut may not have complete label information at the time they are ingested into\nthe training pipeline. To balance model freshness and label certainty, previous\nmethods set a short waiting window or even do not wait for the conversion\nsignal. If conversion happens outside the waiting window, this sample will be\nduplicated and ingested into the training pipeline with a positive label.\nHowever, these methods have some issues. First, they assume the observed\nfeature distribution remains the same as the actual distribution. But this\nassumption does not hold due to the ingestion of duplicated samples. Second,\nthe certainty of the conversion action only comes from the positives. But the\npositives are scarce as conversions are sparse in commercial systems. These\nissues induce bias during the modeling of delayed feedback. In this paper, we\npropose DElayed FEedback modeling with Real negatives (DEFER) method to address\nthese issues. The proposed method ingests real negative samples into the\ntraining pipeline. The ingestion of real negatives ensures the observed feature\ndistribution is equivalent to the actual distribution, thus reducing the bias.\nThe ingestion of real negatives also brings more certainty information of the\nconversion. To correct the distribution shift, DEFER employs importance\nsampling to weigh the loss function. Experimental results on industrial\ndatasets validate the superiority of DEFER. DEFER have been deployed in the\ndisplay advertising system of Alibaba, obtaining over 6.0% improvement on CVR\nin several scenarios. The code and data in this paper are now open-sourced\n{https://github.com/gusuperstar/defer.git}.\n", "versions": [{"version": "v1", "created": "Thu, 29 Apr 2021 05:37:34 GMT"}], "update_date": "2021-04-30", "authors_parsed": [["Gu", "Siyu", ""], ["Sheng", "Xiang-Rong", ""], ["Fan", "Ying", ""], ["Zhou", "Guorui", ""], ["Zhu", "Xiaoqiang", ""]]}, {"id": "2104.14123", "submitter": "Sandeep C R", "authors": "CR Sandeep, Asif Salim, R Sethunadh, S Sumitra", "title": "An efficient scheme based on graph centrality to select nodes for\n  training for effective learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The process of selecting points for training a machine learning model is\noften a challenging task. Many times, we will have a lot of data, but for\ntraining, we require the labels and labeling is often costly. So we need to\nselect the points for training in an efficient manner so that the model trained\non the points selected will be better than the ones trained on any other\ntraining set. We propose a novel method to select the nodes in graph datasets\nusing the concept of graph centrality. Two methods are proposed - one using a\nsmart selection strategy, where the model is required to be trained only once\nand another using active learning method. We have tested this idea on three\npopular graph datasets - Cora, Citeseer and Pubmed- and the results are found\nto be encouraging.\n", "versions": [{"version": "v1", "created": "Thu, 29 Apr 2021 05:43:39 GMT"}, {"version": "v2", "created": "Thu, 6 May 2021 13:33:23 GMT"}, {"version": "v3", "created": "Wed, 19 May 2021 05:27:51 GMT"}], "update_date": "2021-05-20", "authors_parsed": [["Sandeep", "CR", ""], ["Salim", "Asif", ""], ["Sethunadh", "R", ""], ["Sumitra", "S", ""]]}, {"id": "2104.14129", "submitter": "Jianfei Chen", "authors": "Jianfei Chen, Lianmin Zheng, Zhewei Yao, Dequan Wang, Ion Stoica,\n  Michael W. Mahoney, Joseph E. Gonzalez", "title": "ActNN: Reducing Training Memory Footprint via 2-Bit Activation\n  Compressed Training", "comments": "to be published in ICML 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The increasing size of neural network models has been critical for\nimprovements in their accuracy, but device memory is not growing at the same\nrate. This creates fundamental challenges for training neural networks within\nlimited memory environments. In this work, we propose ActNN, a memory-efficient\ntraining framework that stores randomly quantized activations for back\npropagation. We prove the convergence of ActNN for general network\narchitectures, and we characterize the impact of quantization on the\nconvergence via an exact expression for the gradient variance. Using our\ntheory, we propose novel mixed-precision quantization strategies that exploit\nthe activation's heterogeneity across feature dimensions, samples, and layers.\nThese techniques can be readily applied to existing dynamic graph frameworks,\nsuch as PyTorch, simply by substituting the layers. We evaluate ActNN on\nmainstream computer vision models for classification, detection, and\nsegmentation tasks. On all these tasks, ActNN compresses the activation to 2\nbits on average, with negligible accuracy loss. ActNN reduces the memory\nfootprint of the activation by 12x, and it enables training with a 6.6x to 14x\nlarger batch size.\n", "versions": [{"version": "v1", "created": "Thu, 29 Apr 2021 05:50:54 GMT"}, {"version": "v2", "created": "Tue, 6 Jul 2021 05:22:49 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Chen", "Jianfei", ""], ["Zheng", "Lianmin", ""], ["Yao", "Zhewei", ""], ["Wang", "Dequan", ""], ["Stoica", "Ion", ""], ["Mahoney", "Michael W.", ""], ["Gonzalez", "Joseph E.", ""]]}, {"id": "2104.14132", "submitter": "Samet Oymak", "authors": "Samet Oymak, Mingchen Li, Mahdi Soltanolkotabi", "title": "Generalization Guarantees for Neural Architecture Search with\n  Train-Validation Split", "comments": "to appear in ICML 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Neural Architecture Search (NAS) is a popular method for automatically\ndesigning optimized architectures for high-performance deep learning. In this\napproach, it is common to use bilevel optimization where one optimizes the\nmodel weights over the training data (lower-level problem) and various\nhyperparameters such as the configuration of the architecture over the\nvalidation data (upper-level problem). This paper explores the statistical\naspects of such problems with train-validation splits. In practice, the\nlower-level problem is often overparameterized and can easily achieve zero\nloss. Thus, a-priori it seems impossible to distinguish the right\nhyperparameters based on training loss alone which motivates a better\nunderstanding of the role of train-validation split. To this aim this work\nestablishes the following results. (1) We show that refined properties of the\nvalidation loss such as risk and hyper-gradients are indicative of those of the\ntrue test loss. This reveals that the upper-level problem helps select the most\ngeneralizable model and prevent overfitting with a near-minimal validation\nsample size. Importantly, this is established for continuous search spaces\nwhich are highly relevant for popular differentiable search schemes. (2) We\nestablish generalization bounds for NAS problems with an emphasis on an\nactivation search problem. When optimized with gradient-descent, we show that\nthe train-validation procedure returns the best (model, architecture) pair even\nif all architectures can perfectly fit the training data to achieve zero error.\n(3) Finally, we highlight rigorous connections between NAS, multiple kernel\nlearning, and low-rank matrix learning. The latter leads to novel algorithmic\ninsights where the solution of the upper problem can be accurately learned via\nefficient spectral methods to achieve near-minimal risk.\n", "versions": [{"version": "v1", "created": "Thu, 29 Apr 2021 06:11:00 GMT"}, {"version": "v2", "created": "Mon, 10 May 2021 09:49:40 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Oymak", "Samet", ""], ["Li", "Mingchen", ""], ["Soltanolkotabi", "Mahdi", ""]]}, {"id": "2104.14134", "submitter": "Yuanyuan Shi", "authors": "Guannan Qu, Yuanyuan Shi, Sahin Lale, Anima Anandkumar, Adam Wierman", "title": "Stable Online Control of Linear Time-Varying Systems", "comments": "3rd Annual Learning for Dynamics & Control Conference (L4DC)", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG cs.SY eess.SY", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Linear time-varying (LTV) systems are widely used for modeling real-world\ndynamical systems due to their generality and simplicity. Providing stability\nguarantees for LTV systems is one of the central problems in control theory.\nHowever, existing approaches that guarantee stability typically lead to\nsignificantly sub-optimal cumulative control cost in online settings where only\ncurrent or short-term system information is available. In this work, we propose\nan efficient online control algorithm, COvariance Constrained Online Linear\nQuadratic (COCO-LQ) control, that guarantees input-to-state stability for a\nlarge class of LTV systems while also minimizing the control cost. The proposed\nmethod incorporates a state covariance constraint into the semi-definite\nprogramming (SDP) formulation of the LQ optimal controller. We empirically\ndemonstrate the performance of COCO-LQ in both synthetic experiments and a\npower system frequency control example.\n", "versions": [{"version": "v1", "created": "Thu, 29 Apr 2021 06:18:49 GMT"}, {"version": "v2", "created": "Fri, 30 Apr 2021 03:41:41 GMT"}], "update_date": "2021-05-03", "authors_parsed": [["Qu", "Guannan", ""], ["Shi", "Yuanyuan", ""], ["Lale", "Sahin", ""], ["Anandkumar", "Anima", ""], ["Wierman", "Adam", ""]]}, {"id": "2104.14138", "submitter": "Michael Dann", "authors": "Michael Dann, John Thangarajah", "title": "Adapting to Reward Progressivity via Spectral Reinforcement Learning", "comments": "16 pages, 8 figures, 3 tables, accepted as a conference paper at ICLR\n  2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we consider reinforcement learning tasks with progressive\nrewards; that is, tasks where the rewards tend to increase in magnitude over\ntime. We hypothesise that this property may be problematic for value-based deep\nreinforcement learning agents, particularly if the agent must first succeed in\nrelatively unrewarding regions of the task in order to reach more rewarding\nregions. To address this issue, we propose Spectral DQN, which decomposes the\nreward into frequencies such that the high frequencies only activate when large\nrewards are found. This allows the training loss to be balanced so that it\ngives more even weighting across small and large reward regions. In two domains\nwith extreme reward progressivity, where standard value-based methods struggle\nsignificantly, Spectral DQN is able to make much farther progress. Moreover,\nwhen evaluated on a set of six standard Atari games that do not overtly favour\nthe approach, Spectral DQN remains more than competitive: While it\nunderperforms one of the benchmarks in a single game, it comfortably surpasses\nthe benchmarks in three games. These results demonstrate that the approach is\nnot overfit to its target problem, and suggest that Spectral DQN may have\nadvantages beyond addressing reward progressivity.\n", "versions": [{"version": "v1", "created": "Thu, 29 Apr 2021 06:33:21 GMT"}], "update_date": "2021-04-30", "authors_parsed": [["Dann", "Michael", ""], ["Thangarajah", "John", ""]]}, {"id": "2104.14150", "submitter": "Alessio Mongelluzzo", "authors": "Patrizia Agnello, Silvia M. Ansaldi, Emilia Lenzi, Alessio\n  Mongelluzzo, Manuel Roveri", "title": "RECKONition: a NLP-based system for Industrial Accidents at Work\n  Prevention", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Extracting patterns and useful information from Natural Language datasets is\na challenging task, especially when dealing with data written in a language\ndifferent from English, like Italian. Machine and Deep Learning, together with\nNatural Language Processing (NLP) techniques have widely spread and improved\nlately, providing a plethora of useful methods to address both Supervised and\nUnsupervised problems on textual information. We propose RECKONition, a\nNLP-based system for Industrial Accidents at Work Prevention. RECKONition,\nwhich is meant to provide Natural Language Understanding, Clustering and\nInference, is the result of a joint partnership with the Italian National\nInstitute for Insurance against Accidents at Work (INAIL). The obtained results\nshowed the ability to process textual data written in Italian describing\nindustrial accidents dynamics and consequences.\n", "versions": [{"version": "v1", "created": "Thu, 29 Apr 2021 07:13:07 GMT"}], "update_date": "2021-04-30", "authors_parsed": [["Agnello", "Patrizia", ""], ["Ansaldi", "Silvia M.", ""], ["Lenzi", "Emilia", ""], ["Mongelluzzo", "Alessio", ""], ["Roveri", "Manuel", ""]]}, {"id": "2104.14173", "submitter": "Yunwen Lei", "authors": "Liang Wu, Antoine Ledent, Yunwen Lei, Marius Kloft", "title": "Fine-grained Generalization Analysis of Vector-valued Learning", "comments": "To appear in AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Many fundamental machine learning tasks can be formulated as a problem of\nlearning with vector-valued functions, where we learn multiple scalar-valued\nfunctions together. Although there is some generalization analysis on different\nspecific algorithms under the empirical risk minimization principle, a unifying\nanalysis of vector-valued learning under a regularization framework is still\nlacking. In this paper, we initiate the generalization analysis of regularized\nvector-valued learning algorithms by presenting bounds with a mild dependency\non the output dimension and a fast rate on the sample size. Our discussions\nrelax the existing assumptions on the restrictive constraint of hypothesis\nspaces, smoothness of loss functions and low-noise condition. To understand the\ninteraction between optimization and learning, we further use our results to\nderive the first generalization bounds for stochastic gradient descent with\nvector-valued functions. We apply our general results to multi-class\nclassification and multi-label classification, which yield the first bounds\nwith a logarithmic dependency on the output dimension for extreme multi-label\nclassification with the Frobenius regularization. As a byproduct, we derive a\nRademacher complexity bound for loss function classes defined in terms of a\ngeneral strongly convex function.\n", "versions": [{"version": "v1", "created": "Thu, 29 Apr 2021 07:57:34 GMT"}], "update_date": "2021-04-30", "authors_parsed": [["Wu", "Liang", ""], ["Ledent", "Antoine", ""], ["Lei", "Yunwen", ""], ["Kloft", "Marius", ""]]}, {"id": "2104.14203", "submitter": "Chen-Hao Chao", "authors": "Chen-Hao Chao, Bo-Wun Cheng, Chun-Yi Lee", "title": "Rethinking Ensemble-Distillation for Semantic Segmentation Based\n  Unsupervised Domain Adaptation", "comments": "Accepted to CVPRW (LLID) 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent researches on unsupervised domain adaptation (UDA) have demonstrated\nthat end-to-end ensemble learning frameworks serve as a compelling option for\nUDA tasks. Nevertheless, these end-to-end ensemble learning methods often lack\nflexibility as any modification to the ensemble requires retraining of their\nframeworks. To address this problem, we propose a flexible\nensemble-distillation framework for performing semantic segmentation based UDA,\nallowing any arbitrary composition of the members in the ensemble while still\nmaintaining its superior performance. To achieve such flexibility, our\nframework is designed to be robust against the output inconsistency and the\nperformance variation of the members within the ensemble. To examine the\neffectiveness and the robustness of our method, we perform an extensive set of\nexperiments on both GTA5 to Cityscapes and SYNTHIA to Cityscapes benchmarks to\nquantitatively inspect the improvements achievable by our method. We further\nprovide detailed analyses to validate that our design choices are practical and\nbeneficial. The experimental evidence validates that the proposed method indeed\noffer superior performance, robustness and flexibility in semantic segmentation\nbased UDA tasks against contemporary baseline methods.\n", "versions": [{"version": "v1", "created": "Thu, 29 Apr 2021 08:47:24 GMT"}], "update_date": "2021-04-30", "authors_parsed": [["Chao", "Chen-Hao", ""], ["Cheng", "Bo-Wun", ""], ["Lee", "Chun-Yi", ""]]}, {"id": "2104.14210", "submitter": "Indro Spinelli", "authors": "Indro Spinelli, Simone Scardapane, Amir Hussain, Aurelio Uncini", "title": "Biased Edge Dropout for Enhancing Fairness in Graph Representation\n  Learning", "comments": "Submitted to a journal for the peer-review process", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Graph representation learning has become a ubiquitous component in many\nscenarios, ranging from social network analysis to energy forecasting in smart\ngrids. In several applications, ensuring the fairness of the node (or graph)\nrepresentations with respect to some protected attributes is crucial for their\ncorrect deployment. Yet, fairness in graph deep learning remains\nunder-explored, with few solutions available. In particular, the tendency of\nsimilar nodes to cluster on several real-world graphs (i.e., homophily) can\ndramatically worsen the fairness of these procedures. In this paper, we propose\na biased edge dropout algorithm (FairDrop) to counter-act homophily and improve\nfairness in graph representation learning. FairDrop can be plugged in easily on\nmany existing algorithms, is efficient, adaptable, and can be combined with\nother fairness-inducing solutions. After describing the general algorithm, we\ndemonstrate its application on two benchmark tasks, specifically, as a random\nwalk model for producing node embeddings, and to a graph convolutional network\nfor link prediction. We prove that the proposed algorithm can successfully\nimprove the fairness of all models up to a small or negligible drop in\naccuracy, and compares favourably with existing state-of-the-art solutions. In\nan ablation study, we demonstrate that our algorithm can flexibly interpolate\nbetween biasing towards fairness and an unbiased edge dropout. Furthermore, to\nbetter evaluate the gains, we propose a new dyadic group definition to measure\nthe bias of a link prediction task when paired with group-based fairness\nmetrics. In particular, we extend the metric used to measure the bias in the\nnode embeddings to take into account the graph structure.\n", "versions": [{"version": "v1", "created": "Thu, 29 Apr 2021 08:59:36 GMT"}], "update_date": "2021-04-30", "authors_parsed": [["Spinelli", "Indro", ""], ["Scardapane", "Simone", ""], ["Hussain", "Amir", ""], ["Uncini", "Aurelio", ""]]}, {"id": "2104.14223", "submitter": "Oren Spector", "authors": "Oren Spector and Dotan Di Castro", "title": "InsertionNet -- A Scalable Solution for Insertion", "comments": "Qualitative results can be found in our supplementary video on our\n  website: https://sites.google.com/view/insertionnet/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Complicated assembly processes can be described as a sequence of two main\nactivities: grasping and insertion. While general grasping solutions are common\nin industry, insertion is still only applicable to small subsets of problems,\nmainly ones involving simple shapes in fixed locations and in which the\nvariations are not taken into consideration. Recently, RL approaches with prior\nknowledge (e.g., LfD or residual policy) have been adopted. However, these\napproaches might be problematic in contact-rich tasks since interaction might\nendanger the robot and its equipment. In this paper, we tackled this challenge\nby formulating the problem as a regression problem. By combining visual and\nforce inputs, we demonstrate that our method can scale to 16 different\ninsertion tasks in less than 10 minutes. The resulting policies are robust to\nchanges in the socket position, orientation or peg color, as well as to small\ndifferences in peg shape. Finally, we demonstrate an end-to-end solution for 2\ncomplex assembly tasks with multi-insertion objectives when the assembly board\nis randomly placed on a table.\n", "versions": [{"version": "v1", "created": "Thu, 29 Apr 2021 09:21:17 GMT"}], "update_date": "2021-04-30", "authors_parsed": [["Spector", "Oren", ""], ["Di Castro", "Dotan", ""]]}, {"id": "2104.14229", "submitter": "Nasser Ghadiri", "authors": "Hoda Memarzadeh, Nasser Ghadiri, Maryam Lotfi Shahreza and Suresh\n  Pokharel", "title": "Heterogeneous electronic medical record representation for similarity\n  computing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to the widespread use of tools and the development of text processing\ntechniques, the size and range of clinical data are not limited to structured\ndata. The rapid growth of recorded information has led to big data platforms in\nhealthcare that could be used to improve patients' primary care and serve\nvarious secondary purposes. Patient similarity assessment is one of the\nsecondary tasks in identifying patients who are similar to a given patient, and\nit helps derive insights from similar patients' records to provide better\ntreatment. This type of assessment is based on calculating the distance between\npatients. Since representing and calculating the similarity of patients plays\nan essential role in many secondary uses of electronic records, this article\nexamines a new data representation method for Electronic Medical Records (EMRs)\nwhile taking into account the information in clinical narratives for similarity\ncomputing. Some previous works are based on structured data types, while other\nworks only use unstructured data. However, a comprehensive representation of\nthe information contained in the EMR requires the effective aggregation of both\nstructured and unstructured data. To address the limitations of previous\nmethods, we propose a method that captures the co-occurrence of different\nmedical events, including signs, symptoms, and diseases extracted via\nunstructured data and structured data. It integrates data as discriminative\nfeatures to construct a temporal tree, considering the difference between\nevents that have short-term and long-term impacts. Our results show that\nconsidering signs, symptoms, and diseases in every time interval leads to less\nMSE and more precision compared to baseline representations that do not\nconsider this information or consider them separately from structured data.\n", "versions": [{"version": "v1", "created": "Thu, 29 Apr 2021 09:38:14 GMT"}], "update_date": "2021-04-30", "authors_parsed": [["Memarzadeh", "Hoda", ""], ["Ghadiri", "Nasser", ""], ["Shahreza", "Maryam Lotfi", ""], ["Pokharel", "Suresh", ""]]}, {"id": "2104.14235", "submitter": "Sebastian Houben", "authors": "Sebastian Houben, Stephanie Abrecht, Maram Akila, Andreas B\\\"ar, Felix\n  Brockherde, Patrick Feifel, Tim Fingscheidt, Sujan Sai Gannamaneni, Seyed\n  Eghbal Ghobadi, Ahmed Hammam, Anselm Haselhoff, Felix Hauser, Christian\n  Heinzemann, Marco Hoffmann, Nikhil Kapoor, Falk Kappel, Marvin Klingner, Jan\n  Kronenberger, Fabian K\\\"uppers, Jonas L\\\"ohdefink, Michael Mlynarski, Michael\n  Mock, Firas Mualla, Svetlana Pavlitskaya, Maximilian Poretschkin, Alexander\n  Pohl, Varun Ravi-Kumar, Julia Rosenzweig, Matthias Rottmann, Stefan R\\\"uping,\n  Timo S\\\"amann, Jan David Schneider, Elena Schulz, Gesina Schwalbe, Joachim\n  Sicking, Toshika Srivastava, Serin Varghese, Michael Weber, Sebastian\n  Wirkert, Tim Wirtz, Matthias Woehrle", "title": "Inspect, Understand, Overcome: A Survey of Practical Methods for AI\n  Safety", "comments": "94 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The use of deep neural networks (DNNs) in safety-critical applications like\nmobile health and autonomous driving is challenging due to numerous\nmodel-inherent shortcomings. These shortcomings are diverse and range from a\nlack of generalization over insufficient interpretability to problems with\nmalicious inputs. Cyber-physical systems employing DNNs are therefore likely to\nsuffer from safety concerns. In recent years, a zoo of state-of-the-art\ntechniques aiming to address these safety concerns has emerged. This work\nprovides a structured and broad overview of them. We first identify categories\nof insufficiencies to then describe research activities aiming at their\ndetection, quantification, or mitigation. Our paper addresses both machine\nlearning experts and safety engineers: The former ones might profit from the\nbroad range of machine learning topics covered and discussions on limitations\nof recent methods. The latter ones might gain insights into the specifics of\nmodern ML methods. We moreover hope that our contribution fuels discussions on\ndesiderata for ML systems and strategies on how to propel existing approaches\naccordingly.\n", "versions": [{"version": "v1", "created": "Thu, 29 Apr 2021 09:54:54 GMT"}], "update_date": "2021-04-30", "authors_parsed": [["Houben", "Sebastian", ""], ["Abrecht", "Stephanie", ""], ["Akila", "Maram", ""], ["B\u00e4r", "Andreas", ""], ["Brockherde", "Felix", ""], ["Feifel", "Patrick", ""], ["Fingscheidt", "Tim", ""], ["Gannamaneni", "Sujan Sai", ""], ["Ghobadi", "Seyed Eghbal", ""], ["Hammam", "Ahmed", ""], ["Haselhoff", "Anselm", ""], ["Hauser", "Felix", ""], ["Heinzemann", "Christian", ""], ["Hoffmann", "Marco", ""], ["Kapoor", "Nikhil", ""], ["Kappel", "Falk", ""], ["Klingner", "Marvin", ""], ["Kronenberger", "Jan", ""], ["K\u00fcppers", "Fabian", ""], ["L\u00f6hdefink", "Jonas", ""], ["Mlynarski", "Michael", ""], ["Mock", "Michael", ""], ["Mualla", "Firas", ""], ["Pavlitskaya", "Svetlana", ""], ["Poretschkin", "Maximilian", ""], ["Pohl", "Alexander", ""], ["Ravi-Kumar", "Varun", ""], ["Rosenzweig", "Julia", ""], ["Rottmann", "Matthias", ""], ["R\u00fcping", "Stefan", ""], ["S\u00e4mann", "Timo", ""], ["Schneider", "Jan David", ""], ["Schulz", "Elena", ""], ["Schwalbe", "Gesina", ""], ["Sicking", "Joachim", ""], ["Srivastava", "Toshika", ""], ["Varghese", "Serin", ""], ["Weber", "Michael", ""], ["Wirkert", "Sebastian", ""], ["Wirtz", "Tim", ""], ["Woehrle", "Matthias", ""]]}, {"id": "2104.14237", "submitter": "Umar Khan", "authors": "Umar Khan, Sohaib Zahid, Muhammad Asad Ali, Adnan ul Hassan, Faisal\n  Shafait", "title": "TabAug: Data Driven Augmentation for Enhanced Table Structure\n  Recognition", "comments": "to be published in ICDAR2021 , 15 pages , \" packages and articles for\n  this work and its extensions at http://umarky.com \" , \" official repository\n  https://github.com/sohaib023/splerge-tab-aug?fbclid=IwAR37V79vDLMqLGcC5YCyqY_CsFYQRDZ1-wUMW7GJUYTzkf9oM1bZ25HPmgo\n  \"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Table Structure Recognition is an essential part of end-to-end tabular data\nextraction in document images. The recent success of deep learning model\narchitectures in computer vision remains to be non-reflective in table\nstructure recognition, largely because extensive datasets for this domain are\nstill unavailable while labeling new data is expensive and time-consuming.\nTraditionally, in computer vision, these challenges are addressed by standard\naugmentation techniques that are based on image transformations like color\njittering and random cropping. As demonstrated by our experiments, these\ntechniques are not effective for the task of table structure recognition. In\nthis paper, we propose TabAug, a re-imagined Data Augmentation technique that\nproduces structural changes in table images through replication and deletion of\nrows and columns. It also consists of a data-driven probabilistic model that\nallows control over the augmentation process. To demonstrate the efficacy of\nour approach, we perform experimentation on ICDAR 2013 dataset where our\napproach shows consistent improvements in all aspects of the evaluation\nmetrics, with cell-level correct detections improving from 92.16% to 96.11%\nover the baseline.\n", "versions": [{"version": "v1", "created": "Thu, 29 Apr 2021 09:59:46 GMT"}, {"version": "v2", "created": "Sat, 15 May 2021 14:31:19 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Khan", "Umar", ""], ["Zahid", "Sohaib", ""], ["Ali", "Muhammad Asad", ""], ["Hassan", "Adnan ul", ""], ["Shafait", "Faisal", ""]]}, {"id": "2104.14255", "submitter": "Philipp Trunschke", "authors": "Michael G\\\"otte, Reinhold Schneider, Philipp Trunschke", "title": "A block-sparse Tensor Train Format for sample-efficient high-dimensional\n  Polynomial Regression", "comments": "19 pages, 3 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.LG cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Low-rank tensors are an established framework for high-dimensional\nleast-squares problems. We propose to extend this framework by including the\nconcept of block-sparsity. In the context of polynomial regression each\nsparsity pattern corresponds to some subspace of homogeneous multivariate\npolynomials. This allows us to adapt the ansatz space to align better with\nknown sample complexity results. The resulting method is tested in numerical\nexperiments and demonstrates improved computational resource utilization and\nsample efficiency.\n", "versions": [{"version": "v1", "created": "Thu, 29 Apr 2021 10:57:53 GMT"}], "update_date": "2021-04-30", "authors_parsed": [["G\u00f6tte", "Michael", ""], ["Schneider", "Reinhold", ""], ["Trunschke", "Philipp", ""]]}, {"id": "2104.14278", "submitter": "Arman Iranfar", "authors": "Arman Iranfar, Adriana Arza, and David Atienza", "title": "ReLearn: A Robust Machine Learning Framework in Presence of Missing Data\n  for Multimodal Stress Detection from Physiological Signals", "comments": "7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Continuous and multimodal stress detection has been performed recently\nthrough wearable devices and machine learning algorithms. However, a well-known\nand important challenge of working on physiological signals recorded by\nconventional monitoring devices is missing data due to sensors insufficient\ncontact and interference by other equipment. This challenge becomes more\nproblematic when the user/patient is mentally or physically active or stressed\nbecause of more frequent conscious or subconscious movements. In this paper, we\npropose ReLearn, a robust machine learning framework for stress detection from\nbiomarkers extracted from multimodal physiological signals. ReLearn effectively\ncopes with missing data and outliers both at training and inference phases.\nReLearn, composed of machine learning models for feature selection, outlier\ndetection, data imputation, and classification, allows us to classify all\nsamples, including those with missing values at inference. In particular,\naccording to our experiments and stress database, while by discarding all\nmissing data, as a simplistic yet common approach, no prediction can be made\nfor 34% of the data at inference, our approach can achieve accurate\npredictions, as high as 78%, for missing samples. Also, our experiments show\nthat the proposed framework obtains a cross-validation accuracy of 86.8% even\nif more than 50% of samples within the features are missing.\n", "versions": [{"version": "v1", "created": "Thu, 29 Apr 2021 11:53:01 GMT"}, {"version": "v2", "created": "Thu, 29 Jul 2021 12:50:07 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Iranfar", "Arman", ""], ["Arza", "Adriana", ""], ["Atienza", "David", ""]]}, {"id": "2104.14281", "submitter": "Yongzhen Wang", "authors": "Yongzhen Wang, Xiaozhong Liu, Katy B\\\"orner, Jun Lin, Yingnan Ju,\n  Changlong Sun, Luo Si", "title": "Leveraging Online Shopping Behaviors as a Proxy for Personal Lifestyle\n  Choices: New Insights into Chronic Disease Prevention Literacy", "comments": "47 pages with SI, 5 figures, 9 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ubiquitous internet access is reshaping the way we live, but it is\naccompanied by unprecedented challenges in preventing chronic diseases planted\nby long exposure to unhealthy lifestyles. This paper proposes leveraging online\nshopping behaviors as a proxy for personal lifestyle choices to improve chronic\ndisease prevention literacy targeted for times when e-commerce user experience\nhas been assimilated into most people's daily lives. Here, retrospective\nlongitudinal query logs and purchase records from millions of online shoppers\nwere accessed, constructing a broad spectrum of lifestyle features covering\nassorted product categories and buyer personas. Using the lifestyle-related\ninformation preceding their first purchases of prescription drugs, we could\ndetermine associations between online shoppers' past lifestyle choices and\nwhether they suffered from a particular chronic disease or not. Novel lifestyle\nrisk factors were discovered in two exemplars -- depression and diabetes, most\nof which showed cognitive congruence with existing healthcare knowledge.\nFurther, such empirical findings could be adopted to locate online shoppers at\nhigh risk of these chronic diseases with fair accuracy, closely matching the\nperformance of screening surveys benchmarked against medical diagnosis.\nUnobtrusive chronic disease surveillance via e-commerce sites may soon meet\nconsenting individuals in the digital space they already inhabit.\n", "versions": [{"version": "v1", "created": "Thu, 29 Apr 2021 12:05:16 GMT"}, {"version": "v2", "created": "Fri, 30 Apr 2021 00:54:23 GMT"}, {"version": "v3", "created": "Mon, 12 Jul 2021 12:08:12 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Wang", "Yongzhen", ""], ["Liu", "Xiaozhong", ""], ["B\u00f6rner", "Katy", ""], ["Lin", "Jun", ""], ["Ju", "Yingnan", ""], ["Sun", "Changlong", ""], ["Si", "Luo", ""]]}, {"id": "2104.14282", "submitter": "Amit Chattopadhyay", "authors": "Amit K Chattopadhyay and Subhagata Chattopadhyay", "title": "VIRDOC: Statistical and Machine Learning by a VIRtual DOCtor to Predict\n  Dengue Fatality", "comments": "15 pages, 4 figures, 8 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.LG physics.bio-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clinicians conduct routine diagnosis by scrutinizing signs and symptoms of\npatients in treating epidemics. This skill evolves through trial-and-error and\nimproves with time. The success of the therapeutic regimen relies largely on\nthe accuracy of interpretation of such sign-symptoms, based on which the\nclinician ranks the potent causes of the epidemic and analyzes their\ninterdependence to devise sustainable containment strategies. This study\nproposed an alternative medical front, a VIRtual DOCtor (VIRDOC), that can\nself-consistently rank key contributors of an epidemic and also correctly\nidentify the infection stage, using the language of statistical modelling and\nMachine Learning. VIRDOC analyzes medical data and then translates these into a\nvector comprising Multiple Linear Regression (MLR) coefficients to\nprobabilistically predict scores that compare with clinical experience-based\nassessment. The VIRDOC algorithm, risk managed through ANOVA, has been tested\non dengue epidemic data (N=100 with 11 weighted sign-symptoms). Results highly\nencouraging with ca 75% accurate fatality prediction, compared to 71.4% from\ntraditional diagnosis. The algorithm can be generically extended to analyze\nother epidemic forms.\n", "versions": [{"version": "v1", "created": "Thu, 29 Apr 2021 12:06:05 GMT"}], "update_date": "2021-04-30", "authors_parsed": [["Chattopadhyay", "Amit K", ""], ["Chattopadhyay", "Subhagata", ""]]}, {"id": "2104.14289", "submitter": "Sumanth Prabhu", "authors": "Sumanth Prabhu and Moosa Mohamed and Hemant Misra", "title": "Multi-class Text Classification using BERT-based Active Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Text Classification finds interesting applications in the pickup and delivery\nservices industry where customers require one or more items to be picked up\nfrom a location and delivered to a certain destination. Classifying these\ncustomer transactions into multiple categories helps understand the market\nneeds for different customer segments. Each transaction is accompanied by a\ntext description provided by the customer to describe the products being picked\nup and delivered which can be used to classify the transaction. BERT-based\nmodels have proven to perform well in Natural Language Understanding. However,\nthe product descriptions provided by the customers tend to be short, incoherent\nand code-mixed (Hindi-English) text which demands fine-tuning of such models\nwith manually labelled data to achieve high accuracy. Collecting this labelled\ndata can prove to be expensive. In this paper, we explore Active Learning\nstrategies to label transaction descriptions cost effectively while using BERT\nto train a transaction classification model. On TREC-6, AG's News Corpus and an\ninternal dataset, we benchmark the performance of BERT across different Active\nLearning strategies in Multi-Class Text Classification.\n", "versions": [{"version": "v1", "created": "Tue, 27 Apr 2021 19:49:39 GMT"}], "update_date": "2021-04-30", "authors_parsed": [["Prabhu", "Sumanth", ""], ["Mohamed", "Moosa", ""], ["Misra", "Hemant", ""]]}, {"id": "2104.14290", "submitter": "Ben Day", "authors": "Ben Day, Alexander Norcliffe, Jacob Moss, Pietro Li\\`o", "title": "Meta-learning using privileged information for dynamics", "comments": "Published as a workshop paper at the Learning to Learn and SimDL\n  workshops at ICLR 2021. 4 pages, 3 pages of appendices", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural ODE Processes approach the problem of meta-learning for dynamics using\na latent variable model, which permits a flexible aggregation of contextual\ninformation. This flexibility is inherited from the Neural Process framework\nand allows the model to aggregate sets of context observations of arbitrary\nsize into a fixed-length representation. In the physical sciences, we often\nhave access to structured knowledge in addition to raw observations of a\nsystem, such as the value of a conserved quantity or a description of an\nunderstood component. Taking advantage of the aggregation flexibility, we\nextend the Neural ODE Process model to use additional information within the\nLearning Using Privileged Information setting, and we validate our extension\nwith experiments showing improved accuracy and calibration on simulated\ndynamics tasks.\n", "versions": [{"version": "v1", "created": "Thu, 29 Apr 2021 12:18:02 GMT"}], "update_date": "2021-04-30", "authors_parsed": [["Day", "Ben", ""], ["Norcliffe", "Alexander", ""], ["Moss", "Jacob", ""], ["Li\u00f2", "Pietro", ""]]}, {"id": "2104.14291", "submitter": "Aaron Fisher", "authors": "Aaron Fisher", "title": "Optimizing Rescoring Rules with Interpretable Representations of\n  Long-Term Information", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Analyzing temporal data (e.g., wearable device data) requires a decision\nabout how to combine information from the recent and distant past. In the\ncontext of classifying sleep status from actigraphy, Webster's rescoring rules\noffer one popular solution based on the long-term patterns in the output of a\nmoving-window model. Unfortunately, the question of how to optimize rescoring\nrules for any given setting has remained unsolved. To address this problem and\nexpand the possible use cases of rescoring rules, we propose rephrasing these\nrules in terms of epoch-specific features. Our features take two general forms:\n(1) the time lag between now and the most recent [or closest upcoming] bout of\ntime spent in a given state, and (2) the length of the most recent [or closest\nupcoming] bout of time spent in a given state. Given any initial moving window\nmodel, these features can be defined recursively, allowing for straightforward\noptimization of rescoring rules. Joint optimization of the moving window model\nand the subsequent rescoring rules can also be implemented using gradient-based\noptimization software, such as Tensorflow. Beyond binary classification\nproblems (e.g., sleep-wake), the same approach can be applied to summarize\nlong-term patterns for multi-state classification problems (e.g., sitting,\nwalking, or stair climbing). We find that optimized rescoring rules improve the\nperformance of sleep-wake classifiers, achieving accuracy comparable to that of\ncertain neural network architectures.\n", "versions": [{"version": "v1", "created": "Wed, 28 Apr 2021 15:30:16 GMT"}], "update_date": "2021-04-30", "authors_parsed": [["Fisher", "Aaron", ""]]}, {"id": "2104.14297", "submitter": "Yan Gao", "authors": "Yan Gao, Titouan Parcollet, Salah Zaiem, Javier Fernandez-Marques,\n  Pedro P. B. de Gusmao, Daniel J. Beutel, Nicholas D. Lane", "title": "End-to-End Speech Recognition from Federated Acoustic Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training Automatic Speech Recognition (ASR) models under federated learning\n(FL) settings has attracted a lot of attention recently. However, the FL\nscenarios often presented in the literature are artificial and fail to capture\nthe complexity of real FL systems. In this paper, we construct a challenging\nand realistic ASR federated experimental setup consisting of clients with\nheterogeneous data distributions using the French and Italian sets of the\nCommonVoice dataset, a large heterogeneous dataset containing thousands of\ndifferent speakers, acoustic environments and noises. We present the first\nempirical study on attention-based sequence-to-sequence End-to-End (E2E) ASR\nmodel with three aggregation weighting strategies -- standard FedAvg,\nloss-based aggregation and a novel word error rate (WER)-based aggregation,\ncompared in two realistic FL scenarios: cross-silo with 10 clients and\ncross-device with 2K and 4K clients. Our analysis on E2E ASR from heterogeneous\nand realistic federated acoustic models provides the foundations for future\nresearch and development of realistic FL-based ASR applications.\n", "versions": [{"version": "v1", "created": "Thu, 29 Apr 2021 12:31:57 GMT"}, {"version": "v2", "created": "Fri, 9 Jul 2021 14:41:12 GMT"}], "update_date": "2021-07-12", "authors_parsed": [["Gao", "Yan", ""], ["Parcollet", "Titouan", ""], ["Zaiem", "Salah", ""], ["Fernandez-Marques", "Javier", ""], ["de Gusmao", "Pedro P. B.", ""], ["Beutel", "Daniel J.", ""], ["Lane", "Nicholas D.", ""]]}, {"id": "2104.14308", "submitter": "Ivan Vishniakou", "authors": "Ivan Vishniakou, Johannes D. Seelig", "title": "Differentiable model-based adaptive optics for two-photon microscopy", "comments": null, "journal-ref": null, "doi": "10.1364/OE.424344", "report-no": null, "categories": "physics.optics cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Aberrations limit scanning fluorescence microscopy when imaging in scattering\nmaterials such as biological tissue. Model-based approaches for adaptive optics\ntake advantage of a computational model of the optical setup. Such models can\nbe combined with the optimization techniques of machine learning frameworks to\nfind aberration corrections, as was demonstrated for focusing a laser beam\nthrough aberrations onto a camera [arXiv:2007.13400]. Here, we extend this\napproach to two-photon scanning microscopy. The developed sensorless technique\nfinds corrections for aberrations in scattering samples and will be useful for\na range of imaging application, for example in brain tissue.\n", "versions": [{"version": "v1", "created": "Thu, 29 Apr 2021 12:50:08 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Vishniakou", "Ivan", ""], ["Seelig", "Johannes D.", ""]]}, {"id": "2104.14320", "submitter": "Pongpisit Thanasutives", "authors": "Pongpisit Thanasutives, Masayuki Numao, Ken-ichi Fukui", "title": "Adversarial Multi-task Learning Enhanced Physics-informed Neural\n  Networks for Solving Partial Differential Equations", "comments": "Accepted by the International Joint Conference on Neural Networks\n  (IJCNN) 2021, Oral presentation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA math.NA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recently, researchers have utilized neural networks to accurately solve\npartial differential equations (PDEs), enabling the mesh-free method for\nscientific computation. Unfortunately, the network performance drops when\nencountering a high nonlinearity domain. To improve the generalizability, we\nintroduce the novel approach of employing multi-task learning techniques, the\nuncertainty-weighting loss and the gradients surgery, in the context of\nlearning PDE solutions. The multi-task scheme exploits the benefits of learning\nshared representations, controlled by cross-stitch modules, between multiple\nrelated PDEs, which are obtainable by varying the PDE parameterization\ncoefficients, to generalize better on the original PDE. Encouraging the network\npay closer attention to the high nonlinearity domain regions that are more\nchallenging to learn, we also propose adversarial training for generating\nsupplementary high-loss samples, similarly distributed to the original training\ndistribution. In the experiments, our proposed methods are found to be\neffective and reduce the error on the unseen data points as compared to the\nprevious approaches in various PDE examples, including high-dimensional\nstochastic PDEs.\n", "versions": [{"version": "v1", "created": "Thu, 29 Apr 2021 13:17:46 GMT"}, {"version": "v2", "created": "Wed, 12 May 2021 08:05:24 GMT"}], "update_date": "2021-05-13", "authors_parsed": [["Thanasutives", "Pongpisit", ""], ["Numao", "Masayuki", ""], ["Fukui", "Ken-ichi", ""]]}, {"id": "2104.14332", "submitter": "Deng-Cheng Yan", "authors": "Dengcheng Yan, Wenxin Xie, Yiwen Zhang", "title": "Hypernetwork Dismantling via Deep Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SY", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Network dismantling aims to degrade the connectivity of a network by removing\nan optimal set of nodes and has been widely adopted in many real-world\napplications such as epidemic control and rumor containment. However,\nconventional methods usually focus on simple network modeling with only\npairwise interactions, while group-wise interactions modeled by hypernetwork\nare ubiquitous and critical. In this work, we formulate the hypernetwork\ndismantling problem as a node sequence decision problem and propose a deep\nreinforcement learning (DRL)-based hypernetwork dismantling framework. Besides,\nwe design a novel inductive hypernetwork embedding method to ensure the\ntransferability to various real-world hypernetworks. Generally, our framework\nbuilds an agent. It first generates small-scale synthetic hypernetworks and\nembeds the nodes and hypernetworks into a low dimensional vector space to\nrepresent the action and state space in DRL, respectively. Then trial-and-error\ndismantling tasks are conducted by the agent on these synthetic hypernetworks,\nand the dismantling strategy is continuously optimized. Finally, the\nwell-optimized strategy is applied to real-world hypernetwork dismantling\ntasks. Experimental results on five real-world hypernetworks demonstrate the\neffectiveness of our proposed framework.\n", "versions": [{"version": "v1", "created": "Thu, 29 Apr 2021 13:35:29 GMT"}], "update_date": "2021-04-30", "authors_parsed": [["Yan", "Dengcheng", ""], ["Xie", "Wenxin", ""], ["Zhang", "Yiwen", ""]]}, {"id": "2104.14335", "submitter": "Oren Rippel", "authors": "Oren Rippel, Alexander G. Anderson, Kedar Tatwawadi, Sanjay Nair,\n  Craig Lytle, Lubomir Bourdev", "title": "ELF-VC: Efficient Learned Flexible-Rate Video Coding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While learned video codecs have demonstrated great promise, they have yet to\nachieve sufficient efficiency for practical deployment. In this work, we\npropose several novel ideas for learned video compression which allow for\nimproved performance for the low-latency mode (I- and P-frames only) along with\na considerable increase in computational efficiency. In this setting, for\nnatural videos our approach compares favorably across the entire R-D curve\nunder metrics PSNR, MS-SSIM and VMAF against all mainstream video standards\n(H.264, H.265, AV1) and all ML codecs. At the same time, our approach runs at\nleast 5x faster and has fewer parameters than all ML codecs which report these\nfigures.\n  Our contributions include a flexible-rate framework allowing a single model\nto cover a large and dense range of bitrates, at a negligible increase in\ncomputation and parameter count; an efficient backbone optimized for ML-based\ncodecs; and a novel in-loop flow prediction scheme which leverages prior\ninformation towards more efficient compression.\n  We benchmark our method, which we call ELF-VC (Efficient, Learned and\nFlexible Video Coding) on popular video test sets UVG and MCL-JCV under metrics\nPSNR, MS-SSIM and VMAF. For example, on UVG under PSNR, it reduces the BD-rate\nby 44% against H.264, 26% against H.265, 15% against AV1, and 35% against the\ncurrent best ML codec. At the same time, on an NVIDIA Titan V GPU our approach\nencodes/decodes VGA at 49/91 FPS, HD 720 at 19/35 FPS, and HD 1080 at 10/18\nFPS.\n", "versions": [{"version": "v1", "created": "Thu, 29 Apr 2021 17:50:35 GMT"}], "update_date": "2021-04-30", "authors_parsed": [["Rippel", "Oren", ""], ["Anderson", "Alexander G.", ""], ["Tatwawadi", "Kedar", ""], ["Nair", "Sanjay", ""], ["Lytle", "Craig", ""], ["Bourdev", "Lubomir", ""]]}, {"id": "2104.14349", "submitter": "Jing Qin", "authors": "Jing Qin and Joshua Ashley and Biyun Xie", "title": "Hand Gesture Recognition Based on a Nonconvex Regularization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG math.OC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recognition of hand gestures is one of the most fundamental tasks in\nhuman-robot interaction. Sparse representation based methods have been widely\nused due to their efficiency and low requirements on the training data.\nRecently, nonconvex regularization techniques including the $\\ell_{1-2}$\nregularization have been proposed in the image processing community to promote\nsparsity while achieving efficient performance. In this paper, we propose a\nvision-based hand gesture recognition model based on the $\\ell_{1-2}$\nregularization, which is solved by the alternating direction method of\nmultipliers (ADMM). Numerical experiments on binary and gray-scale data sets\nhave shown the effectiveness of this method in identifying hand gestures.\n", "versions": [{"version": "v1", "created": "Thu, 29 Apr 2021 13:58:55 GMT"}, {"version": "v2", "created": "Fri, 30 Apr 2021 04:42:36 GMT"}], "update_date": "2021-05-03", "authors_parsed": [["Qin", "Jing", ""], ["Ashley", "Joshua", ""], ["Xie", "Biyun", ""]]}, {"id": "2104.14362", "submitter": "Ji Liu", "authors": "Ji Liu, Jizhou Huang, Yang Zhou, Xuhong Li, Shilei Ji, Haoyi Xiong,\n  Dejing Dou", "title": "From Distributed Machine Learning to Federated Learning: A Survey", "comments": "31 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, data and computing resources are typically distributed in\nthe devices of end users, various regions or organizations. Because of laws or\nregulations, the distributed data and computing resources cannot be directly\nshared among different regions or organizations for machine learning tasks.\nFederated learning emerges as an efficient approach to exploit distributed data\nand computing resources, so as to collaboratively train machine learning\nmodels, while obeying the laws and regulations and ensuring data security and\ndata privacy. In this paper, we provide a comprehensive survey of existing\nworks for federated learning. We propose a functional architecture of federated\nlearning systems and a taxonomy of related techniques. Furthermore, we present\nthe distributed training, data communication, and security of FL systems.\nFinally, we analyze their limitations and propose future research directions.\n", "versions": [{"version": "v1", "created": "Thu, 29 Apr 2021 14:15:11 GMT"}, {"version": "v2", "created": "Mon, 10 May 2021 10:55:17 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Liu", "Ji", ""], ["Huang", "Jizhou", ""], ["Zhou", "Yang", ""], ["Li", "Xuhong", ""], ["Ji", "Shilei", ""], ["Xiong", "Haoyi", ""], ["Dou", "Dejing", ""]]}, {"id": "2104.14370", "submitter": "Fahad Sohrab", "authors": "Fahad Sohrab, Alexandros Iosifidis, Moncef Gabbouj, Jenni Raitoharju", "title": "Graph-Embedded Subspace Support Vector Data Description", "comments": "12 pages, 3 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a novel subspace learning framework for one-class\nclassification. The proposed framework presents the problem in the form of\ngraph embedding. It includes the previously proposed subspace one-class\ntechniques as its special cases and provides further insight on what these\ntechniques actually optimize. The framework allows to incorporate other\nmeaningful optimization goals via the graph preserving criterion and reveals\nspectral and spectral regression-based solutions as alternatives to the\npreviously used gradient-based technique. We combine the subspace learning\nframework iteratively with Support Vector Data Description applied in the\nsubspace to formulate Graph-Embedded Subspace Support Vector Data Description.\nWe experimentally analyzed the performance of newly proposed different\nvariants. We demonstrate improved performance against the baselines and the\nrecently proposed subspace learning methods for one-class classification.\n", "versions": [{"version": "v1", "created": "Thu, 29 Apr 2021 14:30:48 GMT"}], "update_date": "2021-04-30", "authors_parsed": [["Sohrab", "Fahad", ""], ["Iosifidis", "Alexandros", ""], ["Gabbouj", "Moncef", ""], ["Raitoharju", "Jenni", ""]]}, {"id": "2104.14371", "submitter": "Mehmet Caner", "authors": "Mehmet Caner", "title": "Generalized Linear Models with Structured Sparsity Estimators", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG econ.EM", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  In this paper, we introduce structured sparsity estimators in Generalized\nLinear Models. Structured sparsity estimators in the least squares loss are\nintroduced by Stucky and van de Geer (2018) recently for fixed design and\nnormal errors. We extend their results to debiased structured sparsity\nestimators with Generalized Linear Model based loss. Structured sparsity\nestimation means penalized loss functions with a possible sparsity structure\nused in the chosen norm. These include weighted group lasso, lasso and norms\ngenerated from convex cones. The significant difficulty is that it is not clear\nhow to prove two oracle inequalities. The first one is for the initial\npenalized Generalized Linear Model estimator. Since it is not clear how a\nparticular feasible-weighted nodewise regression may fit in an oracle\ninequality for penalized Generalized Linear Model, we need a second oracle\ninequality to get oracle bounds for the approximate inverse for the sample\nestimate of second-order partial derivative of Generalized Linear Model.\n  Our contributions are fivefold: 1. We generalize the existing oracle\ninequality results in penalized Generalized Linear Models by proving the\nunderlying conditions rather than assuming them. One of the key issues is the\nproof of a sample one-point margin condition and its use in an oracle\ninequality. 2. Our results cover even non sub-Gaussian errors and regressors.\n3. We provide a feasible weighted nodewise regression proof which generalizes\nthe results in the literature from a simple l_1 norm usage to norms generated\nfrom convex cones. 4. We realize that norms used in feasible nodewise\nregression proofs should be weaker or equal to the norms in penalized\nGeneralized Linear Model loss. 5. We can debias the first step estimator via\ngetting an approximate inverse of the singular-sample second order partial\nderivative of Generalized Linear Model loss.\n", "versions": [{"version": "v1", "created": "Thu, 29 Apr 2021 14:31:01 GMT"}], "update_date": "2021-04-30", "authors_parsed": [["Caner", "Mehmet", ""]]}, {"id": "2104.14372", "submitter": "Apostolos Modas", "authors": "Guillermo Ortiz-Jimenez, Itamar Franco Salazar-Reque, Apostolos Modas,\n  Seyed-Mohsen Moosavi-Dezfooli, Pascal Frossard", "title": "A neural anisotropic view of underspecification in deep learning", "comments": "Presented as a RobustML workshop paper at ICLR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The underspecification of most machine learning pipelines means that we\ncannot rely solely on validation performance to assess the robustness of deep\nlearning systems to naturally occurring distribution shifts. Instead, making\nsure that a neural network can generalize across a large number of different\nsituations requires to understand the specific way in which it solves a task.\nIn this work, we propose to study this problem from a geometric perspective\nwith the aim to understand two key characteristics of neural network solutions\nin underspecified settings: how is the geometry of the learned function related\nto the data representation? And, are deep networks always biased towards\nsimpler solutions, as conjectured in recent literature? We show that the way\nneural networks handle the underspecification of these problems is highly\ndependent on the data representation, affecting both the geometry and the\ncomplexity of the learned predictors. Our results highlight that understanding\nthe architectural inductive bias in deep learning is fundamental to address the\nfairness, robustness, and generalization of these systems.\n", "versions": [{"version": "v1", "created": "Thu, 29 Apr 2021 14:31:09 GMT"}], "update_date": "2021-04-30", "authors_parsed": [["Ortiz-Jimenez", "Guillermo", ""], ["Salazar-Reque", "Itamar Franco", ""], ["Modas", "Apostolos", ""], ["Moosavi-Dezfooli", "Seyed-Mohsen", ""], ["Frossard", "Pascal", ""]]}, {"id": "2104.14379", "submitter": "Weizhu Qian", "authors": "Weizhu Qian, Bowei Chen, Xiaowei Huang", "title": "Learning Robust Variational Information Bottleneck with Reference", "comments": "8 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose a new approach to train a variational information bottleneck (VIB)\nthat improves its robustness to adversarial perturbations. Unlike the\ntraditional methods where the hard labels are usually used for the\nclassification task, we refine the categorical class information in the\ntraining phase with soft labels which are obtained from a pre-trained reference\nneural network and can reflect the likelihood of the original class labels. We\nalso relax the Gaussian posterior assumption in the VIB implementation by using\nthe mutual information neural estimation. Extensive experiments have been\nperformed with the MNIST and CIFAR-10 datasets, and the results show that our\nproposed approach significantly outperforms the benchmarked models.\n", "versions": [{"version": "v1", "created": "Thu, 29 Apr 2021 14:46:09 GMT"}], "update_date": "2021-04-30", "authors_parsed": [["Qian", "Weizhu", ""], ["Chen", "Bowei", ""], ["Huang", "Xiaowei", ""]]}, {"id": "2104.14380", "submitter": "Fan Mo", "authors": "Fan Mo, Hamed Haddadi, Kleomenis Katevas, Eduard Marin, Diego Perino,\n  Nicolas Kourtellis", "title": "PPFL: Privacy-preserving Federated Learning with Trusted Execution\n  Environments", "comments": "15 pages, 8 figures, accepted to MobiSys 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  We propose and implement a Privacy-preserving Federated Learning ($PPFL$)\nframework for mobile systems to limit privacy leakages in federated learning.\nLeveraging the widespread presence of Trusted Execution Environments (TEEs) in\nhigh-end and mobile devices, we utilize TEEs on clients for local training, and\non servers for secure aggregation, so that model/gradient updates are hidden\nfrom adversaries. Challenged by the limited memory size of current TEEs, we\nleverage greedy layer-wise training to train each model's layer inside the\ntrusted area until its convergence. The performance evaluation of our\nimplementation shows that $PPFL$ can significantly improve privacy while\nincurring small system overheads at the client-side. In particular, $PPFL$ can\nsuccessfully defend the trained model against data reconstruction, property\ninference, and membership inference attacks. Furthermore, it can achieve\ncomparable model utility with fewer communication rounds (0.54$\\times$) and a\nsimilar amount of network traffic (1.002$\\times$) compared to the standard\nfederated learning of a complete model. This is achieved while only introducing\nup to ~15% CPU time, ~18% memory usage, and ~21% energy consumption overhead in\n$PPFL$'s client-side.\n", "versions": [{"version": "v1", "created": "Thu, 29 Apr 2021 14:46:16 GMT"}, {"version": "v2", "created": "Mon, 28 Jun 2021 20:51:12 GMT"}], "update_date": "2021-06-30", "authors_parsed": [["Mo", "Fan", ""], ["Haddadi", "Hamed", ""], ["Katevas", "Kleomenis", ""], ["Marin", "Eduard", ""], ["Perino", "Diego", ""], ["Kourtellis", "Nicolas", ""]]}, {"id": "2104.14383", "submitter": "Shuang Zhang", "authors": "Shuang Zhang, Liyao Xiang, Xi Yu, Pengzhi Chu, Yingqi Chen, Chen Cen,\n  Li Wang", "title": "Privacy-Preserving Federated Learning on Partitioned Attributes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Real-world data is usually segmented by attributes and distributed across\ndifferent parties. Federated learning empowers collaborative training without\nexposing local data or models. As we demonstrate through designed attacks, even\nwith a small proportion of corrupted data, an adversary can accurately infer\nthe input attributes. We introduce an adversarial learning based procedure\nwhich tunes a local model to release privacy-preserving intermediate\nrepresentations. To alleviate the accuracy decline, we propose a defense method\nbased on the forward-backward splitting algorithm, which respectively deals\nwith the accuracy loss and privacy loss in the forward and backward gradient\ndescent steps, achieving the two objectives simultaneously. Extensive\nexperiments on a variety of datasets have shown that our defense significantly\nmitigates privacy leakage with negligible impact on the federated learning\ntask.\n", "versions": [{"version": "v1", "created": "Thu, 29 Apr 2021 14:49:14 GMT"}], "update_date": "2021-04-30", "authors_parsed": [["Zhang", "Shuang", ""], ["Xiang", "Liyao", ""], ["Yu", "Xi", ""], ["Chu", "Pengzhi", ""], ["Chen", "Yingqi", ""], ["Cen", "Chen", ""], ["Wang", "Li", ""]]}, {"id": "2104.14386", "submitter": "Artemij Amiranashvili", "authors": "Artemij Amiranashvili, Max Argus, Lukas Hermann, Wolfram Burgard,\n  Thomas Brox", "title": "Pre-training of Deep RL Agents for Improved Learning under Domain\n  Randomization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Visual domain randomization in simulated environments is a widely used method\nto transfer policies trained in simulation to real robots. However, domain\nrandomization and augmentation hamper the training of a policy. As\nreinforcement learning struggles with a noisy training signal, this additional\nnuisance can drastically impede training. For difficult tasks it can even\nresult in complete failure to learn. To overcome this problem we propose to\npre-train a perception encoder that already provides an embedding invariant to\nthe randomization. We demonstrate that this yields consistently improved\nresults on a randomized version of DeepMind control suite tasks and a stacking\nenvironment on arbitrary backgrounds with zero-shot transfer to a physical\nrobot.\n", "versions": [{"version": "v1", "created": "Thu, 29 Apr 2021 14:54:11 GMT"}], "update_date": "2021-04-30", "authors_parsed": [["Amiranashvili", "Artemij", ""], ["Argus", "Max", ""], ["Hermann", "Lukas", ""], ["Burgard", "Wolfram", ""], ["Brox", "Thomas", ""]]}, {"id": "2104.14398", "submitter": "Shaun D'Souza", "authors": "Shaun D'Souza", "title": "Implementing Reinforcement Learning Algorithms in Retail Supply Chains\n  with OpenAI Gym Toolkit", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  From cutting costs to improving customer experience, forecasting is the crux\nof retail supply chain management (SCM) and the key to better supply chain\nperformance. Several retailers are using AI/ML models to gather datasets and\nprovide forecast guidance in applications such as Cognitive Demand Forecasting,\nProduct End-of-Life, Forecasting, and Demand Integrated Product Flow. Early\nwork in these areas looked at classical algorithms to improve on a gamut of\nchallenges such as network flow and graphs. But the recent disruptions have\nmade it critical for supply chains to have the resiliency to handle unexpected\nevents. The biggest challenge lies in matching supply with demand.\n  Reinforcement Learning (RL) with its ability to train systems to respond to\nunforeseen environments, is being increasingly adopted in SCM to improve\nforecast accuracy, solve supply chain optimization challenges, and train\nsystems to respond to unforeseen circumstances. Companies like UPS and Amazon\nhave developed RL algorithms to define winning AI strategies and keep up with\nrising consumer delivery expectations. While there are many ways to build RL\nalgorithms for supply chain use cases, the OpenAI Gym toolkit is becoming the\npreferred choice because of the robust framework for event-driven simulations.\n  This white paper explores the application of RL in supply chain forecasting\nand describes how to build suitable RL models and algorithms by using the\nOpenAI Gym toolkit.\n", "versions": [{"version": "v1", "created": "Tue, 27 Apr 2021 03:35:42 GMT"}], "update_date": "2021-04-30", "authors_parsed": [["D'Souza", "Shaun", ""]]}, {"id": "2104.14403", "submitter": "Yilun Zhou", "authors": "Yilun Zhou, Serena Booth, Marco Tulio Ribeiro, Julie Shah", "title": "Do Feature Attribution Methods Correctly Attribute Features?", "comments": "21 pages, 20 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Feature attribution methods are exceedingly popular in interpretable machine\nlearning. They aim to compute the attribution of each input feature to\nrepresent its importance, but there is no consensus on the definition of\n\"attribution\", leading to many competing methods with little systematic\nevaluation. The lack of attribution ground truth further complicates\nevaluation, which has to rely on proxy metrics. To address this, we propose a\ndataset modification procedure such that models trained on the new dataset have\nground truth attribution available. We evaluate three methods: saliency maps,\nrationales, and attention. We identify their deficiencies and add a new\nperspective to the growing body of evidence questioning their correctness and\nreliability in the wild. Our evaluation approach is model-agnostic and can be\nused to assess future feature attribution method proposals as well. Code is\navailable at https://github.com/YilunZhou/feature-attribution-evaluation.\n", "versions": [{"version": "v1", "created": "Tue, 27 Apr 2021 20:35:30 GMT"}], "update_date": "2021-04-30", "authors_parsed": [["Zhou", "Yilun", ""], ["Booth", "Serena", ""], ["Ribeiro", "Marco Tulio", ""], ["Shah", "Julie", ""]]}, {"id": "2104.14406", "submitter": "Kyungsik Kim", "authors": "Ki-Hong Shin, Jae-Won Jung, Ki-Ho Chang, Dong-In Lee, Cheol-Hwan You,\n  Kyungsik Kim", "title": "Dynamical prediction of two meteorological factors using the deep neural\n  network and the long short-term memory $(2)$", "comments": "22 pages, 8 figures, 4 Tables. arXiv admin note: substantial text\n  overlap with arXiv:2101.09356", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cond-mat.dis-nn cond-mat.stat-mech", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents the predictive accuracy using two-variate meteorological\nfactors, average temperature and average humidity, in neural network\nalgorithms. We analyze result in five learning architectures such as the\ntraditional artificial neural network, deep neural network, and extreme\nlearning machine, long short-term memory, and long-short-term memory with\npeephole connections, after manipulating the computer-simulation. Our neural\nnetwork modes are trained on the daily time-series dataset during seven years\n(from 2014 to 2020). From the trained results for 2500, 5000, and 7500 epochs,\nwe obtain the predicted accuracies of the meteorological factors produced from\noutputs in ten metropolitan cities (Seoul, Daejeon, Daegu, Busan, Incheon,\nGwangju, Pohang, Mokpo, Tongyeong, and Jeonju). The error statistics is found\nfrom the result of outputs, and we compare these values to each other after the\nmanipulation of five neural networks. As using the long-short-term memory model\nin testing 1 (the average temperature predicted from the input layer with six\ninput nodes), Tonyeong has the lowest root mean squared error (RMSE) value of\n0.866 $(%)$ in summer from the computer-simulation in order to predict the\ntemperature. To predict the humidity, the RMSE is shown the lowest value of\n5.732 $(%)$, when using the long short-term memory model in summer in Mokpo in\ntesting 2 (the average humidity predicted from the input layer with six input\nnodes). Particularly, the long short-term memory model is is found to be more\naccurate in forecasting daily levels than other neural network models in\ntemperature and humidity forecastings. Our result may provide a\ncomputer-simuation basis for the necessity of exploring and develping a novel\nneural network evaluation method in the future.\n", "versions": [{"version": "v1", "created": "Wed, 28 Apr 2021 06:23:40 GMT"}], "update_date": "2021-04-30", "authors_parsed": [["Shin", "Ki-Hong", ""], ["Jung", "Jae-Won", ""], ["Chang", "Ki-Ho", ""], ["Lee", "Dong-In", ""], ["You", "Cheol-Hwan", ""], ["Kim", "Kyungsik", ""]]}, {"id": "2104.14420", "submitter": "Panyanat Aonpong", "authors": "Panyanat Aonpong, Yutaro Iwamoto, Xian-Hua Han, Lanfen Lin, Yen-Wei\n  Chen", "title": "Genotype-Guided Radiomics Signatures for Recurrence Prediction of\n  Non-Small-Cell Lung Cancer", "comments": "11 pages, 9 figures, 4 Tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Non-small cell lung cancer (NSCLC) is a serious disease and has a high\nrecurrence rate after the surgery. Recently, many machine learning methods have\nbeen proposed for recurrence prediction. The methods using gene data have high\nprediction accuracy but require high cost. Although the radiomics signatures\nusing only CT image are not expensive, its accuracy is relatively low. In this\npaper, we propose a genotype-guided radiomics method (GGR) for obtaining high\nprediction accuracy with low cost. We used a public radiogenomics dataset of\nNSCLC, which includes CT images and gene data. The proposed method is a\ntwo-step method, which consists of two models. The first model is a gene\nestimation model, which is used to estimate the gene expression from radiomics\nfeatures and deep features extracted from computer tomography (CT) image. The\nsecond model is used to predict the recurrence using the estimated gene\nexpression data. The proposed GGR method designed based on hybrid features\nwhich is combination of handcrafted-based and deep learning-based. The\nexperiments demonstrated that the prediction accuracy can be improved\nsignificantly from 78.61% (existing radiomics method) and 79.14% (deep learning\nmethod) to 83.28% by the proposed GGR.\n", "versions": [{"version": "v1", "created": "Thu, 29 Apr 2021 15:34:50 GMT"}], "update_date": "2021-04-30", "authors_parsed": [["Aonpong", "Panyanat", ""], ["Iwamoto", "Yutaro", ""], ["Han", "Xian-Hua", ""], ["Lin", "Lanfen", ""], ["Chen", "Yen-Wei", ""]]}, {"id": "2104.14421", "submitter": "Andrew Wilson", "authors": "Pavel Izmailov, Sharad Vikram, Matthew D. Hoffman, Andrew Gordon\n  Wilson", "title": "What Are Bayesian Neural Network Posteriors Really Like?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The posterior over Bayesian neural network (BNN) parameters is extremely\nhigh-dimensional and non-convex. For computational reasons, researchers\napproximate this posterior using inexpensive mini-batch methods such as\nmean-field variational inference or stochastic-gradient Markov chain Monte\nCarlo (SGMCMC). To investigate foundational questions in Bayesian deep\nlearning, we instead use full-batch Hamiltonian Monte Carlo (HMC) on modern\narchitectures. We show that (1) BNNs can achieve significant performance gains\nover standard training and deep ensembles; (2) a single long HMC chain can\nprovide a comparable representation of the posterior to multiple shorter\nchains; (3) in contrast to recent studies, we find posterior tempering is not\nneeded for near-optimal performance, with little evidence for a \"cold\nposterior\" effect, which we show is largely an artifact of data augmentation;\n(4) BMA performance is robust to the choice of prior scale, and relatively\nsimilar for diagonal Gaussian, mixture of Gaussian, and logistic priors; (5)\nBayesian neural networks show surprisingly poor generalization under domain\nshift; (6) while cheaper alternatives such as deep ensembles and SGMCMC methods\ncan provide good generalization, they provide distinct predictive distributions\nfrom HMC. Notably, deep ensemble predictive distributions are similarly close\nto HMC as standard SGLD, and closer than standard variational inference.\n", "versions": [{"version": "v1", "created": "Thu, 29 Apr 2021 15:38:46 GMT"}], "update_date": "2021-04-30", "authors_parsed": [["Izmailov", "Pavel", ""], ["Vikram", "Sharad", ""], ["Hoffman", "Matthew D.", ""], ["Wilson", "Andrew Gordon", ""]]}, {"id": "2104.14429", "submitter": "Daniel Hesslow", "authors": "Daniel Hesslow, Alessandro Cappelli, Igor Carron, Laurent Daudet,\n  Rapha\\\"el Lafargue, Kilian M\\\"uller, Ruben Ohana, Gustave Pariente, and\n  Iacopo Poli", "title": "Photonic co-processors in HPC: using LightOn OPUs for Randomized\n  Numerical Linear Algebra", "comments": "Add \"This project has received funding from the European Union's\n  Horizon 2020 research and innovation programme under the Marie\n  Sklodowska-Curie grant agreement No 860830\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Randomized Numerical Linear Algebra (RandNLA) is a powerful class of methods,\nwidely used in High Performance Computing (HPC). RandNLA provides approximate\nsolutions to linear algebra functions applied to large signals, at reduced\ncomputational costs. However, the randomization step for dimensionality\nreduction may itself become the computational bottleneck on traditional\nhardware. Leveraging near constant-time linear random projections delivered by\nLightOn Optical Processing Units we show that randomization can be\nsignificantly accelerated, at negligible precision loss, in a wide range of\nimportant RandNLA algorithms, such as RandSVD or trace estimators.\n", "versions": [{"version": "v1", "created": "Thu, 29 Apr 2021 15:48:52 GMT"}, {"version": "v2", "created": "Fri, 7 May 2021 13:03:34 GMT"}], "update_date": "2021-05-10", "authors_parsed": [["Hesslow", "Daniel", ""], ["Cappelli", "Alessandro", ""], ["Carron", "Igor", ""], ["Daudet", "Laurent", ""], ["Lafargue", "Rapha\u00ebl", ""], ["M\u00fcller", "Kilian", ""], ["Ohana", "Ruben", ""], ["Pariente", "Gustave", ""], ["Poli", "Iacopo", ""]]}, {"id": "2104.14433", "submitter": "Amy Marconnet", "authors": "Meghavin Bhatasana, Amy Marconnet", "title": "Machine-Learning Assisted Optimization Strategies for Phase Change\n  Materials Embedded within Electronic Packages", "comments": "13 pages, 8 figures, 7 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.ET cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Leveraging the latent heat of phase change materials (PCMs) can reduce the\npeak temperatures and transient variations in temperature in electronic\ndevices. But as the power levels increase, the thermal conduction pathway from\nthe heat source to the heat sink limits the effectiveness of these systems. In\nthis work, we evaluate embedding the PCM within the silicon device layer of an\nelectronic device to minimize the thermal resistance between the source and the\nPCM to minimize this thermal resistance and enhance the thermal performance of\nthe device. The geometry and material properties of the embedded PCM regions\nare optimized using a combination of parametric and machine learning\nalgorithms. For a fixed geometry, considering commercially available materials,\nSolder 174 significantly outperforms other organic and metallic PCMs. Also with\na fixed geometry, the optimal melting points to minimize the peak temperature\nis higher than the optimal melting point to minimize the amplitude of the\ntransient temperature oscillation, and both optima increase with increasing\nheater power. Extending beyond conventional optimization strategies, genetic\nalgorithms and particle swarm optimization with and without neural network\nsurrogate models are used to enable optimization of many geometric and material\nproperties. For the test case evaluated, the optimized geometries and\nproperties are similar between all ML-assisted algorithms, but the\ncomputational time depends on the technique. Ultimately, the optimized design\nwith embedded phase change materials reduces the maximum temperature rise by\n19% and the fluctuations by up to 88% compared to devices without PCM.\n", "versions": [{"version": "v1", "created": "Wed, 21 Apr 2021 19:20:04 GMT"}], "update_date": "2021-04-30", "authors_parsed": [["Bhatasana", "Meghavin", ""], ["Marconnet", "Amy", ""]]}, {"id": "2104.14435", "submitter": "Changshun Wu", "authors": "Changshun Wu, Yli\\`es Falcone, Saddek Bensalem", "title": "Customizable Reference Runtime Monitoring of Neural Networks using\n  Resolution Boxes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classification neural networks fail to detect inputs that do not fall inside\nthe classes they have been trained for. Runtime monitoring techniques on the\nneuron activation pattern can be used to detect such inputs. We present an\napproach for monitoring classification systems via data abstraction. Data\nabstraction relies on the notion of box with a resolution. Box-based\nabstraction consists in representing a set of values by its minimal and maximal\nvalues in each dimension. We augment boxes with a notion of resolution and\ndefine their clustering coverage, which is intuitively a quantitative metric\nthat indicates the abstraction quality. This allows studying the effect of\ndifferent clustering parameters on the constructed boxes and estimating an\ninterval of sub-optimal parameters. Moreover, we automatically construct\nmonitors that leverage both the correct and incorrect behaviors of a system.\nThis allows checking the size of the monitor abstractions and analyzing the\nseparability of the network. Monitors are obtained by combining the\nsub-monitors of each class of the system placed at some selected layers. Our\nexperiments demonstrate the effectiveness of our clustering coverage estimation\nand show how to assess the effectiveness and precision of monitors according to\nthe selected clustering parameter and monitored layers.\n", "versions": [{"version": "v1", "created": "Sun, 25 Apr 2021 21:58:02 GMT"}, {"version": "v2", "created": "Mon, 12 Jul 2021 12:21:53 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Wu", "Changshun", ""], ["Falcone", "Yli\u00e8s", ""], ["Bensalem", "Saddek", ""]]}, {"id": "2104.14444", "submitter": "Sven Krippendorf", "authors": "Marc Syvaeri, Sven Krippendorf", "title": "Improving Simulations with Symmetry Control Neural Networks", "comments": "7 pages, 2 figures, accepted as workshop paper at ICLR 2021 SimDL\n  Workshop", "journal-ref": null, "doi": null, "report-no": "LMU-ASC 11/21, MPP-2021-67", "categories": "cs.LG physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The dynamics of physical systems is often constrained to lower dimensional\nsub-spaces due to the presence of conserved quantities. Here we propose a\nmethod to learn and exploit such symmetry constraints building upon Hamiltonian\nNeural Networks. By enforcing cyclic coordinates with appropriate loss\nfunctions, we find that we can achieve improved accuracy on simple classical\ndynamics tasks. By fitting analytic formulae to the latent variables in our\nnetwork we recover that our networks are utilizing conserved quantities such as\n(angular) momentum.\n", "versions": [{"version": "v1", "created": "Thu, 29 Apr 2021 16:04:13 GMT"}], "update_date": "2021-04-30", "authors_parsed": [["Syvaeri", "Marc", ""], ["Krippendorf", "Sven", ""]]}, {"id": "2104.14449", "submitter": "Deng-Cheng Yan", "authors": "Dengcheng Yan, Youwen Zhang, Wei Li, Yiwen Zhang", "title": "MUSE: Multi-faceted Attention for Signed Network Embedding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Signed network embedding is an approach to learn low-dimensional\nrepresentations of nodes in signed networks with both positive and negative\nlinks, which facilitates downstream tasks such as link prediction with general\ndata mining frameworks. Due to the distinct properties and significant added\nvalue of negative links, existing signed network embedding methods usually\ndesign dedicated methods based on social theories such as balance theory and\nstatus theory. However, existing signed network embedding methods ignore the\ncharacteristics of multiple facets of each node and mix them up in one single\nrepresentation, which limits the ability to capture the fine-grained attentions\nbetween node pairs. In this paper, we propose MUSE, a MUlti-faceted\nattention-based Signed network Embedding framework to tackle this problem.\nSpecifically, a joint intra- and inter-facet attention mechanism is introduced\nto aggregate fine-grained information from neighbor nodes. Moreover, balance\ntheory is also utilized to guide information aggregation from multi-order\nbalanced and unbalanced neighbors. Experimental results on four real-world\nsigned network datasets demonstrate the effectiveness of our proposed\nframework.\n", "versions": [{"version": "v1", "created": "Thu, 29 Apr 2021 16:09:35 GMT"}], "update_date": "2021-04-30", "authors_parsed": [["Yan", "Dengcheng", ""], ["Zhang", "Youwen", ""], ["Li", "Wei", ""], ["Zhang", "Yiwen", ""]]}, {"id": "2104.14474", "submitter": "Xingang Wang Professor", "authors": "Han Zhang, Huawei Fan, Liang Wang, and Xingang Wang", "title": "Learning Hamiltonian dynamics by reservoir computer", "comments": "11 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG nlin.CD", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Reconstructing the KAM dynamics diagram of Hamiltonian system from the time\nseries of a limited number of parameters is an outstanding question in\nnonlinear science, especially when the Hamiltonian governing the system\ndynamics are unknown. Here, we demonstrate that this question can be addressed\nby the machine learning approach knowing as reservoir computer (RC).\nSpecifically, we show that without prior knowledge about the Hamilton's\nequations of motion, the trained RC is able to not only predict the short-term\nevolution of the system state, but also replicate the long-term ergodic\nproperties of the system dynamics. Furthermore, by the architecture of\nparameter-aware RC, we also show that the RC trained by the time series\nacquired at a handful parameters is able to reconstruct the entire KAM dynamics\ndiagram with a high precision by tuning a control parameter externally. The\nfeasibility and efficiency of the learning techniques are demonstrated in two\nclassical nonlinear Hamiltonian systems, namely the double-pendulum oscillator\nand the standard map. Our study indicates that, as a complex dynamical system,\nRC is able to learn from data the Hamiltonian.\n", "versions": [{"version": "v1", "created": "Sat, 24 Apr 2021 03:08:02 GMT"}], "update_date": "2021-04-30", "authors_parsed": [["Zhang", "Han", ""], ["Fan", "Huawei", ""], ["Wang", "Liang", ""], ["Wang", "Xingang", ""]]}, {"id": "2104.14478", "submitter": "Markus Freitag", "authors": "Markus Freitag, George Foster, David Grangier, Viresh Ratnakar, Qijun\n  Tan, Wolfgang Macherey", "title": "Experts, Errors, and Context: A Large-Scale Study of Human Evaluation\n  for Machine Translation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Human evaluation of modern high-quality machine translation systems is a\ndifficult problem, and there is increasing evidence that inadequate evaluation\nprocedures can lead to erroneous conclusions. While there has been considerable\nresearch on human evaluation, the field still lacks a commonly-accepted\nstandard procedure. As a step toward this goal, we propose an evaluation\nmethodology grounded in explicit error analysis, based on the Multidimensional\nQuality Metrics (MQM) framework. We carry out the largest MQM research study to\ndate, scoring the outputs of top systems from the WMT 2020 shared task in two\nlanguage pairs using annotations provided by professional translators with\naccess to full document context. We analyze the resulting data extensively,\nfinding among other results a substantially different ranking of evaluated\nsystems from the one established by the WMT crowd workers, exhibiting a clear\npreference for human over machine output. Surprisingly, we also find that\nautomatic metrics based on pre-trained embeddings can outperform human crowd\nworkers. We make our corpus publicly available for further research.\n", "versions": [{"version": "v1", "created": "Thu, 29 Apr 2021 16:42:09 GMT"}], "update_date": "2021-04-30", "authors_parsed": [["Freitag", "Markus", ""], ["Foster", "George", ""], ["Grangier", "David", ""], ["Ratnakar", "Viresh", ""], ["Tan", "Qijun", ""], ["Macherey", "Wolfgang", ""]]}, {"id": "2104.14500", "submitter": "Gary Weiss", "authors": "Gary M. Weiss, Nam Nguyen, Karla Dominguez and Daniel D. Leeds", "title": "Identifying Hubs in Undergraduate Course Networks Based on Scaled\n  Co-Enrollments: Extended Version", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Understanding course enrollment patterns is valuable to predict upcoming\ndemands for future courses, and to provide student with realistic courses to\npursue given their current backgrounds. This study uses undergraduate student\nenrollment data to form networks of courses where connections are based on\nstudent co-enrollments. The course networks generated in this paper are based\non eight years of undergraduate course enrollment data from a large\nmetropolitan university. The networks are analyzed to identify \"hub\" courses\noften taken with many other courses. Two notions of hubs are considered: one\nfocused on raw popularity across all students, and one focused on proportional\nlikelihoods of co-enrollment with other courses. A variety of network metrics\nare calculated to evaluate the course networks. Academic departments and\nhigh-level academic categories, such as Humanities vs STEM, are studied for\ntheir influence over course groupings. The identification of hub courses has\npractical applications, since it can help better predict the impact of changes\nin course offerings and in course popularity, and in the case of\ninterdisciplinary hub courses, can be used to increase or decrease interest and\nenrollments in specific academic departments and areas.\n", "versions": [{"version": "v1", "created": "Tue, 27 Apr 2021 16:26:29 GMT"}], "update_date": "2021-04-30", "authors_parsed": [["Weiss", "Gary M.", ""], ["Nguyen", "Nam", ""], ["Dominguez", "Karla", ""], ["Leeds", "Daniel D.", ""]]}, {"id": "2104.14504", "submitter": "Cyrus Cousins", "authors": "Cyrus Cousins", "title": "An Axiomatic Theory of Provably-Fair Welfare-Centric Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address an inherent difficulty in welfare-theoretic fair machine learning\nby proposing an equivalently axiomatically-justified alternative and studying\nthe resulting computational and statistical learning questions. Welfare metrics\nquantify overall wellbeing across a population of one or more groups, and\nwelfare-based objectives and constraints have recently been proposed to\nincentivize fair machine learning methods to produce satisfactory solutions\nthat consider the diverse needs of multiple groups. Unfortunately, many\nmachine-learning problems are more naturally cast as loss minimization tasks,\nrather than utility maximization, which complicates direct application of\nwelfare-centric methods to fair machine learning. In this work, we define a\ncomplementary measure, termed malfare, measuring overall societal harm (rather\nthan wellbeing), with axiomatic justification via the standard axioms of\ncardinal welfare. We then cast fair machine learning as malfare minimization\nover the risk values (expected losses) of each group. Surprisingly, the axioms\nof cardinal welfare (malfare) dictate that this is not equivalent to simply\ndefining utility as negative loss. Building upon these concepts, we define\nfair-PAC (FPAC) learning, where an FPAC learner is an algorithm that learns an\n$\\varepsilon$-$\\delta$ malfare-optimal model with bounded sample complexity,\nfor any data distribution, and for any (axiomatically justified) malfare\nconcept. Finally, we show broad conditions under which, with appropriate\nmodifications, standard PAC-learners may be converted to FPAC learners. This\nplaces FPAC learning on firm theoretical ground, as it yields statistical and\ncomputational efficiency guarantees for many well-studied machine-learning\nmodels, and is also practically relevant, as it democratizes fair ML by\nproviding concrete training algorithms and rigorous generalization guarantees\nfor these models\n", "versions": [{"version": "v1", "created": "Thu, 29 Apr 2021 17:18:17 GMT"}, {"version": "v2", "created": "Mon, 26 Jul 2021 17:57:49 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Cousins", "Cyrus", ""]]}, {"id": "2104.14506", "submitter": "Guang Yang A", "authors": "Qinghao Ye and Jun Xia and Guang Yang", "title": "Explainable AI For COVID-19 CT Classifiers: An Initial Comparison Study", "comments": "6 pages, 4 figures, IEEE CBMS 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial Intelligence (AI) has made leapfrogs in development across all the\nindustrial sectors especially when deep learning has been introduced. Deep\nlearning helps to learn the behaviour of an entity through methods of\nrecognising and interpreting patterns. Despite its limitless potential, the\nmystery is how deep learning algorithms make a decision in the first place.\nExplainable AI (XAI) is the key to unlocking AI and the black-box for deep\nlearning. XAI is an AI model that is programmed to explain its goals, logic,\nand decision making so that the end users can understand. The end users can be\ndomain experts, regulatory agencies, managers and executive board members, data\nscientists, users that use AI, with or without awareness, or someone who is\naffected by the decisions of an AI model. Chest CT has emerged as a valuable\ntool for the clinical diagnostic and treatment management of the lung diseases\nassociated with COVID-19. AI can support rapid evaluation of CT scans to\ndifferentiate COVID-19 findings from other lung diseases. However, how these AI\ntools or deep learning algorithms reach such a decision and which are the most\ninfluential features derived from these neural networks with typically deep\nlayers are not clear. The aim of this study is to propose and develop XAI\nstrategies for COVID-19 classification models with an investigation of\ncomparison. The results demonstrate promising quantification and qualitative\nvisualisations that can further enhance the clinician's understanding and\ndecision making with more granular information from the results given by the\nlearned XAI models.\n", "versions": [{"version": "v1", "created": "Sun, 25 Apr 2021 23:39:14 GMT"}], "update_date": "2021-04-30", "authors_parsed": [["Ye", "Qinghao", ""], ["Xia", "Jun", ""], ["Yang", "Guang", ""]]}, {"id": "2104.14516", "submitter": "Adam Zsolt Wagner", "authors": "Adam Zsolt Wagner", "title": "Constructions in combinatorics via neural networks", "comments": "23 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We demonstrate how by using a reinforcement learning algorithm, the deep\ncross-entropy method, one can find explicit constructions and counterexamples\nto several open conjectures in extremal combinatorics and graph theory. Amongst\nthe conjectures we refute are a question of Brualdi and Cao about maximizing\npermanents of pattern avoiding matrices, and several problems related to the\nadjacency and distance eigenvalues of graphs.\n", "versions": [{"version": "v1", "created": "Thu, 29 Apr 2021 17:32:56 GMT"}], "update_date": "2021-04-30", "authors_parsed": [["Wagner", "Adam Zsolt", ""]]}, {"id": "2104.14526", "submitter": "Tian Tong", "authors": "Tian Tong, Cong Ma, Ashley Prater-Bennette, Erin Tripp, Yuejie Chi", "title": "Scaling and Scalability: Provable Nonconvex Low-Rank Tensor Estimation\n  from Incomplete Measurements", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT eess.SP math.IT math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tensors, which provide a powerful and flexible model for representing\nmulti-attribute data and multi-way interactions, play an indispensable role in\nmodern data science across various fields in science and engineering. A\nfundamental task is to faithfully recover the tensor from highly incomplete\nmeasurements in a statistically and computationally efficient manner.\nHarnessing the low-rank structure of tensors in the Tucker decomposition, this\npaper develops a scaled gradient descent (ScaledGD) algorithm to directly\nrecover the tensor factors with tailored spectral initializations, and shows\nthat it provably converges at a linear rate independent of the condition number\nof the ground truth tensor for two canonical problems -- tensor completion and\ntensor regression -- as soon as the sample size is above the order of $n^{3/2}$\nignoring other dependencies, where $n$ is the dimension of the tensor. This\nleads to an extremely scalable approach to low-rank tensor estimation compared\nwith prior art, which suffers from at least one of the following drawbacks:\nextreme sensitivity to ill-conditioning, high per-iteration costs in terms of\nmemory and computation, or poor sample complexity guarantees. To the best of\nour knowledge, ScaledGD is the first algorithm that achieves near-optimal\nstatistical and computational complexities simultaneously for low-rank tensor\ncompletion with the Tucker decomposition. Our algorithm highlights the power of\nappropriate preconditioning in accelerating nonconvex statistical estimation,\nwhere the iteration-varying preconditioners promote desirable invariance\nproperties of the trajectory with respect to the underlying symmetry in\nlow-rank tensor factorization.\n", "versions": [{"version": "v1", "created": "Thu, 29 Apr 2021 17:44:49 GMT"}], "update_date": "2021-05-03", "authors_parsed": [["Tong", "Tian", ""], ["Ma", "Cong", ""], ["Prater-Bennette", "Ashley", ""], ["Tripp", "Erin", ""], ["Chi", "Yuejie", ""]]}, {"id": "2104.14527", "submitter": "Virginie Do", "authors": "Virginie Do, Sam Corbett-Davies, Jamal Atif, Nicolas Usunier", "title": "Online certification of preference-based fairness for personalized\n  recommender systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose to assess the fairness of personalized recommender systems in the\nsense of envy-freeness: every (group of) user(s) should prefer their\nrecommendations to the recommendations of other (groups of) users. Auditing for\nenvy-freeness requires probing user preferences to detect potential blind\nspots, which may deteriorate recommendation performance. To control the cost of\nexploration, we propose an auditing algorithm based on pure exploration and\nconservative constraints in multi-armed bandits. We study, both theoretically\nand empirically, the trade-offs achieved by this algorithm.\n", "versions": [{"version": "v1", "created": "Thu, 29 Apr 2021 17:45:27 GMT"}], "update_date": "2021-05-03", "authors_parsed": [["Do", "Virginie", ""], ["Corbett-Davies", "Sam", ""], ["Atif", "Jamal", ""], ["Usunier", "Nicolas", ""]]}, {"id": "2104.14534", "submitter": "Raffaello Camoriano", "authors": "Diego Ferigo, Raffaello Camoriano, Paolo Maria Viceconte, Daniele\n  Calandriello, Silvio Traversaro, Lorenzo Rosasco and Daniele Pucci", "title": "On the Emergence of Whole-body Strategies from Humanoid Robot\n  Push-recovery Learning", "comments": "Co-first authors: Diego Ferigo and Raffaello Camoriano; 8 pages", "journal-ref": "IEEE Robotics and Automation Letters (RA-L) 2021", "doi": "10.1109/LRA.2021.3076955", "report-no": null, "categories": "cs.RO cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Balancing and push-recovery are essential capabilities enabling humanoid\nrobots to solve complex locomotion tasks. In this context, classical control\nsystems tend to be based on simplified physical models and hard-coded\nstrategies. Although successful in specific scenarios, this approach requires\ndemanding tuning of parameters and switching logic between\nspecifically-designed controllers for handling more general perturbations. We\napply model-free Deep Reinforcement Learning for training a general and robust\nhumanoid push-recovery policy in a simulation environment. Our method targets\nhigh-dimensional whole-body humanoid control and is validated on the iCub\nhumanoid. Reward components incorporating expert knowledge on humanoid control\nenable fast learning of several robust behaviors by the same policy, spanning\nthe entire body. We validate our method with extensive quantitative analyses in\nsimulation, including out-of-sample tasks which demonstrate policy robustness\nand generalization, both key requirements towards real-world robot deployment.\n", "versions": [{"version": "v1", "created": "Thu, 29 Apr 2021 17:49:20 GMT"}], "update_date": "2021-05-03", "authors_parsed": [["Ferigo", "Diego", ""], ["Camoriano", "Raffaello", ""], ["Viceconte", "Paolo Maria", ""], ["Calandriello", "Daniele", ""], ["Traversaro", "Silvio", ""], ["Rosasco", "Lorenzo", ""], ["Pucci", "Daniele", ""]]}, {"id": "2104.14535", "submitter": "Shelly Sheynin", "authors": "Shelly Sheynin, Sagie Benaim and Lior Wolf", "title": "A Hierarchical Transformation-Discriminating Generative Model for Few\n  Shot Anomaly Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Anomaly detection, the task of identifying unusual samples in data, often\nrelies on a large set of training samples. In this work, we consider the\nsetting of few-shot anomaly detection in images, where only a few images are\ngiven at training. We devise a hierarchical generative model that captures the\nmulti-scale patch distribution of each training image. We further enhance the\nrepresentation of our model by using image transformations and optimize\nscale-specific patch-discriminators to distinguish between real and fake\npatches of the image, as well as between different transformations applied to\nthose patches. The anomaly score is obtained by aggregating the patch-based\nvotes of the correct transformation across scales and image regions. We\ndemonstrate the superiority of our method on both the one-shot and few-shot\nsettings, on the datasets of Paris, CIFAR10, MNIST and FashionMNIST as well as\nin the setting of defect detection on MVTec. In all cases, our method\noutperforms the recent baseline methods.\n", "versions": [{"version": "v1", "created": "Thu, 29 Apr 2021 17:49:48 GMT"}], "update_date": "2021-04-30", "authors_parsed": [["Sheynin", "Shelly", ""], ["Benaim", "Sagie", ""], ["Wolf", "Lior", ""]]}, {"id": "2104.14537", "submitter": "Tianxiang Zhao", "authors": "Tianxiang Zhao, Enyan Dai, Kai Shu, Suhang Wang", "title": "You Can Still Achieve Fairness Without Sensitive Attributes: Exploring\n  Biases in Non-Sensitive Features", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Though machine learning models are achieving great success, ex-tensive\nstudies have exposed their disadvantage of inheriting latent discrimination and\nsocietal bias from the training data, which hinders their adoption on\nhigh-state applications. Thus, many efforts have been taken for developing fair\nmachine learning models. Most of them require that sensitive attributes are\navailable during training to learn fair models. However, in many real-world\napplications, it is usually infeasible to obtain the sensitive attribute due to\nprivacy or legal issues, which challenges existing fair classifiers. Though the\nsensitive attribute of each data sample is unknown, we observe that there are\nusually some non-sensitive features in the training data that are highly\ncorrelated with sensitive attributes, which can be used to alleviate the bias.\nTherefore, in this paper, we study a novel problem of exploring features that\nare highly correlated with sensitive attributes for learning fair and accurate\nclassifier without sensitive attributes. We theoretically show that by\nminimizing the correlation between these related features and model prediction,\nwe can learn a fair classifier. Based on this motivation, we propose a novel\nframework which simultaneously uses these related features for accurate\nprediction and regularizing the model to be fair. In addition, the model can\ndynamically adjust the importance weight of each related feature to balance the\ncontribution of the feature on model classification and fairness. Experimental\nresults on real-world datasets demonstrate the effectiveness of the proposed\nmodel for learning fair models with high classification accuracy.\n", "versions": [{"version": "v1", "created": "Thu, 29 Apr 2021 17:52:11 GMT"}, {"version": "v2", "created": "Sat, 1 May 2021 03:24:58 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Zhao", "Tianxiang", ""], ["Dai", "Enyan", ""], ["Shu", "Kai", ""], ["Wang", "Suhang", ""]]}, {"id": "2104.14538", "submitter": "Aditya Balu", "authors": "Aditya Balu, Sergio Botelho, Biswajit Khara, Vinay Rao, Chinmay Hegde,\n  Soumik Sarkar, Santi Adavani, Adarsh Krishnamurthy, Baskar\n  Ganapathysubramanian", "title": "Distributed Multigrid Neural Solvers on Megavoxel Domains", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  We consider the distributed training of large-scale neural networks that\nserve as PDE solvers producing full field outputs. We specifically consider\nneural solvers for the generalized 3D Poisson equation over megavoxel domains.\nA scalable framework is presented that integrates two distinct advances. First,\nwe accelerate training a large model via a method analogous to the multigrid\ntechnique used in numerical linear algebra. Here, the network is trained using\na hierarchy of increasing resolution inputs in sequence, analogous to the 'V',\n'W', 'F', and 'Half-V' cycles used in multigrid approaches. In conjunction with\nthe multi-grid approach, we implement a distributed deep learning framework\nwhich significantly reduces the time to solve. We show the scalability of this\napproach on both GPU (Azure VMs on Cloud) and CPU clusters (PSC Bridges2). This\napproach is deployed to train a generalized 3D Poisson solver that scales well\nto predict output full-field solutions up to the resolution of 512x512x512 for\na high dimensional family of inputs.\n", "versions": [{"version": "v1", "created": "Thu, 29 Apr 2021 17:53:22 GMT"}], "update_date": "2021-04-30", "authors_parsed": [["Balu", "Aditya", ""], ["Botelho", "Sergio", ""], ["Khara", "Biswajit", ""], ["Rao", "Vinay", ""], ["Hegde", "Chinmay", ""], ["Sarkar", "Soumik", ""], ["Adavani", "Santi", ""], ["Krishnamurthy", "Adarsh", ""], ["Ganapathysubramanian", "Baskar", ""]]}, {"id": "2104.14543", "submitter": "Tobias Haug", "authors": "Tobias Haug, M.S. Kim", "title": "Optimal training of variational quantum algorithms without barren\n  plateaus", "comments": "15 pages, 17 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variational quantum algorithms (VQAs) promise efficient use of near-term\nquantum computers. However, training VQAs often requires an extensive amount of\ntime and suffers from the barren plateau problem where the magnitude of the\ngradients vanishes with increasing number of qubits. Here, we show how to\noptimally train VQAs for learning quantum states. Parameterized quantum\ncircuits can form Gaussian kernels, which we use to derive adaptive learning\nrates for gradient ascent. We introduce the generalized quantum natural\ngradient that features stability and optimized movement in parameter space.\nBoth methods together outperform other optimization routines in training VQAs.\nOur methods also excel at numerically optimizing driving protocols for quantum\ncontrol problems. The gradients of the VQA do not vanish when the fidelity\nbetween the initial state and the state to be learned is bounded from below. We\nidentify a VQA for quantum simulation with such a constraint that thus can be\ntrained free of barren plateaus. Finally, we propose the application of\nGaussian kernels for quantum machine learning.\n", "versions": [{"version": "v1", "created": "Thu, 29 Apr 2021 17:54:59 GMT"}, {"version": "v2", "created": "Wed, 12 May 2021 14:26:13 GMT"}, {"version": "v3", "created": "Wed, 23 Jun 2021 13:34:29 GMT"}], "update_date": "2021-06-24", "authors_parsed": [["Haug", "Tobias", ""], ["Kim", "M. S.", ""]]}, {"id": "2104.14546", "submitter": "Bernd Rosenow", "authors": "Frederieke Richert, Roman Worschech, Bernd Rosenow", "title": "Soft Mode in the Dynamics of Over-realizable On-line Learning for Soft\n  Committee Machines", "comments": "5 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cond-mat.dis-nn cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over-parametrized deep neural networks trained by stochastic gradient descent\nare successful in performing many tasks of practical relevance. One aspect of\nover-parametrization is the possibility that the student network has a larger\nexpressivity than the data generating process. In the context of a\nstudent-teacher scenario, this corresponds to the so-called over-realizable\ncase, where the student network has a larger number of hidden units than the\nteacher. For on-line learning of a two-layer soft committee machine in the\nover-realizable case, we find that the approach to perfect learning occurs in a\npower-law fashion rather than exponentially as in the realizable case. All\nstudent nodes learn and replicate one of the teacher nodes if teacher and\nstudent outputs are suitably rescaled.\n", "versions": [{"version": "v1", "created": "Thu, 29 Apr 2021 17:55:58 GMT"}], "update_date": "2021-04-30", "authors_parsed": [["Richert", "Frederieke", ""], ["Worschech", "Roman", ""], ["Rosenow", "Bernd", ""]]}, {"id": "2104.14547", "submitter": "Anjana Deva Prasad", "authors": "Anjana Deva Prasad, Aditya Balu, Harshil Shah, Soumik Sarkar, Adarsh\n  Krishnamurthy", "title": "NURBS-Diff: A Differentiable NURBS Layer for Machine Learning CAD\n  Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Recent deep-learning-based techniques for the reconstruction of geometries\nfrom different input representations such as images and point clouds have been\ninstrumental in advancing research in geometric machine learning. Most of these\ntechniques rely on a triangular mesh representation for representing the\ngeometry, with very recent attempts in using B-splines. While Non-Uniform\nRational B-splines (NURBS) are the de facto standard in the CAD industry,\nminimal efforts have been made to bridge the gap between deep-learning\nframeworks and the NURBS representation for geometry. The backbone of modern\ndeep learning techniques is the use of a fully automatic differentiable\ndefinition for each mathematical operation to enable backpropagation of losses\nwhile training. In order to integrate the NURBS representation of CAD models\nwith deep learning methods, we propose a differentiable NURBS layer for\nevaluating the curve or surface given a set of NURBS parameters. We have\ndeveloped a NURBS layer defining the forward and backward pass required for\nautomatic differentiation. Our implementation is GPU accelerated and is\ndirectly integrated with PyTorch, a popular deep learning framework. We\ndemonstrate the efficacy of our NURBS layer by automatically incorporating it\nwith the stochastic gradient descent algorithm and performing CAD operations\nsuch as curve or surface fitting and surface offsetting. Further, we show its\nutility in deep learning applications such as point cloud reconstruction and\nstructural modeling and analysis of shell structures such as heart valves.\nThese examples show that our layer has better performance for certain deep\nlearning frameworks and can be directly integrated with any CAD deep-learning\nframework that require the use of NURBS.\n", "versions": [{"version": "v1", "created": "Thu, 29 Apr 2021 17:56:01 GMT"}], "update_date": "2021-04-30", "authors_parsed": [["Prasad", "Anjana Deva", ""], ["Balu", "Aditya", ""], ["Shah", "Harshil", ""], ["Sarkar", "Soumik", ""], ["Krishnamurthy", "Adarsh", ""]]}, {"id": "2104.14549", "submitter": "Hrishikesh Dutta", "authors": "Hrishikesh Dutta and Subir Biswas", "title": "Medium Access using Distributed Reinforcement Learning for IoTs with\n  Low-Complexity Wireless Transceivers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC cs.NI cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a distributed Reinforcement Learning (RL) based framework\nthat can be used for synthesizing MAC layer wireless protocols in IoT networks\nwith low-complexity wireless transceivers. The proposed framework does not rely\non complex hardware capabilities such as carrier sensing and its associated\nalgorithmic complexities that are often not supported in wireless transceivers\nof low-cost and low-energy IoT devices. In this framework, the access protocols\nare first formulated as Markov Decision Processes (MDP) and then solved using\nRL. A distributed and multi-Agent RL framework is used as the basis for\nprotocol synthesis. Distributed behavior makes the nodes independently learn\noptimal transmission strategies without having to rely on full network level\ninformation and direct knowledge of behavior of other nodes. The nodes learn to\nminimize packet collisions such that optimal throughput can be attained and\nmaintained for loading conditions that are higher than what the known benchmark\nprotocols (such as ALOHA) for IoT devices without complex transceivers. In\naddition, the nodes are observed to be able to learn to act optimally in the\npresence of heterogeneous loading and network topological conditions. Finally,\nthe proposed learning approach allows the wireless bandwidth to be fairly\ndistributed among network nodes in a way that is not dependent on such\nheterogeneities. Via simulation experiments, the paper demonstrates the\nperformance of the learning paradigm and its abilities to make nodes adapt\ntheir optimal transmission strategies on the fly in response to various network\ndynamics.\n", "versions": [{"version": "v1", "created": "Thu, 29 Apr 2021 17:57:43 GMT"}], "update_date": "2021-04-30", "authors_parsed": [["Dutta", "Hrishikesh", ""], ["Biswas", "Subir", ""]]}, {"id": "2104.14551", "submitter": "Lucy Chai", "authors": "Lucy Chai, Jun-Yan Zhu, Eli Shechtman, Phillip Isola, Richard Zhang", "title": "Ensembling with Deep Generative Views", "comments": "CVPR 2021 camera ready version; code available at\n  https://github.com/chail/gan-ensembling", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recent generative models can synthesize \"views\" of artificial images that\nmimic real-world variations, such as changes in color or pose, simply by\nlearning from unlabeled image collections. Here, we investigate whether such\nviews can be applied to real images to benefit downstream analysis tasks such\nas image classification. Using a pretrained generator, we first find the latent\ncode corresponding to a given real input image. Applying perturbations to the\ncode creates natural variations of the image, which can then be ensembled\ntogether at test-time. We use StyleGAN2 as the source of generative\naugmentations and investigate this setup on classification tasks involving\nfacial attributes, cat faces, and cars. Critically, we find that several design\ndecisions are required towards making this process work; the perturbation\nprocedure, weighting between the augmentations and original image, and training\nthe classifier on synthesized images can all impact the result. Currently, we\nfind that while test-time ensembling with GAN-based augmentations can offer\nsome small improvements, the remaining bottlenecks are the efficiency and\naccuracy of the GAN reconstructions, coupled with classifier sensitivities to\nartifacts in GAN-generated images.\n", "versions": [{"version": "v1", "created": "Thu, 29 Apr 2021 17:58:35 GMT"}], "update_date": "2021-04-30", "authors_parsed": [["Chai", "Lucy", ""], ["Zhu", "Jun-Yan", ""], ["Shechtman", "Eli", ""], ["Isola", "Phillip", ""], ["Zhang", "Richard", ""]]}, {"id": "2104.14554", "submitter": "L\\'eo Lebrat", "authors": "L\\'eo Lebrat, Rodrigo Santa Cruz, Clinton Fookes, Olivier Salvado", "title": "MongeNet: Efficient Sampler for Geometric Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in geometric deep-learning introduce complex computational\nchallenges for evaluating the distance between meshes. From a mesh model, point\nclouds are necessary along with a robust distance metric to assess surface\nquality or as part of the loss function for training models. Current methods\noften rely on a uniform random mesh discretization, which yields irregular\nsampling and noisy distance estimation. In this paper we introduce MongeNet, a\nfast and optimal transport based sampler that allows for an accurate\ndiscretization of a mesh with better approximation properties. We compare our\nmethod to the ubiquitous random uniform sampling and show that the\napproximation error is almost half with a very small computational overhead.\n", "versions": [{"version": "v1", "created": "Thu, 29 Apr 2021 17:59:01 GMT"}], "update_date": "2021-04-30", "authors_parsed": [["Lebrat", "L\u00e9o", ""], ["Cruz", "Rodrigo Santa", ""], ["Fookes", "Clinton", ""], ["Salvado", "Olivier", ""]]}, {"id": "2104.14558", "submitter": "Christoph Feichtenhofer", "authors": "Christoph Feichtenhofer, Haoqi Fan, Bo Xiong, Ross Girshick, Kaiming\n  He", "title": "A Large-Scale Study on Unsupervised Spatiotemporal Representation\n  Learning", "comments": "CVPR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a large-scale study on unsupervised spatiotemporal representation\nlearning from videos. With a unified perspective on four recent image-based\nframeworks, we study a simple objective that can easily generalize all these\nmethods to space-time. Our objective encourages temporally-persistent features\nin the same video, and in spite of its simplicity, it works surprisingly well\nacross: (i) different unsupervised frameworks, (ii) pre-training datasets,\n(iii) downstream datasets, and (iv) backbone architectures. We draw a series of\nintriguing observations from this study, e.g., we discover that encouraging\nlong-spanned persistency can be effective even if the timespan is 60 seconds.\nIn addition to state-of-the-art results in multiple benchmarks, we report a few\npromising cases in which unsupervised pre-training can outperform its\nsupervised counterpart. Code is made available at\nhttps://github.com/facebookresearch/SlowFast\n", "versions": [{"version": "v1", "created": "Thu, 29 Apr 2021 17:59:53 GMT"}], "update_date": "2021-04-30", "authors_parsed": [["Feichtenhofer", "Christoph", ""], ["Fan", "Haoqi", ""], ["Xiong", "Bo", ""], ["Girshick", "Ross", ""], ["He", "Kaiming", ""]]}, {"id": "2104.14562", "submitter": "Wenqiang Pu", "authors": "Wenqiang Pu, Shahana Ibrahim, Xiao Fu, and Mingyi Hong", "title": "Stochastic Mirror Descent for Low-Rank Tensor Decomposition Under\n  Non-Euclidean Losses", "comments": "Submitted to Transaction on Signal Processing", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work considers low-rank canonical polyadic decomposition (CPD) under a\nclass of non-Euclidean loss functions that frequently arise in statistical\nmachine learning and signal processing. These loss functions are often used for\ncertain types of tensor data, e.g., count and binary tensors, where the least\nsquares loss is considered unnatural.Compared to the least squares loss, the\nnon-Euclidean losses are generally more challenging to handle. Non-Euclidean\nCPD has attracted considerable interests and a number of prior works exist.\nHowever, pressing computational and theoretical challenges, such as scalability\nand convergence issues, still remain. This work offers a unified stochastic\nalgorithmic framework for large-scale CPD decomposition under a variety of\nnon-Euclidean loss functions. Our key contribution lies in a tensor fiber\nsampling strategy-based flexible stochastic mirror descent framework.\nLeveraging the sampling scheme and the multilinear algebraic structure of\nlow-rank tensors, the proposed lightweight algorithm ensures global convergence\nto a stationary point under reasonable conditions. Numerical results show that\nour framework attains promising non-Euclidean CPD performance. The proposed\nframework also exhibits substantial computational savings compared to\nstate-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Thu, 29 Apr 2021 14:58:25 GMT"}], "update_date": "2021-05-03", "authors_parsed": [["Pu", "Wenqiang", ""], ["Ibrahim", "Shahana", ""], ["Fu", "Xiao", ""], ["Hong", "Mingyi", ""]]}, {"id": "2104.14579", "submitter": "Matteo Zecchin", "authors": "Matteo Zecchin, Mahdi Boloursaz Mashhadi, Mikolaj Jankowski, Deniz\n  Gunduz, Marios Kountouris, David Gesbert", "title": "A Novel Look at LIDAR-aided Data-driven mmWave Beam Selection", "comments": "Submitted for publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG eess.SP math.IT", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Efficient millimeter wave (mmWave) beam selection in\nvehicle-to-infrastructure (V2I) communication is a crucial yet challenging task\ndue to the narrow mmWave beamwidth and high user mobility. To reduce the search\noverhead of iterative beam discovery procedures, contextual information from\nlight detection and ranging (LIDAR) sensors mounted on vehicles has been\nleveraged by data-driven methods to produce useful side information. In this\npaper, we propose a lightweight neural network (NN) architecture along with the\ncorresponding LIDAR preprocessing, which significantly outperforms previous\nworks. Our solution comprises multiple novelties that improve both the\nconvergence speed and the final accuracy of the model. In particular, we define\na novel loss function inspired by the knowledge distillation idea, introduce a\ncurriculum training approach exploiting line-of-sight (LOS)/non-line-of-sight\n(NLOS) information, and we propose a non-local attention module to improve the\nperformance for the more challenging NLOS cases. Simulation results on\nbenchmark datasets show that, utilizing solely LIDAR data and the receiver\nposition, our NN-based beam selection scheme can achieve 79.9% throughput of an\nexhaustive beam sweeping approach without any beam search overhead and 95% by\nsearching among as few as 6 beams.\n", "versions": [{"version": "v1", "created": "Thu, 29 Apr 2021 18:07:31 GMT"}, {"version": "v2", "created": "Mon, 3 May 2021 12:02:06 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Zecchin", "Matteo", ""], ["Mashhadi", "Mahdi Boloursaz", ""], ["Jankowski", "Mikolaj", ""], ["Gunduz", "Deniz", ""], ["Kountouris", "Marios", ""], ["Gesbert", "David", ""]]}, {"id": "2104.14616", "submitter": "Adrian Moldovan", "authors": "Adrian Moldovan and Angel Ca\\c{t}aron and R\\u{a}zvan Andonie", "title": "Learning in Feedforward Neural Networks Accelerated by Transfer Entropy", "comments": "18 pages, 13 figures", "journal-ref": null, "doi": "10.3390/e22010102", "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Current neural networks architectures are many times harder to train because\nof the increasing size and complexity of the used datasets. Our objective is to\ndesign more efficient training algorithms utilizing causal relationships\ninferred from neural networks. The transfer entropy (TE) was initially\nintroduced as an information transfer measure used to quantify the statistical\ncoherence between events (time series). Later, it was related to causality,\neven if they are not the same. There are only few papers reporting applications\nof causality or TE in neural networks. Our contribution is an\ninformation-theoretical method for analyzing information transfer between the\nnodes of feedforward neural networks. The information transfer is measured by\nthe TE of feedback neural connections. Intuitively, TE measures the relevance\nof a connection in the network and the feedback amplifies this connection. We\nintroduce a backpropagation type training algorithm that uses TE feedback\nconnections to improve its performance.\n", "versions": [{"version": "v1", "created": "Thu, 29 Apr 2021 19:07:07 GMT"}], "update_date": "2021-05-03", "authors_parsed": [["Moldovan", "Adrian", ""], ["Ca\u0163aron", "Angel", ""], ["Andonie", "R\u0103zvan", ""]]}, {"id": "2104.14623", "submitter": "Alexander Wong", "authors": "Xiaoyu Wen, Mahmoud Famouri, Andrew Hryniowski, and Alexander Wong", "title": "AttendSeg: A Tiny Attention Condenser Neural Network for Semantic\n  Segmentation on the Edge", "comments": "5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this study, we introduce \\textbf{AttendSeg}, a low-precision, highly\ncompact deep neural network tailored for on-device semantic segmentation.\nAttendSeg possesses a self-attention network architecture comprising of\nlight-weight attention condensers for improved spatial-channel selective\nattention at a very low complexity. The unique macro-architecture and\nmicro-architecture design properties of AttendSeg strike a strong balance\nbetween representational power and efficiency, achieved via a machine-driven\ndesign exploration strategy tailored specifically for the task at hand.\nExperimental results demonstrated that the proposed AttendSeg can achieve\nsegmentation accuracy comparable to much larger deep neural networks with\ngreater complexity while possessing a significantly lower architecture and\ncomputational complexity (requiring as much as >27x fewer MACs, >72x fewer\nparameters, and >288x lower weight memory requirements), making it well-suited\nfor TinyML applications on the edge.\n", "versions": [{"version": "v1", "created": "Thu, 29 Apr 2021 19:19:04 GMT"}], "update_date": "2021-05-03", "authors_parsed": [["Wen", "Xiaoyu", ""], ["Famouri", "Mahmoud", ""], ["Hryniowski", "Andrew", ""], ["Wong", "Alexander", ""]]}, {"id": "2104.14624", "submitter": "Martin Grohe", "authors": "Martin Grohe", "title": "The Logic of Graph Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph neural networks (GNNs) are deep learning architectures for machine\nlearning problems on graphs. It has recently been shown that the expressiveness\nof GNNs can be characterised precisely by the combinatorial Weisfeiler-Leman\nalgorithms and by finite variable counting logics. The correspondence has even\nled to new, higher-order GNNs corresponding to the WL algorithm in higher\ndimensions.\n  The purpose of this paper is to explain these descriptive characterisations\nof GNNs.\n", "versions": [{"version": "v1", "created": "Thu, 29 Apr 2021 19:23:26 GMT"}], "update_date": "2021-05-03", "authors_parsed": [["Grohe", "Martin", ""]]}, {"id": "2104.14628", "submitter": "Debora Caldarola", "authors": "Debora Caldarola, Massimiliano Mancini, Fabio Galasso, Marco Ciccone,\n  Emanuele Rodol\\`a, Barbara Caputo", "title": "Cluster-driven Graph Federated Learning over Multiple Domains", "comments": "Accepted to CVPR21 Workshop Learning from Limited or Imperfect Data\n  (L^2ID)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated Learning (FL) deals with learning a central model (i.e. the server)\nin privacy-constrained scenarios, where data are stored on multiple devices\n(i.e. the clients). The central model has no direct access to the data, but\nonly to the updates of the parameters computed locally by each client. This\nraises a problem, known as statistical heterogeneity, because the clients may\nhave different data distributions (i.e. domains). This is only partly\nalleviated by clustering the clients. Clustering may reduce heterogeneity by\nidentifying the domains, but it deprives each cluster model of the data and\nsupervision of others. Here we propose a novel Cluster-driven Graph Federated\nLearning (FedCG). In FedCG, clustering serves to address statistical\nheterogeneity, while Graph Convolutional Networks (GCNs) enable sharing\nknowledge across them. FedCG: i) identifies the domains via an FL-compliant\nclustering and instantiates domain-specific modules (residual branches) for\neach domain; ii) connects the domain-specific modules through a GCN at training\nto learn the interactions among domains and share knowledge; and iii) learns to\ncluster unsupervised via teacher-student classifier-training iterations and to\naddress novel unseen test domains via their domain soft-assignment scores.\nThanks to the unique interplay of GCN over clusters, FedCG achieves the\nstate-of-the-art on multiple FL benchmarks.\n", "versions": [{"version": "v1", "created": "Thu, 29 Apr 2021 19:31:19 GMT"}], "update_date": "2021-05-03", "authors_parsed": [["Caldarola", "Debora", ""], ["Mancini", "Massimiliano", ""], ["Galasso", "Fabio", ""], ["Ciccone", "Marco", ""], ["Rodol\u00e0", "Emanuele", ""], ["Caputo", "Barbara", ""]]}, {"id": "2104.14629", "submitter": "Xiao-Yun Zhou", "authors": "Xiao-Yun Zhou, Bolin Lai, Weijian Li, Yirui Wang, Kang Zheng, Fakai\n  Wang, Chihung Lin, Le Lu, Lingyun Huang, Mei Han, Guotong Xie, Jing Xiao, Kuo\n  Chang-Fu, Adam Harrison, Shun Miao", "title": "Scalable Semi-supervised Landmark Localization for X-ray Images using\n  Few-shot Deep Adaptive Graph", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Landmark localization plays an important role in medical image analysis.\nLearning based methods, including CNN and GCN, have demonstrated the\nstate-of-the-art performance. However, most of these methods are\nfully-supervised and heavily rely on manual labeling of a large training\ndataset. In this paper, based on a fully-supervised graph-based method, DAG, we\nproposed a semi-supervised extension of it, termed few-shot DAG, \\ie five-shot\nDAG. It first trains a DAG model on the labeled data and then fine-tunes the\npre-trained model on the unlabeled data with a teacher-student SSL mechanism.\nIn addition to the semi-supervised loss, we propose another loss using JS\ndivergence to regulate the consistency of the intermediate feature maps. We\nextensively evaluated our method on pelvis, hand and chest landmark detection\ntasks. Our experiment results demonstrate consistent and significant\nimprovements over previous methods.\n", "versions": [{"version": "v1", "created": "Thu, 29 Apr 2021 19:46:18 GMT"}], "update_date": "2021-05-03", "authors_parsed": [["Zhou", "Xiao-Yun", ""], ["Lai", "Bolin", ""], ["Li", "Weijian", ""], ["Wang", "Yirui", ""], ["Zheng", "Kang", ""], ["Wang", "Fakai", ""], ["Lin", "Chihung", ""], ["Lu", "Le", ""], ["Huang", "Lingyun", ""], ["Han", "Mei", ""], ["Xie", "Guotong", ""], ["Xiao", "Jing", ""], ["Chang-Fu", "Kuo", ""], ["Harrison", "Adam", ""], ["Miao", "Shun", ""]]}, {"id": "2104.14633", "submitter": "Jordan Cambe", "authors": "Krittika D'Silva, Jordan Cambe, Anastasios Noulas, Cecilia Mascolo,\n  Adam Waksman", "title": "Modelling Urban Dynamics with Multi-Modal Graph Convolutional Networks", "comments": "10 pages, 4 figures. arXiv admin note: substantial text overlap with\n  arXiv:2104.13981", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.soc-ph cs.AI cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modelling the dynamics of urban venues is a challenging task as it is\nmultifaceted in nature. Demand is a function of many complex and nonlinear\nfeatures such as neighborhood composition, real-time events, and seasonality.\nRecent advances in Graph Convolutional Networks (GCNs) have had promising\nresults as they build a graphical representation of a system and harness the\npotential of deep learning architectures. However, there has been limited work\nusing GCNs in a temporal setting to model dynamic dependencies of the network.\nFurther, within the context of urban environments, there has been no prior work\nusing dynamic GCNs to support venue demand analysis and prediction. In this\npaper, we propose a novel deep learning framework which aims to better model\nthe popularity and growth of urban venues. Using a longitudinal dataset from\nlocation technology platform Foursquare, we model individual venues and venue\ntypes across London and Paris. First, representing cities as connected networks\nof venues, we quantify their structure and note a strong community structure in\nthese retail networks, an observation that highlights the interplay of\ncooperative and competitive forces that emerge in local ecosystems of retail\nbusinesses. Next, we present our deep learning architecture which integrates\nboth spatial and topological features into a temporal model which predicts the\ndemand of a venue at the subsequent time-step. Our experiments demonstrate that\nour model can learn spatio-temporal trends of venue demand and consistently\noutperform baseline models. Relative to state-of-the-art deep learning models,\nour model reduces the RSME by ~ 28% in London and ~ 13% in Paris. Our approach\nhighlights the power of complex network measures and GCNs in building\nprediction models for urban environments. The model could have numerous\napplications within the retail sector to better model venue demand and growth.\n", "versions": [{"version": "v1", "created": "Thu, 29 Apr 2021 20:00:47 GMT"}], "update_date": "2021-05-03", "authors_parsed": [["D'Silva", "Krittika", ""], ["Cambe", "Jordan", ""], ["Noulas", "Anastasios", ""], ["Mascolo", "Cecilia", ""], ["Waksman", "Adam", ""]]}, {"id": "2104.14644", "submitter": "Safa Alver", "authors": "Safa Alver, Doina Precup", "title": "What is Going on Inside Recurrent Meta Reinforcement Learning Agents?", "comments": "Accepted to the Never-Ending Reinforcement Learning Workshop at ICLR\n  2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recurrent meta reinforcement learning (meta-RL) agents are agents that employ\na recurrent neural network (RNN) for the purpose of \"learning a learning\nalgorithm\". After being trained on a pre-specified task distribution, the\nlearned weights of the agent's RNN are said to implement an efficient learning\nalgorithm through their activity dynamics, which allows the agent to quickly\nsolve new tasks sampled from the same distribution. However, due to the\nblack-box nature of these agents, the way in which they work is not yet fully\nunderstood. In this study, we shed light on the internal working mechanisms of\nthese agents by reformulating the meta-RL problem using the Partially\nObservable Markov Decision Process (POMDP) framework. We hypothesize that the\nlearned activity dynamics is acting as belief states for such agents. Several\nillustrative experiments suggest that this hypothesis is true, and that\nrecurrent meta-RL agents can be viewed as agents that learn to act optimally in\npartially observable environments consisting of multiple related tasks. This\nview helps in understanding their failure cases and some interesting\nmodel-based results reported in the literature.\n", "versions": [{"version": "v1", "created": "Thu, 29 Apr 2021 20:34:39 GMT"}], "update_date": "2021-05-03", "authors_parsed": [["Alver", "Safa", ""], ["Precup", "Doina", ""]]}, {"id": "2104.14654", "submitter": "Yang Chen", "authors": "Yang Chen, Jiamou Liu and Bakhadyr Khoussainov", "title": "Agent-Level Maximum Entropy Inverse Reinforcement Learning for Mean\n  Field Games", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mean field games (MFG) facilitate the application of reinforcement learning\n(RL) in large-scale multi-agent systems, through reducing interplays among\nagents to those between an individual agent and the average effect from the\npopulation. However, RL agents are notoriously prone to unexpected behaviours\ndue to the reward mis-specification. Although inverse RL (IRL) holds promise\nfor automatically acquiring suitable rewards from demonstrations, its extension\nto MFG is challenging due to the complicated notion of mean-field-type\nequilibria and the coupling between agent-level and population-level dynamics.\nTo this end, we propose a novel IRL framework for MFG, called Mean Field IRL\n(MFIRL), where we build upon a new equilibrium concept and the maximum entropy\nIRL framework. Crucially, MFIRL is brought forward as the first IRL method that\ncan recover the agent-level (ground-truth) reward functions for MFG.\nExperiments show the superior performance of MFIRL on sample efficiency, reward\nrecovery and robustness against varying environment dynamics, compared to the\nstate-of-the-art method.\n", "versions": [{"version": "v1", "created": "Thu, 29 Apr 2021 21:03:49 GMT"}, {"version": "v2", "created": "Sun, 30 May 2021 22:37:43 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Chen", "Yang", ""], ["Liu", "Jiamou", ""], ["Khoussainov", "Bakhadyr", ""]]}, {"id": "2104.14657", "submitter": "Jing Qian", "authors": "Shurui Li, Jianqin Xu and Jing Qian", "title": "Revisiting the double-well problem by deep learning with a hybrid\n  network", "comments": "11 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.comp-ph cs.LG quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Solving physical problems by deep learning is accurate and efficient mainly\naccounting for the use of an elaborate neural network. We propose a novel\nhybrid network which integrates two different kinds of neural networks: LSTM\nand ResNet, in order to overcome the difficulty met in solving\nstrongly-oscillating dynamics of the system's time evolution. By taking the\ndouble-well model as an example we show that our new method can benefit from a\npre-learning and verification of the periodicity of frequency by using the LSTM\nnetwork, simultaneously making a high-fidelity prediction about the whole\ndynamics of system with ResNet, which is impossibly achieved in the case of\nsingle network. Such a hybrid network can be applied for solving cooperative\ndynamics in a system with fast spatial or temporal modulations, promising for\nrealistic oscillation calculations under experimental conditions.\n", "versions": [{"version": "v1", "created": "Sun, 25 Apr 2021 07:51:43 GMT"}], "update_date": "2021-05-03", "authors_parsed": [["Li", "Shurui", ""], ["Xu", "Jianqin", ""], ["Qian", "Jing", ""]]}, {"id": "2104.14658", "submitter": "Ariful Azad", "authors": "Nicholas Majeske, Bidisha Abesh, Chen Zhu, Ariful Azad", "title": "Inductive Predictions of Extreme Hydrologic Events in The Wabash River\n  Watershed", "comments": "5 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG physics.geo-ph", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We present a machine learning method to predict extreme hydrologic events\nfrom spatially and temporally varying hydrological and meteorological data. We\nused a timestep reduction technique to reduce the computational and memory\nrequirements and trained a bidirection LSTM network to predict soil water and\nstream flow from time series data observed and simulated over eighty years in\nthe Wabash River Watershed. We show that our simple model can be trained much\nfaster than complex attention networks such as GeoMAN without sacrificing\naccuracy. Based on the predicted values of soil water and stream flow, we\npredict the occurrence and severity of extreme hydrologic events such as\ndroughts. We also demonstrate that extreme events can be predicted in\ngeographical locations separate from locations observed during the training\nprocess. This spatially-inductive setting enables us to predict extreme events\nin other areas in the US and other parts of the world using our model trained\nwith the Wabash Basin data.\n", "versions": [{"version": "v1", "created": "Sun, 25 Apr 2021 02:26:09 GMT"}], "update_date": "2021-05-03", "authors_parsed": [["Majeske", "Nicholas", ""], ["Abesh", "Bidisha", ""], ["Zhu", "Chen", ""], ["Azad", "Ariful", ""]]}, {"id": "2104.14659", "submitter": "Bjorn Burkle", "authors": "Michael Andrews, Bjorn Burkle, Yi-fan Chen, Davide DiCroce, Sergei\n  Gleyzer, Ulrich Heintz, Meenakshi Narain, Manfred Paulini, Nikolas Pervan,\n  Yusef Shafi, Wei Sun, Emanuele Usai, Kun Yang", "title": "End-to-End Jet Classification of Boosted Top Quarks with the CMS Open\n  Data", "comments": "14 pages, 5 figures, 7 tables; v1: unpublished", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.data-an cs.CV cs.LG hep-ex", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We describe a novel application of the end-to-end deep learning technique to\nthe task of discriminating top quark-initiated jets from those originating from\nthe hadronization of a light quark or a gluon. The end-to-end deep learning\ntechnique combines deep learning algorithms and low-level detector\nrepresentation of the high-energy collision event. In this study, we use\nlow-level detector information from the simulated CMS Open Data samples to\nconstruct the top jet classifiers. To optimize classifier performance we\nprogressively add low-level information from the CMS tracking detector,\nincluding pixel detector reconstructed hits and impact parameters, and\ndemonstrate the value of additional tracking information even when no new\nspatial structures are added. Relying only on calorimeter energy deposits and\nreconstructed pixel detector hits, the end-to-end classifier achieves an AUC\nscore of 0.975$\\pm$0.002 for the task of classifying boosted top quark jets.\nAfter adding derived track quantities, the classifier AUC score increases to\n0.9824$\\pm$0.0013, serving as the first performance benchmark for these CMS\nOpen Data samples. We additionally provide a timing performance comparison of\ndifferent processor unit architectures for training the network.\n", "versions": [{"version": "v1", "created": "Mon, 19 Apr 2021 19:36:43 GMT"}, {"version": "v2", "created": "Mon, 26 Jul 2021 14:43:45 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Andrews", "Michael", ""], ["Burkle", "Bjorn", ""], ["Chen", "Yi-fan", ""], ["DiCroce", "Davide", ""], ["Gleyzer", "Sergei", ""], ["Heintz", "Ulrich", ""], ["Narain", "Meenakshi", ""], ["Paulini", "Manfred", ""], ["Pervan", "Nikolas", ""], ["Shafi", "Yusef", ""], ["Sun", "Wei", ""], ["Usai", "Emanuele", ""], ["Yang", "Kun", ""]]}, {"id": "2104.14661", "submitter": "Tianyu Lu", "authors": "Tianyu Lu, Alex X. Lu, Alan M. Moses", "title": "Random Embeddings and Linear Regression can Predict Protein Function", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.BM cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Large self-supervised models pretrained on millions of protein sequences have\nrecently gained popularity in generating embeddings of protein sequences for\nprotein function prediction. However, the absence of random baselines makes it\ndifficult to conclude whether pretraining has learned useful information for\nprotein function prediction. Here we show that one-hot encoding and random\nembeddings, both of which do not require any pretraining, are strong baselines\nfor protein function prediction across 14 diverse sequence-to-function tasks.\n", "versions": [{"version": "v1", "created": "Sun, 25 Apr 2021 23:22:04 GMT"}], "update_date": "2021-05-03", "authors_parsed": [["Lu", "Tianyu", ""], ["Lu", "Alex X.", ""], ["Moses", "Alan M.", ""]]}, {"id": "2104.14670", "submitter": "Doseok Jang", "authors": "Doseok Jang, Lucas Spangher, Manan Khattar, Utkarsha Agwan, Costas\n  Spanos", "title": "Using Meta Reinforcement Learning to Bridge the Gap between Simulation\n  and Experiment in Energy Demand Response", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Our team is proposing to run a full-scale energy demand response experiment\nin an office building. Although this is an exciting endeavor which will provide\nvalue to the community, collecting training data for the reinforcement learning\nagent is costly and will be limited. In this work, we apply a meta-learning\narchitecture to warm start the experiment with simulated tasks, to increase\nsample efficiency. We present results that demonstrate a similar a step up in\ncomplexity still corresponds with better learning.\n", "versions": [{"version": "v1", "created": "Thu, 29 Apr 2021 21:55:04 GMT"}, {"version": "v2", "created": "Mon, 17 May 2021 06:09:31 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Jang", "Doseok", ""], ["Spangher", "Lucas", ""], ["Khattar", "Manan", ""], ["Agwan", "Utkarsha", ""], ["Spanos", "Costas", ""]]}, {"id": "2104.14671", "submitter": "Toufique Ahmed Mr.", "authors": "Toufique Ahmed, Noah Rose Ledesma, Premkumar Devanbu", "title": "SYNFIX: Automatically Fixing Syntax Errors using Compiler Diagnostics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Beginning programmers struggle with the complex grammar of modern programming\nlanguages like Java, and make lot of syntax errors. The diagnostic syntax error\nmessages from compilers and IDEs are sometimes useful, but often the messages\nare cryptic and puzzling. Students could be helped, and instructors' time\nsaved, by automated repair suggestions when dealing with syntax errors. Large\nsamples of student errors and fixes are now available, offering the possibility\nof data-driven machine-learning approaches to help students fix syntax errors.\nCurrent machine-learning approaches do a reasonable job fixing syntax errors in\nshorter programs, but don't work as well even for moderately longer programs.\nWe introduce SYNFIX, a machine-learning based tool that substantially improves\non the state-of-the-art, by learning to use compiler diagnostics, employing a\nvery large neural model that leverages unsupervised pre-training, and relying\non multi-label classification rather than autoregressive synthesis to generate\nthe (repaired) output. We describe SYNFIX's architecture in detail, and provide\na detailed evaluation. We have built SYNFIX into a free, open-source version of\nVisual Studio Code; we make all our source code and models freely available.\n", "versions": [{"version": "v1", "created": "Thu, 29 Apr 2021 21:57:44 GMT"}], "update_date": "2021-05-03", "authors_parsed": [["Ahmed", "Toufique", ""], ["Ledesma", "Noah Rose", ""], ["Devanbu", "Premkumar", ""]]}, {"id": "2104.14672", "submitter": "Trevor Avant", "authors": "Trevor Avant and Kristi A. Morgansen", "title": "Analytical bounds on the local Lipschitz constants of ReLU networks", "comments": "11 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we determine analytical upper bounds on the local Lipschitz\nconstants of feedforward neural networks with ReLU activation functions. We do\nso by deriving Lipschitz constants and bounds for ReLU, affine-ReLU, and max\npooling functions, and combining the results to determine a network-wide bound.\nOur method uses several insights to obtain tight bounds, such as keeping track\nof the zero elements of each layer, and analyzing the composition of affine and\nReLU functions. Furthermore, we employ a careful computational approach which\nallows us to apply our method to large networks such as AlexNet and VGG-16. We\npresent several examples using different networks, which show how our local\nLipschitz bounds are tighter than the global Lipschitz bounds. We also show how\nour method can be applied to provide adversarial bounds for classification\nnetworks. These results show that our method produces the largest known bounds\non minimum adversarial perturbations for large networks such as AlexNet and\nVGG-16.\n", "versions": [{"version": "v1", "created": "Thu, 29 Apr 2021 21:57:47 GMT"}], "update_date": "2021-05-03", "authors_parsed": [["Avant", "Trevor", ""], ["Morgansen", "Kristi A.", ""]]}, {"id": "2104.14677", "submitter": "Leila Zahedi", "authors": "Leila Zahedi, Farid Ghareh Mohammadi, Shabnam Rezapour, Matthew W.\n  Ohland, M. Hadi Amini", "title": "Search Algorithms for Automated Hyper-Parameter Tuning", "comments": "10 pages, 3 figure, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning is a powerful method for modeling in different fields such\nas education. Its capability to accurately predict students' success makes it\nan ideal tool for decision-making tasks related to higher education. The\naccuracy of machine learning models depends on selecting the proper\nhyper-parameters. However, it is not an easy task because it requires time and\nexpertise to tune the hyper-parameters to fit the machine learning model. In\nthis paper, we examine the effectiveness of automated hyper-parameter tuning\ntechniques to the realm of students' success. Therefore, we develop two\nautomated Hyper-Parameter Optimization methods, namely grid search and random\nsearch, to assess and improve a previous study's performance. The experiment\nresults show that applying random search and grid search on machine learning\nalgorithms improves accuracy. We empirically show automated methods'\nsuperiority on real-world educational data (MIDFIELD) for tuning HPs of\nconventional machine learning classifiers. This work emphasizes the\neffectiveness of automated hyper-parameter optimization while applying machine\nlearning in the education field to aid faculties, directors', or non-expert\nusers' decisions to improve students' success.\n", "versions": [{"version": "v1", "created": "Thu, 29 Apr 2021 22:11:52 GMT"}], "update_date": "2021-05-03", "authors_parsed": [["Zahedi", "Leila", ""], ["Mohammadi", "Farid Ghareh", ""], ["Rezapour", "Shabnam", ""], ["Ohland", "Matthew W.", ""], ["Amini", "M. Hadi", ""]]}, {"id": "2104.14715", "submitter": "Salar Safarkhani", "authors": "Pola Lydia Lagari, Lefteri H. Tsoukalas, Salar Safarkhani, Isaac E.\n  Lagaris", "title": "Eliminating Multicollinearity Issues in Neural Network Ensembles:\n  Incremental, Negatively Correlated, Optimal Convex Blending", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a {features, target} dataset, we introduce an incremental algorithm\nthat constructs an aggregate regressor, using an ensemble of neural networks.\nIt is well known that ensemble methods suffer from the multicollinearity issue,\nwhich is the manifestation of redundancy arising mainly due to the common\ntraining-dataset. In the present incremental approach, at each stage we\noptimally blend the aggregate regressor with a newly trained neural network\nunder a convexity constraint which, if necessary, induces negative\ncorrelations. Under this framework, collinearity issues do not arise at all,\nrendering so the method both accurate and robust.\n", "versions": [{"version": "v1", "created": "Fri, 30 Apr 2021 01:32:08 GMT"}], "update_date": "2021-05-03", "authors_parsed": [["Lagari", "Pola Lydia", ""], ["Tsoukalas", "Lefteri H.", ""], ["Safarkhani", "Salar", ""], ["Lagaris", "Isaac E.", ""]]}, {"id": "2104.14734", "submitter": "Dan Shiebler", "authors": "Dan Shiebler", "title": "Flattening Multiparameter Hierarchical Clustering Functors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We bring together topological data analysis, applied category theory, and\nmachine learning to study multiparameter hierarchical clustering. We begin by\nintroducing a procedure for flattening multiparameter hierarchical clusterings.\nWe demonstrate that this procedure is a functor from a category of\nmultiparameter hierarchical partitions to a category of binary integer\nprograms. We also include empirical results demonstrating its effectiveness.\nNext, we introduce a Bayesian update algorithm for learning clustering\nparameters from data. We demonstrate that the composition of this algorithm\nwith our flattening procedure satisfies a consistency property.\n", "versions": [{"version": "v1", "created": "Fri, 30 Apr 2021 03:10:20 GMT"}], "update_date": "2021-05-03", "authors_parsed": [["Shiebler", "Dan", ""]]}, {"id": "2104.14744", "submitter": "Sam Ganzfried", "authors": "Sam Ganzfried", "title": "Human strategic decision making in parametrized games", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI cs.LG econ.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many real-world games contain parameters which can affect payoffs, action\nspaces, and information states. For fixed values of the parameters, the game\ncan be solved using standard algorithms. However, in many settings agents must\nact without knowing the values of the parameters that will be encountered in\nadvance. Often the decisions must be made by a human under time and resource\nconstraints, and it is unrealistic to assume that a human can solve the game in\nreal time. We present a new framework that enables human decision makers to\nmake fast decisions without the aid of real-time solvers. We demonstrate\napplicability to a variety of situations including settings with multiple\nplayers and imperfect information.\n", "versions": [{"version": "v1", "created": "Fri, 30 Apr 2021 03:40:27 GMT"}], "update_date": "2021-05-10", "authors_parsed": [["Ganzfried", "Sam", ""]]}, {"id": "2104.14753", "submitter": "Rajiv Movva", "authors": "Rajiv Movva, Jonathan Frankle, Michael Carbin", "title": "Studying the Consistency and Composability of Lottery Ticket Pruning\n  Masks", "comments": "Workshop on Science and Engineering of Deep Learning (ICLR 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Magnitude pruning is a common, effective technique to identify sparse\nsubnetworks at little cost to accuracy. In this work, we ask whether a\nparticular architecture's accuracy-sparsity tradeoff can be improved by\ncombining pruning information across multiple runs of training. From a shared\nResNet-20 initialization, we train several network copies (\\emph{siblings}) to\ncompletion using different SGD data orders on CIFAR-10. While the siblings'\npruning masks are naively not much more similar than chance, starting sibling\ntraining after a few epochs of shared pretraining significantly increases\npruning overlap. We then choose a subnetwork by either (1) taking all weights\nthat survive pruning in any sibling (mask union), or (2) taking only the\nweights that survive pruning across all siblings (mask intersection). The\nresulting subnetwork is retrained. Strikingly, we find that union and\nintersection masks perform very similarly. Both methods match the\naccuracy-sparsity tradeoffs of the one-shot magnitude pruning baseline, even\nwhen we combine masks from up to $k = 10$ siblings.\n", "versions": [{"version": "v1", "created": "Fri, 30 Apr 2021 04:38:06 GMT"}], "update_date": "2021-05-03", "authors_parsed": [["Movva", "Rajiv", ""], ["Frankle", "Jonathan", ""], ["Carbin", "Michael", ""]]}, {"id": "2104.14754", "submitter": "Hyunsu Kim", "authors": "Hyunsu Kim, Yunjey Choi, Junho Kim, Sungjoo Yoo, Youngjung Uh", "title": "Exploiting Spatial Dimensions of Latent in GAN for Real-time Image\n  Editing", "comments": "Accepted to CVPR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Generative adversarial networks (GANs) synthesize realistic images from\nrandom latent vectors. Although manipulating the latent vectors controls the\nsynthesized outputs, editing real images with GANs suffers from i)\ntime-consuming optimization for projecting real images to the latent vectors,\nii) or inaccurate embedding through an encoder. We propose StyleMapGAN: the\nintermediate latent space has spatial dimensions, and a spatially variant\nmodulation replaces AdaIN. It makes the embedding through an encoder more\naccurate than existing optimization-based methods while maintaining the\nproperties of GANs. Experimental results demonstrate that our method\nsignificantly outperforms state-of-the-art models in various image manipulation\ntasks such as local editing and image interpolation. Last but not least,\nconventional editing methods on GANs are still valid on our StyleMapGAN. Source\ncode is available at https://github.com/naver-ai/StyleMapGAN.\n", "versions": [{"version": "v1", "created": "Fri, 30 Apr 2021 04:43:24 GMT"}, {"version": "v2", "created": "Wed, 23 Jun 2021 02:05:12 GMT"}], "update_date": "2021-06-24", "authors_parsed": [["Kim", "Hyunsu", ""], ["Choi", "Yunjey", ""], ["Kim", "Junho", ""], ["Yoo", "Sungjoo", ""], ["Uh", "Youngjung", ""]]}, {"id": "2104.14756", "submitter": "Hanyang Liu", "authors": "Hanyang Liu, Michael Montana, Dingwen Li, Thomas Kannampallil,\n  Chenyang Lu", "title": "Predicting Intraoperative Hypoxemia with Joint Sequence Autoencoder\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  We present an end-to-end model using streaming physiological time series to\naccurately predict near-term risk for hypoxemia, a rare, but life-threatening\ncondition known to cause serious patient harm during surgery. Our proposed\nmodel makes inference on both hypoxemia outcomes and future input sequences,\nenabled by a joint sequence autoencoder that simultaneously optimizes a\ndiscriminative decoder for label prediction, and two auxiliary decoders trained\nfor data reconstruction and forecast, which seamlessly learns future-indicative\nlatent representation. All decoders share a memory-based encoder that helps\ncapture the global dynamics of patient data. In a large surgical cohort of\n73,536 surgeries at a major academic medical center, our model outperforms all\nbaselines and gives a large performance gain over the state-of-the-art\nhypoxemia prediction system. With a high sensitivity cutoff at 80%, it presents\n99.36% precision in predicting hypoxemia and 86.81% precision in predicting the\nmuch more severe and rare hypoxemic condition, persistent hypoxemia. With\nexceptionally low rate of false alarms, our proposed model is promising in\nimproving clinical decision making and easing burden on the health system.\n", "versions": [{"version": "v1", "created": "Fri, 30 Apr 2021 05:01:50 GMT"}, {"version": "v2", "created": "Wed, 19 May 2021 06:56:42 GMT"}], "update_date": "2021-05-20", "authors_parsed": [["Liu", "Hanyang", ""], ["Montana", "Michael", ""], ["Li", "Dingwen", ""], ["Kannampallil", "Thomas", ""], ["Lu", "Chenyang", ""]]}, {"id": "2104.14767", "submitter": "Junghyuk Lee", "authors": "Junghyuk Lee and Jong-Seok Lee", "title": "TREND: Truncated Generalized Normal Density Estimation of Inception\n  Embeddings for Accurate GAN Evaluation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Evaluating image generation models such as generative adversarial networks\n(GANs) is a challenging problem. A common approach is to compare the\ndistributions of the set of ground truth images and the set of generated test\nimages. The Frech\\'et Inception distance is one of the most widely used metrics\nfor evaluation of GANs, which assumes that the features from a trained\nInception model for a set of images follow a normal distribution. In this\npaper, we argue that this is an over-simplified assumption, which may lead to\nunreliable evaluation results, and more accurate density estimation can be\nachieved using a truncated generalized normal distribution. Based on this, we\npropose a novel metric for accurate evaluation of GANs, named TREND (TRuncated\ngEneralized Normal Density estimation of inception embeddings). We demonstrate\nthat our approach significantly reduces errors of density estimation, which\nconsequently eliminates the risk of faulty evaluation results. Furthermore, we\nshow that the proposed metric significantly improves robustness of evaluation\nresults against variation of the number of image samples.\n", "versions": [{"version": "v1", "created": "Fri, 30 Apr 2021 05:51:07 GMT"}], "update_date": "2021-05-03", "authors_parsed": [["Lee", "Junghyuk", ""], ["Lee", "Jong-Seok", ""]]}, {"id": "2104.14777", "submitter": "Khayrul Bashar", "authors": "Md. Khayrul Bashar", "title": "Event-driven timeseries analysis and the comparison of public reactions\n  on COVID-19", "comments": "15 pages, 10 figures, 6 tables, International Conference on Big Data\n  and Application (BDAP 2021), for associated file, see\n  https://aircconline.com/csit/abstract/v11n5/csit110507.html", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The rapid spread of COVID-19 has already affected human lives throughout the\nglobe. Governments of different countries have taken various measures, but how\nthey affected people lives is not clear. In this study, a rule-based and a\nmachine-learning based models are applied to answer the above question using\npublic tweets from Japan, USA, UK, and Australia. Two polarity timeseries\n(meanPol and pnRatio) and two events, namely \"lockdown or emergency (LED)\" and\n\"the economic support package (ESP)\", are considered in this study. Statistical\ntesting on the sub-series around LED and ESP events showed their positive\nimpacts to the people of (UK and Australia) and (USA and UK), respectively\nunlike Japanese people that showed opposite effects. Manual validation with the\nrelevant tweets showed an agreement with the statistical results. A case study\nwith Japanese tweets using supervised logistic regression classifies tweets\ninto heath-worry, economy-worry and other classes with 83.11% accuracy.\nPredicted tweets around events re-confirm the statistical outcomes.\n", "versions": [{"version": "v1", "created": "Fri, 30 Apr 2021 06:14:53 GMT"}], "update_date": "2021-05-03", "authors_parsed": [["Bashar", "Md. Khayrul", ""]]}, {"id": "2104.14778", "submitter": "Ryo Tamura", "authors": "Syun Izawa, Koki Kitai, Shu Tanaka, Ryo Tamura, Koji Tsuda", "title": "Continuous black-box optimization with quantum annealing and random\n  subspace coding", "comments": "8 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A black-box optimization algorithm such as Bayesian optimization finds\nextremum of an unknown function by alternating inference of the underlying\nfunction and optimization of an acquisition function. In a high-dimensional\nspace, such algorithms perform poorly due to the difficulty of acquisition\nfunction optimization. Herein, we apply quantum annealing (QA) to overcome the\ndifficulty in the continuous black-box optimization. As QA specializes in\noptimization of binary problems, a continuous vector has to be encoded to\nbinary, and the solution of QA has to be translated back. Our method has the\nfollowing three parts: 1) Random subspace coding based on axis-parallel\nhyperrectangles from continuous vector to binary vector. 2) A quadratic\nunconstrained binary optimization (QUBO) defined by acquisition function based\non nonnegative-weighted linear regression model which is solved by QA. 3) A\npenalization scheme to ensure that the QA solution can be translated back. It\nis shown in benchmark tests that its performance using D-Wave Advantage$^{\\rm\nTM}$ quantum annealer is competitive with a state-of-the-art method based on\nthe Gaussian process in high-dimensional problems. Our method may open up a new\npossibility of quantum annealing and other QUBO solvers including quantum\napproximate optimization algorithm (QAOA) using a gated-quantum computers, and\nexpand its range of application to continuous-valued problems.\n", "versions": [{"version": "v1", "created": "Fri, 30 Apr 2021 06:19:07 GMT"}], "update_date": "2021-05-03", "authors_parsed": [["Izawa", "Syun", ""], ["Kitai", "Koki", ""], ["Tanaka", "Shu", ""], ["Tamura", "Ryo", ""], ["Tsuda", "Koji", ""]]}, {"id": "2104.14787", "submitter": "Stefan Schrunner", "authors": "Anna Jenul, Stefan Schrunner, J\\\"urgen Pilz, Oliver Tomic", "title": "A User-Guided Bayesian Framework for Ensemble Feature Selection in Life\n  Science Applications (UBayFS)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training machine learning models on high-dimensional datasets is a\nchallenging task and requires measures to prevent overfitting and to keep model\ncomplexity low. Feature selection, which represents such a measure, plays a key\nrole in data preprocessing and may provide insights into the systematic\nvariation in the data. The latter aspect is crucial in domains that rely on\nmodel interpretability, such as life sciences. We propose UBayFS, an ensemble\nfeature selection technique, embedded in a Bayesian statistical framework. Our\napproach considers two sources of information: data and domain knowledge. We\nbuild an ensemble of elementary feature selectors that extract information from\nempirical data and aggregate this information to form a meta-model, which\ncompensates for inconsistencies between elementary feature selectors. The user\nguides UBayFS by weighting features and penalizing specific feature blocks or\ncombinations. The framework builds on a multinomial likelihood and a novel\nversion of constrained Dirichlet-type prior distribution, involving initial\nfeature weights and side constraints. In a quantitative evaluation, we\ndemonstrate that the presented framework allows for a balanced trade-off\nbetween user knowledge and data observations. A comparison with standard\nfeature selectors underlines that UBayFS achieves competitive performance,\nwhile providing additional flexibility to incorporate domain knowledge.\n", "versions": [{"version": "v1", "created": "Fri, 30 Apr 2021 06:51:33 GMT"}, {"version": "v2", "created": "Fri, 28 May 2021 16:21:17 GMT"}], "update_date": "2021-05-31", "authors_parsed": [["Jenul", "Anna", ""], ["Schrunner", "Stefan", ""], ["Pilz", "J\u00fcrgen", ""], ["Tomic", "Oliver", ""]]}, {"id": "2104.14808", "submitter": "Jungang Yang", "authors": "Jungang Yang, Liyao Xiang, Weiting Li, Wei Liu, Xinbing Wang", "title": "Improved Matrix Gaussian Mechanism for Differential Privacy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The wide deployment of machine learning in recent years gives rise to a great\ndemand for large-scale and high-dimensional data, for which the privacy raises\nserious concern. Differential privacy (DP) mechanisms are conventionally\ndeveloped for scalar values, not for structural data like matrices. Our work\nproposes Improved Matrix Gaussian Mechanism (IMGM) for matrix-valued DP, based\non the necessary and sufficient condition of $ (\\varepsilon,\\delta)\n$-differential privacy. IMGM only imposes constraints on the singular values of\nthe covariance matrices of the noise, which leaves room for design. Among the\nlegitimate noise distributions for matrix-valued DP, we find the optimal one\nturns out to be i.i.d. Gaussian noise, and the DP constraint becomes a noise\nlower bound on each element. We further derive a tight composition method for\nIMGM. Apart from the theoretical analysis, experiments on a variety of models\nand datasets also verify that IMGM yields much higher utility than the\nstate-of-the-art mechanisms at the same privacy guarantee.\n", "versions": [{"version": "v1", "created": "Fri, 30 Apr 2021 07:44:53 GMT"}], "update_date": "2021-05-03", "authors_parsed": [["Yang", "Jungang", ""], ["Xiang", "Liyao", ""], ["Li", "Weiting", ""], ["Liu", "Wei", ""], ["Wang", "Xinbing", ""]]}, {"id": "2104.14809", "submitter": "Z Yan", "authors": "Zijian Zhou and Zhenya Yan", "title": "Deep learning neural networks for the third-order nonlinear Schrodinger\n  equation: Solitons, breathers, and rogue waves", "comments": "12 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "nlin.PS cs.LG math-ph math.MP nlin.SI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The third-order nonlinear Schrodinger equation (alias the Hirota equation) is\ninvestigated via deep leaning neural networks, which describes the strongly\ndispersive ion-acoustic wave in plasma and the wave propagation of ultrashort\nlight pulses in optical fibers, as well as broader-banded waves on deep water.\nIn this paper, we use the physics-informed neural networks (PINNs) deep\nlearning method to explore the data-driven solutions (e.g., soliton, breather,\nand rogue waves) of the Hirota equation when the two types of the unperturbated\nand unperturbated (a 2% noise) training data are considered. Moreover, we use\nthe PINNs deep learning to study the data-driven discovery of parameters\nappearing in the Hirota equation with the aid of solitons.\n", "versions": [{"version": "v1", "created": "Fri, 30 Apr 2021 07:50:08 GMT"}], "update_date": "2021-05-03", "authors_parsed": [["Zhou", "Zijian", ""], ["Yan", "Zhenya", ""]]}, {"id": "2104.14821", "submitter": "Ayush Deva", "authors": "Ayush Deva, Siddhant Shingi, Avtansh Tiwari, Nayana Bannur, Sansiddh\n  Jain, Jerome White, Alpan Raval, Srujana Merugu", "title": "Interpretability of Epidemiological Models : The Curse of\n  Non-Identifiability", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Interpretability of epidemiological models is a key consideration, especially\nwhen these models are used in a public health setting. Interpretability is\nstrongly linked to the identifiability of the underlying model parameters,\ni.e., the ability to estimate parameter values with high confidence given\nobservations. In this paper, we define three separate notions of\nidentifiability that explore the different roles played by the model\ndefinition, the loss function, the fitting methodology, and the quality and\nquantity of data. We define an epidemiological compartmental model framework in\nwhich we highlight these non-identifiability issues and their mitigation.\n", "versions": [{"version": "v1", "created": "Fri, 30 Apr 2021 08:11:11 GMT"}], "update_date": "2021-05-03", "authors_parsed": [["Deva", "Ayush", ""], ["Shingi", "Siddhant", ""], ["Tiwari", "Avtansh", ""], ["Bannur", "Nayana", ""], ["Jain", "Sansiddh", ""], ["White", "Jerome", ""], ["Raval", "Alpan", ""], ["Merugu", "Srujana", ""]]}, {"id": "2104.14840", "submitter": "Zhishuai Guo", "authors": "Zhishuai Guo, Yi Xu, Wotao Yin, Rong Jin, Tianbao Yang", "title": "On Stochastic Moving-Average Estimators for Non-Convex Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we demonstrate the power of a widely used stochastic estimator\nbased on moving average (SEMA) on a range of stochastic non-convex optimization\nproblems, which only requires {\\bf a general unbiased stochastic oracle}. We\nanalyze various stochastic methods (existing or newly proposed) based on the\n{\\bf variance recursion property} of SEMA for three families of non-convex\noptimization, namely standard stochastic non-convex minimization, stochastic\nnon-convex strongly-concave min-max optimization, and stochastic bilevel\noptimization. Our contributions include: (i) for standard stochastic non-convex\nminimization, we present a simple and intuitive proof of convergence for a\nfamily Adam-style methods (including Adam) with an increasing or large\n\"momentum\" parameter for the first-order moment, which gives an alternative yet\nmore natural way to guarantee Adam converge; (ii) for stochastic non-convex\nstrongly-concave min-max optimization, we present a single-loop stochastic\ngradient descent ascent method based on the moving average estimators and\nestablish its oracle complexity of $O(1/\\epsilon^4)$ without using a large\nmini-batch size, addressing a gap in the literature; (iii) for stochastic\nbilevel optimization, we present a single-loop stochastic method based on the\nmoving average estimators and establish its oracle complexity of $\\widetilde\nO(1/\\epsilon^4)$ without computing the inverse or SVD of the Hessian matrix,\nimproving state-of-the-art results. For all these problems, we also establish a\nvariance diminishing result for the used stochastic gradient estimators.\n", "versions": [{"version": "v1", "created": "Fri, 30 Apr 2021 08:50:24 GMT"}, {"version": "v2", "created": "Thu, 3 Jun 2021 01:24:31 GMT"}], "update_date": "2021-06-04", "authors_parsed": [["Guo", "Zhishuai", ""], ["Xu", "Yi", ""], ["Yin", "Wotao", ""], ["Jin", "Rong", ""], ["Yang", "Tianbao", ""]]}, {"id": "2104.14847", "submitter": "Samantha Biegel", "authors": "Samantha Biegel, Rafah El-Khatib, Luiz Otavio Vilas Boas Oliveira, Max\n  Baak, Nanne Aben", "title": "Active WeaSuL: Improving Weak Supervision with Active Learning", "comments": "Accepted to the ICLR 2021 Workshop on Weakly Supervised Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The availability of labelled data is one of the main limitations in machine\nlearning. We can alleviate this using weak supervision: a framework that uses\nexpert-defined rules $\\boldsymbol{\\lambda}$ to estimate probabilistic labels\n$p(y|\\boldsymbol{\\lambda})$ for the entire data set. These rules, however, are\ndependent on what experts know about the problem, and hence may be inaccurate\nor may fail to capture important parts of the problem-space. To mitigate this,\nwe propose Active WeaSuL: an approach that incorporates active learning into\nweak supervision. In Active WeaSuL, experts do not only define rules, but they\nalso iteratively provide the true label for a small set of points where the\nweak supervision model is most likely to be mistaken, which are then used to\nbetter estimate the probabilistic labels. In this way, the weak labels provide\na warm start, which active learning then improves upon. We make two\ncontributions: 1) a modification of the weak supervision loss function, such\nthat the expert-labelled data inform and improve the combination of weak\nlabels; and 2) the maxKL divergence sampling strategy, which determines for\nwhich data points expert labelling is most beneficial. Our experiments show\nthat when the budget for labelling data is limited (e.g. $\\leq 60$ data\npoints), Active WeaSuL outperforms weak supervision, active learning, and\ncompeting strategies, with only a handful of labelled data points. This makes\nActive WeaSuL ideal for situations where obtaining labelled data is difficult.\n", "versions": [{"version": "v1", "created": "Fri, 30 Apr 2021 08:58:26 GMT"}], "update_date": "2021-05-03", "authors_parsed": [["Biegel", "Samantha", ""], ["El-Khatib", "Rafah", ""], ["Oliveira", "Luiz Otavio Vilas Boas", ""], ["Baak", "Max", ""], ["Aben", "Nanne", ""]]}, {"id": "2104.14848", "submitter": "Petr Hn\\v{e}tynka", "authors": "Tom\\'a\\v{s} Bure\\v{s}, Ilias Gerostathopoulos, Petr Hn\\v{e}tynka, Jan\n  Pacovsk\\'y", "title": "Forming Ensembles at Runtime: A Machine Learning Approach", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-030-61470-6_26", "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Smart system applications (SSAs) built on top of cyber-physical and\nsocio-technical systems are increasingly composed of components that can work\nboth autonomously and by cooperating with each other. Cooperating robots,\nfleets of cars and fleets of drones, emergency coordination systems are\nexamples of SSAs. One approach to enable cooperation of SSAs is to form dynamic\ncooperation groups-ensembles-between components at runtime. Ensembles can be\nformed based on predefined rules that determine which components should be part\nof an ensemble based on their current state and the state of the environment\n(e.g., \"group together 3 robots that are closer to the obstacle, their battery\nis sufficient and they would not be better used in another ensemble\"). This is\na computationally hard problem since all components are potential members of\nall possible ensembles at runtime. In our experience working with ensembles in\nseveral case studies the past years, using constraint programming to decide\nwhich ensembles should be formed does not scale for more than a limited number\nof components and ensembles. Also, the strict formulation in terms of hard/soft\nconstraints does not easily permit for runtime self-adaptation via learning.\nThis poses a serious limitation to the use of ensembles in large-scale and\npartially uncertain SSAs. To tackle this problem, in this paper we propose to\nrecast the ensemble formation problem as a classification problem and use\nmachine learning to efficiently form ensembles at scale.\n", "versions": [{"version": "v1", "created": "Fri, 30 Apr 2021 08:58:53 GMT"}], "update_date": "2021-05-03", "authors_parsed": [["Bure\u0161", "Tom\u00e1\u0161", ""], ["Gerostathopoulos", "Ilias", ""], ["Hn\u011btynka", "Petr", ""], ["Pacovsk\u00fd", "Jan", ""]]}, {"id": "2104.14870", "submitter": "Zahra Gharaee", "authors": "Zahra Gharaee", "title": "Action in Mind: A Neural Network Approach to Action Recognition and\n  Segmentation", "comments": "Lund University Cognitive Science 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.HC cs.LG cs.RO", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Recognizing and categorizing human actions is an important task with\napplications in various fields such as human-robot interaction, video analysis,\nsurveillance, video retrieval, health care system and entertainment industry.\nThis thesis presents a novel computational approach for human action\nrecognition through different implementations of multi-layer architectures\nbased on artificial neural networks. Each system level development is designed\nto solve different aspects of the action recognition problem including online\nreal-time processing, action segmentation and the involvement of objects. The\nanalysis of the experimental results are illustrated and described in six\narticles. The proposed action recognition architecture of this thesis is\ncomposed of several processing layers including a preprocessing layer, an\nordered vector representation layer and three layers of neural networks. It\nutilizes self-organizing neural networks such as Kohonen feature maps and\ngrowing grids as the main neural network layers. Thus the architecture presents\na biological plausible approach with certain features such as topographic\norganization of the neurons, lateral interactions, semi-supervised learning and\nthe ability to represent high dimensional input space in lower dimensional\nmaps. For each level of development the system is trained with the input data\nconsisting of consecutive 3D body postures and tested with generalized input\ndata that the system has never met before. The experimental results of\ndifferent system level developments show that the system performs well with\nquite high accuracy for recognizing human actions.\n", "versions": [{"version": "v1", "created": "Fri, 30 Apr 2021 09:53:28 GMT"}], "update_date": "2021-05-03", "authors_parsed": [["Gharaee", "Zahra", ""]]}, {"id": "2104.14900", "submitter": "Kai Cui", "authors": "Kai Cui, Anam Tahir, Mark Sinzger, Heinz Koeppl", "title": "Discrete-Time Mean Field Control with Environment States", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.MA math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-agent reinforcement learning methods have shown remarkable potential in\nsolving complex multi-agent problems but mostly lack theoretical guarantees.\nRecently, mean field control and mean field games have been established as a\ntractable solution for large-scale multi-agent problems with many agents. In\nthis work, driven by a motivating scheduling problem, we consider a\ndiscrete-time mean field control model with common environment states. We\nrigorously establish approximate optimality as the number of agents grows in\nthe finite agent case and find that a dynamic programming principle holds,\nresulting in the existence of an optimal stationary policy. As exact solutions\nare difficult in general due to the resulting continuous action space of the\nlimiting mean field Markov decision process, we apply established deep\nreinforcement learning methods to solve the associated mean field control\nproblem. The performance of the learned mean field control policy is compared\nto typical multi-agent reinforcement learning approaches and is found to\nconverge to the mean field performance for sufficiently many agents, verifying\nthe obtained theoretical results and reaching competitive solutions.\n", "versions": [{"version": "v1", "created": "Fri, 30 Apr 2021 10:58:01 GMT"}], "update_date": "2021-05-03", "authors_parsed": [["Cui", "Kai", ""], ["Tahir", "Anam", ""], ["Sinzger", "Mark", ""], ["Koeppl", "Heinz", ""]]}, {"id": "2104.14911", "submitter": "Thiago Freitas dos Santos", "authors": "Thiago Freitas dos Santos, Nardine Osman and Marco Schorlemmer", "title": "Learning for Detecting Norm Violation in Online Communities", "comments": "proceedings for International Workshop on Coordination,\n  Organizations, Institutions, Norms and Ethics for Governance of Multi-Agent\n  Systems (COINE), co-located with AAMAS 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we focus on normative systems for online communities. The\npaper addresses the issue that arises when different community members\ninterpret these norms in different ways, possibly leading to unexpected\nbehavior in interactions, usually with norm violations that affect the\nindividual and community experiences. To address this issue, we propose a\nframework capable of detecting norm violations and providing the violator with\ninformation about the features of their action that makes this action violate a\nnorm. We build our framework using Machine Learning, with Logistic Model Trees\nas the classification algorithm. Since norm violations can be highly\ncontextual, we train our model using data from the Wikipedia online community,\nnamely data on Wikipedia edits. Our work is then evaluated with the Wikipedia\nuse case where we focus on the norm that prohibits vandalism in Wikipedia\nedits.\n", "versions": [{"version": "v1", "created": "Fri, 30 Apr 2021 11:18:04 GMT"}], "update_date": "2021-05-03", "authors_parsed": [["Santos", "Thiago Freitas dos", ""], ["Osman", "Nardine", ""], ["Schorlemmer", "Marco", ""]]}, {"id": "2104.14912", "submitter": "Kai Cui", "authors": "Ramzi Ourari, Kai Cui, Heinz Koeppl", "title": "Decentralized Swarm Collision Avoidance for Quadrotors via End-to-End\n  Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Collision avoidance algorithms are of central interest to many drone\napplications. In particular, decentralized approaches may be the key to\nenabling robust drone swarm solutions in cases where centralized communication\nbecomes computationally prohibitive. In this work, we draw biological\ninspiration from flocks of starlings (Sturnus vulgaris) and apply the insight\nto end-to-end learned decentralized collision avoidance. More specifically, we\npropose a new, scalable observation model following a biomimetic topological\ninteraction rule that leads to stable learning and robust avoidance behavior.\nAdditionally, prior work primarily focuses on invoking a separation principle,\ni.e. designing collision avoidance independent of specific tasks. By applying a\ngeneral reinforcement learning approach, we propose a holistic learning-based\napproach to integrating collision avoidance with various tasks and dynamics. To\nvalidate the generality of this approach, we successfully apply our methodology\nto a number of configurations. Our learned policies are tested in simulation\nand subsequently transferred to real-world drones to validate their real-world\napplicability.\n", "versions": [{"version": "v1", "created": "Fri, 30 Apr 2021 11:19:03 GMT"}], "update_date": "2021-05-03", "authors_parsed": [["Ourari", "Ramzi", ""], ["Cui", "Kai", ""], ["Koeppl", "Heinz", ""]]}, {"id": "2104.14914", "submitter": "Garima Gaur", "authors": "Siddhant Arora, Vinayak Gupta, Garima Gaur, Srikanta Bedathur", "title": "BERT Meets Relational DB: Contextual Representations of Relational\n  Databases", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.DB cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we address the problem of learning low dimension\nrepresentation of entities on relational databases consisting of multiple\ntables. Embeddings help to capture semantics encoded in the database and can be\nused in a variety of settings like auto-completion of tables, fully-neural\nquery processing of relational joins queries, seamlessly handling missing\nvalues, and more. Current work is restricted to working with just single table,\nor using pretrained embeddings over an external corpus making them unsuitable\nfor use in real-world databases. In this work, we look into ways of using these\nattention-based model to learn embeddings for entities in the relational\ndatabase. We are inspired by BERT style pretraining methods and are interested\nin observing how they can be extended for representation learning on structured\ndatabases. We evaluate our approach of the autocompletion of relational\ndatabases and achieve improvement over standard baselines.\n", "versions": [{"version": "v1", "created": "Fri, 30 Apr 2021 11:23:26 GMT"}], "update_date": "2021-05-03", "authors_parsed": [["Arora", "Siddhant", ""], ["Gupta", "Vinayak", ""], ["Gaur", "Garima", ""], ["Bedathur", "Srikanta", ""]]}, {"id": "2104.14917", "submitter": "Fuxian Li", "authors": "Fuxian Li, Jie Feng, Huan Yan, Guangyin Jin, Depeng Jin, and Yong Li", "title": "Dynamic Graph Convolutional Recurrent Network for Traffic Prediction:\n  Benchmark and Solution", "comments": "13 pages, journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traffic prediction is the cornerstone of an intelligent transportation\nsystem. Accurate traffic forecasting is essential for the applications of smart\ncities, i.e., intelligent traffic management and urban planning. Although\nvarious methods are proposed for spatio-temporal modeling, they ignore the\ndynamic characteristics of correlations among locations on road networks.\nMeanwhile, most Recurrent Neural Network (RNN) based works are not efficient\nenough due to their recurrent operations. Additionally, there is a severe lack\nof fair comparison among different methods on the same datasets. To address the\nabove challenges, in this paper, we propose a novel traffic prediction\nframework, named Dynamic Graph Convolutional Recurrent Network (DGCRN). In\nDGCRN, hyper-networks are designed to leverage and extract dynamic\ncharacteristics from node attributes, while the parameters of dynamic filters\nare generated at each time step. We filter the node embeddings and then use\nthem to generate a dynamic graph, which is integrated with a pre-defined static\ngraph. As far as we know, we are the first to employ a generation method to\nmodel fine topology of dynamic graph at each time step. Further, to enhance\nefficiency and performance, we employ a training strategy for DGCRN by\nrestricting the iteration number of decoder during forward and backward\npropagation. Finally, a reproducible standardized benchmark and a brand new\nrepresentative traffic dataset are opened for fair comparison and further\nresearch. Extensive experiments on three datasets demonstrate that our model\noutperforms 15 baselines consistently.\n", "versions": [{"version": "v1", "created": "Fri, 30 Apr 2021 11:25:43 GMT"}, {"version": "v2", "created": "Mon, 3 May 2021 14:11:25 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Li", "Fuxian", ""], ["Feng", "Jie", ""], ["Yan", "Huan", ""], ["Jin", "Guangyin", ""], ["Jin", "Depeng", ""], ["Li", "Yong", ""]]}, {"id": "2104.14921", "submitter": "Truc Nguyen", "authors": "Truc Nguyen and Franz Pernkopf", "title": "Crackle Detection In Lung Sounds Using Transfer Learning And Multi-Input\n  Convolitional Neural Networks", "comments": "Under Review in Proceeding of EMBC 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Large annotated lung sound databases are publicly available and might be used\nto train algorithms for diagnosis systems. However, it might be a challenge to\ndevelop a well-performing algorithm for small non-public data, which have only\na few subjects and show differences in recording devices and setup. In this\npaper, we use transfer learning to tackle the mismatch of the recording setup.\nThis allows us to transfer knowledge from one dataset to another dataset for\ncrackle detection in lung sounds. In particular, a single input convolutional\nneural network (CNN) model is pre-trained on a source domain using ICBHI 2017,\nthe largest publicly available database of lung sounds. We use log-mel\nspectrogram features of respiratory cycles of lung sounds. The pre-trained\nnetwork is used to build a multi-input CNN model, which shares the same network\narchitecture for respiratory cycles and their corresponding respiratory phases.\nThe multi-input model is then fine-tuned on the target domain of our\nself-collected lung sound database for classifying crackles and normal lung\nsounds. Our experimental results show significant performance improvements of\n9.84% (absolute) in F-score on the target domain using the multi-input CNN\nmodel based on transfer learning for crackle detection in adventitious lung\nsound classification task.\n", "versions": [{"version": "v1", "created": "Fri, 30 Apr 2021 11:32:42 GMT"}], "update_date": "2021-05-03", "authors_parsed": [["Nguyen", "Truc", ""], ["Pernkopf", "Franz", ""]]}, {"id": "2104.14929", "submitter": "Matei Moldoveanu", "authors": "Matei Moldoveanu and Abdellatif Zaidi", "title": "On In-network learning. A Comparative Study with Federated and Split\n  Learning", "comments": "Submitted to the 2021 IEEE 22nd International Workshop on Signal\n  Processing Advances in Wireless Communications (SPAWC), special session on\n  Machine learning at the Edge", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider a problem in which distributively extracted\nfeatures are used for performing inference in wireless networks. We elaborate\non our proposed architecture, which we herein refer to as \"in-network\nlearning\", provide a suitable loss function and discuss its optimization using\nneural networks. We compare its performance with both Federated- and Split\nlearning; and show that this architecture offers both better accuracy and\nbandwidth savings.\n", "versions": [{"version": "v1", "created": "Fri, 30 Apr 2021 11:50:11 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Moldoveanu", "Matei", ""], ["Zaidi", "Abdellatif", ""]]}, {"id": "2104.14936", "submitter": "Lijun Sun Mr", "authors": "Xinyu Chen, Mengying Lei, Nicolas Saunier, Lijun Sun", "title": "Low-Rank Autoregressive Tensor Completion for Spatiotemporal Traffic\n  Data Imputation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spatiotemporal traffic time series (e.g., traffic volume/speed) collected\nfrom sensing systems are often incomplete with considerable corruption and\nlarge amounts of missing values, preventing users from harnessing the full\npower of the data. Missing data imputation has been a long-standing research\ntopic and critical application for real-world intelligent transportation\nsystems. A widely applied imputation method is low-rank matrix/tensor\ncompletion; however, the low-rank assumption only preserves the global\nstructure while ignores the strong local consistency in spatiotemporal data. In\nthis paper, we propose a low-rank autoregressive tensor completion (LATC)\nframework by introducing \\textit{temporal variation} as a new regularization\nterm into the completion of a third-order (sensor $\\times$ time of day $\\times$\nday) tensor. The third-order tensor structure allows us to better capture the\nglobal consistency of traffic data, such as the inherent seasonality and\nday-to-day similarity. To achieve local consistency, we design the temporal\nvariation by imposing an AR($p$) model for each time series with coefficients\nas learnable parameters. Different from previous spatial and temporal\nregularization schemes, the minimization of temporal variation can better\ncharacterize temporal generative mechanisms beyond local smoothness, allowing\nus to deal with more challenging scenarios such \"blackout\" missing. To solve\nthe optimization problem in LATC, we introduce an alternating minimization\nscheme that estimates the low-rank tensor and autoregressive coefficients\niteratively. We conduct extensive numerical experiments on several real-world\ntraffic data sets, and our results demonstrate the effectiveness of LATC in\ndiverse missing scenarios.\n", "versions": [{"version": "v1", "created": "Fri, 30 Apr 2021 12:00:57 GMT"}], "update_date": "2021-05-03", "authors_parsed": [["Chen", "Xinyu", ""], ["Lei", "Mengying", ""], ["Saunier", "Nicolas", ""], ["Sun", "Lijun", ""]]}, {"id": "2104.14937", "submitter": "Zheng Wang", "authors": "Zheng Wang, Xiaoliang Fan, Jianzhong Qi, Chenglu Wen, Cheng Wang,\n  Rongshan Yu", "title": "Federated Learning with Fair Averaging", "comments": "Accepted by IJCAI2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Fairness has emerged as a critical problem in federated learning (FL). In\nthis work, we identify a cause of unfairness in FL -- conflicting gradients\nwith large differences in the magnitudes. To address this issue, we propose the\nfederated fair averaging (FedFV) algorithm to mitigate potential conflicts\namong clients before averaging their gradients. We first use the cosine\nsimilarity to detect gradient conflicts, and then iteratively eliminate such\nconflicts by modifying both the direction and the magnitude of the gradients.\nWe further show the theoretical foundation of FedFV to mitigate the issue\nconflicting gradients and converge to Pareto stationary solutions. Extensive\nexperiments on a suite of federated datasets confirm that FedFV compares\nfavorably against state-of-the-art methods in terms of fairness, accuracy and\nefficiency. The source code is available at https://github.com/WwZzz/easyFL.\n", "versions": [{"version": "v1", "created": "Fri, 30 Apr 2021 12:02:03 GMT"}, {"version": "v2", "created": "Mon, 17 May 2021 11:23:17 GMT"}, {"version": "v3", "created": "Wed, 2 Jun 2021 15:28:09 GMT"}, {"version": "v4", "created": "Tue, 15 Jun 2021 05:15:08 GMT"}, {"version": "v5", "created": "Wed, 16 Jun 2021 16:30:15 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Wang", "Zheng", ""], ["Fan", "Xiaoliang", ""], ["Qi", "Jianzhong", ""], ["Wen", "Chenglu", ""], ["Wang", "Cheng", ""], ["Yu", "Rongshan", ""]]}, {"id": "2104.14949", "submitter": "PengFei Zhou", "authors": "Peng-Fei Zhou, Rui Hong, Shi-Ju Ran", "title": "Automatically Differentiable Quantum Circuit for Many-qubit State\n  Preparation", "comments": "5 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cond-mat.str-el cs.LG physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Constructing quantum circuits for efficient state preparation belongs to the\ncentral topics in the field of quantum information and computation. As the\nnumber of qubits grows fast, methods to derive large-scale quantum circuits are\nstrongly desired. In this work, we propose the automatically differentiable\nquantum circuit (ADQC) approach to efficiently prepare arbitrary quantum\nmany-qubit states. A key ingredient is to introduce the latent gates whose\ndecompositions give the unitary gates that form the quantum circuit. The\ncircuit is optimized by updating the latent gates using back propagation to\nminimize the distance between the evolved and target states. Taking the ground\nstates of quantum lattice models and random matrix product states as examples,\nwith the number of qubits where processing the full coefficients is unlikely,\nADQC obtains high fidelities with small numbers of layers $N_L \\sim O(1)$.\nSuperior accuracy is reached compared with the existing state-preparation\napproach based on the matrix product disentangler. The parameter complexity of\nMPS can be significantly reduced by ADQC with the compression ratio $r \\sim\nO(10^{-3})$. Our work sheds light on the \"intelligent construction\" of quantum\ncircuits for many-qubit systems by combining with the machine learning methods.\n", "versions": [{"version": "v1", "created": "Fri, 30 Apr 2021 12:22:26 GMT"}], "update_date": "2021-05-03", "authors_parsed": [["Zhou", "Peng-Fei", ""], ["Hong", "Rui", ""], ["Ran", "Shi-Ju", ""]]}, {"id": "2104.14957", "submitter": "Lena Sembach", "authors": "Lena Sembach, Jan Pablo Burgard, Volker H. Schulz", "title": "A Riemannian Newton Trust-Region Method for Fitting Gaussian Mixture\n  Models", "comments": "30 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC stat.CO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Gaussian Mixture Models are a powerful tool in Data Science and Statistics\nthat are mainly used for clustering and density approximation. The task of\nestimating the model parameters is in practice often solved by the Expectation\nMaximization (EM) algorithm which has its benefits in its simplicity and low\nper-iteration costs. However, the EM converges slowly if there is a large share\nof hidden information or overlapping clusters. Recent advances in Manifold\nOptimization for Gaussian Mixture Models have gained increasing interest. We\nintroduce a formula for the Riemannian Hessian for Gaussian Mixture Models. On\ntop, we propose a new Riemannian Newton Trust-Region method which outperforms\ncurrent approaches both in terms of runtime and number of iterations.\n", "versions": [{"version": "v1", "created": "Fri, 30 Apr 2021 12:48:32 GMT"}], "update_date": "2021-05-03", "authors_parsed": [["Sembach", "Lena", ""], ["Burgard", "Jan Pablo", ""], ["Schulz", "Volker H.", ""]]}, {"id": "2104.14958", "submitter": "Laura Davila Pena", "authors": "L. Davila-Pena, Ignacio Garc\\'ia-Jurado, B. Casas-M\\'endez", "title": "Assessment of the influence of features on a classification problem: an\n  application to COVID-19 patients", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG q-bio.PE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper deals with an important subject in classification problems\naddressed by machine learning techniques: the evaluation of the influence of\neach of the features on the classification of individuals. Specifically, a\nmeasure of that influence is introduced using the Shapley value of cooperative\ngames. In addition, an axiomatic characterisation of the proposed measure is\nprovided based on properties of efficiency and balanced contributions.\nFurthermore, some experiments have been designed in order to validate the\nappropriate performance of such measure. Finally, the methodology introduced is\napplied to a sample of COVID-19 patients to study the influence of certain\ndemographic or risk factors on various events of interest related to the\nevolution of the disease.\n", "versions": [{"version": "v1", "created": "Fri, 9 Apr 2021 20:02:05 GMT"}, {"version": "v2", "created": "Wed, 23 Jun 2021 12:19:20 GMT"}], "update_date": "2021-06-24", "authors_parsed": [["Davila-Pena", "L.", ""], ["Garc\u00eda-Jurado", "Ignacio", ""], ["Casas-M\u00e9ndez", "B.", ""]]}, {"id": "2104.14959", "submitter": "Luca Falorsi", "authors": "Luca Falorsi", "title": "Continuous normalizing flows on manifolds", "comments": "Master Thesis", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Normalizing flows are a powerful technique for obtaining reparameterizable\nsamples from complex multimodal distributions. Unfortunately, current\napproaches are only available for the most basic geometries and fall short when\nthe underlying space has a nontrivial topology, limiting their applicability\nfor most real-world data. Using fundamental ideas from differential geometry\nand geometric control theory, we describe how the recently introduced Neural\nODEs and continuous normalizing flows can be extended to arbitrary smooth\nmanifolds. We propose a general methodology for parameterizing vector fields on\nthese spaces and demonstrate how gradient-based learning can be performed.\nAdditionally, we provide a scalable unbiased estimator for the divergence in\nthis generalized setting. Experiments on a diverse selection of spaces\nempirically showcase the defined framework's ability to obtain\nreparameterizable samples from complex distributions.\n", "versions": [{"version": "v1", "created": "Sun, 14 Mar 2021 15:35:19 GMT"}], "update_date": "2021-05-03", "authors_parsed": [["Falorsi", "Luca", ""]]}, {"id": "2104.14962", "submitter": "Yuncong Yu", "authors": "Yuncong Yu, Dylan Kruyff, Tim Becker, Michael Behrisch", "title": "PSEUDo: Interactive Pattern Search in Multivariate Time Series with\n  Locality-Sensitive Hashing and Relevance Feedback", "comments": "11 pages including 2 pages for references, 10 figures including 1\n  teaser figure, sumbitted to IEEE VIS 2021, gitlab repository\n  https://git.science.uu.nl/vig/sublinear-algorithms-for-va/locality-sensitive-hashing-visual-analytics", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DS stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present PSEUDo, an adaptive feature learning technique for exploring\nvisual patterns in multi-track sequential data. Our approach is designed with\nthe primary focus to overcome the uneconomic retraining requirements and\ninflexible representation learning in current deep learning-based systems.\nMulti-track time series data are generated on an unprecedented scale due to\nincreased sensors and data storage. These datasets hold valuable patterns, like\nin neuromarketing, where researchers try to link patterns in multivariate\nsequential data from physiological sensors to the purchase behavior of products\nand services. But a lack of ground truth and high variance make automatic\npattern detection unreliable. Our advancements are based on a novel query-aware\nlocality-sensitive hashing technique to create a feature-based representation\nof multivariate time series windows. Most importantly, our algorithm features\nsub-linear training and inference time. We can even accomplish both the\nmodeling and comparison of 10,000 different 64-track time series, each with 100\ntime steps (a typical EEG dataset) under 0.8 seconds. This performance gain\nallows for a rapid relevance feedback-driven adaption of the underlying pattern\nsimilarity model and enables the user to modify the speed-vs-accuracy trade-off\ngradually. We demonstrate superiority of PSEUDo in terms of efficiency,\naccuracy, and steerability through a quantitative performance comparison and a\nqualitative visual quality comparison to the state-of-the-art algorithms in the\nfield. Moreover, we showcase the usability of PSEUDo through a case study\ndemonstrating our visual pattern retrieval concepts in a large meteorological\ndataset. We find that our adaptive models can accurately capture the user's\nnotion of similarity and allow for an understandable exploratory visual pattern\nretrieval in large multivariate time series datasets.\n", "versions": [{"version": "v1", "created": "Fri, 30 Apr 2021 13:00:44 GMT"}, {"version": "v2", "created": "Mon, 10 May 2021 15:04:52 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Yu", "Yuncong", ""], ["Kruyff", "Dylan", ""], ["Becker", "Tim", ""], ["Behrisch", "Michael", ""]]}, {"id": "2104.14963", "submitter": "Georg W\\\"olflein", "authors": "Georg W\\\"olflein and Ognjen Arandjelovi\\'c", "title": "Determining Chess Game State From an Image", "comments": "https://github.com/georgw777/chesscog", "journal-ref": "J. Imaging 2021, 7(6), 94", "doi": "10.3390/jimaging7060094", "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Identifying the configuration of chess pieces from an image of a chessboard\nis a problem in computer vision that has not yet been solved accurately.\nHowever, it is important for helping amateur chess players improve their games\nby facilitating automatic computer analysis without the overhead of manually\nentering the pieces. Current approaches are limited by the lack of large\ndatasets and are not designed to adapt to unseen chess sets. This paper puts\nforth a new dataset synthesised from a 3D model that is an order of magnitude\nlarger than existing ones. Trained on this dataset, a novel end-to-end chess\nrecognition system is presented that combines traditional computer vision\ntechniques with deep learning. It localises the chessboard using a RANSAC-based\nalgorithm that computes a projective transformation of the board onto a regular\ngrid. Using two convolutional neural networks, it then predicts an occupancy\nmask for the squares in the warped image and finally classifies the pieces. The\ndescribed system achieves an error rate of 0.23% per square on the test set, 28\ntimes better than the current state of the art. Further, a few-shot transfer\nlearning approach is developed that is able to adapt the inference system to a\npreviously unseen chess set using just two photos of the starting position,\nobtaining a per-square accuracy of 99.83% on images of that new chess set. The\ncode, dataset, and trained models are made available online.\n", "versions": [{"version": "v1", "created": "Fri, 30 Apr 2021 13:02:13 GMT"}, {"version": "v2", "created": "Wed, 2 Jun 2021 14:27:50 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["W\u00f6lflein", "Georg", ""], ["Arandjelovi\u0107", "Ognjen", ""]]}, {"id": "2104.14964", "submitter": "Albert Clap\\'es", "authors": "Penny Tarling, Mauricio Cantor, Albert Clap\\'es and Sergio Escalera", "title": "Deep learning with self-supervision and uncertainty regularization to\n  count fish in underwater images", "comments": "22 pages, 6 figures, submitted to indexed journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Effective conservation actions require effective population monitoring.\nHowever, accurately counting animals in the wild to inform conservation\ndecision-making is difficult. Monitoring populations through image sampling has\nmade data collection cheaper, wide-reaching and less intrusive but created a\nneed to process and analyse this data efficiently. Counting animals from such\ndata is challenging, particularly when densely packed in noisy images.\nAttempting this manually is slow and expensive, while traditional computer\nvision methods are limited in their generalisability. Deep learning is the\nstate-of-the-art method for many computer vision tasks, but it has yet to be\nproperly explored to count animals. To this end, we employ deep learning, with\na density-based regression approach, to count fish in low-resolution sonar\nimages. We introduce a large dataset of sonar videos, deployed to record wild\nmullet schools (Mugil liza), with a subset of 500 labelled images. We utilise\nabundant unlabelled data in a self-supervised task to improve the supervised\ncounting task. For the first time in this context, by introducing uncertainty\nquantification, we improve model training and provide an accompanying measure\nof prediction uncertainty for more informed biological decision-making.\nFinally, we demonstrate the generalisability of our proposed counting framework\nthrough testing it on a recent benchmark dataset of high-resolution annotated\nunderwater images from varying habitats (DeepFish). From experiments on both\ncontrasting datasets, we demonstrate our network outperforms the few other deep\nlearning models implemented for solving this task. By providing an open-source\nframework along with training data, our study puts forth an efficient deep\nlearning template for crowd counting aquatic animals thereby contributing\neffective methods to assess natural populations from the ever-increasing visual\ndata.\n", "versions": [{"version": "v1", "created": "Fri, 30 Apr 2021 13:02:19 GMT"}], "update_date": "2021-05-03", "authors_parsed": [["Tarling", "Penny", ""], ["Cantor", "Mauricio", ""], ["Clap\u00e9s", "Albert", ""], ["Escalera", "Sergio", ""]]}, {"id": "2104.14978", "submitter": "Gaigai Tang", "authors": "Gaigai Tang, Lianxiao Meng, Shuangyin Ren, Weipeng Cao, Qiang Wang,\n  Lin Yang", "title": "A comparative study of neural network techniques for automatic software\n  vulnerability detection", "comments": "This paper has been published at April 28,2021. However, there are\n  some experimental data issues in the published manuscript, which are caused\n  by the calculation error of indicators. This paper is a revised version", "journal-ref": null, "doi": "10.1109/TASE49443.2020.00010", "report-no": null, "categories": "cs.SE cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Software vulnerabilities are usually caused by design flaws or implementation\nerrors, which could be exploited to cause damage to the security of the system.\nAt present, the most commonly used method for detecting software\nvulnerabilities is static analysis. Most of the related technologies work based\non rules or code similarity (source code level) and rely on manually defined\nvulnerability features. However, these rules and vulnerability features are\ndifficult to be defined and designed accurately, which makes static analysis\nface many challenges in practical applications. To alleviate this problem, some\nresearchers have proposed to use neural networks that have the ability of\nautomatic feature extraction to improve the intelligence of detection. However,\nthere are many types of neural networks, and different data preprocessing\nmethods will have a significant impact on model performance. It is a great\nchallenge for engineers and researchers to choose a proper neural network and\ndata preprocessing method for a given problem. To solve this problem, we have\nconducted extensive experiments to test the performance of the two most typical\nneural networks (i.e., Bi-LSTM and RVFL) with the two most classical data\npreprocessing methods (i.e., the vector representation and the program\nsymbolization methods) on software vulnerability detection problems and\nobtained a series of interesting research conclusions, which can provide\nvaluable guidelines for researchers and engineers. Specifically, we found that\n1) the training speed of RVFL is always faster than BiLSTM, but the prediction\naccuracy of Bi-LSTM model is higher than RVFL; 2) using doc2vec for vector\nrepresentation can make the model have faster training speed and generalization\nability than using word2vec; and 3) multi-level symbolization is helpful to\nimprove the precision of neural network models.\n", "versions": [{"version": "v1", "created": "Thu, 29 Apr 2021 01:47:30 GMT"}], "update_date": "2021-05-03", "authors_parsed": [["Tang", "Gaigai", ""], ["Meng", "Lianxiao", ""], ["Ren", "Shuangyin", ""], ["Cao", "Weipeng", ""], ["Wang", "Qiang", ""], ["Yang", "Lin", ""]]}, {"id": "2104.14980", "submitter": "Dejan Stepec", "authors": "Dejan Stepec and Tomaz Martincic and Fabrice Klein and Daniel Vladusic\n  and Joao Pita Costa", "title": "Machine Learning based System for Vessel Turnaround Time Prediction", "comments": "MDM 2020 MBDW workshop", "journal-ref": null, "doi": "10.1109/MDM48529.2020.00060", "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In this paper, we present a novel system for predicting vessel turnaround\ntime, based on machine learning and standardized port call data. We also\ninvestigate the use of specific external maritime big data, to enhance the\naccuracy of the available data and improve the performance of the developed\nsystem. An extensive evaluation is performed in Port of Bordeaux, where we\nreport the results on 11 years of historical port call data and provide\nverification on live, operational data from the port. The proposed automated\ndata-driven turnaround time prediction system is able to perform with increased\naccuracy, in comparison with the current manual expert-based system in Port of\nBordeaux.\n", "versions": [{"version": "v1", "created": "Wed, 28 Apr 2021 15:14:42 GMT"}], "update_date": "2021-05-03", "authors_parsed": [["Stepec", "Dejan", ""], ["Martincic", "Tomaz", ""], ["Klein", "Fabrice", ""], ["Vladusic", "Daniel", ""], ["Costa", "Joao Pita", ""]]}, {"id": "2104.15006", "submitter": "Taylor Carpenter", "authors": "Taylor J. Carpenter, Radoslav Ivanov, Insup Lee, James Weimer", "title": "ModelGuard: Runtime Validation of Lipschitz-continuous Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.LG cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents ModelGuard, a sampling-based approach to runtime model\nvalidation for Lipschitz-continuous models. Although techniques exist for the\nvalidation of many classes of models the majority of these methods cannot be\napplied to the whole of Lipschitz-continuous models, which includes neural\nnetwork models. Additionally, existing techniques generally consider only\nwhite-box models. By taking a sampling-based approach, we can address black-box\nmodels, represented only by an input-output relationship and a Lipschitz\nconstant. We show that by randomly sampling from a parameter space and\nevaluating the model, it is possible to guarantee the correctness of traces\nlabeled consistent and provide a confidence on the correctness of traces\nlabeled inconsistent. We evaluate the applicability and scalability of\nModelGuard in three case studies, including a physical platform.\n", "versions": [{"version": "v1", "created": "Fri, 30 Apr 2021 13:57:57 GMT"}], "update_date": "2021-05-03", "authors_parsed": [["Carpenter", "Taylor J.", ""], ["Ivanov", "Radoslav", ""], ["Lee", "Insup", ""], ["Weimer", "James", ""]]}, {"id": "2104.15007", "submitter": "Roohallah Alizadehsani", "authors": "Nooshin Ayoobi, Danial Sharifrazi, Roohallah Alizadehsani, Afshin\n  Shoeibi, Juan M. Gorriz, Hossein Moosaei, Abbas Khosravi, Saeid Nahavandi,\n  Abdoulmohammad Gholamzadeh Chofreh, Feybi Ariani Goni, Jiri Jaromir Klemes,\n  Amir Mosavi", "title": "Time Series Forecasting of New Cases and New Deaths Rate for COVID-19\n  using Deep Learning Methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Covid-19 has been started in the year 2019 and imposed restrictions in many\ncountries and costs organisations and governments. Predicting the number of new\ncases and deaths during this period can be a useful step in predicting the\ncosts and facilities required in the future. The purpose of this study is to\npredict new cases and death rate for seven days ahead. Deep learning methods\nand statistical analysis model these predictions for 100 days. Six different\ndeep learning methods are examined for the data adopted from the WHO website.\nThree methods are known as LSTM, Convolutional LSTM, and GRU. The\nbi-directional mode is then considered for each method to forecast the rate of\nnew cases and new deaths for Australia and Iran countries. This study is novel\nas it attempts to implement the mentioned three deep learning methods, along\nwith their Bi-directional models, to predict COVID-19 new cases and new death\nrate time series. All methods are compared, and results are presented. The\nresults are examined in the form of graphs and statistical analyses. The\nresults show that the Bi-directional models have lower error than other models.\nSeveral error evaluation metrics are presented to compare all models, and\nfinally, the superiority of Bi-directional methods are determined. The\nexperimental results and statistical test show on datasets to compare the\nproposed method with other baseline methods. This research could be useful for\norganisations working against COVID-19 and determining their long-term plans.\n", "versions": [{"version": "v1", "created": "Wed, 28 Apr 2021 05:44:02 GMT"}], "update_date": "2021-05-03", "authors_parsed": [["Ayoobi", "Nooshin", ""], ["Sharifrazi", "Danial", ""], ["Alizadehsani", "Roohallah", ""], ["Shoeibi", "Afshin", ""], ["Gorriz", "Juan M.", ""], ["Moosaei", "Hossein", ""], ["Khosravi", "Abbas", ""], ["Nahavandi", "Saeid", ""], ["Chofreh", "Abdoulmohammad Gholamzadeh", ""], ["Goni", "Feybi Ariani", ""], ["Klemes", "Jiri Jaromir", ""], ["Mosavi", "Amir", ""]]}, {"id": "2104.15010", "submitter": "Johannes Cornelius Schoeman", "authors": "J. C. Schoeman, C. E. van Daalen, J. A. du Preez", "title": "Degenerate Gaussian factors for probabilistic inference", "comments": "Preprint submitted to International Journal of Approximate Reasoning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  In this paper, we propose a parametrised factor that enables inference on\nGaussian networks where linear dependencies exist among the random variables.\nOur factor representation is a generalisation of traditional Gaussian\nparametrisations where the positive-definite constraint (of covariance and\nprecision matrices) has been relaxed. For this purpose, we derive various\nstatistical operations and results (such as marginalisation, multiplication and\naffine transformations of random variables) which extend the capabilities of\nGaussian factors to these degenerate settings. By using this principled factor\ndefinition, degeneracies can be accommodated accurately and automatically at\nlittle additional computational cost. As illustration, we apply our methodology\nto a representative example involving recursive state estimation of cooperative\nmobile robots.\n", "versions": [{"version": "v1", "created": "Fri, 30 Apr 2021 13:58:29 GMT"}], "update_date": "2021-05-03", "authors_parsed": [["Schoeman", "J. C.", ""], ["van Daalen", "C. E.", ""], ["Preez", "J. A. du", ""]]}, {"id": "2104.15023", "submitter": "Ivan Lazarevich", "authors": "Ivan Lazarevich and Alexander Kozlov and Nikita Malinin", "title": "Post-training deep neural network pruning via layer-wise calibration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present a post-training weight pruning method for deep neural networks\nthat achieves accuracy levels tolerable for the production setting and that is\nsufficiently fast to be run on commodity hardware such as desktop CPUs or edge\ndevices. We propose a data-free extension of the approach for computer vision\nmodels based on automatically-generated synthetic fractal images. We obtain\nstate-of-the-art results for data-free neural network pruning, with ~1.5% top@1\naccuracy drop for a ResNet50 on ImageNet at 50% sparsity rate. When using real\ndata, we are able to get a ResNet50 model on ImageNet with 65% sparsity rate in\n8-bit precision in a post-training setting with a ~1% top@1 accuracy drop. We\nrelease the code as a part of the OpenVINO(TM) Post-Training Optimization tool.\n", "versions": [{"version": "v1", "created": "Fri, 30 Apr 2021 14:20:51 GMT"}], "update_date": "2021-05-03", "authors_parsed": [["Lazarevich", "Ivan", ""], ["Kozlov", "Alexander", ""], ["Malinin", "Nikita", ""]]}, {"id": "2104.15042", "submitter": "Hongmin Li", "authors": "Hongmin Li, Xiucai Ye, Akira Imakura and Tetsuya Sakurai", "title": "Divide-and-conquer based Large-Scale Spectral Clustering", "comments": "14 pages, 6 figures, 10 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Spectral clustering is one of the most popular clustering methods. However,\nhow to balance the efficiency and effectiveness of the large-scale spectral\nclustering with limited computing resources has not been properly solved for a\nlong time. In this paper, we propose a divide-and-conquer based large-scale\nspectral clustering method to strike a good balance between efficiency and\neffectiveness. In the proposed method, a divide-and-conquer based landmark\nselection algorithm and a novel approximate similarity matrix approach are\ndesigned to construct a sparse similarity matrix within extremely low cost.\nThen clustering results can be computed quickly through a bipartite graph\npartition process. The proposed method achieves the lower computational\ncomplexity than most existing large-scale spectral clustering. Experimental\nresults on ten large-scale datasets have demonstrated the efficiency and\neffectiveness of the proposed methods. The MATLAB code of the proposed method\nand experimental datasets are available at\nhttps://github.com/Li-Hongmin/MyPaperWithCode.\n", "versions": [{"version": "v1", "created": "Fri, 30 Apr 2021 15:09:45 GMT"}], "update_date": "2021-05-03", "authors_parsed": [["Li", "Hongmin", ""], ["Ye", "Xiucai", ""], ["Imakura", "Akira", ""], ["Sakurai", "Tetsuya", ""]]}, {"id": "2104.15046", "submitter": "Simen Eide", "authors": "Simen Eide, David S. Leslie, Arnoldo Frigessi", "title": "Dynamic Slate Recommendation with Gated Recurrent Units and Thompson\n  Sampling", "comments": "The code and the data used in the article are available in the\n  following repository: https://github.com/finn-no/recsys-slates-dataset", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We consider the problem of recommending relevant content to users of an\ninternet platform in the form of lists of items, called slates. We introduce a\nvariational Bayesian Recurrent Neural Net recommender system that acts on time\nseries of interactions between the internet platform and the user, and which\nscales to real world industrial situations. The recommender system is tested\nboth online on real users, and on an offline dataset collected from a Norwegian\nweb-based marketplace, FINN.no, that is made public for research. This is one\nof the first publicly available datasets which includes all the slates that are\npresented to users as well as which items (if any) in the slates were clicked\non. Such a data set allows us to move beyond the common assumption that\nimplicitly assumes that users are considering all possible items at each\ninteraction. Instead we build our likelihood using the items that are actually\nin the slate, and evaluate the strengths and weaknesses of both approaches\ntheoretically and in experiments. We also introduce a hierarchical prior for\nthe item parameters based on group memberships. Both item parameters and user\npreferences are learned probabilistically. Furthermore, we combine our model\nwith bandit strategies to ensure learning, and introduce `in-slate Thompson\nSampling' which makes use of the slates to maximise explorative opportunities.\nWe show experimentally that explorative recommender strategies perform on par\nor above their greedy counterparts. Even without making use of exploration to\nlearn more effectively, click rates increase simply because of improved\ndiversity in the recommended slates.\n", "versions": [{"version": "v1", "created": "Fri, 30 Apr 2021 15:16:35 GMT"}], "update_date": "2021-05-03", "authors_parsed": [["Eide", "Simen", ""], ["Leslie", "David S.", ""], ["Frigessi", "Arnoldo", ""]]}, {"id": "2104.15050", "submitter": "Junhua Chen", "authors": "Junhua Chen, Chong Zhang, Alberto Traverso, Ivan Zhovannik, Andre\n  Dekker, Leonard Wee and Inigo Bermejo", "title": "Generative Models Improve Radiomics Reproducibility in Low Dose CTs: A\n  Simulation Study", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.LG eess.IV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Radiomics is an active area of research in medical image analysis, the low\nreproducibility of radiomics has limited its applicability to clinical\npractice. This issue is especially prominent when radiomic features are\ncalculated from noisy images, such as low dose computed tomography (CT) scans.\nIn this article, we investigate the possibility of improving the\nreproducibility of radiomic features calculated on noisy CTs by using\ngenerative models for denoising.One traditional denoising method - non-local\nmeans - and two generative models - encoder-decoder networks (EDN) and\nconditional generative adversarial networks (CGANs) - were selected as the test\nmodels. We added noise to the sinograms of full dose CTs to mimic low dose CTs\nwith two different levels of noise: low-noise CT and high-noise CT. Models were\ntrained on high-noise CTs and used to denoise low-noise CTs without\nre-training. We also test the performance of our model in real data, using\ndataset of same-day repeat low dose CTs to assess the reproducibility of\nradiomic features in denoised images. The EDN and the CGAN improved the\nconcordance correlation coefficients (CCC) of radiomic features for low-noise\nimages from 0.87 to 0.92 and for high-noise images from 0.68 to 0.92\nrespectively. Moreover, the EDN and the CGAN improved the test-retest\nreliability of radiomic features (mean CCC increased from 0.89 to 0.94) based\non real low dose CTs. The results show that denoising using EDN and CGANs can\nimprove the reproducibility of radiomic features calculated on noisy CTs.\nMoreover, images with different noise levels can be denoised to improve the\nreproducibility using these models without re-training, as long as the noise\nintensity is equal or lower than that in high-noise CTs. To the authors'\nknowledge, this is the first effort to improve the reproducibility of radiomic\nfeatures calculated on low dose CT scans.\n", "versions": [{"version": "v1", "created": "Fri, 30 Apr 2021 15:18:57 GMT"}], "update_date": "2021-05-03", "authors_parsed": [["Chen", "Junhua", ""], ["Zhang", "Chong", ""], ["Traverso", "Alberto", ""], ["Zhovannik", "Ivan", ""], ["Dekker", "Andre", ""], ["Wee", "Leonard", ""], ["Bermejo", "Inigo", ""]]}, {"id": "2104.15052", "submitter": "Hongzuo Xu", "authors": "Zhiyue Wu, Hongzuo Xu, Guansong Pang, Fengyuan Yu, Yijie Wang, Songlei\n  Jian, Yongjun Wang", "title": "DRAM Failure Prediction in AIOps: Empirical Evaluation, Challenges and\n  Opportunities", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  DRAM failure prediction is a vital task in AIOps, which is crucial to\nmaintain the reliability and sustainable service of large-scale data centers.\nHowever, limited work has been done on DRAM failure prediction mainly due to\nthe lack of public available datasets. This paper presents a comprehensive\nempirical evaluation of diverse machine learning techniques for DRAM failure\nprediction using a large-scale multi-source dataset, including more than three\nmillions of records of kernel, address, and mcelog data, provided by Alibaba\nCloud through PAKDD 2021 competition. Particularly, we first formulate the\nproblem as a multi-class classification task and exhaustively evaluate seven\npopular/state-of-the-art classifiers on both the individual and multiple data\nsources. We then formulate the problem as an unsupervised anomaly detection\ntask and evaluate three state-of-the-art anomaly detectors. Further, based on\nthe empirical results and our experience of attending this competition, we\ndiscuss major challenges and present future research opportunities in this\ntask.\n", "versions": [{"version": "v1", "created": "Fri, 30 Apr 2021 15:20:22 GMT"}, {"version": "v2", "created": "Tue, 4 May 2021 02:59:45 GMT"}], "update_date": "2021-05-05", "authors_parsed": [["Wu", "Zhiyue", ""], ["Xu", "Hongzuo", ""], ["Pang", "Guansong", ""], ["Yu", "Fengyuan", ""], ["Wang", "Yijie", ""], ["Jian", "Songlei", ""], ["Wang", "Yongjun", ""]]}, {"id": "2104.15061", "submitter": "Haoxi Zhan", "authors": "Haoxi Zhan, Xiaobing Pei", "title": "Black-box Gradient Attack on Graph Neural Networks: Deeper Insights in\n  Graph-based Attack and Defense", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Graph Neural Networks (GNNs) have received significant attention due to their\nstate-of-the-art performance on various graph representation learning tasks.\nHowever, recent studies reveal that GNNs are vulnerable to adversarial attacks,\ni.e. an attacker is able to fool the GNNs by perturbing the graph structure or\nnode features deliberately. While being able to successfully decrease the\nperformance of GNNs, most existing attacking algorithms require access to\neither the model parameters or the training data, which is not practical in the\nreal world.\n  In this paper, we develop deeper insights into the Mettack algorithm, which\nis a representative grey-box attacking method, and then we propose a\ngradient-based black-box attacking algorithm. Firstly, we show that the Mettack\nalgorithm will perturb the edges unevenly, thus the attack will be highly\ndependent on a specific training set. As a result, a simple yet useful strategy\nto defense against Mettack is to train the GNN with the validation set.\nSecondly, to overcome the drawbacks, we propose the Black-Box Gradient Attack\n(BBGA) algorithm. Extensive experiments demonstrate that out proposed method is\nable to achieve stable attack performance without accessing the training sets\nof the GNNs. Further results shows that our proposed method is also applicable\nwhen attacking against various defense methods.\n", "versions": [{"version": "v1", "created": "Fri, 30 Apr 2021 15:30:47 GMT"}], "update_date": "2021-05-03", "authors_parsed": [["Zhan", "Haoxi", ""], ["Pei", "Xiaobing", ""]]}, {"id": "2104.15064", "submitter": "Giovanni Iacca Prof.", "authors": "Hao Qiu, Leonardo Lucio Custode, Giovanni Iacca", "title": "Black-box adversarial attacks using Evolution Strategies", "comments": "To be published in the proceedings of ACM Genetic and Evolutionary\n  Computation Conference (GECCO) Companion 2021", "journal-ref": null, "doi": "10.1145/3449726.3463137", "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In the last decade, deep neural networks have proven to be very powerful in\ncomputer vision tasks, starting a revolution in the computer vision and machine\nlearning fields. However, deep neural networks, usually, are not robust to\nperturbations of the input data. In fact, several studies showed that slightly\nchanging the content of the images can cause a dramatic decrease in the\naccuracy of the attacked neural network. Several methods able to generate\nadversarial samples make use of gradients, which usually are not available to\nan attacker in real-world scenarios. As opposed to this class of attacks,\nanother class of adversarial attacks, called black-box adversarial attacks,\nemerged, which does not make use of information on the gradients, being more\nsuitable for real-world attack scenarios. In this work, we compare three\nwell-known evolution strategies on the generation of black-box adversarial\nattacks for image classification tasks. While our results show that the\nattacked neural networks can be, in most cases, easily fooled by all the\nalgorithms under comparison, they also show that some black-box optimization\nalgorithms may be better in \"harder\" setups, both in terms of attack success\nrate and efficiency (i.e., number of queries).\n", "versions": [{"version": "v1", "created": "Fri, 30 Apr 2021 15:33:07 GMT"}], "update_date": "2021-05-03", "authors_parsed": [["Qiu", "Hao", ""], ["Custode", "Leonardo Lucio", ""], ["Iacca", "Giovanni", ""]]}, {"id": "2104.15079", "submitter": "Aldo Glielmo Mr.", "authors": "Aldo Glielmo, Claudio Zeni, Bingqing Cheng, Gabor Csanyi, Alessandro\n  Laio", "title": "Ranking the information content of distance measures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IT cs.LG math.IT", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Real-world data typically contain a large number of features that are often\nheterogeneous in nature, relevance, and also units of measure. When assessing\nthe similarity between data points, one can build various distance measures\nusing subsets of these features. Using the fewest features but still retaining\nsufficient information about the system is crucial in many statistical learning\napproaches, particularly when data are sparse. We introduce a statistical test\nthat can assess the relative information retained when using two different\ndistance measures, and determine if they are equivalent, independent, or if one\nis more informative than the other. This in turn allows finding the most\ninformative distance measure out of a pool of candidates. The approach is\napplied to find the most relevant policy variables for controlling the Covid-19\nepidemic and to find compact yet informative representations of atomic\nstructures, but its potential applications are wide ranging in many branches of\nscience.\n", "versions": [{"version": "v1", "created": "Fri, 30 Apr 2021 15:57:57 GMT"}], "update_date": "2021-05-03", "authors_parsed": [["Glielmo", "Aldo", ""], ["Zeni", "Claudio", ""], ["Cheng", "Bingqing", ""], ["Csanyi", "Gabor", ""], ["Laio", "Alessandro", ""]]}, {"id": "2104.15083", "submitter": "Rajarshi Roy", "authors": "Jean-Rapha\\\"el Gaglione, Daniel Neider, Rajarshi Roy, Ufuk Topcu and\n  Zhe Xu", "title": "Learning Linear Temporal Properties from Noisy Data: A MaxSAT Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the problem of inferring descriptions of system behavior using\nLinear Temporal Logic (LTL) from a finite set of positive and negative\nexamples. Most of the existing approaches for solving such a task rely on\npredefined templates for guiding the structure of the inferred formula. The\napproaches that can infer arbitrary LTL formulas, on the other hand, are not\nrobust to noise in the data. To alleviate such limitations, we devise two\nalgorithms for inferring concise LTL formulas even in the presence of noise.\nOur first algorithm infers minimal LTL formulas by reducing the inference\nproblem to a problem in maximum satisfiability and then using off-the-shelf\nMaxSAT solvers to find a solution. To the best of our knowledge, we are the\nfirst to incorporate the usage of MaxSAT solvers for inferring formulas in LTL.\nOur second learning algorithm relies on the first algorithm to derive a\ndecision tree over LTL formulas based on a decision tree learning algorithm. We\nhave implemented both our algorithms and verified that our algorithms are\nefficient in extracting concise LTL descriptions even in the presence of noise.\n", "versions": [{"version": "v1", "created": "Fri, 30 Apr 2021 16:06:03 GMT"}, {"version": "v2", "created": "Thu, 24 Jun 2021 19:56:55 GMT"}], "update_date": "2021-06-28", "authors_parsed": [["Gaglione", "Jean-Rapha\u00ebl", ""], ["Neider", "Daniel", ""], ["Roy", "Rajarshi", ""], ["Topcu", "Ufuk", ""], ["Xu", "Zhe", ""]]}, {"id": "2104.15092", "submitter": "Youjiang Xu", "authors": "Youjiang Xu, Linchao Zhu, Lu Jiang, Yi Yang", "title": "Faster Meta Update Strategy for Noise-Robust Deep Learning", "comments": "Accepted to CVPR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It has been shown that deep neural networks are prone to overfitting on\nbiased training data. Towards addressing this issue, meta-learning employs a\nmeta model for correcting the training bias. Despite the promising\nperformances, super slow training is currently the bottleneck in the meta\nlearning approaches. In this paper, we introduce a novel Faster Meta Update\nStrategy (FaMUS) to replace the most expensive step in the meta gradient\ncomputation with a faster layer-wise approximation. We empirically find that\nFaMUS yields not only a reasonably accurate but also a low-variance\napproximation of the meta gradient. We conduct extensive experiments to verify\nthe proposed method on two tasks. We show our method is able to save two-thirds\nof the training time while still maintaining the comparable or achieving even\nbetter generalization performance. In particular, our method achieves the\nstate-of-the-art performance on both synthetic and realistic noisy labels, and\nobtains promising performance on long-tailed recognition on standard\nbenchmarks.\n", "versions": [{"version": "v1", "created": "Fri, 30 Apr 2021 16:19:07 GMT"}], "update_date": "2021-05-03", "authors_parsed": [["Xu", "Youjiang", ""], ["Zhu", "Linchao", ""], ["Jiang", "Lu", ""], ["Yang", "Yi", ""]]}, {"id": "2104.15106", "submitter": "Connor Mclaughlin", "authors": "Connor J. McLaughlin, Efi G. Kokkotou, Jean A. King, Lisa A. Conboy,\n  Ali Yousefi", "title": "Latent Factor Decomposition Model: Applications for Questionnaire Data", "comments": "Pending review for the 43rd IEEE Annual International Conference of\n  the IEEE Engineering in Medicine and Biology Society, EMBC 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The analysis of clinical questionnaire data comes with many inherent\nchallenges. These challenges include the handling of data with missing fields,\nas well as the overall interpretation of a dataset with many fields of\ndifferent scales and forms. While numerous methods have been developed to\naddress these challenges, they are often not robust, statistically sound, or\neasily interpretable. Here, we propose a latent factor modeling framework that\nextends the principal component analysis for both categorical and quantitative\ndata with missing elements. The model simultaneously provides the principal\ncomponents (basis) and each patients' projections on these bases in a latent\nspace. We show an application of our modeling framework through Irritable Bowel\nSyndrome (IBS) symptoms, where we find correlations between these projections\nand other standardized patient symptom scales. This latent factor model can be\neasily applied to different clinical questionnaire datasets for clustering\nanalysis and interpretable inference.\n", "versions": [{"version": "v1", "created": "Fri, 30 Apr 2021 16:40:37 GMT"}], "update_date": "2021-05-03", "authors_parsed": [["McLaughlin", "Connor J.", ""], ["Kokkotou", "Efi G.", ""], ["King", "Jean A.", ""], ["Conboy", "Lisa A.", ""], ["Yousefi", "Ali", ""]]}, {"id": "2104.15109", "submitter": "Jean-Baptiste Truong", "authors": "Jean-Baptiste Truong, William Gallagher, Tian Guo, Robert J. Walls", "title": "Memory-Efficient Deep Learning Inference in Trusted Execution\n  Environments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This study identifies and proposes techniques to alleviate two key\nbottlenecks to executing deep neural networks in trusted execution environments\n(TEEs): page thrashing during the execution of convolutional layers and the\ndecryption of large weight matrices in fully-connected layers. For the former,\nwe propose a novel partitioning scheme, y-plane partitioning, designed to (ii)\nprovide consistent execution time when the layer output is large compared to\nthe TEE secure memory; and (ii) significantly reduce the memory footprint of\nconvolutional layers. For the latter, we leverage quantization and compression.\nIn our evaluation, the proposed optimizations incurred latency overheads\nranging from 1.09X to 2X baseline for a wide range of TEE sizes; in contrast,\nan unmodified implementation incurred latencies of up to 26X when running\ninside of the TEE.\n", "versions": [{"version": "v1", "created": "Fri, 30 Apr 2021 16:48:14 GMT"}], "update_date": "2021-05-03", "authors_parsed": [["Truong", "Jean-Baptiste", ""], ["Gallagher", "William", ""], ["Guo", "Tian", ""], ["Walls", "Robert J.", ""]]}, {"id": "2104.15135", "submitter": "Piyawat Lertvittayakumjorn", "authors": "Piyawat Lertvittayakumjorn, Francesca Toni", "title": "Explanation-Based Human Debugging of NLP Models: A Survey", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To fix a bug in a program, we need to locate where the bug is, understand why\nit causes the problem, and patch the code accordingly. This process becomes\nharder when the program is a trained machine learning model and even harder for\nopaque deep learning models. In this survey, we review papers that exploit\nexplanations to enable humans to debug NLP models. We call this problem\nexplanation-based human debugging (EBHD). In particular, we categorize and\ndiscuss existing works along three main dimensions of EBHD (the bug context,\nthe workflow, and the experimental setting), compile findings on how EBHD\ncomponents affect human debuggers, and highlight open problems that could be\nfuture research directions.\n", "versions": [{"version": "v1", "created": "Fri, 30 Apr 2021 17:53:07 GMT"}], "update_date": "2021-05-03", "authors_parsed": [["Lertvittayakumjorn", "Piyawat", ""], ["Toni", "Francesca", ""]]}]